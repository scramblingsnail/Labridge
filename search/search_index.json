{"config":{"lang":["en","zh"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Labridge","text":""},{"location":"#_1","title":"\u201d\u200b\u6c47\u200b\u6d93\u6ef4\u200b\u4ee5\u6210\u200b\u6c5f\u6d77\u200b\u201c","text":"<p>Labridge \u200b\u5e0c\u671b\u200b\u80fd\u4e3a\u200b\u6240\u6709\u200b\u7684\u200b\u79d1\u5b66\u200b\u5b9e\u9a8c\u5ba4\u200b\u642d\u5efa\u200b\u6c9f\u901a\u200b\u4e0e\u200b\u5408\u4f5c\u200b\u7684\u200b\u6865\u6881\u200b\uff0c\u200b\u63d0\u9ad8\u200b\u79d1\u7814\u200b\u5de5\u4f5c\u8005\u200b\u7684\u200b\u6548\u7387\u200b\uff0c\u200b\u50ac\u5316\u200b\u65b0\u200b\u77e5\u8bc6\u200b\u7684\u200b\u8bde\u751f\u200b\u3002</p> <p></p>"},{"location":"agent_tools/prompt_framework/","title":"Agent\u200b\u63d0\u793a\u200b\u8bcd\u200b\u6846\u67b6","text":"<p>\u200b\u6211\u4eec\u200b\u91c7\u7528\u200b\u4e86\u200b CoT(Chain of Thought) + ReAct(Reasoning &amp; Acting) \u200b\u63d0\u793a\u200b\u8bcd\u200b\u6846\u67b6\u200b\uff0c \u200b\u5e76\u4e14\u200bLabridge\u200b\u5728\u200b Reasoning phase \u200b\u548c\u200b Acting phase \u200b\u4e2d\u200b\uff0c\u200b\u4e3a\u200b\u63d0\u4f9b\u200b\u7528\u6237\u200b\u8fdb\u884c\u200b\u4ecb\u5165\u200b\u7684\u200b\u63a5\u53e3\u200b\uff0c\u200b\u4f7f\u5f97\u200b\u7528\u6237\u200b\u53ef\u4ee5\u200b\u53c2\u4e0e\u200b \u200b\u5230\u200bAgent\u200b\u7684\u200b\u601d\u8003\u200b\u4e0e\u200b\u51b3\u7b56\u200b\u7684\u200b\u8fc7\u7a0b\u200b\u4e2d\u200b\u53bb\u200b\uff0c\u200b\u5bf9\u200bAgent\u200b\u7684\u200b\u884c\u4e3a\u200b\u63d0\u4f9b\u200b\u7ec6\u7c92\u5ea6\u200b\u7684\u200b\u63a7\u5236\u200b\u3002 \u200b\u6211\u4eec\u200b\u79f0\u4e4b\u4e3a\u200b <code>InstructReAct</code></p> <p>\u200b\u793a\u4f8b\u200b\uff1a\u200b\u4ecb\u5165\u200bAgent\u200b\u7684\u200bReasoning &amp; Acting</p> <ul> <li>\u200b\u6307\u4ee4\u200b\u6a21\u5f0f\u200b</li> <li>\u200b\u6307\u4ee4\u200b\u6a21\u5f0f\u200b &amp; \u200b\u8bc4\u8bba\u200b\u6a21\u5f0f\u200b</li> </ul>"},{"location":"agent_tools/prompt_framework/#react","title":"ReAct\u200b\u63d0\u793a\u200b\u8bcd","text":"<pre><code>Your role is that of a research assistant in the laboratory. \nYou will assist the researchers in various aspects of their research, \nincluding helping with research paper reading, research paper retrieval, paper downloading and \nmanagement, integration of laboratory instrument information, recording and retrieval of experimental logs, \nas well as any other aspects that contribute to scientific research.\n\n## Tools\nYou have access to a wide variety of tools. You are responsible for using\nthe tools in any sequence you deem appropriate to complete the task at hand.\nThis may require breaking the task into subtasks and using different tools\nto complete each subtask.\n\nYou have access to the following tools:\n{tool_desc}\n\nyou must follow the instruction below:\n\nTo answer the question using extra tools, think step-by-step, and please use the following format.\n\nThought: Think step-by-step, In order to answer the overall question, given the executed actions and their observations, \n    What's my target in this step? Which tool should I use to help me accomplish this target?\nAction: tool name (one of {tool_names}) if using a tool.\nAction Input: the input to the tool, in a JSON format representing the kwargs (e.g. {{\"input\": \"hello world\", \"num_beams\": 5}})\n\nPlease ALWAYS start with a Thought.\n\nWhen you decide to call a tool, you should strictly follow the format above.\nAdditionally, you MUST NOT user the JSON formatted tool call as your final answer.\nPlease use a valid JSON format for the Action Input. Do NOT do this {{'input': 'hello world', 'num_beams': 5}}.\n\n\nIf this format is used, the user will respond in the following format:\n\nObservation: tool response\n\n## Output Format\n\nWhen you decide to answer, you MUST respond in the one of the following two formats:\nYou MUST return valid and direct response that can answer the user's question, DO NOT output the Tool Call.\n\nThought: I have complete all the sub-tasks and I can answer without using any more tools. \nAnswer: [your answer here]\n\nThought: I cannot answer the question with the provided tools.\nAnswer: Sorry, I cannot answer your query.\n\n## Current Conversation\nBelow is the current conversation consisting of interleaving human and assistant messages.\n</code></pre>"},{"location":"agent_tools/prompt_framework/#instruct","title":"Instruct\u200b\u63d0\u793a\u200b\u8bcd","text":"<pre><code>Your role is that of a research assistant in the laboratory. \nYou will assist the researchers in various aspects of their research, \nincluding helping with research paper reading, research paper retrieval, paper downloading and \nmanagement, integration of laboratory instrument information, recording and retrieval of experimental logs, \nas well as any other aspects that contribute to scientific research.\n\n## Tools\nYou have access to a wide variety of tools. You are responsible for using\nthe tools in any sequence you deem appropriate to complete the task at hand.\nThis may require breaking the task into subtasks and using different tools\nto complete each subtask.\n\nYou have access to the following tools:\n{tool_desc}\n\nSeveral tools have been previously chose by another assistant:\nPrevious choice: {prev_response}\n\nThe User gives some suggestions to the previously selected action:\nUser suggestion: {suggestion}\n\nNow you should adopt the user's suggestions to optimize the tool choices to better answer the question.\nIf the user gives no valid suggestion, or agrees with the previous selected action,\nno modification is needed, just use the previous selected action.\n\nyou must follow the instruction below:\n\n## Output Format\nplease use the following format.\n\nThought: Given the previous action: {prev_response}, Following the user's suggestions: {suggestion}, \ndo I need to modify my action? If need, how should I adjust my action to meet the user's requirements better?\nAction: tool name (one of {tool_names}) if using a tool.\nAction Input: the input to the tool, in a JSON format representing the kwargs (e.g. {{\"input\": \"hello world\", \"num_beams\": 5}})\n\nPlease ALWAYS start with a Thought.\n\nPlease use a valid JSON format for the Action Input. Do NOT do this {{'input': 'hello world', 'num_beams': 5}}.\n\nIf this format is used, the user will respond in the following format:\n\n## Current Conversation\nBelow is the current conversation consisting of interleaving human and assistant messages.\n</code></pre>"},{"location":"agent_tools/tools/","title":"Agent\u200b\u53ef\u200b\u8c03\u7528\u200b\u5de5\u5177","text":"<p>Labridge\u200b\u76ee\u524d\u200b\u53ef\u200b\u8c03\u7528\u200b\u5982\u4e0b\u200b\u5de5\u5177\u200b\uff1a</p> <ul> <li>SharedPaperRetrieverTool</li> <li>RecentPaperRetrieveTool</li> <li>RecentPaperSummarizeTool</li> <li>ArXivSearchDownloadTool</li> <li>AddNewRecentPaperTool</li> <li>ExperimentLogRetrieveTool</li> <li>CreateNewExperimentLogTool</li> <li>SetCurrentExperimentTool</li> <li>RecordExperimentLogTool</li> <li>ChatMemoryRetrieverTool</li> </ul> <p>\u200b\u6240\u6709\u200b\u9700\u8981\u200b\u5b9e\u9a8c\u5ba4\u200b\u6210\u5458\u200b\u6388\u6743\u200b\u7684\u200b\u64cd\u4f5c\u200b\u88ab\u200b\u5b9a\u4e49\u200b\u4e3a\u200b CallbackOperation,  \u200b\u5982\u200b\u521b\u5efa\u200b\u5b9e\u9a8c\u200b\u8bb0\u5f55\u200b\u3001\u200b\u4e0b\u8f7d\u200b\u6587\u732e\u200b\u7b49\u200b\u3002 CallbackOperation \u200b\u7684\u200b\u5177\u4f53\u200b\u5b9a\u4e49\u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Callback.base.operation_base</code></p> <p>\u200b\u76ee\u524d\u200b\u7684\u200b CallbackOperation \u200b\u5305\u62ec\u200b\uff1a</p> <ul> <li>ArxivDownloadOperation \u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Callback.paper.paper_download</code></li> <li>AddNewRecentPaperOperation \u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Callback.paper.add_recent_paper</code></li> <li>PaperSummarizeOperation \u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Callback.paper.paper_summarize</code></li> <li>CreateNewExperimentLogOperation \u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Callback.experiment_log.new_experiment</code></li> <li>SetCurrentExperimentOperation \u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Callback.experiment_log.set_current_experiment</code></li> </ul> <p>\u200b\u6211\u4eec\u200b\u63d0\u4f9b\u200b\u5982\u4e0b\u200b\u5de5\u5177\u200b\u6a21\u677f\u200b\uff0c\u200b\u7528\u4ee5\u200b\u5f00\u53d1\u200b\u7b26\u5408\u200b </p> <p>\u201c\u200b\u6536\u96c6\u200b\u7528\u6237\u200b\u4fe1\u606f\u200b \u2192 \u200b\u5b9a\u4e49\u200b\u6267\u884c\u200b\u64cd\u4f5c\u200b \u2192 \u200b\u5f81\u53d6\u200b\u7528\u6237\u200b\u6388\u6743\u200b \u2192 \u200b\u6267\u884c\u200bCallback\u200b\u64cd\u4f5c\u200b\u201d </p> <p>\u200b\u6d41\u7a0b\u200b\u7684\u200b\u5de5\u5177\u200b</p> <ul> <li>CollectAndAuthorizeTool</li> </ul>"},{"location":"agent_tools/tools/base/tool_base/","title":"\u5404\u79cd\u200bTools\u200b\u7684\u200b\u57fa\u7c7b","text":""},{"location":"agent_tools/tools/base/tool_base/#checkbasetool","title":"CheckBaseTool","text":"<p>\u200b\u8fd9\u4e2a\u200b\u5de5\u5177\u200b\u6a21\u677f\u200b\u5b9e\u73b0\u200b\u4e86\u200b\u4ece\u200b\u8f93\u5165\u200b\u53c2\u6570\u200b\u4e2d\u200b\u68c0\u67e5\u200b\u4e0e\u200b\u83b7\u53d6\u200b\u6240\u200b\u9700\u200b\u53c2\u6570\u200b\u7684\u200b\u529f\u80fd\u200b\u3002</p> <p>\u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Tools.base.tool_base</code></p>"},{"location":"agent_tools/tools/base/tool_base/#retrieverbasetool","title":"RetrieverBaseTool","text":"<p>\u200b\u8fd9\u4e2a\u200b\u5de5\u5177\u200b\u6a21\u677f\u200b\u5b9e\u73b0\u200b\u4e86\u200b\u4f7f\u7528\u200b\u6240\u200b\u7ed9\u200bRetriever\u200b\u8fdb\u884c\u200b\u68c0\u7d22\u200b\uff0c\u200b\u5e76\u200b\u8bb0\u5f55\u200b\u53c2\u8003\u200b\u6587\u6863\u200b\u7b49\u200b\u5de5\u5177\u200b\u65e5\u5fd7\u200b\u7684\u200b\u529f\u80fd\u200b\u3002</p> <p>\u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Tools.base.tool_base</code></p>"},{"location":"agent_tools/tools/base/tool_base/#queryenginebasetool","title":"QueryEngineBaseTool","text":"<p>\u200b\u8fd9\u4e2a\u200b\u5de5\u5177\u200b\u6a21\u677f\u200b\u5b9e\u73b0\u200b\u4e86\u200b\u57fa\u4e8e\u200b\u5411\u91cf\u200b\u6570\u636e\u5e93\u200b\u8fdb\u884c\u200b\u95ee\u7b54\u200b\u7684\u200b\u529f\u80fd\u200b</p> <p>\u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Tools.base.tool_base</code></p>"},{"location":"agent_tools/tools/base/tool_base/#functionbasetool","title":"FunctionBaseTool","text":"<p>\u200b\u8fd9\u4e2a\u200b\u5de5\u5177\u200b\u6a21\u677f\u200b\u5b9e\u73b0\u200b\u4e86\u200b\u8c03\u7528\u200b\u6307\u5b9a\u200b\u51fd\u6570\u200b\u6216\u7c7b\u200b\u65b9\u6cd5\u200b\uff0c\u200b\u5e76\u200b\u8bb0\u5f55\u200b\u5de5\u5177\u200b\u65e5\u5fd7\u200b\u7684\u200b\u529f\u80fd\u200b</p>"},{"location":"agent_tools/tools/base/tool_log/","title":"\u5de5\u5177\u200b\u8c03\u7528\u200b\u65e5\u5fd7","text":""},{"location":"agent_tools/tools/base/tool_log/#toollog","title":"ToolLog","text":"<p>\u200b\u8fd9\u4e2a\u200b\u7c7b\u200b\u8bb0\u5f55\u200b\u67d0\u4e2a\u200b\u5de5\u5177\u200b\u8c03\u7528\u200b\u7684\u200b\u65e5\u5fd7\u200b\uff0c\u200b\u5305\u542b\u200b\u5982\u4e0b\u200b\u4fe1\u606f\u200b\uff1a</p> <ul> <li>tool_name: \u200b\u8c03\u7528\u200b\u7684\u200b\u5de5\u5177\u200b\u540d\u79f0\u200b</li> <li>log_to_user: \u200b\u8fd9\u90e8\u5206\u200b\u65e5\u5fd7\u200b\u5c06\u4f1a\u200b\u4f5c\u4e3a\u200b\u989d\u5916\u200b\u4fe1\u606f\u200b\u52a0\u200b\u5728\u200bLabridge\u200b\u5bf9\u200b\u7528\u6237\u200b\u56de\u590d\u200b\u7684\u200b\u672b\u5c3e\u200b</li> <li>log_to_system: \u200b\u8fd9\u90e8\u5206\u200b\u65e5\u5fd7\u200b\u5c06\u200b\u5b58\u50a8\u200b\u4e8e\u200b\u7528\u6237\u200b\u7684\u200b\u4ea4\u4e92\u200b\u65e5\u5fd7\u200b\u6570\u636e\u5e93\u200b</li> </ul> <p>\u200b\u5177\u4f53\u200b\u7ec6\u8282\u200b\u8bf7\u200b\u53c2\u8003\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Tools.base.tool_log</code></p>"},{"location":"agent_tools/tools/chat_history/chat_memory_retrieve_tool/","title":"SharedPaperRetrieverTool","text":"<p>\u200b\u8fd9\u4e2a\u200b\u5de5\u5177\u200b\u7528\u4e8e\u200b\u4ece\u200b\u5b9e\u9a8c\u5ba4\u200b\u5171\u4eab\u200b\u6587\u732e\u200b\u5e93\u4e2d\u200b\u68c0\u7d22\u200b\u76f8\u5173\u200b\u4fe1\u606f\u200b\u3002</p>"},{"location":"agent_tools/tools/chat_history/chat_memory_retrieve_tool/#_1","title":"\u8c03\u7528\u200b\u53c2\u6570","text":"<ul> <li>item_to_be_retrieved (str): \u200b\u5f85\u200b\u68c0\u7d22\u200b\u4fe1\u606f\u200b</li> <li>memory_id (str): \u200b\u6210\u5458\u200b\u540d\u200b\u6216\u200b\u6210\u5458\u200b\u5c0f\u7ec4\u200b\u540d\u200b</li> <li>start_date (Optional[str]): \u200b\u65f6\u95f4\u200b\u8fc7\u6ee4\u200b\u7684\u200b\u5f00\u59cb\u200b\u65e5\u671f\u200b</li> <li>end_date (Optional[str]): \u200b\u65f6\u95f4\u200b\u8fc7\u6ee4\u200b\u7684\u200b\u7ed3\u675f\u200b\u65e5\u671f\u200b</li> <li>kwargs (Any): \u200b\u63d0\u9ad8\u200b LLM \u200b\u8c03\u7528\u200b\u672c\u200b\u5de5\u5177\u200b\u7684\u200b\u5bb9\u9519\u200b</li> </ul>"},{"location":"agent_tools/tools/chat_history/chat_memory_retrieve_tool/#_2","title":"\u5de5\u5177\u200b\u63cf\u8ff0","text":"<pre><code>This tool is used to retrieve relevant chat history in a certain chat history memory.\nThe memory_id of a chat history memory is the `user_id` of a specific user or the `chat_group_id` of a specific\nchat group.\n\nAdditionally, you can provide the `start_date` and `end_state` to limit the retrieving range of date,\nThe end date can be the same as the start date, but should not be earlier than the start date.\nIf the start date or end_date is not provided, retrieving will be performed among the whole memory.\n\nArgs:\n    item_to_be_retrieved (str): Things that you want to retrieve in the chat history memory.\n    memory_id (str): The memory_id of a chat history memory. It is either a `user_id` or a `chat_group_id`.\n    start_date (str): The START date of the retrieving date limit. Defaults to None.\n        If given, it should be given in the following FORMAT: Year-Month-Day.\n        For example, 2020-12-1 means the year 2020, the 12th month, the 1rst day.\n    end_date (str): The END date of the retrieving date limit. Defaults to None.\n        If given, It should be given in the following FORMAT: Year-Month-Day.\n        For example, 2024-6-2 means the year 2024, the 6th month, the 2nd day.\n\nReturns:\n    Retrieved chat history.\n</code></pre> <p>\u200b\u8be6\u7ec6\u200b\u5185\u5bb9\u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Tools.memory.chat.retrieve</code></p>"},{"location":"agent_tools/tools/experiment_log/create_new_experiment_log/","title":"CreateNewExperimentLogTool","text":"<p>\u200b\u8fd9\u4e2a\u200b\u5de5\u5177\u200b\u7528\u4e8e\u200b\u4e3a\u200b\u67d0\u4e2a\u200b\u6210\u5458\u200b\u5728\u200b\u5176\u200b\u5b9e\u9a8c\u200b\u65e5\u5fd7\u200b\u6570\u636e\u5e93\u200b\u4e2d\u200b\u65b0\u5efa\u200b\u5b9e\u9a8c\u200b\u8bb0\u5f55\u200b\u3002</p> <p>\u200b\u6ce8\u200b\uff1a\u200b\u8fd9\u4e2a\u200b\u5de5\u5177\u200b\u662f\u200b\u4e00\u4e2a\u200b <code>CollectAndAuthorizeTool</code> \u200b\u6a21\u677f\u200b\u5de5\u5177\u200b\uff0c\u200b\u9700\u8981\u200b\u6536\u96c6\u200b\u7528\u6237\u200b\u4fe1\u606f\u200b\u4ee5\u53ca\u200b\u83b7\u53d6\u200b\u7528\u6237\u200b\u6388\u6743\u200b\u3002</p>"},{"location":"agent_tools/tools/experiment_log/create_new_experiment_log/#_1","title":"\u8c03\u7528\u200b\u53c2\u6570","text":"<ul> <li>user_id (str): \u200b\u6210\u5458\u200b\u540d\u200b</li> </ul>"},{"location":"agent_tools/tools/experiment_log/create_new_experiment_log/#_2","title":"\u5de5\u5177\u200b\u63cf\u8ff0","text":"<pre><code>This tool is used to create a new experiment log record for the user.\nThis tool is only used when the user asks for creating a new experiment log record,\nor when other tools call this tool.\n\nArgs:\n    user_id (str): The user_id of a lab member.\n\nReturns:\n    The tool's output and log.\n</code></pre> <p>\u200b\u8be6\u7ec6\u200b\u5185\u5bb9\u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Tools.memory.experiment.insert</code></p>"},{"location":"agent_tools/tools/experiment_log/experiment_log_retrieve_tool/","title":"ExperimentLogRetrieveTool","text":"<p>\u200b\u8fd9\u4e2a\u200b\u5de5\u5177\u200b\u7528\u4e8e\u200b\u4ece\u200b\u67d0\u4e2a\u200b\u6210\u5458\u200b\u7684\u200b\u5b9e\u9a8c\u200b\u65e5\u5fd7\u200b\u6570\u636e\u5e93\u200b\u4e2d\u200b\u68c0\u7d22\u200b\u76f8\u5173\u200b\u4fe1\u606f\u200b\u3002</p>"},{"location":"agent_tools/tools/experiment_log/experiment_log_retrieve_tool/#_1","title":"\u8c03\u7528\u200b\u53c2\u6570","text":"<ul> <li>item_to_be_retrieved (str): \u200b\u5f85\u200b\u68c0\u7d22\u200b\u4fe1\u606f\u200b</li> <li>memory_id (str): \u200b\u6210\u5458\u200b\u540d\u200b</li> <li>start_date (Optional[str]): \u200b\u65f6\u95f4\u200b\u8fc7\u6ee4\u200b\u7684\u200b\u5f00\u59cb\u200b\u65e5\u671f\u200b</li> <li>end_date (Optional[str]): \u200b\u65f6\u95f4\u200b\u8fc7\u6ee4\u200b\u7684\u200b\u7ed3\u675f\u200b\u65e5\u671f\u200b</li> <li>experiment_name (Optional[str]): \u200b\u6307\u5b9a\u200b\u5b9e\u9a8c\u200b\u540d\u79f0\u200b\uff0c\u200b\u9650\u5236\u200b\u68c0\u7d22\u200b\u8303\u56f4\u200b</li> <li>kwargs (Any): \u200b\u63d0\u9ad8\u200b LLM \u200b\u8c03\u7528\u200b\u672c\u200b\u5de5\u5177\u200b\u7684\u200b\u5bb9\u9519\u200b</li> </ul>"},{"location":"agent_tools/tools/experiment_log/experiment_log_retrieve_tool/#_2","title":"\u5de5\u5177\u200b\u63cf\u8ff0","text":"<pre><code>This tool is used to retrieve experiment logs of a user.\nUse this tool to help you to answer questions about experimental records.\n\nArgs:\n    item_to_be_retrieved (str): This argument is necessary.\n        It denotes things that you want to retrieve in the chat history memory.\n    memory_id (str): This argument is necessary.\n        It is the user_id of a lab member.\n    start_date (str): This argument is optional.\n        It denotes the start date in the format 'Year-Month-Day'.\n        If both start_date and end_date are specified, only logs which are recorded between the\n        start_date and end_date will be retrieved.\n    end_date (str): This argument is optional.\n        It denotes the end date in the format 'Year-Month-Day'.\n    experiment_name (str): This argument is optional.\n        It is the name of a specific experiment.\n        If it is specified and is valid, only logs of this experiment will be retrieved.\n    kwargs: Other arguments will be ignored.\n\nReturns:\n    Retrieved experiment logs.\n</code></pre> <p>\u200b\u8be6\u7ec6\u200b\u5185\u5bb9\u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Tools.memory.experiment.retrieve</code></p>"},{"location":"agent_tools/tools/experiment_log/record_experiment_log_tool/","title":"RecordExperimentLogTool","text":"<p>\u200b\u8fd9\u4e2a\u200b\u5de5\u5177\u200b\u7528\u4e8e\u200b\u4e3a\u200b\u67d0\u4e2a\u200b\u6210\u5458\u200b\u8bb0\u5f55\u200b\u5b9e\u9a8c\u200b\u65e5\u5fd7\u200b\u3002</p>"},{"location":"agent_tools/tools/experiment_log/record_experiment_log_tool/#_1","title":"\u8c03\u7528\u200b\u53c2\u6570","text":"<ul> <li>user_id (str): \u200b\u6210\u5458\u200b\u540d\u200b</li> <li>log_str (str): \u200b\u5b9e\u9a8c\u200b\u65e5\u5fd7\u200b</li> </ul>"},{"location":"agent_tools/tools/experiment_log/record_experiment_log_tool/#_2","title":"\u5de5\u5177\u200b\u63cf\u8ff0","text":"<pre><code>This tool is used to record the experiment log of the experiment in progress for a user.\n\nIf the no experiment record exists or experiment in progress is not valid, this tool will call\nthe corresponding tools to help the user.\n\nArgs:\n    user_id (str): The user_id of a lab member.\n    log_str (str): The experiment log to be recorded.\n\nReturns:\n    The tool output and log.\n</code></pre> <p>\u200b\u8be6\u7ec6\u200b\u5185\u5bb9\u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Tools.memory.experiment.insert</code></p>"},{"location":"agent_tools/tools/experiment_log/set_current_experiment_tool/","title":"SetCurrentExperimentTool","text":"<p>\u200b\u8fd9\u4e2a\u200b\u5de5\u5177\u200b\u7528\u4e8e\u200b\u4e3a\u200b\u67d0\u4e2a\u200b\u6210\u5458\u200b\u8bbe\u7f6e\u200b\u5f53\u524d\u200b\u8fdb\u884c\u200b\u7684\u200b\u5b9e\u9a8c\u200b\uff0c\u200b\u5b9e\u9a8c\u200b\u8fdb\u884c\u200b\u671f\u95f4\u200b\u7684\u200b\u65e5\u5fd7\u200b\u5c06\u4f1a\u200b\u6dfb\u52a0\u200b\u5728\u200b\u8be5\u200b\u5b9e\u9a8c\u200b\u7684\u200b\u5bf9\u5e94\u200b\u8bb0\u5f55\u200b\u4e2d\u200b\u3002</p> <p>\u200b\u6ce8\u200b\uff1a\u200b\u8fd9\u4e2a\u200b\u5de5\u5177\u200b\u662f\u200b\u4e00\u4e2a\u200b <code>CollectAndAuthorizeTool</code> \u200b\u6a21\u677f\u200b\u5de5\u5177\u200b\uff0c\u200b\u9700\u8981\u200b\u6536\u96c6\u200b\u7528\u6237\u200b\u4fe1\u606f\u200b\u4ee5\u53ca\u200b\u83b7\u53d6\u200b\u7528\u6237\u200b\u6388\u6743\u200b\u3002</p>"},{"location":"agent_tools/tools/experiment_log/set_current_experiment_tool/#_1","title":"\u8c03\u7528\u200b\u53c2\u6570","text":"<ul> <li>user_id (str): \u200b\u6210\u5458\u200b\u540d\u200b</li> </ul>"},{"location":"agent_tools/tools/experiment_log/set_current_experiment_tool/#_2","title":"\u5de5\u5177\u200b\u63cf\u8ff0","text":"<pre><code>This tool is used to record the experiment log of the experiment in progress for a user.\n\nIf the no experiment record exists or experiment in progress is not valid, this tool will call\nthe corresponding tools to help the user.\n\nArgs:\n    user_id (str): The user_id of a lab member.\n    log_str (str): The experiment log to be recorded.\n\nReturns:\n    The tool output and log.\n</code></pre> <p>\u200b\u8be6\u7ec6\u200b\u5185\u5bb9\u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Tools.memory.experiment.insert</code></p>"},{"location":"agent_tools/tools/interact/collect_and_authorize_tool/","title":"CollectAndAuthorizeTool","text":"<p>\u200b\u8fd9\u662f\u200b\u4e00\u4e2a\u200b\u5de5\u5177\u200b\u6a21\u677f\u200b\uff0c\u200b\u5728\u200b\u6b64\u57fa\u7840\u200b\u4e0a\u200b\u5f00\u53d1\u200b\u7b26\u5408\u200b \u201c\u200b\u6536\u96c6\u200b\u7528\u6237\u200b\u4fe1\u606f\u200b \u2192 \u200b\u5b9a\u4e49\u200b\u6267\u884c\u200b\u64cd\u4f5c\u200b \u2192 \u200b\u5f81\u53d6\u200b\u7528\u6237\u200b\u6388\u6743\u200b \u2192 \u200b\u6267\u884c\u200bCallback\u200b\u64cd\u4f5c\u200b\u201d \u200b\u6d41\u7a0b\u200b\u7684\u200b\u5de5\u5177\u200b</p> <p>\u200b\u8be6\u7ec6\u200b\u5185\u5bb9\u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Tools.interact.collect_and_authorize</code></p> <p></p>"},{"location":"agent_tools/tools/shared_papers/shared_paper_retrieve_tool/","title":"SharedPaperRetrieverTool","text":"<p>\u200b\u8fd9\u4e2a\u200b\u5de5\u5177\u200b\u7528\u4e8e\u200b\u4ece\u200b\u5b9e\u9a8c\u5ba4\u200b\u5171\u4eab\u200b\u6587\u732e\u200b\u4fe1\u606f\u5e93\u200b\u4e2d\u200b\u68c0\u7d22\u200b\u76f8\u5173\u200b\u4fe1\u606f\u200b\u3002</p>"},{"location":"agent_tools/tools/shared_papers/shared_paper_retrieve_tool/#_1","title":"\u8c03\u7528\u200b\u53c2\u6570","text":"<ul> <li>item_to_be_retrieved (str): \u200b\u5f85\u200b\u68c0\u7d22\u200b\u4fe1\u606f\u200b</li> </ul>"},{"location":"agent_tools/tools/shared_papers/shared_paper_retrieve_tool/#_2","title":"\u5de5\u5177\u200b\u63cf\u8ff0","text":"<pre><code>This tool is used to retrieve academic information in the Laboratory's shared paper database.\nIt is useful to help answer the user's academic questions.\n\nArgs:\n    item_to_be_retrieved (str): The things that you want to retrieve in the shared paper database.\n</code></pre> <p>\u200b\u8be6\u7ec6\u200b\u5185\u5bb9\u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Tools.paper.shared_papers.retriever</code></p>"},{"location":"agent_tools/tools/temporary_papers/add_new_recent_paper_tool/","title":"AddNewRecentPaperTool","text":"<p>\u200b\u8fd9\u4e2a\u200b\u5de5\u5177\u200b\u7528\u4e8e\u200b\u5411\u200b\u67d0\u4e2a\u200b\u6210\u5458\u200b\u7684\u200b\u8fd1\u671f\u200b\u6587\u732e\u200b\u5e93\u4e2d\u200b\u6dfb\u52a0\u200b\u6587\u732e\u200b\u3002</p>"},{"location":"agent_tools/tools/temporary_papers/add_new_recent_paper_tool/#_1","title":"\u8c03\u7528\u200b\u53c2\u6570","text":"<ul> <li>user_id (str): \u200b\u6210\u5458\u200b\u4fe1\u606f\u200b</li> <li>paper_file_path (str): \u200b\u65b0\u200b\u6587\u732e\u200b\u7684\u200b\u8def\u5f84\u200b</li> </ul>"},{"location":"agent_tools/tools/temporary_papers/add_new_recent_paper_tool/#_2","title":"\u5de5\u5177\u200b\u63cf\u8ff0","text":"<pre><code>This tool is used to add a new paper to a specific user's recent papers storage.\n\nArgs:\n    user_id (str): The user_id of a lab member.\n    paper_file_path (str): The file path of the paper to be added. Browse the chat context or tool logs\n        to get the correct and valid file path.\n\nReturns:\n    FuncOutputWithLog: The output and log.\n</code></pre> <p>\u200b\u8be6\u7ec6\u200b\u5185\u5bb9\u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Tools.paper.temporary_papers.insert</code></p>"},{"location":"agent_tools/tools/temporary_papers/arxiv_search_download_tool/","title":"ArXivSearchDownloadTool","text":"<p>\u200b\u8fd9\u4e2a\u200b\u5de5\u5177\u200b\u7528\u4e8e\u200b\u4e3a\u200b\u67d0\u4e2a\u200b\u6210\u5458\u200b\u4ece\u200barXiv\u200b\u4e0a\u200b\u68c0\u7d22\u200b\u5e76\u200b\u4e0b\u8f7d\u200b\u6587\u732e\u200b\u3002</p> <p>\u200b\u6ce8\u200b\uff1a\u200b\u8fd9\u662f\u200b\u4e00\u4e2a\u200b\u9700\u8981\u200b\u7528\u6237\u200b\u6388\u6743\u200b\u7684\u200b\u5de5\u5177\u200b\u3002</p>"},{"location":"agent_tools/tools/temporary_papers/arxiv_search_download_tool/#_1","title":"\u8c03\u7528\u200b\u53c2\u6570","text":"<ul> <li>user_id (str): \u200b\u6210\u5458\u200b\u540d\u200b</li> <li>search_str (str): \u200b\u5f85\u200b\u68c0\u7d22\u200b\u4fe1\u606f\u200b</li> <li>kwargs (Any): \u200b\u7528\u4e8e\u200b\u63d0\u9ad8\u200b LLM \u200b\u8c03\u7528\u200b\u672c\u200b\u5de5\u5177\u200b\u7684\u200b\u5bb9\u9519\u200b</li> </ul>"},{"location":"agent_tools/tools/temporary_papers/arxiv_search_download_tool/#_2","title":"\u5de5\u5177\u200b\u63cf\u8ff0","text":"<pre><code>This tool is used to search relevant papers in arXiv and download the papers that the user is interested in.\nWhen using the tool, be sure that the search_str MUST be English.\nIf the user do not use English, translate the search string to English first.\n\nArgs:\n    user_id (str): The user_id of a lab member.\n    search_str (str): The string that is used to search in arXiv.\n\nReturns:\n    FuncOutputWithLog: the operation output and log.\n</code></pre> <p>\u200b\u8be6\u7ec6\u200b\u5185\u5bb9\u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Tools.paper.download.arxiv_download</code></p>"},{"location":"agent_tools/tools/temporary_papers/recent_paper_retrieve_tool/","title":"RecentPaperRetrieveTool","text":"<p>\u200b\u8fd9\u4e2a\u200b\u5de5\u5177\u200b\u7528\u4e8e\u200b\u4ece\u200b\u67d0\u4e2a\u200b\u6210\u5458\u200b\u7684\u200b\u8fd1\u671f\u200b\u6587\u732e\u200b\u5e93\u4e2d\u200b\u68c0\u7d22\u200b\u76f8\u5173\u200b\u4fe1\u606f\u200b\u3002</p>"},{"location":"agent_tools/tools/temporary_papers/recent_paper_retrieve_tool/#_1","title":"\u8c03\u7528\u200b\u53c2\u6570","text":"<ul> <li>paper_info (str): \u200b\u76ee\u6807\u200b\u6587\u732e\u200b\u7684\u200b\u76f8\u5173\u200b\u4fe1\u606f\u200b\uff0c\u200b\u5982\u200b\u6807\u9898\u200b\uff0c\u200b\u6587\u4ef6\u200b\u8def\u5f84\u200b\u7b49\u200b</li> <li>item_to_be_retrieved (str): \u200b\u5f85\u200b\u68c0\u7d22\u200b\u4fe1\u606f\u200b</li> <li>user_id (str): \u200b\u6210\u5458\u200b\u540d\u200b</li> <li>start_date (Optional[str]): \u200b\u65f6\u95f4\u200b\u8fc7\u6ee4\u200b\u7684\u200b\u5f00\u59cb\u200b\u65e5\u671f\u200b</li> <li>end_date (Optional[str]): \u200b\u65f6\u95f4\u200b\u8fc7\u6ee4\u200b\u7684\u200b\u7ed3\u675f\u200b\u65e5\u671f\u200b</li> <li>kwargs (Any): \u200b\u7528\u4e8e\u200b\u63d0\u9ad8\u200b LLM \u200b\u8c03\u7528\u200b\u672c\u200b\u5de5\u5177\u200b\u7684\u200b\u5bb9\u9519\u200b</li> </ul>"},{"location":"agent_tools/tools/temporary_papers/recent_paper_retrieve_tool/#_2","title":"\u5de5\u5177\u200b\u63cf\u8ff0","text":"<pre><code>This tool is used to retrieve in the recent papers storage of a specific user.\nThese information should be provided:\n1. The paper information, such as title or save path.\n2. The specific question that you want to obtain answer from the paper.\n3. The user id.\n\nArgs:\n    paper_info (str): This argument is necessary.\n        It is the relevant information of the paper.\n        For example, it can be the paper title, or its save path.\n    item_to_be_retrieved (str): This argument is necessary.\n        It denotes the specific question that you want to retrieve in a specific paper.\n    user_id (str): This argument is necessary.\n        The user_id of a lab member.\n    start_date (str): This argument is optional. It denotes the start date in the format 'Year-Month-Day'.\n        If both start_date and end_date are specified, only papers which are added to storage between the\n        start_date and end_date will be retrieved.\n    end_date: This argument is optional. It denotes the end date in the format 'Year-Month-Day'.\n    **kwargs: Other keyword arguments will be ignored.\n\nReturns:\n    The retrieved results.\n</code></pre> <p>\u200b\u8be6\u7ec6\u200b\u5185\u5bb9\u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Tools.paper.temporary_papers.paper_retriever</code></p>"},{"location":"agent_tools/tools/temporary_papers/recent_paper_summarize_tool/","title":"RecentPaperSummarizeTool","text":"<p>\u200b\u8fd9\u4e2a\u200b\u5de5\u5177\u200b\u7528\u4e8e\u200b\u4e3a\u200b\u67d0\u4e2a\u200b\u6210\u5458\u200b\u603b\u7ed3\u200b\u5176\u200b\u8fd1\u671f\u200b\u6587\u732e\u200b\u5e93\u200b\u7684\u200b\u6587\u732e\u200b\uff0c\u200b\u6216\u200b\u5c06\u200b\u65b0\u200b\u6587\u732e\u200b\u52a0\u5165\u200b\u8fd1\u671f\u200b\u6587\u732e\u200b\u5e93\u200b\u5e76\u200b\u603b\u7ed3\u200b\u3002</p>"},{"location":"agent_tools/tools/temporary_papers/recent_paper_summarize_tool/#_1","title":"\u8c03\u7528\u200b\u53c2\u6570","text":"<ul> <li>user_id (str): \u200b\u6210\u5458\u200b\u540d\u200b</li> <li>paper_file_path (str): \u200b\u5f85\u200b\u603b\u7ed3\u200b\u6587\u732e\u200b\u8def\u5f84\u200b</li> </ul>"},{"location":"agent_tools/tools/temporary_papers/recent_paper_summarize_tool/#_2","title":"\u5de5\u5177\u200b\u63cf\u8ff0","text":"<pre><code>This tool is used to summarize a paper that is stored in a specific user's recent papers storage.\nThis tool is used ONLY when the user explicitly ask for a summarization of the paper.\nDO NOT use this tool by yourself.\n\nArgs:\n    user_id (str): The user_id of a lab member.\n    paper_file_path (str): The file path of a specific paper. Browse the chat context to get the correct\n        and valid file path of the paper.\n\nReturns:\n    The summary of the paper.\n</code></pre> <p>\u200b\u8be6\u7ec6\u200b\u5185\u5bb9\u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Tools.paper.temporary_papers.paper_summarize</code></p>"},{"location":"code_docs/accounts/super_users/","title":"Super users","text":""},{"location":"code_docs/accounts/super_users/#labridge.accounts.super_users","title":"<code>labridge.accounts.super_users</code>","text":""},{"location":"code_docs/accounts/super_users/#labridge.accounts.super_users.InstrumentSuperUserManager","title":"<code>labridge.accounts.super_users.InstrumentSuperUserManager</code>","text":"<p>               Bases: <code>object</code></p> <p>This is the account manager of super-users.</p> <p>Each set of super-users are related to a specific scientific instrument. These super-users own full authority to their instruments, and are responsible for the instrument management such as updating instruction manual, adding a new super-user, etc.</p> <p>The accounts of super-users are stored as a dictionary as follows in a json format. <code>{instrument_id: [super_user_ids, ]}</code></p> Source code in <code>labridge\\accounts\\super_users.py</code> <pre><code>class InstrumentSuperUserManager(object):\n\tr\"\"\"\n\tThis is the account manager of super-users.\n\n\tEach set of super-users are related to a specific scientific instrument.\n\tThese super-users own full authority to their instruments, and are responsible for the instrument management such as\n\tupdating instruction manual, adding a new super-user, etc.\n\n\tThe accounts of super-users are stored as a dictionary as follows in a json format.\n\t`{instrument_id: [super_user_ids, ]}`\n\t\"\"\"\n\tdef __init__(self):\n\t\troot = Path(__file__)\n\t\tfor idx in range(3):\n\t\t\troot = root.parent\n\t\tself.root = root\n\t\tself.super_user_ids_path = str(root / SUPER_USER_IDS_PERSIS_PATH)\n\t\tself.fs = fsspec.filesystem(\"file\")\n\t\tdir_path = str(Path(self.super_user_ids_path).parent)\n\t\tif not self.fs.exists(dir_path):\n\t\t\tself.fs.makedirs(dir_path)\n\n\tdef _get_user_ids_dict(self) -&gt; Dict[str, List[str]]:\n\t\tr\"\"\" Get the super-user accounts dictionary. \"\"\"\n\t\tif not self.fs.exists(self.super_user_ids_path):\n\t\t\treturn {}\n\t\twith self.fs.open(self.super_user_ids_path, \"rb\") as f:\n\t\t\tsuper_user_ids = json.load(f)\n\t\treturn super_user_ids\n\n\tdef get_super_users(self, instrument_id: str) -&gt; List[str]:\n\t\tr\"\"\" Get the super-users of a specific instrument. \"\"\"\n\t\treturn list(self._get_user_ids_dict()[instrument_id])\n\n\tdef is_super_user(self, user_id: str, instrument_id: str) -&gt; bool:\n\t\tr\"\"\" Judge whether a user is the super-user of a instrument. \"\"\"\n\t\tsuper_user_list = self.get_super_users(instrument_id=instrument_id)\n\t\treturn user_id in super_user_list\n\n\t@staticmethod\n\tdef check_users(user_id: Union[str, List[str]]):\n\t\tr\"\"\" Check whether all given users have registered.\"\"\"\n\t\tuser_manager = AccountManager()\n\t\tif not isinstance(user_id, list):\n\t\t\tuser_id = [user_id]\n\n\t\tfor user in user_id:\n\t\t\tuser_manager.check_valid_user(user_id=user)\n\n\tdef add_super_user(self, user_id: str, instrument_id: str):\n\t\tr\"\"\" Add a new super-user for the instrument. \"\"\"\n\t\tsuper_user_ids = self._get_user_ids_dict()\n\t\tself.check_users(user_id=user_id)\n\n\t\tif instrument_id not in super_user_ids.keys():\n\t\t\traise ValueError(f\"The instrument {instrument_id} is not registered yet.\")\n\n\t\tsuper_user_ids[instrument_id].append(user_id)\n\t\twith self.fs.open(self.super_user_ids_path, \"w\") as f:\n\t\t\tf.write(json.dumps(super_user_ids))\n\n\tdef delete_super_user(self, user_id: str, instrument_id: str):\n\t\tr\"\"\" Delete a super-user of the instrument. \"\"\"\n\t\tsuper_user_ids = self._get_user_ids_dict()\n\t\tif instrument_id not in super_user_ids.keys():\n\t\t\traise ValueError(f\"The instrument {instrument_id} is not registered yet.\")\n\t\tsuper_user_ids[instrument_id].remove(user_id)\n\t\twith self.fs.open(self.super_user_ids_path, \"w\") as f:\n\t\t\tf.write(json.dumps(super_user_ids))\n\n\tdef add_instrument(self, instrument_id: str, super_users: List[str]):\n\t\tr\"\"\" Add a new instrument along with its super-users. \"\"\"\n\t\tsuper_user_ids = self._get_user_ids_dict()\n\t\tif instrument_id in super_user_ids.keys():\n\t\t\traise ValueError(f\"The instrument {instrument_id} already exists.\")\n\n\t\tself.check_users(user_id=super_users)\n\t\tsuper_user_ids[instrument_id] = super_users\n\t\twith self.fs.open(self.super_user_ids_path, \"w\") as f:\n\t\t\tf.write(json.dumps(super_user_ids))\n</code></pre>"},{"location":"code_docs/accounts/super_users/#labridge.accounts.super_users.InstrumentSuperUserManager.add_instrument","title":"<code>labridge.accounts.super_users.InstrumentSuperUserManager.add_instrument(instrument_id, super_users)</code>","text":"<p>Add a new instrument along with its super-users.</p> Source code in <code>labridge\\accounts\\super_users.py</code> <pre><code>def add_instrument(self, instrument_id: str, super_users: List[str]):\n\tr\"\"\" Add a new instrument along with its super-users. \"\"\"\n\tsuper_user_ids = self._get_user_ids_dict()\n\tif instrument_id in super_user_ids.keys():\n\t\traise ValueError(f\"The instrument {instrument_id} already exists.\")\n\n\tself.check_users(user_id=super_users)\n\tsuper_user_ids[instrument_id] = super_users\n\twith self.fs.open(self.super_user_ids_path, \"w\") as f:\n\t\tf.write(json.dumps(super_user_ids))\n</code></pre>"},{"location":"code_docs/accounts/super_users/#labridge.accounts.super_users.InstrumentSuperUserManager.add_super_user","title":"<code>labridge.accounts.super_users.InstrumentSuperUserManager.add_super_user(user_id, instrument_id)</code>","text":"<p>Add a new super-user for the instrument.</p> Source code in <code>labridge\\accounts\\super_users.py</code> <pre><code>def add_super_user(self, user_id: str, instrument_id: str):\n\tr\"\"\" Add a new super-user for the instrument. \"\"\"\n\tsuper_user_ids = self._get_user_ids_dict()\n\tself.check_users(user_id=user_id)\n\n\tif instrument_id not in super_user_ids.keys():\n\t\traise ValueError(f\"The instrument {instrument_id} is not registered yet.\")\n\n\tsuper_user_ids[instrument_id].append(user_id)\n\twith self.fs.open(self.super_user_ids_path, \"w\") as f:\n\t\tf.write(json.dumps(super_user_ids))\n</code></pre>"},{"location":"code_docs/accounts/super_users/#labridge.accounts.super_users.InstrumentSuperUserManager.check_users","title":"<code>labridge.accounts.super_users.InstrumentSuperUserManager.check_users(user_id)</code>  <code>staticmethod</code>","text":"<p>Check whether all given users have registered.</p> Source code in <code>labridge\\accounts\\super_users.py</code> <pre><code>@staticmethod\ndef check_users(user_id: Union[str, List[str]]):\n\tr\"\"\" Check whether all given users have registered.\"\"\"\n\tuser_manager = AccountManager()\n\tif not isinstance(user_id, list):\n\t\tuser_id = [user_id]\n\n\tfor user in user_id:\n\t\tuser_manager.check_valid_user(user_id=user)\n</code></pre>"},{"location":"code_docs/accounts/super_users/#labridge.accounts.super_users.InstrumentSuperUserManager.delete_super_user","title":"<code>labridge.accounts.super_users.InstrumentSuperUserManager.delete_super_user(user_id, instrument_id)</code>","text":"<p>Delete a super-user of the instrument.</p> Source code in <code>labridge\\accounts\\super_users.py</code> <pre><code>def delete_super_user(self, user_id: str, instrument_id: str):\n\tr\"\"\" Delete a super-user of the instrument. \"\"\"\n\tsuper_user_ids = self._get_user_ids_dict()\n\tif instrument_id not in super_user_ids.keys():\n\t\traise ValueError(f\"The instrument {instrument_id} is not registered yet.\")\n\tsuper_user_ids[instrument_id].remove(user_id)\n\twith self.fs.open(self.super_user_ids_path, \"w\") as f:\n\t\tf.write(json.dumps(super_user_ids))\n</code></pre>"},{"location":"code_docs/accounts/super_users/#labridge.accounts.super_users.InstrumentSuperUserManager.get_super_users","title":"<code>labridge.accounts.super_users.InstrumentSuperUserManager.get_super_users(instrument_id)</code>","text":"<p>Get the super-users of a specific instrument.</p> Source code in <code>labridge\\accounts\\super_users.py</code> <pre><code>def get_super_users(self, instrument_id: str) -&gt; List[str]:\n\tr\"\"\" Get the super-users of a specific instrument. \"\"\"\n\treturn list(self._get_user_ids_dict()[instrument_id])\n</code></pre>"},{"location":"code_docs/accounts/super_users/#labridge.accounts.super_users.InstrumentSuperUserManager.is_super_user","title":"<code>labridge.accounts.super_users.InstrumentSuperUserManager.is_super_user(user_id, instrument_id)</code>","text":"<p>Judge whether a user is the super-user of a instrument.</p> Source code in <code>labridge\\accounts\\super_users.py</code> <pre><code>def is_super_user(self, user_id: str, instrument_id: str) -&gt; bool:\n\tr\"\"\" Judge whether a user is the super-user of a instrument. \"\"\"\n\tsuper_user_list = self.get_super_users(instrument_id=instrument_id)\n\treturn user_id in super_user_list\n</code></pre>"},{"location":"code_docs/accounts/users/","title":"Users","text":""},{"location":"code_docs/accounts/users/#labridge.accounts.users","title":"<code>labridge.accounts.users</code>","text":""},{"location":"code_docs/accounts/users/#labridge.accounts.users.AccountManager","title":"<code>labridge.accounts.users.AccountManager</code>","text":"<p>               Bases: <code>object</code></p> <p>This is account manager of the Laboratory members and chat groups. Only registered users have access to the Lab assistant.</p> <p>The user account information is stored as a dictionary in JSON format: <code>{user_id: password}</code></p> <p>The chat groups information is stored as a dictionary in JSON format: <code>{chat_group_id: [user_id, ]}</code></p> Source code in <code>labridge\\accounts\\users.py</code> <pre><code>class AccountManager(object):\n\tr\"\"\"\n\tThis is account manager of the Laboratory members and chat groups.\n\tOnly registered users have access to the Lab assistant.\n\n\tThe user account information is stored as a dictionary in JSON format:\n\t`{user_id: password}`\n\n\tThe chat groups information is stored as a dictionary in JSON format:\n\t`{chat_group_id: [user_id, ]}`\n\t\"\"\"\n\tdef __init__(self):\n\t\troot = Path(__file__)\n\t\tfor idx in range(3):\n\t\t\troot = root.parent\n\t\tself.root = root\n\t\tself.user_ids_path = str(root / USER_IDS_PERSIS_PATH)\n\t\tself.chat_group_ids_path = str(root / CHAT_GROUP_IDS_PERSIST_PATH)\n\t\tself.fs = fsspec.filesystem(\"file\")\n\t\tdir_path = str(Path(self.user_ids_path).parent)\n\t\tif not self.fs.exists(dir_path):\n\t\t\tself.fs.makedirs(dir_path)\n\n\tdef _get_user_ids_dict(self) -&gt; Dict[str, str]:\n\t\tr\"\"\" Get the user account dict. \"\"\"\n\t\tif not self.fs.exists(self.user_ids_path):\n\t\t\treturn {}\n\t\twith self.fs.open(self.user_ids_path, \"rb\") as f:\n\t\t\tuser_ids = json.load(f)\n\t\treturn user_ids\n\n\tdef _get_chat_group_ids_dict(self) -&gt; Dict[str, List[str]]:\n\t\tr\"\"\" Get the chat group id dict. \"\"\"\n\t\tif not self.fs.exists(self.chat_group_ids_path):\n\t\t\treturn {}\n\t\twith self.fs.open(self.chat_group_ids_path, \"rb\") as f:\n\t\t\tchat_group_ids = json.load(f)\n\t\treturn chat_group_ids\n\n\tdef get_users(self) -&gt; List[str]:\n\t\tr\"\"\" Get the registered users. \"\"\"\n\t\treturn list(self._get_user_ids_dict().keys())\n\n\tdef get_chat_groups(self) -&gt; List[str]:\n\t\tr\"\"\" Get the registered chat groups \"\"\"\n\t\treturn list(self._get_chat_group_ids_dict().keys())\n\n\tdef user_log_in(self, user_id: str, password: str) -&gt; bool:\n\t\tr\"\"\" User log in \"\"\"\n\t\ttry:\n\t\t\tself.check_valid_user(user_id)\n\t\t\tuser_ids = self._get_user_ids_dict()\n\t\t\treturn password == user_ids[user_id]\n\t\texcept ValueError:\n\t\t\treturn False\n\n\tdef check_valid_user(self, user_id: str):\n\t\tr\"\"\" Check whether the given user is registered. \"\"\"\n\t\tuser_list = self.get_users()\n\t\tif user_id not in user_list:\n\t\t\traise ValueError(f\"Invalid user id, the user {user_id} is not registered.\")\n\n\tdef is_valid_chat_group(self, chat_group_id: str):\n\t\tr\"\"\" Check whether the given chat group is registered \"\"\"\n\t\tchat_group_list = self.get_chat_groups()\n\t\tif chat_group_id not in chat_group_list:\n\t\t\traise ValueError(f\"The chat group {chat_group_id} is not registered.\")\n\n\tdef add_user(self, user_id: str, password: str):\n\t\tr\"\"\" Register a new user. \"\"\"\n\t\tuser_ids = self._get_user_ids_dict()\n\n\t\tif user_id not in user_ids:\n\t\t\tuser_ids[user_id] = password\n\t\t\twith self.fs.open(self.user_ids_path, \"w\") as f:\n\t\t\t\tf.write(json.dumps(user_ids))\n\n\tdef add_chat_group(self, chat_group_id: str, user_list: List[str]) -&gt; Optional[str]:\n\t\tr\"\"\"\n\t\tRegister a new chat group along with its members.\n\t\tAll members in the chat group should have registered as a user.\n\t\t\"\"\"\n\t\tfor user_id in user_list:\n\t\t\ttry:\n\t\t\t\tself.check_valid_user(user_id)\n\t\t\texcept ValueError as e:\n\t\t\t\treturn f\"Error: {e!s}\"\n\n\t\tchat_group_ids = self._get_chat_group_ids_dict()\n\n\t\tif chat_group_id not in chat_group_ids:\n\t\t\tchat_group_ids[chat_group_id] = user_list\n\t\t\twith self.fs.open(self.chat_group_ids_path, \"w\") as f:\n\t\t\t\tf.write(json.dumps(chat_group_ids))\n\t\t\treturn None\n\n\tdef update_chat_group_members(self, chat_group_id: str, new_user_list: List[str]) -&gt; Optional[str]:\n\t\tr\"\"\" Update the members of a chat group. \"\"\"\n\t\tfor user_id in new_user_list:\n\t\t\ttry:\n\t\t\t\tself.check_valid_user(user_id)\n\t\t\texcept ValueError as e:\n\t\t\t\treturn f\"Error: {e!s}\"\n\n\t\tchat_group_ids = self._get_chat_group_ids_dict()\n\t\tchat_group_ids[chat_group_id] = new_user_list\n\t\twith self.fs.open(self.chat_group_ids_path, \"w\") as f:\n\t\t\tf.write(json.dumps(chat_group_ids))\n\t\treturn None\n</code></pre>"},{"location":"code_docs/accounts/users/#labridge.accounts.users.AccountManager.add_chat_group","title":"<code>labridge.accounts.users.AccountManager.add_chat_group(chat_group_id, user_list)</code>","text":"<p>Register a new chat group along with its members. All members in the chat group should have registered as a user.</p> Source code in <code>labridge\\accounts\\users.py</code> <pre><code>def add_chat_group(self, chat_group_id: str, user_list: List[str]) -&gt; Optional[str]:\n\tr\"\"\"\n\tRegister a new chat group along with its members.\n\tAll members in the chat group should have registered as a user.\n\t\"\"\"\n\tfor user_id in user_list:\n\t\ttry:\n\t\t\tself.check_valid_user(user_id)\n\t\texcept ValueError as e:\n\t\t\treturn f\"Error: {e!s}\"\n\n\tchat_group_ids = self._get_chat_group_ids_dict()\n\n\tif chat_group_id not in chat_group_ids:\n\t\tchat_group_ids[chat_group_id] = user_list\n\t\twith self.fs.open(self.chat_group_ids_path, \"w\") as f:\n\t\t\tf.write(json.dumps(chat_group_ids))\n\t\treturn None\n</code></pre>"},{"location":"code_docs/accounts/users/#labridge.accounts.users.AccountManager.add_user","title":"<code>labridge.accounts.users.AccountManager.add_user(user_id, password)</code>","text":"<p>Register a new user.</p> Source code in <code>labridge\\accounts\\users.py</code> <pre><code>def add_user(self, user_id: str, password: str):\n\tr\"\"\" Register a new user. \"\"\"\n\tuser_ids = self._get_user_ids_dict()\n\n\tif user_id not in user_ids:\n\t\tuser_ids[user_id] = password\n\t\twith self.fs.open(self.user_ids_path, \"w\") as f:\n\t\t\tf.write(json.dumps(user_ids))\n</code></pre>"},{"location":"code_docs/accounts/users/#labridge.accounts.users.AccountManager.check_valid_user","title":"<code>labridge.accounts.users.AccountManager.check_valid_user(user_id)</code>","text":"<p>Check whether the given user is registered.</p> Source code in <code>labridge\\accounts\\users.py</code> <pre><code>def check_valid_user(self, user_id: str):\n\tr\"\"\" Check whether the given user is registered. \"\"\"\n\tuser_list = self.get_users()\n\tif user_id not in user_list:\n\t\traise ValueError(f\"Invalid user id, the user {user_id} is not registered.\")\n</code></pre>"},{"location":"code_docs/accounts/users/#labridge.accounts.users.AccountManager.get_chat_groups","title":"<code>labridge.accounts.users.AccountManager.get_chat_groups()</code>","text":"<p>Get the registered chat groups</p> Source code in <code>labridge\\accounts\\users.py</code> <pre><code>def get_chat_groups(self) -&gt; List[str]:\n\tr\"\"\" Get the registered chat groups \"\"\"\n\treturn list(self._get_chat_group_ids_dict().keys())\n</code></pre>"},{"location":"code_docs/accounts/users/#labridge.accounts.users.AccountManager.get_users","title":"<code>labridge.accounts.users.AccountManager.get_users()</code>","text":"<p>Get the registered users.</p> Source code in <code>labridge\\accounts\\users.py</code> <pre><code>def get_users(self) -&gt; List[str]:\n\tr\"\"\" Get the registered users. \"\"\"\n\treturn list(self._get_user_ids_dict().keys())\n</code></pre>"},{"location":"code_docs/accounts/users/#labridge.accounts.users.AccountManager.is_valid_chat_group","title":"<code>labridge.accounts.users.AccountManager.is_valid_chat_group(chat_group_id)</code>","text":"<p>Check whether the given chat group is registered</p> Source code in <code>labridge\\accounts\\users.py</code> <pre><code>def is_valid_chat_group(self, chat_group_id: str):\n\tr\"\"\" Check whether the given chat group is registered \"\"\"\n\tchat_group_list = self.get_chat_groups()\n\tif chat_group_id not in chat_group_list:\n\t\traise ValueError(f\"The chat group {chat_group_id} is not registered.\")\n</code></pre>"},{"location":"code_docs/accounts/users/#labridge.accounts.users.AccountManager.update_chat_group_members","title":"<code>labridge.accounts.users.AccountManager.update_chat_group_members(chat_group_id, new_user_list)</code>","text":"<p>Update the members of a chat group.</p> Source code in <code>labridge\\accounts\\users.py</code> <pre><code>def update_chat_group_members(self, chat_group_id: str, new_user_list: List[str]) -&gt; Optional[str]:\n\tr\"\"\" Update the members of a chat group. \"\"\"\n\tfor user_id in new_user_list:\n\t\ttry:\n\t\t\tself.check_valid_user(user_id)\n\t\texcept ValueError as e:\n\t\t\treturn f\"Error: {e!s}\"\n\n\tchat_group_ids = self._get_chat_group_ids_dict()\n\tchat_group_ids[chat_group_id] = new_user_list\n\twith self.fs.open(self.chat_group_ids_path, \"w\") as f:\n\t\tf.write(json.dumps(chat_group_ids))\n\treturn None\n</code></pre>"},{"location":"code_docs/accounts/users/#labridge.accounts.users.AccountManager.user_log_in","title":"<code>labridge.accounts.users.AccountManager.user_log_in(user_id, password)</code>","text":"<p>User log in</p> Source code in <code>labridge\\accounts\\users.py</code> <pre><code>def user_log_in(self, user_id: str, password: str) -&gt; bool:\n\tr\"\"\" User log in \"\"\"\n\ttry:\n\t\tself.check_valid_user(user_id)\n\t\tuser_ids = self._get_user_ids_dict()\n\t\treturn password == user_ids[user_id]\n\texcept ValueError:\n\t\treturn False\n</code></pre>"},{"location":"code_docs/agent/chat_agent/","title":"Chat agent","text":""},{"location":"code_docs/agent/chat_agent/#labridge.agent.chat_agent","title":"<code>labridge.agent.chat_agent</code>","text":""},{"location":"code_docs/agent/chat_agent/#labridge.agent.chat_agent.LabChatAgent","title":"<code>labridge.agent.chat_agent.LabChatAgent</code>","text":"<p>This is the Chat agent following the ReAct framework, with access to multiple tools ranging papers, instruments and experiments.</p> Source code in <code>labridge\\agent\\chat_agent.py</code> <pre><code>class LabChatAgent:\n\tr\"\"\"\n\tThis is the Chat agent following the ReAct framework, with access to multiple tools\n\tranging papers, instruments and experiments.\n\t\"\"\"\n\n\tdef __init__(\n\t\tself,\n\t\tchat_engine: InstructReActAgent = None,\n\t):\n\t\tself._chat_engine = chat_engine\n\t\tself._short_memory_manager = ShortMemoryManager()\n\t\tself._account_manager = AccountManager()\n\t\tself._chatting_status = {}\n\t\tself.reset_chatting_status()\n\n\tdef reset_chatting_status(self):\n\t\tusers = self._account_manager.get_users()\n\t\tself._chatting_status = {user: False for user in users}\n\n\tdef update_users(self):\n\t\tself._account_manager = AccountManager()\n\n\t@property\n\tdef chat_engine(self) -&gt; InstructReActAgent:\n\t\tif self._chat_engine is None:\n\t\t\tself._chat_engine = self.get_chat_engine()\n\t\treturn self._chat_engine\n\n\tdef is_chatting(self, user_id: str) -&gt; bool:\n\t\treturn self._chatting_status[user_id]\n\n\tdef set_chatting(self, user_id: str, chatting: bool):\n\t\tself._chatting_status[user_id] = chatting\n\n\t@property\n\tdef short_memory_manager(self):\n\t\treturn self._short_memory_manager\n\n\tasync def chat(self, packed_msgs: PackedUserMessage) -&gt; AgentResponse:\n\t\tr\"\"\" Chat with agent. \"\"\"\n\t\tuser_id = packed_msgs.user_id\n\t\tself.set_chatting(user_id=user_id, chatting=True)\n\t\tpacked_json = packed_msgs.dumps()\n\t\tchat_history = self.short_memory_manager.load_memory(user_id=user_id)\n\n\t\tresponse = await self.chat_engine.achat(\n\t\t\tmessage=packed_json,\n\t\t\tchat_history=chat_history,\n\t\t)\n\t\tchat_history = self.chat_engine.memory.get()\n\t\tself.short_memory_manager.save_memory(user_id=user_id, chat_history=chat_history)\n\t\tself.chat_engine.reset()\n\n\t\tref_paths = response.metadata[\"references\"]\n\t\tif len(ref_paths) &lt; 1:\n\t\t\tref_paths = None\n\n\t\tagent_response = AgentResponse(\n\t\t\tresponse=response.response,\n\t\t\treferences=ref_paths,\n\t\t)\n\t\treturn agent_response\n\n\tdef test_chat(self, packed_msgs: PackedUserMessage) -&gt; AgentResponse:\n\t\tr\"\"\" Debug. \"\"\"\n\t\tuser_id = packed_msgs.user_id\n\t\tself.set_chatting(user_id=user_id, chatting=True)\n\t\tpacked_json = packed_msgs.dumps()\n\t\tchat_history = self.short_memory_manager.load_memory(user_id=user_id)\n\n\t\tresponse = self.chat_engine.chat(\n\t\t\tmessage=packed_json,\n\t\t\tchat_history=chat_history,\n\t\t)\n\t\tchat_history = self.chat_engine.memory.get()\n\t\tself.short_memory_manager.save_memory(user_id=user_id, chat_history=chat_history)\n\n\t\tref_paths = response.metadata[\"references\"]\n\t\tif len(ref_paths) &lt; 1:\n\t\t\tref_paths = None\n\n\t\tagent_response = AgentResponse(\n\t\t\tresponse=response.response,\n\t\t\treferences=ref_paths,\n\t\t)\n\t\treturn agent_response\n\n\n\tdef get_tools(self) -&gt; List[AsyncBaseTool]:\n\t\tr\"\"\" Available tools. \"\"\"\n\t\treturn [\n\t\t\tChatMemoryRetrieverTool(),\n\t\t\tExperimentLogRetrieveTool(),\n\t\t\tCreateNewExperimentLogTool(),\n\t\t\tSetCurrentExperimentTool(),\n\t\t\tRecordExperimentLogTool(),\n\t\t\tSharedPaperRetrieverTool(),\n\t\t\tArXivSearchDownloadTool(),\n\t\t\tAddNewRecentPaperTool(),\n\t\t\tRecentPaperRetrieveTool(),\n\t\t\tRecentPaperSummarizeTool(),\n\t\t\tInstrumentRetrieverTool(),\n\t\t]\n\n\tdef get_chat_engine(self) -&gt; InstructReActAgent:\n\t\tllm, embed_model = get_models()\n\t\tSettings.embed_model = embed_model\n\t\tSettings.llm = llm\n\t\ttools = self.get_tools()\n\n\t\treact_chat_formatter = ReActChatFormatter.from_defaults(system_header=LABRIDGE_CHAT_SYSTEM_HEADER)\n\n\t\tchat_engine = InstructReActAgent.from_tools(\n\t\t\ttools=tools,\n\t\t\treact_chat_formatter=react_chat_formatter,\n\t\t\tverbose=True,\n\t\t\tllm=llm,\n\t\t\tmemory=ChatMemoryBuffer.from_defaults(token_limit=3000),\n\t\t\tenable_instruct=False,\n\t\t\tenable_comment=False,\n\t\t\tmax_iterations=20,\n\t\t)\n\t\treturn chat_engine\n</code></pre>"},{"location":"code_docs/agent/chat_agent/#labridge.agent.chat_agent.LabChatAgent.chat","title":"<code>labridge.agent.chat_agent.LabChatAgent.chat(packed_msgs)</code>  <code>async</code>","text":"<p>Chat with agent.</p> Source code in <code>labridge\\agent\\chat_agent.py</code> <pre><code>async def chat(self, packed_msgs: PackedUserMessage) -&gt; AgentResponse:\n\tr\"\"\" Chat with agent. \"\"\"\n\tuser_id = packed_msgs.user_id\n\tself.set_chatting(user_id=user_id, chatting=True)\n\tpacked_json = packed_msgs.dumps()\n\tchat_history = self.short_memory_manager.load_memory(user_id=user_id)\n\n\tresponse = await self.chat_engine.achat(\n\t\tmessage=packed_json,\n\t\tchat_history=chat_history,\n\t)\n\tchat_history = self.chat_engine.memory.get()\n\tself.short_memory_manager.save_memory(user_id=user_id, chat_history=chat_history)\n\tself.chat_engine.reset()\n\n\tref_paths = response.metadata[\"references\"]\n\tif len(ref_paths) &lt; 1:\n\t\tref_paths = None\n\n\tagent_response = AgentResponse(\n\t\tresponse=response.response,\n\t\treferences=ref_paths,\n\t)\n\treturn agent_response\n</code></pre>"},{"location":"code_docs/agent/chat_agent/#labridge.agent.chat_agent.LabChatAgent.get_tools","title":"<code>labridge.agent.chat_agent.LabChatAgent.get_tools()</code>","text":"<p>Available tools.</p> Source code in <code>labridge\\agent\\chat_agent.py</code> <pre><code>def get_tools(self) -&gt; List[AsyncBaseTool]:\n\tr\"\"\" Available tools. \"\"\"\n\treturn [\n\t\tChatMemoryRetrieverTool(),\n\t\tExperimentLogRetrieveTool(),\n\t\tCreateNewExperimentLogTool(),\n\t\tSetCurrentExperimentTool(),\n\t\tRecordExperimentLogTool(),\n\t\tSharedPaperRetrieverTool(),\n\t\tArXivSearchDownloadTool(),\n\t\tAddNewRecentPaperTool(),\n\t\tRecentPaperRetrieveTool(),\n\t\tRecentPaperSummarizeTool(),\n\t\tInstrumentRetrieverTool(),\n\t]\n</code></pre>"},{"location":"code_docs/agent/chat_agent/#labridge.agent.chat_agent.LabChatAgent.test_chat","title":"<code>labridge.agent.chat_agent.LabChatAgent.test_chat(packed_msgs)</code>","text":"<p>Debug.</p> Source code in <code>labridge\\agent\\chat_agent.py</code> <pre><code>def test_chat(self, packed_msgs: PackedUserMessage) -&gt; AgentResponse:\n\tr\"\"\" Debug. \"\"\"\n\tuser_id = packed_msgs.user_id\n\tself.set_chatting(user_id=user_id, chatting=True)\n\tpacked_json = packed_msgs.dumps()\n\tchat_history = self.short_memory_manager.load_memory(user_id=user_id)\n\n\tresponse = self.chat_engine.chat(\n\t\tmessage=packed_json,\n\t\tchat_history=chat_history,\n\t)\n\tchat_history = self.chat_engine.memory.get()\n\tself.short_memory_manager.save_memory(user_id=user_id, chat_history=chat_history)\n\n\tref_paths = response.metadata[\"references\"]\n\tif len(ref_paths) &lt; 1:\n\t\tref_paths = None\n\n\tagent_response = AgentResponse(\n\t\tresponse=response.response,\n\t\treferences=ref_paths,\n\t)\n\treturn agent_response\n</code></pre>"},{"location":"code_docs/agent/chat_msg/msg_types/","title":"Msg types","text":""},{"location":"code_docs/agent/chat_msg/msg_types/#labridge.agent.chat_msg.msg_types","title":"<code>labridge.agent.chat_msg.msg_types</code>","text":""},{"location":"code_docs/agent/chat_msg/msg_types/#labridge.agent.chat_msg.msg_types.AgentResponse","title":"<code>labridge.agent.chat_msg.msg_types.AgentResponse</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>The response of chat agent.</p> <p>response (str): The response string. references (Optional[List[str]]): The paths of reference files.</p> Source code in <code>labridge\\agent\\chat_msg\\msg_types.py</code> <pre><code>class AgentResponse(BaseModel):\n\tr\"\"\"\n\tThe response of chat agent.\n\n\tresponse (str): The response string.\n\treferences (Optional[List[str]]): The paths of reference files.\n\t\"\"\"\n\tresponse: str\n\treferences: Optional[List[str]]\n</code></pre>"},{"location":"code_docs/agent/chat_msg/msg_types/#labridge.agent.chat_msg.msg_types.BaseClientMessage","title":"<code>labridge.agent.chat_msg.msg_types.BaseClientMessage</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>This is the base class for client's messages.</p> <p>user_id (str): The user id of a Lab member. reply_in_speech (bool): If True, the agent will reply in speech. enable_instruct (bool): If True, enable the user to intervene into the agent's reasoning phase. enable_comment (bool): If True: enable the user to intervene into the agent's acting phase.</p> Source code in <code>labridge\\agent\\chat_msg\\msg_types.py</code> <pre><code>class BaseClientMessage(BaseModel):\n\tr\"\"\"\n\tThis is the base class for client's messages.\n\n\tuser_id (str): The user id of a Lab member.\n\treply_in_speech (bool): If True, the agent will reply in speech.\n\tenable_instruct (bool): If True, enable the user to intervene into the agent's reasoning phase.\n\tenable_comment (bool): If True: enable the user to intervene into the agent's acting phase.\n\t\"\"\"\n\tuser_id: str\n\treply_in_speech: bool\n\tenable_instruct: bool\n\tenable_comment: bool\n</code></pre>"},{"location":"code_docs/agent/chat_msg/msg_types/#labridge.agent.chat_msg.msg_types.ChatMsgBuffer","title":"<code>labridge.agent.chat_msg.msg_types.ChatMsgBuffer</code>","text":"<p>               Bases: <code>object</code></p> <p>This class includes buffers that manager the messages from users and the agent's corresponding reply.</p> <p>Before a chat, the user's messages will put into the <code>user_msg_buffer</code>. When the agent get a user's messages, these messages will be packed and used as input to Call <code>Chat()</code>.</p> <p>Additionally, During the execution of <code>Chat()</code>, the agent is able to get new messages from the buffer, such as when collecting information from the user in some tools.</p> <p>The response of the agent will be put into the <code>agent_reply_buffer</code>, similarly, the user may receive an 'inner' response from the buffer.</p> <p>Depending on the user's choice <code>reply_in_speech</code>, the agent's response will be sent back to the user directly or transformed to speech before that.</p> Source code in <code>labridge\\agent\\chat_msg\\msg_types.py</code> <pre><code>class ChatMsgBuffer(object):\n\tr\"\"\"\n\tThis class includes buffers that manager the messages from users and the agent's corresponding reply.\n\n\tBefore a chat, the user's messages will put into the `user_msg_buffer`.\n\tWhen the agent get a user's messages, these messages will be packed and used as input to Call `Chat()`.\n\n\tAdditionally, During the execution of `Chat()`, the agent is able to get new messages from the buffer, such as\n\twhen collecting information from the user in some tools.\n\n\tThe response of the agent will be put into the `agent_reply_buffer`, similarly, the user may receive an 'inner'\n\tresponse from the buffer.\n\n\tDepending on the user's choice `reply_in_speech`, the agent's response will be sent back to the user directly or\n\ttransformed to speech before that.\n\t\"\"\"\n\tdef __init__(self):\n\t\troot = Path(__file__)\n\t\tfor i in range(4):\n\t\t\troot = root.parent\n\t\tself._root = root\n\t\tself.account_manager = AccountManager()\n\t\tself.user_msg_buffer: Dict[str, List[BaseClientMessage]] = {}\n\t\tself.agent_reply_buffer: Dict[str, Optional[Union[ServerReply, ServerSpeechReply]]] = {}\n\t\tself.config_buffer: Dict[str, ChatConfig] = {}\n\t\tself.user_msg_formatter = UserMsgFormatter()\n\t\tself.reset_buffer()\n\t\tself._fs = fsspec.filesystem(\"file\")\n\n\tdef reset_buffer(self):\n\t\tr\"\"\"\n\t\tReset the user_msg_buffer and agent_reply_buffer.\n\n\t\tReturns:\n\t\t\tNone\n\t\t\"\"\"\n\t\tusers = self.account_manager.get_users()\n\t\tself.user_msg_buffer = {user: [] for user in users}\n\t\tself.agent_reply_buffer = {user: None for user in users}\n\t\tself.config_buffer = {user: ChatConfig() for user in users}\n\n\tdef clear_user_msg(self, user_id: str):\n\t\tr\"\"\"\n\t\tClear a user's messages in the buffer.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user id of a Lab member.\n\t\t\"\"\"\n\t\tself.user_msg_buffer[user_id] = []\n\n\tdef put_user_msg(self, user_msg: BaseClientMessage):\n\t\tr\"\"\"\n\t\tPut a new user message into the buffer.\n\n\t\tArgs:\n\t\t\tuser_msg (BaseClientMessage): A new message from a user.\n\t\t\"\"\"\n\t\tif not isinstance(user_msg, (FileWithTextMessage, ChatTextMessage, ChatSpeechMessage)):\n\t\t\traise ValueError(f\"The Msg type {type(user_msg)} is not supported.\")\n\n\t\tuser_id = user_msg.user_id\n\t\tself.account_manager.check_valid_user(user_id=user_id)\n\t\tself.user_msg_buffer[user_id].append(user_msg)\n\t\tself.config_buffer[user_id].update(\n\t\t\tenable_instruct=user_msg.enable_instruct,\n\t\t\tenable_comment=user_msg.enable_comment,\n\t\t\treply_in_speech=user_msg.reply_in_speech,\n\t\t)\n\n\tasync def get_user_msg(self, user_id: str, timeout: int = 240) -&gt; Optional[PackedUserMessage]:\n\t\tr\"\"\"\n\t\tWait until a user's messages are put into the buffer, and get them.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user id of a Lab member.\n\t\t\ttimeout (int): If timeout, return None.\n\n\t\tReturns:\n\t\t\tOptional[PackedUserMessage]: The obtained packed user messages.\n\t\t\t\tIf no user messages if put in until time is out, return None.\n\t\t\"\"\"\n\t\tstart_time = time.time()\n\n\t\twhile True:\n\t\t\tmsgs = self.user_msg_buffer[user_id]\n\t\t\tend_time = time.time()\n\t\t\tif len(msgs) &gt; 0 or end_time &gt; start_time + timeout:\n\t\t\t\tself.clear_user_msg(user_id=user_id)\n\t\t\t\tbreak\n\t\t\tawait asyncio.sleep(1)\n\t\tif len(msgs) &gt; 0:\n\t\t\tpacked_msgs = self.user_msg_formatter.formatted_msgs(msgs=msgs)\n\t\t\treturn packed_msgs\n\n\t\tno_reply_msg = PackedUserMessage(\n\t\t\tuser_id=user_id,\n\t\t\tuser_msg=\"\",\n\t\t\tsystem_msg=f\"The user {user_id} does not reply, end this conversation.\",\n\t\t)\n\t\treturn no_reply_msg\n\n\tdef test_get_user_text(\n\t\tself,\n\t\tuser_id: str,\n\t\tenable_instruct: bool = False,\n\t\tenable_comment: bool = False,\n\t) -&gt; PackedUserMessage:\n\t\tr\"\"\" For debug. \"\"\"\n\t\tuser_msg = input(\"User: \")\n\n\t\ttext_msg = ChatTextMessage(\n\t\t\tuser_id=user_id,\n\t\t\ttext=user_msg,\n\t\t\treply_in_speech=False,\n\t\t\tenable_instruct=enable_instruct,\n\t\t\tenable_comment=enable_comment,\n\t\t)\n\t\tpacked_msgs = self.user_msg_formatter.formatted_msgs(msgs=[text_msg])\n\t\treturn packed_msgs\n\n\tdef default_user_speech_path(self, user_id: str) -&gt; str:\n\t\tr\"\"\" Default save path of a user's speech. \"\"\"\n\t\tuser_speech_path = self._root / f\"{USER_TMP_DIR}/{user_id}/{USER_SPEECH_NAME}\"\n\t\tdir_pth = str(user_speech_path.parent)\n\t\tif not self._fs.exists(dir_pth):\n\t\t\tself._fs.mkdirs(dir_pth)\n\t\treturn str(user_speech_path)\n\n\tdef default_agent_speech_path(self, user_id: str) -&gt; str:\n\t\tr\"\"\" Default save path of agent's speech. \"\"\"\n\t\tagent_speech_path = self._root / f\"{USER_TMP_DIR}/{user_id}/{AGENT_SPEECH_NAME}\"\n\t\tdir_pth = str(agent_speech_path.parent)\n\t\tif not self._fs.exists(dir_pth):\n\t\t\tself._fs.mkdirs(dir_pth)\n\t\treturn str(agent_speech_path)\n\n\tdef default_tmp_file_path(self, user_id: str, file_name: str) -&gt; str:\n\t\tr\"\"\" Default save path of the user's uploaded file. \"\"\"\n\t\tdate, _ = get_time()\n\t\ttmp_dir = self._root / f\"{USER_TMP_DIR}/{user_id}/{date}\"\n\t\ttmp_path = str(tmp_dir / file_name)\n\t\treturn tmp_path\n\n\tdef put_agent_reply(\n\t\tself,\n\t\tuser_id: str,\n\t\treply_str: str,\n\t\treferences: List[str] = None,\n\t\tinner_chat: bool = False,\n\t\textra_info: str = None,\n\t):\n\t\tr\"\"\"\n\t\tPut an agent's reply into the buffer.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user id of a Lab member.\n\t\t\treply_str (str): The agent's reply string.\n\t\t\treferences (List[str]): The paths of reference files. Defaults to None.\n\t\t\tinner_chat (bool): Whether the reply happens inside a chat.\n\t\t\textra_info (str): extra information generally with long texts.\n\t\t\"\"\"\n\t\tself.account_manager.check_valid_user(user_id=user_id)\n\n\t\tif references is not None:\n\t\t\tref_dict = {}\n\t\t\tfor ref_path in references:\n\t\t\t\tif not self._fs.exists(ref_path):\n\t\t\t\t\tcontinue\n\n\t\t\t\tref_size = os.path.getsize(ref_path)\n\t\t\t\tref_dict[ref_path] = ref_size\n\t\t\tif ref_dict:\n\t\t\t\treferences = ref_dict\n\t\t\telse:\n\t\t\t\treferences = None\n\n\t\tif not self.config_buffer[user_id].reply_in_speech:\n\t\t\treply = ServerReply(\n\t\t\t\treply_text=reply_str,\n\t\t\t\treferences=references,\n\t\t\t\tvalid=True,\n\t\t\t\tinner_chat=inner_chat,\n\t\t\t\textra_info=extra_info,\n\t\t\t)\n\t\t\tself.agent_reply_buffer[user_id] = reply\n\t\t\treturn\n\n\t\tspeech_name = self.default_agent_speech_path(user_id=user_id)\n\t\tspeech_path = TTSWorker.transform(text=reply_str, speech_name=speech_name)\n\n\t\tspeech_size = os.path.getsize(speech_path)\n\t\treply = ServerSpeechReply(\n\t\t\treply_speech={\n\t\t\t\tspeech_path: speech_size,\n\t\t\t},\n\t\t\tinner_chat=inner_chat,\n\t\t\treferences=references,\n\t\t\tvalid=True,\n\t\t\textra_info=extra_info,\n\t\t)\n\t\tself.agent_reply_buffer[user_id] = reply\n\n\tdef get_agent_reply(self, user_id: str) -&gt; Union[ServerReply, ServerSpeechReply]:\n\t\tr\"\"\"\n\t\tGet the agent reply to a user from the buffer.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user id of a Lab member.\n\n\t\tReturns:\n\t\t\tUnion[ServerReply, ServerSpeechReply]: If an agent's reply exists, return a valid reply,\n\t\t\t\totherwise, return an invalid reply.\n\t\t\"\"\"\n\t\tagent_reply = self.agent_reply_buffer[user_id]\n\t\tif agent_reply is None:\n\t\t\treturn ServerReply(\n\t\t\t\treply_text=\"Please wait.\",\n\t\t\t\tvalid=False,\n\t\t\t)\n\t\telse:\n\t\t\tself.agent_reply_buffer[user_id] = None\n\t\t\treturn agent_reply\n</code></pre>"},{"location":"code_docs/agent/chat_msg/msg_types/#labridge.agent.chat_msg.msg_types.ChatMsgBuffer.clear_user_msg","title":"<code>labridge.agent.chat_msg.msg_types.ChatMsgBuffer.clear_user_msg(user_id)</code>","text":"<p>Clear a user's messages in the buffer.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user id of a Lab member.</p> <p> TYPE: <code>str</code> </p> Source code in <code>labridge\\agent\\chat_msg\\msg_types.py</code> <pre><code>def clear_user_msg(self, user_id: str):\n\tr\"\"\"\n\tClear a user's messages in the buffer.\n\n\tArgs:\n\t\tuser_id (str): The user id of a Lab member.\n\t\"\"\"\n\tself.user_msg_buffer[user_id] = []\n</code></pre>"},{"location":"code_docs/agent/chat_msg/msg_types/#labridge.agent.chat_msg.msg_types.ChatMsgBuffer.default_agent_speech_path","title":"<code>labridge.agent.chat_msg.msg_types.ChatMsgBuffer.default_agent_speech_path(user_id)</code>","text":"<p>Default save path of agent's speech.</p> Source code in <code>labridge\\agent\\chat_msg\\msg_types.py</code> <pre><code>def default_agent_speech_path(self, user_id: str) -&gt; str:\n\tr\"\"\" Default save path of agent's speech. \"\"\"\n\tagent_speech_path = self._root / f\"{USER_TMP_DIR}/{user_id}/{AGENT_SPEECH_NAME}\"\n\tdir_pth = str(agent_speech_path.parent)\n\tif not self._fs.exists(dir_pth):\n\t\tself._fs.mkdirs(dir_pth)\n\treturn str(agent_speech_path)\n</code></pre>"},{"location":"code_docs/agent/chat_msg/msg_types/#labridge.agent.chat_msg.msg_types.ChatMsgBuffer.default_tmp_file_path","title":"<code>labridge.agent.chat_msg.msg_types.ChatMsgBuffer.default_tmp_file_path(user_id, file_name)</code>","text":"<p>Default save path of the user's uploaded file.</p> Source code in <code>labridge\\agent\\chat_msg\\msg_types.py</code> <pre><code>def default_tmp_file_path(self, user_id: str, file_name: str) -&gt; str:\n\tr\"\"\" Default save path of the user's uploaded file. \"\"\"\n\tdate, _ = get_time()\n\ttmp_dir = self._root / f\"{USER_TMP_DIR}/{user_id}/{date}\"\n\ttmp_path = str(tmp_dir / file_name)\n\treturn tmp_path\n</code></pre>"},{"location":"code_docs/agent/chat_msg/msg_types/#labridge.agent.chat_msg.msg_types.ChatMsgBuffer.default_user_speech_path","title":"<code>labridge.agent.chat_msg.msg_types.ChatMsgBuffer.default_user_speech_path(user_id)</code>","text":"<p>Default save path of a user's speech.</p> Source code in <code>labridge\\agent\\chat_msg\\msg_types.py</code> <pre><code>def default_user_speech_path(self, user_id: str) -&gt; str:\n\tr\"\"\" Default save path of a user's speech. \"\"\"\n\tuser_speech_path = self._root / f\"{USER_TMP_DIR}/{user_id}/{USER_SPEECH_NAME}\"\n\tdir_pth = str(user_speech_path.parent)\n\tif not self._fs.exists(dir_pth):\n\t\tself._fs.mkdirs(dir_pth)\n\treturn str(user_speech_path)\n</code></pre>"},{"location":"code_docs/agent/chat_msg/msg_types/#labridge.agent.chat_msg.msg_types.ChatMsgBuffer.get_agent_reply","title":"<code>labridge.agent.chat_msg.msg_types.ChatMsgBuffer.get_agent_reply(user_id)</code>","text":"<p>Get the agent reply to a user from the buffer.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user id of a Lab member.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Union[ServerReply, ServerSpeechReply]</code> <p>Union[ServerReply, ServerSpeechReply]: If an agent's reply exists, return a valid reply, otherwise, return an invalid reply.</p> Source code in <code>labridge\\agent\\chat_msg\\msg_types.py</code> <pre><code>def get_agent_reply(self, user_id: str) -&gt; Union[ServerReply, ServerSpeechReply]:\n\tr\"\"\"\n\tGet the agent reply to a user from the buffer.\n\n\tArgs:\n\t\tuser_id (str): The user id of a Lab member.\n\n\tReturns:\n\t\tUnion[ServerReply, ServerSpeechReply]: If an agent's reply exists, return a valid reply,\n\t\t\totherwise, return an invalid reply.\n\t\"\"\"\n\tagent_reply = self.agent_reply_buffer[user_id]\n\tif agent_reply is None:\n\t\treturn ServerReply(\n\t\t\treply_text=\"Please wait.\",\n\t\t\tvalid=False,\n\t\t)\n\telse:\n\t\tself.agent_reply_buffer[user_id] = None\n\t\treturn agent_reply\n</code></pre>"},{"location":"code_docs/agent/chat_msg/msg_types/#labridge.agent.chat_msg.msg_types.ChatMsgBuffer.get_user_msg","title":"<code>labridge.agent.chat_msg.msg_types.ChatMsgBuffer.get_user_msg(user_id, timeout=240)</code>  <code>async</code>","text":"<p>Wait until a user's messages are put into the buffer, and get them.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user id of a Lab member.</p> <p> TYPE: <code>str</code> </p> <code>timeout</code> <p>If timeout, return None.</p> <p> TYPE: <code>int</code> DEFAULT: <code>240</code> </p> RETURNS DESCRIPTION <code>Optional[PackedUserMessage]</code> <p>Optional[PackedUserMessage]: The obtained packed user messages. If no user messages if put in until time is out, return None.</p> Source code in <code>labridge\\agent\\chat_msg\\msg_types.py</code> <pre><code>async def get_user_msg(self, user_id: str, timeout: int = 240) -&gt; Optional[PackedUserMessage]:\n\tr\"\"\"\n\tWait until a user's messages are put into the buffer, and get them.\n\n\tArgs:\n\t\tuser_id (str): The user id of a Lab member.\n\t\ttimeout (int): If timeout, return None.\n\n\tReturns:\n\t\tOptional[PackedUserMessage]: The obtained packed user messages.\n\t\t\tIf no user messages if put in until time is out, return None.\n\t\"\"\"\n\tstart_time = time.time()\n\n\twhile True:\n\t\tmsgs = self.user_msg_buffer[user_id]\n\t\tend_time = time.time()\n\t\tif len(msgs) &gt; 0 or end_time &gt; start_time + timeout:\n\t\t\tself.clear_user_msg(user_id=user_id)\n\t\t\tbreak\n\t\tawait asyncio.sleep(1)\n\tif len(msgs) &gt; 0:\n\t\tpacked_msgs = self.user_msg_formatter.formatted_msgs(msgs=msgs)\n\t\treturn packed_msgs\n\n\tno_reply_msg = PackedUserMessage(\n\t\tuser_id=user_id,\n\t\tuser_msg=\"\",\n\t\tsystem_msg=f\"The user {user_id} does not reply, end this conversation.\",\n\t)\n\treturn no_reply_msg\n</code></pre>"},{"location":"code_docs/agent/chat_msg/msg_types/#labridge.agent.chat_msg.msg_types.ChatMsgBuffer.put_agent_reply","title":"<code>labridge.agent.chat_msg.msg_types.ChatMsgBuffer.put_agent_reply(user_id, reply_str, references=None, inner_chat=False, extra_info=None)</code>","text":"<p>Put an agent's reply into the buffer.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user id of a Lab member.</p> <p> TYPE: <code>str</code> </p> <code>reply_str</code> <p>The agent's reply string.</p> <p> TYPE: <code>str</code> </p> <code>references</code> <p>The paths of reference files. Defaults to None.</p> <p> TYPE: <code>List[str]</code> DEFAULT: <code>None</code> </p> <code>inner_chat</code> <p>Whether the reply happens inside a chat.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>extra_info</code> <p>extra information generally with long texts.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> Source code in <code>labridge\\agent\\chat_msg\\msg_types.py</code> <pre><code>def put_agent_reply(\n\tself,\n\tuser_id: str,\n\treply_str: str,\n\treferences: List[str] = None,\n\tinner_chat: bool = False,\n\textra_info: str = None,\n):\n\tr\"\"\"\n\tPut an agent's reply into the buffer.\n\n\tArgs:\n\t\tuser_id (str): The user id of a Lab member.\n\t\treply_str (str): The agent's reply string.\n\t\treferences (List[str]): The paths of reference files. Defaults to None.\n\t\tinner_chat (bool): Whether the reply happens inside a chat.\n\t\textra_info (str): extra information generally with long texts.\n\t\"\"\"\n\tself.account_manager.check_valid_user(user_id=user_id)\n\n\tif references is not None:\n\t\tref_dict = {}\n\t\tfor ref_path in references:\n\t\t\tif not self._fs.exists(ref_path):\n\t\t\t\tcontinue\n\n\t\t\tref_size = os.path.getsize(ref_path)\n\t\t\tref_dict[ref_path] = ref_size\n\t\tif ref_dict:\n\t\t\treferences = ref_dict\n\t\telse:\n\t\t\treferences = None\n\n\tif not self.config_buffer[user_id].reply_in_speech:\n\t\treply = ServerReply(\n\t\t\treply_text=reply_str,\n\t\t\treferences=references,\n\t\t\tvalid=True,\n\t\t\tinner_chat=inner_chat,\n\t\t\textra_info=extra_info,\n\t\t)\n\t\tself.agent_reply_buffer[user_id] = reply\n\t\treturn\n\n\tspeech_name = self.default_agent_speech_path(user_id=user_id)\n\tspeech_path = TTSWorker.transform(text=reply_str, speech_name=speech_name)\n\n\tspeech_size = os.path.getsize(speech_path)\n\treply = ServerSpeechReply(\n\t\treply_speech={\n\t\t\tspeech_path: speech_size,\n\t\t},\n\t\tinner_chat=inner_chat,\n\t\treferences=references,\n\t\tvalid=True,\n\t\textra_info=extra_info,\n\t)\n\tself.agent_reply_buffer[user_id] = reply\n</code></pre>"},{"location":"code_docs/agent/chat_msg/msg_types/#labridge.agent.chat_msg.msg_types.ChatMsgBuffer.put_user_msg","title":"<code>labridge.agent.chat_msg.msg_types.ChatMsgBuffer.put_user_msg(user_msg)</code>","text":"<p>Put a new user message into the buffer.</p> PARAMETER DESCRIPTION <code>user_msg</code> <p>A new message from a user.</p> <p> TYPE: <code>BaseClientMessage</code> </p> Source code in <code>labridge\\agent\\chat_msg\\msg_types.py</code> <pre><code>def put_user_msg(self, user_msg: BaseClientMessage):\n\tr\"\"\"\n\tPut a new user message into the buffer.\n\n\tArgs:\n\t\tuser_msg (BaseClientMessage): A new message from a user.\n\t\"\"\"\n\tif not isinstance(user_msg, (FileWithTextMessage, ChatTextMessage, ChatSpeechMessage)):\n\t\traise ValueError(f\"The Msg type {type(user_msg)} is not supported.\")\n\n\tuser_id = user_msg.user_id\n\tself.account_manager.check_valid_user(user_id=user_id)\n\tself.user_msg_buffer[user_id].append(user_msg)\n\tself.config_buffer[user_id].update(\n\t\tenable_instruct=user_msg.enable_instruct,\n\t\tenable_comment=user_msg.enable_comment,\n\t\treply_in_speech=user_msg.reply_in_speech,\n\t)\n</code></pre>"},{"location":"code_docs/agent/chat_msg/msg_types/#labridge.agent.chat_msg.msg_types.ChatMsgBuffer.reset_buffer","title":"<code>labridge.agent.chat_msg.msg_types.ChatMsgBuffer.reset_buffer()</code>","text":"<p>Reset the user_msg_buffer and agent_reply_buffer.</p> RETURNS DESCRIPTION <p>None</p> Source code in <code>labridge\\agent\\chat_msg\\msg_types.py</code> <pre><code>def reset_buffer(self):\n\tr\"\"\"\n\tReset the user_msg_buffer and agent_reply_buffer.\n\n\tReturns:\n\t\tNone\n\t\"\"\"\n\tusers = self.account_manager.get_users()\n\tself.user_msg_buffer = {user: [] for user in users}\n\tself.agent_reply_buffer = {user: None for user in users}\n\tself.config_buffer = {user: ChatConfig() for user in users}\n</code></pre>"},{"location":"code_docs/agent/chat_msg/msg_types/#labridge.agent.chat_msg.msg_types.ChatMsgBuffer.test_get_user_text","title":"<code>labridge.agent.chat_msg.msg_types.ChatMsgBuffer.test_get_user_text(user_id, enable_instruct=False, enable_comment=False)</code>","text":"<p>For debug.</p> Source code in <code>labridge\\agent\\chat_msg\\msg_types.py</code> <pre><code>def test_get_user_text(\n\tself,\n\tuser_id: str,\n\tenable_instruct: bool = False,\n\tenable_comment: bool = False,\n) -&gt; PackedUserMessage:\n\tr\"\"\" For debug. \"\"\"\n\tuser_msg = input(\"User: \")\n\n\ttext_msg = ChatTextMessage(\n\t\tuser_id=user_id,\n\t\ttext=user_msg,\n\t\treply_in_speech=False,\n\t\tenable_instruct=enable_instruct,\n\t\tenable_comment=enable_comment,\n\t)\n\tpacked_msgs = self.user_msg_formatter.formatted_msgs(msgs=[text_msg])\n\treturn packed_msgs\n</code></pre>"},{"location":"code_docs/agent/chat_msg/msg_types/#labridge.agent.chat_msg.msg_types.ChatSpeechMessage","title":"<code>labridge.agent.chat_msg.msg_types.ChatSpeechMessage</code>","text":"<p>               Bases: <code>BaseClientMessage</code></p> <p>This message includes:</p> <ol> <li>Basic: user_id.</li> <li>The save path of user's speech file data.</li> </ol> <p>This message is used in the <code>websocket_chat_speech</code>.</p> Source code in <code>labridge\\agent\\chat_msg\\msg_types.py</code> <pre><code>class ChatSpeechMessage(BaseClientMessage):\n\tr\"\"\"\n\tThis message includes:\n\n\t1. Basic: user_id.\n\t2. The save path of user's speech file data.\n\n\tThis message is used in the `websocket_chat_speech`.\n\t\"\"\"\n\tspeech_path: str\n\treply_in_speech: bool = True\n</code></pre>"},{"location":"code_docs/agent/chat_msg/msg_types/#labridge.agent.chat_msg.msg_types.ChatTextMessage","title":"<code>labridge.agent.chat_msg.msg_types.ChatTextMessage</code>","text":"<p>               Bases: <code>BaseClientMessage</code></p> <p>This message includes:</p> <ol> <li>Basic: user_id.</li> <li>The user's query.</li> </ol> <p>This message is used in the <code>websocket_chat_text</code>.</p> Source code in <code>labridge\\agent\\chat_msg\\msg_types.py</code> <pre><code>class ChatTextMessage(BaseClientMessage):\n\tr\"\"\"\n\tThis message includes:\n\n\t1. Basic: user_id.\n\t2. The user's query.\n\n\tThis message is used in the `websocket_chat_text`.\n\t\"\"\"\n\ttext: str\n\treply_in_speech: bool = False\n</code></pre>"},{"location":"code_docs/agent/chat_msg/msg_types/#labridge.agent.chat_msg.msg_types.FileWithTextMessage","title":"<code>labridge.agent.chat_msg.msg_types.FileWithTextMessage</code>","text":"<p>               Bases: <code>BaseClientMessage</code></p> <p>This message includes:</p> <ol> <li>Basic: user_id</li> <li>The info of the file to be uploaded.</li> <li>The attached user's query.</li> <li>Whether to reply in speech or not.</li> </ol> <p>This message is used in the <code>websocket_chat_with_file</code>.</p> Source code in <code>labridge\\agent\\chat_msg\\msg_types.py</code> <pre><code>class FileWithTextMessage(BaseClientMessage):\n\tr\"\"\"\n\tThis message includes:\n\n\t1. Basic: user_id\n\t2. The info of the file to be uploaded.\n\t3. The attached user's query.\n\t4. Whether to reply in speech or not.\n\n\tThis message is used in the `websocket_chat_with_file`.\n\t\"\"\"\n\tattached_text: str\n\treply_in_speech: bool = False\n\tfile_path: Optional[str] = None\n\n\tdef dumps(self) -&gt; str:\n\t\tr\"\"\"\n\t\tThe formatted string that the client sends to the server for uploading request,\n\t\tincluding the file info and the attached text.\n\t\t\"\"\"\n\t\tmsg_dict = {\n\t\t\t\"user_id\": self.user_id,\n\t\t\t\"file_name\": self.file_name,\n\t\t\t\"attached_text\": self.attached_text\n\t\t}\n\t\treturn json.dumps(msg_dict)\n\n\t@classmethod\n\tdef loads(cls, dumped_str):\n\t\tmsg_dict = json.loads(dumped_str)\n\t\tuser_id = msg_dict.get(\"user_id\")\n\t\tfile_name = msg_dict.get(\"file_name\")\n\t\tattached_text = msg_dict.get(\"attached_text\")\n\t\treturn cls(\n\t\t\tuser_id=user_id,\n\t\t\tfile_name=file_name,\n\t\t\tattached_text=attached_text,\n\t\t)\n</code></pre>"},{"location":"code_docs/agent/chat_msg/msg_types/#labridge.agent.chat_msg.msg_types.FileWithTextMessage.dumps","title":"<code>labridge.agent.chat_msg.msg_types.FileWithTextMessage.dumps()</code>","text":"<p>The formatted string that the client sends to the server for uploading request, including the file info and the attached text.</p> Source code in <code>labridge\\agent\\chat_msg\\msg_types.py</code> <pre><code>def dumps(self) -&gt; str:\n\tr\"\"\"\n\tThe formatted string that the client sends to the server for uploading request,\n\tincluding the file info and the attached text.\n\t\"\"\"\n\tmsg_dict = {\n\t\t\"user_id\": self.user_id,\n\t\t\"file_name\": self.file_name,\n\t\t\"attached_text\": self.attached_text\n\t}\n\treturn json.dumps(msg_dict)\n</code></pre>"},{"location":"code_docs/agent/chat_msg/msg_types/#labridge.agent.chat_msg.msg_types.PackedUserMessage","title":"<code>labridge.agent.chat_msg.msg_types.PackedUserMessage</code>","text":"<p>Pack the user messages.</p> <p>user_id (str): The user id of a Lab member. system_msg (str): The corresponding system message. user_msg (str): The packed user messages. reply_in_speech (bool): Whether the agent should reply in speech or not chat_group_id (Optional[str]): The ID of a chat group (If the messages are from a chat group). Defaults to None.</p> Source code in <code>labridge\\agent\\chat_msg\\msg_types.py</code> <pre><code>class PackedUserMessage:\n\tr\"\"\"\n\tPack the user messages.\n\n\tuser_id (str): The user id of a Lab member.\n\tsystem_msg (str): The corresponding system message.\n\tuser_msg (str): The packed user messages.\n\treply_in_speech (bool): Whether the agent should reply in speech or not\n\tchat_group_id (Optional[str]): The ID of a chat group (If the messages are from a chat group). Defaults to None.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tuser_id: str,\n\t\tsystem_msg: str,\n\t\tuser_msg: str,\n\t\tchat_group_id: Optional[str] = None,\n\t):\n\t\tself.user_id = user_id\n\t\tself.system_msg = system_msg\n\t\tself.user_msg = user_msg\n\t\tself.chat_group_id = chat_group_id\n\n\tdef dumps(self) -&gt; str:\n\t\tmsg_dict = {\n\t\t\t\"user_id\": self.user_id,\n\t\t\t\"system_msg\": self.system_msg,\n\t\t\t\"user_msg\": self.user_msg,\n\t\t\t\"chat_group_id\": self.chat_group_id,\n\t\t}\n\t\treturn json.dumps(msg_dict)\n\n\t@classmethod\n\tdef loads(cls, dumped_str: str):\n\t\tr\"\"\"\n\t\tLoad from a dumped JSON string.\n\n\t\tArgs:\n\t\t\tdumped_str (str): The dumped JSON string.\n\n\t\tReturns:\n\t\t\tPackedUserMessage\n\t\t\"\"\"\n\t\tmsg_dict = json.loads(dumped_str)\n\t\treturn cls(\n\t\t\tuser_id=msg_dict[\"user_id\"],\n\t\t\tsystem_msg=msg_dict[\"system_msg\"],\n\t\t\tuser_msg=msg_dict[\"user_msg\"],\n\t\t\tchat_group_id=msg_dict[\"chat_group_id\"],\n\t\t)\n</code></pre>"},{"location":"code_docs/agent/chat_msg/msg_types/#labridge.agent.chat_msg.msg_types.PackedUserMessage.loads","title":"<code>labridge.agent.chat_msg.msg_types.PackedUserMessage.loads(dumped_str)</code>  <code>classmethod</code>","text":"<p>Load from a dumped JSON string.</p> PARAMETER DESCRIPTION <code>dumped_str</code> <p>The dumped JSON string.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <p>PackedUserMessage</p> Source code in <code>labridge\\agent\\chat_msg\\msg_types.py</code> <pre><code>@classmethod\ndef loads(cls, dumped_str: str):\n\tr\"\"\"\n\tLoad from a dumped JSON string.\n\n\tArgs:\n\t\tdumped_str (str): The dumped JSON string.\n\n\tReturns:\n\t\tPackedUserMessage\n\t\"\"\"\n\tmsg_dict = json.loads(dumped_str)\n\treturn cls(\n\t\tuser_id=msg_dict[\"user_id\"],\n\t\tsystem_msg=msg_dict[\"system_msg\"],\n\t\tuser_msg=msg_dict[\"user_msg\"],\n\t\tchat_group_id=msg_dict[\"chat_group_id\"],\n\t)\n</code></pre>"},{"location":"code_docs/agent/chat_msg/msg_types/#labridge.agent.chat_msg.msg_types.ServerReply","title":"<code>labridge.agent.chat_msg.msg_types.ServerReply</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>The server's text reply.</p> <p>reply_text (str): The reply text. valid (bool): Whether this reply contains valid information. references (Optional[Dict[str, int]]): The paths of reference files and file size. error (Optional[str]): The error information. If no error, it is None. inner_chat (Optional[bool]): Whether the reply is produced inside the Chat Call.         - If this reply is the final response of the agent, it is False.         - If this reply is an internal response such as collecting information from the user or getting authorization,         it is True. When <code>inner_chat</code> is True, the client should post the user's answer to corresponding URL with flag <code>Inner</code>.</p> Source code in <code>labridge\\agent\\chat_msg\\msg_types.py</code> <pre><code>class ServerReply(BaseModel):\n\tr\"\"\"\n\tThe server's text reply.\n\n\treply_text (str): The reply text.\n\tvalid (bool): Whether this reply contains valid information.\n\treferences (Optional[Dict[str, int]]): The paths of reference files and file size.\n\terror (Optional[str]): The error information. If no error, it is None.\n\tinner_chat (Optional[bool]): Whether the reply is produced inside the Chat Call.\n\t\t- If this reply is the final response of the agent, it is False.\n\t\t- If this reply is an internal response such as collecting information from the user or getting authorization,\n\t\tit is True. When `inner_chat` is True, the client should post the user's answer to corresponding URL with flag `Inner`.\n\t\"\"\"\n\treply_text: str\n\tvalid: bool\n\treferences: Optional[Dict[str, int]] = None\n\textra_info: Optional[str] = None\n\terror: Optional[str] = None\n\tinner_chat: Optional[bool] = False\n</code></pre>"},{"location":"code_docs/agent/chat_msg/msg_types/#labridge.agent.chat_msg.msg_types.ServerSpeechReply","title":"<code>labridge.agent.chat_msg.msg_types.ServerSpeechReply</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>The server's speech reply.</p> <p>reply_speech (Dict[str, int]): The path of the agent's speech file. valid (bool): Whether the reply contains valid information. When receiving an invalid reply,         the client should continue to get the server's reply until get a valid reply. references (Optional[List[str]]): The paths of reference files. inner_chat (Optional[bool]): Whether the reply is produced inside the Chat Call.         - If this reply is the final response of the agent, it is False.         - If this reply is an internal response such as collecting information from the user or getting authorization,         it is True. When <code>inner_chat</code> is True, the client should post the user's answer to corresponding URL with flag <code>Inner</code>.</p> Source code in <code>labridge\\agent\\chat_msg\\msg_types.py</code> <pre><code>class ServerSpeechReply(BaseModel):\n\tr\"\"\"\n\tThe server's speech reply.\n\n\treply_speech (Dict[str, int]): The path of the agent's speech file.\n\tvalid (bool): Whether the reply contains valid information. When receiving an invalid reply,\n\t\tthe client should continue to get the server's reply until get a valid reply.\n\treferences (Optional[List[str]]): The paths of reference files.\n\tinner_chat (Optional[bool]): Whether the reply is produced inside the Chat Call.\n\t\t- If this reply is the final response of the agent, it is False.\n\t\t- If this reply is an internal response such as collecting information from the user or getting authorization,\n\t\tit is True. When `inner_chat` is True, the client should post the user's answer to corresponding URL with flag `Inner`.\n\t\"\"\"\n\treply_speech: Dict[str, int]\n\tvalid: bool\n\treferences: Optional[List[str]] = None\n\textra_info: Optional[str] = None\n\terror: Optional[str] = None\n\tinner_chat: Optional[bool] = False\n</code></pre>"},{"location":"code_docs/agent/chat_msg/msg_types/#labridge.agent.chat_msg.msg_types.UserMsgFormatter","title":"<code>labridge.agent.chat_msg.msg_types.UserMsgFormatter</code>","text":"<p>               Bases: <code>object</code></p> <p>This class transform the user's messages into specific formats and generate corresponding system messages.</p> Source code in <code>labridge\\agent\\chat_msg\\msg_types.py</code> <pre><code>class UserMsgFormatter(object):\n\tr\"\"\"\n\tThis class transform the user's messages into specific formats and generate corresponding system messages.\n\t\"\"\"\n\n\tdef _speech_to_text(self, msg: ChatSpeechMessage) -&gt; str:\n\t\tr\"\"\" Speech message to text. \"\"\"\n\t\ttext = ASRWorker.transform(speech_path=msg.speech_path)\n\t\treturn text\n\n\tdef _formatted_file_with_text(self, msg: FileWithTextMessage, file_idx: int) -&gt; Tuple[str, str]:\n\t\tr\"\"\" FileWithTextMessage to formatted text. \"\"\"\n\t\tsystem_str = f\"Path of File {file_idx}: {msg.file_path}\"\n\t\tuser_str = f\"The user query about the File {file_idx}:\\n{msg.attached_text}\"\n\t\treturn system_str, user_str\n\n\tdef formatted_msgs(self, msgs: List[BaseClientMessage]) -&gt; PackedUserMessage:\n\t\tr\"\"\"\n\t\tTurn into formatted text message.\n\n\t\tArgs:\n\t\t\tmsgs (List[BaseClientMessage]): The user's messages.\n\n\t\tReturns:\n\t\t\tPackedUserMessage: The packed user messages, and system message.\n\n\t\t\"\"\"\n\t\tfile_idx = 1\n\t\tuser_id = msgs[0].user_id\n\t\treply_in_speech = msgs[0].reply_in_speech\n\t\tenable_instruct = msgs[0].enable_instruct\n\t\tenable_comment = msgs[0].enable_comment\n\n\t\tdate_str, time_str = get_time()\n\t\tuser_queries = []\n\t\tsystem_strings = [\n\t\t\tf\"You are chatting with a user one-to-one\\n\"\n\t\t\tf\"User id: {user_id}\\n\"\n\t\t\tf\"Current date: {date_str}\\n\"\n\t\t\tf\"Current time: {time_str}\\n\",\n\t\t]\n\n\t\tfor msg in msgs:\n\t\t\tif isinstance(msg, ChatSpeechMessage):\n\t\t\t\tuser_str = self._speech_to_text(msg=msg)\n\t\t\t\tuser_queries.append(user_str)\n\t\t\telif isinstance(msg, FileWithTextMessage):\n\t\t\t\tsystem_str, user_str = self._formatted_file_with_text(msg=msg, file_idx=file_idx)\n\t\t\t\tfile_idx += 1\n\t\t\t\tuser_queries.append(user_str)\n\t\t\t\tsystem_strings.append(system_str)\n\t\t\telif isinstance(msg, ChatTextMessage):\n\t\t\t\tuser_queries.append(msg.text)\n\t\t\telse:\n\t\t\t\traise ValueError(f\"Invalid Msg type: {type(msg)}\")\n\n\t\tsystem_msg = \"\\n\".join(system_strings)\n\t\tuser_msg = \"\\n\".join(user_queries)\n\t\tpacked_msg = PackedUserMessage(\n\t\t\tsystem_msg=system_msg,\n\t\t\tuser_id=user_id,\n\t\t\tuser_msg=user_msg,\n\t\t)\n\t\treturn packed_msg\n</code></pre>"},{"location":"code_docs/agent/chat_msg/msg_types/#labridge.agent.chat_msg.msg_types.UserMsgFormatter.formatted_msgs","title":"<code>labridge.agent.chat_msg.msg_types.UserMsgFormatter.formatted_msgs(msgs)</code>","text":"<p>Turn into formatted text message.</p> PARAMETER DESCRIPTION <code>msgs</code> <p>The user's messages.</p> <p> TYPE: <code>List[BaseClientMessage]</code> </p> RETURNS DESCRIPTION <code>PackedUserMessage</code> <p>The packed user messages, and system message.</p> <p> TYPE: <code>PackedUserMessage</code> </p> Source code in <code>labridge\\agent\\chat_msg\\msg_types.py</code> <pre><code>def formatted_msgs(self, msgs: List[BaseClientMessage]) -&gt; PackedUserMessage:\n\tr\"\"\"\n\tTurn into formatted text message.\n\n\tArgs:\n\t\tmsgs (List[BaseClientMessage]): The user's messages.\n\n\tReturns:\n\t\tPackedUserMessage: The packed user messages, and system message.\n\n\t\"\"\"\n\tfile_idx = 1\n\tuser_id = msgs[0].user_id\n\treply_in_speech = msgs[0].reply_in_speech\n\tenable_instruct = msgs[0].enable_instruct\n\tenable_comment = msgs[0].enable_comment\n\n\tdate_str, time_str = get_time()\n\tuser_queries = []\n\tsystem_strings = [\n\t\tf\"You are chatting with a user one-to-one\\n\"\n\t\tf\"User id: {user_id}\\n\"\n\t\tf\"Current date: {date_str}\\n\"\n\t\tf\"Current time: {time_str}\\n\",\n\t]\n\n\tfor msg in msgs:\n\t\tif isinstance(msg, ChatSpeechMessage):\n\t\t\tuser_str = self._speech_to_text(msg=msg)\n\t\t\tuser_queries.append(user_str)\n\t\telif isinstance(msg, FileWithTextMessage):\n\t\t\tsystem_str, user_str = self._formatted_file_with_text(msg=msg, file_idx=file_idx)\n\t\t\tfile_idx += 1\n\t\t\tuser_queries.append(user_str)\n\t\t\tsystem_strings.append(system_str)\n\t\telif isinstance(msg, ChatTextMessage):\n\t\t\tuser_queries.append(msg.text)\n\t\telse:\n\t\t\traise ValueError(f\"Invalid Msg type: {type(msg)}\")\n\n\tsystem_msg = \"\\n\".join(system_strings)\n\tuser_msg = \"\\n\".join(user_queries)\n\tpacked_msg = PackedUserMessage(\n\t\tsystem_msg=system_msg,\n\t\tuser_id=user_id,\n\t\tuser_msg=user_msg,\n\t)\n\treturn packed_msg\n</code></pre>"},{"location":"code_docs/agent/react/prompt/","title":"Prompt","text":""},{"location":"code_docs/agent/react/prompt/#labridge.agent.react.prompt","title":"<code>labridge.agent.react.prompt</code>","text":""},{"location":"code_docs/agent/react/react/","title":"React","text":""},{"location":"code_docs/agent/react/react/#labridge.agent.react.react","title":"<code>labridge.agent.react.react</code>","text":""},{"location":"code_docs/agent/react/react/#labridge.agent.react.react.InstructReActAgent","title":"<code>labridge.agent.react.react.InstructReActAgent</code>","text":"<p>               Bases: <code>AgentRunner</code></p> <p>This Agent uses the Reasoning and acting prompt framework. Additionally, this class enables the user to intervene the reasoning phase and acting phase:</p> <ul> <li>If <code>enable_instruct</code> is set to True, in the reasoning phase, the user is able to instruct the agent's thought.</li> <li>If 'enable_comment' is set to True, in the reacting phase, the user is able to comment the agent's action, the user's comment will be treated as observation to instruct the agent's next thought.</li> </ul> PARAMETER DESCRIPTION <code>tools</code> <p>The available tools of the agent.</p> <p> TYPE: <code>Sequence[BaseTool]</code> </p> <code>llm</code> <p>The used LLM.</p> <p> TYPE: <code>LLM</code> </p> <code>memory</code> <p>The short-term memory.</p> <p> TYPE: <code>BaseMemory</code> </p> <code>max_iterations</code> <p>The maximum reasoning-acting steps.</p> <p> TYPE: <code>int</code> DEFAULT: <code>10</code> </p> <code>react_chat_formatter</code> <p>The ReAct prompt template.</p> <p> TYPE: <code>Optional[ReActChatFormatter]</code> DEFAULT: <code>None</code> </p> <code>output_parser</code> <p>Used to parse tool call from the agent's Acting output.</p> <p> TYPE: <code>Optional[ReActOutputParser]</code> DEFAULT: <code>None</code> </p> <code>callback_manager</code> <p> TYPE: <code>Optional[CallbackManager]</code> DEFAULT: <code>None</code> </p> <code>verbose</code> <p>Whether to show the inner Reasoning-Acting process.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>tool_retriever</code> <p>Used to retrieve proper tool among the given tools.</p> <p> TYPE: <code>Optional[ObjectRetriever[BaseTool]]</code> DEFAULT: <code>None</code> </p> <code>handle_reasoning_failure_fn</code> <p> TYPE: <code>Optional[Callable[[CallbackManager, Exception], ToolOutput]]</code> DEFAULT: <code>None</code> </p> <code>enable_instruct</code> <p>Whether to enable user's instructing in the reasoning phase.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>enable_comment</code> <p>Whether to enable user's commenting in the acting phase.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> Source code in <code>labridge\\agent\\react\\react.py</code> <pre><code>class InstructReActAgent(AgentRunner):\n\tr\"\"\"\n\tThis Agent uses the Reasoning and acting prompt framework.\n\tAdditionally, this class enables the user to intervene the reasoning phase and acting phase:\n\n\t- If `enable_instruct` is set to True, in the reasoning phase, the user is able to instruct the agent's thought.\n\t- If 'enable_comment' is set to True, in the reacting phase, the user is able to comment the agent's action, the\n\tuser's comment will be treated as observation to instruct the agent's next thought.\n\n\tArgs:\n\t\ttools (Sequence[BaseTool]): The available tools of the agent.\n\t\tllm (LLM): The used LLM.\n\t\tmemory (BaseMemory): The short-term memory.\n\t\tmax_iterations (int): The maximum reasoning-acting steps.\n\t\treact_chat_formatter (Optional[ReActChatFormatter]): The ReAct prompt template.\n\t\toutput_parser (Optional[ReActOutputParser]): Used to parse tool call from the agent's Acting output.\n\t\tcallback_manager (Optional[CallbackManager]):\n\t\tverbose (bool): Whether to show the inner Reasoning-Acting process.\n\t\ttool_retriever (Optional[ObjectRetriever[BaseTool]]): Used to retrieve proper tool among the given tools.\n\t\thandle_reasoning_failure_fn (Optional[Callable[[CallbackManager, Exception], ToolOutput]]):\n\t\tenable_instruct (bool): Whether to enable user's instructing in the reasoning phase.\n\t\tenable_comment (bool): Whether to enable user's commenting in the acting phase.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\ttools: Sequence[BaseTool],\n\t\tllm: LLM,\n\t\tmemory: BaseMemory,\n\t\tmax_iterations: int = 10,\n\t\treact_chat_formatter: Optional[ReActChatFormatter] = None,\n\t\toutput_parser: Optional[ReActOutputParser] = None,\n\t\tcallback_manager: Optional[CallbackManager] = None,\n\t\tverbose: bool = False,\n\t\ttool_retriever: Optional[ObjectRetriever[BaseTool]] = None,\n\t\thandle_reasoning_failure_fn: Optional[Callable[[CallbackManager, Exception],\n\t\tToolOutput]] = None,\n\t\tenable_instruct: bool = False,\n\t\tenable_comment: bool = False,\n\t):\n\t\tself.user_id_list = AccountManager().get_users()\n\t\tself.chat_group_list = AccountManager().get_chat_groups()\n\t\tstep_engine = InstructReActAgentWorker.from_tools(\n\t\t\ttools=tools,\n\t\t\ttool_retriever=tool_retriever,\n\t\t\tuser_id_list=self.user_id_list,\n\t\t\tchat_group_id_list=self.chat_group_list,\n\t\t\tllm=llm,\n\t\t\tmax_iterations=max_iterations,\n\t\t\treact_chat_formatter=react_chat_formatter,\n\t\t\toutput_parser=output_parser,\n\t\t\tcallback_manager=callback_manager,\n\t\t\tverbose=verbose,\n\t\t\thandle_reasoning_failure_fn=handle_reasoning_failure_fn,\n\t\t\tenable_instruct=enable_instruct,\n\t\t)\n\t\tself._enable_comment = enable_comment\n\t\tsuper().__init__(\n\t\t\tstep_engine,\n\t\t\tmemory=memory,\n\t\t\tllm=llm,\n\t\t\tcallback_manager=callback_manager,\n\t\t)\n\n\tdef update_user_id_list(self):\n\t\tr\"\"\" Update the registered user ids \"\"\"\n\t\tself.user_id_list = AccountManager().get_users()\n\t\tself.agent_worker.user_id_list = self.user_id_list\n\n\tdef set_enable_instruct(self, enable: bool):\n\t\tr\"\"\" Set enable_instruct. \"\"\"\n\t\tself.agent_worker.set_enable_instruct(enable)\n\n\tdef set_enable_comment(self, enable: bool):\n\t\tr\"\"\" Set enable_comment. \"\"\"\n\t\tself._enable_comment = enable\n\n\t@property\n\tdef enable_instruct(self):\n\t\tr\"\"\" Enable user's instruction in Reasoning Phase. \"\"\"\n\t\treturn self.agent_worker.enable_instruct\n\n\t@property\n\tdef enable_comment(self):\n\t\tr\"\"\" Enable user's instruction in Acting Phase. \"\"\"\n\t\treturn self._enable_comment\n\n\tdef final_process_tool_logs(self, task: Task) -&gt; Tuple[str, List[str]]:\n\t\tr\"\"\"\n\t\tProcess the tool logs of the agent's acting.\n\n\t\t1. Record the log_to_system: log_to_system will be recorded to the long-term memory.\n\t\t2. Extract the log_to_user: log_to_user will be attached to the agent's answer.\n\t\t3. Extract the references: references are the file paths of the relevant documents. This information will be\n\t\tsent to the frontend.\n\t\t\"\"\"\n\t\ttool_log_list = task.extra_state[\"tool_log\"]\n\t\ttool_logs_str = get_all_system_logs(tool_logs=tool_log_list)\n\n\t\t# task.extra_state[\"new_memory\"].put(\n\t\t# \tChatMessage(\n\t\t# \t\tcontent=tool_logs_str,\n\t\t# \t\trole=MessageRole.TOOL,\n\t\t# \t)\n\t\t# )\n\t\tto_user_logs = get_extra_str_to_user(tool_logs=tool_log_list)\n\t\tref_file_paths = get_ref_file_paths(tool_logs=tool_log_list)\n\t\treturn to_user_logs, ref_file_paths\n\n\t@dispatcher.span\n\tdef _chat(self, message: str, chat_history: Optional[List[ChatMessage]] = None,\n\t\ttool_choice: Union[str, dict] = \"auto\",\n\t\tmode: ChatResponseMode = ChatResponseMode.WAIT, ) -&gt; AGENT_CHAT_RESPONSE_TYPE:\n\t\t\"\"\"\n\t\tChat with step executor.\n\t\tUser is able to instruct or comment.\n\t\t\"\"\"\n\t\tif chat_history is not None:\n\t\t\tself.memory.set(chat_history)\n\n\t\tpacked_msgs = PackedUserMessage.loads(dumped_str=message)\n\t\tuser_id, chat_group_id = packed_msgs.user_id, packed_msgs.chat_group_id\n\t\tuser_msg, system_msg = packed_msgs.user_msg, packed_msgs.system_msg\n\n\t\ttask = self.create_task(\n\t\t\tinput=user_msg,\n\t\t\textra_state={\n\t\t\t\t\"system_msg\": system_msg,\n\t\t\t\t\"user_id\": user_id,\n\t\t\t\t\"enable_instruct\": ChatBuffer.config_buffer[user_id].enable_instruct,\n\t\t\t\t\"enable_comment\": ChatBuffer.config_buffer[user_id].enable_comment,\n\t\t\t}\n\t\t)\n\t\tif chat_group_id is not None:\n\t\t\ttask.extra_state[\"chat_group_id\"] = chat_group_id\n\n\t\tresult_output = None\n\t\tdispatcher.event(AgentChatWithStepStartEvent(user_msg=user_msg))\n\n\t\t# \u200b\u663e\u5f0f\u200b\u83b7\u53d6\u200b initial step\n\t\tstep = self.state.get_step_queue(task.task_id).popleft()\n\n\t\twhile True:\n\t\t\t# pass step queue in as argument, assume step executor is stateless\n\t\t\tcur_step_output = self._run_step(\n\t\t\t\ttask.task_id,\n\t\t\t\tstep=step,\n\t\t\t\tmode=mode,\n\t\t\t\ttool_choice=tool_choice,\n\t\t\t)\n\n\t\t\tif cur_step_output.is_last:\n\t\t\t\tresult_output = cur_step_output\n\t\t\t\tbreak\n\n\t\t\tstep_queue = self.state.get_step_queue(task.task_id)\n\t\t\tstep = step_queue.popleft()\n\n\t\t\t# Send the observation to the user.\n\t\t\tif task.extra_state[\"enable_comment\"]:\n\t\t\t\t# TODO: \u200b\u5c06\u200b cur_step_output.output.response \u200b\u8f93\u51fa\u200b\u7ed9\u200b User, \u200b\u83b7\u53d6\u200b User \u200b\u7684\u200b Instruction\u3002\n\t\t\t\tprint_text(text=cur_step_output.output.response, color=\"llama_turquoise\", end=\"\\n\")\n\t\t\t\t# TODO: \u200b\u83b7\u53d6\u200b\u4e0b\u200b\u4e00\u6b65\u200b step, \u200b\u5e76\u200b\u5c06\u200bInstruction\u200b\u4f5c\u4e3a\u200b step.input\u3002\n\t\t\t\tpacked_msgs = ChatBuffer.test_get_user_text(\n\t\t\t\t\tuser_id=user_id,\n\t\t\t\t\tenable_instruct=False,\n\t\t\t\t\tenable_comment=False,\n\t\t\t\t)\n\n\t\t\t\tuser_comment = packed_msgs.user_msg\n\t\t\t\tsystem_msg = packed_msgs.system_msg\n\t\t\t\tupdate_intervene_status(\n\t\t\t\t\ttask=task,\n\t\t\t\t\tenable_instruct=ChatBuffer.config_buffer[user_id].enable_instruct,\n\t\t\t\t\tenable_comment=ChatBuffer.config_buffer[user_id].enable_comment,\n\t\t\t\t\treply_in_speech=ChatBuffer.config_buffer[user_id].reply_in_speech,\n\t\t\t\t)\n\t\t\t\t# Add as the step's input\n\t\t\t\tstep.input = user_comment\n\t\t\t\tstep.step_state[\"system_msg\"] = system_msg\n\t\t\t\tprint_text(f\"&gt;&gt;&gt; User's comment: \\n {user_comment}\", color=\"blue\", end=\"\\n\")\n\n\t\t\t# ensure tool_choice does not cause endless loops\n\t\t\ttool_choice = \"auto\"\n\n\t\tto_user_logs, ref_file_paths = self.final_process_tool_logs(task=task)\n\t\tresult = self.finalize_response(task.task_id, result_output, )\n\t\t# add the tool log if necessary.\n\t\tresult.response += f\"\\n\\n{to_user_logs}\"\n\t\tdispatcher.event(AgentChatWithStepEndEvent(response=result))\n\n\t\tif result.metadata is None:\n\t\t\tresult.metadata = {\"references\": ref_file_paths}\n\t\telse:\n\t\t\tresult.metadata.update({\"references\": ref_file_paths})\n\t\treturn result\n\n\t@dispatcher.span\n\tasync def _achat(self, message: str, chat_history: Optional[List[ChatMessage]] = None,\n\t\ttool_choice: Union[str, dict] = \"auto\",\n\t\tmode: ChatResponseMode = ChatResponseMode.WAIT, ) -&gt; AGENT_CHAT_RESPONSE_TYPE:\n\t\t\"\"\"\n\t\tAsync version.\n\t\tChat with step executor.\n\t\tUser is able to instruct or comment.\n\t\t\"\"\"\n\t\tif chat_history is not None:\n\t\t\tself.memory.set(chat_history)\n\n\t\tpacked_msgs = PackedUserMessage.loads(dumped_str=message)\n\t\tuser_id, chat_group_id = packed_msgs.user_id, packed_msgs.chat_group_id\n\t\tuser_msg, system_msg = packed_msgs.user_msg, packed_msgs.system_msg\n\n\t\ttask = self.create_task(\n\t\t\tinput=user_msg,\n\t\t\textra_state={\n\t\t\t\t\"system_msg\": system_msg,\n\t\t\t\t\"user_id\": user_id,\n\t\t\t\t\"enable_instruct\": ChatBuffer.config_buffer[user_id].enable_instruct,\n\t\t\t\t\"enable_comment\": ChatBuffer.config_buffer[user_id].enable_comment,\n\t\t\t\t\"reply_in_speech\": ChatBuffer.config_buffer[user_id].reply_in_speech,\n\t\t\t}\n\t\t)\n\t\tif chat_group_id is not None:\n\t\t\ttask.extra_state[\"chat_group_id\"] = chat_group_id\n\n\t\tresult_output = None\n\t\tdispatcher.event(AgentChatWithStepStartEvent(user_msg=user_msg))\n\n\t\t# explicitly get initial step\n\t\tstep = self.state.get_step_queue(task.task_id).popleft()\n\t\twhile True:\n\t\t\t# pass step queue in as argument, assume step executor is stateless\n\t\t\tcur_step_output = await self._arun_step(\n\t\t\t\ttask.task_id,\n\t\t\t\tstep=step,\n\t\t\t\tmode=mode,\n\t\t\t\ttool_choice=tool_choice,\n\t\t\t)\n\n\t\t\tif cur_step_output.is_last:\n\t\t\t\tresult_output = cur_step_output\n\t\t\t\tbreak\n\n\t\t\tstep_queue = self.state.get_step_queue(task.task_id)\n\t\t\tstep = step_queue.popleft()\n\n\t\t\t# Send the observation to the user.\n\t\t\tif task.extra_state[\"enable_comment\"]:\n\t\t\t\t# TODO: \u200b\u5c06\u200b cur_step_output.output.response \u200b\u8f93\u51fa\u200b\u7ed9\u200b User, \u200b\u83b7\u53d6\u200b User \u200b\u7684\u200b Instruction\u3002\n\t\t\t\tChatBuffer.put_agent_reply(\n\t\t\t\t\tuser_id=user_id,\n\t\t\t\t\treply_str=cur_step_output.output.response,\n\t\t\t\t\tinner_chat=True,\n\t\t\t\t)\n\t\t\t\t# TODO: \u200b\u5c06\u200bInstruction\u200b\u4f5c\u4e3a\u200b step.input, \u200b\u4ee5\u53ca\u200b\u5c06\u200b system_msg \u200b\u8bb0\u5165\u200b step.extra_state\u3002\n\t\t\t\tpacked_msgs = await ChatBuffer.get_user_msg(user_id=user_id)\n\t\t\t\tuser_comment, system_msg = packed_msgs.user_msg, packed_msgs.system_msg\n\t\t\t\t# update\n\t\t\t\tupdate_intervene_status(\n\t\t\t\t\ttask=task,\n\t\t\t\t\tenable_instruct=ChatBuffer.config_buffer[user_id].enable_instruct,\n\t\t\t\t\tenable_comment=ChatBuffer.config_buffer[user_id].enable_comment,\n\t\t\t\t\treply_in_speech=ChatBuffer.config_buffer[user_id].reply_in_speech,\n\t\t\t\t)\n\t\t\t\t# add to the step's input\n\t\t\t\tstep.input = user_comment\n\t\t\t\tstep.step_state[\"system_msg\"] = system_msg\n\t\t\t\tprint_text(\n\t\t\t\t\tf\"System: {system_msg}\"\n\t\t\t\t\tf\"&gt;&gt;&gt; User's comment: \\n {user_comment}\",\n\t\t\t\t\tcolor=\"blue\",\n\t\t\t\t\tend=\"\\n\",\n\t\t\t\t)\n\n\t\t\t# ensure tool_choice does not cause endless loops\n\t\t\ttool_choice = \"auto\"\n\n\t\tto_user_logs, ref_file_paths = self.final_process_tool_logs(task=task)\n\t\tresult = self.finalize_response(task.task_id, result_output, )\n\t\tresult.response += f\"\\n\\n{to_user_logs}\"\n\t\tdispatcher.event(AgentChatWithStepEndEvent(response=result))\n\t\tif result.metadata is None:\n\t\t\tresult.metadata = {\"references\": ref_file_paths}\n\t\telse:\n\t\t\tresult.metadata.update({\"references\": ref_file_paths})\n\t\treturn result\n\n\t@classmethod\n\tdef from_tools(\n\t\tcls,\n\t\ttools: Optional[List[BaseTool]] = None,\n\t\ttool_retriever: Optional[ObjectRetriever[BaseTool]] = None,\n\t\tllm: Optional[LLM] = None,\n\t\tchat_history: Optional[List[ChatMessage]] = None,\n\t\tmemory: Optional[BaseMemory] = None,\n\t\tmemory_cls: Type[BaseMemory] = ChatMemoryBuffer,\n\t\tmax_iterations: int = 10,\n\t\treact_chat_formatter: Optional[ReActChatFormatter] = None,\n\t\toutput_parser: Optional[ReActOutputParser] = None,\n\t\tcallback_manager: Optional[CallbackManager] = None,\n\t\tverbose: bool = False,\n\t\thandle_reasoning_failure_fn: Optional[Callable[[CallbackManager, Exception], ToolOutput]] = None,\n\t\tenable_instruct: bool = False,\n\t\tenable_comment: bool = False,\n\t\t**kwargs: Any,\n\t) -&gt; \"InstructReActAgent\":\n\t\t\"\"\"\n\t\tConvenience constructor method from set of BaseTools (Optional).\n\n\t\tNOTE: kwargs should have been exhausted by this point. In other words\n\t\tthe various upstream components such as BaseSynthesizer (response synthesizer)\n\t\tor BaseRetriever should have picked up off their respective kwargs in their\n\t\tconstructions.\n\n\t\tIf `handle_reasoning_failure_fn` is provided, when LLM fails to follow the response templates specified in\n\t\tthe System Prompt, this function will be called. This function should provide to the Agent, so that the Agent\n\t\tcan have a second chance to fix its mistakes.\n\t\tTo handle the exception yourself, you can provide a function that raises the `Exception`.\n\n\t\tNote: If you modified any response template in the System Prompt, you should override the method\n\t\t`_extract_reasoning_step` in `ReActAgentWorker`.\n\n\t\tReturns:\n\t\t\tInstructReActAgent\n\t\t\"\"\"\n\t\tllm = llm or Settings.llm\n\t\tif callback_manager is not None:\n\t\t\tllm.callback_manager = callback_manager\n\t\tmemory = memory or memory_cls.from_defaults(chat_history=chat_history or [], llm=llm)\n\t\treturn cls(\n\t\t\ttools=tools or [],\n\t\t\ttool_retriever=tool_retriever,\n\t\t\tllm=llm,\n\t\t\tmemory=memory,\n\t\t\tmax_iterations=max_iterations,\n\t\t\treact_chat_formatter=react_chat_formatter,\n\t\t\toutput_parser=output_parser,\n\t\t\tcallback_manager=callback_manager,\n\t\t\tverbose=verbose,\n\t\t\thandle_reasoning_failure_fn=handle_reasoning_failure_fn,\n\t\t\tenable_instruct=enable_instruct,\n\t\t\tenable_comment=enable_comment,\n\t\t)\n</code></pre>"},{"location":"code_docs/agent/react/react/#labridge.agent.react.react.InstructReActAgent.enable_comment","title":"<code>labridge.agent.react.react.InstructReActAgent.enable_comment</code>  <code>property</code>","text":"<p>Enable user's instruction in Acting Phase.</p>"},{"location":"code_docs/agent/react/react/#labridge.agent.react.react.InstructReActAgent.enable_instruct","title":"<code>labridge.agent.react.react.InstructReActAgent.enable_instruct</code>  <code>property</code>","text":"<p>Enable user's instruction in Reasoning Phase.</p>"},{"location":"code_docs/agent/react/react/#labridge.agent.react.react.InstructReActAgent.final_process_tool_logs","title":"<code>labridge.agent.react.react.InstructReActAgent.final_process_tool_logs(task)</code>","text":"<p>Process the tool logs of the agent's acting.</p> <ol> <li>Record the log_to_system: log_to_system will be recorded to the long-term memory.</li> <li>Extract the log_to_user: log_to_user will be attached to the agent's answer.</li> <li>Extract the references: references are the file paths of the relevant documents. This information will be sent to the frontend.</li> </ol> Source code in <code>labridge\\agent\\react\\react.py</code> <pre><code>def final_process_tool_logs(self, task: Task) -&gt; Tuple[str, List[str]]:\n\tr\"\"\"\n\tProcess the tool logs of the agent's acting.\n\n\t1. Record the log_to_system: log_to_system will be recorded to the long-term memory.\n\t2. Extract the log_to_user: log_to_user will be attached to the agent's answer.\n\t3. Extract the references: references are the file paths of the relevant documents. This information will be\n\tsent to the frontend.\n\t\"\"\"\n\ttool_log_list = task.extra_state[\"tool_log\"]\n\ttool_logs_str = get_all_system_logs(tool_logs=tool_log_list)\n\n\t# task.extra_state[\"new_memory\"].put(\n\t# \tChatMessage(\n\t# \t\tcontent=tool_logs_str,\n\t# \t\trole=MessageRole.TOOL,\n\t# \t)\n\t# )\n\tto_user_logs = get_extra_str_to_user(tool_logs=tool_log_list)\n\tref_file_paths = get_ref_file_paths(tool_logs=tool_log_list)\n\treturn to_user_logs, ref_file_paths\n</code></pre>"},{"location":"code_docs/agent/react/react/#labridge.agent.react.react.InstructReActAgent.from_tools","title":"<code>labridge.agent.react.react.InstructReActAgent.from_tools(tools=None, tool_retriever=None, llm=None, chat_history=None, memory=None, memory_cls=ChatMemoryBuffer, max_iterations=10, react_chat_formatter=None, output_parser=None, callback_manager=None, verbose=False, handle_reasoning_failure_fn=None, enable_instruct=False, enable_comment=False, **kwargs)</code>  <code>classmethod</code>","text":"<p>Convenience constructor method from set of BaseTools (Optional).</p> <p>NOTE: kwargs should have been exhausted by this point. In other words the various upstream components such as BaseSynthesizer (response synthesizer) or BaseRetriever should have picked up off their respective kwargs in their constructions.</p> <p>If <code>handle_reasoning_failure_fn</code> is provided, when LLM fails to follow the response templates specified in the System Prompt, this function will be called. This function should provide to the Agent, so that the Agent can have a second chance to fix its mistakes. To handle the exception yourself, you can provide a function that raises the <code>Exception</code>.</p> <p>Note: If you modified any response template in the System Prompt, you should override the method <code>_extract_reasoning_step</code> in <code>ReActAgentWorker</code>.</p> RETURNS DESCRIPTION <code>InstructReActAgent</code> <p>InstructReActAgent</p> Source code in <code>labridge\\agent\\react\\react.py</code> <pre><code>@classmethod\ndef from_tools(\n\tcls,\n\ttools: Optional[List[BaseTool]] = None,\n\ttool_retriever: Optional[ObjectRetriever[BaseTool]] = None,\n\tllm: Optional[LLM] = None,\n\tchat_history: Optional[List[ChatMessage]] = None,\n\tmemory: Optional[BaseMemory] = None,\n\tmemory_cls: Type[BaseMemory] = ChatMemoryBuffer,\n\tmax_iterations: int = 10,\n\treact_chat_formatter: Optional[ReActChatFormatter] = None,\n\toutput_parser: Optional[ReActOutputParser] = None,\n\tcallback_manager: Optional[CallbackManager] = None,\n\tverbose: bool = False,\n\thandle_reasoning_failure_fn: Optional[Callable[[CallbackManager, Exception], ToolOutput]] = None,\n\tenable_instruct: bool = False,\n\tenable_comment: bool = False,\n\t**kwargs: Any,\n) -&gt; \"InstructReActAgent\":\n\t\"\"\"\n\tConvenience constructor method from set of BaseTools (Optional).\n\n\tNOTE: kwargs should have been exhausted by this point. In other words\n\tthe various upstream components such as BaseSynthesizer (response synthesizer)\n\tor BaseRetriever should have picked up off their respective kwargs in their\n\tconstructions.\n\n\tIf `handle_reasoning_failure_fn` is provided, when LLM fails to follow the response templates specified in\n\tthe System Prompt, this function will be called. This function should provide to the Agent, so that the Agent\n\tcan have a second chance to fix its mistakes.\n\tTo handle the exception yourself, you can provide a function that raises the `Exception`.\n\n\tNote: If you modified any response template in the System Prompt, you should override the method\n\t`_extract_reasoning_step` in `ReActAgentWorker`.\n\n\tReturns:\n\t\tInstructReActAgent\n\t\"\"\"\n\tllm = llm or Settings.llm\n\tif callback_manager is not None:\n\t\tllm.callback_manager = callback_manager\n\tmemory = memory or memory_cls.from_defaults(chat_history=chat_history or [], llm=llm)\n\treturn cls(\n\t\ttools=tools or [],\n\t\ttool_retriever=tool_retriever,\n\t\tllm=llm,\n\t\tmemory=memory,\n\t\tmax_iterations=max_iterations,\n\t\treact_chat_formatter=react_chat_formatter,\n\t\toutput_parser=output_parser,\n\t\tcallback_manager=callback_manager,\n\t\tverbose=verbose,\n\t\thandle_reasoning_failure_fn=handle_reasoning_failure_fn,\n\t\tenable_instruct=enable_instruct,\n\t\tenable_comment=enable_comment,\n\t)\n</code></pre>"},{"location":"code_docs/agent/react/react/#labridge.agent.react.react.InstructReActAgent.set_enable_comment","title":"<code>labridge.agent.react.react.InstructReActAgent.set_enable_comment(enable)</code>","text":"<p>Set enable_comment.</p> Source code in <code>labridge\\agent\\react\\react.py</code> <pre><code>def set_enable_comment(self, enable: bool):\n\tr\"\"\" Set enable_comment. \"\"\"\n\tself._enable_comment = enable\n</code></pre>"},{"location":"code_docs/agent/react/react/#labridge.agent.react.react.InstructReActAgent.set_enable_instruct","title":"<code>labridge.agent.react.react.InstructReActAgent.set_enable_instruct(enable)</code>","text":"<p>Set enable_instruct.</p> Source code in <code>labridge\\agent\\react\\react.py</code> <pre><code>def set_enable_instruct(self, enable: bool):\n\tr\"\"\" Set enable_instruct. \"\"\"\n\tself.agent_worker.set_enable_instruct(enable)\n</code></pre>"},{"location":"code_docs/agent/react/react/#labridge.agent.react.react.InstructReActAgent.update_user_id_list","title":"<code>labridge.agent.react.react.InstructReActAgent.update_user_id_list()</code>","text":"<p>Update the registered user ids</p> Source code in <code>labridge\\agent\\react\\react.py</code> <pre><code>def update_user_id_list(self):\n\tr\"\"\" Update the registered user ids \"\"\"\n\tself.user_id_list = AccountManager().get_users()\n\tself.agent_worker.user_id_list = self.user_id_list\n</code></pre>"},{"location":"code_docs/agent/react/react_chat_format/","title":"React chat format","text":""},{"location":"code_docs/agent/react/react_chat_format/#labridge.agent.react.react_chat_format","title":"<code>labridge.agent.react.react_chat_format</code>","text":""},{"location":"code_docs/agent/react/react_chat_format/#labridge.agent.react.react_chat_format.InstructChatFormatter","title":"<code>labridge.agent.react.react_chat_format.InstructChatFormatter</code>","text":"<p>               Bases: <code>object</code></p> <p>Instruct chat formatter.</p> Source code in <code>labridge\\agent\\react\\react_chat_format.py</code> <pre><code>class InstructChatFormatter(object):\n    \"\"\"Instruct chat formatter.\"\"\"\n\n    system_header: str = INSTRUCT_CHAT_SYSTEM_HEADER  # default\n    context: str = \"\"  # not needed w/ default\n\n    def format(\n        self,\n        tools: Sequence[BaseTool],\n        chat_history: List[ChatMessage],\n\t\tprev_response: str,\n\t\tsuggestion: str,\n        current_reasoning: Optional[List[BaseReasoningStep]] = None,\n    ) -&gt; List[ChatMessage]:\n        \"\"\"Format chat history into list of ChatMessage.\"\"\"\n        current_reasoning = current_reasoning or []\n\n        format_args = {\n            \"tool_desc\": \"\\n\".join(get_react_tool_descriptions(tools)),\n            \"tool_names\": \", \".join([tool.metadata.get_name() for tool in tools]),\n\t\t\t\"prev_response\": prev_response,\n\t\t\t\"suggestion\": suggestion,\n        }\n        if self.context:\n            format_args[\"context\"] = self.context\n\n        fmt_sys_header = self.system_header.format(**format_args)\n\n        # format reasoning history as alternating user and assistant messages\n        # where the assistant messages are thoughts and actions and the user\n        # messages are observations\n        reasoning_history = []\n        for reasoning_step in current_reasoning:\n            if isinstance(reasoning_step, ObservationReasoningStep):\n                message = ChatMessage(\n                    role=MessageRole.USER,\n                    content=reasoning_step.get_content(),\n                )\n            else:\n                message = ChatMessage(\n                    role=MessageRole.ASSISTANT,\n                    content=reasoning_step.get_content(),\n                )\n            reasoning_history.append(message)\n\n        return [\n            ChatMessage(role=MessageRole.SYSTEM, content=fmt_sys_header),\n            *chat_history,\n            *reasoning_history,\n        ]\n</code></pre>"},{"location":"code_docs/agent/react/react_chat_format/#labridge.agent.react.react_chat_format.InstructChatFormatter.format","title":"<code>labridge.agent.react.react_chat_format.InstructChatFormatter.format(tools, chat_history, prev_response, suggestion, current_reasoning=None)</code>","text":"<p>Format chat history into list of ChatMessage.</p> Source code in <code>labridge\\agent\\react\\react_chat_format.py</code> <pre><code>    def format(\n        self,\n        tools: Sequence[BaseTool],\n        chat_history: List[ChatMessage],\n\t\tprev_response: str,\n\t\tsuggestion: str,\n        current_reasoning: Optional[List[BaseReasoningStep]] = None,\n    ) -&gt; List[ChatMessage]:\n        \"\"\"Format chat history into list of ChatMessage.\"\"\"\n        current_reasoning = current_reasoning or []\n\n        format_args = {\n            \"tool_desc\": \"\\n\".join(get_react_tool_descriptions(tools)),\n            \"tool_names\": \", \".join([tool.metadata.get_name() for tool in tools]),\n\t\t\t\"prev_response\": prev_response,\n\t\t\t\"suggestion\": suggestion,\n        }\n        if self.context:\n            format_args[\"context\"] = self.context\n\n        fmt_sys_header = self.system_header.format(**format_args)\n\n        # format reasoning history as alternating user and assistant messages\n        # where the assistant messages are thoughts and actions and the user\n        # messages are observations\n        reasoning_history = []\n        for reasoning_step in current_reasoning:\n            if isinstance(reasoning_step, ObservationReasoningStep):\n                message = ChatMessage(\n                    role=MessageRole.USER,\n                    content=reasoning_step.get_content(),\n                )\n            else:\n                message = ChatMessage(\n                    role=MessageRole.ASSISTANT,\n                    content=reasoning_step.get_content(),\n                )\n            reasoning_history.append(message)\n\n        return [\n            ChatMessage(role=MessageRole.SYSTEM, content=fmt_sys_header),\n            *chat_history,\n            *reasoning_history,\n        ]\n</code></pre>"},{"location":"code_docs/agent/react/react_step/","title":"React step","text":""},{"location":"code_docs/agent/react/react_step/#labridge.agent.react.react_step","title":"<code>labridge.agent.react.react_step</code>","text":""},{"location":"code_docs/agent/react/react_step/#labridge.agent.react.react_step.InstructReActAgentWorker","title":"<code>labridge.agent.react.react_step.InstructReActAgentWorker</code>","text":"<p>               Bases: <code>ReActAgentWorker</code></p> Source code in <code>labridge\\agent\\react\\react_step.py</code> <pre><code>class InstructReActAgentWorker(ReActAgentWorker):\n\tdef __init__(\n\t\tself,\n\t\ttools: Sequence[BaseTool],\n\t\tllm: LLM,\n\t\tuser_id_list: List[str],\n\t\tchat_group_id_list: List[str],\n\t\tmax_iterations: int = 10,\n\t\treact_chat_formatter: Optional[ReActChatFormatter] = None,\n\t\toutput_parser: Optional[ReActOutputParser] = None,\n\t\tcallback_manager: Optional[CallbackManager] = None,\n\t\tverbose: bool = False,\n\t\ttool_retriever: Optional[ObjectRetriever[BaseTool]] = None,\n\t\thandle_reasoning_failure_fn: Optional[Callable[[CallbackManager, Exception], ToolOutput]] = None,\n\t\tenable_instruct: bool = False,\n\t):\n\t\tself._enable_instruct = enable_instruct\n\t\tself._instruct_chat_formatter = InstructChatFormatter()\n\t\tself.user_id_list = user_id_list\n\t\tself.chat_group_id_list = chat_group_id_list\n\t\tsuper().__init__(\n\t\t\ttools=tools,\n\t\t\tllm=llm,\n\t\t\tmax_iterations=max_iterations,\n\t\t\treact_chat_formatter=react_chat_formatter,\n\t\t\toutput_parser=output_parser,\n\t\t\tcallback_manager=callback_manager,\n\t\t\tverbose=verbose,\n\t\t\ttool_retriever=tool_retriever,\n\t\t\thandle_reasoning_failure_fn=handle_reasoning_failure_fn,\n\t\t)\n\n\tdef set_enable_instruct(self, enable: bool):\n\t\tself._enable_instruct = enable\n\n\t@property\n\tdef enable_instruct(self):\n\t\tr\"\"\" Enable user's instruction in reasoning phase. \"\"\"\n\t\treturn self._enable_instruct\n\n\t@classmethod\n\tdef from_tools(\n\t\tcls,\n\t\ttools: Optional[Sequence[BaseTool]] = None,\n\t\ttool_retriever: Optional[ObjectRetriever[BaseTool]] = None,\n\t\tllm: Optional[LLM] = None,\n\t\tuser_id_list: List[str] = None,\n\t\tchat_group_id_list: List[str] = None,\n\t\tmax_iterations: int = 10,\n\t\treact_chat_formatter: Optional[ReActChatFormatter] = None,\n\t\toutput_parser: Optional[ReActOutputParser] = None,\n\t\tcallback_manager: Optional[CallbackManager] = None,\n\t\tverbose: bool = False,\n\t\thandle_reasoning_failure_fn: Optional[Callable[[CallbackManager, Exception], ToolOutput]] = None,\n\t\tenable_instruct: bool = False,\n\t\t**kwargs: Any,\n\t) -&gt; \"InstructReActAgentWorker\":\n\t\t\"\"\"\n\t\tConvenience constructor method from set of BaseTools (Optional).\n\n\t\tNOTE: kwargs should have been exhausted by this point. In other words\n\t\tthe various upstream components such as BaseSynthesizer (response synthesizer)\n\t\tor BaseRetriever should have picked up off their respective kwargs in their\n\t\tconstructions.\n\n\t\tReturns:\n\t\t\tReActAgentWorker\n\t\t\"\"\"\n\t\tllm = llm or Settings.llm\n\t\tif callback_manager is not None:\n\t\t\tllm.callback_manager = callback_manager\n\t\treturn cls(\n\t\t\ttools=tools or [],\n\t\t\ttool_retriever=tool_retriever,\n\t\t\tuser_id_list=user_id_list or AccountManager().get_users(),\n\t\t\tchat_group_id_list=chat_group_id_list or AccountManager().get_chat_groups(),\n\t\t\tllm=llm,\n\t\t\tmax_iterations=max_iterations,\n\t\t\treact_chat_formatter=react_chat_formatter,\n\t\t\toutput_parser=output_parser,\n\t\t\tcallback_manager=callback_manager,\n\t\t\tverbose=verbose,\n\t\t\thandle_reasoning_failure_fn=handle_reasoning_failure_fn,\n\t\t\tenable_instruct=enable_instruct,\n\t\t)\n\n\tdef initialize_step(self, task: Task, **kwargs: Any) -&gt; TaskStep:\n\t\t\"\"\"Initialize step from task.\"\"\"\n\t\tsources: List[ToolOutput] = []\n\t\tcurrent_reasoning: List[BaseReasoningStep] = []\n\t\t# temporary memory for new messages\n\t\tnew_memory = ChatMemoryBuffer.from_defaults()\n\t\t# the tool log list with ToolLogs.\n\t\ttool_log = []\n\n\t\t# initialize task state\n\t\ttask_state = {\n\t\t\t\"sources\": sources,\n\t\t\t\"current_reasoning\": current_reasoning,\n\t\t\t\"new_memory\": new_memory,\n\t\t\t\"tool_log\": tool_log,\n\t\t}\n\t\ttask.extra_state.update(task_state)\n\n\t\treturn TaskStep(\n\t\t\ttask_id=task.task_id,\n\t\t\tstep_id=str(uuid.uuid4()),\n\t\t\tinput=task.input,\n\t\t\tstep_state={\"is_first\": True, \"system_msg\": task.extra_state[\"system_msg\"]},\n\t\t)\n\n\tdef _run_step(self, step: TaskStep, task: Task, ) -&gt; TaskStepOutput:\n\t\t\"\"\"Run step.\"\"\"\n\t\tuser_id = task.extra_state[\"user_id\"]\n\t\tif step.input is not None:\n\t\t\tstep.step_state[\"user_id\"] = user_id\n\t\t\tadd_user_step_to_reasoning(\n\t\t\t\tstep,\n\t\t\t\ttask.extra_state[\"new_memory\"],\n\t\t\t\ttask.extra_state[\"current_reasoning\"],\n\t\t\t\tverbose=self._verbose,\n\t\t\t)\n\t\ttools = self.get_tools(task.input)\n\t\tinput_chat = self._react_chat_formatter.format(\n\t\t\ttools,\n\t\t\tchat_history=task.memory.get(input=task.input) + task.extra_state[\"new_memory\"].get_all(),\n\t\t\tcurrent_reasoning=task.extra_state[\"current_reasoning\"],\n\t\t)\n\n\t\t# send prompt\n\t\tchat_response = self._llm.chat(input_chat)\n\n\t\tif task.extra_state[\"enable_instruct\"]:\n\t\t\t# TODO: interface: Send the action to the user\n\t\t\tprint_text(f\"&gt;&gt;&gt; Initial reasoning: \\n{chat_response.message.content}\", color=\"pink\", end=\"\\n\")\n\t\t\t# TODO: interface: Get the user's suggestion\n\t\t\tpacked_msgs = ChatBuffer.test_get_user_text(\n\t\t\t\tuser_id=user_id,\n\t\t\t\tenable_instruct=False,\n\t\t\t\tenable_comment=False,\n\t\t\t)\n\n\t\t\tuser_advice = packed_msgs.user_msg\n\t\t\t# update enable_instruct and enable_comment\n\t\t\tupdate_intervene_status(\n\t\t\t\ttask=task,\n\t\t\t\tenable_instruct=ChatBuffer.config_buffer[user_id].enable_instruct,\n\t\t\t\tenable_comment=ChatBuffer.config_buffer[user_id].enable_comment,\n\t\t\t\treply_in_speech=ChatBuffer.config_buffer[user_id].reply_in_speech,\n\t\t\t)\n\t\t\tprint_text(f\"&gt;&gt;&gt; User's suggestion: \\n{user_advice}\", color=\"blue\", end=\"\\n\")\n\t\t\treasoning_step = ObservationReasoningStep(observation=f\"User's suggestion: {user_advice}\")\n\t\t\ttask.extra_state[\"current_reasoning\"].append(reasoning_step)\n\n\t\t\tinstruct_chat = self._instruct_chat_formatter.format(\n\t\t\t\ttools,\n\t\t\t\tchat_history=task.memory.get(input=task.input) + task.extra_state[\"new_memory\"].get_all(),\n\t\t\t\tcurrent_reasoning=task.extra_state[\"current_reasoning\"],\n\t\t\t\tprev_response=chat_response.message.content,\n\t\t\t\tsuggestion=f\"User's suggestion: {user_advice}\",\n\t\t\t)\n\t\t\tchat_response = self._llm.chat(instruct_chat)\n\t\t\tprint_text(f\"&gt;&gt;&gt; Modified reasoning: \\n{chat_response.message.content}\", color=\"green\", end=\"\\n\")\n\n\t\t# given react prompt outputs, call tools or return response\n\t\treasoning_steps, is_done = self._process_actions(task, tools, output=chat_response)\n\t\ttask.extra_state[\"current_reasoning\"].extend(reasoning_steps)\n\t\tagent_response = self._get_response(task.extra_state[\"current_reasoning\"], task.extra_state[\"sources\"])\n\n\t\tif is_done:\n\t\t\tdate, h_m_s = get_time()\n\t\t\tadditional_kwargs = {\n\t\t\t\tLOG_DATE_NAME: date,\n\t\t\t\tLOG_TIME_NAME: h_m_s,\n\t\t\t}\n\t\t\ttask.extra_state[\"new_memory\"].put(\n\t\t\t\tChatMessage(\n\t\t\t\t\tcontent=agent_response.response,\n\t\t\t\t\trole=MessageRole.ASSISTANT,\n\t\t\t\t\tadditional_kwargs=additional_kwargs,\n\t\t\t\t)\n\t\t\t)\n\n\t\treturn self._get_task_step_response(agent_response, step, is_done)\n\n\tasync def _arun_step(self, step: TaskStep, task: Task, ) -&gt; TaskStepOutput:\n\t\t\"\"\"Run step.\"\"\"\n\t\tuser_id = task.extra_state[\"user_id\"]\n\t\tif step.input is not None:\n\t\t\tstep.step_state[\"user_id\"] = user_id\n\t\t\tadd_user_step_to_reasoning(\n\t\t\t\tstep,\n\t\t\t\ttask.extra_state[\"new_memory\"],\n\t\t\t\ttask.extra_state[\"current_reasoning\"],\n\t\t\t\tverbose=self._verbose,\n\t\t\t)\n\n\t\ttools = self.get_tools(task.input)\n\n\t\tinput_chat = self._react_chat_formatter.format(\n\t\t\ttools,\n\t\t\tchat_history=task.memory.get(input=task.input) + task.extra_state[\"new_memory\"].get_all(),\n\t\t\tcurrent_reasoning=task.extra_state[\"current_reasoning\"],\n\t\t)\n\n\t\t# send prompt\n\t\tchat_response = await self._llm.achat(input_chat)\n\n\t\tif task.extra_state[\"enable_instruct\"]:\n\t\t\t# TODO: interface: Send the action to the user\n\t\t\tinit_reasoning = (\n\t\t\t\tf\"**\u200b\u5f53\u524d\u200bThought**:\\n\"\n\t\t\t\tf\"{chat_response.message.content}\\n\"\n\t\t\t\tf\"\u200b\u8bf7\u200b\u60a8\u200b\u53c2\u4e0e\u200b\u5230\u200b\u6211\u200b\u7684\u200bReasoning\u200b\u8fc7\u7a0b\u200b\u4e2d\u200b\uff0c\u200b\u7ed9\u4e88\u200b\u6307\u5bfc\u200b\u3002\u200b\u6211\u200b\u5c06\u200b\u53c2\u8003\u200b\u60a8\u200b\u7684\u200b\u5efa\u8bae\u200b\u5bf9\u200b\u6211\u200b\u7684\u200b\u51b3\u7b56\u200b\u505a\u51fa\u200b\u8c03\u6574\u200b\uff1a\"\n\t\t\t)\n\n\t\t\tChatBuffer.put_agent_reply(\n\t\t\t\tuser_id=user_id,\n\t\t\t\treply_str=init_reasoning,\n\t\t\t\tinner_chat=True,\n\t\t\t)\n\t\t\t# TODO: interface: Get the user's suggestion\n\t\t\tpacked_msgs = await ChatBuffer.get_user_msg(\n\t\t\t\tuser_id=user_id,\n\t\t\t)\n\n\t\t\tuser_advice = packed_msgs.user_msg\n\t\t\tsystem_msg = packed_msgs.system_msg\n\t\t\t# Update the enable_instruct and enable_comment\n\t\t\tupdate_intervene_status(\n\t\t\t\ttask=task,\n\t\t\t\tenable_instruct=ChatBuffer.config_buffer[user_id].enable_instruct,\n\t\t\t\tenable_comment=ChatBuffer.config_buffer[user_id].enable_comment,\n\t\t\t\treply_in_speech=ChatBuffer.config_buffer[user_id].reply_in_speech,\n\t\t\t)\n\n\t\t\t# Put the user's instruction into reasoning.\n\t\t\tsystem_step = ObservationReasoningStep(observation=f\"&lt;system&gt;:{system_msg}\")\n\t\t\treasoning_step = ObservationReasoningStep(observation=f\"User's suggestion: {user_advice}\")\n\t\t\ttask.extra_state[\"current_reasoning\"].extend([system_step, reasoning_step])\n\n\t\t\tinstruct_chat = self._instruct_chat_formatter.format(\n\t\t\t\ttools,\n\t\t\t\tchat_history=task.memory.get(input=task.input) + task.extra_state[\"new_memory\"].get_all(),\n\t\t\t\tcurrent_reasoning=task.extra_state[\"current_reasoning\"],\n\t\t\t\tprev_response=chat_response.message.content,\n\t\t\t\tsuggestion=f\"User's suggestion: {user_advice}\",\n\t\t\t)\n\t\t\tchat_response = await self._llm.achat(instruct_chat)\n\n\t\t\t# modified_reasoning = (\n\t\t\t# \tf\"**\u200b\u53c2\u8003\u200b\u60a8\u200b\u5efa\u8bae\u200b\u540e\u200b\u7684\u200bThought**:\\n\"\n\t\t\t# \tf\"{chat_response.message.content}\\n\\n\"\n\t\t\t# \tf\"\u200b\u6211\u200b\u5c06\u200b\u6839\u636e\u200b\u8fd9\u4e2a\u200bThought\u200b\u884c\u52a8\u200b\u3002\"\n\t\t\t# )\n\t\t\t#\n\t\t\t# ChatBuffer.put_agent_reply(\n\t\t\t# \tuser_id=step.step_state[\"user_id\"],\n\t\t\t# \treply_str=modified_reasoning,\n\t\t\t# \tinner_chat=True,\n\t\t\t# )\n\n\t\t# given react prompt outputs, call tools or return response\n\t\treasoning_steps, is_done = await self._aprocess_actions(task, tools, output=chat_response)\n\t\ttask.extra_state[\"current_reasoning\"].extend(reasoning_steps)\n\t\tagent_response = self._get_response(task.extra_state[\"current_reasoning\"], task.extra_state[\"sources\"])\n\t\tif is_done:\n\t\t\tdate, h_m_s = get_time()\n\t\t\tadditional_kwargs = {\n\t\t\t\tLOG_DATE_NAME: date,\n\t\t\t\tLOG_TIME_NAME: h_m_s,\n\t\t\t}\n\t\t\ttask.extra_state[\"new_memory\"].put(\n\t\t\t\tChatMessage(\n\t\t\t\t\tcontent=agent_response.response,\n\t\t\t\t\trole=MessageRole.ASSISTANT,\n\t\t\t\t\tadditional_kwargs=additional_kwargs,\n\t\t\t\t)\n\t\t\t)\n\n\t\treturn self._get_task_step_response(agent_response, step, is_done)\n\n\tdef _process_actions(\n\t\tself,\n\t\ttask: Task,\n\t\ttools: Sequence[AsyncBaseTool],\n\t\toutput: ChatResponse,\n\t\tis_streaming: bool = False,\n\t) -&gt; Tuple[List[BaseReasoningStep], bool]:\n\t\ttools_dict: Dict[str, AsyncBaseTool] = {tool.metadata.get_name(): tool for tool in tools}\n\t\ttool = None\n\n\t\ttry:\n\t\t\t_, current_reasoning, is_done = self._extract_reasoning_step(output, is_streaming)\n\t\texcept ValueError as exp:\n\t\t\tcurrent_reasoning = []\n\t\t\ttool_output = self._handle_reasoning_failure_fn(self.callback_manager, exp)\n\t\telse:\n\t\t\tif is_done:\n\t\t\t\treturn current_reasoning, True\n\n\t\t\t# call tool with input\n\t\t\treasoning_step = cast(ActionReasoningStep, current_reasoning[-1])\n\t\t\tif reasoning_step.action in tools_dict:\n\t\t\t\ttool = tools_dict[reasoning_step.action]\n\t\t\t\twith self.callback_manager.event(\n\t\t\t\t\t\tCBEventType.FUNCTION_CALL,\n\t\t\t\t\t\tpayload={EventPayload.FUNCTION_CALL: reasoning_step.action_input,\n\t\t\t\t\t\t\tEventPayload.TOOL: tool.metadata,\n\t\t\t\t\t\t},\n\t\t\t\t) as event:\n\t\t\t\t\ttry:\n\t\t\t\t\t\ttool_output = tool.call(**reasoning_step.action_input)\n\t\t\t\t\texcept Exception as e:\n\t\t\t\t\t\ttool_output = ToolOutput(\n\t\t\t\t\t\t\tcontent=f\"Error: {e!s}\",\n\t\t\t\t\t\t\ttool_name=tool.metadata.name,\n\t\t\t\t\t\t\traw_input={\"kwargs\": reasoning_step.action_input},\n\t\t\t\t\t\t\traw_output=e,\n\t\t\t\t\t\t\tis_error=True,\n\t\t\t\t\t\t)\n\t\t\t\t\tevent.on_end(payload={EventPayload.FUNCTION_OUTPUT: str(tool_output)})\n\t\t\telse:\n\t\t\t\ttool_output = self._handle_nonexistent_tool_name(reasoning_step)\n\n\t\ttask.extra_state[\"sources\"].append(tool_output)\n\n\t\ttool_output_str, tool_log_str = unpack_tool_output(tool_out_json=tool_output.content)\n\t\tif tool is not None and tool.metadata.return_direct:\n\t\t\tobservation = tool_output_str\n\t\telse:\n\t\t\tobservation = f\"Tool output:\\n{tool_output_str}\\nTool logs:\\n{tool_log_str}\"\n\n\t\t# record the tool log.\n\t\tif tool_log_str:\n\t\t\ttool_log = ToolLog.loads(log_str=tool_log_str)\n\t\t\ttask.extra_state[\"tool_log\"].append(tool_log)\n\t\t\ttask.extra_state[\"new_memory\"].put(\n\t\t\t\tChatMessage(\n\t\t\t\t\tcontent=tool_log_str,\n\t\t\t\t\trole=MessageRole.TOOL,\n\t\t\t\t)\n\t\t\t)\n\n\t\tobservation_step = ObservationReasoningStep(\n\t\t\tobservation=observation,\n\t\t\treturn_direct=(tool.metadata.return_direct and not tool_output.is_error if tool else False),\n\t\t)\n\t\tcurrent_reasoning.append(observation_step)\n\t\tif self._verbose:\n\t\t\tprint_text(f\"{observation_step.get_content()}\\n\", color=\"blue\")\n\t\treturn (\n\t\t\tcurrent_reasoning,\n\t\t\ttool.metadata.return_direct and not tool_output.is_error if tool else False,\n\t\t)\n\n\tasync def _aprocess_actions(\n\t\tself,\n\t\ttask: Task,\n\t\ttools: Sequence[AsyncBaseTool],\n\t\toutput: ChatResponse,\n\t\tis_streaming: bool = False,\n\t) -&gt; Tuple[List[BaseReasoningStep], bool]:\n\t\ttools_dict = {tool.metadata.name: tool for tool in tools}\n\t\ttool = None\n\n\t\ttry:\n\t\t\t_, current_reasoning, is_done = self._extract_reasoning_step(output, is_streaming)\n\t\texcept ValueError as exp:\n\t\t\tcurrent_reasoning = []\n\t\t\ttool_output = self._handle_reasoning_failure_fn(self.callback_manager, exp)\n\t\telse:\n\t\t\tif is_done:\n\t\t\t\treturn current_reasoning, True\n\n\t\t\t# call tool with input\n\t\t\treasoning_step = cast(ActionReasoningStep, current_reasoning[-1])\n\t\t\tif reasoning_step.action in tools_dict:\n\t\t\t\ttool = tools_dict[reasoning_step.action]\n\t\t\t\twith self.callback_manager.event(CBEventType.FUNCTION_CALL,\n\t\t\t\t\t\tpayload={EventPayload.FUNCTION_CALL: reasoning_step.action_input,\n\t\t\t\t\t\t\tEventPayload.TOOL: tool.metadata, }, ) as event:\n\t\t\t\t\ttry:\n\t\t\t\t\t\ttool_output = await tool.acall(**reasoning_step.action_input)\n\t\t\t\t\texcept Exception as e:\n\t\t\t\t\t\ttool_output = ToolOutput(content=f\"Error: {e!s}\", tool_name=tool.metadata.name,\n\t\t\t\t\t\t\traw_input={\"kwargs\": reasoning_step.action_input}, raw_output=e, is_error=True, )\n\t\t\t\t\tevent.on_end(payload={EventPayload.FUNCTION_OUTPUT: str(tool_output)})\n\t\t\telse:\n\t\t\t\ttool_output = self._handle_nonexistent_tool_name(reasoning_step)\n\n\t\ttask.extra_state[\"sources\"].append(tool_output)\n\n\t\ttool_output_str, tool_log_str = unpack_tool_output(tool_out_json=tool_output.content)\n\t\tif tool is not None and tool.metadata.return_direct:\n\t\t\tobservation = tool_output_str\n\t\telse:\n\t\t\tobservation = f\"Tool output:\\n{tool_output_str}\\nTool logs:\\n{tool_log_str}\"\n\n\t\t# record the tool log.\n\t\tif tool_log_str:\n\t\t\ttool_log = ToolLog.loads(log_str=tool_log_str)\n\t\t\ttask.extra_state[\"tool_log\"].append(tool_log)\n\t\t\ttask.extra_state[\"new_memory\"].put(\n\t\t\t\tChatMessage(\n\t\t\t\t\tcontent=tool_log_str,\n\t\t\t\t\trole=MessageRole.TOOL,\n\t\t\t\t)\n\t\t\t)\n\n\t\tobservation_step = ObservationReasoningStep(observation=observation,\n\t\t\treturn_direct=(tool.metadata.return_direct and not tool_output.is_error if tool else False), )\n\n\t\tcurrent_reasoning.append(observation_step)\n\t\tif self._verbose:\n\t\t\tprint_text(f\"{observation_step.get_content()}\\n\", color=\"blue\")\n\t\treturn (\n\t\t\tcurrent_reasoning, tool.metadata.return_direct and not tool_output.is_error if tool else False,\n\t\t)\n\n\tdef finalize_task(self, task: Task, **kwargs: Any) -&gt; None:\n\t\t\"\"\"Finalize task, after all the steps are completed.\"\"\"\n\t\tuser_id = task.extra_state.get(\"user_id\", None)\n\t\tchat_group_id = task.extra_state.get(\"chat_group_id\", None)\n\n\t\tif chat_group_id is not None:\n\t\t\tif chat_group_id in self.chat_group_id_list:\n\t\t\t\tupdate_chat_memory(\n\t\t\t\t\tmemory_id=user_id,\n\t\t\t\t\tchat_messages=task.extra_state[\"new_memory\"].get_all(),\n\t\t\t\t)\n\t\t\telse:\n\t\t\t\tif self._verbose:\n\t\t\t\t\tprint_text(f\"The chat group {chat_group_id} is not registered.\", color=\"cyan\", end=\"\\n\")\n\t\telse:\n\t\t\tif user_id in self.user_id_list:\n\t\t\t\tupdate_chat_memory(\n\t\t\t\t\tmemory_id=user_id,\n\t\t\t\t\tchat_messages=task.extra_state[\"new_memory\"].get_all(),\n\t\t\t\t)\n\t\t\telse:\n\t\t\t\tif self._verbose and user_id is not None:\n\t\t\t\t\tprint_text(f\"{user_id} is not registered as a user.\", color=\"cyan\", end=\"\\n\")\n\n\t\t# add new messages to memory\n\t\ttask.memory.set(task.memory.get_all() + task.extra_state[\"new_memory\"].get_all())\n\t\t# reset new memory\n\t\ttask.extra_state[\"new_memory\"].reset()\n</code></pre>"},{"location":"code_docs/agent/react/react_step/#labridge.agent.react.react_step.InstructReActAgentWorker.enable_instruct","title":"<code>labridge.agent.react.react_step.InstructReActAgentWorker.enable_instruct</code>  <code>property</code>","text":"<p>Enable user's instruction in reasoning phase.</p>"},{"location":"code_docs/agent/react/react_step/#labridge.agent.react.react_step.InstructReActAgentWorker.finalize_task","title":"<code>labridge.agent.react.react_step.InstructReActAgentWorker.finalize_task(task, **kwargs)</code>","text":"<p>Finalize task, after all the steps are completed.</p> Source code in <code>labridge\\agent\\react\\react_step.py</code> <pre><code>def finalize_task(self, task: Task, **kwargs: Any) -&gt; None:\n\t\"\"\"Finalize task, after all the steps are completed.\"\"\"\n\tuser_id = task.extra_state.get(\"user_id\", None)\n\tchat_group_id = task.extra_state.get(\"chat_group_id\", None)\n\n\tif chat_group_id is not None:\n\t\tif chat_group_id in self.chat_group_id_list:\n\t\t\tupdate_chat_memory(\n\t\t\t\tmemory_id=user_id,\n\t\t\t\tchat_messages=task.extra_state[\"new_memory\"].get_all(),\n\t\t\t)\n\t\telse:\n\t\t\tif self._verbose:\n\t\t\t\tprint_text(f\"The chat group {chat_group_id} is not registered.\", color=\"cyan\", end=\"\\n\")\n\telse:\n\t\tif user_id in self.user_id_list:\n\t\t\tupdate_chat_memory(\n\t\t\t\tmemory_id=user_id,\n\t\t\t\tchat_messages=task.extra_state[\"new_memory\"].get_all(),\n\t\t\t)\n\t\telse:\n\t\t\tif self._verbose and user_id is not None:\n\t\t\t\tprint_text(f\"{user_id} is not registered as a user.\", color=\"cyan\", end=\"\\n\")\n\n\t# add new messages to memory\n\ttask.memory.set(task.memory.get_all() + task.extra_state[\"new_memory\"].get_all())\n\t# reset new memory\n\ttask.extra_state[\"new_memory\"].reset()\n</code></pre>"},{"location":"code_docs/agent/react/react_step/#labridge.agent.react.react_step.InstructReActAgentWorker.from_tools","title":"<code>labridge.agent.react.react_step.InstructReActAgentWorker.from_tools(tools=None, tool_retriever=None, llm=None, user_id_list=None, chat_group_id_list=None, max_iterations=10, react_chat_formatter=None, output_parser=None, callback_manager=None, verbose=False, handle_reasoning_failure_fn=None, enable_instruct=False, **kwargs)</code>  <code>classmethod</code>","text":"<p>Convenience constructor method from set of BaseTools (Optional).</p> <p>NOTE: kwargs should have been exhausted by this point. In other words the various upstream components such as BaseSynthesizer (response synthesizer) or BaseRetriever should have picked up off their respective kwargs in their constructions.</p> RETURNS DESCRIPTION <code>InstructReActAgentWorker</code> <p>ReActAgentWorker</p> Source code in <code>labridge\\agent\\react\\react_step.py</code> <pre><code>@classmethod\ndef from_tools(\n\tcls,\n\ttools: Optional[Sequence[BaseTool]] = None,\n\ttool_retriever: Optional[ObjectRetriever[BaseTool]] = None,\n\tllm: Optional[LLM] = None,\n\tuser_id_list: List[str] = None,\n\tchat_group_id_list: List[str] = None,\n\tmax_iterations: int = 10,\n\treact_chat_formatter: Optional[ReActChatFormatter] = None,\n\toutput_parser: Optional[ReActOutputParser] = None,\n\tcallback_manager: Optional[CallbackManager] = None,\n\tverbose: bool = False,\n\thandle_reasoning_failure_fn: Optional[Callable[[CallbackManager, Exception], ToolOutput]] = None,\n\tenable_instruct: bool = False,\n\t**kwargs: Any,\n) -&gt; \"InstructReActAgentWorker\":\n\t\"\"\"\n\tConvenience constructor method from set of BaseTools (Optional).\n\n\tNOTE: kwargs should have been exhausted by this point. In other words\n\tthe various upstream components such as BaseSynthesizer (response synthesizer)\n\tor BaseRetriever should have picked up off their respective kwargs in their\n\tconstructions.\n\n\tReturns:\n\t\tReActAgentWorker\n\t\"\"\"\n\tllm = llm or Settings.llm\n\tif callback_manager is not None:\n\t\tllm.callback_manager = callback_manager\n\treturn cls(\n\t\ttools=tools or [],\n\t\ttool_retriever=tool_retriever,\n\t\tuser_id_list=user_id_list or AccountManager().get_users(),\n\t\tchat_group_id_list=chat_group_id_list or AccountManager().get_chat_groups(),\n\t\tllm=llm,\n\t\tmax_iterations=max_iterations,\n\t\treact_chat_formatter=react_chat_formatter,\n\t\toutput_parser=output_parser,\n\t\tcallback_manager=callback_manager,\n\t\tverbose=verbose,\n\t\thandle_reasoning_failure_fn=handle_reasoning_failure_fn,\n\t\tenable_instruct=enable_instruct,\n\t)\n</code></pre>"},{"location":"code_docs/agent/react/react_step/#labridge.agent.react.react_step.InstructReActAgentWorker.initialize_step","title":"<code>labridge.agent.react.react_step.InstructReActAgentWorker.initialize_step(task, **kwargs)</code>","text":"<p>Initialize step from task.</p> Source code in <code>labridge\\agent\\react\\react_step.py</code> <pre><code>def initialize_step(self, task: Task, **kwargs: Any) -&gt; TaskStep:\n\t\"\"\"Initialize step from task.\"\"\"\n\tsources: List[ToolOutput] = []\n\tcurrent_reasoning: List[BaseReasoningStep] = []\n\t# temporary memory for new messages\n\tnew_memory = ChatMemoryBuffer.from_defaults()\n\t# the tool log list with ToolLogs.\n\ttool_log = []\n\n\t# initialize task state\n\ttask_state = {\n\t\t\"sources\": sources,\n\t\t\"current_reasoning\": current_reasoning,\n\t\t\"new_memory\": new_memory,\n\t\t\"tool_log\": tool_log,\n\t}\n\ttask.extra_state.update(task_state)\n\n\treturn TaskStep(\n\t\ttask_id=task.task_id,\n\t\tstep_id=str(uuid.uuid4()),\n\t\tinput=task.input,\n\t\tstep_state={\"is_first\": True, \"system_msg\": task.extra_state[\"system_msg\"]},\n\t)\n</code></pre>"},{"location":"code_docs/agent/react/react_step/#labridge.agent.react.react_step.add_user_step_to_reasoning","title":"<code>labridge.agent.react.react_step.add_user_step_to_reasoning(step, memory, current_reasoning, verbose=False)</code>","text":"<p>Add user step to memory.</p> Source code in <code>labridge\\agent\\react\\react_step.py</code> <pre><code>def add_user_step_to_reasoning(\n    step: TaskStep,\n    memory: BaseMemory,\n    current_reasoning: List[BaseReasoningStep],\n    verbose: bool = False,\n) -&gt; None:\n\t\"\"\"Add user step to memory.\"\"\"\n\tif \"is_first\" in step.step_state and step.step_state[\"is_first\"]:\n\t\t# add to new memory\n\t\trecord_str = step.input\n\t\tdate, h_m_s = get_time()\n\t\tadditional_kwargs = {\n\t\t\tLOG_DATE_NAME: date,\n\t\t\tLOG_TIME_NAME: h_m_s,\n\t\t}\n\t\tmemory.put(\n\t\t\tChatMessage(\n\t\t\t\tcontent=step.step_state[\"system_msg\"],\n\t\t\t\trole=MessageRole.SYSTEM,\n\t\t\t\tadditional_kwargs=additional_kwargs,\n\t\t\t)\n\t\t)\n\t\tmemory.put(\n\t\t\tChatMessage(\n\t\t\t\tcontent=record_str,\n\t\t\t\trole=MessageRole.USER,\n\t\t\t\tadditional_kwargs=additional_kwargs,\n\t\t\t)\n\t\t)\n\t\tstep.step_state[\"is_first\"] = False\n\telse:\n\t\treasoning_step = ObservationReasoningStep(observation=step.input)\n\t\tcurrent_reasoning.append(reasoning_step)\n\t\tif verbose:\n\t\t\tprint(f\"Added user message to memory: {step.input}\")\n</code></pre>"},{"location":"code_docs/agent/react/react_step/#labridge.agent.react.react_step.update_intervene_status","title":"<code>labridge.agent.react.react_step.update_intervene_status(task, enable_instruct, enable_comment, reply_in_speech)</code>","text":"<p>Update the <code>enable_instruct</code> and <code>enable_comment</code> in the Reasoning &amp; Acting.</p> PARAMETER DESCRIPTION <code>task</code> <p>The processing task.</p> <p> TYPE: <code>Task</code> </p> <code>enable_instruct</code> <p>If True, enable the user to instruct the agent's Reasoning.</p> <p> TYPE: <code>bool</code> </p> <code>enable_comment</code> <p>If True, enable the user to comment on the agent's Acting.</p> <p> TYPE: <code>bool</code> </p> <code>reply_in_speech</code> <p>If True, the agent will reply in speech.</p> <p> TYPE: <code>bool</code> </p> RETURNS DESCRIPTION <p>None</p> Source code in <code>labridge\\agent\\react\\react_step.py</code> <pre><code>def update_intervene_status(\n\ttask: Task,\n\tenable_instruct: bool,\n\tenable_comment: bool,\n\treply_in_speech: bool\n):\n\tr\"\"\"\n\tUpdate the `enable_instruct` and `enable_comment` in the Reasoning &amp; Acting.\n\n\tArgs:\n\t\ttask (Task): The processing task.\n\t\tenable_instruct (bool): If True, enable the user to instruct the agent's Reasoning.\n\t\tenable_comment (bool): If True, enable the user to comment on the agent's Acting.\n\t\treply_in_speech (bool): If True, the agent will reply in speech.\n\n\tReturns:\n\t\tNone\n\t\"\"\"\n\ttask.extra_state[\"enable_instruct\"] = enable_instruct\n\ttask.extra_state[\"enable_comment\"] = enable_comment\n\ttask.extra_state[\"reply_in_speech\"] = reply_in_speech\n</code></pre>"},{"location":"code_docs/callback/base/operation_base/","title":"Operation base","text":""},{"location":"code_docs/callback/base/operation_base/#labridge.callback.base.operation_base","title":"<code>labridge.callback.base.operation_base</code>","text":""},{"location":"code_docs/callback/base/operation_base/#labridge.callback.base.operation_base.CallBackOperationBase","title":"<code>labridge.callback.base.operation_base.CallBackOperationBase</code>","text":"<p>               Bases: <code>object</code></p> <p>This is base class for callback operation. Here, callback operations indicate those operations requiring the user's permission.</p> PARAMETER DESCRIPTION <code>llm</code> <p>The used LLM.</p> <p> TYPE: <code>LLM</code> </p> <code>embed_model</code> <p>The used embedding model.</p> <p> TYPE: <code>BaseEmbedding</code> </p> <code>verbose</code> <p>Whether to show the inner progress.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> Source code in <code>labridge\\callback\\base\\operation_base.py</code> <pre><code>class CallBackOperationBase(object):\n\tr\"\"\"\n\tThis is base class for callback operation.\n\tHere, callback operations indicate those operations requiring the user's permission.\n\n\tArgs:\n\t\tllm (LLM): The used LLM.\n\t\tembed_model (BaseEmbedding): The used embedding model.\n\t\tverbose (bool): Whether to show the inner progress.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tllm: LLM,\n\t\tembed_model: BaseEmbedding,\n\t\top_name: str,\n\t\tverbose: bool = False,\n\t):\n\t\tself.op_name = op_name\n\t\tself._llm = llm\n\t\tself._embed_model = embed_model\n\t\tself._verbose = verbose\n\n\n\t@abstractmethod\n\tdef operation_description(self, **kwargs) -&gt; str:\n\t\tr\"\"\" This method return the description of the operation, which is presented to the users. \"\"\"\n\n\t@abstractmethod\n\tdef do_operation(self, **kwargs) -&gt; OperationOutputLog:\n\t\tr\"\"\" This method will execute the operation when authorized. And return the operation log \"\"\"\n\n\t@abstractmethod\n\tasync def ado_operation(self, **kwargs) -&gt; OperationOutputLog:\n\t\tr\"\"\" This method will asynchronously execute the operation when authorized. And return the operation log \"\"\"\n</code></pre>"},{"location":"code_docs/callback/base/operation_base/#labridge.callback.base.operation_base.CallBackOperationBase.ado_operation","title":"<code>labridge.callback.base.operation_base.CallBackOperationBase.ado_operation(**kwargs)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>This method will asynchronously execute the operation when authorized. And return the operation log</p> Source code in <code>labridge\\callback\\base\\operation_base.py</code> <pre><code>@abstractmethod\nasync def ado_operation(self, **kwargs) -&gt; OperationOutputLog:\n\tr\"\"\" This method will asynchronously execute the operation when authorized. And return the operation log \"\"\"\n</code></pre>"},{"location":"code_docs/callback/base/operation_base/#labridge.callback.base.operation_base.CallBackOperationBase.do_operation","title":"<code>labridge.callback.base.operation_base.CallBackOperationBase.do_operation(**kwargs)</code>  <code>abstractmethod</code>","text":"<p>This method will execute the operation when authorized. And return the operation log</p> Source code in <code>labridge\\callback\\base\\operation_base.py</code> <pre><code>@abstractmethod\ndef do_operation(self, **kwargs) -&gt; OperationOutputLog:\n\tr\"\"\" This method will execute the operation when authorized. And return the operation log \"\"\"\n</code></pre>"},{"location":"code_docs/callback/base/operation_base/#labridge.callback.base.operation_base.CallBackOperationBase.operation_description","title":"<code>labridge.callback.base.operation_base.CallBackOperationBase.operation_description(**kwargs)</code>  <code>abstractmethod</code>","text":"<p>This method return the description of the operation, which is presented to the users.</p> Source code in <code>labridge\\callback\\base\\operation_base.py</code> <pre><code>@abstractmethod\ndef operation_description(self, **kwargs) -&gt; str:\n\tr\"\"\" This method return the description of the operation, which is presented to the users. \"\"\"\n</code></pre>"},{"location":"code_docs/callback/base/operation_log/","title":"Operation log","text":""},{"location":"code_docs/callback/base/operation_log/#labridge.callback.base.operation_log","title":"<code>labridge.callback.base.operation_log</code>","text":""},{"location":"code_docs/callback/base/operation_log/#labridge.callback.base.operation_log.OperationOutputLog","title":"<code>labridge.callback.base.operation_log.OperationOutputLog</code>","text":"<p>               Bases: <code>object</code></p> <p>This class record the log of a specific callback operation. The <code>operation_output</code> will be a part of the corresponding tool output. The <code>log_to_user</code> and <code>references</code> in <code>log_to_system</code> will be presented to the users.</p> PARAMETER DESCRIPTION <code>operation_name</code> <p>The operation name.</p> <p> TYPE: <code>str</code> </p> <code>operation_output</code> <p>The operation output.</p> <p> TYPE: <code>str</code> </p> <code>log_to_user</code> <p>This log might be presented to the users.</p> <p> TYPE: <code>str</code> </p> <code>log_to_system</code> <p>This log is more structured, specifically, it is a dictionary in JSON format. The keys 'operation_description' and 'references' are required. The values of <code>references</code> are either None or List[str], where the <code>str</code> is in JSON format, for example, the dumped string of a <code>PaperInfo</code>.</p> <p> TYPE: <code>dict</code> </p> Source code in <code>labridge\\callback\\base\\operation_log.py</code> <pre><code>class OperationOutputLog(object):\n\tr\"\"\"\n\tThis class record the log of a specific callback operation.\n\tThe `operation_output` will be a part of the corresponding tool output.\n\tThe `log_to_user` and `references` in `log_to_system` will be presented to the users.\n\n\tArgs:\n\t\toperation_name (str): The operation name.\n\t\toperation_output (str): The operation output.\n\t\tlog_to_user (str): This log might be presented to the users.\n\t\tlog_to_system (dict): This log is more structured, specifically, it is a dictionary in JSON format.\n\t\t\tThe keys 'operation_description' and 'references' are required. The values of `references` are either\n\t\t\tNone or List[str], where the `str` is in JSON format, for example, the dumped string of a `PaperInfo`.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\toperation_name: str,\n\t\toperation_output: Optional[str],\n\t\tlog_to_user: Optional[str],\n\t\tlog_to_system: Dict[str, Union[str, Optional[List[str]]]],\n\t\toperation_abort: Optional[bool] = False,\n\n\t):\n\t\tself.operation_name = operation_name\n\t\tself.operation_output = operation_output\n\t\tself.log_to_user = log_to_user\n\t\tself.operation_abort = operation_abort\n\n\t\tfor key in LOG_TO_SYSTEM_KEYS:\n\t\t\tif key not in log_to_system.keys():\n\t\t\t\traise ValueError(f\"The key {key} is required in the log_to_system.\")\n\n\t\tref = log_to_system[OP_REFERENCES]\n\t\tif ref and not isinstance(ref, list):\n\t\t\traise ValueError(f\"The value of '{OP_REFERENCES}' can only be list or None.\")\n\t\tself.log_to_system = log_to_system\n\n\t@classmethod\n\tdef construct(\n\t\tcls,\n\t\toperation_name: str,\n\t\toperation_output: str,\n\t\top_description: str,\n\t\top_references: Optional[List[str]] = None,\n\t\tlog_to_user: Optional[str] = None,\n\t\toperation_abort: Optional[bool] = False,\n\t):\n\t\treturn cls(\n\t\t\toperation_name=operation_name,\n\t\t\toperation_output=operation_output,\n\t\t\tlog_to_user=log_to_user,\n\t\t\tlog_to_system={\n\t\t\t\tOP_DESCRIPTION: op_description,\n\t\t\t\tOP_REFERENCES: op_references,\n\t\t\t},\n\t\t\toperation_abort = operation_abort,\n\t\t)\n\n\tdef dumps(self) -&gt; str:\n\t\tr\"\"\" Dump to JSON string. \"\"\"\n\t\toutput_logs = {\n\t\t\t\"operation_name\": self.operation_name,\n\t\t\t\"operation_output\": self.operation_output,\n\t\t\t\"log_to_user\": self.log_to_user,\n\t\t\t\"log_to_system\": self.log_to_system,\n\t\t\t\"operation_abort\": self.operation_abort\n\t\t}\n\t\treturn json.dumps(output_logs)\n\n\t@classmethod\n\tdef loads(\n\t\tcls,\n\t\tlog_str: str,\n\t):\n\t\tr\"\"\" Load from JSON string. \"\"\"\n\t\ttry:\n\t\t\toutput_logs = json.loads(log_str)\n\t\t\toperation_name = output_logs[\"operation_name\"]\n\t\t\toperation_output = output_logs[\"operation_output\"]\n\t\t\tlog_to_user = output_logs[\"log_to_user\"]\n\t\t\tlog_to_system = output_logs[\"log_to_system\"]\n\t\t\toperation_abort = output_logs[\"operation_abort\"]\n\t\t\treturn cls(\n\t\t\t\toperation_name=operation_name,\n\t\t\t\toperation_output=operation_output,\n\t\t\t\tlog_to_user=log_to_user,\n\t\t\t\tlog_to_system=log_to_system,\n\t\t\t\toperation_abort=operation_abort,\n\t\t\t)\n\t\texcept Exception:\n\t\t\traise ValueError(\"Invalid operation log string.\")\n</code></pre>"},{"location":"code_docs/callback/base/operation_log/#labridge.callback.base.operation_log.OperationOutputLog.dumps","title":"<code>labridge.callback.base.operation_log.OperationOutputLog.dumps()</code>","text":"<p>Dump to JSON string.</p> Source code in <code>labridge\\callback\\base\\operation_log.py</code> <pre><code>def dumps(self) -&gt; str:\n\tr\"\"\" Dump to JSON string. \"\"\"\n\toutput_logs = {\n\t\t\"operation_name\": self.operation_name,\n\t\t\"operation_output\": self.operation_output,\n\t\t\"log_to_user\": self.log_to_user,\n\t\t\"log_to_system\": self.log_to_system,\n\t\t\"operation_abort\": self.operation_abort\n\t}\n\treturn json.dumps(output_logs)\n</code></pre>"},{"location":"code_docs/callback/base/operation_log/#labridge.callback.base.operation_log.OperationOutputLog.loads","title":"<code>labridge.callback.base.operation_log.OperationOutputLog.loads(log_str)</code>  <code>classmethod</code>","text":"<p>Load from JSON string.</p> Source code in <code>labridge\\callback\\base\\operation_log.py</code> <pre><code>@classmethod\ndef loads(\n\tcls,\n\tlog_str: str,\n):\n\tr\"\"\" Load from JSON string. \"\"\"\n\ttry:\n\t\toutput_logs = json.loads(log_str)\n\t\toperation_name = output_logs[\"operation_name\"]\n\t\toperation_output = output_logs[\"operation_output\"]\n\t\tlog_to_user = output_logs[\"log_to_user\"]\n\t\tlog_to_system = output_logs[\"log_to_system\"]\n\t\toperation_abort = output_logs[\"operation_abort\"]\n\t\treturn cls(\n\t\t\toperation_name=operation_name,\n\t\t\toperation_output=operation_output,\n\t\t\tlog_to_user=log_to_user,\n\t\t\tlog_to_system=log_to_system,\n\t\t\toperation_abort=operation_abort,\n\t\t)\n\texcept Exception:\n\t\traise ValueError(\"Invalid operation log string.\")\n</code></pre>"},{"location":"code_docs/callback/experiment_log/new_experiment/","title":"New experiment","text":""},{"location":"code_docs/callback/experiment_log/new_experiment/#labridge.callback.experiment_log.new_experiment","title":"<code>labridge.callback.experiment_log.new_experiment</code>","text":""},{"location":"code_docs/callback/experiment_log/new_experiment/#labridge.callback.experiment_log.new_experiment.CreateNewExperimentLogOperation","title":"<code>labridge.callback.experiment_log.new_experiment.CreateNewExperimentLogOperation</code>","text":"<p>               Bases: <code>CallBackOperationBase</code></p> <p>This operation will create a new experiment record for a specific user.</p> PARAMETER DESCRIPTION <code>llm</code> <p>The used LLM.</p> <p> TYPE: <code>LLM</code> DEFAULT: <code>None</code> </p> <code>embed_model</code> <p>The used embedding model.</p> <p> TYPE: <code>BaseEmbedding</code> DEFAULT: <code>None</code> </p> <code>verbose</code> <p>Whether to show the inner progress.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> Source code in <code>labridge\\callback\\experiment_log\\new_experiment.py</code> <pre><code>class CreateNewExperimentLogOperation(CallBackOperationBase):\n\tr\"\"\"\n\tThis operation will create a new experiment record for a specific user.\n\n\tArgs:\n\t\tllm (LLM): The used LLM.\n\t\tembed_model (BaseEmbedding): The used embedding model.\n\t\tverbose (bool): Whether to show the inner progress.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tllm: LLM = None,\n\t\tembed_model: BaseEmbedding = None,\n\t\tverbose: bool = False,\n\t\top_name: str = None,\n\t):\n\t\tembed_model = embed_model or Settings.embed_model\n\t\tllm = llm or Settings.llm\n\t\tsuper().__init__(\n\t\t\tllm=llm,\n\t\t\tembed_model=embed_model,\n\t\t\tverbose=verbose,\n\t\t\top_name=op_name or CreateNewExperimentLogOperation.__name__,\n\t\t)\n\n\tdef operation_description(self, **kwargs) -&gt; str:\n\t\tr\"\"\"\n\t\tReturn the operation description, this description will be sent to the user for authorization.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user id of a lab member.\n\t\t\texperiment_name (str): The name of the new experiment.\n\t\t\texperiment_description (str): The description of the new experiment.\n\n\t\tReturns:\n\t\t\tstr: The operation description.\n\t\t\"\"\"\n\t\tuser_id = kwargs[\"user_id\"]\n\t\texpr_name = kwargs[NEW_EXPERIMENT_NAME_KEY]\n\t\texpr_description = kwargs[NEW_EXPERIMENT_DESCRIPTION_KEY]\n\n\t\top_description = CREATE_NEW_EXPERIMENT_DESCRIPTION.format(\n\t\t\tuser_id=user_id,\n\t\t\texperiment_name=expr_name,\n\t\t\texperiment_description=expr_description,\n\t\t)\n\t\treturn op_description\n\n\tdef do_operation(self, **kwargs) -&gt; OperationOutputLog:\n\t\tr\"\"\"\n\t\tExecute the operation to add a new experiment record.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user id of a lab member.\n\t\t\texperiment_name (str): The name of the new experiment.\n\t\t\texperiment_description (str): The description of the new experiment.\n\n\t\tReturns:\n\t\t\tOperationOutputLog: The output and log of the operation.\n\t\t\"\"\"\n\t\tuser_id = kwargs[\"user_id\"]\n\t\texpr_name = kwargs[NEW_EXPERIMENT_NAME_KEY]\n\t\texpr_description = kwargs[NEW_EXPERIMENT_DESCRIPTION_KEY]\n\t\texpr_log_store = ExperimentLog.from_user_id(\n\t\t\tuser_id=user_id,\n\t\t\tembed_model=self._embed_model,\n\t\t)\n\n\t\texpr_log_store.create_experiment(\n\t\t\texperiment_name=expr_name,\n\t\t\tdescription=expr_description,\n\t\t)\n\t\texpr_log_store.persist()\n\n\t\top_log_str = (\n\t\t\tf\"Have created a new experiment log record for the user {user_id}.\\n\"\n\t\t\tf\"Experiment name: {expr_name}\"\n\t\t)\n\t\treturn OperationOutputLog(\n\t\t\toperation_name=self.op_name,\n\t\t\toperation_output=None,\n\t\t\tlog_to_user=None,\n\t\t\tlog_to_system={\n\t\t\t\tOP_DESCRIPTION: op_log_str,\n\t\t\t\tOP_REFERENCES: None,\n\t\t\t}\n\t\t)\n\n\tasync def ado_operation(self, **kwargs) -&gt; OperationOutputLog:\n\t\treturn self.do_operation(**kwargs)\n</code></pre>"},{"location":"code_docs/callback/experiment_log/new_experiment/#labridge.callback.experiment_log.new_experiment.CreateNewExperimentLogOperation.do_operation","title":"<code>labridge.callback.experiment_log.new_experiment.CreateNewExperimentLogOperation.do_operation(**kwargs)</code>","text":"<p>Execute the operation to add a new experiment record.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user id of a lab member.</p> <p> TYPE: <code>str</code> </p> <code>experiment_name</code> <p>The name of the new experiment.</p> <p> TYPE: <code>str</code> </p> <code>experiment_description</code> <p>The description of the new experiment.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>OperationOutputLog</code> <p>The output and log of the operation.</p> <p> TYPE: <code>OperationOutputLog</code> </p> Source code in <code>labridge\\callback\\experiment_log\\new_experiment.py</code> <pre><code>def do_operation(self, **kwargs) -&gt; OperationOutputLog:\n\tr\"\"\"\n\tExecute the operation to add a new experiment record.\n\n\tArgs:\n\t\tuser_id (str): The user id of a lab member.\n\t\texperiment_name (str): The name of the new experiment.\n\t\texperiment_description (str): The description of the new experiment.\n\n\tReturns:\n\t\tOperationOutputLog: The output and log of the operation.\n\t\"\"\"\n\tuser_id = kwargs[\"user_id\"]\n\texpr_name = kwargs[NEW_EXPERIMENT_NAME_KEY]\n\texpr_description = kwargs[NEW_EXPERIMENT_DESCRIPTION_KEY]\n\texpr_log_store = ExperimentLog.from_user_id(\n\t\tuser_id=user_id,\n\t\tembed_model=self._embed_model,\n\t)\n\n\texpr_log_store.create_experiment(\n\t\texperiment_name=expr_name,\n\t\tdescription=expr_description,\n\t)\n\texpr_log_store.persist()\n\n\top_log_str = (\n\t\tf\"Have created a new experiment log record for the user {user_id}.\\n\"\n\t\tf\"Experiment name: {expr_name}\"\n\t)\n\treturn OperationOutputLog(\n\t\toperation_name=self.op_name,\n\t\toperation_output=None,\n\t\tlog_to_user=None,\n\t\tlog_to_system={\n\t\t\tOP_DESCRIPTION: op_log_str,\n\t\t\tOP_REFERENCES: None,\n\t\t}\n\t)\n</code></pre>"},{"location":"code_docs/callback/experiment_log/new_experiment/#labridge.callback.experiment_log.new_experiment.CreateNewExperimentLogOperation.operation_description","title":"<code>labridge.callback.experiment_log.new_experiment.CreateNewExperimentLogOperation.operation_description(**kwargs)</code>","text":"<p>Return the operation description, this description will be sent to the user for authorization.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user id of a lab member.</p> <p> TYPE: <code>str</code> </p> <code>experiment_name</code> <p>The name of the new experiment.</p> <p> TYPE: <code>str</code> </p> <code>experiment_description</code> <p>The description of the new experiment.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>str</code> <p>The operation description.</p> <p> TYPE: <code>str</code> </p> Source code in <code>labridge\\callback\\experiment_log\\new_experiment.py</code> <pre><code>def operation_description(self, **kwargs) -&gt; str:\n\tr\"\"\"\n\tReturn the operation description, this description will be sent to the user for authorization.\n\n\tArgs:\n\t\tuser_id (str): The user id of a lab member.\n\t\texperiment_name (str): The name of the new experiment.\n\t\texperiment_description (str): The description of the new experiment.\n\n\tReturns:\n\t\tstr: The operation description.\n\t\"\"\"\n\tuser_id = kwargs[\"user_id\"]\n\texpr_name = kwargs[NEW_EXPERIMENT_NAME_KEY]\n\texpr_description = kwargs[NEW_EXPERIMENT_DESCRIPTION_KEY]\n\n\top_description = CREATE_NEW_EXPERIMENT_DESCRIPTION.format(\n\t\tuser_id=user_id,\n\t\texperiment_name=expr_name,\n\t\texperiment_description=expr_description,\n\t)\n\treturn op_description\n</code></pre>"},{"location":"code_docs/callback/experiment_log/set_current_experiment/","title":"Set current experiment","text":""},{"location":"code_docs/callback/experiment_log/set_current_experiment/#labridge.callback.experiment_log.set_current_experiment","title":"<code>labridge.callback.experiment_log.set_current_experiment</code>","text":""},{"location":"code_docs/callback/experiment_log/set_current_experiment/#labridge.callback.experiment_log.set_current_experiment.SetCurrentExperimentOperation","title":"<code>labridge.callback.experiment_log.set_current_experiment.SetCurrentExperimentOperation</code>","text":"<p>               Bases: <code>CallBackOperationBase</code></p> <p>This operation will set a recorded experiment as the user's experiment in progress.</p> PARAMETER DESCRIPTION <code>llm</code> <p>The used LLM.</p> <p> TYPE: <code>LLM</code> DEFAULT: <code>None</code> </p> <code>embed_model</code> <p>The used embedding model.</p> <p> TYPE: <code>BaseEmbedding</code> DEFAULT: <code>None</code> </p> <code>verbose</code> <p>Whether to show the inner progress.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> Source code in <code>labridge\\callback\\experiment_log\\set_current_experiment.py</code> <pre><code>class SetCurrentExperimentOperation(CallBackOperationBase):\n\tr\"\"\"\n\tThis operation will set a recorded experiment as the user's experiment in progress.\n\n\tArgs:\n\t\tllm (LLM): The used LLM.\n\t\tembed_model (BaseEmbedding): The used embedding model.\n\t\tverbose (bool): Whether to show the inner progress.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tllm: LLM = None,\n\t\tembed_model: BaseEmbedding = None,\n\t\tverbose: bool = False,\n\t\top_name: str = None,\n\t):\n\n\t\tllm = llm or Settings.llm\n\t\tembed_model = embed_model or Settings.embed_model\n\t\tsuper().__init__(\n\t\t\tllm=llm,\n\t\t\tembed_model=embed_model,\n\t\t\tverbose=verbose,\n\t\t\top_name=op_name or SetCurrentExperimentOperation.__name__,\n\t\t)\n\n\tdef operation_description(self, **kwargs) -&gt; str:\n\t\tr\"\"\"\n\t\tReturn the operation description, this description will be sent to the user for authorization.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user id of a lab member.\n\t\t\texperiment_name (str): The name of a recorded experiment.\n\t\t\texperiment_duration (str): The duration of the experiment, in a format of \"%Hh%Mm%Ss\",\n\t\t\t\trefer to `common.utils.time`.\n\n\t\tReturns:\n\t\t\tstr: The operation description.\n\t\t\"\"\"\n\t\tuser_id = kwargs[\"user_id\"]\n\t\texperiment_name = kwargs[\"experiment_name\"]\n\t\texperiment_duration = kwargs[\"experiment_duration\"]\n\n\t\tstart_date, start_time = get_time()\n\t\tstart = str_to_datetime(date_str=start_date, time_str=start_time)\n\t\tdelta_time = str_to_delta_time(time_str=experiment_duration)\n\t\tend = start + delta_time\n\t\tend_date, end_time = datetime_to_str(date_time=end)\n\t\top_description = SET_CURRENT_EXPERIMENT_DESCRIPTION.format(\n\t\t\tuser_id=user_id,\n\t\t\texperiment_name=experiment_name,\n\t\t\tstart_date=start_date,\n\t\t\tstart_time=start_time,\n\t\t\tend_date=end_date,\n\t\t\tend_time=end_time,\n\t\t)\n\t\treturn op_description\n\n\tdef do_operation(self, **kwargs) -&gt; OperationOutputLog:\n\t\tr\"\"\"\n\t\tExecute the operation set the experiment in progress for a user.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user id of a lab member.\n\t\t\texperiment_name (str): The name of a recorded experiment.\n\t\t\texperiment_duration (str): The duration of the experiment, in a format of \"%Hh%Mm%Ss\",\n\t\t\t\trefer to `common.utils.time`.\n\n\t\tReturns:\n\t\t\tOperationOutputLog: The output and log of the operation.\n\t\t\"\"\"\n\t\tuser_id = kwargs[\"user_id\"]\n\t\texperiment_name = kwargs[\"experiment_name\"]\n\t\texperiment_duration = kwargs[\"experiment_duration\"]\n\n\t\tstart_date, start_time = get_time()\n\t\tstart = str_to_datetime(date_str=start_date, time_str=start_time)\n\t\tdelta_time = str_to_delta_time(time_str=experiment_duration)\n\t\tend = start + delta_time\n\t\tend_date, end_time = datetime_to_str(date_time=end)\n\n\t\texpr_log_store = ExperimentLog.from_user_id(\n\t\t\tuser_id=user_id,\n\t\t\tembed_model=self._embed_model\n\t\t)\n\t\texpr_log_store.set_recent_experiment(\n\t\t\texperiment_name=experiment_name,\n\t\t\tstart_date=start_date,\n\t\t\tstart_time=start_time,\n\t\t\tend_date=end_date,\n\t\t\tend_time=end_time,\n\t\t)\n\t\texpr_log_store.persist()\n\t\top_log_str = (\n\t\t\tf\"Set the experiment in progress for {user_id}.\\n\"\n\t\t\tf\"Experiment name: {experiment_name}.\\n\"\n\t\t\tf\"Start from {start_date}, {start_time} to {end_date}, {end_time}.\"\n\t\t)\n\t\treturn OperationOutputLog(\n\t\t\toperation_name=self.op_name,\n\t\t\toperation_output=None,\n\t\t\tlog_to_user=None,\n\t\t\tlog_to_system={\n\t\t\t\tOP_DESCRIPTION: op_log_str,\n\t\t\t\tOP_REFERENCES: None,\n\t\t\t}\n\t\t)\n\n\tasync def ado_operation(self, **kwargs) -&gt; OperationOutputLog:\n\t\treturn self.do_operation(**kwargs)\n</code></pre>"},{"location":"code_docs/callback/experiment_log/set_current_experiment/#labridge.callback.experiment_log.set_current_experiment.SetCurrentExperimentOperation.do_operation","title":"<code>labridge.callback.experiment_log.set_current_experiment.SetCurrentExperimentOperation.do_operation(**kwargs)</code>","text":"<p>Execute the operation set the experiment in progress for a user.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user id of a lab member.</p> <p> TYPE: <code>str</code> </p> <code>experiment_name</code> <p>The name of a recorded experiment.</p> <p> TYPE: <code>str</code> </p> <code>experiment_duration</code> <p>The duration of the experiment, in a format of \"%Hh%Mm%Ss\", refer to <code>common.utils.time</code>.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>OperationOutputLog</code> <p>The output and log of the operation.</p> <p> TYPE: <code>OperationOutputLog</code> </p> Source code in <code>labridge\\callback\\experiment_log\\set_current_experiment.py</code> <pre><code>def do_operation(self, **kwargs) -&gt; OperationOutputLog:\n\tr\"\"\"\n\tExecute the operation set the experiment in progress for a user.\n\n\tArgs:\n\t\tuser_id (str): The user id of a lab member.\n\t\texperiment_name (str): The name of a recorded experiment.\n\t\texperiment_duration (str): The duration of the experiment, in a format of \"%Hh%Mm%Ss\",\n\t\t\trefer to `common.utils.time`.\n\n\tReturns:\n\t\tOperationOutputLog: The output and log of the operation.\n\t\"\"\"\n\tuser_id = kwargs[\"user_id\"]\n\texperiment_name = kwargs[\"experiment_name\"]\n\texperiment_duration = kwargs[\"experiment_duration\"]\n\n\tstart_date, start_time = get_time()\n\tstart = str_to_datetime(date_str=start_date, time_str=start_time)\n\tdelta_time = str_to_delta_time(time_str=experiment_duration)\n\tend = start + delta_time\n\tend_date, end_time = datetime_to_str(date_time=end)\n\n\texpr_log_store = ExperimentLog.from_user_id(\n\t\tuser_id=user_id,\n\t\tembed_model=self._embed_model\n\t)\n\texpr_log_store.set_recent_experiment(\n\t\texperiment_name=experiment_name,\n\t\tstart_date=start_date,\n\t\tstart_time=start_time,\n\t\tend_date=end_date,\n\t\tend_time=end_time,\n\t)\n\texpr_log_store.persist()\n\top_log_str = (\n\t\tf\"Set the experiment in progress for {user_id}.\\n\"\n\t\tf\"Experiment name: {experiment_name}.\\n\"\n\t\tf\"Start from {start_date}, {start_time} to {end_date}, {end_time}.\"\n\t)\n\treturn OperationOutputLog(\n\t\toperation_name=self.op_name,\n\t\toperation_output=None,\n\t\tlog_to_user=None,\n\t\tlog_to_system={\n\t\t\tOP_DESCRIPTION: op_log_str,\n\t\t\tOP_REFERENCES: None,\n\t\t}\n\t)\n</code></pre>"},{"location":"code_docs/callback/experiment_log/set_current_experiment/#labridge.callback.experiment_log.set_current_experiment.SetCurrentExperimentOperation.operation_description","title":"<code>labridge.callback.experiment_log.set_current_experiment.SetCurrentExperimentOperation.operation_description(**kwargs)</code>","text":"<p>Return the operation description, this description will be sent to the user for authorization.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user id of a lab member.</p> <p> TYPE: <code>str</code> </p> <code>experiment_name</code> <p>The name of a recorded experiment.</p> <p> TYPE: <code>str</code> </p> <code>experiment_duration</code> <p>The duration of the experiment, in a format of \"%Hh%Mm%Ss\", refer to <code>common.utils.time</code>.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>str</code> <p>The operation description.</p> <p> TYPE: <code>str</code> </p> Source code in <code>labridge\\callback\\experiment_log\\set_current_experiment.py</code> <pre><code>def operation_description(self, **kwargs) -&gt; str:\n\tr\"\"\"\n\tReturn the operation description, this description will be sent to the user for authorization.\n\n\tArgs:\n\t\tuser_id (str): The user id of a lab member.\n\t\texperiment_name (str): The name of a recorded experiment.\n\t\texperiment_duration (str): The duration of the experiment, in a format of \"%Hh%Mm%Ss\",\n\t\t\trefer to `common.utils.time`.\n\n\tReturns:\n\t\tstr: The operation description.\n\t\"\"\"\n\tuser_id = kwargs[\"user_id\"]\n\texperiment_name = kwargs[\"experiment_name\"]\n\texperiment_duration = kwargs[\"experiment_duration\"]\n\n\tstart_date, start_time = get_time()\n\tstart = str_to_datetime(date_str=start_date, time_str=start_time)\n\tdelta_time = str_to_delta_time(time_str=experiment_duration)\n\tend = start + delta_time\n\tend_date, end_time = datetime_to_str(date_time=end)\n\top_description = SET_CURRENT_EXPERIMENT_DESCRIPTION.format(\n\t\tuser_id=user_id,\n\t\texperiment_name=experiment_name,\n\t\tstart_date=start_date,\n\t\tstart_time=start_time,\n\t\tend_date=end_date,\n\t\tend_time=end_time,\n\t)\n\treturn op_description\n</code></pre>"},{"location":"code_docs/callback/paper/add_recent_paper/","title":"Add recent paper","text":""},{"location":"code_docs/callback/paper/add_recent_paper/#labridge.callback.paper.add_paper","title":"<code>labridge.callback.paper.add_paper</code>","text":""},{"location":"code_docs/callback/paper/add_recent_paper/#labridge.callback.paper.add_paper.AddNewRecentPaperOperation","title":"<code>labridge.callback.paper.add_paper.AddNewRecentPaperOperation</code>","text":"<p>               Bases: <code>CallBackOperationBase</code></p> <p>This operation will add a new paper into a user's recent papers.</p> PARAMETER DESCRIPTION <code>llm</code> <p>The used LLM.</p> <p> TYPE: <code>LLM</code> DEFAULT: <code>None</code> </p> <code>embed_model</code> <p>The used embedding model.</p> <p> TYPE: <code>BaseEmbedding</code> DEFAULT: <code>None</code> </p> <code>verbose</code> <p>Whether to show the inner progress.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> Source code in <code>labridge\\callback\\paper\\add_paper.py</code> <pre><code>class AddNewRecentPaperOperation(CallBackOperationBase):\n\tr\"\"\"\n\tThis operation will add a new paper into a user's recent papers.\n\n\tArgs:\n\t\tllm (LLM): The used LLM.\n\t\tembed_model (BaseEmbedding): The used embedding model.\n\t\tverbose (bool): Whether to show the inner progress.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tllm: LLM = None,\n\t\tembed_model: BaseEmbedding = None,\n\t\tverbose: bool = False,\n\t\top_name: str = None,\n\t):\n\t\tembed_model = embed_model or Settings.embed_model\n\t\tllm = llm or Settings.llm\n\t\tsuper().__init__(\n\t\t\tembed_model=embed_model,\n\t\t\tllm=llm,\n\t\t\tverbose=verbose,\n\t\t\top_name=op_name or AddNewRecentPaperOperation.__name__,\n\t\t)\n\n\tdef operation_description(self, **kwargs) -&gt; str:\n\t\tr\"\"\"\n\t\tReturn the operation description, this description will be sent to the user for authorization.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user id of a lab member.\n\t\t\tpaper_file_path (str): The file path of the new paper.\n\n\t\tReturns:\n\t\t\tstr: The operation description.\n\t\t\"\"\"\n\t\tuser_id = kwargs.get(\"user_id\", None)\n\t\tpaper_file_path = kwargs.get(\"paper_file_path\", None)\n\n\t\tif None in [user_id, paper_file_path]:\n\t\t\traise ValueError(f\"Should provide these arguments: user_id, paper_file_path.\")\n\t\treturn ADD_NEW_RECENT_PAPER_TMPL.format(\n\t\t\tuser_id=user_id,\n\t\t\tpaper_file_path=paper_file_path,\n\t\t)\n\n\tdef do_operation(\n\t\tself,\n\t\t**kwargs\n\t) -&gt; OperationOutputLog:\n\t\tr\"\"\"\n\t\tExecute the operation after authorized to add a new paper to a user's recent papers.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user id of a lab member.\n\t\t\tpaper_file_path (str): The file path of the new paper.\n\n\t\tReturns:\n\t\t\tOperationOutputLog: The output and log of the operation.\n\t\t\"\"\"\n\t\tuser_id = kwargs.get(\"user_id\", None)\n\t\tpaper_file_path = kwargs.get(\"paper_file_path\", None)\n\n\t\tif None in [user_id, paper_file_path]:\n\t\t\traise ValueError(f\"Should provide these arguments: user_id, paper_file_path.\")\n\n\t\tpaper_store = RecentPaperStore.from_user_id(\n\t\t\tuser_id=user_id,\n\t\t\tembed_model=self._embed_model,\n\t\t)\n\t\ttry:\n\t\t\tpaper_store.put(paper_file_path=paper_file_path)\n\t\t\tpaper_store.persist()\n\t\t\top_log = (\n\t\t\t\tf\"Have put a new paper to the recent papers of the user {user_id}\\n\"\n\t\t\t\tf\"Paper file path: {paper_file_path}\"\n\t\t\t)\n\t\t\tpaper_info = PaperInfo(\n\t\t\t\tfile_path=paper_file_path,\n\t\t\t\tpossessor=user_id,\n\t\t\t\ttitle=paper_file_path,\n\t\t\t)\n\t\t\treturn OperationOutputLog(\n\t\t\t\toperation_name=self.op_name,\n\t\t\t\toperation_output=None,\n\t\t\t\tlog_to_user=None,\n\t\t\t\tlog_to_system={\n\t\t\t\t\tOP_DESCRIPTION: op_log,\n\t\t\t\t\tOP_REFERENCES: [paper_info.dumps()]\n\t\t\t\t}\n\t\t\t)\n\n\t\texcept Exception as e:\n\t\t\top_log = f\"Error: {e}\"\n\t\t\treturn OperationOutputLog(\n\t\t\t\toperation_name=self.op_name,\n\t\t\t\toperation_output=None,\n\t\t\t\tlog_to_user=None,\n\t\t\t\tlog_to_system={\n\t\t\t\t\tOP_DESCRIPTION: op_log,\n\t\t\t\t\tOP_REFERENCES: None\n\t\t\t\t}\n\t\t)\n\n\tasync def ado_operation(\n\t\tself,\n\t\t**kwargs\n\t) -&gt; OperationOutputLog:\n\t\treturn self.do_operation(**kwargs)\n</code></pre>"},{"location":"code_docs/callback/paper/add_recent_paper/#labridge.callback.paper.add_paper.AddNewRecentPaperOperation.do_operation","title":"<code>labridge.callback.paper.add_paper.AddNewRecentPaperOperation.do_operation(**kwargs)</code>","text":"<p>Execute the operation after authorized to add a new paper to a user's recent papers.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user id of a lab member.</p> <p> TYPE: <code>str</code> </p> <code>paper_file_path</code> <p>The file path of the new paper.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>OperationOutputLog</code> <p>The output and log of the operation.</p> <p> TYPE: <code>OperationOutputLog</code> </p> Source code in <code>labridge\\callback\\paper\\add_paper.py</code> <pre><code>def do_operation(\n\tself,\n\t**kwargs\n) -&gt; OperationOutputLog:\n\tr\"\"\"\n\tExecute the operation after authorized to add a new paper to a user's recent papers.\n\n\tArgs:\n\t\tuser_id (str): The user id of a lab member.\n\t\tpaper_file_path (str): The file path of the new paper.\n\n\tReturns:\n\t\tOperationOutputLog: The output and log of the operation.\n\t\"\"\"\n\tuser_id = kwargs.get(\"user_id\", None)\n\tpaper_file_path = kwargs.get(\"paper_file_path\", None)\n\n\tif None in [user_id, paper_file_path]:\n\t\traise ValueError(f\"Should provide these arguments: user_id, paper_file_path.\")\n\n\tpaper_store = RecentPaperStore.from_user_id(\n\t\tuser_id=user_id,\n\t\tembed_model=self._embed_model,\n\t)\n\ttry:\n\t\tpaper_store.put(paper_file_path=paper_file_path)\n\t\tpaper_store.persist()\n\t\top_log = (\n\t\t\tf\"Have put a new paper to the recent papers of the user {user_id}\\n\"\n\t\t\tf\"Paper file path: {paper_file_path}\"\n\t\t)\n\t\tpaper_info = PaperInfo(\n\t\t\tfile_path=paper_file_path,\n\t\t\tpossessor=user_id,\n\t\t\ttitle=paper_file_path,\n\t\t)\n\t\treturn OperationOutputLog(\n\t\t\toperation_name=self.op_name,\n\t\t\toperation_output=None,\n\t\t\tlog_to_user=None,\n\t\t\tlog_to_system={\n\t\t\t\tOP_DESCRIPTION: op_log,\n\t\t\t\tOP_REFERENCES: [paper_info.dumps()]\n\t\t\t}\n\t\t)\n\n\texcept Exception as e:\n\t\top_log = f\"Error: {e}\"\n\t\treturn OperationOutputLog(\n\t\t\toperation_name=self.op_name,\n\t\t\toperation_output=None,\n\t\t\tlog_to_user=None,\n\t\t\tlog_to_system={\n\t\t\t\tOP_DESCRIPTION: op_log,\n\t\t\t\tOP_REFERENCES: None\n\t\t\t}\n\t)\n</code></pre>"},{"location":"code_docs/callback/paper/add_recent_paper/#labridge.callback.paper.add_paper.AddNewRecentPaperOperation.operation_description","title":"<code>labridge.callback.paper.add_paper.AddNewRecentPaperOperation.operation_description(**kwargs)</code>","text":"<p>Return the operation description, this description will be sent to the user for authorization.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user id of a lab member.</p> <p> TYPE: <code>str</code> </p> <code>paper_file_path</code> <p>The file path of the new paper.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>str</code> <p>The operation description.</p> <p> TYPE: <code>str</code> </p> Source code in <code>labridge\\callback\\paper\\add_paper.py</code> <pre><code>def operation_description(self, **kwargs) -&gt; str:\n\tr\"\"\"\n\tReturn the operation description, this description will be sent to the user for authorization.\n\n\tArgs:\n\t\tuser_id (str): The user id of a lab member.\n\t\tpaper_file_path (str): The file path of the new paper.\n\n\tReturns:\n\t\tstr: The operation description.\n\t\"\"\"\n\tuser_id = kwargs.get(\"user_id\", None)\n\tpaper_file_path = kwargs.get(\"paper_file_path\", None)\n\n\tif None in [user_id, paper_file_path]:\n\t\traise ValueError(f\"Should provide these arguments: user_id, paper_file_path.\")\n\treturn ADD_NEW_RECENT_PAPER_TMPL.format(\n\t\tuser_id=user_id,\n\t\tpaper_file_path=paper_file_path,\n\t)\n</code></pre>"},{"location":"code_docs/callback/paper/paper_download/","title":"Paper download","text":""},{"location":"code_docs/callback/paper/paper_download/#labridge.callback.paper.paper_download","title":"<code>labridge.callback.paper.paper_download</code>","text":""},{"location":"code_docs/callback/paper/paper_download/#labridge.callback.paper.paper_download.ArxivDownloadOperation","title":"<code>labridge.callback.paper.paper_download.ArxivDownloadOperation</code>","text":"<p>               Bases: <code>CallBackOperationBase</code></p> <p>This operation will download papers from aXiv for the user.</p> PARAMETER DESCRIPTION <code>llm</code> <p>The used LLM.</p> <p> TYPE: <code>LLM</code> DEFAULT: <code>None</code> </p> <code>embed_model</code> <p>The used embedding model.</p> <p> TYPE: <code>BaseEmbedding</code> DEFAULT: <code>None</code> </p> <code>verbose</code> <p>Whether to show the inner progress.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> Source code in <code>labridge\\callback\\paper\\paper_download.py</code> <pre><code>class ArxivDownloadOperation(CallBackOperationBase):\n\tr\"\"\"\n\tThis operation will download papers from aXiv for the user.\n\n\tArgs:\n\t\tllm (LLM): The used LLM.\n\t\tembed_model (BaseEmbedding): The used embedding model.\n\t\tverbose (bool): Whether to show the inner progress.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tllm: LLM = None,\n\t\tembed_model: BaseEmbedding = None,\n\t\tverbose: bool = False,\n\t\top_name: str = None,\n\t):\n\t\troot = Path(__file__)\n\n\t\tfor idx in range(4):\n\t\t\troot = root.parent\n\n\t\tself.root = root\n\t\tself._fs = fsspec.filesystem(\"file\")\n\t\tembed_model = embed_model or Settings.embed_model\n\t\tllm = llm or Settings.llm\n\t\tsuper().__init__(\n\t\t\tllm=llm,\n\t\t\tembed_model=embed_model,\n\t\t\tverbose=verbose,\n\t\t\top_name=op_name or ArxivDownloadOperation.__name__,\n\t\t)\n\n\tdef _get_default_path(self, user_id: str, title: str) -&gt; Tuple[str, str]:\n\t\tr\"\"\"\n\t\tThe downloaded paper will be stored in the user's recent paper warehouse.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user id of a lab member.\n\t\t\ttitle (str): The title of the paper, will be used as the filename.\n\n\t\tReturns:\n\t\t\tTuple[str, str]:\n\t\t\t\tThe paper file path and file name.\n\t\t\"\"\"\n\t\tfile_name = f\"{title}.pdf\"\n\t\tfile_dir = self.root / TMP_PAPER_WAREHOUSE_DIR\n\t\tfile_dir = file_dir / user_id\n\n\t\tif not self._fs.exists(file_dir):\n\t\t\tself._fs.makedirs(file_dir)\n\t\treturn str(file_dir), file_name\n\n\tdef operation_description(self, **kwargs) -&gt; str:\n\t\tr\"\"\"\n\t\tDescribe the operation.\n\n\t\tArgs:\n\t\t\tuser_id (str): the user id.\n\t\t\tpaper_infos (List[Dict[str, str]]): the metadata of papers,\n\t\t\t\tfor each paper, the `title` must be provided.\n\n\t\tReturns:\n\t\t\tthe operation description.\n\t\t\"\"\"\n\t\tuser_id = kwargs.get(\"user_id\", None)\n\t\tpaper_infos = kwargs.get(\"paper_infos\", None)\n\n\t\tif None in [user_id, paper_infos]:\n\t\t\traise ValueError(\"should provide valid user_id, paper_infos.\")\n\n\t\tpapers = []\n\t\tfor paper in paper_infos:\n\t\t\ttitle = paper.get(\"title\", None)\n\t\t\tfile_dir, file_name = self._get_default_path(user_id=user_id, title=title)\n\t\t\tsave_path = str(Path(file_dir) / file_name)\n\t\t\tpaper_dsc = PAPER_DESCRIPTION_TMPL.format(title=title, save_path=save_path)\n\t\t\tpapers.append(paper_dsc)\n\t\tpapers = \"\\n\\n\".join(papers)\n\t\theader = ARXIV_DOWNLOAD_DESCRIPTION.format(user_id=user_id)\n\t\tdescription = f\"{header}\\n{papers}\"\n\t\treturn description\n\n\tdef download_paper(self, user_id: str, title: str, pdf_url: str) -&gt; Optional[str]:\n\t\tr\"\"\"\n\t\tDownload a paper from arxiv and save to the user's recent paper directory.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user id of a lab member.\n\t\t\ttitle (str): The paper title.\n\t\t\tpdf_url (str): The paper URL.\n\n\t\tReturns:\n\t\t\tOptional[str]:\n\n\t\t\t\t- If the paper is successfully downloaded, return the file_path.\n\t\t\t\t- If the downloading fails, return None.\n\t\t\"\"\"\n\t\tif None in [user_id, title, pdf_url]:\n\t\t\traise ValueError(\"should provide valid user_id, title, pdf_url to download paper.\")\n\t\tfile_dir, file_name = self._get_default_path(user_id=user_id, title=title)\n\t\tresult = Result(entry_id=\"\")\n\t\tresult.pdf_url = pdf_url\n\n\t\tif self._verbose:\n\t\t\tprint_text(text=f\"Downloading paper '{title}' ...\", color=\"pink\", end=\"\\n\")\n\n\t\ttry:\n\t\t\tresult.download_pdf(dirpath=file_dir, filename=file_name)\n\t\t\tfile_path = str(Path(file_dir) / file_name)\n\t\t\treturn file_path\n\t\texcept Exception as e:\n\t\t\tprint(f\"Download failed. Error: {e}\")\n\t\t\treturn None\n\n\tasync def adownload_paper(self, user_id: str, title: str, pdf_url: str) -&gt; Optional[str]:\n\t\tr\"\"\"\n\t\tAsynchronously download a paper from arxiv and save to the user's recent paper directory.\n\t\t\"\"\"\n\t\tif None in [user_id, title, pdf_url]:\n\t\t\traise ValueError(\"should provide valid user_id, title, pdf_url to download paper.\")\n\n\t\tfile_dir, file_name = self._get_default_path(user_id=user_id, title=title)\n\t\tfile_path = str(Path(file_dir) / file_name)\n\n\t\tif self._verbose:\n\t\t\tprint_text(text=f\"Downloading paper '{title}' ...\", color=\"pink\", end=\"\\n\")\n\t\ttry:\n\t\t\tawait adownload_file(url=pdf_url, save_path=file_path)\n\t\t\treturn file_path\n\t\texcept Exception as e:\n\t\t\tprint(f\"Download failed. Error: {e}\")\n\t\t\treturn None\n\n\tdef _get_log(\n\t\tself,\n\t\tuser_id: str,\n\t\tsucceed_papers: List[Tuple[str, str]],\n\t\tfail_papers: List[str]\n\t) -&gt; OperationOutputLog:\n\t\tr\"\"\" Get the operation log. \"\"\"\n\t\tlogs = []\n\t\tif succeed_papers:\n\t\t\tlogs.append(f\"Successfully download these papers, and restore them in the recent papers of user {user_id}:\")\n\n\t\tref_paper_infos = []\n\n\t\tfor title, file_path in succeed_papers:\n\t\t\tdownload_log = {\n\t\t\t\t\"Title\": title,\n\t\t\t\t\"Save path\": file_path,\n\t\t\t}\n\t\t\tdownload_log_str = json.dumps(download_log)\n\t\t\tlogs.append(download_log_str)\n\t\t\tpaper_info = PaperInfo(\n\t\t\t\ttitle=title,\n\t\t\t\tfile_path=file_path,\n\t\t\t\tpossessor=user_id,\n\t\t\t)\n\t\t\tref_paper_infos.append(paper_info.dumps())\n\n\t\tif fail_papers:\n\t\t\tfailed_log = \"These paper downloading failed:\\n\"\n\t\t\tfailed_log += \"\\n\".join(fail_papers)\n\t\t\tlogs.append(failed_log)\n\t\tlog_str = \"\\n\\n\".join(logs)\n\t\treturn OperationOutputLog(\n\t\t\toperation_name=self.op_name,\n\t\t\toperation_output=None,\n\t\t\tlog_to_user=None,\n\t\t\tlog_to_system={\n\t\t\t\tOP_DESCRIPTION: log_str,\n\t\t\t\tOP_REFERENCES: ref_paper_infos,\n\t\t\t}\n\t\t)\n\n\tdef do_operation(self, **kwargs) -&gt; OperationOutputLog:\n\t\tr\"\"\"\n\t\tExecute the downloading operation and return the log string.\n\n\t\tArgs:\n\t\t\tuser_id (str): the user id.\n\t\t\tpaper_infos (List[Dict[str, str]]): the metadata of papers,\n\t\t\t\tfor each paper, the `title` and `pdf_url` must be provided\n\n\t\tReturns:\n\t\t\tOperationLog:\n\t\t\t\tThe operation output and log.\n\t\t\"\"\"\n\t\tuser_id = kwargs.get(\"user_id\", None)\n\t\tpaper_infos = kwargs.get(\"paper_infos\", [])\n\n\t\tif None in [user_id, paper_infos]:\n\t\t\traise ValueError(\"These arguments must be provided: user_id, paper_infos.\")\n\n\t\tif not isinstance(paper_infos, list):\n\t\t\tpaper_infos = [paper_infos]\n\n\t\ttmp_paper_store = RecentPaperStore.from_user_id(\n\t\t\tuser_id=user_id,\n\t\t\tembed_model=self._embed_model,\n\t\t)\n\n\t\tsucceed, fail = [], []\n\n\t\tfor info in paper_infos:\n\t\t\tpdf_url = info.get(\"pdf_url\", None)\n\t\t\ttitle = info.get(\"title\", None)\n\t\t\tfile_path = self.download_paper(\n\t\t\t\tuser_id=user_id,\n\t\t\t\ttitle=title,\n\t\t\t\tpdf_url=pdf_url,\n\t\t\t)\n\t\t\tif file_path is None:\n\t\t\t\tfail.append(title)\n\t\t\telse:\n\t\t\t\tsucceed.append((title, file_path))\n\t\t\t\ttmp_paper_store.put(paper_file_path=file_path)\n\n\t\ttmp_paper_store.persist()\n\t\toutput_log = self._get_log(user_id=user_id, succeed_papers=succeed, fail_papers=fail)\n\t\treturn output_log\n\n\tasync def ado_operation(self, **kwargs) -&gt; OperationOutputLog:\n\t\tr\"\"\"\n\t\tAsynchronously do the downloading operation and return the log string.\n\n\t\tArgs:\n\t\t\tuser_id (str): the user id.\n\t\t\tpaper_infos (List[Dict[str, str]]): the metadata of papers,\n\t\t\t\tfor each paper, the `title` and `pdf_url` must be provided\n\n\t\tReturns:\n\t\t\tstr:\n\t\t\t\tThe operation output and log.\n\t\t\"\"\"\n\t\tuser_id = kwargs.get(\"user_id\", None)\n\t\tpaper_infos = kwargs.get(\"paper_infos\", [])\n\n\t\tif None in [user_id, paper_infos]:\n\t\t\traise ValueError(\"These arguments must be provided: user_id, paper_infos.\")\n\n\t\tif not isinstance(paper_infos, list):\n\t\t\tpaper_infos = [paper_infos]\n\n\t\ttmp_paper_store = RecentPaperStore.from_user_id(\n\t\t\tuser_id=user_id,\n\t\t\tembed_model=self._embed_model,\n\t\t)\n\n\t\tsucceed, fail = [], []\n\n\t\tasync def single_op(info):\n\t\t\tpdf_url = info.get(\"pdf_url\", None)\n\t\t\ttitle = info.get(\"title\", None)\n\t\t\tfile_path = await self.adownload_paper(\n\t\t\t\tuser_id=user_id,\n\t\t\t\ttitle=title,\n\t\t\t\tpdf_url=pdf_url,\n\t\t\t)\n\t\t\tif file_path is None:\n\t\t\t\tfail.append(title)\n\t\t\telse:\n\t\t\t\tsucceed.append((title, file_path))\n\t\t\t\ttmp_paper_store.put(paper_file_path=file_path)\n\n\t\ttask_list = tuple([asyncio.create_task(single_op(paper_info)) for paper_info in paper_infos])\n\t\tawait asyncio.gather(*task_list)\n\t\ttmp_paper_store.persist()\n\t\toutput_log = self._get_log(user_id=user_id, succeed_papers=succeed, fail_papers=fail)\n\t\treturn output_log\n</code></pre>"},{"location":"code_docs/callback/paper/paper_download/#labridge.callback.paper.paper_download.ArxivDownloadOperation.ado_operation","title":"<code>labridge.callback.paper.paper_download.ArxivDownloadOperation.ado_operation(**kwargs)</code>  <code>async</code>","text":"<p>Asynchronously do the downloading operation and return the log string.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>the user id.</p> <p> TYPE: <code>str</code> </p> <code>paper_infos</code> <p>the metadata of papers, for each paper, the <code>title</code> and <code>pdf_url</code> must be provided</p> <p> TYPE: <code>List[Dict[str, str]]</code> </p> RETURNS DESCRIPTION <code>str</code> <p>The operation output and log.</p> <p> TYPE: <code>OperationOutputLog</code> </p> Source code in <code>labridge\\callback\\paper\\paper_download.py</code> <pre><code>async def ado_operation(self, **kwargs) -&gt; OperationOutputLog:\n\tr\"\"\"\n\tAsynchronously do the downloading operation and return the log string.\n\n\tArgs:\n\t\tuser_id (str): the user id.\n\t\tpaper_infos (List[Dict[str, str]]): the metadata of papers,\n\t\t\tfor each paper, the `title` and `pdf_url` must be provided\n\n\tReturns:\n\t\tstr:\n\t\t\tThe operation output and log.\n\t\"\"\"\n\tuser_id = kwargs.get(\"user_id\", None)\n\tpaper_infos = kwargs.get(\"paper_infos\", [])\n\n\tif None in [user_id, paper_infos]:\n\t\traise ValueError(\"These arguments must be provided: user_id, paper_infos.\")\n\n\tif not isinstance(paper_infos, list):\n\t\tpaper_infos = [paper_infos]\n\n\ttmp_paper_store = RecentPaperStore.from_user_id(\n\t\tuser_id=user_id,\n\t\tembed_model=self._embed_model,\n\t)\n\n\tsucceed, fail = [], []\n\n\tasync def single_op(info):\n\t\tpdf_url = info.get(\"pdf_url\", None)\n\t\ttitle = info.get(\"title\", None)\n\t\tfile_path = await self.adownload_paper(\n\t\t\tuser_id=user_id,\n\t\t\ttitle=title,\n\t\t\tpdf_url=pdf_url,\n\t\t)\n\t\tif file_path is None:\n\t\t\tfail.append(title)\n\t\telse:\n\t\t\tsucceed.append((title, file_path))\n\t\t\ttmp_paper_store.put(paper_file_path=file_path)\n\n\ttask_list = tuple([asyncio.create_task(single_op(paper_info)) for paper_info in paper_infos])\n\tawait asyncio.gather(*task_list)\n\ttmp_paper_store.persist()\n\toutput_log = self._get_log(user_id=user_id, succeed_papers=succeed, fail_papers=fail)\n\treturn output_log\n</code></pre>"},{"location":"code_docs/callback/paper/paper_download/#labridge.callback.paper.paper_download.ArxivDownloadOperation.adownload_paper","title":"<code>labridge.callback.paper.paper_download.ArxivDownloadOperation.adownload_paper(user_id, title, pdf_url)</code>  <code>async</code>","text":"<p>Asynchronously download a paper from arxiv and save to the user's recent paper directory.</p> Source code in <code>labridge\\callback\\paper\\paper_download.py</code> <pre><code>async def adownload_paper(self, user_id: str, title: str, pdf_url: str) -&gt; Optional[str]:\n\tr\"\"\"\n\tAsynchronously download a paper from arxiv and save to the user's recent paper directory.\n\t\"\"\"\n\tif None in [user_id, title, pdf_url]:\n\t\traise ValueError(\"should provide valid user_id, title, pdf_url to download paper.\")\n\n\tfile_dir, file_name = self._get_default_path(user_id=user_id, title=title)\n\tfile_path = str(Path(file_dir) / file_name)\n\n\tif self._verbose:\n\t\tprint_text(text=f\"Downloading paper '{title}' ...\", color=\"pink\", end=\"\\n\")\n\ttry:\n\t\tawait adownload_file(url=pdf_url, save_path=file_path)\n\t\treturn file_path\n\texcept Exception as e:\n\t\tprint(f\"Download failed. Error: {e}\")\n\t\treturn None\n</code></pre>"},{"location":"code_docs/callback/paper/paper_download/#labridge.callback.paper.paper_download.ArxivDownloadOperation.do_operation","title":"<code>labridge.callback.paper.paper_download.ArxivDownloadOperation.do_operation(**kwargs)</code>","text":"<p>Execute the downloading operation and return the log string.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>the user id.</p> <p> TYPE: <code>str</code> </p> <code>paper_infos</code> <p>the metadata of papers, for each paper, the <code>title</code> and <code>pdf_url</code> must be provided</p> <p> TYPE: <code>List[Dict[str, str]]</code> </p> RETURNS DESCRIPTION <code>OperationLog</code> <p>The operation output and log.</p> <p> TYPE: <code>OperationOutputLog</code> </p> Source code in <code>labridge\\callback\\paper\\paper_download.py</code> <pre><code>def do_operation(self, **kwargs) -&gt; OperationOutputLog:\n\tr\"\"\"\n\tExecute the downloading operation and return the log string.\n\n\tArgs:\n\t\tuser_id (str): the user id.\n\t\tpaper_infos (List[Dict[str, str]]): the metadata of papers,\n\t\t\tfor each paper, the `title` and `pdf_url` must be provided\n\n\tReturns:\n\t\tOperationLog:\n\t\t\tThe operation output and log.\n\t\"\"\"\n\tuser_id = kwargs.get(\"user_id\", None)\n\tpaper_infos = kwargs.get(\"paper_infos\", [])\n\n\tif None in [user_id, paper_infos]:\n\t\traise ValueError(\"These arguments must be provided: user_id, paper_infos.\")\n\n\tif not isinstance(paper_infos, list):\n\t\tpaper_infos = [paper_infos]\n\n\ttmp_paper_store = RecentPaperStore.from_user_id(\n\t\tuser_id=user_id,\n\t\tembed_model=self._embed_model,\n\t)\n\n\tsucceed, fail = [], []\n\n\tfor info in paper_infos:\n\t\tpdf_url = info.get(\"pdf_url\", None)\n\t\ttitle = info.get(\"title\", None)\n\t\tfile_path = self.download_paper(\n\t\t\tuser_id=user_id,\n\t\t\ttitle=title,\n\t\t\tpdf_url=pdf_url,\n\t\t)\n\t\tif file_path is None:\n\t\t\tfail.append(title)\n\t\telse:\n\t\t\tsucceed.append((title, file_path))\n\t\t\ttmp_paper_store.put(paper_file_path=file_path)\n\n\ttmp_paper_store.persist()\n\toutput_log = self._get_log(user_id=user_id, succeed_papers=succeed, fail_papers=fail)\n\treturn output_log\n</code></pre>"},{"location":"code_docs/callback/paper/paper_download/#labridge.callback.paper.paper_download.ArxivDownloadOperation.download_paper","title":"<code>labridge.callback.paper.paper_download.ArxivDownloadOperation.download_paper(user_id, title, pdf_url)</code>","text":"<p>Download a paper from arxiv and save to the user's recent paper directory.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user id of a lab member.</p> <p> TYPE: <code>str</code> </p> <code>title</code> <p>The paper title.</p> <p> TYPE: <code>str</code> </p> <code>pdf_url</code> <p>The paper URL.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Optional[str]</code> <p>Optional[str]:</p> <ul> <li>If the paper is successfully downloaded, return the file_path.</li> <li>If the downloading fails, return None.</li> </ul> Source code in <code>labridge\\callback\\paper\\paper_download.py</code> <pre><code>def download_paper(self, user_id: str, title: str, pdf_url: str) -&gt; Optional[str]:\n\tr\"\"\"\n\tDownload a paper from arxiv and save to the user's recent paper directory.\n\n\tArgs:\n\t\tuser_id (str): The user id of a lab member.\n\t\ttitle (str): The paper title.\n\t\tpdf_url (str): The paper URL.\n\n\tReturns:\n\t\tOptional[str]:\n\n\t\t\t- If the paper is successfully downloaded, return the file_path.\n\t\t\t- If the downloading fails, return None.\n\t\"\"\"\n\tif None in [user_id, title, pdf_url]:\n\t\traise ValueError(\"should provide valid user_id, title, pdf_url to download paper.\")\n\tfile_dir, file_name = self._get_default_path(user_id=user_id, title=title)\n\tresult = Result(entry_id=\"\")\n\tresult.pdf_url = pdf_url\n\n\tif self._verbose:\n\t\tprint_text(text=f\"Downloading paper '{title}' ...\", color=\"pink\", end=\"\\n\")\n\n\ttry:\n\t\tresult.download_pdf(dirpath=file_dir, filename=file_name)\n\t\tfile_path = str(Path(file_dir) / file_name)\n\t\treturn file_path\n\texcept Exception as e:\n\t\tprint(f\"Download failed. Error: {e}\")\n\t\treturn None\n</code></pre>"},{"location":"code_docs/callback/paper/paper_download/#labridge.callback.paper.paper_download.ArxivDownloadOperation.operation_description","title":"<code>labridge.callback.paper.paper_download.ArxivDownloadOperation.operation_description(**kwargs)</code>","text":"<p>Describe the operation.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>the user id.</p> <p> TYPE: <code>str</code> </p> <code>paper_infos</code> <p>the metadata of papers, for each paper, the <code>title</code> must be provided.</p> <p> TYPE: <code>List[Dict[str, str]]</code> </p> RETURNS DESCRIPTION <code>str</code> <p>the operation description.</p> Source code in <code>labridge\\callback\\paper\\paper_download.py</code> <pre><code>def operation_description(self, **kwargs) -&gt; str:\n\tr\"\"\"\n\tDescribe the operation.\n\n\tArgs:\n\t\tuser_id (str): the user id.\n\t\tpaper_infos (List[Dict[str, str]]): the metadata of papers,\n\t\t\tfor each paper, the `title` must be provided.\n\n\tReturns:\n\t\tthe operation description.\n\t\"\"\"\n\tuser_id = kwargs.get(\"user_id\", None)\n\tpaper_infos = kwargs.get(\"paper_infos\", None)\n\n\tif None in [user_id, paper_infos]:\n\t\traise ValueError(\"should provide valid user_id, paper_infos.\")\n\n\tpapers = []\n\tfor paper in paper_infos:\n\t\ttitle = paper.get(\"title\", None)\n\t\tfile_dir, file_name = self._get_default_path(user_id=user_id, title=title)\n\t\tsave_path = str(Path(file_dir) / file_name)\n\t\tpaper_dsc = PAPER_DESCRIPTION_TMPL.format(title=title, save_path=save_path)\n\t\tpapers.append(paper_dsc)\n\tpapers = \"\\n\\n\".join(papers)\n\theader = ARXIV_DOWNLOAD_DESCRIPTION.format(user_id=user_id)\n\tdescription = f\"{header}\\n{papers}\"\n\treturn description\n</code></pre>"},{"location":"code_docs/callback/paper/paper_summarize/","title":"Paper summarize","text":""},{"location":"code_docs/callback/paper/paper_summarize/#labridge.callback.paper.paper_summarize","title":"<code>labridge.callback.paper.paper_summarize</code>","text":""},{"location":"code_docs/callback/paper/paper_summarize/#labridge.callback.paper.paper_summarize.PaperSummarizeOperation","title":"<code>labridge.callback.paper.paper_summarize.PaperSummarizeOperation</code>","text":"<p>               Bases: <code>CallBackOperationBase</code></p> <p>This operation will summarize a paper.</p> PARAMETER DESCRIPTION <code>llm</code> <p>The used LLM.</p> <p> TYPE: <code>LLM</code> DEFAULT: <code>None</code> </p> <code>embed_model</code> <p>The used embedding model.</p> <p> TYPE: <code>BaseEmbedding</code> DEFAULT: <code>None</code> </p> <code>verbose</code> <p>Whether to show the inner progress.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> Source code in <code>labridge\\callback\\paper\\paper_summarize.py</code> <pre><code>class PaperSummarizeOperation(CallBackOperationBase):\n\tr\"\"\"\n\tThis operation will summarize a paper.\n\n\tArgs:\n\t\tllm (LLM): The used LLM.\n\t\tembed_model (BaseEmbedding): The used embedding model.\n\t\tverbose (bool): Whether to show the inner progress.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tllm: LLM = None,\n\t\tembed_model: BaseEmbedding = None,\n\t\tverbose: bool = False,\n\t\top_name: str = None,\n\t):\n\t\troot = Path(__file__)\n\n\t\tfor idx in range(4):\n\t\t\troot = root.parent\n\n\t\tself.root = root\n\t\tself._fs = fsspec.filesystem(\"file\")\n\t\tembed_model = embed_model or Settings.embed_model\n\t\tllm = llm or Settings.llm\n\t\tself._summarizer = PaperBatchSummarize(llm=llm)\n\t\tsuper().__init__(\n\t\t\tllm=llm,\n\t\t\tembed_model=embed_model,\n\t\t\tverbose=verbose,\n\t\t\top_name=op_name or PaperSummarizeOperation.__name__,\n\t\t)\n\n\tdef operation_description(self, **kwargs) -&gt; str:\n\t\tr\"\"\"\n\t\tDescribe the operation.\n\n\t\tArgs:\n\t\t\tuser_id (str): the user id.\n\t\t\tpaper_file_path (str): The file path of the paper.\n\n\t\tReturns:\n\t\t\tstr: the operation description.\n\t\t\"\"\"\n\t\tuser_id = kwargs.get(\"user_id\", None)\n\t\tpaper_file_path = kwargs.get(\"paper_file_path\", None)\n\n\t\tif None in [user_id, paper_file_path]:\n\t\t\traise ValueError(\"should provide valid user_id, paper_infos.\")\n\n\t\tdescription = SUMMARIZE_DESCRIPTION_TMPL.format(user_id=user_id, paper_file_path=paper_file_path)\n\t\treturn description\n\n\tdef do_operation(\n\t\tself,\n\t\tuser_id: str,\n\t\tpaper_file_path: str,\n\t) -&gt; OperationOutputLog:\n\t\tr\"\"\"\n\t\tExecute the operation to summarize a paper in a user's recent papers.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user id of a lab member.\n\t\t\tpaper_file_path (str): The file path of the paper.\n\n\t\tReturns:\n\t\t\tOperationOutputLog:\n\t\t\t\tThe operation output and log.\n\t\t\"\"\"\n\t\trecent_paper_store = RecentPaperStore.from_user_id(\n\t\t\tuser_id=user_id,\n\t\t\tembed_model=self._embed_model,\n\t\t)\n\t\trecent_paper_store.check_valid_paper(paper_file_path=paper_file_path)\n\t\tsummary_node = recent_paper_store.get_summary_node(paper_file_path=paper_file_path)\n\t\tif summary_node is not None:\n\t\t\treturn summary_node.text\n\n\t\t# TODO: Send to the user\n\t\tprint(\"Assistant: \u200b\u6b63\u5728\u200b\u4e3a\u200b\u60a8\u200b\u603b\u7ed3\u200b\u4e2d\u200b\uff0c\u200b\u8bf7\u200b\u7a0d\u5019\u200b\u3002\")\n\t\tpaper_nodes = recent_paper_store.get_paper_nodes(paper_file_path=paper_file_path)\n\t\tnodes_with_scores = [NodeWithScore(node=n) for n in paper_nodes]\n\t\t# get the summary for each doc_id\n\t\tsummary_response = self._summarizer.synthesize(\n\t\t\tnodes=nodes_with_scores,\n\t\t\tquery=\"\"\n\t\t)\n\t\tsummary_response = cast(Response, summary_response)\n\t\tsummary_node = TextNode(text=summary_response.response)\n\t\trecent_paper_store.insert_summary_node(\n\t\t\tpaper_file_path=paper_file_path,\n\t\t\tsummary_node=summary_node,\n\t\t)\n\t\trecent_paper_store.persist()\n\t\tpaper_info = PaperInfo(\n\t\t\ttitle=paper_file_path,\n\t\t\tpossessor=user_id,\n\t\t\tfile_path=paper_file_path,\n\t\t)\n\t\top_log = f\"Have summarized the paper {paper_file_path} for the user {user_id}.\"\n\t\treturn OperationOutputLog(\n\t\t\toperation_name=self.op_name,\n\t\t\toperation_output=summary_node.text,\n\t\t\tlog_to_user=None,\n\t\t\tlog_to_system={\n\t\t\t\tOP_DESCRIPTION: op_log,\n\t\t\t\tOP_REFERENCES: [paper_info.dumps()]\n\t\t\t},\n\t\t)\n\n\tasync def ado_operation(\n\t\tself,\n\t\tuser_id: str,\n\t\tpaper_file_path: str,\n\t) -&gt; OperationOutputLog:\n\t\tr\"\"\"\n\t\tAsynchronously execute the operation to summarize a paper in a user's recent papers.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user id of a lab member.\n\t\t\tpaper_file_path (str): The file path of the paper.\n\n\t\tReturns:\n\t\t\tOperationOutputLog:\n\t\t\t\tThe output and log.\n\t\t\"\"\"\n\t\trecent_paper_store = RecentPaperStore.from_user_id(\n\t\t\tuser_id=user_id,\n\t\t\tembed_model=self._embed_model,\n\t\t)\n\t\trecent_paper_store.check_valid_paper(paper_file_path=paper_file_path)\n\t\tsummary_node = recent_paper_store.get_summary_node(paper_file_path=paper_file_path)\n\t\tif summary_node is not None:\n\t\t\treturn summary_node.text\n\n\t\t# TODO: Send to the user\n\t\tprint(\"Assistant: \u200b\u6b63\u5728\u200b\u4e3a\u200b\u60a8\u200b\u603b\u7ed3\u200b\u4e2d\u200b\uff0c\u200b\u8bf7\u200b\u7a0d\u5019\u200b\u3002\")\n\t\tpaper_nodes = recent_paper_store.get_paper_nodes(paper_file_path=paper_file_path)\n\t\tnodes_with_scores = [NodeWithScore(node=n) for n in paper_nodes]\n\t\t# get the summary for each doc_id\n\t\tsummary_response = await self._summarizer.asynthesize(\n\t\t\tnodes=nodes_with_scores,\n\t\t\tquery=\"\"\n\t\t)\n\t\tsummary_response = cast(Response, summary_response)\n\t\tsummary_node = TextNode(text=summary_response.response)\n\t\trecent_paper_store.insert_summary_node(\n\t\t\tpaper_file_path=paper_file_path,\n\t\t\tsummary_node=summary_node,\n\t\t)\n\t\trecent_paper_store.persist()\n\t\tpaper_info = PaperInfo(\n\t\t\ttitle=paper_file_path,\n\t\t\tpossessor=user_id,\n\t\t\tfile_path=paper_file_path,\n\t\t)\n\t\top_log = f\"Have summarized the paper {paper_file_path} for the user {user_id}.\"\n\t\treturn OperationOutputLog(\n\t\t\toperation_name=self.op_name,\n\t\t\toperation_output=summary_node.text,\n\t\t\tlog_to_user=None,\n\t\t\tlog_to_system={\n\t\t\t\tOP_DESCRIPTION: op_log,\n\t\t\t\tOP_REFERENCES: [paper_info.dumps()]\n\t\t\t},\n\t\t)\n</code></pre>"},{"location":"code_docs/callback/paper/paper_summarize/#labridge.callback.paper.paper_summarize.PaperSummarizeOperation.ado_operation","title":"<code>labridge.callback.paper.paper_summarize.PaperSummarizeOperation.ado_operation(user_id, paper_file_path)</code>  <code>async</code>","text":"<p>Asynchronously execute the operation to summarize a paper in a user's recent papers.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user id of a lab member.</p> <p> TYPE: <code>str</code> </p> <code>paper_file_path</code> <p>The file path of the paper.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>OperationOutputLog</code> <p>The output and log.</p> <p> TYPE: <code>OperationOutputLog</code> </p> Source code in <code>labridge\\callback\\paper\\paper_summarize.py</code> <pre><code>async def ado_operation(\n\tself,\n\tuser_id: str,\n\tpaper_file_path: str,\n) -&gt; OperationOutputLog:\n\tr\"\"\"\n\tAsynchronously execute the operation to summarize a paper in a user's recent papers.\n\n\tArgs:\n\t\tuser_id (str): The user id of a lab member.\n\t\tpaper_file_path (str): The file path of the paper.\n\n\tReturns:\n\t\tOperationOutputLog:\n\t\t\tThe output and log.\n\t\"\"\"\n\trecent_paper_store = RecentPaperStore.from_user_id(\n\t\tuser_id=user_id,\n\t\tembed_model=self._embed_model,\n\t)\n\trecent_paper_store.check_valid_paper(paper_file_path=paper_file_path)\n\tsummary_node = recent_paper_store.get_summary_node(paper_file_path=paper_file_path)\n\tif summary_node is not None:\n\t\treturn summary_node.text\n\n\t# TODO: Send to the user\n\tprint(\"Assistant: \u200b\u6b63\u5728\u200b\u4e3a\u200b\u60a8\u200b\u603b\u7ed3\u200b\u4e2d\u200b\uff0c\u200b\u8bf7\u200b\u7a0d\u5019\u200b\u3002\")\n\tpaper_nodes = recent_paper_store.get_paper_nodes(paper_file_path=paper_file_path)\n\tnodes_with_scores = [NodeWithScore(node=n) for n in paper_nodes]\n\t# get the summary for each doc_id\n\tsummary_response = await self._summarizer.asynthesize(\n\t\tnodes=nodes_with_scores,\n\t\tquery=\"\"\n\t)\n\tsummary_response = cast(Response, summary_response)\n\tsummary_node = TextNode(text=summary_response.response)\n\trecent_paper_store.insert_summary_node(\n\t\tpaper_file_path=paper_file_path,\n\t\tsummary_node=summary_node,\n\t)\n\trecent_paper_store.persist()\n\tpaper_info = PaperInfo(\n\t\ttitle=paper_file_path,\n\t\tpossessor=user_id,\n\t\tfile_path=paper_file_path,\n\t)\n\top_log = f\"Have summarized the paper {paper_file_path} for the user {user_id}.\"\n\treturn OperationOutputLog(\n\t\toperation_name=self.op_name,\n\t\toperation_output=summary_node.text,\n\t\tlog_to_user=None,\n\t\tlog_to_system={\n\t\t\tOP_DESCRIPTION: op_log,\n\t\t\tOP_REFERENCES: [paper_info.dumps()]\n\t\t},\n\t)\n</code></pre>"},{"location":"code_docs/callback/paper/paper_summarize/#labridge.callback.paper.paper_summarize.PaperSummarizeOperation.do_operation","title":"<code>labridge.callback.paper.paper_summarize.PaperSummarizeOperation.do_operation(user_id, paper_file_path)</code>","text":"<p>Execute the operation to summarize a paper in a user's recent papers.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user id of a lab member.</p> <p> TYPE: <code>str</code> </p> <code>paper_file_path</code> <p>The file path of the paper.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>OperationOutputLog</code> <p>The operation output and log.</p> <p> TYPE: <code>OperationOutputLog</code> </p> Source code in <code>labridge\\callback\\paper\\paper_summarize.py</code> <pre><code>def do_operation(\n\tself,\n\tuser_id: str,\n\tpaper_file_path: str,\n) -&gt; OperationOutputLog:\n\tr\"\"\"\n\tExecute the operation to summarize a paper in a user's recent papers.\n\n\tArgs:\n\t\tuser_id (str): The user id of a lab member.\n\t\tpaper_file_path (str): The file path of the paper.\n\n\tReturns:\n\t\tOperationOutputLog:\n\t\t\tThe operation output and log.\n\t\"\"\"\n\trecent_paper_store = RecentPaperStore.from_user_id(\n\t\tuser_id=user_id,\n\t\tembed_model=self._embed_model,\n\t)\n\trecent_paper_store.check_valid_paper(paper_file_path=paper_file_path)\n\tsummary_node = recent_paper_store.get_summary_node(paper_file_path=paper_file_path)\n\tif summary_node is not None:\n\t\treturn summary_node.text\n\n\t# TODO: Send to the user\n\tprint(\"Assistant: \u200b\u6b63\u5728\u200b\u4e3a\u200b\u60a8\u200b\u603b\u7ed3\u200b\u4e2d\u200b\uff0c\u200b\u8bf7\u200b\u7a0d\u5019\u200b\u3002\")\n\tpaper_nodes = recent_paper_store.get_paper_nodes(paper_file_path=paper_file_path)\n\tnodes_with_scores = [NodeWithScore(node=n) for n in paper_nodes]\n\t# get the summary for each doc_id\n\tsummary_response = self._summarizer.synthesize(\n\t\tnodes=nodes_with_scores,\n\t\tquery=\"\"\n\t)\n\tsummary_response = cast(Response, summary_response)\n\tsummary_node = TextNode(text=summary_response.response)\n\trecent_paper_store.insert_summary_node(\n\t\tpaper_file_path=paper_file_path,\n\t\tsummary_node=summary_node,\n\t)\n\trecent_paper_store.persist()\n\tpaper_info = PaperInfo(\n\t\ttitle=paper_file_path,\n\t\tpossessor=user_id,\n\t\tfile_path=paper_file_path,\n\t)\n\top_log = f\"Have summarized the paper {paper_file_path} for the user {user_id}.\"\n\treturn OperationOutputLog(\n\t\toperation_name=self.op_name,\n\t\toperation_output=summary_node.text,\n\t\tlog_to_user=None,\n\t\tlog_to_system={\n\t\t\tOP_DESCRIPTION: op_log,\n\t\t\tOP_REFERENCES: [paper_info.dumps()]\n\t\t},\n\t)\n</code></pre>"},{"location":"code_docs/callback/paper/paper_summarize/#labridge.callback.paper.paper_summarize.PaperSummarizeOperation.operation_description","title":"<code>labridge.callback.paper.paper_summarize.PaperSummarizeOperation.operation_description(**kwargs)</code>","text":"<p>Describe the operation.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>the user id.</p> <p> TYPE: <code>str</code> </p> <code>paper_file_path</code> <p>The file path of the paper.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>str</code> <p>the operation description.</p> <p> TYPE: <code>str</code> </p> Source code in <code>labridge\\callback\\paper\\paper_summarize.py</code> <pre><code>def operation_description(self, **kwargs) -&gt; str:\n\tr\"\"\"\n\tDescribe the operation.\n\n\tArgs:\n\t\tuser_id (str): the user id.\n\t\tpaper_file_path (str): The file path of the paper.\n\n\tReturns:\n\t\tstr: the operation description.\n\t\"\"\"\n\tuser_id = kwargs.get(\"user_id\", None)\n\tpaper_file_path = kwargs.get(\"paper_file_path\", None)\n\n\tif None in [user_id, paper_file_path]:\n\t\traise ValueError(\"should provide valid user_id, paper_infos.\")\n\n\tdescription = SUMMARIZE_DESCRIPTION_TMPL.format(user_id=user_id, paper_file_path=paper_file_path)\n\treturn description\n</code></pre>"},{"location":"code_docs/common/prompt/llm_doc_choice_select/","title":"Llm doc choice select","text":""},{"location":"code_docs/common/prompt/llm_doc_choice_select/#labridge.common.prompt.llm_doc_choice_select","title":"<code>labridge.common.prompt.llm_doc_choice_select</code>","text":""},{"location":"code_docs/common/query_engine/query_engines/","title":"Query engines","text":""},{"location":"code_docs/common/query_engine/query_engines/#labridge.common.query_engine.query_engines","title":"<code>labridge.common.query_engine.query_engines</code>","text":""},{"location":"code_docs/common/query_engine/query_engines/#labridge.common.query_engine.query_engines.SingleQueryEngine","title":"<code>labridge.common.query_engine.query_engines.SingleQueryEngine</code>","text":"<p>               Bases: <code>BaseQueryEngine</code></p> <p>A single query engine.</p> PARAMETER DESCRIPTION <code>llm</code> <p>The used LLM.</p> <p> TYPE: <code>LLM</code> </p> <code>prompt_tmpl</code> <p>The prompt template.</p> <p> TYPE: <code>str</code> </p> Source code in <code>labridge\\common\\query_engine\\query_engines.py</code> <pre><code>class SingleQueryEngine(BaseQueryEngine):\n\tr\"\"\"\n\tA single query engine.\n\n\tArgs:\n\t\tllm (LLM): The used LLM.\n\t\tprompt_tmpl (str): The prompt template.\n\t\"\"\"\n\tdef __init__(self, llm: LLM, prompt_tmpl: str):\n\t\tif llm is not None:\n\t\t\tself.llm = llm\n\t\telse:\n\t\t\tself.llm = Settings.llm\n\t\tself.prompt_tmpl = prompt_tmpl\n\t\tsuper().__init__(callback_manager=None)\n\n\tdef _query(self, query_bundle: QueryBundle) -&gt; RESPONSE_TYPE:\n\t\treturn self.single_query(query_bundle.query_str)\n\n\tasync def _aquery(self, query_bundle: QueryBundle) -&gt; RESPONSE_TYPE:\n\t\treturn self.single_query(query_bundle.query_str)\n\n\tdef _get_prompt_modules(self) -&gt; Dict[str, Any]:\n\t\t\"\"\"Get prompts.\"\"\"\n\t\treturn {}\n\n\tdef single_query(self, query_str: str) -&gt; Union[RESPONSE_TYPE, str]:\n\t\tquery = self.prompt_tmpl.format(query_str)\n\t\tmotivation_str = self.llm.complete(prompt=query)\n\t\tmotivation = Response(motivation_str.text)\n\t\treturn motivation\n</code></pre>"},{"location":"code_docs/common/utils/chat/","title":"Chat","text":""},{"location":"code_docs/common/utils/chat/#labridge.common.utils.chat","title":"<code>labridge.common.utils.chat</code>","text":""},{"location":"code_docs/common/utils/chat/#labridge.common.utils.chat.pack_user_message","title":"<code>labridge.common.utils.chat.pack_user_message(user_id, user_msg, system_msg, reply_in_speech)</code>","text":"Source code in <code>labridge\\common\\utils\\chat.py</code> <pre><code>def pack_user_message(user_id: str, user_msg: str, system_msg: str, reply_in_speech: bool):\n\tr\"\"\" TODO: change to system format \"\"\"\n\tmessage_dict = {\n\t\t\"user_id\": user_id,\n\t\t\"user_message\": user_msg,\n\t\t\"system_message\": system_msg,\n\t}\n\tmessage_str = json.dumps(message_dict)\n\treturn message_str\n</code></pre>"},{"location":"code_docs/common/utils/time/","title":"Time","text":""},{"location":"code_docs/common/utils/time/#labridge.common.utils.time","title":"<code>labridge.common.utils.time</code>","text":""},{"location":"code_docs/common/utils/time/#labridge.common.utils.time.datetime_to_str","title":"<code>labridge.common.utils.time.datetime_to_str(date_time)</code>","text":"<p>Transform datetime into formatted strings.</p> PARAMETER DESCRIPTION <code>date_time</code> <p>The datetime.</p> <p> TYPE: <code>datetime</code> </p> RETURNS DESCRIPTION <code>Tuple[str, str]</code> <p>Tuple[str, str]: The formatted date string and time string.</p> Source code in <code>labridge\\common\\utils\\time.py</code> <pre><code>def datetime_to_str(date_time: datetime.datetime) -&gt; Tuple[str, str]:\n\tr\"\"\"\n\tTransform datetime into formatted strings.\n\n\tArgs:\n\t\tdate_time (datetime.datetime): The datetime.\n\n\tReturns:\n\t\tTuple[str, str]: The formatted date string and time string.\n\t\"\"\"\n\tdate_str = date_time.date().strftime(f\"{DATE_FORMAT}\")\n\ttime_str = date_time.time().strftime(f\"{TIME_FORMAT}\")\n\treturn date_str, time_str\n</code></pre>"},{"location":"code_docs/common/utils/time/#labridge.common.utils.time.get_time","title":"<code>labridge.common.utils.time.get_time()</code>","text":"<p>Get current date time in <code>DATE_FORMAT</code> and <code>TIME_FORMAT</code></p> RETURNS DESCRIPTION <code>Tuple[str, str]</code> <p>Tuple[str, str]: The formatted date string and time string.</p> Source code in <code>labridge\\common\\utils\\time.py</code> <pre><code>def get_time() -&gt; Tuple[str, str]:\n\tr\"\"\"\n\tGet current date time in `DATE_FORMAT` and `TIME_FORMAT`\n\n\tReturns:\n\t\tTuple[str, str]: The formatted date string and time string.\n\t\"\"\"\n\tnow = time.strftime(f\"{DATE_FORMAT} {TIME_FORMAT}\")\n\tdate, h_m_s = now.split()\n\treturn date, h_m_s\n</code></pre>"},{"location":"code_docs/common/utils/time/#labridge.common.utils.time.parse_date_list","title":"<code>labridge.common.utils.time.parse_date_list(start_date_str, end_date_str)</code>","text":"<p>Return the formatted strings of all dates from start_date to end_date.</p> PARAMETER DESCRIPTION <code>start_date_str</code> <p>The formatted string of the start date.</p> <p> TYPE: <code>str</code> </p> <code>end_date_str</code> <p>The formatted string of the end date.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>List[str]</code> <p>List[str]: The formatted date string.</p> RAISES DESCRIPTION <code>-ValueError</code> <p>If the end_date is earlier than the start_date.</p> Source code in <code>labridge\\common\\utils\\time.py</code> <pre><code>def parse_date_list(start_date_str: str, end_date_str: str) -&gt; List[str]:\n\tr\"\"\"\n\tReturn the formatted strings of all dates from start_date to end_date.\n\n\tArgs:\n\t\tstart_date_str (str): The formatted string of the start date.\n\t\tend_date_str (str): The formatted string of the end date.\n\n\tReturns:\n\t\tList[str]: The formatted date string.\n\n\tRaises:\n\t\t- ValueError: If the end_date is earlier than the start_date.\n\t\t- Any other errors raises in internal process.\n\t\"\"\"\n\tstart_date = str_to_date(start_date_str)\n\tend_date = str_to_date(end_date_str)\n\tif end_date &lt; start_date:\n\t\traise ValueError(\"The end_date can not be earlier than the start_date!\")\n\n\tdate_list = []\n\tcurrent_date = start_date\n\twhile current_date &lt;= end_date:\n\t\tdate_list.append(current_date.strftime(DATE_FORMAT))\n\t\tcurrent_date = current_date + datetime.timedelta(days=1)\n\treturn date_list\n</code></pre>"},{"location":"code_docs/common/utils/time/#labridge.common.utils.time.parse_delta_time","title":"<code>labridge.common.utils.time.parse_delta_time(time_unit)</code>","text":"<p>Get the delta time from a unit of a formatted time_delta string.</p> PARAMETER DESCRIPTION <code>time_unit</code> <p>A unit of a formatted time_delta string.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>dict</code> <ul> <li>If the time_unit is valid, return the parsed delta time. For example: \"2h\" -&gt; {\"hours\": 2}</li> <li>If the time_unit is invalid, return an empty dict.</li> </ul> <p> TYPE: <code>Dict[str, int]</code> </p> Source code in <code>labridge\\common\\utils\\time.py</code> <pre><code>def parse_delta_time(time_unit: str) -&gt; Dict[str, int]:\n\tr\"\"\"\n\tGet the delta time from a unit of a formatted time_delta string.\n\n\tArgs:\n\t\ttime_unit (str): A unit of a formatted time_delta string.\n\n\tReturns:\n\t\tdict:\n\t\t\t- If the time_unit is valid, return the parsed delta time. For example: \"2h\" -&gt; {\"hours\": 2}\n\t\t\t- If the time_unit is invalid, return an empty dict.\n\t\"\"\"\n\tnumbers = [char for char in time_unit if char.isnumeric()]\n\tflag = [char for char in time_unit if char.isalpha()]\n\n\tnum = int(\"\".join(numbers))\n\tflag_str = \"\".join(flag).lower()\n\n\tif flag_str in DELTA_TIME_FLAG_MAPPING.keys():\n\t\tkey = DELTA_TIME_FLAG_MAPPING.get(flag_str)\n\t\treturn {key: num}\n\treturn {}\n</code></pre>"},{"location":"code_docs/common/utils/time/#labridge.common.utils.time.str_to_date","title":"<code>labridge.common.utils.time.str_to_date(date_str)</code>","text":"<p>Transform a formatted date string to <code>datetime.date</code>.</p> PARAMETER DESCRIPTION <code>date_str</code> <p>The date string in format <code>DATE_FORMAT</code>.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>date</code> <p>datetime.date: The date.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If the date_str does not match the DATE_FORMAT`.</p> Source code in <code>labridge\\common\\utils\\time.py</code> <pre><code>def str_to_date(date_str: str) -&gt; datetime.date:\n\tr\"\"\"\n\tTransform a formatted date string to `datetime.date`.\n\n\tArgs:\n\t\tdate_str (str): The date string in format `DATE_FORMAT`.\n\n\tReturns:\n\t\tdatetime.date: The date.\n\n\tRaises:\n\t\tValueError: If the date_str does not match the DATE_FORMAT`.\n\t\"\"\"\n\tyear_month_day = date_str.split(\"-\")\n\n\ttry:\n\t\tmy_date = datetime.date(\n\t\t\tyear=int(year_month_day[0]),\n\t\t\tmonth=int(year_month_day[1]),\n\t\t\tday=int(year_month_day[2]),\n\t\t)\n\t\treturn my_date\n\texcept Exception:\n\t\traise ValueError(f\"The input date string {date_str} is invalid.\")\n</code></pre>"},{"location":"code_docs/common/utils/time/#labridge.common.utils.time.str_to_datetime","title":"<code>labridge.common.utils.time.str_to_datetime(date_str, time_str)</code>","text":"<p>Transform formatted time strings to <code>datetime.datetime</code>.</p> PARAMETER DESCRIPTION <code>date_str</code> <p>The date string in format <code>DATE_FORMAT</code>.</p> <p> TYPE: <code>str</code> </p> <code>time_str</code> <p>The time string in format <code>TIME_FORMAT</code>.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>datetime</code> <p>datetime.datetime: The datetime</p> Source code in <code>labridge\\common\\utils\\time.py</code> <pre><code>def str_to_datetime(date_str: str, time_str: str) -&gt; datetime.datetime:\n\tr\"\"\"\n\tTransform formatted time strings to `datetime.datetime`.\n\n\tArgs:\n\t\tdate_str (str): The date string in format `DATE_FORMAT`.\n\t\ttime_str (str): The time string in format `TIME_FORMAT`.\n\n\tReturns:\n\t\tdatetime.datetime: The datetime\n\n\tRaises:\n\t\tAny Error raises in `str_to_date` or `str_to_time`.\n\t\"\"\"\n\tmy_date = str_to_date(date_str)\n\tmy_time = str_to_time(time_str)\n\tmy_datetime = datetime.datetime(\n\t\tyear=my_date.year,\n\t\tmonth=my_date.month,\n\t\tday=my_date.day,\n\t\thour=my_time.hour,\n\t\tminute=my_time.minute,\n\t\tsecond=my_time.second,\n\t)\n\treturn my_datetime\n</code></pre>"},{"location":"code_docs/common/utils/time/#labridge.common.utils.time.str_to_delta_time","title":"<code>labridge.common.utils.time.str_to_delta_time(time_str)</code>","text":"<p>Transform a formatted time_delta string to <code>datetime.timedelta</code>.</p> PARAMETER DESCRIPTION <code>time_str</code> <p>The time_delta str in format <code>DELTA_TIME_FORMAT</code>.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>timedelta</code> <p>datetime.timedelta: The time delta.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If the time_str does not match the <code>DELTA_TIME_FORMAT</code>.</p> Source code in <code>labridge\\common\\utils\\time.py</code> <pre><code>def str_to_delta_time(time_str: str) -&gt; datetime.timedelta:\n\tr\"\"\"\n\tTransform a formatted time_delta string to `datetime.timedelta`.\n\n\tArgs:\n\t\ttime_str (str): The time_delta str in format `DELTA_TIME_FORMAT`.\n\n\tReturns:\n\t\tdatetime.timedelta: The time delta.\n\n\tRaises:\n\t\tValueError: If the time_str does not match the `DELTA_TIME_FORMAT`.\n\t\"\"\"\n\thour_minute_second = time_str.split(\":\")\n\n\tdefault = {\n\t\t\"hours\": 0,\n\t\t\"minutes\": 0,\n\t\t\"seconds\": 0,\n\t}\n\n\tfor unit in hour_minute_second:\n\t\tparsed_dict = parse_delta_time(time_unit=unit)\n\t\tdefault.update(parsed_dict)\n\n\ttry:\n\t\tdelta_time = datetime.timedelta(**default)\n\t\treturn delta_time\n\texcept Exception:\n\t\traise ValueError(f\"The input time string {time_str} is invalid.\")\n</code></pre>"},{"location":"code_docs/common/utils/time/#labridge.common.utils.time.str_to_time","title":"<code>labridge.common.utils.time.str_to_time(time_str)</code>","text":"<p>Transform a formatted time string to <code>datetime.time</code>.</p> PARAMETER DESCRIPTION <code>time_str</code> <p>The time string in format <code>TIME_FORMAT</code>.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>time</code> <p>datetime.time: The time.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If the time_str does not match the TIME_FORMAT`.</p> Source code in <code>labridge\\common\\utils\\time.py</code> <pre><code>def str_to_time(time_str: str) -&gt; datetime.time:\n\tr\"\"\"\n\tTransform a formatted time string to `datetime.time`.\n\n\tArgs:\n\t\ttime_str (str): The time string in format `TIME_FORMAT`.\n\n\tReturns:\n\t\tdatetime.time: The time.\n\n\tRaises:\n\t\tValueError: If the time_str does not match the TIME_FORMAT`.\n\t\"\"\"\n\thour_minute_second = time_str.split(\":\")\n\n\ttry:\n\t\tmy_time = datetime.time(\n\t\t\thour=int(hour_minute_second[0]),\n\t\t\tminute=int(hour_minute_second[1]),\n\t\t\tsecond=int(hour_minute_second[2]),\n\t\t)\n\t\treturn my_time\n\texcept Exception:\n\t\traise ValueError(f\"The input time string {time_str} is invalid.\")\n</code></pre>"},{"location":"code_docs/func_modules/instrument/prompt/llm_instrument_choice_select/","title":"Llm instrument choice select","text":""},{"location":"code_docs/func_modules/instrument/prompt/llm_instrument_choice_select/#labridge.func_modules.instrument.prompt.llm_instrument_choice_select","title":"<code>labridge.func_modules.instrument.prompt.llm_instrument_choice_select</code>","text":""},{"location":"code_docs/func_modules/instrument/retrieve/instrument_retriever/","title":"Instrument retriever","text":""},{"location":"code_docs/func_modules/instrument/retrieve/instrument_retriever/#labridge.func_modules.instrument.retrieve.instrument_retriever","title":"<code>labridge.func_modules.instrument.retrieve.instrument_retriever</code>","text":""},{"location":"code_docs/func_modules/instrument/retrieve/instrument_retriever/#labridge.func_modules.instrument.retrieve.instrument_retriever.InstrumentRetriever","title":"<code>labridge.func_modules.instrument.retrieve.instrument_retriever.InstrumentRetriever</code>","text":"<p>This is a retriever retrieving in the instrument docs. Hybrid retrieving is used.</p> PARAMETER DESCRIPTION <code>llm</code> <p>The used large language model.</p> <p> TYPE: <code>LLM</code> DEFAULT: <code>None</code> </p> <code>embed_model</code> <p>The used embedding model.</p> <p> TYPE: <code>BaseEmbedding</code> DEFAULT: <code>None</code> </p> <code>similarity_top_k</code> <p>When retrieving in the vector store, the top-k relevant nodes will be selected.</p> <p> TYPE: <code>int</code> DEFAULT: <code>3</code> </p> <code>instrument_top_k</code> <p>When choosing among the instruments based on their descriptions, the top-k instruments will be used.</p> <p> TYPE: <code>int</code> DEFAULT: <code>2</code> </p> <code>final_top_k</code> <p>Finally, retrieving is conducted among the nodes belong to the corresponding instruments that are chose in the former content-based retrieving and instrument selection. The top-k nodes will be used as the finally retrieved nodes.</p> <p> TYPE: <code>int</code> DEFAULT: <code>3</code> </p> Source code in <code>labridge\\func_modules\\instrument\\retrieve\\instrument_retriever.py</code> <pre><code>class InstrumentRetriever:\n\tr\"\"\"\n\tThis is a retriever retrieving in the instrument docs.\n\tHybrid retrieving is used.\n\n\tArgs:\n\t\tllm (LLM): The used large language model.\n\t\tembed_model (BaseEmbedding): The used embedding model.\n\t\tsimilarity_top_k (int): When retrieving in the vector store, the top-k relevant nodes will be selected.\n\t\tinstrument_top_k (int): When choosing among the instruments based on their descriptions, the top-k instruments\n\t\t\twill be used.\n\t\tfinal_top_k (int): Finally, retrieving is conducted among the nodes belong to the corresponding instruments\n\t\t\tthat are chose in the former content-based retrieving and instrument selection. The top-k nodes will be\n\t\t\tused as the finally retrieved nodes.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tllm: LLM = None,\n\t\tembed_model: BaseEmbedding = None,\n\t\tsimilarity_top_k: int = 3,\n\t\tinstrument_top_k: int = 2,\n\t\tfinal_top_k: int = 3,\n\t\tchoice_batch_size: int = 8,\n\t):\n\t\tself.llm = llm or Settings.llm\n\t\tembed_model = embed_model or Settings.embed_model\n\t\tself.instrument_store = InstrumentStorage.from_default(embed_model=embed_model)\n\t\tself.vector_index_retriever = self.instrument_store.vector_index.as_retriever(\n\t\t\tsimilarity_top_k=similarity_top_k,\n\t\t)\n\t\tself._similarity_top_k = similarity_top_k\n\t\tself._instrument_top_k = instrument_top_k\n\t\tself._choice_batch_size = choice_batch_size\n\t\tself._final_top_k = final_top_k\n\t\tself._format_node_batch_fn = format_instrument_node_batch_fn\n\t\tself._choice_select_prompt = INSTRUMENT_CHOICE_SELECT_PROMPT\n\t\tself._parse_choice_select_answer_fn = default_parse_choice_select_answer_fn\n\n\tdef _retrieve_proper_instrument(self, retrieve_items: str) -&gt; List[str]:\n\t\tr\"\"\"\n\t\tUse LLM to select the proper instruments based on their description.\n\n\t\tArgs:\n\t\t\tretrieve_items (str): The things to be retrieved.\n\n\t\tReturns:\n\t\t\tList[str]:\n\t\t\t\tThe retrieved node_ids.\n\t\t\"\"\"\n\t\tinstrument_ids = self.instrument_store.get_all_instruments()\n\t\tdsc_nodes = self.instrument_store.get_nodes(node_ids=instrument_ids)\n\n\t\tall_nodes: List[BaseNode] = []\n\t\tall_relevances: List[float] = []\n\n\t\tfor idx in range(0, len(dsc_nodes), self._choice_batch_size):\n\t\t\tnodes = dsc_nodes[idx: idx + self._choice_batch_size]\n\t\t\tfmt_batch_str = self._format_node_batch_fn(nodes)\n\t\t\tllm_response = self.llm.predict(\n\t\t\t\tself._choice_select_prompt,\n\t\t\t\tcontext_str=fmt_batch_str,\n\t\t\t\tquery_str=retrieve_items,\n\t\t\t)\n\n\t\t\tanswer_lines = llm_response.split(\"\\n\")\n\t\t\tvalid_lines = []\n\t\t\tfor answer_line in answer_lines:\n\t\t\t\tif len(answer_line) &gt; 4:\n\t\t\t\t\tvalid_lines.append(answer_line.strip())\n\t\t\tvalid_response = \"\\n\".join(valid_lines)\n\n\t\t\tchoices, relevances = self._parse_choice_select_answer_fn(valid_response, len(nodes), raise_error=True)\n\t\t\tchoice_indices = [c - 1 for c in choices]\n\n\t\t\tchoice_instruments = [nodes[ci] for ci in choice_indices]\n\n\t\t\tall_nodes.extend(choice_instruments)\n\t\t\tall_relevances.extend(relevances)\n\n\t\tzipped_list = list(zip(all_nodes, all_relevances))\n\t\tsorted_list = sorted(zipped_list, key=lambda x: x[1], reverse=True)\n\t\ttop_k_list = sorted_list[: self._instrument_top_k]\n\n\t\tselect_instrument_ids = [node.node_id for node, relevance in top_k_list]\n\t\treturn select_instrument_ids\n\n\tasync def _aretrieve_proper_instrument(self, retrieve_items: str):\n\t\tr\"\"\"\n\t\tAsynchronously select the proper instruments based on their description.\n\n\t\tArgs:\n\t\t\tretrieve_items (str): The things to be retrieved.\n\n\t\tReturns:\n\t\t\tList[str]:\n\t\t\t\tThe retrieved node_ids.\n\t\t\"\"\"\n\t\tinstrument_ids = self.instrument_store.get_all_instruments()\n\t\tdsc_nodes = self.instrument_store.get_nodes(node_ids=instrument_ids)\n\n\t\tall_nodes: List[BaseNode] = []\n\t\tall_relevances: List[float] = []\n\n\t\tfor idx in range(0, len(dsc_nodes), self._choice_batch_size):\n\t\t\tnodes = dsc_nodes[idx: idx + self._choice_batch_size]\n\t\t\tfmt_batch_str = self._format_node_batch_fn(nodes)\n\t\t\tllm_response = await self.llm.apredict(\n\t\t\t\tself._choice_select_prompt,\n\t\t\t\tcontext_str=fmt_batch_str,\n\t\t\t\tquery_str=retrieve_items,\n\t\t\t)\n\t\t\tchoices, relevances = self._parse_choice_select_answer_fn(llm_response, len(nodes))\n\t\t\tchoice_indices = [c - 1 for c in choices]\n\n\t\t\tchoice_instruments = [nodes[ci] for ci in choice_indices]\n\n\t\t\tall_nodes.extend(choice_instruments)\n\t\t\tall_relevances.extend(relevances)\n\n\t\tzipped_list = list(zip(all_nodes, all_relevances))\n\t\tsorted_list = sorted(zipped_list, key=lambda x: x[1], reverse=True)\n\t\ttop_k_list = sorted_list[: self._instrument_top_k]\n\n\t\tselect_instrument_ids = [node.node_id for node, relevance in top_k_list]\n\t\treturn select_instrument_ids\n\n\tdef set_retriever_top_k(self, similarity_top_k: int):\n\t\tr\"\"\" Set the top-k of the first content-based retrieving. \"\"\"\n\t\tself.vector_index_retriever._similarity_top_k = similarity_top_k\n\n\tdef set_retriever_node_ids(self, node_ids: Optional[List[str]] = None):\n\t\tr\"\"\" Confine the range of node_ids in retrieving. \"\"\"\n\t\tself.vector_index_retriever._node_ids = node_ids\n\n\tdef _retrieve_instrument_content_based(self, retrieve_items: str) -&gt; List[str]:\n\t\tr\"\"\"\n\t\tContent-based retrieving.\n\n\t\tArgs:\n\t\t\tretrieve_items (str): Item to be retrieved.\n\n\t\tReturns:\n\t\t\tList[str]: The ids of the instruments that the retrieved docs belong to.\n\t\t\"\"\"\n\t\tself.set_retriever_top_k(self._similarity_top_k)\n\t\tself.set_retriever_node_ids()\n\t\tcontent_nodes = self.vector_index_retriever.retrieve(retrieve_items)\n\n\t\tinstrument_ids = set()\n\t\t# TODO: To be modified\n\t\tfor node in content_nodes:\n\t\t\tinstrument_node = node.node.parent_node\n\t\t\tif instrument_node is not None:\n\t\t\t\tinstrument_ids.add(instrument_node.node_id)\n\t\t\telse:\n\t\t\t\tinstrument_ids.add(node.node_id)\n\t\treturn list(instrument_ids)\n\n\tasync def _aretrieve_instrument_content_based(self, retrieve_items: str) -&gt; List[str]:\n\t\tr\"\"\"\n\t\tAsynchronously content-based retrieving.\n\n\t\tArgs:\n\t\t\tretrieve_items (str): Item to be retrieved.\n\n\t\tReturns:\n\t\t\tList[str]: The ids of the instruments that the retrieved docs belong to.\n\t\t\"\"\"\n\t\tself.set_retriever_top_k(self._similarity_top_k)\n\t\tself.set_retriever_node_ids()\n\t\tcontent_nodes = await self.vector_index_retriever.aretrieve(retrieve_items)\n\n\t\tinstrument_ids = set()\n\t\t# TODO: To be modified\n\t\tfor node in content_nodes:\n\t\t\tinstrument_node = node.node.parent_node\n\t\t\tif instrument_node is not None:\n\t\t\t\tinstrument_ids.add(instrument_node.node_id)\n\t\t\telse:\n\t\t\t\tinstrument_ids.add(node.node_id)\n\t\treturn list(instrument_ids)\n\n\t@dispatcher.span\n\tdef retrieve(\n\t\tself,\n\t\titem_to_be_retrieved: str,\n\t) -&gt; List[NodeWithScore]:\n\t\tr\"\"\"\n\t\tThis tool is used to help the laboratory member to solve their encountered difficulties in their experiment,\n\t\tby retrieving in the documents of the lab's scientific instruments.\n\n\t\tyou could use this tool to suggest proper instruments to help him/her to overcome the difficulties,\n\t\tand provide comprehensive information about these instruments from the instrument documents\n\t\tincluding instruction manuals, operation specifications of scientific instruments.\n\n\t\tArgs:\n\t\t\titem_to_be_retrieved (str): The string to be retrieved relevant to the scientific instruments\n\n\t\tReturns:\n\t\t\tList[NodeWithScore]: The retrieved nodes.\n\t\t\t\tThe contents of these retrieved nodes will be presented as the output.\n\t\t\"\"\"\n\t\t# This docstring will be used as the tool description.\n\t\tdsc_instruments = self._retrieve_proper_instrument(retrieve_items=item_to_be_retrieved)\n\n\t\t# content_instruments = self._retrieve_instrument_content_based(retrieve_items=item_to_be_retrieved)\n\t\t# instrument_ids = list(set(dsc_instruments + content_instruments))\n\n\t\tinstrument_ids = dsc_instruments\n\n\t\tinstruments = self.instrument_store.get_nodes(node_ids=instrument_ids)\n\t\tretrieve_range = []\n\n\t\tretrieve_range.extend(instrument_ids)\n\t\tfor ins in instruments:\n\t\t\tdoc_nodes = ins.child_nodes\n\t\t\tif doc_nodes is not None:\n\t\t\t\tretrieve_range.extend([node.node_id for node in doc_nodes])\n\n\t\tself.set_retriever_top_k(self._final_top_k)\n\t\tself.set_retriever_node_ids(node_ids=retrieve_range)\n\t\tfinal_nodes = self.vector_index_retriever.retrieve(item_to_be_retrieved)\n\t\treturn final_nodes\n\n\tasync def aretrieve(\n\t\tself,\n\t\titem_to_be_retrieved: str,\n\t) -&gt; List[NodeWithScore]:\n\t\tr\"\"\"\n\t\tThis tool is used to retrieve in the documents of the lab's scientific instruments.\n\t\tThese documents include the instruction manuals, operation specifications of scientific instruments.\n\n\t\tArgs:\n\t\t\titem_to_be_retrieved (str): The string to be retrieved relevant to the scientific instruments\n\n\t\tReturns:\n\t\t\tList[NodeWithScore]: The retrieved nodes.\n\t\t\t\tThe contents of these retrieved nodes will be presented as the output.\n\t\t\"\"\"\n\t\t# This docstring will be used as the tool description.\n\t\tdsc_instruments = await self._aretrieve_proper_instrument(retrieve_items=item_to_be_retrieved)\n\t\t# content_instruments = await self._aretrieve_instrument_content_based(retrieve_items=item_to_be_retrieved)\n\t\t# instrument_ids = list(set(dsc_instruments + content_instruments))\n\n\t\tinstrument_ids = dsc_instruments\n\n\t\tinstruments = self.instrument_store.get_nodes(node_ids=instrument_ids)\n\t\tretrieve_range = []\n\n\t\tretrieve_range.extend(instrument_ids)\n\t\tfor ins in instruments:\n\t\t\tdoc_nodes = ins.child_nodes\n\t\t\tif doc_nodes is not None:\n\t\t\t\tretrieve_range.extend([node.node_id for node in doc_nodes])\n\n\t\tself.set_retriever_top_k(self._final_top_k)\n\t\tself.set_retriever_node_ids(node_ids=retrieve_range)\n\t\tfinal_nodes = await self.vector_index_retriever.aretrieve(item_to_be_retrieved)\n\t\treturn final_nodes\n</code></pre>"},{"location":"code_docs/func_modules/instrument/retrieve/instrument_retriever/#labridge.func_modules.instrument.retrieve.instrument_retriever.InstrumentRetriever.aretrieve","title":"<code>labridge.func_modules.instrument.retrieve.instrument_retriever.InstrumentRetriever.aretrieve(item_to_be_retrieved)</code>  <code>async</code>","text":"<p>This tool is used to retrieve in the documents of the lab's scientific instruments. These documents include the instruction manuals, operation specifications of scientific instruments.</p> PARAMETER DESCRIPTION <code>item_to_be_retrieved</code> <p>The string to be retrieved relevant to the scientific instruments</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>List[NodeWithScore]</code> <p>List[NodeWithScore]: The retrieved nodes. The contents of these retrieved nodes will be presented as the output.</p> Source code in <code>labridge\\func_modules\\instrument\\retrieve\\instrument_retriever.py</code> <pre><code>async def aretrieve(\n\tself,\n\titem_to_be_retrieved: str,\n) -&gt; List[NodeWithScore]:\n\tr\"\"\"\n\tThis tool is used to retrieve in the documents of the lab's scientific instruments.\n\tThese documents include the instruction manuals, operation specifications of scientific instruments.\n\n\tArgs:\n\t\titem_to_be_retrieved (str): The string to be retrieved relevant to the scientific instruments\n\n\tReturns:\n\t\tList[NodeWithScore]: The retrieved nodes.\n\t\t\tThe contents of these retrieved nodes will be presented as the output.\n\t\"\"\"\n\t# This docstring will be used as the tool description.\n\tdsc_instruments = await self._aretrieve_proper_instrument(retrieve_items=item_to_be_retrieved)\n\t# content_instruments = await self._aretrieve_instrument_content_based(retrieve_items=item_to_be_retrieved)\n\t# instrument_ids = list(set(dsc_instruments + content_instruments))\n\n\tinstrument_ids = dsc_instruments\n\n\tinstruments = self.instrument_store.get_nodes(node_ids=instrument_ids)\n\tretrieve_range = []\n\n\tretrieve_range.extend(instrument_ids)\n\tfor ins in instruments:\n\t\tdoc_nodes = ins.child_nodes\n\t\tif doc_nodes is not None:\n\t\t\tretrieve_range.extend([node.node_id for node in doc_nodes])\n\n\tself.set_retriever_top_k(self._final_top_k)\n\tself.set_retriever_node_ids(node_ids=retrieve_range)\n\tfinal_nodes = await self.vector_index_retriever.aretrieve(item_to_be_retrieved)\n\treturn final_nodes\n</code></pre>"},{"location":"code_docs/func_modules/instrument/retrieve/instrument_retriever/#labridge.func_modules.instrument.retrieve.instrument_retriever.InstrumentRetriever.retrieve","title":"<code>labridge.func_modules.instrument.retrieve.instrument_retriever.InstrumentRetriever.retrieve(item_to_be_retrieved)</code>","text":"<p>This tool is used to help the laboratory member to solve their encountered difficulties in their experiment, by retrieving in the documents of the lab's scientific instruments.</p> <p>you could use this tool to suggest proper instruments to help him/her to overcome the difficulties, and provide comprehensive information about these instruments from the instrument documents including instruction manuals, operation specifications of scientific instruments.</p> PARAMETER DESCRIPTION <code>item_to_be_retrieved</code> <p>The string to be retrieved relevant to the scientific instruments</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>List[NodeWithScore]</code> <p>List[NodeWithScore]: The retrieved nodes. The contents of these retrieved nodes will be presented as the output.</p> Source code in <code>labridge\\func_modules\\instrument\\retrieve\\instrument_retriever.py</code> <pre><code>@dispatcher.span\ndef retrieve(\n\tself,\n\titem_to_be_retrieved: str,\n) -&gt; List[NodeWithScore]:\n\tr\"\"\"\n\tThis tool is used to help the laboratory member to solve their encountered difficulties in their experiment,\n\tby retrieving in the documents of the lab's scientific instruments.\n\n\tyou could use this tool to suggest proper instruments to help him/her to overcome the difficulties,\n\tand provide comprehensive information about these instruments from the instrument documents\n\tincluding instruction manuals, operation specifications of scientific instruments.\n\n\tArgs:\n\t\titem_to_be_retrieved (str): The string to be retrieved relevant to the scientific instruments\n\n\tReturns:\n\t\tList[NodeWithScore]: The retrieved nodes.\n\t\t\tThe contents of these retrieved nodes will be presented as the output.\n\t\"\"\"\n\t# This docstring will be used as the tool description.\n\tdsc_instruments = self._retrieve_proper_instrument(retrieve_items=item_to_be_retrieved)\n\n\t# content_instruments = self._retrieve_instrument_content_based(retrieve_items=item_to_be_retrieved)\n\t# instrument_ids = list(set(dsc_instruments + content_instruments))\n\n\tinstrument_ids = dsc_instruments\n\n\tinstruments = self.instrument_store.get_nodes(node_ids=instrument_ids)\n\tretrieve_range = []\n\n\tretrieve_range.extend(instrument_ids)\n\tfor ins in instruments:\n\t\tdoc_nodes = ins.child_nodes\n\t\tif doc_nodes is not None:\n\t\t\tretrieve_range.extend([node.node_id for node in doc_nodes])\n\n\tself.set_retriever_top_k(self._final_top_k)\n\tself.set_retriever_node_ids(node_ids=retrieve_range)\n\tfinal_nodes = self.vector_index_retriever.retrieve(item_to_be_retrieved)\n\treturn final_nodes\n</code></pre>"},{"location":"code_docs/func_modules/instrument/retrieve/instrument_retriever/#labridge.func_modules.instrument.retrieve.instrument_retriever.InstrumentRetriever.set_retriever_node_ids","title":"<code>labridge.func_modules.instrument.retrieve.instrument_retriever.InstrumentRetriever.set_retriever_node_ids(node_ids=None)</code>","text":"<p>Confine the range of node_ids in retrieving.</p> Source code in <code>labridge\\func_modules\\instrument\\retrieve\\instrument_retriever.py</code> <pre><code>def set_retriever_node_ids(self, node_ids: Optional[List[str]] = None):\n\tr\"\"\" Confine the range of node_ids in retrieving. \"\"\"\n\tself.vector_index_retriever._node_ids = node_ids\n</code></pre>"},{"location":"code_docs/func_modules/instrument/retrieve/instrument_retriever/#labridge.func_modules.instrument.retrieve.instrument_retriever.InstrumentRetriever.set_retriever_top_k","title":"<code>labridge.func_modules.instrument.retrieve.instrument_retriever.InstrumentRetriever.set_retriever_top_k(similarity_top_k)</code>","text":"<p>Set the top-k of the first content-based retrieving.</p> Source code in <code>labridge\\func_modules\\instrument\\retrieve\\instrument_retriever.py</code> <pre><code>def set_retriever_top_k(self, similarity_top_k: int):\n\tr\"\"\" Set the top-k of the first content-based retrieving. \"\"\"\n\tself.vector_index_retriever._similarity_top_k = similarity_top_k\n</code></pre>"},{"location":"code_docs/func_modules/instrument/retrieve/instrument_retriever/#labridge.func_modules.instrument.retrieve.instrument_retriever.format_instrument_node_batch_fn","title":"<code>labridge.func_modules.instrument.retrieve.instrument_retriever.format_instrument_node_batch_fn(instrument_nodes)</code>","text":"<p>This function returns a text containing the indices and descriptions of a batch of instruments. LLM will select from these instruments according to this text.</p> PARAMETER DESCRIPTION <code>instrument_nodes</code> <p>The nodes stored in the <code>InstrumentStorage</code>, containing the instrument name and description.</p> <p> TYPE: <code>List[BaseNode]</code> </p> RETURNS DESCRIPTION <code>str</code> <p>The generated text.</p> <p> TYPE: <code>str</code> </p> Source code in <code>labridge\\func_modules\\instrument\\retrieve\\instrument_retriever.py</code> <pre><code>def format_instrument_node_batch_fn(instrument_nodes: List[BaseNode]) -&gt; str:\n\tr\"\"\"\n\tThis function returns a text containing the indices and descriptions of a batch of instruments.\n\tLLM will select from these instruments according to this text.\n\n\tArgs:\n\t\tinstrument_nodes (List[BaseNode]): The nodes stored in the `InstrumentStorage`,\n\t\t\tcontaining the instrument name and description.\n\n\tReturns:\n\t\tstr: The generated text.\n\t\"\"\"\n\ttexts = []\n\tfor idx in range(len(instrument_nodes)):\n\t\tnumber = idx + 1\n\t\ttexts.append(\n\t\t\tf\"Instrument {number}:\\n\"\n\t\t\tf\"{instrument_nodes[idx].get_content(metadata_mode=MetadataMode.LLM)}\"\n\t\t)\n\treturn \"\\n\\n\".join(texts)\n</code></pre>"},{"location":"code_docs/func_modules/instrument/store/instrument_store/","title":"Instrument store","text":""},{"location":"code_docs/func_modules/instrument/store/instrument_store/#labridge.func_modules.instrument.store.instrument_store","title":"<code>labridge.func_modules.instrument.store.instrument_store</code>","text":""},{"location":"code_docs/func_modules/instrument/store/instrument_store/#labridge.func_modules.instrument.store.instrument_store.InstrumentStorage","title":"<code>labridge.func_modules.instrument.store.instrument_store.InstrumentStorage</code>","text":"<p>               Bases: <code>object</code></p> <p>This class is used for the storage of instrument documents.</p> PARAMETER DESCRIPTION <code>vector_index</code> <p>The vector database that stores the instrument documents.</p> <p> TYPE: <code>VectorStoreIndex</code> DEFAULT: <code>None</code> </p> <code>persist_dir</code> <p>The save path of the vector_index.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>embed_model</code> <p>The used embedding model.</p> <p> TYPE: <code>BaseEmbedding</code> DEFAULT: <code>None</code> </p> Source code in <code>labridge\\func_modules\\instrument\\store\\instrument_store.py</code> <pre><code>class InstrumentStorage(object):\n\tr\"\"\"\n\tThis class is used for the storage of instrument documents.\n\n\tArgs:\n\t\tvector_index (VectorStoreIndex): The vector database that stores the instrument documents.\n\t\tpersist_dir (str): The save path of the vector_index.\n\t\tembed_model (BaseEmbedding): The used embedding model.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tvector_index: VectorStoreIndex = None,\n\t\tpersist_dir: str = None,\n\t\tembed_model: BaseEmbedding = None\n\t):\n\t\troot = Path(__file__)\n\t\tfor i in range(5):\n\t\t\troot = root.parent\n\t\tself.root = root\n\t\tself.vector_index = vector_index\n\t\tself.vector_index.set_index_id(INSTRUMENT_VECTOR_INDEX_ID)\n\t\tself.embed_model = embed_model\n\t\tself.persist_dir = persist_dir or self._default_persist_dir()\n\t\tself.instrument_ware_house_dir = self._default_warehouse_dir()\n\n\tdef _default_persist_dir(self) -&gt; str:\n\t\tr\"\"\" Return the default save directory of the instrument vector index. \"\"\"\n\t\treturn str(self.root / DEFAULT_INSTRUMENT_VECTOR_PERSIST_DIR)\n\n\tdef _default_warehouse_dir(self) -&gt; str:\n\t\tr\"\"\" Returns the default save directory of the instrument documents. \"\"\"\n\t\treturn str(self.root / DEFAULT_INSTRUMENT_WAREHOUSE_DIR)\n\n\t@classmethod\n\tdef from_storage(\n\t\tcls,\n\t\tpersist_dir: str,\n\t\tembed_model: BaseEmbedding,\n\t):\n\t\tr\"\"\"\n\t\tConstruct from an existing storage.\n\n\t\tArgs:\n\t\t\tpersist_dir (str): The persis_dir of an existing InstrumentStorage.\n\t\t\tembed_model (BaseEmbedding): The used embedding model.\n\n\t\tReturns:\n\t\t\tInstrumentStorage: The loaded storage.\n\t\t\"\"\"\n\t\tvector_storage_context = StorageContext.from_defaults(persist_dir=persist_dir)\n\t\tvector_index = load_index_from_storage(\n\t\t\tstorage_context=vector_storage_context,\n\t\t\tindex_id=INSTRUMENT_VECTOR_INDEX_ID,\n\t\t\tembed_model=embed_model,\n\t\t)\n\t\treturn cls(\n\t\t\tvector_index=vector_index,\n\t\t\tpersist_dir=persist_dir,\n\t\t)\n\n\t@classmethod\n\tdef from_default(\n\t\tcls,\n\t\tembed_model: BaseEmbedding = None,\n\t):\n\t\tr\"\"\"\n\t\tLoad the default instrument storage.\n\n\t\tArgs:\n\t\t\tembed_model (BaseEmbedding): The used embedding model.\n\n\t\tReturns:\n\t\t\tInstrumentStorage: The loaded storage.\n\t\t\"\"\"\n\t\troot = Path(__file__)\n\t\tfor i in range(5):\n\t\t\troot = root.parent\n\t\tpersist_dir = str(root / DEFAULT_INSTRUMENT_VECTOR_PERSIST_DIR)\n\n\t\tembed_model = embed_model or Settings.embed_model\n\t\tfs = fsspec.filesystem(\"file\")\n\t\tif fs.exists(persist_dir):\n\t\t\treturn cls.from_storage(\n\t\t\t\tpersist_dir=persist_dir,\n\t\t\t\tembed_model=embed_model,\n\t\t\t)\n\t\troot_node = TextNode(\n\t\t\ttext=\"root node for the instruments.\",\n\t\t\tid_=INSTRUMENT_ROOT_NODE_NAME\n\t\t)\n\t\tnodes = [root_node]\n\t\tvector_index = VectorStoreIndex(\n\t\t\tnodes=nodes,\n\t\t\tembed_model=embed_model,\n\t\t)\n\n\t\treturn cls(\n\t\t\tvector_index=vector_index,\n\t\t\tpersist_dir=persist_dir,\n\t\t\tembed_model=embed_model,\n\t\t)\n\n\tdef _add_instrument_docs_to_warehouse(\n\t\tself,\n\t\tinstrument_id: str,\n\t\tinstrument_doc_paths: List[str],\n\t) -&gt; List[str]:\n\t\tr\"\"\"\n\t\tStore the instrument documents in the instrument warehouse.\n\n\t\tArgs:\n\t\t\tinstrument_id (str): The instrument name.\n\t\t\tinstrument_doc_paths (InstrumentStorage): The file paths of the instrument's documents.\n\n\t\tReturns:\n\t\t\tList[str]: The file paths of the stored instrument documents\n\t\t\"\"\"\n\t\tfs = fsspec.filesystem(\"file\")\n\t\twarehouse_dir = self.root / DEFAULT_INSTRUMENT_WAREHOUSE_DIR\n\t\tinstrument_dir = warehouse_dir / instrument_id\n\n\t\tif not fs.exists(str(instrument_dir)):\n\t\t\tfs.makedirs(str(instrument_dir))\n\n\t\tfor doc_path in instrument_doc_paths:\n\t\t\tif not fs.exists(doc_path):\n\t\t\t\traise ValueError(f\"Error: {doc_path} do not exist!\")\n\n\t\tstore_paths = []\n\t\tfor doc_path in instrument_doc_paths:\n\t\t\tfs.cp(doc_path, str(instrument_dir))\n\t\t\tdoc_name = Path(doc_path).name\n\t\t\tstore_paths.append(\n\t\t\t\tstr(instrument_dir / doc_name)\n\t\t\t)\n\t\treturn store_paths\n\n\tdef _default_vector_transformations(self) -&gt; List[TransformComponent]:\n\t\tr\"\"\" Default transformations of the vector index. \"\"\"\n\t\treturn [SentenceSplitter(chunk_size=1024, chunk_overlap=256, include_metadata=True), ]\n\n\tdef get_nodes(self, node_ids: List[str]) -&gt; List[BaseNode]:\n\t\tr\"\"\"\n\t\tGet the nodes according to node_ids.\n\n\t\tArgs:\n\t\t\tnode_ids (List[str]): The node ids.\n\n\t\tReturns:\n\t\t\tList[BaseNode]: The corresponding nodes in the vector index.\n\n\t\tRaises:\n\t\t\tValueError: If any node_id does not exist in the vector index.\n\t\t\"\"\"\n\t\treturn self.vector_index.docstore.get_nodes(node_ids=node_ids)\n\n\tdef _get_node(self, node_id: str) -&gt; BaseNode:\n\t\tr\"\"\" get node from the vector index \"\"\"\n\t\treturn self.vector_index.docstore.get_node(node_id)\n\n\tdef _update_node(\n\t\tself,\n\t\tnode_id: str,\n\t\tnode: BaseNode,\n\t):\n\t\tr\"\"\" update node in vector index \"\"\"\n\t\tself.vector_index.delete_nodes([node_id])\n\t\tself.vector_index.insert_nodes([node])\n\n\tdef get_all_instruments(self) -&gt; List[str]:\n\t\tr\"\"\"\n\t\tGet all instrument ids.\n\n\t\tReturns:\n\t\t\tList[str]: All instrument ids.\n\t\t\"\"\"\n\t\troot_node = self._get_node(node_id=INSTRUMENT_ROOT_NODE_NAME)\n\t\tinstrument_list = root_node.child_nodes or []\n\t\tinstrument_ids = [ins.node_id for ins in instrument_list]\n\t\treturn instrument_ids\n\n\tdef add_instrument(\n\t\tself,\n\t\tinstrument_id: str,\n\t\tinstrument_description: str,\n\t\tinstrument_doc_paths: List[str],\n\t\tsuper_user_ids: List[str],\n\t):\n\t\tr\"\"\"\n\t\tAdd a new instrument to storage.\n\n\t\t1. Add a text node containing the instrument id and description, and add it to the root_node's children.\n\t\t2. Add the instrument document nodes as the children of the instrument node.\n\n\t\tArgs:\n\t\t\tinstrument_id (str): The instrument name.\n\t\t\tinstrument_description (str): The instrument description.\n\t\t\tinstrument_doc_paths (List[str]): The file paths of the instrument's documents.\n\t\t\tsuper_user_ids (List[str]): The supe-users of the instrument.\n\t\t\"\"\"\n\t\t# Add to instrument manager\n\t\tmanager = InstrumentSuperUserManager()\n\t\tmanager.add_instrument(\n\t\t\tinstrument_id=instrument_id,\n\t\t\tsuper_users=super_user_ids,\n\t\t)\n\t\t# add instrument node to root node.\n\t\troot_node = self._get_node(node_id=INSTRUMENT_ROOT_NODE_NAME)\n\t\tprint(\"root_node childs: \", root_node.child_nodes)\n\t\tinstrument_list = root_node.child_nodes or []\n\n\t\tinstrument_node = TextNode(\n\t\t\ttext=instrument_description,\n\t\t\tid_=instrument_id,\n\t\t)\n\t\tinstrument_list.append(\n\t\t\tRelatedNodeInfo(node_id=instrument_node.node_id)\n\t\t)\n\t\troot_node.relationships[NodeRelationship.CHILD] = instrument_list\n\t\tself._update_node(node_id=INSTRUMENT_ROOT_NODE_NAME, node=root_node)\n\n\t\tself.vector_index.insert_nodes(nodes=[instrument_node])\n\n\t\tself.add_instrument_doc(\n\t\t\tinstrument_id=instrument_id,\n\t\t\tdoc_path=instrument_doc_paths,\n\t\t)\n\n\tdef add_instrument_doc(\n\t\tself,\n\t\tinstrument_id: str,\n\t\tdoc_path: Union[str, List[str]]\n\t):\n\t\tr\"\"\"\n\t\tAdd documents to an instrument's docs.\n\n\t\tArgs:\n\t\t\tinstrument_id (str): The instrument name.\n\t\t\tdoc_path (Union[str, List[str]]): New documents of the instrument.\n\t\t\"\"\"\n\t\tinstrument_node = self._get_node(node_id=instrument_id)\n\t\tif not isinstance(doc_path, list):\n\t\t\tdoc_path = [doc_path]\n\n\t\tif len(doc_path) &lt; 1:\n\t\t\treturn\n\n\t\tpath_list = self._add_instrument_docs_to_warehouse(\n\t\t\tinstrument_id=instrument_id,\n\t\t\tinstrument_doc_paths=doc_path,\n\t\t)\n\n\t\t# read the docs.\n\t\treader = SimpleDirectoryReader(\n\t\t\tinput_files=path_list,\n\t\t\tfile_metadata=instrument_get_file_metadata,\n\t\t\tfilename_as_id=True,\n\t\t\trecursive=True,\n\t\t)\n\t\tdocuments = reader.load_data()\n\n\t\tfor doc in documents:\n\t\t\tself.vector_index.docstore.set_document_hash(doc.get_doc_id(), doc.hash)\n\n\t\t# chunk to nodes.\n\t\tdoc_nodes = run_transformations(nodes=documents, transformations=self._default_vector_transformations(), )\n\n\t\tchild_nodes = instrument_node.child_nodes or []\n\t\tfor doc_node in doc_nodes:\n\t\t\tchild_nodes.append(RelatedNodeInfo(node_id=doc_node.node_id))\n\t\t\tdoc_node.relationships[NodeRelationship.PARENT] = RelatedNodeInfo(node_id=instrument_id)\n\n\t\tinstrument_node.relationships[NodeRelationship.CHILD] = child_nodes\n\n\t\tself._update_node(node_id=instrument_id, node=instrument_node)\n\t\tself.vector_index.insert_nodes(nodes=doc_nodes)\n\n\tdef delete_instrument_doc(\n\t\tself,\n\t\tinstrument_id: str,\n\t\tdoc_rel_path: Union[str, List[str]],\n\t):\n\t\tr\"\"\"\n\t\tDelete specific docs from the instrument storage and warehouse according to the relative path of the document.\n\n\t\tArgs:\n\t\t\tinstrument_id (str): The instrument name.\n\t\t\tdoc_rel_path (str): The document path relative to root.\n\t\t\"\"\"\n\t\tinstrument_node = self._get_node(node_id=instrument_id)\n\t\tchild_node_list = instrument_node.child_nodes\n\n\t\tif not isinstance(doc_rel_path, list):\n\t\t\tdoc_rel_path = [doc_rel_path]\n\n\t\tdelete_node_ids = []\n\t\tfor child_node in child_node_list:\n\t\t\tnode_id = child_node.node_id\n\t\t\tdoc_node = self._get_node(node_id=node_id)\n\t\t\tif doc_node.metadata[INSTRUMENT_FILE_PATH_KEY] in doc_rel_path:\n\t\t\t\tdelete_node_ids.append(node_id)\n\t\t\t\tchild_node_list.remove(child_node)\n\n\t\tinstrument_node.relationships[NodeRelationship.CHILD] = child_node_list\n\t\tself._update_node(node_id=instrument_id, node=instrument_node)\n\t\tself.vector_index.delete_nodes(node_ids=delete_node_ids)\n\n\t\tfs = fsspec.filesystem(\"file\")\n\t\tfor rel_path in doc_rel_path:\n\t\t\tabs_path = str(self.root / rel_path)\n\t\t\tfs.rm(abs_path)\n\n\tdef update_instrument_doc(\n\t\tself,\n\t\tinstrument_id: str,\n\t\tinstrument_doc_name: str,\n\t\tnew_doc_path: str,\n\t):\n\t\tr\"\"\"\n\t\tUpdate an instrument document with a new document.\n\n\t\tArgs:\n\t\t\tinstrument_id (str): The instrument name.\n\t\t\tinstrument_doc_name (str): The old instrument document name.\n\t\t\tnew_doc_path (str): The path of the new document.\n\t\t\"\"\"\n\t\told_doc_path = Path(DEFAULT_INSTRUMENT_WAREHOUSE_DIR) / instrument_doc_name\n\t\told_doc_path = str(old_doc_path)\n\n\t\tself.delete_instrument_doc(\n\t\t\tinstrument_id=instrument_id,\n\t\t\tdoc_rel_path=old_doc_path,\n\t\t)\n\t\tself.add_instrument_doc(\n\t\t\tinstrument_id=instrument_id,\n\t\t\tdoc_path=new_doc_path,\n\t\t)\n\n\tdef persist(self, persist_dir: str = None):\n\t\tr\"\"\" Save the storage. \"\"\"\n\t\tpersist_dir = persist_dir or self.persist_dir\n\t\tfs = fsspec.filesystem(\"file\")\n\t\tif not fs.exists(persist_dir):\n\t\t\tfs.makedirs(persist_dir)\n\t\tself.vector_index.storage_context.persist(persist_dir=persist_dir)\n</code></pre>"},{"location":"code_docs/func_modules/instrument/store/instrument_store/#labridge.func_modules.instrument.store.instrument_store.InstrumentStorage.add_instrument","title":"<code>labridge.func_modules.instrument.store.instrument_store.InstrumentStorage.add_instrument(instrument_id, instrument_description, instrument_doc_paths, super_user_ids)</code>","text":"<p>Add a new instrument to storage.</p> <ol> <li>Add a text node containing the instrument id and description, and add it to the root_node's children.</li> <li>Add the instrument document nodes as the children of the instrument node.</li> </ol> PARAMETER DESCRIPTION <code>instrument_id</code> <p>The instrument name.</p> <p> TYPE: <code>str</code> </p> <code>instrument_description</code> <p>The instrument description.</p> <p> TYPE: <code>str</code> </p> <code>instrument_doc_paths</code> <p>The file paths of the instrument's documents.</p> <p> TYPE: <code>List[str]</code> </p> <code>super_user_ids</code> <p>The supe-users of the instrument.</p> <p> TYPE: <code>List[str]</code> </p> Source code in <code>labridge\\func_modules\\instrument\\store\\instrument_store.py</code> <pre><code>def add_instrument(\n\tself,\n\tinstrument_id: str,\n\tinstrument_description: str,\n\tinstrument_doc_paths: List[str],\n\tsuper_user_ids: List[str],\n):\n\tr\"\"\"\n\tAdd a new instrument to storage.\n\n\t1. Add a text node containing the instrument id and description, and add it to the root_node's children.\n\t2. Add the instrument document nodes as the children of the instrument node.\n\n\tArgs:\n\t\tinstrument_id (str): The instrument name.\n\t\tinstrument_description (str): The instrument description.\n\t\tinstrument_doc_paths (List[str]): The file paths of the instrument's documents.\n\t\tsuper_user_ids (List[str]): The supe-users of the instrument.\n\t\"\"\"\n\t# Add to instrument manager\n\tmanager = InstrumentSuperUserManager()\n\tmanager.add_instrument(\n\t\tinstrument_id=instrument_id,\n\t\tsuper_users=super_user_ids,\n\t)\n\t# add instrument node to root node.\n\troot_node = self._get_node(node_id=INSTRUMENT_ROOT_NODE_NAME)\n\tprint(\"root_node childs: \", root_node.child_nodes)\n\tinstrument_list = root_node.child_nodes or []\n\n\tinstrument_node = TextNode(\n\t\ttext=instrument_description,\n\t\tid_=instrument_id,\n\t)\n\tinstrument_list.append(\n\t\tRelatedNodeInfo(node_id=instrument_node.node_id)\n\t)\n\troot_node.relationships[NodeRelationship.CHILD] = instrument_list\n\tself._update_node(node_id=INSTRUMENT_ROOT_NODE_NAME, node=root_node)\n\n\tself.vector_index.insert_nodes(nodes=[instrument_node])\n\n\tself.add_instrument_doc(\n\t\tinstrument_id=instrument_id,\n\t\tdoc_path=instrument_doc_paths,\n\t)\n</code></pre>"},{"location":"code_docs/func_modules/instrument/store/instrument_store/#labridge.func_modules.instrument.store.instrument_store.InstrumentStorage.add_instrument_doc","title":"<code>labridge.func_modules.instrument.store.instrument_store.InstrumentStorage.add_instrument_doc(instrument_id, doc_path)</code>","text":"<p>Add documents to an instrument's docs.</p> PARAMETER DESCRIPTION <code>instrument_id</code> <p>The instrument name.</p> <p> TYPE: <code>str</code> </p> <code>doc_path</code> <p>New documents of the instrument.</p> <p> TYPE: <code>Union[str, List[str]]</code> </p> Source code in <code>labridge\\func_modules\\instrument\\store\\instrument_store.py</code> <pre><code>def add_instrument_doc(\n\tself,\n\tinstrument_id: str,\n\tdoc_path: Union[str, List[str]]\n):\n\tr\"\"\"\n\tAdd documents to an instrument's docs.\n\n\tArgs:\n\t\tinstrument_id (str): The instrument name.\n\t\tdoc_path (Union[str, List[str]]): New documents of the instrument.\n\t\"\"\"\n\tinstrument_node = self._get_node(node_id=instrument_id)\n\tif not isinstance(doc_path, list):\n\t\tdoc_path = [doc_path]\n\n\tif len(doc_path) &lt; 1:\n\t\treturn\n\n\tpath_list = self._add_instrument_docs_to_warehouse(\n\t\tinstrument_id=instrument_id,\n\t\tinstrument_doc_paths=doc_path,\n\t)\n\n\t# read the docs.\n\treader = SimpleDirectoryReader(\n\t\tinput_files=path_list,\n\t\tfile_metadata=instrument_get_file_metadata,\n\t\tfilename_as_id=True,\n\t\trecursive=True,\n\t)\n\tdocuments = reader.load_data()\n\n\tfor doc in documents:\n\t\tself.vector_index.docstore.set_document_hash(doc.get_doc_id(), doc.hash)\n\n\t# chunk to nodes.\n\tdoc_nodes = run_transformations(nodes=documents, transformations=self._default_vector_transformations(), )\n\n\tchild_nodes = instrument_node.child_nodes or []\n\tfor doc_node in doc_nodes:\n\t\tchild_nodes.append(RelatedNodeInfo(node_id=doc_node.node_id))\n\t\tdoc_node.relationships[NodeRelationship.PARENT] = RelatedNodeInfo(node_id=instrument_id)\n\n\tinstrument_node.relationships[NodeRelationship.CHILD] = child_nodes\n\n\tself._update_node(node_id=instrument_id, node=instrument_node)\n\tself.vector_index.insert_nodes(nodes=doc_nodes)\n</code></pre>"},{"location":"code_docs/func_modules/instrument/store/instrument_store/#labridge.func_modules.instrument.store.instrument_store.InstrumentStorage.delete_instrument_doc","title":"<code>labridge.func_modules.instrument.store.instrument_store.InstrumentStorage.delete_instrument_doc(instrument_id, doc_rel_path)</code>","text":"<p>Delete specific docs from the instrument storage and warehouse according to the relative path of the document.</p> PARAMETER DESCRIPTION <code>instrument_id</code> <p>The instrument name.</p> <p> TYPE: <code>str</code> </p> <code>doc_rel_path</code> <p>The document path relative to root.</p> <p> TYPE: <code>str</code> </p> Source code in <code>labridge\\func_modules\\instrument\\store\\instrument_store.py</code> <pre><code>def delete_instrument_doc(\n\tself,\n\tinstrument_id: str,\n\tdoc_rel_path: Union[str, List[str]],\n):\n\tr\"\"\"\n\tDelete specific docs from the instrument storage and warehouse according to the relative path of the document.\n\n\tArgs:\n\t\tinstrument_id (str): The instrument name.\n\t\tdoc_rel_path (str): The document path relative to root.\n\t\"\"\"\n\tinstrument_node = self._get_node(node_id=instrument_id)\n\tchild_node_list = instrument_node.child_nodes\n\n\tif not isinstance(doc_rel_path, list):\n\t\tdoc_rel_path = [doc_rel_path]\n\n\tdelete_node_ids = []\n\tfor child_node in child_node_list:\n\t\tnode_id = child_node.node_id\n\t\tdoc_node = self._get_node(node_id=node_id)\n\t\tif doc_node.metadata[INSTRUMENT_FILE_PATH_KEY] in doc_rel_path:\n\t\t\tdelete_node_ids.append(node_id)\n\t\t\tchild_node_list.remove(child_node)\n\n\tinstrument_node.relationships[NodeRelationship.CHILD] = child_node_list\n\tself._update_node(node_id=instrument_id, node=instrument_node)\n\tself.vector_index.delete_nodes(node_ids=delete_node_ids)\n\n\tfs = fsspec.filesystem(\"file\")\n\tfor rel_path in doc_rel_path:\n\t\tabs_path = str(self.root / rel_path)\n\t\tfs.rm(abs_path)\n</code></pre>"},{"location":"code_docs/func_modules/instrument/store/instrument_store/#labridge.func_modules.instrument.store.instrument_store.InstrumentStorage.from_default","title":"<code>labridge.func_modules.instrument.store.instrument_store.InstrumentStorage.from_default(embed_model=None)</code>  <code>classmethod</code>","text":"<p>Load the default instrument storage.</p> PARAMETER DESCRIPTION <code>embed_model</code> <p>The used embedding model.</p> <p> TYPE: <code>BaseEmbedding</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>InstrumentStorage</code> <p>The loaded storage.</p> Source code in <code>labridge\\func_modules\\instrument\\store\\instrument_store.py</code> <pre><code>@classmethod\ndef from_default(\n\tcls,\n\tembed_model: BaseEmbedding = None,\n):\n\tr\"\"\"\n\tLoad the default instrument storage.\n\n\tArgs:\n\t\tembed_model (BaseEmbedding): The used embedding model.\n\n\tReturns:\n\t\tInstrumentStorage: The loaded storage.\n\t\"\"\"\n\troot = Path(__file__)\n\tfor i in range(5):\n\t\troot = root.parent\n\tpersist_dir = str(root / DEFAULT_INSTRUMENT_VECTOR_PERSIST_DIR)\n\n\tembed_model = embed_model or Settings.embed_model\n\tfs = fsspec.filesystem(\"file\")\n\tif fs.exists(persist_dir):\n\t\treturn cls.from_storage(\n\t\t\tpersist_dir=persist_dir,\n\t\t\tembed_model=embed_model,\n\t\t)\n\troot_node = TextNode(\n\t\ttext=\"root node for the instruments.\",\n\t\tid_=INSTRUMENT_ROOT_NODE_NAME\n\t)\n\tnodes = [root_node]\n\tvector_index = VectorStoreIndex(\n\t\tnodes=nodes,\n\t\tembed_model=embed_model,\n\t)\n\n\treturn cls(\n\t\tvector_index=vector_index,\n\t\tpersist_dir=persist_dir,\n\t\tembed_model=embed_model,\n\t)\n</code></pre>"},{"location":"code_docs/func_modules/instrument/store/instrument_store/#labridge.func_modules.instrument.store.instrument_store.InstrumentStorage.from_storage","title":"<code>labridge.func_modules.instrument.store.instrument_store.InstrumentStorage.from_storage(persist_dir, embed_model)</code>  <code>classmethod</code>","text":"<p>Construct from an existing storage.</p> PARAMETER DESCRIPTION <code>persist_dir</code> <p>The persis_dir of an existing InstrumentStorage.</p> <p> TYPE: <code>str</code> </p> <code>embed_model</code> <p>The used embedding model.</p> <p> TYPE: <code>BaseEmbedding</code> </p> RETURNS DESCRIPTION <code>InstrumentStorage</code> <p>The loaded storage.</p> Source code in <code>labridge\\func_modules\\instrument\\store\\instrument_store.py</code> <pre><code>@classmethod\ndef from_storage(\n\tcls,\n\tpersist_dir: str,\n\tembed_model: BaseEmbedding,\n):\n\tr\"\"\"\n\tConstruct from an existing storage.\n\n\tArgs:\n\t\tpersist_dir (str): The persis_dir of an existing InstrumentStorage.\n\t\tembed_model (BaseEmbedding): The used embedding model.\n\n\tReturns:\n\t\tInstrumentStorage: The loaded storage.\n\t\"\"\"\n\tvector_storage_context = StorageContext.from_defaults(persist_dir=persist_dir)\n\tvector_index = load_index_from_storage(\n\t\tstorage_context=vector_storage_context,\n\t\tindex_id=INSTRUMENT_VECTOR_INDEX_ID,\n\t\tembed_model=embed_model,\n\t)\n\treturn cls(\n\t\tvector_index=vector_index,\n\t\tpersist_dir=persist_dir,\n\t)\n</code></pre>"},{"location":"code_docs/func_modules/instrument/store/instrument_store/#labridge.func_modules.instrument.store.instrument_store.InstrumentStorage.get_all_instruments","title":"<code>labridge.func_modules.instrument.store.instrument_store.InstrumentStorage.get_all_instruments()</code>","text":"<p>Get all instrument ids.</p> RETURNS DESCRIPTION <code>List[str]</code> <p>List[str]: All instrument ids.</p> Source code in <code>labridge\\func_modules\\instrument\\store\\instrument_store.py</code> <pre><code>def get_all_instruments(self) -&gt; List[str]:\n\tr\"\"\"\n\tGet all instrument ids.\n\n\tReturns:\n\t\tList[str]: All instrument ids.\n\t\"\"\"\n\troot_node = self._get_node(node_id=INSTRUMENT_ROOT_NODE_NAME)\n\tinstrument_list = root_node.child_nodes or []\n\tinstrument_ids = [ins.node_id for ins in instrument_list]\n\treturn instrument_ids\n</code></pre>"},{"location":"code_docs/func_modules/instrument/store/instrument_store/#labridge.func_modules.instrument.store.instrument_store.InstrumentStorage.get_nodes","title":"<code>labridge.func_modules.instrument.store.instrument_store.InstrumentStorage.get_nodes(node_ids)</code>","text":"<p>Get the nodes according to node_ids.</p> PARAMETER DESCRIPTION <code>node_ids</code> <p>The node ids.</p> <p> TYPE: <code>List[str]</code> </p> RETURNS DESCRIPTION <code>List[BaseNode]</code> <p>List[BaseNode]: The corresponding nodes in the vector index.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If any node_id does not exist in the vector index.</p> Source code in <code>labridge\\func_modules\\instrument\\store\\instrument_store.py</code> <pre><code>def get_nodes(self, node_ids: List[str]) -&gt; List[BaseNode]:\n\tr\"\"\"\n\tGet the nodes according to node_ids.\n\n\tArgs:\n\t\tnode_ids (List[str]): The node ids.\n\n\tReturns:\n\t\tList[BaseNode]: The corresponding nodes in the vector index.\n\n\tRaises:\n\t\tValueError: If any node_id does not exist in the vector index.\n\t\"\"\"\n\treturn self.vector_index.docstore.get_nodes(node_ids=node_ids)\n</code></pre>"},{"location":"code_docs/func_modules/instrument/store/instrument_store/#labridge.func_modules.instrument.store.instrument_store.InstrumentStorage.persist","title":"<code>labridge.func_modules.instrument.store.instrument_store.InstrumentStorage.persist(persist_dir=None)</code>","text":"<p>Save the storage.</p> Source code in <code>labridge\\func_modules\\instrument\\store\\instrument_store.py</code> <pre><code>def persist(self, persist_dir: str = None):\n\tr\"\"\" Save the storage. \"\"\"\n\tpersist_dir = persist_dir or self.persist_dir\n\tfs = fsspec.filesystem(\"file\")\n\tif not fs.exists(persist_dir):\n\t\tfs.makedirs(persist_dir)\n\tself.vector_index.storage_context.persist(persist_dir=persist_dir)\n</code></pre>"},{"location":"code_docs/func_modules/instrument/store/instrument_store/#labridge.func_modules.instrument.store.instrument_store.InstrumentStorage.update_instrument_doc","title":"<code>labridge.func_modules.instrument.store.instrument_store.InstrumentStorage.update_instrument_doc(instrument_id, instrument_doc_name, new_doc_path)</code>","text":"<p>Update an instrument document with a new document.</p> PARAMETER DESCRIPTION <code>instrument_id</code> <p>The instrument name.</p> <p> TYPE: <code>str</code> </p> <code>instrument_doc_name</code> <p>The old instrument document name.</p> <p> TYPE: <code>str</code> </p> <code>new_doc_path</code> <p>The path of the new document.</p> <p> TYPE: <code>str</code> </p> Source code in <code>labridge\\func_modules\\instrument\\store\\instrument_store.py</code> <pre><code>def update_instrument_doc(\n\tself,\n\tinstrument_id: str,\n\tinstrument_doc_name: str,\n\tnew_doc_path: str,\n):\n\tr\"\"\"\n\tUpdate an instrument document with a new document.\n\n\tArgs:\n\t\tinstrument_id (str): The instrument name.\n\t\tinstrument_doc_name (str): The old instrument document name.\n\t\tnew_doc_path (str): The path of the new document.\n\t\"\"\"\n\told_doc_path = Path(DEFAULT_INSTRUMENT_WAREHOUSE_DIR) / instrument_doc_name\n\told_doc_path = str(old_doc_path)\n\n\tself.delete_instrument_doc(\n\t\tinstrument_id=instrument_id,\n\t\tdoc_rel_path=old_doc_path,\n\t)\n\tself.add_instrument_doc(\n\t\tinstrument_id=instrument_id,\n\t\tdoc_path=new_doc_path,\n\t)\n</code></pre>"},{"location":"code_docs/func_modules/instrument/store/instrument_store/#labridge.func_modules.instrument.store.instrument_store.instrument_get_file_metadata","title":"<code>labridge.func_modules.instrument.store.instrument_store.instrument_get_file_metadata(file_path)</code>","text":"<p>Get the metadata of instrument doc nodes. This function will be used in the <code>SimpleDirectoryReader</code>.</p> PARAMETER DESCRIPTION <code>file_path</code> <p>The file path of a instrument document.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: These metadata will be recorded in each doc node:</p> <ul> <li>the path relative to the project root.</li> <li>the instrument id.</li> </ul> Source code in <code>labridge\\func_modules\\instrument\\store\\instrument_store.py</code> <pre><code>def instrument_get_file_metadata(file_path: str) -&gt; Dict[str, Any]:\n\tr\"\"\"\n\tGet the metadata of instrument doc nodes.\n\tThis function will be used in the `SimpleDirectoryReader`.\n\n\tArgs:\n\t\tfile_path (str): The file path of a instrument document.\n\n\tReturns:\n\t\tDict[str, Any]:\n\t\t\tThese metadata will be recorded in each doc node:\n\n\t\t\t- the path relative to the project root.\n\t\t\t- the instrument id.\n\t\"\"\"\n\troot = Path(__file__)\n\tfor i in range(5):\n\t\troot = root.parent\n\n\trel_path = Path(file_path).relative_to(root)\n\tinstrument_name = Path(file_path).parts[-2]\n\tmetadata = {\n\t\tINSTRUMENT_FILE_PATH_KEY: str(rel_path),\n\t\tINSTRUMENT_NAME_KEY: instrument_name\n\t}\n\treturn metadata\n</code></pre>"},{"location":"code_docs/func_modules/memory/base/","title":"Base","text":""},{"location":"code_docs/func_modules/memory/base/#labridge.func_modules.memory.base","title":"<code>labridge.func_modules.memory.base</code>","text":""},{"location":"code_docs/func_modules/memory/base/#labridge.func_modules.memory.base.LogBaseRetriever","title":"<code>labridge.func_modules.memory.base.LogBaseRetriever</code>","text":"<p>               Bases: <code>object</code></p> <p>This is the base class for log-type information retriever, such as chat history and experiment log.</p> <p>The attributes <code>memory</code> and <code>memory_vector_retriever</code> should be specified in the subclass, and they will be updated in the method <code>retrieve</code>.</p> PARAMETER DESCRIPTION <code>embed_model</code> <p>The used embedding model.</p> <p> TYPE: <code>BaseEmbedding</code> </p> <code>final_use_context</code> <p>Whether to use the context nodes of the retrieved nodes as the final results.</p> <p> TYPE: <code>bool</code> </p> <code>relevant_top_k</code> <p>The top-k relevant retrieved nodes will be used.</p> <p> TYPE: <code>int</code> </p> Note <p>The docstring of the Method <code>retrieve</code> will be used as the tool description of the corresponding retriever tool.</p> Source code in <code>labridge\\func_modules\\memory\\base.py</code> <pre><code>class LogBaseRetriever(object):\n\tr\"\"\"\n\tThis is the base class for log-type information retriever, such as chat history and experiment log.\n\n\tThe attributes `memory` and `memory_vector_retriever` should be specified in the subclass,\n\tand they will be updated in the method `retrieve`.\n\n\tArgs:\n\t\tembed_model (BaseEmbedding): The used embedding model.\n\t\tfinal_use_context (bool): Whether to use the context nodes of the retrieved nodes as the final results.\n\t\trelevant_top_k (int): The top-k relevant retrieved nodes will be used.\n\n\tNote:\n\t\tThe docstring of the Method `retrieve` will be used as the tool description of the corresponding\n\t\tretriever tool.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tembed_model: BaseEmbedding,\n\t\tfinal_use_context: bool,\n\t\trelevant_top_k: int,\n\t):\n\t\tself.memory = None\n\t\tself.memory_vector_retriever = None\n\t\tself.embed_model = embed_model or Settings.embed_model\n\t\tself.final_use_context = final_use_context\n\t\tself.relevant_top_k = relevant_top_k\n\n\tdef _parse_date(self, start_date_str: str, end_date_str: str) -&gt; List[str]:\n\t\tr\"\"\"\n\t\tGet the strings of dates that between the start date and the end date (including them).\n\n\t\tArgs:\n\t\t\tstart_date_str (str): The string of the start date in a specific format, specified in `common.utils.time`.\n\t\t\tend_date_str (str): The string of the end date.\n\n\t\tReturns:\n\t\t\"\"\"\n\t\treturn parse_date_list(\n\t\t\tstart_date_str=start_date_str,\n\t\t\tend_date_str=end_date_str,\n\t\t)\n\n\t@abstractmethod\n\tdef get_memory_vector_retriever(self) -&gt; VectorIndexRetriever:\n\t\tr\"\"\" Get the vector index retriever from the memory \"\"\"\n\n\t@abstractmethod\n\tdef get_memory_vector_index(self) -&gt; VectorStoreIndex:\n\t\tr\"\"\" Get the vector index \"\"\"\n\n\tdef get_date_filter(self, date_list: List[str]) -&gt; MetadataFilter:\n\t\tr\"\"\"\n\t\tReturn the MetadataFilter that filters nodes with dates in the date_list.\n\n\t\tArgs:\n\t\t\tdate_list (List[str]): The candidate date strings.\n\n\t\tReturns:\n\t\t\tMetadataFilter: The date filter.\n\t\t\"\"\"\n\t\tdate_filter = MetadataFilter(\n\t\t\tkey=LOG_DATE_NAME,\n\t\t\tvalue=date_list,\n\t\t\toperator=FilterOperator.ANY,\n\t\t)\n\t\treturn date_filter\n\n\tdef _log_node_filter(self) -&gt; MetadataFilter:\n\t\tr\"\"\"\n\t\tReturn the filter that filters `LOG_NODE_TYPE` nodes.\n\n\t\tReturns:\n\t\t\tThe node_type filter.\n\t\t\"\"\"\n\t\tlog_type_filter = MetadataFilter(\n\t\t\tkey=MEMORY_NODE_TYPE_NAME,\n\t\t\tvalue=LOG_NODE_TYPE,\n\t\t\toperator=FilterOperator.EQ,\n\t\t)\n\t\treturn log_type_filter\n\n\tdef sort_retrieved_nodes(\n\t\tself,\n\t\tmemory_nodes: List[NodeWithScore],\n\t\tdescending: bool = False,\n\t) -&gt; List[NodeWithScore]:\n\t\tr\"\"\"\n\t\tSort the retrieved nodes according datetime.\n\n\t\tArgs:\n\t\t\tmemory_nodes (List[NodeWithScore]): The retrieved nodes.\n\t\t\tdescending (bool): Sort in descending order. Defaults to False.\n\n\t\tReturns:\n\t\t\tList[NodeWithScore]: The sorted nodes.\n\t\t\"\"\"\n\t\tif len(memory_nodes) &lt; 1:\n\t\t\treturn []\n\t\tnodes_datetime = []\n\t\tfor node in memory_nodes:\n\t\t\tnode_date_str = node.node.metadata[LOG_DATE_NAME][0]\n\t\t\tnode_time_str = node.node.metadata[LOG_TIME_NAME][0]\n\t\t\tnodes_datetime.append(str_to_datetime(date_str=node_date_str, time_str=node_time_str))\n\n\t\tsorted_items = sorted(zip(memory_nodes, nodes_datetime), key=lambda x: x[1], reverse=descending)\n\t\tsorted_nodes, sorted_datetime = zip(*sorted_items)\n\t\treturn sorted_nodes\n\n\tdef _add_context(self, content_nodes: List[NodeWithScore]) -&gt; List[NodeWithScore]:\n\t\tr\"\"\"\n\t\tAdd the 1-hop context nodes of each content node and keep the QA time order.\n\t\tOnly the context nodes whose date is the same as the retrieved node will be added.\n\n\t\tArgs:\n\t\t\tcontent_nodes (List[NodeWithScore]): The retrieved nodes.\n\n\t\tReturns:\n\t\t\tList[NodeWithScore]: The final nodes including the context nodes.\n\t\t\"\"\"\n\t\texisting_ids = [node.node.node_id for node in content_nodes]\n\t\tfinal_nodes = []\n\t\tvector_index = self.get_memory_vector_index()\n\t\tfor node in content_nodes:\n\t\t\t# print(node.get_content())\n\t\t\tnode_date = node.node.metadata[LOG_DATE_NAME]\n\t\t\tprev_node_info = node.node.prev_node\n\t\t\tnext_node_info = node.node.next_node\n\t\t\tif prev_node_info is not None:\n\t\t\t\tprev_id = prev_node_info.node_id\n\t\t\t\tprev_node = vector_index.docstore.get_node(prev_id)\n\t\t\t\tif prev_id not in existing_ids and prev_node.metadata[LOG_DATE_NAME] == node_date:\n\t\t\t\t\texisting_ids.append(prev_id)\n\t\t\t\t\tfinal_nodes.append(NodeWithScore(node=prev_node))\n\n\t\t\tfinal_nodes.append(node)\n\n\t\t\tif next_node_info is not None:\n\t\t\t\tnext_id = next_node_info.node_id\n\t\t\t\tnext_node = vector_index.docstore.get_node(next_id)\n\t\t\t\tif next_id not in existing_ids and next_node.metadata[LOG_DATE_NAME] == node_date:\n\t\t\t\t\texisting_ids.append(next_id)\n\t\t\t\t\tfinal_nodes.append(NodeWithScore(node=next_node))\n\t\tfinal_nodes = self.sort_retrieved_nodes(memory_nodes=final_nodes)\n\t\treturn final_nodes\n\n\t@dispatcher.span\n\t@abstractmethod\n\tdef retrieve(\n\t\tself,\n\t\titem_to_be_retrieved: str,\n\t\tmemory_id: str,\n\t\tstart_date: str = None,\n\t\tend_date: str = None,\n\t\t**kwargs: Any,\n\t) -&gt; List[NodeWithScore]:\n\t\tr\"\"\"\n\t\tThe docstring of this Method will be used as the tool description of the corresponding retriever tool.\n\t\t\"\"\"\n\n\t@dispatcher.span\n\t@abstractmethod\n\tasync def aretrieve(\n\t\tself,\n\t\titem_to_be_retrieved: str,\n\t\tmemory_id: str,\n\t\tstart_date: str = None,\n\t\tend_date: str = None,\n\t\t**kwargs: Any,\n\t) -&gt; List[NodeWithScore]:\n\t\tr\"\"\"\n\t\tThe docstring of this Method will be used as the tool description of the corresponding retriever tool.\n\t\t\"\"\"\n</code></pre>"},{"location":"code_docs/func_modules/memory/base/#labridge.func_modules.memory.base.LogBaseRetriever.aretrieve","title":"<code>labridge.func_modules.memory.base.LogBaseRetriever.aretrieve(item_to_be_retrieved, memory_id, start_date=None, end_date=None, **kwargs)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>The docstring of this Method will be used as the tool description of the corresponding retriever tool.</p> Source code in <code>labridge\\func_modules\\memory\\base.py</code> <pre><code>@dispatcher.span\n@abstractmethod\nasync def aretrieve(\n\tself,\n\titem_to_be_retrieved: str,\n\tmemory_id: str,\n\tstart_date: str = None,\n\tend_date: str = None,\n\t**kwargs: Any,\n) -&gt; List[NodeWithScore]:\n\tr\"\"\"\n\tThe docstring of this Method will be used as the tool description of the corresponding retriever tool.\n\t\"\"\"\n</code></pre>"},{"location":"code_docs/func_modules/memory/base/#labridge.func_modules.memory.base.LogBaseRetriever.get_date_filter","title":"<code>labridge.func_modules.memory.base.LogBaseRetriever.get_date_filter(date_list)</code>","text":"<p>Return the MetadataFilter that filters nodes with dates in the date_list.</p> PARAMETER DESCRIPTION <code>date_list</code> <p>The candidate date strings.</p> <p> TYPE: <code>List[str]</code> </p> RETURNS DESCRIPTION <code>MetadataFilter</code> <p>The date filter.</p> <p> TYPE: <code>MetadataFilter</code> </p> Source code in <code>labridge\\func_modules\\memory\\base.py</code> <pre><code>def get_date_filter(self, date_list: List[str]) -&gt; MetadataFilter:\n\tr\"\"\"\n\tReturn the MetadataFilter that filters nodes with dates in the date_list.\n\n\tArgs:\n\t\tdate_list (List[str]): The candidate date strings.\n\n\tReturns:\n\t\tMetadataFilter: The date filter.\n\t\"\"\"\n\tdate_filter = MetadataFilter(\n\t\tkey=LOG_DATE_NAME,\n\t\tvalue=date_list,\n\t\toperator=FilterOperator.ANY,\n\t)\n\treturn date_filter\n</code></pre>"},{"location":"code_docs/func_modules/memory/base/#labridge.func_modules.memory.base.LogBaseRetriever.get_memory_vector_index","title":"<code>labridge.func_modules.memory.base.LogBaseRetriever.get_memory_vector_index()</code>  <code>abstractmethod</code>","text":"<p>Get the vector index</p> Source code in <code>labridge\\func_modules\\memory\\base.py</code> <pre><code>@abstractmethod\ndef get_memory_vector_index(self) -&gt; VectorStoreIndex:\n\tr\"\"\" Get the vector index \"\"\"\n</code></pre>"},{"location":"code_docs/func_modules/memory/base/#labridge.func_modules.memory.base.LogBaseRetriever.get_memory_vector_retriever","title":"<code>labridge.func_modules.memory.base.LogBaseRetriever.get_memory_vector_retriever()</code>  <code>abstractmethod</code>","text":"<p>Get the vector index retriever from the memory</p> Source code in <code>labridge\\func_modules\\memory\\base.py</code> <pre><code>@abstractmethod\ndef get_memory_vector_retriever(self) -&gt; VectorIndexRetriever:\n\tr\"\"\" Get the vector index retriever from the memory \"\"\"\n</code></pre>"},{"location":"code_docs/func_modules/memory/base/#labridge.func_modules.memory.base.LogBaseRetriever.retrieve","title":"<code>labridge.func_modules.memory.base.LogBaseRetriever.retrieve(item_to_be_retrieved, memory_id, start_date=None, end_date=None, **kwargs)</code>  <code>abstractmethod</code>","text":"<p>The docstring of this Method will be used as the tool description of the corresponding retriever tool.</p> Source code in <code>labridge\\func_modules\\memory\\base.py</code> <pre><code>@dispatcher.span\n@abstractmethod\ndef retrieve(\n\tself,\n\titem_to_be_retrieved: str,\n\tmemory_id: str,\n\tstart_date: str = None,\n\tend_date: str = None,\n\t**kwargs: Any,\n) -&gt; List[NodeWithScore]:\n\tr\"\"\"\n\tThe docstring of this Method will be used as the tool description of the corresponding retriever tool.\n\t\"\"\"\n</code></pre>"},{"location":"code_docs/func_modules/memory/base/#labridge.func_modules.memory.base.LogBaseRetriever.sort_retrieved_nodes","title":"<code>labridge.func_modules.memory.base.LogBaseRetriever.sort_retrieved_nodes(memory_nodes, descending=False)</code>","text":"<p>Sort the retrieved nodes according datetime.</p> PARAMETER DESCRIPTION <code>memory_nodes</code> <p>The retrieved nodes.</p> <p> TYPE: <code>List[NodeWithScore]</code> </p> <code>descending</code> <p>Sort in descending order. Defaults to False.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>List[NodeWithScore]</code> <p>List[NodeWithScore]: The sorted nodes.</p> Source code in <code>labridge\\func_modules\\memory\\base.py</code> <pre><code>def sort_retrieved_nodes(\n\tself,\n\tmemory_nodes: List[NodeWithScore],\n\tdescending: bool = False,\n) -&gt; List[NodeWithScore]:\n\tr\"\"\"\n\tSort the retrieved nodes according datetime.\n\n\tArgs:\n\t\tmemory_nodes (List[NodeWithScore]): The retrieved nodes.\n\t\tdescending (bool): Sort in descending order. Defaults to False.\n\n\tReturns:\n\t\tList[NodeWithScore]: The sorted nodes.\n\t\"\"\"\n\tif len(memory_nodes) &lt; 1:\n\t\treturn []\n\tnodes_datetime = []\n\tfor node in memory_nodes:\n\t\tnode_date_str = node.node.metadata[LOG_DATE_NAME][0]\n\t\tnode_time_str = node.node.metadata[LOG_TIME_NAME][0]\n\t\tnodes_datetime.append(str_to_datetime(date_str=node_date_str, time_str=node_time_str))\n\n\tsorted_items = sorted(zip(memory_nodes, nodes_datetime), key=lambda x: x[1], reverse=descending)\n\tsorted_nodes, sorted_datetime = zip(*sorted_items)\n\treturn sorted_nodes\n</code></pre>"},{"location":"code_docs/func_modules/memory/chat/chat_memory/","title":"Chat memory","text":""},{"location":"code_docs/func_modules/memory/chat/chat_memory/#labridge.func_modules.memory.chat.chat_memory","title":"<code>labridge.func_modules.memory.chat.chat_memory</code>","text":""},{"location":"code_docs/func_modules/memory/chat/chat_memory/#labridge.func_modules.memory.chat.chat_memory.ChatVectorMemory","title":"<code>labridge.func_modules.memory.chat.chat_memory.ChatVectorMemory</code>","text":"<p>               Bases: <code>VectorMemory</code></p> <p>This class is used to store the chat history, involving the logs of called tools in chat.</p> PARAMETER DESCRIPTION <code>vector_index</code> <p>The vector database.</p> <p> TYPE: <code>VectorStoreIndex</code> </p> <code>retriever_kwargs</code> <p>Not used. Refer to <code>ChatMemoryRetriever</code>.</p> <p> TYPE: <code>dict</code> </p> <code>persist_dir</code> <p>The save directory.</p> <p> TYPE: <code>str</code> </p> Note <p>In the vector index, the metadata <code>LOG_DATE_NAME</code> and <code>LOG_TIME_NAME</code> are recorded for each chat log node, they are useful for filtering in retrieving. The metadata <code>date</code> and <code>time</code> is recorded in a list format for the convenience of metadata filtering. For example: ['2024-08-10'], ['09:05:03'].</p> Source code in <code>labridge\\func_modules\\memory\\chat\\chat_memory.py</code> <pre><code>class ChatVectorMemory(VectorMemory):\n\tr\"\"\"\n\tThis class is used to store the chat history, involving the logs of called tools in chat.\n\n\tArgs:\n\t\tvector_index (VectorStoreIndex): The vector database.\n\t\tretriever_kwargs (dict): Not used. Refer to `ChatMemoryRetriever`.\n\t\tpersist_dir (str): The save directory.\n\n\tNote:\n\t\tIn the vector index, the metadata `LOG_DATE_NAME` and `LOG_TIME_NAME` are recorded for each chat log node, they are\n\t\tuseful for filtering in retrieving.\n\t\tThe metadata `date` and `time` is recorded in a list format for the convenience of metadata filtering.\n\t\tFor example: ['2024-08-10'], ['09:05:03'].\n\t\"\"\"\n\tpersist_dir: str = Field(\n\t\tdefault=\"\",\n\t\tdescription=\"The persist dir of the memory index relative to the root.\",\n\t)\n\tdef __init__(\n\t\tself,\n\t\tvector_index: VectorStoreIndex,\n\t\tretriever_kwargs: dict,\n\t\tpersist_dir: str\n\t):\n\t\tsuper().__init__(vector_index=vector_index, retriever_kwargs=retriever_kwargs)\n\t\tself.vector_index.set_index_id(CHAT_MEMORY_VECTOR_INDEX_ID)\n\t\tself.persist_dir = persist_dir\n\n\t@classmethod\n\tdef from_storage(\n\t\tcls,\n\t\tpersist_dir: str,\n\t\tembed_model: BaseEmbedding,\n\t\tretriever_kwargs: dict,\n\t):\n\t\tr\"\"\"\n\t\tLoad from an existing storage.\n\n\t\tArgs:\n\t\t\tpersist_dir (str): The save path of the storage.\n\t\t\tembed_model (BaseEmbedding): The used embedding model.\n\t\t\tretriever_kwargs (dict): Not used.\n\n\t\tReturns:\n\t\t\tChatVectorMemory\n\t\t\"\"\"\n\t\tvector_storage_context = StorageContext.from_defaults(persist_dir=persist_dir)\n\t\tvector_index = load_index_from_storage(\n\t\t\tstorage_context=vector_storage_context,\n\t\t\tindex_id=CHAT_MEMORY_VECTOR_INDEX_ID,\n\t\t\tembed_model=embed_model,\n\t\t)\n\t\treturn cls(\n\t\t\tvector_index=vector_index,\n\t\t\tretriever_kwargs=retriever_kwargs,\n\t\t\tpersist_dir=persist_dir,\n\t\t)\n\n\t@property\n\tdef memory_id(self) -&gt; str:\n\t\tr\"\"\"\n\t\tThe memory_id is either a user_id or a chat_group_id.\n\n\t\tReturns:\n\t\t\tstr: The memory id of this ChatMemory.\n\t\t\"\"\"\n\t\troot = Path(__file__)\n\t\tfor idx in range(5):\n\t\t\troot = root.parent\n\n\t\tmem_id = Path(self.persist_dir).relative_to(root / CHAT_MEMORY_PERSIST_DIR)\n\t\treturn str(mem_id)\n\n\tdef is_chat_group_memory(self) -&gt; bool:\n\t\tr\"\"\"\n\t\tWhether this class records the history of a chat group or not.\n\t\t\"\"\"\n\t\ttry:\n\t\t\tself.vector_index.docstore.get_node(CHAT_GROUP_MEMBERS_NODE_NAME)\n\t\t\treturn True\n\t\texcept ValueError as e:\n\t\t\treturn False\n\n\t@classmethod\n\tdef from_memory_id(\n\t\tcls,\n\t\tmemory_id: str,\n\t\tembed_model: BaseEmbedding,\n\t\tretriever_kwargs: dict,\n\t\tdescription: str = None,\n\t\tgroup_members: Optional[List[str]] = None,\n\t):\n\t\tr\"\"\"\n\t\tConstruct from the memory_id.\n\t\tIf the corresponding persist_dir of the memory_id does not exist, a new ChatMemory will be created.\n\n\t\tArgs:\n\t\t\tmemory_id (str): a user_id of a lab member or a chat_group_id.\n\t\t\tembed_model (BaseEmbedding): The used embedding model.\n\t\t\tretriever_kwargs (dict): Not used.\n\t\t\tdescription (str): The description of this ChatMemory.\n\t\t\tgroup_members (Optional[List[str]]): If the memory_id is a chat_group_id, the group members must be given.\n\n\t\tReturns:\n\t\t\tChatVectorMemory\n\t\t\"\"\"\n\t\taccount_manager = AccountManager()\n\n\t\tif memory_id not in account_manager.get_users() + account_manager.get_chat_groups():\n\t\t\traise ValueError(f\"Invalid user id or chat group id: {memory_id}.\")\n\n\t\troot = Path(__file__)\n\t\tfor idx in range(5):\n\t\t\troot = root.parent\n\n\t\tpersist_dir = str(root / f\"{CHAT_MEMORY_PERSIST_DIR}/{memory_id}\")\n\t\tfs = fsspec.filesystem(\"file\")\n\t\tif fs.exists(persist_dir):\n\t\t\treturn cls.from_storage(\n\t\t\t\tpersist_dir=persist_dir,\n\t\t\t\tembed_model=embed_model,\n\t\t\t\tretriever_kwargs=retriever_kwargs,\n\t\t\t)\n\n\t\tdate, h_m_s = get_time()\n\t\tinit_msg = ChatMessage(\n\t\t\trole=MessageRole.SYSTEM,\n\t\t\tcontent=f\"This Memory Index is used for storing the chat history related to the USER/CHAT GROUP: {memory_id}\\n\"\n\t\t\t\t\tf\"Description: {description}.\",\n\t\t\tadditional_kwargs={\n\t\t\t\tLOG_DATE_NAME: date,\n\t\t\t\tLOG_TIME_NAME: h_m_s,\n\t\t\t},\n\t\t)\n\t\ttext_node = _get_starter_node_for_new_batch()\n\t\ttext_node.id_ = MEMORY_FIRST_NODE_NAME\n\t\ttext_node.text += init_msg.content\n\t\ttext_node.metadata[LOG_DATE_NAME] = [init_msg.additional_kwargs[LOG_DATE_NAME],]\n\t\ttext_node.metadata[LOG_TIME_NAME] = [init_msg.additional_kwargs[LOG_TIME_NAME],]\n\n\t\tlast_id_info_node = TextNode(text=text_node.node_id, id_=MEMORY_LAST_NODE_ID_NAME)\n\n\t\tnodes = [text_node, last_id_info_node]\n\t\tif group_members is not None:\n\t\t\tfor user_id in group_members:\n\t\t\t\ttry:\n\t\t\t\t\taccount_manager.check_valid_user(user_id=user_id)\n\t\t\t\texcept ValueError as e:\n\t\t\t\t\treturn f\"Error: {e!s}\"\n\t\t\tmembers_node = TextNode(text=\",\".join(group_members))\n\t\t\tmembers_node.id_ = CHAT_GROUP_MEMBERS_NODE_NAME\n\t\t\tnodes.append(members_node)\n\n\t\tvector_index = VectorStoreIndex(\n\t\t\tnodes=nodes,\n\t\t\tembed_model=embed_model,\n\t\t)\n\t\treturn cls(\n\t\t\tvector_index=vector_index,\n\t\t\tpersist_dir=persist_dir,\n\t\t\tretriever_kwargs=retriever_kwargs,\n\t\t)\n\n\tdef update_node(self, node_id: str, node: BaseNode):\n\t\tr\"\"\"\n\t\tUpdate a node in the vector index.\n\n\t\tArgs:\n\t\t\tnode_id (str): The node_id of the node to be updated.\n\t\t\tnode (BaseNode): The new node.\n\t\t\"\"\"\n\t\tself.vector_index.delete_nodes([node_id])\n\t\tself.vector_index.insert_nodes([node])\n\n\tdef put(self, message: ChatMessage) -&gt; None:\n\t\t\"\"\"\n\t\tPut chat history.\n\n\t\tMetadata: `LOG_DATE_NAME`: [date, ]; `LOG_TIME_NAME`: [time, ]\n\n\t\tThe node_id of the Last Text Node is stored in the node `MEMORY_LAST_NODE_ID_NAME`\n\t\tEvery time a New Text Node is put in, execute:\n\n\t\t- Last Text Node -&gt; next_node = New Text Node\n\t\t- New Text Node -&gt; prev_node = Last Text Node\n\t\t- let New Text Node be the Last Text Node\n\n\t\tArgs:\n\t\t\tmessage (ChatMessage): a chat message.\n\t\t\"\"\"\n\t\tif not self.batch_by_user_message or message.role in [MessageRole.USER, MessageRole.SYSTEM, ]:\n\t\t\t# if not batching by user message, commit to vector store immediately after adding\n\t\t\tself.cur_batch_textnode = _get_starter_node_for_new_batch()\n\t\t\t# add date and time\n\t\t\tself.cur_batch_textnode.metadata[LOG_DATE_NAME] = [message.additional_kwargs[LOG_DATE_NAME],]\n\t\t\tself.cur_batch_textnode.metadata[LOG_TIME_NAME] = [message.additional_kwargs[LOG_TIME_NAME],]\n\t\t\t# add previous and next relationships.\n\t\t\tlast_info_node = self.vector_index.docstore.get_node(MEMORY_LAST_NODE_ID_NAME)\n\t\t\tlast_node_id = last_info_node.text\n\t\t\tlast_node = self.vector_index.docstore.get_node(last_node_id)\n\t\t\tlast_node.relationships[NodeRelationship.NEXT] = RelatedNodeInfo(\n\t\t\t\tnode_id=self.cur_batch_textnode.node_id\n\t\t\t)\n\t\t\tself.cur_batch_textnode.relationships[NodeRelationship.PREVIOUS] = RelatedNodeInfo(\n\t\t\t\tnode_id=last_node.node_id\n\t\t\t)\n\t\t\t# update last node id\n\t\t\tlast_info_node.set_content(self.cur_batch_textnode.node_id)\n\t\t\tself.update_node(node_id=last_node_id, node=last_node)\n\t\t\tself.update_node(node_id=MEMORY_LAST_NODE_ID_NAME, node=last_info_node)\n\n\t\t# update current batch textnode\n\t\tsub_dict = _stringify_chat_message(message)\n\t\trole = sub_dict[\"role\"]\n\t\tcontent = sub_dict[\"content\"] or \"\"\n\t\tnew_msg = (\n\t\t\tf\"&gt;&gt;&gt; {role} message:\\n\"\n\t\t\tf\"{content.strip()}\\n\"\n\t\t)\n\t\tself.cur_batch_textnode.text += new_msg\n\t\t# self.cur_batch_textnode.metadata[\"sub_dicts\"].append(sub_dict)\n\t\tself._commit_node(override_last=True)\n\n\tdef persist(self, persist_dir: str = None):\n\t\tpersist_dir = persist_dir or self.persist_dir\n\t\tfs = fsspec.filesystem(\"file\")\n\t\tif not fs.exists(persist_dir):\n\t\t\tfs.makedirs(persist_dir)\n\t\tself.vector_index.storage_context.persist(persist_dir=persist_dir)\n</code></pre>"},{"location":"code_docs/func_modules/memory/chat/chat_memory/#labridge.func_modules.memory.chat.chat_memory.ChatVectorMemory.memory_id","title":"<code>labridge.func_modules.memory.chat.chat_memory.ChatVectorMemory.memory_id: str</code>  <code>property</code>","text":"<p>The memory_id is either a user_id or a chat_group_id.</p> RETURNS DESCRIPTION <code>str</code> <p>The memory id of this ChatMemory.</p> <p> TYPE: <code>str</code> </p>"},{"location":"code_docs/func_modules/memory/chat/chat_memory/#labridge.func_modules.memory.chat.chat_memory.ChatVectorMemory.from_memory_id","title":"<code>labridge.func_modules.memory.chat.chat_memory.ChatVectorMemory.from_memory_id(memory_id, embed_model, retriever_kwargs, description=None, group_members=None)</code>  <code>classmethod</code>","text":"<p>Construct from the memory_id. If the corresponding persist_dir of the memory_id does not exist, a new ChatMemory will be created.</p> PARAMETER DESCRIPTION <code>memory_id</code> <p>a user_id of a lab member or a chat_group_id.</p> <p> TYPE: <code>str</code> </p> <code>embed_model</code> <p>The used embedding model.</p> <p> TYPE: <code>BaseEmbedding</code> </p> <code>retriever_kwargs</code> <p>Not used.</p> <p> TYPE: <code>dict</code> </p> <code>description</code> <p>The description of this ChatMemory.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>group_members</code> <p>If the memory_id is a chat_group_id, the group members must be given.</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <p>ChatVectorMemory</p> Source code in <code>labridge\\func_modules\\memory\\chat\\chat_memory.py</code> <pre><code>@classmethod\ndef from_memory_id(\n\tcls,\n\tmemory_id: str,\n\tembed_model: BaseEmbedding,\n\tretriever_kwargs: dict,\n\tdescription: str = None,\n\tgroup_members: Optional[List[str]] = None,\n):\n\tr\"\"\"\n\tConstruct from the memory_id.\n\tIf the corresponding persist_dir of the memory_id does not exist, a new ChatMemory will be created.\n\n\tArgs:\n\t\tmemory_id (str): a user_id of a lab member or a chat_group_id.\n\t\tembed_model (BaseEmbedding): The used embedding model.\n\t\tretriever_kwargs (dict): Not used.\n\t\tdescription (str): The description of this ChatMemory.\n\t\tgroup_members (Optional[List[str]]): If the memory_id is a chat_group_id, the group members must be given.\n\n\tReturns:\n\t\tChatVectorMemory\n\t\"\"\"\n\taccount_manager = AccountManager()\n\n\tif memory_id not in account_manager.get_users() + account_manager.get_chat_groups():\n\t\traise ValueError(f\"Invalid user id or chat group id: {memory_id}.\")\n\n\troot = Path(__file__)\n\tfor idx in range(5):\n\t\troot = root.parent\n\n\tpersist_dir = str(root / f\"{CHAT_MEMORY_PERSIST_DIR}/{memory_id}\")\n\tfs = fsspec.filesystem(\"file\")\n\tif fs.exists(persist_dir):\n\t\treturn cls.from_storage(\n\t\t\tpersist_dir=persist_dir,\n\t\t\tembed_model=embed_model,\n\t\t\tretriever_kwargs=retriever_kwargs,\n\t\t)\n\n\tdate, h_m_s = get_time()\n\tinit_msg = ChatMessage(\n\t\trole=MessageRole.SYSTEM,\n\t\tcontent=f\"This Memory Index is used for storing the chat history related to the USER/CHAT GROUP: {memory_id}\\n\"\n\t\t\t\tf\"Description: {description}.\",\n\t\tadditional_kwargs={\n\t\t\tLOG_DATE_NAME: date,\n\t\t\tLOG_TIME_NAME: h_m_s,\n\t\t},\n\t)\n\ttext_node = _get_starter_node_for_new_batch()\n\ttext_node.id_ = MEMORY_FIRST_NODE_NAME\n\ttext_node.text += init_msg.content\n\ttext_node.metadata[LOG_DATE_NAME] = [init_msg.additional_kwargs[LOG_DATE_NAME],]\n\ttext_node.metadata[LOG_TIME_NAME] = [init_msg.additional_kwargs[LOG_TIME_NAME],]\n\n\tlast_id_info_node = TextNode(text=text_node.node_id, id_=MEMORY_LAST_NODE_ID_NAME)\n\n\tnodes = [text_node, last_id_info_node]\n\tif group_members is not None:\n\t\tfor user_id in group_members:\n\t\t\ttry:\n\t\t\t\taccount_manager.check_valid_user(user_id=user_id)\n\t\t\texcept ValueError as e:\n\t\t\t\treturn f\"Error: {e!s}\"\n\t\tmembers_node = TextNode(text=\",\".join(group_members))\n\t\tmembers_node.id_ = CHAT_GROUP_MEMBERS_NODE_NAME\n\t\tnodes.append(members_node)\n\n\tvector_index = VectorStoreIndex(\n\t\tnodes=nodes,\n\t\tembed_model=embed_model,\n\t)\n\treturn cls(\n\t\tvector_index=vector_index,\n\t\tpersist_dir=persist_dir,\n\t\tretriever_kwargs=retriever_kwargs,\n\t)\n</code></pre>"},{"location":"code_docs/func_modules/memory/chat/chat_memory/#labridge.func_modules.memory.chat.chat_memory.ChatVectorMemory.from_storage","title":"<code>labridge.func_modules.memory.chat.chat_memory.ChatVectorMemory.from_storage(persist_dir, embed_model, retriever_kwargs)</code>  <code>classmethod</code>","text":"<p>Load from an existing storage.</p> PARAMETER DESCRIPTION <code>persist_dir</code> <p>The save path of the storage.</p> <p> TYPE: <code>str</code> </p> <code>embed_model</code> <p>The used embedding model.</p> <p> TYPE: <code>BaseEmbedding</code> </p> <code>retriever_kwargs</code> <p>Not used.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <p>ChatVectorMemory</p> Source code in <code>labridge\\func_modules\\memory\\chat\\chat_memory.py</code> <pre><code>@classmethod\ndef from_storage(\n\tcls,\n\tpersist_dir: str,\n\tembed_model: BaseEmbedding,\n\tretriever_kwargs: dict,\n):\n\tr\"\"\"\n\tLoad from an existing storage.\n\n\tArgs:\n\t\tpersist_dir (str): The save path of the storage.\n\t\tembed_model (BaseEmbedding): The used embedding model.\n\t\tretriever_kwargs (dict): Not used.\n\n\tReturns:\n\t\tChatVectorMemory\n\t\"\"\"\n\tvector_storage_context = StorageContext.from_defaults(persist_dir=persist_dir)\n\tvector_index = load_index_from_storage(\n\t\tstorage_context=vector_storage_context,\n\t\tindex_id=CHAT_MEMORY_VECTOR_INDEX_ID,\n\t\tembed_model=embed_model,\n\t)\n\treturn cls(\n\t\tvector_index=vector_index,\n\t\tretriever_kwargs=retriever_kwargs,\n\t\tpersist_dir=persist_dir,\n\t)\n</code></pre>"},{"location":"code_docs/func_modules/memory/chat/chat_memory/#labridge.func_modules.memory.chat.chat_memory.ChatVectorMemory.is_chat_group_memory","title":"<code>labridge.func_modules.memory.chat.chat_memory.ChatVectorMemory.is_chat_group_memory()</code>","text":"<p>Whether this class records the history of a chat group or not.</p> Source code in <code>labridge\\func_modules\\memory\\chat\\chat_memory.py</code> <pre><code>def is_chat_group_memory(self) -&gt; bool:\n\tr\"\"\"\n\tWhether this class records the history of a chat group or not.\n\t\"\"\"\n\ttry:\n\t\tself.vector_index.docstore.get_node(CHAT_GROUP_MEMBERS_NODE_NAME)\n\t\treturn True\n\texcept ValueError as e:\n\t\treturn False\n</code></pre>"},{"location":"code_docs/func_modules/memory/chat/chat_memory/#labridge.func_modules.memory.chat.chat_memory.ChatVectorMemory.put","title":"<code>labridge.func_modules.memory.chat.chat_memory.ChatVectorMemory.put(message)</code>","text":"<p>Put chat history.</p> <p>Metadata: <code>LOG_DATE_NAME</code>: [date, ]; <code>LOG_TIME_NAME</code>: [time, ]</p> <p>The node_id of the Last Text Node is stored in the node <code>MEMORY_LAST_NODE_ID_NAME</code> Every time a New Text Node is put in, execute:</p> <ul> <li>Last Text Node -&gt; next_node = New Text Node</li> <li>New Text Node -&gt; prev_node = Last Text Node</li> <li>let New Text Node be the Last Text Node</li> </ul> PARAMETER DESCRIPTION <code>message</code> <p>a chat message.</p> <p> TYPE: <code>ChatMessage</code> </p> Source code in <code>labridge\\func_modules\\memory\\chat\\chat_memory.py</code> <pre><code>def put(self, message: ChatMessage) -&gt; None:\n\t\"\"\"\n\tPut chat history.\n\n\tMetadata: `LOG_DATE_NAME`: [date, ]; `LOG_TIME_NAME`: [time, ]\n\n\tThe node_id of the Last Text Node is stored in the node `MEMORY_LAST_NODE_ID_NAME`\n\tEvery time a New Text Node is put in, execute:\n\n\t- Last Text Node -&gt; next_node = New Text Node\n\t- New Text Node -&gt; prev_node = Last Text Node\n\t- let New Text Node be the Last Text Node\n\n\tArgs:\n\t\tmessage (ChatMessage): a chat message.\n\t\"\"\"\n\tif not self.batch_by_user_message or message.role in [MessageRole.USER, MessageRole.SYSTEM, ]:\n\t\t# if not batching by user message, commit to vector store immediately after adding\n\t\tself.cur_batch_textnode = _get_starter_node_for_new_batch()\n\t\t# add date and time\n\t\tself.cur_batch_textnode.metadata[LOG_DATE_NAME] = [message.additional_kwargs[LOG_DATE_NAME],]\n\t\tself.cur_batch_textnode.metadata[LOG_TIME_NAME] = [message.additional_kwargs[LOG_TIME_NAME],]\n\t\t# add previous and next relationships.\n\t\tlast_info_node = self.vector_index.docstore.get_node(MEMORY_LAST_NODE_ID_NAME)\n\t\tlast_node_id = last_info_node.text\n\t\tlast_node = self.vector_index.docstore.get_node(last_node_id)\n\t\tlast_node.relationships[NodeRelationship.NEXT] = RelatedNodeInfo(\n\t\t\tnode_id=self.cur_batch_textnode.node_id\n\t\t)\n\t\tself.cur_batch_textnode.relationships[NodeRelationship.PREVIOUS] = RelatedNodeInfo(\n\t\t\tnode_id=last_node.node_id\n\t\t)\n\t\t# update last node id\n\t\tlast_info_node.set_content(self.cur_batch_textnode.node_id)\n\t\tself.update_node(node_id=last_node_id, node=last_node)\n\t\tself.update_node(node_id=MEMORY_LAST_NODE_ID_NAME, node=last_info_node)\n\n\t# update current batch textnode\n\tsub_dict = _stringify_chat_message(message)\n\trole = sub_dict[\"role\"]\n\tcontent = sub_dict[\"content\"] or \"\"\n\tnew_msg = (\n\t\tf\"&gt;&gt;&gt; {role} message:\\n\"\n\t\tf\"{content.strip()}\\n\"\n\t)\n\tself.cur_batch_textnode.text += new_msg\n\t# self.cur_batch_textnode.metadata[\"sub_dicts\"].append(sub_dict)\n\tself._commit_node(override_last=True)\n</code></pre>"},{"location":"code_docs/func_modules/memory/chat/chat_memory/#labridge.func_modules.memory.chat.chat_memory.ChatVectorMemory.update_node","title":"<code>labridge.func_modules.memory.chat.chat_memory.ChatVectorMemory.update_node(node_id, node)</code>","text":"<p>Update a node in the vector index.</p> PARAMETER DESCRIPTION <code>node_id</code> <p>The node_id of the node to be updated.</p> <p> TYPE: <code>str</code> </p> <code>node</code> <p>The new node.</p> <p> TYPE: <code>BaseNode</code> </p> Source code in <code>labridge\\func_modules\\memory\\chat\\chat_memory.py</code> <pre><code>def update_node(self, node_id: str, node: BaseNode):\n\tr\"\"\"\n\tUpdate a node in the vector index.\n\n\tArgs:\n\t\tnode_id (str): The node_id of the node to be updated.\n\t\tnode (BaseNode): The new node.\n\t\"\"\"\n\tself.vector_index.delete_nodes([node_id])\n\tself.vector_index.insert_nodes([node])\n</code></pre>"},{"location":"code_docs/func_modules/memory/chat/chat_memory/#labridge.func_modules.memory.chat.chat_memory.update_chat_memory","title":"<code>labridge.func_modules.memory.chat.chat_memory.update_chat_memory(memory_id, chat_messages, embed_model=None)</code>","text":"<p>Update the user/chat_group specific chat memory.</p> PARAMETER DESCRIPTION <code>memory_id</code> <p>user_id or chat_group_id</p> <p> TYPE: <code>str</code> </p> <code>chat_messages</code> <p>New chat messages.</p> <p> TYPE: <code>List[ChatMessage]</code> </p> <code>embed_model</code> <p>The used embedding model.</p> <p> TYPE: <code>BaseEmbedding</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <p>None or an Error string.</p> Source code in <code>labridge\\func_modules\\memory\\chat\\chat_memory.py</code> <pre><code>def update_chat_memory(\n\tmemory_id: str,\n\tchat_messages: List[ChatMessage],\n\tembed_model: BaseEmbedding = None\n):\n\tr\"\"\"\n\tUpdate the user/chat_group specific chat memory.\n\n\tArgs:\n\t\tmemory_id (str): user_id or chat_group_id\n\t\tchat_messages (List[ChatMessage]): New chat messages.\n\t\tembed_model (BaseEmbedding): The used embedding model.\n\n\tReturns:\n\t\tNone or an Error string.\n\t\"\"\"\n\tchat_memory = ChatVectorMemory.from_memory_id(\n\t\tmemory_id=memory_id,\n\t\tembed_model=embed_model or Settings.embed_model,\n\t\tretriever_kwargs={},\n\t)\n\n\tif not isinstance(chat_memory, ChatVectorMemory):\n\t\treturn chat_memory\n\n\tfor msg in chat_messages:\n\t\tchat_memory.put(msg)\n\n\tchat_memory.persist()\n</code></pre>"},{"location":"code_docs/func_modules/memory/chat/retrieve/","title":"Retrieve","text":""},{"location":"code_docs/func_modules/memory/chat/retrieve/#labridge.func_modules.memory.chat.retrieve","title":"<code>labridge.func_modules.memory.chat.retrieve</code>","text":""},{"location":"code_docs/func_modules/memory/chat/retrieve/#labridge.func_modules.memory.chat.retrieve.ChatMemoryRetriever","title":"<code>labridge.func_modules.memory.chat.retrieve.ChatMemoryRetriever</code>","text":"<p>               Bases: <code>LogBaseRetriever</code></p> <p>This is a retriever that retrieve in the permanent chat history of a user or a chat group. You can use this tool when you want to obtain the historical interaction between you and the user.</p> PARAMETER DESCRIPTION <code>embed_model</code> <p>The used embedding model, if not specified, will use the <code>Settings.embed_model</code></p> <p> TYPE: <code>BaseEmbedding</code> DEFAULT: <code>None</code> </p> <code>final_use_context</code> <p>Whether to add the context nodes of the retrieved log nodes to the final results. Defaults to True.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>relevant_top_k</code> <p>The top-k relevant nodes in retrieving will be used as the retrieved results. Defaults to <code>CHAT_MEMORY_RELEVANT_TOP_K</code>.</p> <p> TYPE: <code>int</code> DEFAULT: <code>CHAT_MEMORY_RELEVANT_TOP_K</code> </p> Source code in <code>labridge\\func_modules\\memory\\chat\\retrieve.py</code> <pre><code>class ChatMemoryRetriever(LogBaseRetriever):\n\tr\"\"\"\n\tThis is a retriever that retrieve in the permanent chat history of a user or a chat group.\n\tYou can use this tool when you want to obtain the historical interaction between you and the user.\n\n\tArgs:\n\t\tembed_model (BaseEmbedding): The used embedding model, if not specified, will use the `Settings.embed_model`\n\t\tfinal_use_context (bool): Whether to add the context nodes of the retrieved log nodes to the final results.\n\t\t\tDefaults to True.\n\t\trelevant_top_k (int): The top-k relevant nodes in retrieving will be used as the retrieved results.\n\t\t\tDefaults to `CHAT_MEMORY_RELEVANT_TOP_K`.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tembed_model: BaseEmbedding = None,\n\t\tfinal_use_context: bool = True,\n\t\trelevant_top_k: int = CHAT_MEMORY_RELEVANT_TOP_K\n\t):\n\t\tsuper().__init__(\n\t\t\tembed_model=embed_model,\n\t\t\tfinal_use_context=final_use_context,\n\t\t\trelevant_top_k=relevant_top_k,\n\t\t)\n\n\tdef get_memory_vector_retriever(self) -&gt; VectorIndexRetriever:\n\t\tmemory_retriever = self.memory.vector_index.as_retriever(\n\t\t\tsimilarity_top_k=self.relevant_top_k,\n\t\t\tfilters=None,\n\t\t)\n\t\treturn memory_retriever\n\n\tdef reset_vector_retriever(self):\n\t\tself.memory_vector_retriever._filters = None\n\t\tself.memory_vector_retriever._node_ids = None\n\n\tdef get_memory_vector_index(self) -&gt; VectorStoreIndex:\n\t\treturn self.memory.vector_index\n\n\t@dispatcher.span\n\tdef retrieve(\n\t\tself,\n\t\titem_to_be_retrieved: str,\n\t\tmemory_id: str,\n\t\tstart_date: str = None,\n\t\tend_date: str = None,\n\t\t**kwargs: Any,\n\t) -&gt; List[NodeWithScore]:\n\t\tr\"\"\"\n\t\tThis tool is used to retrieve relevant chat history in a certain chat history memory.\n\t\tThe memory_id of a chat history memory is the `user_id` of a specific user or the `chat_group_id` of a specific\n\t\tchat group.\n\n\t\tAdditionally, you can provide the `start_date` and `end_state` to limit the retrieving range of date,\n\t\tThe end date can be the same as the start date, but should not be earlier than the start date.\n\t\tIf the start date or end_date is not provided, retrieving will be performed among the whole memory.\n\n\t\tArgs:\n\t\t\titem_to_be_retrieved (str): Things that you want to retrieve in the chat history memory.\n\t\t\tmemory_id (str): The memory_id of a chat history memory. It is either a `user_id` or a `chat_group_id`.\n\t\t\tstart_date (str): The START date of the retrieving date limit. Defaults to None.\n\t\t\t\tIf given, it should be given in the following FORMAT: Year-Month-Day.\n\t\t\t\tFor example, 2020-12-1 means the year 2020, the 12th month, the 1rst day.\n\t\t\tend_date (str): The END date of the retrieving date limit. Defaults to None.\n\t\t\t\tIf given, It should be given in the following FORMAT: Year-Month-Day.\n\t\t\t\tFor example, 2024-6-2 means the year 2024, the 6th month, the 2nd day.\n\n\t\tReturns:\n\t\t\tRetrieved chat history.\n\t\t\"\"\"\n\t\t# This docstring is used as the tool description.\n\t\t# set self.memory_index according to the user_id.\n\t\tif self.memory is None or self.memory.memory_id != memory_id:\n\t\t\tself.memory = ChatVectorMemory.from_memory_id(memory_id=memory_id, embed_model=self.embed_model,\n\t\t\t\tretriever_kwargs={}, )\n\t\t\tself.memory_vector_retriever = self.get_memory_vector_retriever()\n\n\t\t# get the candidate date list.\n\t\tdate_list = self._parse_date(start_date_str=start_date, end_date_str=end_date)\n\t\tmetadata_filters =  MetadataFilters(\n\t\t\tfilters=[\n\t\t\t\tself.get_date_filter(date_list=date_list),\n\t\t\t]\n\t\t)\n\t\tself.memory_vector_retriever._filters = metadata_filters\n\t\tchat_nodes = self.memory_vector_retriever.retrieve(item_to_be_retrieved)\n\t\tself.reset_vector_retriever()\n\t\t# get the results, add prev node and next node to it (if in a same date.).\n\t\tif self.final_use_context:\n\t\t\tchat_nodes = self._add_context(content_nodes=chat_nodes)\n\t\treturn chat_nodes\n\n\t@dispatcher.span\n\tasync def aretrieve(\n\t\tself,\n\t\titem_to_be_retrieved: str,\n\t\tmemory_id: str,\n\t\tstart_date: str = None,\n\t\tend_date: str = None,\n\t\t**kwargs: Any,\n\t) -&gt; List[NodeWithScore]:\n\t\tr\"\"\"\n\t\tThis method is used to asynchronously retrieve relevant chat history in a certain chat history memory.\n\t\tThe memory_id of a chat history memory is the `user_id` of a specific user or the `chat_group_id` of a specific\n\t\tchat group.\n\n\t\tAdditionally, you can provide the `start_date` and `end_state` to limit the retrieving range of date,\n\t\tThe end date should not be earlier than the start date.\n\t\tIf the start date or end_date is not provided, retrieving will be performed among the whole memory.\n\n\t\tArgs:\n\t\t\titem_to_be_retrieved (str): Things that you want to retrieve in the chat history memory.\n\t\t\tmemory_id (str): The memory_id of a chat history memory. It is either a `user_id` or a `chat_group_id`.\n\t\t\tstart_date (str): The START date of the retrieving date limit. Defaults to None.\n\t\t\t\tIf given, it should be given in the following FORMAT: Year-Month-Day.\n\t\t\t\tFor example, 2020-12-1 means the year 2020, the 12th month, the 1rst day.\n\t\t\tend_date (str): The END date of the retrieving date limit. Defaults to None.\n\t\t\t\tIf given, it should be given in the following FORMAT: Year-Month-Day.\n\t\t\t\tFor example, 2024-6-2 means the year 2024, the 6th month, the 2nd day.\n\n\t\tReturns:\n\t\t\tRetrieved chat history.\n\t\t\"\"\"\n\t\t# set self.memory_index according to the user_id.\n\t\tif self.memory is None or self.memory.memory_id != memory_id:\n\t\t\tself.memory = ChatVectorMemory.from_memory_id(\n\t\t\t\tmemory_id=memory_id,\n\t\t\t\tembed_model=self.embed_model,\n\t\t\t\tretriever_kwargs={},\n\t\t\t)\n\t\t\tself.memory_vector_retriever = self.get_memory_vector_retriever()\n\n\t\t# get the candidate date list.\n\t\tdate_list = self._parse_date(start_date_str=start_date, end_date_str=end_date)\n\t\tmetadata_filters = MetadataFilters(\n\t\t\tfilters=[\n\t\t\t\tself.get_date_filter(date_list=date_list),\n\t\t\t]\n\t\t)\n\t\tself.memory_vector_retriever._filters = metadata_filters\n\t\tchat_nodes = await self.memory_vector_retriever.aretrieve(item_to_be_retrieved)\n\t\t# get the results, add prev node and next node to it (if in a same date.).\n\t\tif self.final_use_context:\n\t\t\tchat_nodes = self._add_context(content_nodes=chat_nodes)\n\t\treturn chat_nodes\n</code></pre>"},{"location":"code_docs/func_modules/memory/chat/retrieve/#labridge.func_modules.memory.chat.retrieve.ChatMemoryRetriever.aretrieve","title":"<code>labridge.func_modules.memory.chat.retrieve.ChatMemoryRetriever.aretrieve(item_to_be_retrieved, memory_id, start_date=None, end_date=None, **kwargs)</code>  <code>async</code>","text":"<p>This method is used to asynchronously retrieve relevant chat history in a certain chat history memory. The memory_id of a chat history memory is the <code>user_id</code> of a specific user or the <code>chat_group_id</code> of a specific chat group.</p> <p>Additionally, you can provide the <code>start_date</code> and <code>end_state</code> to limit the retrieving range of date, The end date should not be earlier than the start date. If the start date or end_date is not provided, retrieving will be performed among the whole memory.</p> PARAMETER DESCRIPTION <code>item_to_be_retrieved</code> <p>Things that you want to retrieve in the chat history memory.</p> <p> TYPE: <code>str</code> </p> <code>memory_id</code> <p>The memory_id of a chat history memory. It is either a <code>user_id</code> or a <code>chat_group_id</code>.</p> <p> TYPE: <code>str</code> </p> <code>start_date</code> <p>The START date of the retrieving date limit. Defaults to None. If given, it should be given in the following FORMAT: Year-Month-Day. For example, 2020-12-1 means the year 2020, the 12<sup>th</sup> month, the 1rst day.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>end_date</code> <p>The END date of the retrieving date limit. Defaults to None. If given, it should be given in the following FORMAT: Year-Month-Day. For example, 2024-6-2 means the year 2024, the 6<sup>th</sup> month, the 2<sup>nd</sup> day.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>List[NodeWithScore]</code> <p>Retrieved chat history.</p> Source code in <code>labridge\\func_modules\\memory\\chat\\retrieve.py</code> <pre><code>@dispatcher.span\nasync def aretrieve(\n\tself,\n\titem_to_be_retrieved: str,\n\tmemory_id: str,\n\tstart_date: str = None,\n\tend_date: str = None,\n\t**kwargs: Any,\n) -&gt; List[NodeWithScore]:\n\tr\"\"\"\n\tThis method is used to asynchronously retrieve relevant chat history in a certain chat history memory.\n\tThe memory_id of a chat history memory is the `user_id` of a specific user or the `chat_group_id` of a specific\n\tchat group.\n\n\tAdditionally, you can provide the `start_date` and `end_state` to limit the retrieving range of date,\n\tThe end date should not be earlier than the start date.\n\tIf the start date or end_date is not provided, retrieving will be performed among the whole memory.\n\n\tArgs:\n\t\titem_to_be_retrieved (str): Things that you want to retrieve in the chat history memory.\n\t\tmemory_id (str): The memory_id of a chat history memory. It is either a `user_id` or a `chat_group_id`.\n\t\tstart_date (str): The START date of the retrieving date limit. Defaults to None.\n\t\t\tIf given, it should be given in the following FORMAT: Year-Month-Day.\n\t\t\tFor example, 2020-12-1 means the year 2020, the 12th month, the 1rst day.\n\t\tend_date (str): The END date of the retrieving date limit. Defaults to None.\n\t\t\tIf given, it should be given in the following FORMAT: Year-Month-Day.\n\t\t\tFor example, 2024-6-2 means the year 2024, the 6th month, the 2nd day.\n\n\tReturns:\n\t\tRetrieved chat history.\n\t\"\"\"\n\t# set self.memory_index according to the user_id.\n\tif self.memory is None or self.memory.memory_id != memory_id:\n\t\tself.memory = ChatVectorMemory.from_memory_id(\n\t\t\tmemory_id=memory_id,\n\t\t\tembed_model=self.embed_model,\n\t\t\tretriever_kwargs={},\n\t\t)\n\t\tself.memory_vector_retriever = self.get_memory_vector_retriever()\n\n\t# get the candidate date list.\n\tdate_list = self._parse_date(start_date_str=start_date, end_date_str=end_date)\n\tmetadata_filters = MetadataFilters(\n\t\tfilters=[\n\t\t\tself.get_date_filter(date_list=date_list),\n\t\t]\n\t)\n\tself.memory_vector_retriever._filters = metadata_filters\n\tchat_nodes = await self.memory_vector_retriever.aretrieve(item_to_be_retrieved)\n\t# get the results, add prev node and next node to it (if in a same date.).\n\tif self.final_use_context:\n\t\tchat_nodes = self._add_context(content_nodes=chat_nodes)\n\treturn chat_nodes\n</code></pre>"},{"location":"code_docs/func_modules/memory/chat/retrieve/#labridge.func_modules.memory.chat.retrieve.ChatMemoryRetriever.retrieve","title":"<code>labridge.func_modules.memory.chat.retrieve.ChatMemoryRetriever.retrieve(item_to_be_retrieved, memory_id, start_date=None, end_date=None, **kwargs)</code>","text":"<p>This tool is used to retrieve relevant chat history in a certain chat history memory. The memory_id of a chat history memory is the <code>user_id</code> of a specific user or the <code>chat_group_id</code> of a specific chat group.</p> <p>Additionally, you can provide the <code>start_date</code> and <code>end_state</code> to limit the retrieving range of date, The end date can be the same as the start date, but should not be earlier than the start date. If the start date or end_date is not provided, retrieving will be performed among the whole memory.</p> PARAMETER DESCRIPTION <code>item_to_be_retrieved</code> <p>Things that you want to retrieve in the chat history memory.</p> <p> TYPE: <code>str</code> </p> <code>memory_id</code> <p>The memory_id of a chat history memory. It is either a <code>user_id</code> or a <code>chat_group_id</code>.</p> <p> TYPE: <code>str</code> </p> <code>start_date</code> <p>The START date of the retrieving date limit. Defaults to None. If given, it should be given in the following FORMAT: Year-Month-Day. For example, 2020-12-1 means the year 2020, the 12<sup>th</sup> month, the 1rst day.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>end_date</code> <p>The END date of the retrieving date limit. Defaults to None. If given, It should be given in the following FORMAT: Year-Month-Day. For example, 2024-6-2 means the year 2024, the 6<sup>th</sup> month, the 2<sup>nd</sup> day.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>List[NodeWithScore]</code> <p>Retrieved chat history.</p> Source code in <code>labridge\\func_modules\\memory\\chat\\retrieve.py</code> <pre><code>@dispatcher.span\ndef retrieve(\n\tself,\n\titem_to_be_retrieved: str,\n\tmemory_id: str,\n\tstart_date: str = None,\n\tend_date: str = None,\n\t**kwargs: Any,\n) -&gt; List[NodeWithScore]:\n\tr\"\"\"\n\tThis tool is used to retrieve relevant chat history in a certain chat history memory.\n\tThe memory_id of a chat history memory is the `user_id` of a specific user or the `chat_group_id` of a specific\n\tchat group.\n\n\tAdditionally, you can provide the `start_date` and `end_state` to limit the retrieving range of date,\n\tThe end date can be the same as the start date, but should not be earlier than the start date.\n\tIf the start date or end_date is not provided, retrieving will be performed among the whole memory.\n\n\tArgs:\n\t\titem_to_be_retrieved (str): Things that you want to retrieve in the chat history memory.\n\t\tmemory_id (str): The memory_id of a chat history memory. It is either a `user_id` or a `chat_group_id`.\n\t\tstart_date (str): The START date of the retrieving date limit. Defaults to None.\n\t\t\tIf given, it should be given in the following FORMAT: Year-Month-Day.\n\t\t\tFor example, 2020-12-1 means the year 2020, the 12th month, the 1rst day.\n\t\tend_date (str): The END date of the retrieving date limit. Defaults to None.\n\t\t\tIf given, It should be given in the following FORMAT: Year-Month-Day.\n\t\t\tFor example, 2024-6-2 means the year 2024, the 6th month, the 2nd day.\n\n\tReturns:\n\t\tRetrieved chat history.\n\t\"\"\"\n\t# This docstring is used as the tool description.\n\t# set self.memory_index according to the user_id.\n\tif self.memory is None or self.memory.memory_id != memory_id:\n\t\tself.memory = ChatVectorMemory.from_memory_id(memory_id=memory_id, embed_model=self.embed_model,\n\t\t\tretriever_kwargs={}, )\n\t\tself.memory_vector_retriever = self.get_memory_vector_retriever()\n\n\t# get the candidate date list.\n\tdate_list = self._parse_date(start_date_str=start_date, end_date_str=end_date)\n\tmetadata_filters =  MetadataFilters(\n\t\tfilters=[\n\t\t\tself.get_date_filter(date_list=date_list),\n\t\t]\n\t)\n\tself.memory_vector_retriever._filters = metadata_filters\n\tchat_nodes = self.memory_vector_retriever.retrieve(item_to_be_retrieved)\n\tself.reset_vector_retriever()\n\t# get the results, add prev node and next node to it (if in a same date.).\n\tif self.final_use_context:\n\t\tchat_nodes = self._add_context(content_nodes=chat_nodes)\n\treturn chat_nodes\n</code></pre>"},{"location":"code_docs/func_modules/memory/chat/short_memory/","title":"Short memory","text":""},{"location":"code_docs/func_modules/memory/chat/short_memory/#labridge.func_modules.memory.chat.short_memory","title":"<code>labridge.func_modules.memory.chat.short_memory</code>","text":""},{"location":"code_docs/func_modules/memory/chat/short_memory/#labridge.func_modules.memory.chat.short_memory.ShortMemoryManager","title":"<code>labridge.func_modules.memory.chat.short_memory.ShortMemoryManager</code>","text":"<p>               Bases: <code>object</code></p> <p>This class manage the short-term chat memories between the agent and users.</p> ATTRIBUTE DESCRIPTION <code>_root</code> <p>The project root.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>_valid_delta_days</code> <p>Only valid chat histories will be loaded.</p> <p> TYPE: <code>Optional[int]</code> </p> <code>_valid_delta_hours</code> <p>Same as above.</p> <p> TYPE: <code>Optional[int]</code> </p> <code>_valid_delta_minutes</code> <p>Same as above.</p> <p> TYPE: <code>Optional[int]</code> </p> Source code in <code>labridge\\func_modules\\memory\\chat\\short_memory.py</code> <pre><code>class ShortMemoryManager(object):\n\tr\"\"\"\n\tThis class manage the short-term chat memories between the agent and users.\n\n\tAttributes:\n\t\t_root (Optional[str]): The project root.\n\t\t_valid_delta_days (Optional[int]): Only valid chat histories will be loaded.\n\t\t_valid_delta_hours (Optional[int]): Same as above.\n\t\t_valid_delta_minutes (Optional[int]): Same as above.\n\t\"\"\"\n\t_root: Optional[str] = None\n\t_valid_delta_days: Optional[int] = 0\n\t_valid_delta_hours: Optional[int] = 2\n\t_valid_delta_minutes: Optional[int] = 30\n\n\t@property\n\tdef root(self) -&gt; str:\n\t\tr\"\"\" Return the project root \"\"\"\n\t\tif self._root is None:\n\t\t\troot_dir = Path(__file__)\n\t\t\tfor idx in range(5):\n\t\t\t\troot_dir = root_dir.parent\n\t\t\tself._root = str(root_dir)\n\t\treturn self._root\n\n\t@property\n\tdef valid_delta_time(self) -&gt; datetime.timedelta:\n\t\tr\"\"\" Return the valid time delta. \"\"\"\n\t\treturn datetime.timedelta(\n\t\t\tdays=self._valid_delta_days,\n\t\t\thours=self._valid_delta_hours,\n\t\t\tminutes=self._valid_delta_minutes,\n\t\t)\n\n\t@staticmethod\n\tdef _pack_time_key(date_str: str, time_str: str) -&gt; str:\n\t\treturn f\"{date_str} {time_str}\"\n\n\t@staticmethod\n\tdef _unpack_time_key(time_key: str) -&gt; datetime.datetime:\n\t\tdate_str, time_str = time_key.split()\n\t\tlast_datetime = str_to_datetime(date_str=date_str, time_str=time_str)\n\t\treturn last_datetime\n\n\tdef clear_memory(self, user_id: str):\n\t\tpersist_path = Path(self.root) / f\"{SHORT_MEMORY_PERSIST_DIR}/{user_id}.json\"\n\t\tfs = fsspec.filesystem(\"file\")\n\t\tif fs.exists(persist_path):\n\t\t\tfs.rm(persist_path)\n\n\tdef load_memory(self, user_id: str) -&gt; Optional[List[ChatMessage]]:\n\t\tr\"\"\"\n\t\tOnly chat messages within the valid time delta will be loaded.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user_id of a lab member.\n\n\t\tReturns:\n\t\t\tThe loaded short memory:\n\t\t\t\tIf the short memory storage does not exist or the datetime of the short memory is invalid, return None.\n\t\t\"\"\"\n\t\tpersist_path = Path(self.root) / f\"{SHORT_MEMORY_PERSIST_DIR}/{user_id}.json\"\n\t\tfs = fsspec.filesystem(\"file\")\n\t\tif not fs.exists(persist_path):\n\t\t\treturn None\n\n\t\tchat_store = SimpleChatStore.from_persist_path(persist_path=str(persist_path))\n\t\tkeys = chat_store.get_keys()\n\t\tif len(keys) &lt; 1:\n\t\t\tfs.rm(persist_path)\n\t\t\treturn None\n\t\ttime_key = chat_store.get_keys()[0]\n\t\tlast_datetime = self._unpack_time_key(time_key=time_key)\n\t\tnow = datetime.datetime.now()\n\t\tif last_datetime + self.valid_delta_time &lt; now:\n\t\t\treturn None\n\t\treturn chat_store.store[time_key]\n\n\tdef save_memory(self, user_id: str, chat_history: List[ChatMessage]):\n\t\tr\"\"\"\n\t\tPersist the short-term memory for the user's next chat request.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user id of a Lab member.\n\t\t\tchat_history (List[ChatMessage]): Current chat history between the user and agent.\n\t\t\"\"\"\n\t\tdate, h_m_s = get_time()\n\t\ttime_key = self._pack_time_key(date_str=date, time_str=h_m_s)\n\t\tstore_dict = {\n\t\t\ttime_key: chat_history,\n\t\t}\n\t\tchat_store = SimpleChatStore(store=store_dict)\n\t\tpersist_path = Path(self.root) / f\"{SHORT_MEMORY_PERSIST_DIR}/{user_id}.json\"\n\t\tpersist_path = str(persist_path)\n\t\tchat_store.persist(persist_path=persist_path)\n</code></pre>"},{"location":"code_docs/func_modules/memory/chat/short_memory/#labridge.func_modules.memory.chat.short_memory.ShortMemoryManager.root","title":"<code>labridge.func_modules.memory.chat.short_memory.ShortMemoryManager.root: str</code>  <code>property</code>","text":"<p>Return the project root</p>"},{"location":"code_docs/func_modules/memory/chat/short_memory/#labridge.func_modules.memory.chat.short_memory.ShortMemoryManager.valid_delta_time","title":"<code>labridge.func_modules.memory.chat.short_memory.ShortMemoryManager.valid_delta_time: datetime.timedelta</code>  <code>property</code>","text":"<p>Return the valid time delta.</p>"},{"location":"code_docs/func_modules/memory/chat/short_memory/#labridge.func_modules.memory.chat.short_memory.ShortMemoryManager.load_memory","title":"<code>labridge.func_modules.memory.chat.short_memory.ShortMemoryManager.load_memory(user_id)</code>","text":"<p>Only chat messages within the valid time delta will be loaded.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user_id of a lab member.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Optional[List[ChatMessage]]</code> <p>The loaded short memory: If the short memory storage does not exist or the datetime of the short memory is invalid, return None.</p> Source code in <code>labridge\\func_modules\\memory\\chat\\short_memory.py</code> <pre><code>def load_memory(self, user_id: str) -&gt; Optional[List[ChatMessage]]:\n\tr\"\"\"\n\tOnly chat messages within the valid time delta will be loaded.\n\n\tArgs:\n\t\tuser_id (str): The user_id of a lab member.\n\n\tReturns:\n\t\tThe loaded short memory:\n\t\t\tIf the short memory storage does not exist or the datetime of the short memory is invalid, return None.\n\t\"\"\"\n\tpersist_path = Path(self.root) / f\"{SHORT_MEMORY_PERSIST_DIR}/{user_id}.json\"\n\tfs = fsspec.filesystem(\"file\")\n\tif not fs.exists(persist_path):\n\t\treturn None\n\n\tchat_store = SimpleChatStore.from_persist_path(persist_path=str(persist_path))\n\tkeys = chat_store.get_keys()\n\tif len(keys) &lt; 1:\n\t\tfs.rm(persist_path)\n\t\treturn None\n\ttime_key = chat_store.get_keys()[0]\n\tlast_datetime = self._unpack_time_key(time_key=time_key)\n\tnow = datetime.datetime.now()\n\tif last_datetime + self.valid_delta_time &lt; now:\n\t\treturn None\n\treturn chat_store.store[time_key]\n</code></pre>"},{"location":"code_docs/func_modules/memory/chat/short_memory/#labridge.func_modules.memory.chat.short_memory.ShortMemoryManager.save_memory","title":"<code>labridge.func_modules.memory.chat.short_memory.ShortMemoryManager.save_memory(user_id, chat_history)</code>","text":"<p>Persist the short-term memory for the user's next chat request.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user id of a Lab member.</p> <p> TYPE: <code>str</code> </p> <code>chat_history</code> <p>Current chat history between the user and agent.</p> <p> TYPE: <code>List[ChatMessage]</code> </p> Source code in <code>labridge\\func_modules\\memory\\chat\\short_memory.py</code> <pre><code>def save_memory(self, user_id: str, chat_history: List[ChatMessage]):\n\tr\"\"\"\n\tPersist the short-term memory for the user's next chat request.\n\n\tArgs:\n\t\tuser_id (str): The user id of a Lab member.\n\t\tchat_history (List[ChatMessage]): Current chat history between the user and agent.\n\t\"\"\"\n\tdate, h_m_s = get_time()\n\ttime_key = self._pack_time_key(date_str=date, time_str=h_m_s)\n\tstore_dict = {\n\t\ttime_key: chat_history,\n\t}\n\tchat_store = SimpleChatStore(store=store_dict)\n\tpersist_path = Path(self.root) / f\"{SHORT_MEMORY_PERSIST_DIR}/{user_id}.json\"\n\tpersist_path = str(persist_path)\n\tchat_store.persist(persist_path=persist_path)\n</code></pre>"},{"location":"code_docs/func_modules/memory/experiment/experiment_log/","title":"Experiment log","text":""},{"location":"code_docs/func_modules/memory/experiment/experiment_log/#labridge.func_modules.memory.experiment.experiment_log","title":"<code>labridge.func_modules.memory.experiment.experiment_log</code>","text":""},{"location":"code_docs/func_modules/memory/experiment/experiment_log/#labridge.func_modules.memory.experiment.experiment_log.ExperimentLog","title":"<code>labridge.func_modules.memory.experiment.experiment_log.ExperimentLog</code>","text":"<p>               Bases: <code>object</code></p> <p>This class stores the experiment logs for a specific user. It is constructed as a tree, with a root node. Different experiments are inserted as child nodes of the tree node. For each experiment node, TextNodes recording experiment logs are stored as its child nodes in chronological order. Like:</p> <pre><code>                                                                                root_node\n                                                                        /                               \\\n                                                                   /                             \\\n                                                        Experiment1                     Experiment2\n                                        /               ...                             \\\n                                log1 --next-&gt; ... --next-&gt; log n\n</code></pre> <p>Additionally, a recent_experiment node records the most recent experiment of the user, with the start time and the end time of the experiment.</p> PARAMETER DESCRIPTION <code>vector_index</code> <p>The vector database storing the experiment logs.</p> <p> TYPE: <code>VectorStoreIndex</code> </p> <code>persist_dir</code> <p>The persist directory.</p> <p> TYPE: <code>str</code> </p> Note <p>The metadata <code>date</code> and <code>time</code> is recorded in a list format for the convenience of metadata filtering. For example: ['2024-08-10'], ['09:05:03'].</p> Source code in <code>labridge\\func_modules\\memory\\experiment\\experiment_log.py</code> <pre><code>class ExperimentLog(object):\n\tr\"\"\"\n\tThis class stores the experiment logs for a specific user.\n\tIt is constructed as a tree, with a root node. Different experiments are inserted as child nodes of the tree node.\n\tFor each experiment node, TextNodes recording experiment logs are stored as its child nodes in chronological order.\n\tLike:\n\n\t```\n\t\t\t\t\t\t\t\t\t\t\troot_node\n\t\t\t\t\t\t\t\t\t\t/\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t   /\t\t\t\t \\\n\t\t\t\t\t\t\t\tExperiment1\t\t\tExperiment2\n\t\t\t\t\t\t/\t\t...\t\t\t\t\\\n\t\t\t\t\tlog1 --next-&gt; ... --next-&gt; log n\n\t```\n\n\tAdditionally, a recent_experiment node records the most recent experiment of the user, with the start time and the\n\tend time of the experiment.\n\n\tArgs:\n\t\tvector_index (VectorStoreIndex): The vector database storing the experiment logs.\n\t\tpersist_dir (str): The persist directory.\n\n\tNote:\n\t\tThe metadata `date` and `time` is recorded in a list format for the convenience of metadata filtering.\n\t\tFor example: ['2024-08-10'], ['09:05:03'].\n\t\"\"\"\n\tdef __init__(self, vector_index: VectorStoreIndex, persist_dir: str):\n\t\tself.vector_index = vector_index\n\t\tself.vector_index.set_index_id(EXPERIMENT_LOG_VECTOR_INDEX_ID)\n\t\tself.persist_dir = persist_dir\n\t\tself._fs = fsspec.filesystem(\"file\")\n\t\troot = Path(__file__)\n\t\tfor idx in range(5):\n\t\t\troot = root.parent\n\t\tself._root = root\n\n\t@classmethod\n\tdef from_storage(\n\t\tcls,\n\t\tpersist_dir: str,\n\t\tembed_model: BaseEmbedding,\n\t):\n\t\tr\"\"\"\n\t\tLoad from an existing storage.\n\n\t\tArgs:\n\t\t\tpersist_dir (str): The persist directory of an existing storage.\n\t\t\tembed_model (BaseEmbedding): The used embedding model.\n\n\t\tReturns:\n\t\t\tExperimentLog\n\t\t\"\"\"\n\t\tvector_storage_context = StorageContext.from_defaults(persist_dir=persist_dir)\n\t\tvector_index = load_index_from_storage(\n\t\t\tstorage_context=vector_storage_context,\n\t\t\tindex_id=EXPERIMENT_LOG_VECTOR_INDEX_ID,\n\t\t\tembed_model=embed_model,\n\t\t)\n\t\treturn cls(\n\t\t\tvector_index=vector_index,\n\t\t\tpersist_dir=persist_dir,\n\t\t)\n\n\t@property\n\tdef user_id(self)-&gt;str:\n\t\tr\"\"\" Get the corresponding user_id of this storage \"\"\"\n\t\troot = Path(__file__)\n\t\tfor idx in range(5):\n\t\t\troot = root.parent\n\n\t\tuser_id = Path(self.persist_dir).relative_to(root / EXPERIMENT_LOG_PERSIST_DIR)\n\t\treturn str(user_id)\n\n\tdef update(self):\n\t\tr\"\"\" Reload from the disk. \"\"\"\n\t\treturn self.from_user_id(\n\t\t\tuser_id=self.user_id,\n\t\t\tembed_model=self.vector_index._embed_model,\n\t\t)\n\n\t@classmethod\n\tdef from_user_id(\n\t\tcls,\n\t\tuser_id: str,\n\t\tembed_model: BaseEmbedding,\n\t):\n\t\tr\"\"\"\n\t\tConstruct from a user_id.\n\t\tIf the persist directory of the user_id does not exist, a new ExperimentLog will be created for the user.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user_id of a Lab member.\n\t\t\tembed_model (BaseEmbedding): The used embedding model.\n\n\t\tReturns:\n\t\t\tExperimentLog\n\t\t\"\"\"\n\t\taccount_manager = AccountManager()\n\t\taccount_manager.check_valid_user(user_id=user_id)\n\n\t\troot = Path(__file__)\n\t\tfor idx in range(5):\n\t\t\troot = root.parent\n\n\t\tpersist_dir = str(root / f\"{EXPERIMENT_LOG_PERSIST_DIR}/{user_id}\")\n\t\tfs = fsspec.filesystem(\"file\")\n\t\tif fs.exists(persist_dir):\n\t\t\treturn cls.from_storage(\n\t\t\t\tpersist_dir=persist_dir,\n\t\t\t\tembed_model=embed_model,\n\t\t\t)\n\n\t\t# root node.\n\t\tdate, h_m_s = get_time()\n\t\troot_node = TextNode(\n\t\t\ttext=f\"Root node for the experiment logs of {user_id}\",\n\t\t\tid_=INIT_NODE_NAME,\n\t\t\tmetadata={\n\t\t\t\tLOG_DATE_NAME: [date,],\n\t\t\t\tLOG_TIME_NAME: [h_m_s,],\n\t\t\t\tMEMORY_NODE_TYPE_NAME: NOT_LOG_NODE_TYPE,\n\t\t\t}\n\t\t)\n\t\t# record the most recent experiment.\n\t\trecent_expr_node = TextNode(\n\t\t\ttext=f\"The most recent experiment of the user {user_id}\",\n\t\t\tid_=RECENT_EXPERIMENT_NODE_NAME,\n\t\t\tmetadata={\n\t\t\t\tRECENT_EXPERIMENT_NAME_KEY: None,\n\t\t\t\tRECENT_EXPERIMENT_START_TIME_KEY: None,\n\t\t\t\tRECENT_EXPERIMENT_END_TIME_KEY: None,\n\t\t\t\tLOG_DATE_NAME: [date,],\n\t\t\t\tLOG_TIME_NAME: [h_m_s,],\n\t\t\t\tMEMORY_NODE_TYPE_NAME: NOT_LOG_NODE_TYPE,\n\t\t\t}\n\t\t)\n\t\tnodes = [root_node, recent_expr_node]\n\t\tvector_index = VectorStoreIndex(\n\t\t\tnodes=nodes,\n\t\t\tembed_model=embed_model,\n\t\t)\n\t\treturn cls(\n\t\t\tvector_index=vector_index,\n\t\t\tpersist_dir=persist_dir,\n\t\t)\n\n\tdef get_recent_experiment(self) -&gt; Optional[str]:\n\t\tr\"\"\" Get the most recent experiment name. \"\"\"\n\t\trecent_node = self._get_node(node_id=RECENT_EXPERIMENT_NODE_NAME)\n\t\tmetadata = recent_node.metadata\n\n\t\texpr_name = metadata[RECENT_EXPERIMENT_NAME_KEY]\n\t\tif expr_name is None:\n\t\t\treturn None\n\n\t\tstart_date_str, start_time_str = metadata[RECENT_EXPERIMENT_START_TIME_KEY]\n\t\tend_date_str, end_time_str = metadata[RECENT_EXPERIMENT_END_TIME_KEY]\n\n\t\ttry:\n\t\t\tstart = str_to_datetime(date_str=start_date_str, time_str=start_time_str)\n\t\t\tend = str_to_datetime(date_str=end_date_str, time_str=end_time_str)\n\t\t\tdate, h_m_s = get_time()\n\t\t\tcurrent = str_to_datetime(date_str=date, time_str=h_m_s)\n\t\t\tif start &lt;= current &lt;= end:\n\t\t\t\treturn expr_name\n\t\t\treturn None\n\t\texcept Exception as e:\n\t\t\tprint(f\"Error in get_recent_experiment: {e}\")\n\t\t\treturn None\n\n\tdef get_all_experiments(self) -&gt; Optional[List[str]]:\n\t\tr\"\"\" Get all experiment names. \"\"\"\n\t\troot_node = self._get_node(node_id=INIT_NODE_NAME)\n\t\texpr_list = root_node.child_nodes\n\t\tif expr_list:\n\t\t\treturn [expr.node_id for expr in expr_list]\n\t\treturn None\n\n\tdef get_all_experiments_with_description(self) -&gt; Optional[Dict[str, str]]:\n\t\tr\"\"\" Get all experiment names and their descriptions. \"\"\"\n\t\troot_node = self._get_node(node_id=INIT_NODE_NAME)\n\t\texpr_list = root_node.child_nodes\n\n\t\texperiments = {}\n\t\tif expr_list:\n\t\t\tfor child in expr_list:\n\t\t\t\texpr_id = child.node_id\n\t\t\t\texpr_node = self._get_node(node_id=expr_id)\n\t\t\t\texperiments[expr_id] = expr_node.text\n\t\t\treturn experiments\n\t\treturn None\n\n\tdef set_recent_experiment(\n\t\tself,\n\t\texperiment_name: str,\n\t\tstart_date: str,\n\t\tstart_time: str,\n\t\tend_date: str,\n\t\tend_time: str,\n\t):\n\t\tr\"\"\"\n\t\tSet the most recent (or actually, in progress) experiment and its duration.\n\n\t\tArgs:\n\t\t\texperiment_name (str): The experiment name to be set in progress.\n\t\t\tstart_date (str): The formatted string of the start date of the experiment.\n\t\t\tstart_time (str): The formatted string of the start time of the experiment.\n\t\t\tend_date (str): The formatted string of the end date of the experiment.\n\t\t\tend_time (str): The formatted string of the end time of the experiment.\n\t\t\"\"\"\n\t\texpr_list = self.get_all_experiments()\n\t\tif experiment_name not in expr_list:\n\t\t\traise ValueError(\n\t\t\t\tf\"The experiment {experiment_name} \" \n\t\t\t\tf\"does not exist in the experiment log memory of the user {self.user_id}\"\n\t\t\t)\n\n\t\trecent_node = self._get_node(node_id=RECENT_EXPERIMENT_NODE_NAME)\n\t\trecent_node.metadata[RECENT_EXPERIMENT_START_TIME_KEY] = (\n\t\t\tstart_date, start_time\n\t\t)\n\t\trecent_node.metadata[RECENT_EXPERIMENT_END_TIME_KEY] = (\n\t\t\tend_date, end_time\n\t\t)\n\t\trecent_node.metadata[RECENT_EXPERIMENT_NAME_KEY] = experiment_name\n\t\tself._update_node(\n\t\t\tnode_id=RECENT_EXPERIMENT_NODE_NAME,\n\t\t\tnode=recent_node,\n\t\t)\n\n\tdef _get_node(self, node_id: str) -&gt; BaseNode:\n\t\tr\"\"\" Get node. \"\"\"\n\t\treturn self.vector_index.docstore.get_node(node_id)\n\n\tdef _update_node(\n\t\tself,\n\t\tnode_id: str,\n\t\tnode: BaseNode,\n\t):\n\t\t\"\"\" Update an existing node. \"\"\"\n\t\tself.vector_index.delete_nodes([node_id])\n\t\tself.vector_index.insert_nodes([node])\n\n\tdef is_expr_exist(self, experiment_name: str) -&gt; bool:\n\t\tr\"\"\"\n\t\tWhether an experiment exists in the storage.\n\n\t\tArgs:\n\t\t\texperiment_name (str): The experiment name.\n\n\t\tReturns:\n\t\t\tbool: Whether the experiment exists.\n\t\t\"\"\"\n\t\troot_node = self._get_node(node_id=INIT_NODE_NAME)\n\t\texpr_list = root_node.relationships[NodeRelationship.CHILD]\n\t\treturn experiment_name in [expr.node_id for expr in expr_list]\n\n\tdef get_expr_log_node_ids(self, experiment_name: str) -&gt; List[str]:\n\t\tr\"\"\"\n\t\tGet the log node ids of a specific experiment.\n\n\t\tArgs:\n\t\t\texperiment_name (str): The experiment name.\n\n\t\tReturns:\n\t\t\tList[str]: The log node ids of the experiment node.\n\t\t\"\"\"\n\t\texpr_node = self._get_node(node_id=experiment_name)\n\t\treturn [log_node.node_id for log_node in expr_node.child_nodes]\n\n\tdef create_experiment(self, experiment_name: str, description: str):\n\t\tr\"\"\"\n\t\tAdd a new experiment.\n\n\t\tArgs:\n\t\t\texperiment_name (str): The experiment name.\n\t\t\tdescription (str): The experiment description.\n\t\t\"\"\"\n\t\troot_node = self._get_node(node_id=INIT_NODE_NAME)\n\t\texpr_list = root_node.child_nodes or []\n\t\tif experiment_name in [expr.node_id for expr in expr_list]:\n\t\t\traise ValueError(f\"The experiment name {experiment_name} already exists.\")\n\n\t\tnew_expr_node = self._new_node(\n\t\t\ttext=description,\n\t\t\tnode_id=experiment_name,\n\t\t\tnode_type=NOT_LOG_NODE_TYPE,\n\t\t)\n\n\t\texpr_header_node = self._new_node(\n\t\t\ttext=f\"The log beginning of the experiment {experiment_name}\",\n\t\t\tnode_id=f\"{experiment_name}_header\",\n\t\t\tnode_type=LOG_NODE_TYPE\n\t\t)\n\t\tnew_expr_node.relationships[NodeRelationship.CHILD] = [RelatedNodeInfo(node_id=expr_header_node.node_id)]\n\t\texpr_header_node.relationships[NodeRelationship.PARENT] = RelatedNodeInfo(node_id=new_expr_node.node_id)\n\n\t\tlast_info_node = self._new_node(\n\t\t\ttext=expr_header_node.node_id,\n\t\t\tnode_id=f\"{experiment_name}_{EXPERIMENT_LAST_NODE_ID_PREFIX}\",\n\t\t\tnode_type=NOT_LOG_NODE_TYPE,\n\t\t)\n\n\t\texpr_list.append(\n\t\t\tRelatedNodeInfo(node_id=new_expr_node.node_id)\n\t\t)\n\t\troot_node.relationships[NodeRelationship.CHILD] = expr_list\n\t\tself._update_node(node_id=INIT_NODE_NAME, node=root_node)\n\n\t\tself.vector_index.insert_nodes(\n\t\t\t[\n\t\t\t\tnew_expr_node,\n\t\t\t\texpr_header_node,\n\t\t\t\tlast_info_node,\n\t\t\t]\n\t\t)\n\n\tdef _new_node(\n\t\tself,\n\t\ttext: str,\n\t\tnode_type: str,\n\t\tnode_id: str = None,\n\t\textra_metadata: dict = None,\n\t) -&gt; TextNode:\n\t\tr\"\"\" A new node with `node_type` \"\"\"\n\t\tdate, h_m_s = get_time()\n\t\tmetadata = extra_metadata or dict()\n\t\tmetadata.update(\n\t\t\t{\n\t\t\t\tLOG_DATE_NAME: [date, ],\n\t\t\t\tLOG_TIME_NAME: [h_m_s, ],\n\t\t\t\tMEMORY_NODE_TYPE_NAME: node_type,\n\t\t\t}\n\t\t)\n\n\t\tnode = TextNode(\n\t\t\tid_=node_id or str(uuid.uuid4()),\n\t\t\ttext=text,\n\t\t\tmetadata=metadata,\n\t\t)\n\t\tnode.excluded_embed_metadata_keys = [MEMORY_NODE_TYPE_NAME, ]\n\t\tnode.excluded_llm_metadata_keys = [MEMORY_NODE_TYPE_NAME, ]\n\t\treturn node\n\n\tdef record_attachment(self, file_path: str) -&gt; str:\n\t\tif not self._fs.exists(file_path):\n\t\t\traise ValueError(f\"The path of the attachment file is not valid: {file_path}\")\n\n\t\tdate, h_m_s = get_time()\n\t\trecord_dir = str(self._root / f\"{EXPERIMENT_LOG_ATTACHMENT_DIR}/{self.user_id}/{date}\")\n\t\tif not self._fs.exists(record_dir):\n\t\t\tself._fs.mkdirs(record_dir)\n\n\t\tself._fs.cp(file_path, record_dir)\n\n\t\tfile_name = Path(file_path).name\n\t\trecord_path = f\"{record_dir}/{file_name}\"\n\t\treturn record_path\n\n\tdef put(\n\t\tself,\n\t\texperiment_name: str,\n\t\tlog_str: str,\n\t\tattached_file_path: str = None,\n\t):\n\t\tr\"\"\"\n\t\tPut in an experiment log into a specific experiment store.\n\n\t\tThese operations are done:\n\n\t\t- last_log_node -&gt; set_next(new_log_node)\n\t\t- new_log_node -&gt; set_previous(last_log_node)\n\t\t- last_store_node -&gt; set_content(new_log_node.node_id)\n\t\t- experiment_node -&gt; add_child(new_log_node)\n\n\t\tArgs:\n\t\t\texperiment_name (str): An existing experiment name.\n\t\t\tlog_str (str): The experiment log string to be put in.\n\t\t\tattached_file_path (str): The path of the attached file. Defaults to None.\n\t\t\"\"\"\n\t\t# TODO: Support files.\n\t\troot_node = self._get_node(node_id=INIT_NODE_NAME)\n\t\texperiments = root_node.child_nodes\n\t\tif experiments is None or experiment_name not in [expr.node_id for expr in experiments]:\n\t\t\traise ValueError(f\"The experiment {experiment_name} of user {self.user_id} does not exist.\")\n\n\t\textra_metadata = None\n\t\tif attached_file_path is not None:\n\t\t\trecord_path = self.record_attachment(file_path=attached_file_path)\n\t\t\textra_metadata = {\n\t\t\t\tEXPERIMENT_LOG_ATTACHMENT_KEY: record_path,\n\t\t\t}\n\n\t\tnew_log_node = self._new_node(\n\t\t\ttext=log_str,\n\t\t\tnode_type=LOG_NODE_TYPE,\n\t\t\textra_metadata=extra_metadata,\n\t\t)\n\t\texpr_node = self._get_node(node_id=experiment_name)\n\t\tlast_store_name = f\"{experiment_name}_{EXPERIMENT_LAST_NODE_ID_PREFIX}\"\n\t\tlast_store_node = self._get_node(node_id=last_store_name)\n\t\tlast_log_id = last_store_node.text\n\t\tlast_log_node = self._get_node(last_log_id)\n\t\tlast_log_node.relationships[NodeRelationship.NEXT] = RelatedNodeInfo(\n\t\t\tnode_id=new_log_node.node_id\n\t\t)\n\t\tnew_log_node.relationships[NodeRelationship.PREVIOUS] = RelatedNodeInfo(\n\t\t\tnode_id=last_log_node.node_id\n\t\t)\n\t\tnew_log_node.relationships[NodeRelationship.PARENT] = RelatedNodeInfo(\n\t\t\tnode_id=expr_node.node_id\n\t\t)\n\t\tlast_store_node.set_content(new_log_node.node_id)\n\t\tself._update_node(node_id=last_log_id, node=last_log_node)\n\t\tself._update_node(node_id=last_store_name, node=last_store_node)\n\n\t\tlog_node_list = expr_node.child_nodes or []\n\t\tlog_node_list.append(\n\t\t\tRelatedNodeInfo(node_id=new_log_node.node_id)\n\t\t)\n\t\texpr_node.relationships[NodeRelationship.CHILD] = log_node_list\n\t\tself._update_node(node_id=experiment_name, node=expr_node)\n\t\tprint(\"Parent: \", new_log_node.parent_node.node_id)\n\t\tself.vector_index.insert_nodes([new_log_node])\n\n\tdef persist(self, persist_dir: str = None):\n\t\tr\"\"\"\n\t\tPersist to disk.\n\n\t\tArgs:\n\t\t\tpersist_dir (str): The persist directory. If not given, use `self.directory`.\n\t\t\"\"\"\n\t\tpersist_dir = persist_dir or self.persist_dir\n\t\tfs = fsspec.filesystem(\"file\")\n\t\tif not fs.exists(persist_dir):\n\t\t\tfs.makedirs(persist_dir)\n\t\tself.vector_index.storage_context.persist(persist_dir=persist_dir)\n</code></pre>"},{"location":"code_docs/func_modules/memory/experiment/experiment_log/#labridge.func_modules.memory.experiment.experiment_log.ExperimentLog.user_id","title":"<code>labridge.func_modules.memory.experiment.experiment_log.ExperimentLog.user_id: str</code>  <code>property</code>","text":"<p>Get the corresponding user_id of this storage</p>"},{"location":"code_docs/func_modules/memory/experiment/experiment_log/#labridge.func_modules.memory.experiment.experiment_log.ExperimentLog.create_experiment","title":"<code>labridge.func_modules.memory.experiment.experiment_log.ExperimentLog.create_experiment(experiment_name, description)</code>","text":"<p>Add a new experiment.</p> PARAMETER DESCRIPTION <code>experiment_name</code> <p>The experiment name.</p> <p> TYPE: <code>str</code> </p> <code>description</code> <p>The experiment description.</p> <p> TYPE: <code>str</code> </p> Source code in <code>labridge\\func_modules\\memory\\experiment\\experiment_log.py</code> <pre><code>def create_experiment(self, experiment_name: str, description: str):\n\tr\"\"\"\n\tAdd a new experiment.\n\n\tArgs:\n\t\texperiment_name (str): The experiment name.\n\t\tdescription (str): The experiment description.\n\t\"\"\"\n\troot_node = self._get_node(node_id=INIT_NODE_NAME)\n\texpr_list = root_node.child_nodes or []\n\tif experiment_name in [expr.node_id for expr in expr_list]:\n\t\traise ValueError(f\"The experiment name {experiment_name} already exists.\")\n\n\tnew_expr_node = self._new_node(\n\t\ttext=description,\n\t\tnode_id=experiment_name,\n\t\tnode_type=NOT_LOG_NODE_TYPE,\n\t)\n\n\texpr_header_node = self._new_node(\n\t\ttext=f\"The log beginning of the experiment {experiment_name}\",\n\t\tnode_id=f\"{experiment_name}_header\",\n\t\tnode_type=LOG_NODE_TYPE\n\t)\n\tnew_expr_node.relationships[NodeRelationship.CHILD] = [RelatedNodeInfo(node_id=expr_header_node.node_id)]\n\texpr_header_node.relationships[NodeRelationship.PARENT] = RelatedNodeInfo(node_id=new_expr_node.node_id)\n\n\tlast_info_node = self._new_node(\n\t\ttext=expr_header_node.node_id,\n\t\tnode_id=f\"{experiment_name}_{EXPERIMENT_LAST_NODE_ID_PREFIX}\",\n\t\tnode_type=NOT_LOG_NODE_TYPE,\n\t)\n\n\texpr_list.append(\n\t\tRelatedNodeInfo(node_id=new_expr_node.node_id)\n\t)\n\troot_node.relationships[NodeRelationship.CHILD] = expr_list\n\tself._update_node(node_id=INIT_NODE_NAME, node=root_node)\n\n\tself.vector_index.insert_nodes(\n\t\t[\n\t\t\tnew_expr_node,\n\t\t\texpr_header_node,\n\t\t\tlast_info_node,\n\t\t]\n\t)\n</code></pre>"},{"location":"code_docs/func_modules/memory/experiment/experiment_log/#labridge.func_modules.memory.experiment.experiment_log.ExperimentLog.from_storage","title":"<code>labridge.func_modules.memory.experiment.experiment_log.ExperimentLog.from_storage(persist_dir, embed_model)</code>  <code>classmethod</code>","text":"<p>Load from an existing storage.</p> PARAMETER DESCRIPTION <code>persist_dir</code> <p>The persist directory of an existing storage.</p> <p> TYPE: <code>str</code> </p> <code>embed_model</code> <p>The used embedding model.</p> <p> TYPE: <code>BaseEmbedding</code> </p> RETURNS DESCRIPTION <p>ExperimentLog</p> Source code in <code>labridge\\func_modules\\memory\\experiment\\experiment_log.py</code> <pre><code>@classmethod\ndef from_storage(\n\tcls,\n\tpersist_dir: str,\n\tembed_model: BaseEmbedding,\n):\n\tr\"\"\"\n\tLoad from an existing storage.\n\n\tArgs:\n\t\tpersist_dir (str): The persist directory of an existing storage.\n\t\tembed_model (BaseEmbedding): The used embedding model.\n\n\tReturns:\n\t\tExperimentLog\n\t\"\"\"\n\tvector_storage_context = StorageContext.from_defaults(persist_dir=persist_dir)\n\tvector_index = load_index_from_storage(\n\t\tstorage_context=vector_storage_context,\n\t\tindex_id=EXPERIMENT_LOG_VECTOR_INDEX_ID,\n\t\tembed_model=embed_model,\n\t)\n\treturn cls(\n\t\tvector_index=vector_index,\n\t\tpersist_dir=persist_dir,\n\t)\n</code></pre>"},{"location":"code_docs/func_modules/memory/experiment/experiment_log/#labridge.func_modules.memory.experiment.experiment_log.ExperimentLog.from_user_id","title":"<code>labridge.func_modules.memory.experiment.experiment_log.ExperimentLog.from_user_id(user_id, embed_model)</code>  <code>classmethod</code>","text":"<p>Construct from a user_id. If the persist directory of the user_id does not exist, a new ExperimentLog will be created for the user.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user_id of a Lab member.</p> <p> TYPE: <code>str</code> </p> <code>embed_model</code> <p>The used embedding model.</p> <p> TYPE: <code>BaseEmbedding</code> </p> RETURNS DESCRIPTION <p>ExperimentLog</p> Source code in <code>labridge\\func_modules\\memory\\experiment\\experiment_log.py</code> <pre><code>@classmethod\ndef from_user_id(\n\tcls,\n\tuser_id: str,\n\tembed_model: BaseEmbedding,\n):\n\tr\"\"\"\n\tConstruct from a user_id.\n\tIf the persist directory of the user_id does not exist, a new ExperimentLog will be created for the user.\n\n\tArgs:\n\t\tuser_id (str): The user_id of a Lab member.\n\t\tembed_model (BaseEmbedding): The used embedding model.\n\n\tReturns:\n\t\tExperimentLog\n\t\"\"\"\n\taccount_manager = AccountManager()\n\taccount_manager.check_valid_user(user_id=user_id)\n\n\troot = Path(__file__)\n\tfor idx in range(5):\n\t\troot = root.parent\n\n\tpersist_dir = str(root / f\"{EXPERIMENT_LOG_PERSIST_DIR}/{user_id}\")\n\tfs = fsspec.filesystem(\"file\")\n\tif fs.exists(persist_dir):\n\t\treturn cls.from_storage(\n\t\t\tpersist_dir=persist_dir,\n\t\t\tembed_model=embed_model,\n\t\t)\n\n\t# root node.\n\tdate, h_m_s = get_time()\n\troot_node = TextNode(\n\t\ttext=f\"Root node for the experiment logs of {user_id}\",\n\t\tid_=INIT_NODE_NAME,\n\t\tmetadata={\n\t\t\tLOG_DATE_NAME: [date,],\n\t\t\tLOG_TIME_NAME: [h_m_s,],\n\t\t\tMEMORY_NODE_TYPE_NAME: NOT_LOG_NODE_TYPE,\n\t\t}\n\t)\n\t# record the most recent experiment.\n\trecent_expr_node = TextNode(\n\t\ttext=f\"The most recent experiment of the user {user_id}\",\n\t\tid_=RECENT_EXPERIMENT_NODE_NAME,\n\t\tmetadata={\n\t\t\tRECENT_EXPERIMENT_NAME_KEY: None,\n\t\t\tRECENT_EXPERIMENT_START_TIME_KEY: None,\n\t\t\tRECENT_EXPERIMENT_END_TIME_KEY: None,\n\t\t\tLOG_DATE_NAME: [date,],\n\t\t\tLOG_TIME_NAME: [h_m_s,],\n\t\t\tMEMORY_NODE_TYPE_NAME: NOT_LOG_NODE_TYPE,\n\t\t}\n\t)\n\tnodes = [root_node, recent_expr_node]\n\tvector_index = VectorStoreIndex(\n\t\tnodes=nodes,\n\t\tembed_model=embed_model,\n\t)\n\treturn cls(\n\t\tvector_index=vector_index,\n\t\tpersist_dir=persist_dir,\n\t)\n</code></pre>"},{"location":"code_docs/func_modules/memory/experiment/experiment_log/#labridge.func_modules.memory.experiment.experiment_log.ExperimentLog.get_all_experiments","title":"<code>labridge.func_modules.memory.experiment.experiment_log.ExperimentLog.get_all_experiments()</code>","text":"<p>Get all experiment names.</p> Source code in <code>labridge\\func_modules\\memory\\experiment\\experiment_log.py</code> <pre><code>def get_all_experiments(self) -&gt; Optional[List[str]]:\n\tr\"\"\" Get all experiment names. \"\"\"\n\troot_node = self._get_node(node_id=INIT_NODE_NAME)\n\texpr_list = root_node.child_nodes\n\tif expr_list:\n\t\treturn [expr.node_id for expr in expr_list]\n\treturn None\n</code></pre>"},{"location":"code_docs/func_modules/memory/experiment/experiment_log/#labridge.func_modules.memory.experiment.experiment_log.ExperimentLog.get_all_experiments_with_description","title":"<code>labridge.func_modules.memory.experiment.experiment_log.ExperimentLog.get_all_experiments_with_description()</code>","text":"<p>Get all experiment names and their descriptions.</p> Source code in <code>labridge\\func_modules\\memory\\experiment\\experiment_log.py</code> <pre><code>def get_all_experiments_with_description(self) -&gt; Optional[Dict[str, str]]:\n\tr\"\"\" Get all experiment names and their descriptions. \"\"\"\n\troot_node = self._get_node(node_id=INIT_NODE_NAME)\n\texpr_list = root_node.child_nodes\n\n\texperiments = {}\n\tif expr_list:\n\t\tfor child in expr_list:\n\t\t\texpr_id = child.node_id\n\t\t\texpr_node = self._get_node(node_id=expr_id)\n\t\t\texperiments[expr_id] = expr_node.text\n\t\treturn experiments\n\treturn None\n</code></pre>"},{"location":"code_docs/func_modules/memory/experiment/experiment_log/#labridge.func_modules.memory.experiment.experiment_log.ExperimentLog.get_expr_log_node_ids","title":"<code>labridge.func_modules.memory.experiment.experiment_log.ExperimentLog.get_expr_log_node_ids(experiment_name)</code>","text":"<p>Get the log node ids of a specific experiment.</p> PARAMETER DESCRIPTION <code>experiment_name</code> <p>The experiment name.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>List[str]</code> <p>List[str]: The log node ids of the experiment node.</p> Source code in <code>labridge\\func_modules\\memory\\experiment\\experiment_log.py</code> <pre><code>def get_expr_log_node_ids(self, experiment_name: str) -&gt; List[str]:\n\tr\"\"\"\n\tGet the log node ids of a specific experiment.\n\n\tArgs:\n\t\texperiment_name (str): The experiment name.\n\n\tReturns:\n\t\tList[str]: The log node ids of the experiment node.\n\t\"\"\"\n\texpr_node = self._get_node(node_id=experiment_name)\n\treturn [log_node.node_id for log_node in expr_node.child_nodes]\n</code></pre>"},{"location":"code_docs/func_modules/memory/experiment/experiment_log/#labridge.func_modules.memory.experiment.experiment_log.ExperimentLog.get_recent_experiment","title":"<code>labridge.func_modules.memory.experiment.experiment_log.ExperimentLog.get_recent_experiment()</code>","text":"<p>Get the most recent experiment name.</p> Source code in <code>labridge\\func_modules\\memory\\experiment\\experiment_log.py</code> <pre><code>def get_recent_experiment(self) -&gt; Optional[str]:\n\tr\"\"\" Get the most recent experiment name. \"\"\"\n\trecent_node = self._get_node(node_id=RECENT_EXPERIMENT_NODE_NAME)\n\tmetadata = recent_node.metadata\n\n\texpr_name = metadata[RECENT_EXPERIMENT_NAME_KEY]\n\tif expr_name is None:\n\t\treturn None\n\n\tstart_date_str, start_time_str = metadata[RECENT_EXPERIMENT_START_TIME_KEY]\n\tend_date_str, end_time_str = metadata[RECENT_EXPERIMENT_END_TIME_KEY]\n\n\ttry:\n\t\tstart = str_to_datetime(date_str=start_date_str, time_str=start_time_str)\n\t\tend = str_to_datetime(date_str=end_date_str, time_str=end_time_str)\n\t\tdate, h_m_s = get_time()\n\t\tcurrent = str_to_datetime(date_str=date, time_str=h_m_s)\n\t\tif start &lt;= current &lt;= end:\n\t\t\treturn expr_name\n\t\treturn None\n\texcept Exception as e:\n\t\tprint(f\"Error in get_recent_experiment: {e}\")\n\t\treturn None\n</code></pre>"},{"location":"code_docs/func_modules/memory/experiment/experiment_log/#labridge.func_modules.memory.experiment.experiment_log.ExperimentLog.is_expr_exist","title":"<code>labridge.func_modules.memory.experiment.experiment_log.ExperimentLog.is_expr_exist(experiment_name)</code>","text":"<p>Whether an experiment exists in the storage.</p> PARAMETER DESCRIPTION <code>experiment_name</code> <p>The experiment name.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>Whether the experiment exists.</p> <p> TYPE: <code>bool</code> </p> Source code in <code>labridge\\func_modules\\memory\\experiment\\experiment_log.py</code> <pre><code>def is_expr_exist(self, experiment_name: str) -&gt; bool:\n\tr\"\"\"\n\tWhether an experiment exists in the storage.\n\n\tArgs:\n\t\texperiment_name (str): The experiment name.\n\n\tReturns:\n\t\tbool: Whether the experiment exists.\n\t\"\"\"\n\troot_node = self._get_node(node_id=INIT_NODE_NAME)\n\texpr_list = root_node.relationships[NodeRelationship.CHILD]\n\treturn experiment_name in [expr.node_id for expr in expr_list]\n</code></pre>"},{"location":"code_docs/func_modules/memory/experiment/experiment_log/#labridge.func_modules.memory.experiment.experiment_log.ExperimentLog.persist","title":"<code>labridge.func_modules.memory.experiment.experiment_log.ExperimentLog.persist(persist_dir=None)</code>","text":"<p>Persist to disk.</p> PARAMETER DESCRIPTION <code>persist_dir</code> <p>The persist directory. If not given, use <code>self.directory</code>.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> Source code in <code>labridge\\func_modules\\memory\\experiment\\experiment_log.py</code> <pre><code>def persist(self, persist_dir: str = None):\n\tr\"\"\"\n\tPersist to disk.\n\n\tArgs:\n\t\tpersist_dir (str): The persist directory. If not given, use `self.directory`.\n\t\"\"\"\n\tpersist_dir = persist_dir or self.persist_dir\n\tfs = fsspec.filesystem(\"file\")\n\tif not fs.exists(persist_dir):\n\t\tfs.makedirs(persist_dir)\n\tself.vector_index.storage_context.persist(persist_dir=persist_dir)\n</code></pre>"},{"location":"code_docs/func_modules/memory/experiment/experiment_log/#labridge.func_modules.memory.experiment.experiment_log.ExperimentLog.put","title":"<code>labridge.func_modules.memory.experiment.experiment_log.ExperimentLog.put(experiment_name, log_str, attached_file_path=None)</code>","text":"<p>Put in an experiment log into a specific experiment store.</p> <p>These operations are done:</p> <ul> <li>last_log_node -&gt; set_next(new_log_node)</li> <li>new_log_node -&gt; set_previous(last_log_node)</li> <li>last_store_node -&gt; set_content(new_log_node.node_id)</li> <li>experiment_node -&gt; add_child(new_log_node)</li> </ul> PARAMETER DESCRIPTION <code>experiment_name</code> <p>An existing experiment name.</p> <p> TYPE: <code>str</code> </p> <code>log_str</code> <p>The experiment log string to be put in.</p> <p> TYPE: <code>str</code> </p> <code>attached_file_path</code> <p>The path of the attached file. Defaults to None.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> Source code in <code>labridge\\func_modules\\memory\\experiment\\experiment_log.py</code> <pre><code>def put(\n\tself,\n\texperiment_name: str,\n\tlog_str: str,\n\tattached_file_path: str = None,\n):\n\tr\"\"\"\n\tPut in an experiment log into a specific experiment store.\n\n\tThese operations are done:\n\n\t- last_log_node -&gt; set_next(new_log_node)\n\t- new_log_node -&gt; set_previous(last_log_node)\n\t- last_store_node -&gt; set_content(new_log_node.node_id)\n\t- experiment_node -&gt; add_child(new_log_node)\n\n\tArgs:\n\t\texperiment_name (str): An existing experiment name.\n\t\tlog_str (str): The experiment log string to be put in.\n\t\tattached_file_path (str): The path of the attached file. Defaults to None.\n\t\"\"\"\n\t# TODO: Support files.\n\troot_node = self._get_node(node_id=INIT_NODE_NAME)\n\texperiments = root_node.child_nodes\n\tif experiments is None or experiment_name not in [expr.node_id for expr in experiments]:\n\t\traise ValueError(f\"The experiment {experiment_name} of user {self.user_id} does not exist.\")\n\n\textra_metadata = None\n\tif attached_file_path is not None:\n\t\trecord_path = self.record_attachment(file_path=attached_file_path)\n\t\textra_metadata = {\n\t\t\tEXPERIMENT_LOG_ATTACHMENT_KEY: record_path,\n\t\t}\n\n\tnew_log_node = self._new_node(\n\t\ttext=log_str,\n\t\tnode_type=LOG_NODE_TYPE,\n\t\textra_metadata=extra_metadata,\n\t)\n\texpr_node = self._get_node(node_id=experiment_name)\n\tlast_store_name = f\"{experiment_name}_{EXPERIMENT_LAST_NODE_ID_PREFIX}\"\n\tlast_store_node = self._get_node(node_id=last_store_name)\n\tlast_log_id = last_store_node.text\n\tlast_log_node = self._get_node(last_log_id)\n\tlast_log_node.relationships[NodeRelationship.NEXT] = RelatedNodeInfo(\n\t\tnode_id=new_log_node.node_id\n\t)\n\tnew_log_node.relationships[NodeRelationship.PREVIOUS] = RelatedNodeInfo(\n\t\tnode_id=last_log_node.node_id\n\t)\n\tnew_log_node.relationships[NodeRelationship.PARENT] = RelatedNodeInfo(\n\t\tnode_id=expr_node.node_id\n\t)\n\tlast_store_node.set_content(new_log_node.node_id)\n\tself._update_node(node_id=last_log_id, node=last_log_node)\n\tself._update_node(node_id=last_store_name, node=last_store_node)\n\n\tlog_node_list = expr_node.child_nodes or []\n\tlog_node_list.append(\n\t\tRelatedNodeInfo(node_id=new_log_node.node_id)\n\t)\n\texpr_node.relationships[NodeRelationship.CHILD] = log_node_list\n\tself._update_node(node_id=experiment_name, node=expr_node)\n\tprint(\"Parent: \", new_log_node.parent_node.node_id)\n\tself.vector_index.insert_nodes([new_log_node])\n</code></pre>"},{"location":"code_docs/func_modules/memory/experiment/experiment_log/#labridge.func_modules.memory.experiment.experiment_log.ExperimentLog.set_recent_experiment","title":"<code>labridge.func_modules.memory.experiment.experiment_log.ExperimentLog.set_recent_experiment(experiment_name, start_date, start_time, end_date, end_time)</code>","text":"<p>Set the most recent (or actually, in progress) experiment and its duration.</p> PARAMETER DESCRIPTION <code>experiment_name</code> <p>The experiment name to be set in progress.</p> <p> TYPE: <code>str</code> </p> <code>start_date</code> <p>The formatted string of the start date of the experiment.</p> <p> TYPE: <code>str</code> </p> <code>start_time</code> <p>The formatted string of the start time of the experiment.</p> <p> TYPE: <code>str</code> </p> <code>end_date</code> <p>The formatted string of the end date of the experiment.</p> <p> TYPE: <code>str</code> </p> <code>end_time</code> <p>The formatted string of the end time of the experiment.</p> <p> TYPE: <code>str</code> </p> Source code in <code>labridge\\func_modules\\memory\\experiment\\experiment_log.py</code> <pre><code>def set_recent_experiment(\n\tself,\n\texperiment_name: str,\n\tstart_date: str,\n\tstart_time: str,\n\tend_date: str,\n\tend_time: str,\n):\n\tr\"\"\"\n\tSet the most recent (or actually, in progress) experiment and its duration.\n\n\tArgs:\n\t\texperiment_name (str): The experiment name to be set in progress.\n\t\tstart_date (str): The formatted string of the start date of the experiment.\n\t\tstart_time (str): The formatted string of the start time of the experiment.\n\t\tend_date (str): The formatted string of the end date of the experiment.\n\t\tend_time (str): The formatted string of the end time of the experiment.\n\t\"\"\"\n\texpr_list = self.get_all_experiments()\n\tif experiment_name not in expr_list:\n\t\traise ValueError(\n\t\t\tf\"The experiment {experiment_name} \" \n\t\t\tf\"does not exist in the experiment log memory of the user {self.user_id}\"\n\t\t)\n\n\trecent_node = self._get_node(node_id=RECENT_EXPERIMENT_NODE_NAME)\n\trecent_node.metadata[RECENT_EXPERIMENT_START_TIME_KEY] = (\n\t\tstart_date, start_time\n\t)\n\trecent_node.metadata[RECENT_EXPERIMENT_END_TIME_KEY] = (\n\t\tend_date, end_time\n\t)\n\trecent_node.metadata[RECENT_EXPERIMENT_NAME_KEY] = experiment_name\n\tself._update_node(\n\t\tnode_id=RECENT_EXPERIMENT_NODE_NAME,\n\t\tnode=recent_node,\n\t)\n</code></pre>"},{"location":"code_docs/func_modules/memory/experiment/experiment_log/#labridge.func_modules.memory.experiment.experiment_log.ExperimentLog.update","title":"<code>labridge.func_modules.memory.experiment.experiment_log.ExperimentLog.update()</code>","text":"<p>Reload from the disk.</p> Source code in <code>labridge\\func_modules\\memory\\experiment\\experiment_log.py</code> <pre><code>def update(self):\n\tr\"\"\" Reload from the disk. \"\"\"\n\treturn self.from_user_id(\n\t\tuser_id=self.user_id,\n\t\tembed_model=self.vector_index._embed_model,\n\t)\n</code></pre>"},{"location":"code_docs/func_modules/memory/experiment/retrieve_log/","title":"Retrieve log","text":""},{"location":"code_docs/func_modules/memory/experiment/retrieve_log/#labridge.func_modules.memory.experiment.retrieve_log","title":"<code>labridge.func_modules.memory.experiment.retrieve_log</code>","text":""},{"location":"code_docs/func_modules/memory/experiment/retrieve_log/#labridge.func_modules.memory.experiment.retrieve_log.ExperimentLogRetriever","title":"<code>labridge.func_modules.memory.experiment.retrieve_log.ExperimentLogRetriever</code>","text":"<p>               Bases: <code>LogBaseRetriever</code></p> <p>This class retrieve in a specific user's experiment logs.</p> <p>The docstring of the method <code>retrieve</code> or <code>aretrieve</code> are used as tool description of the corresponding retriever tool.</p> PARAMETER DESCRIPTION <code>embed_model</code> <p>The embed model. Defaults to None. If set to None, the Settings.embed_model will be used.</p> <p> TYPE: <code>BaseEmbedding</code> DEFAULT: <code>None</code> </p> <code>final_use_context</code> <p>Whether to add the context nodes of the retrieved nodes to the final results. Defaults to True.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>relevant_top_k</code> <p>The <code>relevant_top_k</code> log nodes will be selected as the retrieved nodes. Defaults to <code>EXPERIMENT_LOG_RELEVANT_TOP_K</code>.</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> Source code in <code>labridge\\func_modules\\memory\\experiment\\retrieve_log.py</code> <pre><code>class ExperimentLogRetriever(LogBaseRetriever):\n\tr\"\"\"\n\tThis class retrieve in a specific user's experiment logs.\n\n\tThe docstring of the method `retrieve` or `aretrieve` are used as tool description of the\n\tcorresponding retriever tool.\n\n\tArgs:\n\t\tembed_model (BaseEmbedding): The embed model. Defaults to None.\n\t\t\tIf set to None, the Settings.embed_model will be used.\n\t\tfinal_use_context (bool): Whether to add the context nodes of the retrieved nodes to the final results.\n\t\t\tDefaults to True.\n\t\trelevant_top_k (int): The `relevant_top_k` log nodes will be selected as the retrieved nodes.\n\t\t\tDefaults to `EXPERIMENT_LOG_RELEVANT_TOP_K`.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tembed_model: BaseEmbedding = None,\n\t\tfinal_use_context: bool = True,\n\t\trelevant_top_k: int = None,\n\t):\n\t\trelevant_top_k = relevant_top_k or EXPERIMENT_LOG_RELEVANT_TOP_K\n\t\tsuper().__init__(\n\t\t\tembed_model=embed_model,\n\t\t\tfinal_use_context=final_use_context,\n\t\t\trelevant_top_k=relevant_top_k,\n\t\t)\n\n\tdef get_memory_vector_index(self) -&gt; VectorStoreIndex:\n\t\tr\"\"\" Get the vector index. \"\"\"\n\t\treturn self.memory.vector_index\n\n\tdef get_memory_vector_retriever(self) -&gt; VectorIndexRetriever:\n\t\tr\"\"\" Get the default vector index retriever, with default similarity_top_k and no date filters. \"\"\"\n\t\tmemory_retriever = self.memory.vector_index.as_retriever(\n\t\t\tsimilarity_top_k=self.relevant_top_k,\n\t\t\tfilters=None,\n\t\t)\n\t\treturn memory_retriever\n\n\tdef reset_vector_retriever(self):\n\t\tr\"\"\"\n\t\tReset the vector index retriever to defaults.\n\t\tSpecifically, with no date filters and confined node ids.\n\t\t\"\"\"\n\t\tself.memory_vector_retriever._filters = [self._log_node_filter(),]\n\t\tself.memory_vector_retriever._node_ids = None\n\n\t@dispatcher.span\n\tdef retrieve(\n\t\tself,\n\t\titem_to_be_retrieved: str,\n\t\tmemory_id: str,\n\t\tstart_date: str = None,\n\t\tend_date: str = None,\n\t\texperiment_name: str = None,\n\t\t**kwargs: Any,\n\t) -&gt; List[NodeWithScore]:\n\t\tr\"\"\"\n\t\tThis tool is used to retrieve experiment logs of a user.\n\t\tUse this tool to help you to answer questions about experimental records.\n\n\t\tArgs:\n\t\t\titem_to_be_retrieved (str): This argument is necessary.\n\t\t\t\tIt denotes things that you want to retrieve in the chat history memory.\n\t\t\tmemory_id (str): This argument is necessary.\n\t\t\t\tIt is the user_id of a lab member.\n\t\t\tstart_date (str): This argument is optional.\n\t\t\t\tIt denotes the start date in the format 'Year-Month-Day'.\n\t\t\t\tIf both start_date and end_date are specified, only logs which are recorded between the\n\t\t\t\tstart_date and end_date will be retrieved.\n\t\t\tend_date (str): This argument is optional.\n\t\t\t\tIt denotes the end date in the format 'Year-Month-Day'.\n\t\t\texperiment_name (str): This argument is optional.\n\t\t\t\tIt is the name of a specific experiment.\n\t\t\t\tIf it is specified and is valid, only logs of this experiment will be retrieved.\n\t\t\tkwargs: Other arguments will be ignored.\n\n\t\tReturns:\n\t\t\tRetrieved experiment logs.\n\t\t\"\"\"\n\t\tif self.memory is None or self.memory.user_id != memory_id:\n\t\t\tself.memory = ExperimentLog.from_user_id(\n\t\t\t\tuser_id=memory_id,\n\t\t\t\tembed_model=self.embed_model,\n\t\t\t)\n\t\t\tself.memory_vector_retriever = self.get_memory_vector_retriever()\n\n\t\tself.reset_vector_retriever()\n\n\t\tif experiment_name is None or not self.memory.is_expr_exist(experiment_name):\n\t\t\tretrieve_node_ids = None\n\t\telse:\n\t\t\tretrieve_node_ids = self.memory.get_expr_log_node_ids(experiment_name)\n\n\t\tfilters = [self._log_node_filter(), ]\n\t\tif None not in [start_date, end_date]:\n\t\t\t# get the candidate date list.\n\t\t\tdate_list = self._parse_date(start_date_str=start_date, end_date_str=end_date)\n\t\t\tfilters.append(\n\t\t\t\tself.get_date_filter(date_list=date_list),\n\t\t\t)\n\n\t\tmetadata_filters = MetadataFilters(filters=filters)\n\n\t\tself.memory_vector_retriever._filters = metadata_filters\n\t\tself.memory_vector_retriever._node_ids = retrieve_node_ids\n\n\t\t# TODO: hybrid retrieve: add retrieve experiment.\n\t\tlog_nodes = self.memory_vector_retriever.retrieve(item_to_be_retrieved)\n\n\t\tif self.final_use_context:\n\t\t\tlog_nodes = self._add_context(content_nodes=log_nodes)\n\t\treturn log_nodes\n\n\t@dispatcher.span\n\tasync def aretrieve(\n\t\tself,\n\t\titem_to_be_retrieved: str,\n\t\tmemory_id: str,\n\t\tstart_date: str = None,\n\t\tend_date: str = None,\n\t\texperiment_name: str = None,\n\t\t**kwargs: Any,\n\t) -&gt; List[NodeWithScore]:\n\t\tr\"\"\"\n\t\tThis tool is used to retrieve relevant experiment logs in a certain experiment log memory.\n\n\t\tArgs:\n\t\t\titem_to_be_retrieved (str): This argument is necessary.\n\t\t\t\tIt denotes things that you want to retrieve in the chat history memory.\n\t\t\tmemory_id (str): This argument is necessary.\n\t\t\t\tIt is the user_id of a lab member.\n\t\t\tstart_date (str): This argument is optional.\n\t\t\t\tIt denotes the start date in the format 'Year-Month-Day'.\n\t\t\t\tIf both start_date and end_date are specified, only logs which are recorded between the\n\t\t\t\tstart_date and end_date will be retrieved.\n\t\t\tend_date (str): This argument is optional.\n\t\t\t\tIt denotes the end date in the format 'Year-Month-Day'.\n\t\t\texperiment_name (str): This argument is optional.\n\t\t\t\tIt is the name of a specific experiment.\n\t\t\t\tIf it is specified and is valid, only logs of this experiment will be retrieved.\n\t\t\tkwargs: Other arguments will be ignored.\n\n\t\tReturns:\n\t\t\tRetrieved experiment logs.\n\t\t\"\"\"\n\t\tif self.memory is None or self.memory.user_id != memory_id:\n\t\t\tself.memory = ExperimentLog.from_user_id(\n\t\t\t\tuser_id=memory_id,\n\t\t\t\tembed_model=self.embed_model,\n\t\t\t)\n\t\t\tself.memory_vector_retriever = self.get_memory_vector_retriever()\n\t\tself.reset_vector_retriever()\n\n\t\tif experiment_name is None or not self.memory.is_expr_exist(experiment_name):\n\t\t\tretrieve_node_ids = None\n\t\telse:\n\t\t\tretrieve_node_ids = self.memory.get_expr_log_node_ids(experiment_name)\n\n\t\tfilters = [self._log_node_filter(), ]\n\t\tif None not in [start_date, end_date]:\n\t\t\t# get the candidate date list.\n\t\t\tdate_list = self._parse_date(start_date_str=start_date, end_date_str=end_date)\n\t\t\tfilters.append(\n\t\t\t\tself.get_date_filter(date_list=date_list)\n\t\t\t)\n\n\t\tmetadata_filters = MetadataFilters(filters=filters)\n\n\t\tself.memory_vector_retriever._filters = metadata_filters\n\t\tself.memory_vector_retriever._node_ids = retrieve_node_ids\n\t\tlog_nodes = await self.memory_vector_retriever.aretrieve(item_to_be_retrieved)\n\n\t\tif self.final_use_context:\n\t\t\tlog_nodes = self._add_context(content_nodes=log_nodes)\n\t\treturn log_nodes\n</code></pre>"},{"location":"code_docs/func_modules/memory/experiment/retrieve_log/#labridge.func_modules.memory.experiment.retrieve_log.ExperimentLogRetriever.aretrieve","title":"<code>labridge.func_modules.memory.experiment.retrieve_log.ExperimentLogRetriever.aretrieve(item_to_be_retrieved, memory_id, start_date=None, end_date=None, experiment_name=None, **kwargs)</code>  <code>async</code>","text":"<p>This tool is used to retrieve relevant experiment logs in a certain experiment log memory.</p> PARAMETER DESCRIPTION <code>item_to_be_retrieved</code> <p>This argument is necessary. It denotes things that you want to retrieve in the chat history memory.</p> <p> TYPE: <code>str</code> </p> <code>memory_id</code> <p>This argument is necessary. It is the user_id of a lab member.</p> <p> TYPE: <code>str</code> </p> <code>start_date</code> <p>This argument is optional. It denotes the start date in the format 'Year-Month-Day'. If both start_date and end_date are specified, only logs which are recorded between the start_date and end_date will be retrieved.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>end_date</code> <p>This argument is optional. It denotes the end date in the format 'Year-Month-Day'.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>experiment_name</code> <p>This argument is optional. It is the name of a specific experiment. If it is specified and is valid, only logs of this experiment will be retrieved.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Other arguments will be ignored.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>List[NodeWithScore]</code> <p>Retrieved experiment logs.</p> Source code in <code>labridge\\func_modules\\memory\\experiment\\retrieve_log.py</code> <pre><code>@dispatcher.span\nasync def aretrieve(\n\tself,\n\titem_to_be_retrieved: str,\n\tmemory_id: str,\n\tstart_date: str = None,\n\tend_date: str = None,\n\texperiment_name: str = None,\n\t**kwargs: Any,\n) -&gt; List[NodeWithScore]:\n\tr\"\"\"\n\tThis tool is used to retrieve relevant experiment logs in a certain experiment log memory.\n\n\tArgs:\n\t\titem_to_be_retrieved (str): This argument is necessary.\n\t\t\tIt denotes things that you want to retrieve in the chat history memory.\n\t\tmemory_id (str): This argument is necessary.\n\t\t\tIt is the user_id of a lab member.\n\t\tstart_date (str): This argument is optional.\n\t\t\tIt denotes the start date in the format 'Year-Month-Day'.\n\t\t\tIf both start_date and end_date are specified, only logs which are recorded between the\n\t\t\tstart_date and end_date will be retrieved.\n\t\tend_date (str): This argument is optional.\n\t\t\tIt denotes the end date in the format 'Year-Month-Day'.\n\t\texperiment_name (str): This argument is optional.\n\t\t\tIt is the name of a specific experiment.\n\t\t\tIf it is specified and is valid, only logs of this experiment will be retrieved.\n\t\tkwargs: Other arguments will be ignored.\n\n\tReturns:\n\t\tRetrieved experiment logs.\n\t\"\"\"\n\tif self.memory is None or self.memory.user_id != memory_id:\n\t\tself.memory = ExperimentLog.from_user_id(\n\t\t\tuser_id=memory_id,\n\t\t\tembed_model=self.embed_model,\n\t\t)\n\t\tself.memory_vector_retriever = self.get_memory_vector_retriever()\n\tself.reset_vector_retriever()\n\n\tif experiment_name is None or not self.memory.is_expr_exist(experiment_name):\n\t\tretrieve_node_ids = None\n\telse:\n\t\tretrieve_node_ids = self.memory.get_expr_log_node_ids(experiment_name)\n\n\tfilters = [self._log_node_filter(), ]\n\tif None not in [start_date, end_date]:\n\t\t# get the candidate date list.\n\t\tdate_list = self._parse_date(start_date_str=start_date, end_date_str=end_date)\n\t\tfilters.append(\n\t\t\tself.get_date_filter(date_list=date_list)\n\t\t)\n\n\tmetadata_filters = MetadataFilters(filters=filters)\n\n\tself.memory_vector_retriever._filters = metadata_filters\n\tself.memory_vector_retriever._node_ids = retrieve_node_ids\n\tlog_nodes = await self.memory_vector_retriever.aretrieve(item_to_be_retrieved)\n\n\tif self.final_use_context:\n\t\tlog_nodes = self._add_context(content_nodes=log_nodes)\n\treturn log_nodes\n</code></pre>"},{"location":"code_docs/func_modules/memory/experiment/retrieve_log/#labridge.func_modules.memory.experiment.retrieve_log.ExperimentLogRetriever.get_memory_vector_index","title":"<code>labridge.func_modules.memory.experiment.retrieve_log.ExperimentLogRetriever.get_memory_vector_index()</code>","text":"<p>Get the vector index.</p> Source code in <code>labridge\\func_modules\\memory\\experiment\\retrieve_log.py</code> <pre><code>def get_memory_vector_index(self) -&gt; VectorStoreIndex:\n\tr\"\"\" Get the vector index. \"\"\"\n\treturn self.memory.vector_index\n</code></pre>"},{"location":"code_docs/func_modules/memory/experiment/retrieve_log/#labridge.func_modules.memory.experiment.retrieve_log.ExperimentLogRetriever.get_memory_vector_retriever","title":"<code>labridge.func_modules.memory.experiment.retrieve_log.ExperimentLogRetriever.get_memory_vector_retriever()</code>","text":"<p>Get the default vector index retriever, with default similarity_top_k and no date filters.</p> Source code in <code>labridge\\func_modules\\memory\\experiment\\retrieve_log.py</code> <pre><code>def get_memory_vector_retriever(self) -&gt; VectorIndexRetriever:\n\tr\"\"\" Get the default vector index retriever, with default similarity_top_k and no date filters. \"\"\"\n\tmemory_retriever = self.memory.vector_index.as_retriever(\n\t\tsimilarity_top_k=self.relevant_top_k,\n\t\tfilters=None,\n\t)\n\treturn memory_retriever\n</code></pre>"},{"location":"code_docs/func_modules/memory/experiment/retrieve_log/#labridge.func_modules.memory.experiment.retrieve_log.ExperimentLogRetriever.reset_vector_retriever","title":"<code>labridge.func_modules.memory.experiment.retrieve_log.ExperimentLogRetriever.reset_vector_retriever()</code>","text":"<p>Reset the vector index retriever to defaults. Specifically, with no date filters and confined node ids.</p> Source code in <code>labridge\\func_modules\\memory\\experiment\\retrieve_log.py</code> <pre><code>def reset_vector_retriever(self):\n\tr\"\"\"\n\tReset the vector index retriever to defaults.\n\tSpecifically, with no date filters and confined node ids.\n\t\"\"\"\n\tself.memory_vector_retriever._filters = [self._log_node_filter(),]\n\tself.memory_vector_retriever._node_ids = None\n</code></pre>"},{"location":"code_docs/func_modules/memory/experiment/retrieve_log/#labridge.func_modules.memory.experiment.retrieve_log.ExperimentLogRetriever.retrieve","title":"<code>labridge.func_modules.memory.experiment.retrieve_log.ExperimentLogRetriever.retrieve(item_to_be_retrieved, memory_id, start_date=None, end_date=None, experiment_name=None, **kwargs)</code>","text":"<p>This tool is used to retrieve experiment logs of a user. Use this tool to help you to answer questions about experimental records.</p> PARAMETER DESCRIPTION <code>item_to_be_retrieved</code> <p>This argument is necessary. It denotes things that you want to retrieve in the chat history memory.</p> <p> TYPE: <code>str</code> </p> <code>memory_id</code> <p>This argument is necessary. It is the user_id of a lab member.</p> <p> TYPE: <code>str</code> </p> <code>start_date</code> <p>This argument is optional. It denotes the start date in the format 'Year-Month-Day'. If both start_date and end_date are specified, only logs which are recorded between the start_date and end_date will be retrieved.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>end_date</code> <p>This argument is optional. It denotes the end date in the format 'Year-Month-Day'.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>experiment_name</code> <p>This argument is optional. It is the name of a specific experiment. If it is specified and is valid, only logs of this experiment will be retrieved.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Other arguments will be ignored.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>List[NodeWithScore]</code> <p>Retrieved experiment logs.</p> Source code in <code>labridge\\func_modules\\memory\\experiment\\retrieve_log.py</code> <pre><code>@dispatcher.span\ndef retrieve(\n\tself,\n\titem_to_be_retrieved: str,\n\tmemory_id: str,\n\tstart_date: str = None,\n\tend_date: str = None,\n\texperiment_name: str = None,\n\t**kwargs: Any,\n) -&gt; List[NodeWithScore]:\n\tr\"\"\"\n\tThis tool is used to retrieve experiment logs of a user.\n\tUse this tool to help you to answer questions about experimental records.\n\n\tArgs:\n\t\titem_to_be_retrieved (str): This argument is necessary.\n\t\t\tIt denotes things that you want to retrieve in the chat history memory.\n\t\tmemory_id (str): This argument is necessary.\n\t\t\tIt is the user_id of a lab member.\n\t\tstart_date (str): This argument is optional.\n\t\t\tIt denotes the start date in the format 'Year-Month-Day'.\n\t\t\tIf both start_date and end_date are specified, only logs which are recorded between the\n\t\t\tstart_date and end_date will be retrieved.\n\t\tend_date (str): This argument is optional.\n\t\t\tIt denotes the end date in the format 'Year-Month-Day'.\n\t\texperiment_name (str): This argument is optional.\n\t\t\tIt is the name of a specific experiment.\n\t\t\tIf it is specified and is valid, only logs of this experiment will be retrieved.\n\t\tkwargs: Other arguments will be ignored.\n\n\tReturns:\n\t\tRetrieved experiment logs.\n\t\"\"\"\n\tif self.memory is None or self.memory.user_id != memory_id:\n\t\tself.memory = ExperimentLog.from_user_id(\n\t\t\tuser_id=memory_id,\n\t\t\tembed_model=self.embed_model,\n\t\t)\n\t\tself.memory_vector_retriever = self.get_memory_vector_retriever()\n\n\tself.reset_vector_retriever()\n\n\tif experiment_name is None or not self.memory.is_expr_exist(experiment_name):\n\t\tretrieve_node_ids = None\n\telse:\n\t\tretrieve_node_ids = self.memory.get_expr_log_node_ids(experiment_name)\n\n\tfilters = [self._log_node_filter(), ]\n\tif None not in [start_date, end_date]:\n\t\t# get the candidate date list.\n\t\tdate_list = self._parse_date(start_date_str=start_date, end_date_str=end_date)\n\t\tfilters.append(\n\t\t\tself.get_date_filter(date_list=date_list),\n\t\t)\n\n\tmetadata_filters = MetadataFilters(filters=filters)\n\n\tself.memory_vector_retriever._filters = metadata_filters\n\tself.memory_vector_retriever._node_ids = retrieve_node_ids\n\n\t# TODO: hybrid retrieve: add retrieve experiment.\n\tlog_nodes = self.memory_vector_retriever.retrieve(item_to_be_retrieved)\n\n\tif self.final_use_context:\n\t\tlog_nodes = self._add_context(content_nodes=log_nodes)\n\treturn log_nodes\n</code></pre>"},{"location":"code_docs/func_modules/paper/download/arxiv/","title":"Arxiv","text":""},{"location":"code_docs/func_modules/paper/download/arxiv/#labridge.func_modules.paper.download.arxiv","title":"<code>labridge.func_modules.paper.download.arxiv</code>","text":""},{"location":"code_docs/func_modules/paper/download/arxiv/#labridge.func_modules.paper.download.arxiv.ArxivCategory","title":"<code>labridge.func_modules.paper.download.arxiv.ArxivCategory</code>","text":"<p>               Bases: <code>object</code></p> <p>The research fields category from arXiv.</p> ATTRIBUTE DESCRIPTION <code>category</code> <p>a dict containing sub dicts. - key: the research fields group name. - value: a sub dict containing the research fields categories. Each sub dict contains:</p> <pre><code>    - key: the research fields category name.\n    - value: the description of this category.\n</code></pre> <p> TYPE: <code>dict</code> </p> <code>persist_path</code> <p>the storing path of the category dict.</p> <p> TYPE: <code>str</code> </p> <code>arxiv_category_url</code> <p>the url of the arxiv category.</p> <p> TYPE: <code>str</code> </p> PARAMETER DESCRIPTION <code>persist_path</code> <p>the storing path of the category dict.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> Source code in <code>labridge\\func_modules\\paper\\download\\arxiv.py</code> <pre><code>class ArxivCategory(object):\n\tr\"\"\"\n\tThe research fields category from arXiv.\n\n\tAttributes:\n\t\tcategory (dict): a dict containing sub dicts.\n\t\t\t- key: the research fields group name.\n\t\t\t- value: a sub dict containing the research fields categories.\n\t\t\tEach sub dict contains:\n\n\t\t\t\t- key: the research fields category name.\n\t\t\t\t- value: the description of this category.\n\t\tpersist_path (str): the storing path of the category dict.\n\t\tarxiv_category_url (str): the url of the arxiv category.\n\n\tArgs:\n\t\tpersist_path (str): the storing path of the category dict.\n\t\"\"\"\n\tcategory: dict\n\tpersist_path: str\n\tarxiv_category_url: str = \"https://arxiv.org/category_taxonomy\"\n\n\tdef __init__(self, persist_path: Optional[str] = None):\n\t\tself.persist_path = persist_path or self._default_persist_path()\n\t\tif Path(self.persist_path).exists():\n\t\t\tself.category = self.load_category()\n\t\telse:\n\t\t\tself.category = self.category_from_arxiv()\n\t\t\tself.save_category()\n\n\tdef _default_persist_path(self) -&gt; str:\n\t\tr\"\"\" Default persist path. \"\"\"\n\t\troot = Path(__file__)\n\t\tfor i in range(5):\n\t\t\troot = root.parent\n\t\treturn str(root / ARXIV_CATEGORY_PATH)\n\n\tdef category_from_arxiv(self, arxiv_category_url: Optional[str] = None) -&gt; dict:\n\t\tr\"\"\"\n\t\tParse categories from arxiv.\n\n\t\tArgs:\n\t\t\tarxiv_category_url (Optional[str]): Generally, the url is \"https://arxiv.org/category_taxonomy\".\n\n\t\tReturns:\n\t\t\tdict: The category dict in the following format:\n\t\t\t\t`{Group: {Category: description (str)}}`\n\t\t\"\"\"\n\t\tarxiv_category_url = arxiv_category_url or self.arxiv_category_url\n\t\tweb_reader = SimpleWebPageReader(html_to_text=True)\n\t\tweb_text = web_reader.load_data([arxiv_category_url])\n\t\ttext = web_text[0].text\n\t\tfields_str = text.split(\"Category description if available\")[1]\n\t\tfields_dict= dict()\n\t\tline_list = fields_str.split('\\n')\n\n\t\tdescription = []\n\t\tgroup = None\n\t\tcategory = None\n\t\tfor line in line_list:\n\t\t\tline_items = line.split()\n\t\t\tif line_items and line_items[0] == \"##\":\n\t\t\t\tgroup = \" \".join(line_items[1:])\n\t\t\t\tfields_dict[group] = {}\n\t\t\t\tcategory = None\n\t\t\telif line_items and line_items[0] == \"####\":\n\t\t\t\tif category is not None:\n\t\t\t\t\tfields_dict[group][category] = \" \".join(description)\n\t\t\t\tcategory = line_items[1]\n\t\t\t\tdescription = [f\"{' '.join(line_items[2:])}:\"]\n\t\t\telse:\n\t\t\t\tdescription.append(line)\n\n\t\tfields_dict[group][category] = \" \".join(description)\n\n\t\t# Extra information.\n\t\tfor group in Extra_Descriptions.keys():\n\t\t\tfor category in Extra_Descriptions[group].keys():\n\t\t\t\tfields_dict[group][category] += Extra_Descriptions[group][category]\n\n\t\treturn fields_dict\n\n\tdef load_category(self, persist_path: Optional[str] = None, fs: Optional[fsspec.AbstractFileSystem] = None):\n\t\t\"\"\"Load the research categories from a persist path.\"\"\"\n\t\tfs = fs or fsspec.filesystem(\"file\")\n\t\tpersist_path = persist_path or self.persist_path\n\t\twith fs.open(persist_path, \"rb\") as f:\n\t\t\tcategory = json.load(f)\n\t\treturn category\n\n\tdef save_category(self, persist_path: Optional[str] = None, fs: Optional[fsspec.AbstractFileSystem] = None):\n\t\t\"\"\"Save the research categories from a persist path.\"\"\"\n\t\tpersist_path = persist_path or self.persist_path\n\t\tfs = fs or fsspec.filesystem(\"file\")\n\t\tdirpath = str(Path(persist_path).parent)\n\t\tif not fs.exists(dirpath):\n\t\t\tfs.makedirs(dirpath)\n\n\t\twith fs.open(persist_path, \"w\") as f:\n\t\t\tf.write(json.dumps(self.category))\n</code></pre>"},{"location":"code_docs/func_modules/paper/download/arxiv/#labridge.func_modules.paper.download.arxiv.ArxivCategory.category_from_arxiv","title":"<code>labridge.func_modules.paper.download.arxiv.ArxivCategory.category_from_arxiv(arxiv_category_url=None)</code>","text":"<p>Parse categories from arxiv.</p> PARAMETER DESCRIPTION <code>arxiv_category_url</code> <p>Generally, the url is \"https://arxiv.org/category_taxonomy\".</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>dict</code> <p>The category dict in the following format: <code>{Group: {Category: description (str)}}</code></p> <p> TYPE: <code>dict</code> </p> Source code in <code>labridge\\func_modules\\paper\\download\\arxiv.py</code> <pre><code>def category_from_arxiv(self, arxiv_category_url: Optional[str] = None) -&gt; dict:\n\tr\"\"\"\n\tParse categories from arxiv.\n\n\tArgs:\n\t\tarxiv_category_url (Optional[str]): Generally, the url is \"https://arxiv.org/category_taxonomy\".\n\n\tReturns:\n\t\tdict: The category dict in the following format:\n\t\t\t`{Group: {Category: description (str)}}`\n\t\"\"\"\n\tarxiv_category_url = arxiv_category_url or self.arxiv_category_url\n\tweb_reader = SimpleWebPageReader(html_to_text=True)\n\tweb_text = web_reader.load_data([arxiv_category_url])\n\ttext = web_text[0].text\n\tfields_str = text.split(\"Category description if available\")[1]\n\tfields_dict= dict()\n\tline_list = fields_str.split('\\n')\n\n\tdescription = []\n\tgroup = None\n\tcategory = None\n\tfor line in line_list:\n\t\tline_items = line.split()\n\t\tif line_items and line_items[0] == \"##\":\n\t\t\tgroup = \" \".join(line_items[1:])\n\t\t\tfields_dict[group] = {}\n\t\t\tcategory = None\n\t\telif line_items and line_items[0] == \"####\":\n\t\t\tif category is not None:\n\t\t\t\tfields_dict[group][category] = \" \".join(description)\n\t\t\tcategory = line_items[1]\n\t\t\tdescription = [f\"{' '.join(line_items[2:])}:\"]\n\t\telse:\n\t\t\tdescription.append(line)\n\n\tfields_dict[group][category] = \" \".join(description)\n\n\t# Extra information.\n\tfor group in Extra_Descriptions.keys():\n\t\tfor category in Extra_Descriptions[group].keys():\n\t\t\tfields_dict[group][category] += Extra_Descriptions[group][category]\n\n\treturn fields_dict\n</code></pre>"},{"location":"code_docs/func_modules/paper/download/arxiv/#labridge.func_modules.paper.download.arxiv.ArxivCategory.load_category","title":"<code>labridge.func_modules.paper.download.arxiv.ArxivCategory.load_category(persist_path=None, fs=None)</code>","text":"<p>Load the research categories from a persist path.</p> Source code in <code>labridge\\func_modules\\paper\\download\\arxiv.py</code> <pre><code>def load_category(self, persist_path: Optional[str] = None, fs: Optional[fsspec.AbstractFileSystem] = None):\n\t\"\"\"Load the research categories from a persist path.\"\"\"\n\tfs = fs or fsspec.filesystem(\"file\")\n\tpersist_path = persist_path or self.persist_path\n\twith fs.open(persist_path, \"rb\") as f:\n\t\tcategory = json.load(f)\n\treturn category\n</code></pre>"},{"location":"code_docs/func_modules/paper/download/arxiv/#labridge.func_modules.paper.download.arxiv.ArxivCategory.save_category","title":"<code>labridge.func_modules.paper.download.arxiv.ArxivCategory.save_category(persist_path=None, fs=None)</code>","text":"<p>Save the research categories from a persist path.</p> Source code in <code>labridge\\func_modules\\paper\\download\\arxiv.py</code> <pre><code>def save_category(self, persist_path: Optional[str] = None, fs: Optional[fsspec.AbstractFileSystem] = None):\n\t\"\"\"Save the research categories from a persist path.\"\"\"\n\tpersist_path = persist_path or self.persist_path\n\tfs = fs or fsspec.filesystem(\"file\")\n\tdirpath = str(Path(persist_path).parent)\n\tif not fs.exists(dirpath):\n\t\tfs.makedirs(dirpath)\n\n\twith fs.open(persist_path, \"w\") as f:\n\t\tf.write(json.dumps(self.category))\n</code></pre>"},{"location":"code_docs/func_modules/paper/download/arxiv/#labridge.func_modules.paper.download.arxiv.ArxivClient","title":"<code>labridge.func_modules.paper.download.arxiv.ArxivClient</code>","text":"<p>               Bases: <code>Client</code></p> <p>Similar to the class <code>Client</code> in the package <code>arxiv</code>. The method <code>_format_url</code> is corrected here to enable advanced search.</p> <p>For details about advanced search in arXiv, refer to Details of Query Construction</p> <p>Advanced search fields: |      prefix  |       explanation             | |:--------:|:-----------------:| |ti            |Title                          | |au            |Author                         | |abs           |Abstract                       | |co            |Comment                        | |jr            |Journal Reference      | |cat           |Subject Category       | |rn            |Report Number          | |id_list       |Id list                        | |all           |All of the above       |</p> Source code in <code>labridge\\func_modules\\paper\\download\\arxiv.py</code> <pre><code>class ArxivClient(Client):\n\tr\"\"\"\n\t Similar to the class `Client` in the package `arxiv`.\n\t The method `_format_url` is corrected here to enable advanced search.\n\n\t For details about advanced search in arXiv, refer to\n\t [Details of Query Construction](https://info.arxiv.org/help/api/user-manual.html#query_details)\n\n\t Advanced search fields:\n\t |\tprefix\t|\texplanation\t\t|\n\t |:--------:|:-----------------:|\n\t |ti\t\t|Title\t\t\t\t|\n\t |au\t\t|Author\t\t\t\t|\n\t |abs\t\t|Abstract\t\t\t|\n\t |co\t\t|Comment\t\t\t|\n\t |jr\t\t|Journal Reference\t|\n\t |cat\t\t|Subject Category\t|\n\t |rn\t\t|Report Number\t\t|\n\t |id_list\t|Id list\t\t\t|\n\t |all\t\t|All of the above\t|\n\t \"\"\"\n\n\tpage_size: int\n\t\"\"\"\n\tMaximum number of results fetched in a single API request. Smaller pages can\n\tbe retrieved faster, but may require more round-trips.\n\n\tThe API's limit is 2000 results per page.\n\t\"\"\"\n\tdelay_seconds: float\n\t\"\"\"\n\tNumber of seconds to wait between API requests.\n\n\t[arXiv's Terms of Use](https://arxiv.org/help/api/tou) ask that you \"make no\n\tmore than one request every three seconds.\"\n\t\"\"\"\n\tnum_retries: int\n\t\"\"\"\n\tNumber of times to retry a failing API request before raising an Exception.\n\t\"\"\"\n\tdef __init_(self, page_size: int = 100, delay_seconds: float = 3.0, num_retries: int = 3):\n\t\tsuper().__init__(\n\t\t\tpage_size=page_size,\n\t\t\tdelay_seconds=delay_seconds,\n\t\t\tnum_retries=num_retries\n\t\t)\n\n\tdef query_format(self, url_args: dict) -&gt; str:\n\t\tr\"\"\" Formatted url for searching in arXiv. \"\"\"\n\t\tquery = url_args[\"search_query\"]\n\t\tsuffix = f\"search_query={query}\"\n\t\tfor key in url_args.keys():\n\t\t\tif key != \"search_query\":\n\t\t\t\tsuffix += f\"&amp;{key}={url_args[key]}\"\n\t\treturn self.query_url_format.format(suffix)\n\n\tdef _format_url(self, search: Search, start: int, page_size: int) -&gt; str:\n\t\tr\"\"\" Formatted url for searching in arXiv. \"\"\"\n\t\turl_args = search._url_args()\n\t\turl_args.update(\n\t\t\t{\n\t\t\t\t\"start\": start,\n\t\t\t\t\"max_results\": page_size,\n\t\t\t}\n\t\t)\n\t\treturn self.query_format(url_args)\n</code></pre>"},{"location":"code_docs/func_modules/paper/download/arxiv/#labridge.func_modules.paper.download.arxiv.ArxivClient.delay_seconds","title":"<code>labridge.func_modules.paper.download.arxiv.ArxivClient.delay_seconds: float</code>  <code>instance-attribute</code>","text":"<p>Number of seconds to wait between API requests.</p> <p>arXiv's Terms of Use ask that you \"make no more than one request every three seconds.\"</p>"},{"location":"code_docs/func_modules/paper/download/arxiv/#labridge.func_modules.paper.download.arxiv.ArxivClient.num_retries","title":"<code>labridge.func_modules.paper.download.arxiv.ArxivClient.num_retries: int</code>  <code>instance-attribute</code>","text":"<p>Number of times to retry a failing API request before raising an Exception.</p>"},{"location":"code_docs/func_modules/paper/download/arxiv/#labridge.func_modules.paper.download.arxiv.ArxivClient.page_size","title":"<code>labridge.func_modules.paper.download.arxiv.ArxivClient.page_size: int</code>  <code>instance-attribute</code>","text":"<p>Maximum number of results fetched in a single API request. Smaller pages can be retrieved faster, but may require more round-trips.</p> <p>The API's limit is 2000 results per page.</p>"},{"location":"code_docs/func_modules/paper/download/arxiv/#labridge.func_modules.paper.download.arxiv.ArxivClient.query_format","title":"<code>labridge.func_modules.paper.download.arxiv.ArxivClient.query_format(url_args)</code>","text":"<p>Formatted url for searching in arXiv.</p> Source code in <code>labridge\\func_modules\\paper\\download\\arxiv.py</code> <pre><code>def query_format(self, url_args: dict) -&gt; str:\n\tr\"\"\" Formatted url for searching in arXiv. \"\"\"\n\tquery = url_args[\"search_query\"]\n\tsuffix = f\"search_query={query}\"\n\tfor key in url_args.keys():\n\t\tif key != \"search_query\":\n\t\t\tsuffix += f\"&amp;{key}={url_args[key]}\"\n\treturn self.query_url_format.format(suffix)\n</code></pre>"},{"location":"code_docs/func_modules/paper/download/arxiv/#labridge.func_modules.paper.download.arxiv.ArxivDailyDownloader","title":"<code>labridge.func_modules.paper.download.arxiv.ArxivDailyDownloader</code>","text":"<p>               Bases: <code>object</code></p> <p>Get the recent relevant papers on arXiv.</p> ATTRIBUTE DESCRIPTION <code>category</code> <p>Storing the research fields categories.</p> <p> TYPE: <code>ArxivCategory</code> </p> <code>client</code> <p>For Fetching papers.</p> <p> TYPE: <code>ArxivClient</code> </p> <code>recent_days</code> <p>papers dating back to <code>recent_days</code> ago from today will be obtained.</p> <p> TYPE: <code>int</code> </p> Source code in <code>labridge\\func_modules\\paper\\download\\arxiv.py</code> <pre><code>class ArxivDailyDownloader(object):\n\tr\"\"\"\n\tGet the recent relevant papers on arXiv.\n\n\tAttributes:\n\t\tcategory (ArxivCategory): Storing the research fields categories.\n\t\tclient (ArxivClient): For Fetching papers.\n\t\trecent_days (int): papers dating back to `recent_days` ago from today will be obtained.\n\t\"\"\"\n\n\tcategory: ArxivCategory\n\tclient: ArxivClient\n\trecent_days: int\n\n\tdef __init__(self, recent_days: int = 1):\n\t\tself.today = datetime.date.today()\n\t\tself.category = ArxivCategory()\n\t\tself.client = ArxivClient()\n\t\tself.recent_days = recent_days\n\t\tself.search = Search(\n\t\t\tquery=\"cat:cs.AI\",\n\t\t\tsort_by=SortCriterion.SubmittedDate,\n\t\t\tsort_order=SortOrder.Descending,\n\t\t)\n\n\tdef _is_valid_category(self, cat: str) -&gt; bool:\n\t\tr\"\"\"\n\t\tCheck if the category is valid\n\n\t\tArgs:\n\t\t\tcat (str): a research category.\n\n\t\tReturns:\n\t\t\tbool: Whether the given category is a valid category in arXiv.\n\t\t\"\"\"\n\t\tcat_dict = self.category.category\n\t\tfor group in cat_dict.keys():\n\t\t\tif cat in cat_dict[group].keys():\n\t\t\t\treturn True\n\t\treturn False\n\n\tdef _valid_date(self, date: datetime.date, start_date: datetime.date, end_date: datetime.date) -&gt; bool:\n\t\tr\"\"\" Check if the date is 'recent' \"\"\"\n\t\treturn start_date &lt;= date &lt;= end_date\n\n\tdef get_daily_papers_info(self, relevant_categories: List[str]) -&gt; List[Result]:\n\t\tr\"\"\"\n\t\tGet the recent papers relevant to the input categories.\n\n\t\tThe information (e.g. Abstract, Title, Authors) of these daily papers will be sent to\n\t\tthe corresponding Lab Members. The papers selected by the members will be parsed and stored\n\t\tinto a proper directory.\n\n\t\tArgs:\n\t\t\trelevant_categories (List[str]): The recent papers in these categories will be counted.\n\n\t\tReturn:\n\t\t\tList[Result]: Recent papers information.\n\t\t\"\"\"\n\t\tquery = \"\"\n\t\tfor cat in relevant_categories:\n\t\t\tif self._is_valid_category(cat):\n\t\t\t\tif len(query) &gt; 0:\n\t\t\t\t\tquery += \"+OR+\"\n\t\t\t\tquery += f\"cat:{cat}\"\n\n\t\tdaily_papers = []\n\t\tif len(query) == 0:\n\t\t\treturn daily_papers\n\n\t\tself.search.query = query\n\t\tstart_date = self.today - datetime.timedelta(days=self.recent_days)\n\t\tfor result in self.client.results(search=self.search):\n\t\t\tsubmit_date = result.published\n\t\t\tif not self._valid_date(date=submit_date, start_date=start_date, end_date=self.today):\n\t\t\t\tbreak\n\t\t\tdaily_papers.append(result)\n\t\treturn daily_papers\n\n\tdef download_papers(self, paper_dict: Dict[Result, str]):\n\t\tr\"\"\"\n\t\tDownload the selected papers.\n\n\t\tArgs:\n\t\t\tpaper_dict (Dict[Result, str]):\n\t\t\t\t- key: paper (Result)\n\t\t\t\t- value: save_dir (str)\n\t\t\"\"\"\n\t\tfor paper in paper_dict.keys():\n\t\t\tpaper.download_pdf(dirpath=paper_dict[paper], filename=f\"{paper.title}.pdf\")\n</code></pre>"},{"location":"code_docs/func_modules/paper/download/arxiv/#labridge.func_modules.paper.download.arxiv.ArxivDailyDownloader.download_papers","title":"<code>labridge.func_modules.paper.download.arxiv.ArxivDailyDownloader.download_papers(paper_dict)</code>","text":"<p>Download the selected papers.</p> PARAMETER DESCRIPTION <code>paper_dict</code> <ul> <li>key: paper (Result)</li> <li>value: save_dir (str)</li> </ul> <p> TYPE: <code>Dict[Result, str]</code> </p> Source code in <code>labridge\\func_modules\\paper\\download\\arxiv.py</code> <pre><code>def download_papers(self, paper_dict: Dict[Result, str]):\n\tr\"\"\"\n\tDownload the selected papers.\n\n\tArgs:\n\t\tpaper_dict (Dict[Result, str]):\n\t\t\t- key: paper (Result)\n\t\t\t- value: save_dir (str)\n\t\"\"\"\n\tfor paper in paper_dict.keys():\n\t\tpaper.download_pdf(dirpath=paper_dict[paper], filename=f\"{paper.title}.pdf\")\n</code></pre>"},{"location":"code_docs/func_modules/paper/download/arxiv/#labridge.func_modules.paper.download.arxiv.ArxivDailyDownloader.get_daily_papers_info","title":"<code>labridge.func_modules.paper.download.arxiv.ArxivDailyDownloader.get_daily_papers_info(relevant_categories)</code>","text":"<p>Get the recent papers relevant to the input categories.</p> <p>The information (e.g. Abstract, Title, Authors) of these daily papers will be sent to the corresponding Lab Members. The papers selected by the members will be parsed and stored into a proper directory.</p> PARAMETER DESCRIPTION <code>relevant_categories</code> <p>The recent papers in these categories will be counted.</p> <p> TYPE: <code>List[str]</code> </p> Return <p>List[Result]: Recent papers information.</p> Source code in <code>labridge\\func_modules\\paper\\download\\arxiv.py</code> <pre><code>def get_daily_papers_info(self, relevant_categories: List[str]) -&gt; List[Result]:\n\tr\"\"\"\n\tGet the recent papers relevant to the input categories.\n\n\tThe information (e.g. Abstract, Title, Authors) of these daily papers will be sent to\n\tthe corresponding Lab Members. The papers selected by the members will be parsed and stored\n\tinto a proper directory.\n\n\tArgs:\n\t\trelevant_categories (List[str]): The recent papers in these categories will be counted.\n\n\tReturn:\n\t\tList[Result]: Recent papers information.\n\t\"\"\"\n\tquery = \"\"\n\tfor cat in relevant_categories:\n\t\tif self._is_valid_category(cat):\n\t\t\tif len(query) &gt; 0:\n\t\t\t\tquery += \"+OR+\"\n\t\t\tquery += f\"cat:{cat}\"\n\n\tdaily_papers = []\n\tif len(query) == 0:\n\t\treturn daily_papers\n\n\tself.search.query = query\n\tstart_date = self.today - datetime.timedelta(days=self.recent_days)\n\tfor result in self.client.results(search=self.search):\n\t\tsubmit_date = result.published\n\t\tif not self._valid_date(date=submit_date, start_date=start_date, end_date=self.today):\n\t\t\tbreak\n\t\tdaily_papers.append(result)\n\treturn daily_papers\n</code></pre>"},{"location":"code_docs/func_modules/paper/download/arxiv/#labridge.func_modules.paper.download.arxiv.ArxivSearcher","title":"<code>labridge.func_modules.paper.download.arxiv.ArxivSearcher</code>","text":"<p>               Bases: <code>object</code></p> <p>This class searches for papers in the arxiv.</p> ATTRIBUTE DESCRIPTION <code>max_results_num</code> <p>Maximum number of results in a search.</p> <p> TYPE: <code>int</code> </p> <code>category</code> <p>The arXiv research category.</p> <p> TYPE: <code>ArxivCategory</code> </p> <code>client</code> <p>Client responsible for searching.</p> <p> TYPE: <code>ArxivClient</code> </p> <code>searcher</code> <p>The parameters of searching.</p> <p> TYPE: <code>Search</code> </p> Source code in <code>labridge\\func_modules\\paper\\download\\arxiv.py</code> <pre><code>class ArxivSearcher(object):\n\tr\"\"\"\n\tThis class searches for papers in the arxiv.\n\n\tAttributes:\n\t\tmax_results_num (int): Maximum number of results in a search.\n\t\tcategory (ArxivCategory): The arXiv research category.\n\t\tclient (ArxivClient): Client responsible for searching.\n\t\tsearcher (Search): The parameters of searching.\n\t\"\"\"\n\tdef __init__(self, max_results_num: int = 5):\n\t\tself.max_results_num = max_results_num\n\t\tself.category = ArxivCategory()\n\t\tself.client = ArxivClient()\n\t\tself.searcher = Search(\n\t\t\tquery=\"\",\n\t\t\tsort_by=SortCriterion.Relevance,\n\t\t\tsort_order=SortOrder.Descending,\n\t\t)\n\n\tdef search(self, search_str: str) -&gt; List[Result]:\n\t\tr\"\"\"\n\t\tSearch according to the title or abstract.\n\n\t\tArgs:\n\t\t\tsearch_str (str): The search string, typically the title or abstract.\n\n\t\tReturns:\n\t\t\tList[Result]: The search results.\n\t\t\"\"\"\n\t\tquery = f\"ti:{search_str}+OR+abs:{search_str}\"\n\t\tself.searcher.query = query\n\t\tcount = 0\n\t\tresults = []\n\t\tfor result in self.client.results(search=self.searcher):\n\t\t\tcount += 1\n\t\t\tresults.append(result)\n\t\t\tif count &gt;= self.max_results_num:\n\t\t\t\tbreak\n\t\treturn results\n</code></pre>"},{"location":"code_docs/func_modules/paper/download/arxiv/#labridge.func_modules.paper.download.arxiv.ArxivSearcher.search","title":"<code>labridge.func_modules.paper.download.arxiv.ArxivSearcher.search(search_str)</code>","text":"<p>Search according to the title or abstract.</p> PARAMETER DESCRIPTION <code>search_str</code> <p>The search string, typically the title or abstract.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>List[Result]</code> <p>List[Result]: The search results.</p> Source code in <code>labridge\\func_modules\\paper\\download\\arxiv.py</code> <pre><code>def search(self, search_str: str) -&gt; List[Result]:\n\tr\"\"\"\n\tSearch according to the title or abstract.\n\n\tArgs:\n\t\tsearch_str (str): The search string, typically the title or abstract.\n\n\tReturns:\n\t\tList[Result]: The search results.\n\t\"\"\"\n\tquery = f\"ti:{search_str}+OR+abs:{search_str}\"\n\tself.searcher.query = query\n\tcount = 0\n\tresults = []\n\tfor result in self.client.results(search=self.searcher):\n\t\tcount += 1\n\t\tresults.append(result)\n\t\tif count &gt;= self.max_results_num:\n\t\t\tbreak\n\treturn results\n</code></pre>"},{"location":"code_docs/func_modules/paper/download/async_utils/","title":"Async utils","text":""},{"location":"code_docs/func_modules/paper/download/async_utils/#labridge.func_modules.paper.download.async_utils","title":"<code>labridge.func_modules.paper.download.async_utils</code>","text":""},{"location":"code_docs/func_modules/paper/download/async_utils/#labridge.func_modules.paper.download.async_utils.adownload_file","title":"<code>labridge.func_modules.paper.download.async_utils.adownload_file(url, save_path)</code>  <code>async</code>","text":"<p>Asynchronously download file.</p> PARAMETER DESCRIPTION <code>url</code> <p>The url of the file.</p> <p> TYPE: <code>str</code> </p> <code>save_path</code> <p>The save path of the file.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>save_path</code> <p>The save path.</p> <p> TYPE: <code>str</code> </p> Source code in <code>labridge\\func_modules\\paper\\download\\async_utils.py</code> <pre><code>async def adownload_file(url: str, save_path: str) -&gt; str:\n\tr\"\"\"\n\tAsynchronously download file.\n\n\tArgs:\n\t\turl (str): The url of the file.\n\t\tsave_path (str): The save path of the file.\n\n\tReturns:\n\t\tsave_path (str): The save path.\n\t\"\"\"\n\tasync with aiohttp.ClientSession() as session:\n\t\tasync with session.get(url) as response:\n\t\t\twith open(save_path, 'wb') as f:\n\t\t\t\twhile True:\n\t\t\t\t\tchunk = await response.content.read(1024)\n\t\t\t\t\tif not chunk:\n\t\t\t\t\t\tbreak\n\t\t\t\t\tf.write(chunk)\n\treturn save_path\n</code></pre>"},{"location":"code_docs/func_modules/paper/parse/paper_reader/","title":"Paper reader","text":""},{"location":"code_docs/func_modules/paper/parse/paper_reader/#labridge.func_modules.paper.parse.paper_reader","title":"<code>labridge.func_modules.paper.parse.paper_reader</code>","text":""},{"location":"code_docs/func_modules/paper/parse/paper_reader/#labridge.func_modules.paper.parse.paper_reader.PaperReader","title":"<code>labridge.func_modules.paper.parse.paper_reader.PaperReader</code>","text":"<p>Read a PDF paper, and extract valid meta_data from it.</p> PARAMETER DESCRIPTION <code>llm</code> <p>the used llm, if not provided, use the llm from <code>service_context</code>. Defaults to None.</p> <p> TYPE: <code>LLM</code> DEFAULT: <code>None</code> </p> <code>source_keyword_threshold</code> <p>used in PaperSourceAnalyzer. refer to PaperSourceAnalyzer for details. Defaults to 10</p> <p> TYPE: <code>int</code> DEFAULT: <code>10</code> </p> <code>use_llm_for_source</code> <p>whether to use LLM in the source analyzer. Defaults to True.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>extract_metadata</code> <p>whether to use LLM to extract metadata for papers. Defaults to True.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>necessary_metadata</code> <p>Paper level metadata. The necessary metadata that must be extracted. It is a dictionary with k-v pairs like: {metadata_name: description}. The description is used to instruct the llm to extract the corresponding metadata. For example:</p> <ul> <li>key: \"Title\"</li> <li>value: \"The title often appears as a single concise sentence at the head of a paper.\"</li> </ul> <p> TYPE: <code>Dict[str, str]</code> DEFAULT: <code>None</code> </p> <code>optional_metadata</code> <p>Paper level metadata. The optional metadata that is not forced to extract from the paper. It is a dictionary with k-v pairs like: {metadata_name: description}.</p> <p> TYPE: <code>Dict[str, str]</code> DEFAULT: <code>None</code> </p> <code>extract_retry_times</code> <p>max retry times if not all necessary metadata is extracted.</p> <p> TYPE: <code>int</code> DEFAULT: <code>2</code> </p> <code>service_context</code> <p>the service context.</p> <p> TYPE: <code>ServiceContext</code> DEFAULT: <code>None</code> </p> <code>recursive</code> <p>Whether to recursively search in subdirectories.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <pre><code>False by default.\n    exclude (List): glob of python file paths to exclude (Optional)\n</code></pre> <p>exclude_hidden (bool): Whether to exclude hidden files (dotfiles). required_exts (Optional[List[str]]): List of required extensions.     Default is None. num_files_limit (Optional[int]): Maximum number of files to read.     Default is None.         filename_as_id (bool): whether to use the filename as the document id. True by default.                 If set to True, the doc node will be named as <code>{file_path}_{content_type}</code>.                 The file_path is relative to root directory.</p> Source code in <code>labridge\\func_modules\\paper\\parse\\paper_reader.py</code> <pre><code>class PaperReader:\n\tr\"\"\"\n\tRead a PDF paper, and extract valid meta_data from it.\n\n\tArgs:\n\t\tllm (LLM: the used llm, if not provided, use the llm from `service_context`.\n\t\t\tDefaults to None.\n\t\tsource_keyword_threshold (int): used in PaperSourceAnalyzer. refer to PaperSourceAnalyzer for details.\n\t\t\tDefaults to 10\n\t\tuse_llm_for_source (bool): whether to use LLM in the source analyzer. Defaults to True.\n\t\textract_metadata (bool): whether to use LLM to extract metadata for papers. Defaults to True.\n\t\tnecessary_metadata (Dict[str, str]): Paper level metadata.\n\t\t\tThe necessary metadata that must be extracted.\n\t\t \tIt is a dictionary with k-v pairs like: {metadata_name: description}. The description\n\t\t \tis used to instruct the llm to extract the corresponding metadata.\n\t\t \tFor example:\n\n\t\t \t- key: \"Title\"\n\t\t \t- value: \"The title often appears as a single concise sentence at the head of a paper.\"\n\t\toptional_metadata (Dict[str, str]): Paper level metadata.\n\t\t\tThe optional metadata that is not forced to extract from the paper.\n\t\t\tIt is a dictionary with k-v pairs like: {metadata_name: description}.\n\t\textract_retry_times: max retry times if not all necessary metadata is extracted.\n\t\tservice_context (ServiceContext): the service context.\n\t\trecursive (bool): Whether to recursively search in subdirectories.\n            False by default.\n\t\texclude (List): glob of python file paths to exclude (Optional)\n        exclude_hidden (bool): Whether to exclude hidden files (dotfiles).\n        required_exts (Optional[List[str]]): List of required extensions.\n            Default is None.\n        num_files_limit (Optional[int]): Maximum number of files to read.\n            Default is None.\n\t\tfilename_as_id (bool): whether to use the filename as the document id. True by default.\n\t\t\tIf set to True, the doc node will be named as `{file_path}_{content_type}`.\n\t\t\tThe file_path is relative to root directory.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tllm: LLM = None,\n\t\tsource_keyword_threshold: int = 10,\n\t\tuse_llm_for_source: bool = True,\n\t\textract_metadata: bool = True,\n\t\tnecessary_metadata: Dict[str, str] = None,\n\t\toptional_metadata: Dict[str, str] = None,\n\t\textract_retry_times: int = 2,\n\t\tfilename_as_id: bool = True,\n\t\tservice_context: ServiceContext = None,\n\t\trecursive: bool = False,\n\t\texclude: Optional[List] = None,\n\t\texclude_hidden: bool = True,\n\t\trequired_exts: Optional[List[str]] = None,\n\t\tnum_files_limit: Optional[int] = None,\n\t\tfs: Optional[fsspec.AbstractFileSystem] = None,\n\t):\n\t\tself.metadata_extractor = None\n\t\tself.extract_metadata = extract_metadata\n\t\tif extract_metadata:\n\t\t\tself.metadata_extractor = PaperMetadataExtractor(\n\t\t\t\tllm=llm,\n\t\t\t\tnecessary_metadata=necessary_metadata,\n\t\t\t\toptional_metadata=optional_metadata,\n\t\t\t\tmax_retry_times=extract_retry_times,\n\t\t\t\tservice_context=service_context,\n\t\t\t)\n\t\tif llm is None:\n\t\t\tself.llm = llm_from_settings_or_context(Settings, service_context)\n\t\telse:\n\t\t\tself.llm = llm\n\n\t\tself.source_analyzer = PaperSourceAnalyzer(llm=self.llm, keyword_count_threshold=source_keyword_threshold)\n\t\tself.use_llm_for_source = use_llm_for_source\n\t\tself.filename_as_id = filename_as_id\n\t\tself.recursive = recursive\n\t\tself.exclude = exclude\n\t\tself.exclude_hidden = exclude_hidden\n\t\tself.required_exts = required_exts\n\t\tself.num_files_limit = num_files_limit\n\t\tself.fs = fs or LocalFileSystem()\n\t\troot = Path(__file__)\n\t\tfor i in range(5):\n\t\t\troot = root.parent\n\t\tself.root = root\n\n\tdef get_paper_possessor(self, paper_path: Union[Path, str]) -&gt; str:\n\t\tr\"\"\"\n\t\tGet the possessor of this paper.\n\t\tAssume the possessor is the first level directory under the paper warehouse.\n\n\t\tArgs:\n\t\t\tpaper_path (Union[Path, str]): The file path of paper.\n\n\t\tReturns:\n\t\t\tstr: The paper possessor.\n\t\t\"\"\"\n\t\tif isinstance(paper_path, str):\n\t\t\tpaper_path = Path(paper_path)\n\t\ttry:\n\t\t\tpaper_warehouse = self.root / SHARED_PAPER_WAREHOUSE_DIR\n\t\t\trel = paper_path.relative_to(paper_warehouse)\n\t\t\tpossessor = rel.parts[0]\n\t\t\treturn possessor\n\t\texcept ValueError:\n\t\t\traise ValueError(\"The path of the paper is not valid, a valid path should be under the PaperWarehouse directory.\")\n\n\tdef read_single_paper(\n\t\tself,\n\t\tfile_path: Union[Path, str],\n\t\tshow_progress: bool = True,\n\t\textra_metadata: dict = None,\n\t) -&gt; Optional[Tuple[List[Document], List[Document]]]:\n\t\tr\"\"\"\n\t\tRead a single pdf paper.\n\n\t\tArgs:\n\t\t\tfile_path (Union[Path, str]): the path of pdf paper.\n\t\t\tshow_progress (bool): show parsing progress.\n\t\t\textra_metadata (dict): Existing metadata obtained by approaches such as arXiv API.\n\n\t\tReturns:\n\t\t\tTuple[List[Document], List[Document]]:\n\t\t\t\tThe ingested content docs and extra docs.\n\n\t\t\t\t- chunk_docs: the docs for retrieving, include information such as main text, methods.\n\t\t\t\tMight be None if nothing is parsed (auto_parse_paper fails.)\n\t\t\t\t- extra_docs: docs that involve supplementary information such as references.\n\t\t\t\tMight be None.\n\t\t\"\"\"\n\t\tif isinstance(file_path, str):\n\t\t\tfile_path = Path(file_path)\n\t\tif str(file_path)[-4:] != '.pdf':\n\t\t\traise ValueError(\"Expect a PDF file.\")\n\t\tif show_progress:\n\t\t\tprint_text(f\"&gt;&gt;&gt; Loading {file_path}\", color=\"blue\", end=\"\\n\")\n\t\tparsed_docs = auto_parse_paper(\n\t\t\tfile_path=file_path,\n\t\t\tsource_analyzer=self.source_analyzer,\n\t\t\tuse_llm_for_source=self.use_llm_for_source\n\t\t)\n\n\t\tchunk_docs, extra_docs, metadata_docs = [], [], []\n\t\tfor doc in parsed_docs:\n\t\t\tif doc.metadata[CONTENT_TYPE_NAME] in MetadataContents:\n\t\t\t\tmetadata_docs.append(doc)\n\t\t\telif doc.metadata[CONTENT_TYPE_NAME] in ChunkContents:\n\t\t\t\tchunk_docs.append(doc)\n\t\t\telse:\n\t\t\t\textra_docs.append(doc)\n\n\t\t# metadata\n\t\tpaper_metadata = dict()\n\n\t\tif self.extract_metadata:\n\t\t\tpaper_metadata = self.metadata_extractor.extract_paper_metadata(\n\t\t\t\tpdf_path=file_path,\n\t\t\t\textra_metadata=extra_metadata,\n\t\t\t)\n\t\t\tif paper_metadata is None:\n\t\t\t\treturn None\n\n\t\t\tfor meta_doc in metadata_docs:\n\t\t\t\tmetadata_name = meta_doc.metadata[CONTENT_TYPE_NAME]\n\t\t\t\tif metadata_name not in paper_metadata.keys():\n\t\t\t\t\tpaper_metadata[metadata_name] = meta_doc.text\n\n\t\tpossessor = self.get_paper_possessor(file_path)\n\t\tpaper_metadata[PAPER_POSSESSOR] = possessor\n\t\tpaper_metadata[PAPER_REL_FILE_PATH] = str(file_path.relative_to(self.root))\n\n\t\tfor idx, doc in enumerate(parsed_docs):\n\t\t\tdoc.metadata.update(paper_metadata)\n\t\t\tif self.filename_as_id:\n\t\t\t\trel_path = str(file_path.relative_to(self.root))\n\t\t\t\tdoc.id_ = f\"{rel_path!s}_{doc.metadata[CONTENT_TYPE_NAME]}\"\n\t\treturn chunk_docs, extra_docs\n\n\tdef read_papers(\n\t\tself,\n\t\tinput_dir: Optional[str] = None,\n\t\tinput_files: Optional[List] = None,\n\t\tshow_progress: bool = True,\n\t) -&gt; Tuple[List[Document], List[Document]]:\n\t\tr\"\"\"\n\t\tRead papers.\n\n\t\tArgs:\n\t\t\tinput_dir (Optional[str]): the paper directory.\n\t\t\tinput_files (Optional[List]): the paths of papers. If it is specified, the `input_dir` is ignored.\n\t\t\tshow_progress (bool): show parsing progress.\n\n\t\tReturns:\n\t\t\tTuple[List[Document], List[Document]]:\n\t\t\t\tthe content docs and the extra docs.\n\n\t\t\t\t- contents: for retrieving, each sequence in the list contains the content docs of a paper.\n\t\t\t\t- extra_info: extra info, each sequence in the list contains the extra docs of a paper.\n\t\t\"\"\"\n\t\t_Path = Path if is_default_fs(self.fs) else PurePosixPath\n\t\tpaper_files = None\n\t\tif input_files:\n\t\t\tpaper_files = []\n\t\t\tfor path in input_files:\n\t\t\t\tif not self.fs.isfile(path):\n\t\t\t\t\traise ValueError(f\"File {path} does not exist.\")\n\t\t\t\tinput_file = _Path(path)\n\t\t\t\tpaper_files.append(input_file)\n\t\telif input_dir:\n\t\t\tif not self.fs.isdir(input_dir):\n\t\t\t\traise ValueError(f\"Directory {input_dir} does not exist.\")\n\t\t\tinput_dir = _Path(input_dir)\n\t\t\tpaper_files = self._add_files(input_dir)\n\n\t\tcontents, extra_info = [], []\n\t\tif paper_files is not None:\n\t\t\tfor idx, paper in enumerate(paper_files):\n\t\t\t\tif str(paper)[-4:] != '.pdf':\n\t\t\t\t\tcontinue\n\t\t\t\tcontent_docs, extra_docs = self.read_single_paper(file_path=paper, show_progress=show_progress)\n\t\t\t\tcontents += content_docs\n\t\t\t\textra_info += extra_docs\n\t\treturn contents, extra_info\n\n\tdef is_hidden(self, path: Path) -&gt; bool:\n\t\treturn any(part.startswith(\".\") and part not in [\".\", \"..\"] for part in path.parts)\n\n\tdef _add_files(self, input_dir: Path) -&gt; List[Path]:\n\t\t\"\"\"Add files.\"\"\"\n\t\tall_files = set()\n\t\trejected_files = set()\n\t\trejected_dirs = set()\n\t\t# Default to POSIX paths for non-default file systems (e.g. S3)\n\t\t_Path = Path if is_default_fs(self.fs) else PurePosixPath\n\n\t\tif self.exclude is not None:\n\t\t\tfor excluded_pattern in self.exclude:\n\t\t\t\tif self.recursive:\n\t\t\t\t\t# Recursive glob\n\t\t\t\t\texcluded_glob = _Path(input_dir) / _Path(\"**\") / excluded_pattern\n\t\t\t\telse:\n\t\t\t\t\t# Non-recursive glob\n\t\t\t\t\texcluded_glob = _Path(input_dir) / excluded_pattern\n\t\t\t\tfor file in self.fs.glob(str(excluded_glob)):\n\t\t\t\t\tif self.fs.isdir(file):\n\t\t\t\t\t\trejected_dirs.add(_Path(file))\n\t\t\t\t\telse:\n\t\t\t\t\t\trejected_files.add(_Path(file))\n\n\t\tfile_refs: List[str] = []\n\t\tif self.recursive:\n\t\t\tfile_refs = self.fs.glob(str(input_dir) + \"/**/*\")\n\t\telse:\n\t\t\tfile_refs = self.fs.glob(str(input_dir) + \"/*\")\n\n\t\tfor ref in file_refs:\n\t\t\t# Manually check if file is hidden or directory instead of\n\t\t\t# in glob for backwards compatibility.\n\t\t\tref = _Path(ref)\n\t\t\tis_dir = self.fs.isdir(ref)\n\t\t\tskip_because_hidden = self.exclude_hidden and self.is_hidden(ref)\n\t\t\tskip_because_bad_ext = (self.required_exts is not None and ref.suffix not in self.required_exts)\n\t\t\tskip_because_excluded = ref in rejected_files\n\t\t\tif not skip_because_excluded:\n\t\t\t\tif is_dir:\n\t\t\t\t\tref_parent_dir = ref\n\t\t\t\telse:\n\t\t\t\t\tref_parent_dir = self.fs._parent(ref)\n\t\t\t\tfor rejected_dir in rejected_dirs:\n\t\t\t\t\tif str(ref_parent_dir).startswith(str(rejected_dir)):\n\t\t\t\t\t\tskip_because_excluded = True\n\t\t\t\t\t\tlogger.debug(\"Skipping %s because it in parent dir %s which is in %s\", ref, ref_parent_dir,\n\t\t\t\t\t\t\trejected_dir, )\n\t\t\t\t\t\tbreak\n\n\t\t\tif (is_dir or skip_because_hidden or skip_because_bad_ext or skip_because_excluded):\n\t\t\t\tcontinue\n\t\t\telse:\n\t\t\t\tall_files.add(ref)\n\n\t\tnew_input_files = sorted(all_files)\n\n\t\tif len(new_input_files) == 0:\n\t\t\traise ValueError(f\"No files found in {input_dir}.\")\n\n\t\tif self.num_files_limit is not None and self.num_files_limit &gt; 0:\n\t\t\tnew_input_files = new_input_files[0: self.num_files_limit]\n\n\t\t# print total number of files added\n\t\tlogger.debug(f\"&gt; [PaperReader] Total files added: {len(new_input_files)}\")\n\n\t\treturn new_input_files\n</code></pre>"},{"location":"code_docs/func_modules/paper/parse/paper_reader/#labridge.func_modules.paper.parse.paper_reader.PaperReader.get_paper_possessor","title":"<code>labridge.func_modules.paper.parse.paper_reader.PaperReader.get_paper_possessor(paper_path)</code>","text":"<p>Get the possessor of this paper. Assume the possessor is the first level directory under the paper warehouse.</p> PARAMETER DESCRIPTION <code>paper_path</code> <p>The file path of paper.</p> <p> TYPE: <code>Union[Path, str]</code> </p> RETURNS DESCRIPTION <code>str</code> <p>The paper possessor.</p> <p> TYPE: <code>str</code> </p> Source code in <code>labridge\\func_modules\\paper\\parse\\paper_reader.py</code> <pre><code>def get_paper_possessor(self, paper_path: Union[Path, str]) -&gt; str:\n\tr\"\"\"\n\tGet the possessor of this paper.\n\tAssume the possessor is the first level directory under the paper warehouse.\n\n\tArgs:\n\t\tpaper_path (Union[Path, str]): The file path of paper.\n\n\tReturns:\n\t\tstr: The paper possessor.\n\t\"\"\"\n\tif isinstance(paper_path, str):\n\t\tpaper_path = Path(paper_path)\n\ttry:\n\t\tpaper_warehouse = self.root / SHARED_PAPER_WAREHOUSE_DIR\n\t\trel = paper_path.relative_to(paper_warehouse)\n\t\tpossessor = rel.parts[0]\n\t\treturn possessor\n\texcept ValueError:\n\t\traise ValueError(\"The path of the paper is not valid, a valid path should be under the PaperWarehouse directory.\")\n</code></pre>"},{"location":"code_docs/func_modules/paper/parse/paper_reader/#labridge.func_modules.paper.parse.paper_reader.PaperReader.read_papers","title":"<code>labridge.func_modules.paper.parse.paper_reader.PaperReader.read_papers(input_dir=None, input_files=None, show_progress=True)</code>","text":"<p>Read papers.</p> PARAMETER DESCRIPTION <code>input_dir</code> <p>the paper directory.</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>input_files</code> <p>the paths of papers. If it is specified, the <code>input_dir</code> is ignored.</p> <p> TYPE: <code>Optional[List]</code> DEFAULT: <code>None</code> </p> <code>show_progress</code> <p>show parsing progress.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>Tuple[List[Document], List[Document]]</code> <p>Tuple[List[Document], List[Document]]: the content docs and the extra docs.</p> <ul> <li>contents: for retrieving, each sequence in the list contains the content docs of a paper.</li> <li>extra_info: extra info, each sequence in the list contains the extra docs of a paper.</li> </ul> Source code in <code>labridge\\func_modules\\paper\\parse\\paper_reader.py</code> <pre><code>def read_papers(\n\tself,\n\tinput_dir: Optional[str] = None,\n\tinput_files: Optional[List] = None,\n\tshow_progress: bool = True,\n) -&gt; Tuple[List[Document], List[Document]]:\n\tr\"\"\"\n\tRead papers.\n\n\tArgs:\n\t\tinput_dir (Optional[str]): the paper directory.\n\t\tinput_files (Optional[List]): the paths of papers. If it is specified, the `input_dir` is ignored.\n\t\tshow_progress (bool): show parsing progress.\n\n\tReturns:\n\t\tTuple[List[Document], List[Document]]:\n\t\t\tthe content docs and the extra docs.\n\n\t\t\t- contents: for retrieving, each sequence in the list contains the content docs of a paper.\n\t\t\t- extra_info: extra info, each sequence in the list contains the extra docs of a paper.\n\t\"\"\"\n\t_Path = Path if is_default_fs(self.fs) else PurePosixPath\n\tpaper_files = None\n\tif input_files:\n\t\tpaper_files = []\n\t\tfor path in input_files:\n\t\t\tif not self.fs.isfile(path):\n\t\t\t\traise ValueError(f\"File {path} does not exist.\")\n\t\t\tinput_file = _Path(path)\n\t\t\tpaper_files.append(input_file)\n\telif input_dir:\n\t\tif not self.fs.isdir(input_dir):\n\t\t\traise ValueError(f\"Directory {input_dir} does not exist.\")\n\t\tinput_dir = _Path(input_dir)\n\t\tpaper_files = self._add_files(input_dir)\n\n\tcontents, extra_info = [], []\n\tif paper_files is not None:\n\t\tfor idx, paper in enumerate(paper_files):\n\t\t\tif str(paper)[-4:] != '.pdf':\n\t\t\t\tcontinue\n\t\t\tcontent_docs, extra_docs = self.read_single_paper(file_path=paper, show_progress=show_progress)\n\t\t\tcontents += content_docs\n\t\t\textra_info += extra_docs\n\treturn contents, extra_info\n</code></pre>"},{"location":"code_docs/func_modules/paper/parse/paper_reader/#labridge.func_modules.paper.parse.paper_reader.PaperReader.read_single_paper","title":"<code>labridge.func_modules.paper.parse.paper_reader.PaperReader.read_single_paper(file_path, show_progress=True, extra_metadata=None)</code>","text":"<p>Read a single pdf paper.</p> PARAMETER DESCRIPTION <code>file_path</code> <p>the path of pdf paper.</p> <p> TYPE: <code>Union[Path, str]</code> </p> <code>show_progress</code> <p>show parsing progress.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>extra_metadata</code> <p>Existing metadata obtained by approaches such as arXiv API.</p> <p> TYPE: <code>dict</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Optional[Tuple[List[Document], List[Document]]]</code> <p>Tuple[List[Document], List[Document]]: The ingested content docs and extra docs.</p> <ul> <li>chunk_docs: the docs for retrieving, include information such as main text, methods. Might be None if nothing is parsed (auto_parse_paper fails.)</li> <li>extra_docs: docs that involve supplementary information such as references. Might be None.</li> </ul> Source code in <code>labridge\\func_modules\\paper\\parse\\paper_reader.py</code> <pre><code>def read_single_paper(\n\tself,\n\tfile_path: Union[Path, str],\n\tshow_progress: bool = True,\n\textra_metadata: dict = None,\n) -&gt; Optional[Tuple[List[Document], List[Document]]]:\n\tr\"\"\"\n\tRead a single pdf paper.\n\n\tArgs:\n\t\tfile_path (Union[Path, str]): the path of pdf paper.\n\t\tshow_progress (bool): show parsing progress.\n\t\textra_metadata (dict): Existing metadata obtained by approaches such as arXiv API.\n\n\tReturns:\n\t\tTuple[List[Document], List[Document]]:\n\t\t\tThe ingested content docs and extra docs.\n\n\t\t\t- chunk_docs: the docs for retrieving, include information such as main text, methods.\n\t\t\tMight be None if nothing is parsed (auto_parse_paper fails.)\n\t\t\t- extra_docs: docs that involve supplementary information such as references.\n\t\t\tMight be None.\n\t\"\"\"\n\tif isinstance(file_path, str):\n\t\tfile_path = Path(file_path)\n\tif str(file_path)[-4:] != '.pdf':\n\t\traise ValueError(\"Expect a PDF file.\")\n\tif show_progress:\n\t\tprint_text(f\"&gt;&gt;&gt; Loading {file_path}\", color=\"blue\", end=\"\\n\")\n\tparsed_docs = auto_parse_paper(\n\t\tfile_path=file_path,\n\t\tsource_analyzer=self.source_analyzer,\n\t\tuse_llm_for_source=self.use_llm_for_source\n\t)\n\n\tchunk_docs, extra_docs, metadata_docs = [], [], []\n\tfor doc in parsed_docs:\n\t\tif doc.metadata[CONTENT_TYPE_NAME] in MetadataContents:\n\t\t\tmetadata_docs.append(doc)\n\t\telif doc.metadata[CONTENT_TYPE_NAME] in ChunkContents:\n\t\t\tchunk_docs.append(doc)\n\t\telse:\n\t\t\textra_docs.append(doc)\n\n\t# metadata\n\tpaper_metadata = dict()\n\n\tif self.extract_metadata:\n\t\tpaper_metadata = self.metadata_extractor.extract_paper_metadata(\n\t\t\tpdf_path=file_path,\n\t\t\textra_metadata=extra_metadata,\n\t\t)\n\t\tif paper_metadata is None:\n\t\t\treturn None\n\n\t\tfor meta_doc in metadata_docs:\n\t\t\tmetadata_name = meta_doc.metadata[CONTENT_TYPE_NAME]\n\t\t\tif metadata_name not in paper_metadata.keys():\n\t\t\t\tpaper_metadata[metadata_name] = meta_doc.text\n\n\tpossessor = self.get_paper_possessor(file_path)\n\tpaper_metadata[PAPER_POSSESSOR] = possessor\n\tpaper_metadata[PAPER_REL_FILE_PATH] = str(file_path.relative_to(self.root))\n\n\tfor idx, doc in enumerate(parsed_docs):\n\t\tdoc.metadata.update(paper_metadata)\n\t\tif self.filename_as_id:\n\t\t\trel_path = str(file_path.relative_to(self.root))\n\t\t\tdoc.id_ = f\"{rel_path!s}_{doc.metadata[CONTENT_TYPE_NAME]}\"\n\treturn chunk_docs, extra_docs\n</code></pre>"},{"location":"code_docs/func_modules/paper/parse/extractors/metadata_extract/","title":"Metadata extract","text":""},{"location":"code_docs/func_modules/paper/parse/extractors/metadata_extract/#labridge.func_modules.paper.parse.extractors.metadata_extract","title":"<code>labridge.func_modules.paper.parse.extractors.metadata_extract</code>","text":""},{"location":"code_docs/func_modules/paper/parse/extractors/metadata_extract/#labridge.func_modules.paper.parse.extractors.metadata_extract.PaperMetadataExtractor","title":"<code>labridge.func_modules.paper.parse.extractors.metadata_extract.PaperMetadataExtractor</code>","text":"<p>This class uses LLM to extracts metadata from a paper.</p> <p>The LLM is instructed to extract all <code>DEFAULT_NECESSARY_METADATA</code>. The LLM is encourages to extract <code>DEFAULT_OPTIONAL_METADATA</code>.</p> PARAMETER DESCRIPTION <code>llm</code> <p>The used LLM.</p> <p> TYPE: <code>LLM</code> DEFAULT: <code>None</code> </p> <code>necessary_metadata</code> <p>The LLM is instructed to extract all necessary_metadata. Defaults to <code>DEFAULT_NECESSARY_METADATA</code>.</p> <p> TYPE: <code>Dict[str, str]</code> DEFAULT: <code>None</code> </p> <code>optional_metadata</code> <p>The LLM is encourages to extract optional_metadata. Defaults to <code>DEFAULT_OPTIONAL_METADATA</code>.</p> <p> TYPE: <code>Dict[str, str]</code> DEFAULT: <code>None</code> </p> <code>max_retry_times</code> <p>The maximum retry times for extracting necessary_metadata.</p> <p> TYPE: <code>int</code> DEFAULT: <code>2</code> </p> <code>service_context</code> <p>The context including llm, embed_model, etc.</p> <p> TYPE: <code>ServiceContext</code> DEFAULT: <code>None</code> </p> Source code in <code>labridge\\func_modules\\paper\\parse\\extractors\\metadata_extract.py</code> <pre><code>class PaperMetadataExtractor:\n\tr\"\"\"\n\tThis class uses LLM to extracts metadata from a paper.\n\n\tThe LLM is instructed to extract all `DEFAULT_NECESSARY_METADATA`.\n\tThe LLM is encourages to extract `DEFAULT_OPTIONAL_METADATA`.\n\n\tArgs:\n\t\tllm (LLM): The used LLM.\n\t\tnecessary_metadata (Dict[str, str]): The LLM is instructed to extract all necessary_metadata.\n\t\t\tDefaults to `DEFAULT_NECESSARY_METADATA`.\n\t\toptional_metadata (Dict[str, str]): The LLM is encourages to extract optional_metadata.\n\t\t\tDefaults to `DEFAULT_OPTIONAL_METADATA`.\n\t\tmax_retry_times (int): The maximum retry times for extracting necessary_metadata.\n\t\tservice_context (ServiceContext): The context including llm, embed_model, etc.\n\t\"\"\"\n\n\tdef __init__(\n\t\tself,\n\t\tllm: LLM = None,\n\t\tnecessary_metadata: Dict[str, str] = None,\n\t\toptional_metadata: Dict[str, str] = None,\n\t\tmax_retry_times: int = 2,\n\t\tservice_context: ServiceContext = None,\n\t):\n\t\tself.necessary_metadata = necessary_metadata or DEFAULT_NECESSARY_METADATA\n\t\tself.optional_metadata = optional_metadata or DEFAULT_OPTIONAL_METADATA\n\t\tif llm is None:\n\t\t\tself.llm = llm_from_settings_or_context(Settings, service_context)\n\t\telse:\n\t\t\tself.llm = llm\n\n\t\tself.prompt_tmpl = self.get_prompt_tmpl()\n\t\tself.crossref_worker = CrossRefWorker()\n\t\tself.query_engine = SingleQueryEngine(llm=llm, prompt_tmpl=self.prompt_tmpl)\n\t\tself.max_retry_times = max_retry_times\n\n\tdef _default_transformations(self) -&gt; List[TransformComponent]:\n\t\treturn [\n\t\t\t\tSentenceSplitter(chunk_size=1024, chunk_overlap=256, include_metadata=True),\n\t\t\t\tKeywordExtractor(keywords=5, llm=self.llm),\n\t\t\t]\n\n\tdef get_prompt_tmpl(\n\t\tself,\n\t\tnecessary_metadata: Dict[str, str] = None,\n\t\toptional_metadata: Dict[str, str] = None,\n\t) -&gt; str:\n\t\tr\"\"\"\n\t\tThis function is used to get the prompt template used for extracting metadata, according to the\n\t\t`necessary_metadata` and `optional_metadata`.\n\n\t\tArgs:\n\t\t\tnecessary_metadata (Dict[str, str]): necessary metadata, Defaults to `self.necessary_metadata`.\n\t\t\toptional_metadata (Dict[str, str]): optional metadata, Defaults to `self.optional_metadata`.\n\t\t\"\"\"\n\t\tnecessary_metadata = necessary_metadata or self.necessary_metadata\n\t\toptional_metadata = optional_metadata or self.optional_metadata\n\n\t\ttmpl = (\"Here is the first page of a research paper. \"\n\t\t\t\t\"You need try to extract some information from it.\\n\\n\"\n\t\t\t\t\"The NECESSARY metadata that you MUST extract contain:\\n\")\n\t\tnecessary_metadata_names = ', '.join(list(necessary_metadata.keys()))\n\t\ttmpl += necessary_metadata_names\n\t\ttmpl += (\"\\n\\nIt is better to extract the following metadata,\"\n\t\t\t\t \"But if a optional metadata does not appear in the paper, you do not need to output it.\\n\")\n\t\toptional_metadata_names = ', '.join(list(optional_metadata.keys()))\n\t\ttmpl += optional_metadata_names\n\t\ttmpl += (\"\\n\\n\"\n\t\t\t\t \"Here are some suggestions for you to extract these metadata:\")\n\t\ttmpl += \"\\n\\nSuggestions for extracting NECESSARY metadata:\\n\"\n\n\t\tfor key in necessary_metadata.keys():\n\t\t\ttmpl += f\"**{key}**: {necessary_metadata[key]}\\n\"\n\n\t\ttmpl += (\"\\n\\n\"\n\t\t\t\t \"Suggestions for extracting optional metadata:\\n\")\n\t\tfor key in optional_metadata.keys():\n\t\t\ttmpl += f\"**{key}**: {optional_metadata[key]}\\n\"\n\t\ttmpl += (\"\\n\\n\"\n\t\t\t\t \"The first page of the paper is as follows:\\n\"\n\t\t\t\t \"{}\")\n\t\ttmpl += (\"\\n\\nOutput your extracted metadata as the following FORMAT:\\n\"\n\t\t\t\t \"**metadata_name**: &lt;extracted corresponding metadata&gt;\\n\\n\"\n\t\t\t\t \"List your extracted metadata as follows:\\n\\n\")\n\n\t\tfor key in necessary_metadata.keys():\n\t\t\ttmpl += f\"**{key}**: \\n\\n\"\n\t\tfor key in optional_metadata.keys():\n\t\t\ttmpl += f\"**{key}**: \\n\\n\"\n\t\treturn tmpl\n\n\tdef _set_query_prompt(\n\t\tself,\n\t\tnecessary_metadata: Dict[str, str] = None,\n\t\toptional_metadata: Dict[str, str] = None,\n\t):\n\t\tr\"\"\" If both `necessary_metadata` and `optional_metadata` are None, set the default prompt. \"\"\"\n\t\tself.query_engine.prompt_tmpl = self.get_prompt_tmpl(necessary_metadata, optional_metadata)\n\n\tdef metadata_output_format(self, llm_answer: str) -&gt; Dict[str, str]:\n\t\tr\"\"\"\n\t\tThe LLM is supposed to answer like this:\n\n\t\t- **metadata_name 1**: extracted metadata 1.\n\t\t- **metadata_name 2**: extracted metadata 2.\n\n\t\tExtract a metadata dictionary from the answer of llm.\n\n\t\tArgs:\n\t\t\tllm_answer (str): The LLM Output.\n\t\t\"\"\"\n\t\tstr_list = llm_answer.split(\"**\")\n\t\tmetadata = dict()\n\n\t\tidx = 0\n\t\t# key: 1 v: 2\n\t\twhile 2 * idx + 2 &lt; len(str_list):\n\t\t\tkey = str_list[2 * idx + 1]\n\t\t\tval = str_list[2 * idx + 2]\n\t\t\tkey = key.replace(\"\\n\", \"\")\n\t\t\tval = val.replace(\"\\n\", \"\")\n\t\t\tif key in self.necessary_metadata.keys() or key in self.optional_metadata.keys():\n\t\t\t\tmetadata[key] = val.replace(\": \", \"\", 1)\n\t\t\tidx += 1\n\t\treturn metadata\n\n\tdef _extract_metadata(\n\t\tself,\n\t\tpdf_path: Union[Path, str] = None,\n\t\tpdf_docs: List[Document] = None,\n\t\tnecessary_metadata: Dict[str, str] = None,\n\t\toptional_metadata: Dict[str, str] = None,\n\t) -&gt; Dict[str, str]:\n\t\tr\"\"\"\n\t\tUse the LLM to extract metadata of a paper.\n\n\t\tArgs:\n\t\t\tpdf_path: (Union[Path, str]): the path of a pdf paper.\n\t\t\tpdf_docs (List[Document]): the documents of a pdf paper.\n\t\t\tnecessary_metadata (Dict[str, str]):\n\t\t\toptional_metadata (optional_metadata):\n\n\t\tReturns:\n\t\t\tmetadata (Dict[str, str]): The extracted meta data.\n\t\t\"\"\"\n\n\t\tif pdf_path is not None:\n\t\t\tpdf_docs = PyMuPDFReader().load_data(file_path=pdf_path)\n\t\telif pdf_docs is None:\n\t\t\traise ValueError(\"pdf_path and pdf_docs can not both be None.\")\n\n\t\tfirst_page = pdf_docs[0].text\n\t\tself._set_query_prompt(necessary_metadata, optional_metadata)\n\t\tresponse = self.query_engine.query(first_page)\n\t\t# reset prompt\n\t\tself._set_query_prompt()\n\t\textract_text = response.response\n\t\tmetadata = self.metadata_output_format(extract_text)\n\t\treturn metadata\n\n\tdef _lacked_metadata(self, paper_metadata: Dict[str, str]) -&gt; Tuple[Dict, Dict]:\n\t\tr\"\"\"\n\t\tReturn current lacked metadata.\n\n\t\tArgs:\n\t\t\tpaper_metadata (Dict[str, str]): Extracted metadata.\n\n\t\tReturns:\n\t\t\tTuple[Dict, Dict]: The lacked necessary metadata and lacked optional metadata\n\t\t\"\"\"\n\t\tlack_necessary_keys = set(self.necessary_metadata.keys()) - set(paper_metadata.keys())\n\t\tlack_optional_keys = set(self.optional_metadata.keys()) - set(paper_metadata.keys())\n\n\t\tlack_necessary_metadata = dict()\n\t\tlack_optional_metadata = dict()\n\t\tfor key in lack_necessary_keys:\n\t\t\tlack_necessary_metadata.update({key: self.necessary_metadata[key]})\n\n\t\tfor key in lack_optional_keys:\n\t\t\tlack_optional_metadata.update({key: self.optional_metadata[key]})\n\n\t\treturn lack_necessary_metadata, lack_optional_metadata\n\n\tdef extract_paper_metadata(\n\t\tself,\n\t\tpdf_path: Union[Path, str] = None,\n\t\tpdf_docs: List[Document] = None,\n\t\tshow_progress: bool = True,\n\t\textra_metadata: dict = None,\n\t) -&gt; Optional[Dict[str, str]]:\n\t\tr\"\"\"\n\t\tExtract required metadata from a paper.\n\t\tTitle and DOI is necessary, we will use the CrossRef API to get the DOI of a paper according to its title.\n\t\tIf any of them misses, this method will return None.\n\n\t\tArgs:\n\t\t\tpdf_path (Union[Path, str]): The file path of the paper.\n\t\t\tpdf_docs (List[Document]): If the pdf_path is not provided, the provided pdf_docs will be used.\n\t\t\t\tpdf_docs and pdf_path can not all be None.\n\t\t\tshow_progress (bool): Whether to show the inner progress.\n\t\t\textra_metadata (dict): Existing metadata obtained by approaches such as arXiv API.\n\n\t\tReturns:\n\t\t\tDict[str, str]: The extracted metadata.\n\t\t\"\"\"\n\t\tif pdf_path:\n\t\t\tpdf_docs = PyMuPDFReader().load_data(file_path=pdf_path)\n\t\telif pdf_docs is None:\n\t\t\traise ValueError(\"pdf_path and pdf_docs can not both be None.\")\n\n\t\tpaper_metadata = extra_metadata or dict()\n\t\tlack_necessary_metadata, _ = self._lacked_metadata(paper_metadata)\n\t\tretry_count = 0\n\t\twhile len(lack_necessary_metadata.keys()) &gt; 0 and retry_count &lt;= self.max_retry_times:\n\t\t\tnew_metadata = self._extract_metadata(\n\t\t\t\tpdf_docs=pdf_docs,\n\t\t\t\tnecessary_metadata=lack_necessary_metadata,\n\t\t\t\toptional_metadata=self.optional_metadata,\n\t\t\t)\n\t\t\tretry_count += 1\n\t\t\tif show_progress:\n\t\t\t\tprint_text(f\"&gt;&gt;&gt;\\tExtract try idx {retry_count}: {list(new_metadata.keys())}\", color=\"cyan\", end=\"\\n\")\n\t\t\tpaper_metadata.update(new_metadata)\n\t\t\tlack_necessary_metadata, _ = self._lacked_metadata(paper_metadata)\n\n\t\ttitle = paper_metadata.get(PAPER_TITLE, None)\n\t\tif title is None:\n\t\t\treturn None\n\n\t\t# find doi according to title\n\t\tdoi = paper_metadata.get(PAPER_DOI, None)\n\t\tif doi is None:\n\t\t\tdoi = self.crossref_worker.find_doi_by_title(title=title)\n\t\tif doi is None:\n\t\t\tprint(\"DOI find fails.\")\n\t\t\treturn None\n\n\t\tpaper_metadata[PAPER_DOI] = doi\n\t\treturn paper_metadata\n</code></pre>"},{"location":"code_docs/func_modules/paper/parse/extractors/metadata_extract/#labridge.func_modules.paper.parse.extractors.metadata_extract.PaperMetadataExtractor.extract_paper_metadata","title":"<code>labridge.func_modules.paper.parse.extractors.metadata_extract.PaperMetadataExtractor.extract_paper_metadata(pdf_path=None, pdf_docs=None, show_progress=True, extra_metadata=None)</code>","text":"<p>Extract required metadata from a paper. Title and DOI is necessary, we will use the CrossRef API to get the DOI of a paper according to its title. If any of them misses, this method will return None.</p> PARAMETER DESCRIPTION <code>pdf_path</code> <p>The file path of the paper.</p> <p> TYPE: <code>Union[Path, str]</code> DEFAULT: <code>None</code> </p> <code>pdf_docs</code> <p>If the pdf_path is not provided, the provided pdf_docs will be used. pdf_docs and pdf_path can not all be None.</p> <p> TYPE: <code>List[Document]</code> DEFAULT: <code>None</code> </p> <code>show_progress</code> <p>Whether to show the inner progress.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>extra_metadata</code> <p>Existing metadata obtained by approaches such as arXiv API.</p> <p> TYPE: <code>dict</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Optional[Dict[str, str]]</code> <p>Dict[str, str]: The extracted metadata.</p> Source code in <code>labridge\\func_modules\\paper\\parse\\extractors\\metadata_extract.py</code> <pre><code>def extract_paper_metadata(\n\tself,\n\tpdf_path: Union[Path, str] = None,\n\tpdf_docs: List[Document] = None,\n\tshow_progress: bool = True,\n\textra_metadata: dict = None,\n) -&gt; Optional[Dict[str, str]]:\n\tr\"\"\"\n\tExtract required metadata from a paper.\n\tTitle and DOI is necessary, we will use the CrossRef API to get the DOI of a paper according to its title.\n\tIf any of them misses, this method will return None.\n\n\tArgs:\n\t\tpdf_path (Union[Path, str]): The file path of the paper.\n\t\tpdf_docs (List[Document]): If the pdf_path is not provided, the provided pdf_docs will be used.\n\t\t\tpdf_docs and pdf_path can not all be None.\n\t\tshow_progress (bool): Whether to show the inner progress.\n\t\textra_metadata (dict): Existing metadata obtained by approaches such as arXiv API.\n\n\tReturns:\n\t\tDict[str, str]: The extracted metadata.\n\t\"\"\"\n\tif pdf_path:\n\t\tpdf_docs = PyMuPDFReader().load_data(file_path=pdf_path)\n\telif pdf_docs is None:\n\t\traise ValueError(\"pdf_path and pdf_docs can not both be None.\")\n\n\tpaper_metadata = extra_metadata or dict()\n\tlack_necessary_metadata, _ = self._lacked_metadata(paper_metadata)\n\tretry_count = 0\n\twhile len(lack_necessary_metadata.keys()) &gt; 0 and retry_count &lt;= self.max_retry_times:\n\t\tnew_metadata = self._extract_metadata(\n\t\t\tpdf_docs=pdf_docs,\n\t\t\tnecessary_metadata=lack_necessary_metadata,\n\t\t\toptional_metadata=self.optional_metadata,\n\t\t)\n\t\tretry_count += 1\n\t\tif show_progress:\n\t\t\tprint_text(f\"&gt;&gt;&gt;\\tExtract try idx {retry_count}: {list(new_metadata.keys())}\", color=\"cyan\", end=\"\\n\")\n\t\tpaper_metadata.update(new_metadata)\n\t\tlack_necessary_metadata, _ = self._lacked_metadata(paper_metadata)\n\n\ttitle = paper_metadata.get(PAPER_TITLE, None)\n\tif title is None:\n\t\treturn None\n\n\t# find doi according to title\n\tdoi = paper_metadata.get(PAPER_DOI, None)\n\tif doi is None:\n\t\tdoi = self.crossref_worker.find_doi_by_title(title=title)\n\tif doi is None:\n\t\tprint(\"DOI find fails.\")\n\t\treturn None\n\n\tpaper_metadata[PAPER_DOI] = doi\n\treturn paper_metadata\n</code></pre>"},{"location":"code_docs/func_modules/paper/parse/extractors/metadata_extract/#labridge.func_modules.paper.parse.extractors.metadata_extract.PaperMetadataExtractor.get_prompt_tmpl","title":"<code>labridge.func_modules.paper.parse.extractors.metadata_extract.PaperMetadataExtractor.get_prompt_tmpl(necessary_metadata=None, optional_metadata=None)</code>","text":"<p>This function is used to get the prompt template used for extracting metadata, according to the <code>necessary_metadata</code> and <code>optional_metadata</code>.</p> PARAMETER DESCRIPTION <code>necessary_metadata</code> <p>necessary metadata, Defaults to <code>self.necessary_metadata</code>.</p> <p> TYPE: <code>Dict[str, str]</code> DEFAULT: <code>None</code> </p> <code>optional_metadata</code> <p>optional metadata, Defaults to <code>self.optional_metadata</code>.</p> <p> TYPE: <code>Dict[str, str]</code> DEFAULT: <code>None</code> </p> Source code in <code>labridge\\func_modules\\paper\\parse\\extractors\\metadata_extract.py</code> <pre><code>def get_prompt_tmpl(\n\tself,\n\tnecessary_metadata: Dict[str, str] = None,\n\toptional_metadata: Dict[str, str] = None,\n) -&gt; str:\n\tr\"\"\"\n\tThis function is used to get the prompt template used for extracting metadata, according to the\n\t`necessary_metadata` and `optional_metadata`.\n\n\tArgs:\n\t\tnecessary_metadata (Dict[str, str]): necessary metadata, Defaults to `self.necessary_metadata`.\n\t\toptional_metadata (Dict[str, str]): optional metadata, Defaults to `self.optional_metadata`.\n\t\"\"\"\n\tnecessary_metadata = necessary_metadata or self.necessary_metadata\n\toptional_metadata = optional_metadata or self.optional_metadata\n\n\ttmpl = (\"Here is the first page of a research paper. \"\n\t\t\t\"You need try to extract some information from it.\\n\\n\"\n\t\t\t\"The NECESSARY metadata that you MUST extract contain:\\n\")\n\tnecessary_metadata_names = ', '.join(list(necessary_metadata.keys()))\n\ttmpl += necessary_metadata_names\n\ttmpl += (\"\\n\\nIt is better to extract the following metadata,\"\n\t\t\t \"But if a optional metadata does not appear in the paper, you do not need to output it.\\n\")\n\toptional_metadata_names = ', '.join(list(optional_metadata.keys()))\n\ttmpl += optional_metadata_names\n\ttmpl += (\"\\n\\n\"\n\t\t\t \"Here are some suggestions for you to extract these metadata:\")\n\ttmpl += \"\\n\\nSuggestions for extracting NECESSARY metadata:\\n\"\n\n\tfor key in necessary_metadata.keys():\n\t\ttmpl += f\"**{key}**: {necessary_metadata[key]}\\n\"\n\n\ttmpl += (\"\\n\\n\"\n\t\t\t \"Suggestions for extracting optional metadata:\\n\")\n\tfor key in optional_metadata.keys():\n\t\ttmpl += f\"**{key}**: {optional_metadata[key]}\\n\"\n\ttmpl += (\"\\n\\n\"\n\t\t\t \"The first page of the paper is as follows:\\n\"\n\t\t\t \"{}\")\n\ttmpl += (\"\\n\\nOutput your extracted metadata as the following FORMAT:\\n\"\n\t\t\t \"**metadata_name**: &lt;extracted corresponding metadata&gt;\\n\\n\"\n\t\t\t \"List your extracted metadata as follows:\\n\\n\")\n\n\tfor key in necessary_metadata.keys():\n\t\ttmpl += f\"**{key}**: \\n\\n\"\n\tfor key in optional_metadata.keys():\n\t\ttmpl += f\"**{key}**: \\n\\n\"\n\treturn tmpl\n</code></pre>"},{"location":"code_docs/func_modules/paper/parse/extractors/metadata_extract/#labridge.func_modules.paper.parse.extractors.metadata_extract.PaperMetadataExtractor.metadata_output_format","title":"<code>labridge.func_modules.paper.parse.extractors.metadata_extract.PaperMetadataExtractor.metadata_output_format(llm_answer)</code>","text":"<p>The LLM is supposed to answer like this:</p> <ul> <li>metadata_name 1: extracted metadata 1.</li> <li>metadata_name 2: extracted metadata 2.</li> </ul> <p>Extract a metadata dictionary from the answer of llm.</p> PARAMETER DESCRIPTION <code>llm_answer</code> <p>The LLM Output.</p> <p> TYPE: <code>str</code> </p> Source code in <code>labridge\\func_modules\\paper\\parse\\extractors\\metadata_extract.py</code> <pre><code>def metadata_output_format(self, llm_answer: str) -&gt; Dict[str, str]:\n\tr\"\"\"\n\tThe LLM is supposed to answer like this:\n\n\t- **metadata_name 1**: extracted metadata 1.\n\t- **metadata_name 2**: extracted metadata 2.\n\n\tExtract a metadata dictionary from the answer of llm.\n\n\tArgs:\n\t\tllm_answer (str): The LLM Output.\n\t\"\"\"\n\tstr_list = llm_answer.split(\"**\")\n\tmetadata = dict()\n\n\tidx = 0\n\t# key: 1 v: 2\n\twhile 2 * idx + 2 &lt; len(str_list):\n\t\tkey = str_list[2 * idx + 1]\n\t\tval = str_list[2 * idx + 2]\n\t\tkey = key.replace(\"\\n\", \"\")\n\t\tval = val.replace(\"\\n\", \"\")\n\t\tif key in self.necessary_metadata.keys() or key in self.optional_metadata.keys():\n\t\t\tmetadata[key] = val.replace(\": \", \"\", 1)\n\t\tidx += 1\n\treturn metadata\n</code></pre>"},{"location":"code_docs/func_modules/paper/parse/extractors/source_analyze/","title":"Source analyze","text":""},{"location":"code_docs/func_modules/paper/parse/extractors/source_analyze/#labridge.func_modules.paper.parse.extractors.source_analyze","title":"<code>labridge.func_modules.paper.parse.extractors.source_analyze</code>","text":""},{"location":"code_docs/func_modules/paper/parse/extractors/source_analyze/#labridge.func_modules.paper.parse.extractors.source_analyze.PaperSourceAnalyzer","title":"<code>labridge.func_modules.paper.parse.extractors.source_analyze.PaperSourceAnalyzer</code>","text":"<p>This class analyze the source of the paper, such as 'Nature', 'IEEE'.</p> <p>In default, the source analysis bases on keyword occurrence count. Also, LLM can be used to help analyzing the source.</p> PARAMETER DESCRIPTION <code>llm</code> <p>The used LLM.</p> <p> TYPE: <code>LLM</code> DEFAULT: <code>None</code> </p> <code>service_context</code> <p>The service context.</p> <p> TYPE: <code>ServiceContext</code> DEFAULT: <code>None</code> </p> <code>keyword_count_threshold</code> <p>A PaperSource is selected as a candidate only if its corresponding keyword occurrence count exceed this threshold.</p> <p> TYPE: <code>int</code> DEFAULT: <code>10</code> </p> Source code in <code>labridge\\func_modules\\paper\\parse\\extractors\\source_analyze.py</code> <pre><code>class PaperSourceAnalyzer:\n\tr\"\"\"\n\tThis class analyze the source of the paper, such as 'Nature', 'IEEE'.\n\n\tIn default, the source analysis bases on keyword occurrence count.\n\tAlso, LLM can be used to help analyzing the source.\n\n\tArgs:\n\t\tllm (LLM): The used LLM.\n\t\tservice_context (ServiceContext): The service context.\n\t\tkeyword_count_threshold (int): A PaperSource is selected as a candidate\n\t\t\tonly if its corresponding keyword occurrence count exceed this threshold.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tllm: LLM = None,\n\t\tservice_context: ServiceContext = None,\n\t\tkeyword_count_threshold: int = 10,\n\t):\n\t\tself.llm = llm or llm_from_settings_or_context(Settings, service_context)\n\t\tself.keyword_count_threshold = keyword_count_threshold\n\n\tdef reader_analyze(self, paper_path: Union[Path, str]) -&gt; PaperSource:\n\t\t\"\"\"\n\t\tAnalyze the paper source using a structured pdf reader.\n\n\t\tArgs:\n\t\t\tpaper_path (Union[Path, str]): The paper path.\n\n\t\tReturns:\n\t\t\tPaperSource: The paper source.\n\t\t\"\"\"\n\t\timport PyPDF2\n\n\t\twith open(paper_path, 'rb') as file:\n\t\t\tfileReader = PyPDF2.PdfReader(file)\n\t\t\tfile_info = fileReader.trailer['/Info']\n\n\t\tsource = None\n\t\tif '/Subject' in file_info.keys():\n\t\t\tsrc_string = file_info['/Subject']\n\t\t\tif len(src_string) &gt;= len(PaperSource.NATURE):\n\t\t\t\tsource = PaperSource.IEEE\n\t\t\t\tfor start in range(len(src_string) - len(PaperSource.NATURE) + 1):\n\t\t\t\t\tif src_string[start: start + len(PaperSource.NATURE)].upper() == PaperSource.NATURE.upper():\n\t\t\t\t\t\tsource = PaperSource.NATURE\n\t\treturn source\n\n\tdef llm_analyze(self, paper_path: Union[Path, str]) -&gt; PaperSource:\n\t\t\"\"\" TODO: using llm. \"\"\"\n\t\treturn PaperSource.DEFAULT\n\n\tdef keyword_analyze(self, paper_path: Union[Path, str]) -&gt; PaperSource:\n\t\tr\"\"\"\n\t\tAnalyze the paper source based on keyword occurrence count.\n\n\t\tArgs:\n\t\t\tpaper_path (Union[Path, str]): The paper path.\n\n\t\tReturns:\n\t\t\tPaperSource: The analyzed paper source.\n\t\t\"\"\"\n\t\timport pymupdf\n\t\timport re\n\n\t\tdoc = pymupdf.open(paper_path)\n\t\tpages = [page.get_text() for page in doc]\n\n\t\t\"\"\" Searching in the text.\"\"\"\n\t\tsource = None\n\t\tcount = 0\n\t\tfor page_text in pages:\n\t\t\tfor t in re.findall(r\"\\w+\", page_text):\n\t\t\t\tif t.strip().upper() == PaperSource.NATURE.upper():\n\t\t\t\t\tcount += 1\n\t\tif count &gt; self.keyword_count_threshold:\n\t\t\tsource = PaperSource.NATURE\n\t\telse:\n\t\t\tsource = PaperSource.IEEE\n\t\treturn source\n\n\tdef analyze_source(self, paper_path: Union[Path, str], use_llm = False) -&gt; PaperSource:\n\t\tr\"\"\"\n\t\tSequentially use `reader_analyze`, `keyword_analyze`, and `llm_analyze` to analyze the paper source\n\n\t\tArgs:\n\t\t\tpaper_path (Union[Path, str]): The paper path.\n\t\t\tuse_llm (bool): Whether to use `llm_analyze`.\n\n\t\tReturns:\n\t\t\tPaperSource\n\t\t\"\"\"\n\t\tsource = self.reader_analyze(paper_path)\n\t\tif source is None:\n\t\t\tsource = self.keyword_analyze(paper_path)\n\t\tif source is None and use_llm:\n\t\t\tsource = self.llm_analyze(paper_path)\n\t\tif source is None:\n\t\t\tsource = PaperSource.DEFAULT\n\t\treturn source\n</code></pre>"},{"location":"code_docs/func_modules/paper/parse/extractors/source_analyze/#labridge.func_modules.paper.parse.extractors.source_analyze.PaperSourceAnalyzer.analyze_source","title":"<code>labridge.func_modules.paper.parse.extractors.source_analyze.PaperSourceAnalyzer.analyze_source(paper_path, use_llm=False)</code>","text":"<p>Sequentially use <code>reader_analyze</code>, <code>keyword_analyze</code>, and <code>llm_analyze</code> to analyze the paper source</p> PARAMETER DESCRIPTION <code>paper_path</code> <p>The paper path.</p> <p> TYPE: <code>Union[Path, str]</code> </p> <code>use_llm</code> <p>Whether to use <code>llm_analyze</code>.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>PaperSource</code> <p>PaperSource</p> Source code in <code>labridge\\func_modules\\paper\\parse\\extractors\\source_analyze.py</code> <pre><code>def analyze_source(self, paper_path: Union[Path, str], use_llm = False) -&gt; PaperSource:\n\tr\"\"\"\n\tSequentially use `reader_analyze`, `keyword_analyze`, and `llm_analyze` to analyze the paper source\n\n\tArgs:\n\t\tpaper_path (Union[Path, str]): The paper path.\n\t\tuse_llm (bool): Whether to use `llm_analyze`.\n\n\tReturns:\n\t\tPaperSource\n\t\"\"\"\n\tsource = self.reader_analyze(paper_path)\n\tif source is None:\n\t\tsource = self.keyword_analyze(paper_path)\n\tif source is None and use_llm:\n\t\tsource = self.llm_analyze(paper_path)\n\tif source is None:\n\t\tsource = PaperSource.DEFAULT\n\treturn source\n</code></pre>"},{"location":"code_docs/func_modules/paper/parse/extractors/source_analyze/#labridge.func_modules.paper.parse.extractors.source_analyze.PaperSourceAnalyzer.keyword_analyze","title":"<code>labridge.func_modules.paper.parse.extractors.source_analyze.PaperSourceAnalyzer.keyword_analyze(paper_path)</code>","text":"<p>Analyze the paper source based on keyword occurrence count.</p> PARAMETER DESCRIPTION <code>paper_path</code> <p>The paper path.</p> <p> TYPE: <code>Union[Path, str]</code> </p> RETURNS DESCRIPTION <code>PaperSource</code> <p>The analyzed paper source.</p> <p> TYPE: <code>PaperSource</code> </p> Source code in <code>labridge\\func_modules\\paper\\parse\\extractors\\source_analyze.py</code> <pre><code>def keyword_analyze(self, paper_path: Union[Path, str]) -&gt; PaperSource:\n\tr\"\"\"\n\tAnalyze the paper source based on keyword occurrence count.\n\n\tArgs:\n\t\tpaper_path (Union[Path, str]): The paper path.\n\n\tReturns:\n\t\tPaperSource: The analyzed paper source.\n\t\"\"\"\n\timport pymupdf\n\timport re\n\n\tdoc = pymupdf.open(paper_path)\n\tpages = [page.get_text() for page in doc]\n\n\t\"\"\" Searching in the text.\"\"\"\n\tsource = None\n\tcount = 0\n\tfor page_text in pages:\n\t\tfor t in re.findall(r\"\\w+\", page_text):\n\t\t\tif t.strip().upper() == PaperSource.NATURE.upper():\n\t\t\t\tcount += 1\n\tif count &gt; self.keyword_count_threshold:\n\t\tsource = PaperSource.NATURE\n\telse:\n\t\tsource = PaperSource.IEEE\n\treturn source\n</code></pre>"},{"location":"code_docs/func_modules/paper/parse/extractors/source_analyze/#labridge.func_modules.paper.parse.extractors.source_analyze.PaperSourceAnalyzer.llm_analyze","title":"<code>labridge.func_modules.paper.parse.extractors.source_analyze.PaperSourceAnalyzer.llm_analyze(paper_path)</code>","text":"Source code in <code>labridge\\func_modules\\paper\\parse\\extractors\\source_analyze.py</code> <pre><code>def llm_analyze(self, paper_path: Union[Path, str]) -&gt; PaperSource:\n\t\"\"\" TODO: using llm. \"\"\"\n\treturn PaperSource.DEFAULT\n</code></pre>"},{"location":"code_docs/func_modules/paper/parse/extractors/source_analyze/#labridge.func_modules.paper.parse.extractors.source_analyze.PaperSourceAnalyzer.reader_analyze","title":"<code>labridge.func_modules.paper.parse.extractors.source_analyze.PaperSourceAnalyzer.reader_analyze(paper_path)</code>","text":"<p>Analyze the paper source using a structured pdf reader.</p> PARAMETER DESCRIPTION <code>paper_path</code> <p>The paper path.</p> <p> TYPE: <code>Union[Path, str]</code> </p> RETURNS DESCRIPTION <code>PaperSource</code> <p>The paper source.</p> <p> TYPE: <code>PaperSource</code> </p> Source code in <code>labridge\\func_modules\\paper\\parse\\extractors\\source_analyze.py</code> <pre><code>def reader_analyze(self, paper_path: Union[Path, str]) -&gt; PaperSource:\n\t\"\"\"\n\tAnalyze the paper source using a structured pdf reader.\n\n\tArgs:\n\t\tpaper_path (Union[Path, str]): The paper path.\n\n\tReturns:\n\t\tPaperSource: The paper source.\n\t\"\"\"\n\timport PyPDF2\n\n\twith open(paper_path, 'rb') as file:\n\t\tfileReader = PyPDF2.PdfReader(file)\n\t\tfile_info = fileReader.trailer['/Info']\n\n\tsource = None\n\tif '/Subject' in file_info.keys():\n\t\tsrc_string = file_info['/Subject']\n\t\tif len(src_string) &gt;= len(PaperSource.NATURE):\n\t\t\tsource = PaperSource.IEEE\n\t\t\tfor start in range(len(src_string) - len(PaperSource.NATURE) + 1):\n\t\t\t\tif src_string[start: start + len(PaperSource.NATURE)].upper() == PaperSource.NATURE.upper():\n\t\t\t\t\tsource = PaperSource.NATURE\n\treturn source\n</code></pre>"},{"location":"code_docs/func_modules/paper/parse/parsers/auto/","title":"Auto","text":""},{"location":"code_docs/func_modules/paper/parse/parsers/auto/#labridge.func_modules.paper.parse.parsers.auto","title":"<code>labridge.func_modules.paper.parse.parsers.auto</code>","text":""},{"location":"code_docs/func_modules/paper/parse/parsers/auto/#labridge.func_modules.paper.parse.parsers.auto.auto_parse_paper","title":"<code>labridge.func_modules.paper.parse.parsers.auto.auto_parse_paper(file_path, source_analyzer, use_llm_for_source)</code>","text":"<p>Automatically parse a paper according to the analyzed paper source.</p> PARAMETER DESCRIPTION <code>file_path</code> <p>The paper path.</p> <p> TYPE: <code>Union[str, Path]</code> </p> <code>source_analyzer</code> <p>The analyzer that analyze the paper source.</p> <p> TYPE: <code>PaperSourceAnalyzer</code> </p> <code>use_llm_for_source</code> <p>Whether to use LLM in the source_analyzer.</p> <p> TYPE: <code>bool</code> </p> RETURNS DESCRIPTION <code>List[Document]</code> <p>List[Document]: The parsed paper documents. For example: A paper from Nature will be seperated into these components: <code>ABSTRACT</code>, <code>MAINTEXT</code>, <code>REFERENCES</code>, <code>METHODS</code>.</p> Source code in <code>labridge\\func_modules\\paper\\parse\\parsers\\auto.py</code> <pre><code>def auto_parse_paper(\n\tfile_path: Union[str, Path],\n\tsource_analyzer: PaperSourceAnalyzer,\n\tuse_llm_for_source: bool,\n) -&gt; List[Document]:\n\tr\"\"\"\n\tAutomatically parse a paper according to the analyzed paper source.\n\n\tArgs:\n\t\tfile_path (Union[str, Path]): The paper path.\n\t\tsource_analyzer (PaperSourceAnalyzer): The analyzer that analyze the paper source.\n\t\tuse_llm_for_source (bool): Whether to use LLM in the source_analyzer.\n\n\tReturns:\n\t\tList[Document]: The parsed paper documents.\n\t\t\tFor example: A paper from Nature will be seperated into these components:\n\t\t\t`ABSTRACT`, `MAINTEXT`, `REFERENCES`, `METHODS`.\n\t\"\"\"\n\tpaper_source = source_analyzer.analyze_source(file_path, use_llm_for_source)\n\n\tif paper_source == PaperSource.NATURE:\n\t\tparser = NaturePaperParser()\n\telif paper_source == PaperSource.IEEE:\n\t\tparser = IEEEPaperParser()\n\telif paper_source == PaperSource.DEFAULT:\n\t\tparser = DefaultPaperParser()\n\telse:\n\t\traise ValueError(\"Invalid paper source.\")\n\n\tdocs = parser.parse_paper(file_path=file_path)\n\treturn docs\n</code></pre>"},{"location":"code_docs/func_modules/paper/parse/parsers/base/","title":"Base","text":""},{"location":"code_docs/func_modules/paper/parse/parsers/base/#labridge.func_modules.paper.parse.parsers.base","title":"<code>labridge.func_modules.paper.parse.parsers.base</code>","text":""},{"location":"code_docs/func_modules/paper/parse/parsers/base/#labridge.func_modules.paper.parse.parsers.base.BasePaperParser","title":"<code>labridge.func_modules.paper.parse.parsers.base.BasePaperParser</code>","text":"<p>This is the base paper parser. The Parser separates a paper into subcomponents according to several separators.</p> PARAMETER DESCRIPTION <code>separators</code> <p>Each tuple includes the separators that separate two components.</p> <p> TYPE: <code>List[Tuple[str]]</code> </p> <code>content_names</code> <p> TYPE: <code>Dict[int, Tuple[str]</code> </p> <code>separator_tolerance</code> <p>The tolerance of mismatch chars.</p> <p> TYPE: <code>int</code> DEFAULT: <code>3</code> </p> Source code in <code>labridge\\func_modules\\paper\\parse\\parsers\\base.py</code> <pre><code>class BasePaperParser:\n\tr\"\"\"\n\tThis is the base paper parser.\n\tThe Parser separates a paper into subcomponents according to several separators.\n\n\tArgs:\n\t\tseparators (List[Tuple[str]]): Each tuple includes the separators that separate two components.\n\t\tcontent_names (Dict[int, Tuple[str]): Key: component index; Value: component name candidates.\n\t\tseparator_tolerance (int): The tolerance of mismatch chars.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tseparators: List[Tuple[str]],\n\t\tcontent_names: Dict[int, Tuple[str]],\n\t\tseparator_tolerance: int = 3\n\t):\n\t\tself.separators = separators\n\t\tself.content_names = content_names\n\t\tself.separator_tolerance = separator_tolerance\n\n\t@abstractmethod\n\tdef parse_title(self, file_path: Union[str, Path]) -&gt; str:\n\t\t...\n\n\tdef to_documents(\n\t\tself,\n\t\tparsed_components: List[str],\n\t\textra_info: Dict[str, str],\n\t) -&gt; List[Document]:\n\t\tr\"\"\"\n\t\tTransform the parsed components to Documents.\n\n\t\tArgs:\n\t\t\tparsed_components (List[str]): The separated component strings.\n\t\t\textra_info (Dict[str, str]): The extra information will be recorded in the Document's metadata.\n\n\t\tReturns:\n\t\t\tList[Document]: The parsed Documents.\n\t\t\"\"\"\n\t\tcomponent_names = self.content_names[len(parsed_components)]\n\t\tdocuments = []\n\n\t\t# merge texts with the same name.\n\t\tmerged_component_names = []\n\t\tmerged_components = []\n\t\tfor idx, name in enumerate(component_names):\n\t\t\tif name not in merged_component_names:\n\t\t\t\tmerged_component_names.append(name)\n\t\t\t\tmerged_components.append(parsed_components[idx])\n\t\t\telse:\n\t\t\t\tname_idx = merged_component_names.index(name)\n\t\t\t\tmerged_components[name_idx] += parsed_components[idx]\n\n\t\tfor idx, component in enumerate(merged_components):\n\t\t\tdoc_info = {CONTENT_TYPE_NAME: merged_component_names[idx]}\n\t\t\tdoc_info.update(extra_info)\n\t\t\tdoc = Document(text=merged_components[idx], extra_info=doc_info)\n\t\t\tdocuments.append(doc)\n\t\treturn documents\n\n\tdef parse_paper(self, file_path: Union[str, Path]) -&gt; List[Document]:\n\t\tr\"\"\"\n\t\tSplit the article into main text, methods, extra info (references, extended data.) according to specific separators.\n\t\tFor example, separators for Nature are:\n\n\t\tExample:\n\t\t\t```python\n\t\t\t&gt;&gt;&gt; [\n\t\t\t... \t(\"Online content\", ),\n\t\t\t... \t(\"Methods\", ),\n\t\t\t... \t(\"Data availability\", \"Code availability\", \"References\")\n\t\t\t... ]\n\t\t\t```\n\n\t\tArgs:\n\t\t\tfile_path (Union[str, Path]): The paper path.\n\n\t\tReturns:\n\t\t\tTuple[List, Optional[str]]:\n\n\t\t\t\t- The separated paper text (List[str]): For example: [Main text, References 1, Methods, References 2]\n\t\t\t\t- The title (Optional[str]): Might be None if PyMuPDF failed to extract the doc toc. In that case you may\n\t\t\t\tneed to search for LLM's help to extract it.\n\t\t\"\"\"\n\t\tif not isinstance(file_path, str) and not isinstance(file_path, Path):\n\t\t\traise TypeError(\"file_path must be a string or Path.\")\n\n\t\tseparators = self.separators\n\t\tdoc = pymupdf.open(file_path)\n\t\tpages = [page.get_textpage() for page in doc]\n\n\t\ttext_blocks = []\n\t\tsep_p = 0\n\t\tcomponents = []\n\t\ttext_in_block = 4\n\t\tfor idx, text_page in enumerate(pages):\n\t\t\tpage_blocks = text_page.extractBLOCKS()\n\t\t\tif idx == 0:\n\t\t\t\tpage_blocks.pop(0)\n\t\t\tfor each_block in page_blocks:\n\t\t\t\tsep_idx = get_sep_idx(each_block[text_in_block], separators, self.separator_tolerance)\n\t\t\t\tif sep_p &lt; len(separators) and sep_idx &gt;= sep_p:\n\t\t\t\t\ttext_list = [block[text_in_block] for block in text_blocks]\n\t\t\t\t\ttext = ''.join(text_list)\n\t\t\t\t\tcomponents.append(text)\n\t\t\t\t\tsep_p = sep_idx + 1\n\t\t\t\t\ttext_blocks = []\n\t\t\t\ttext_blocks.append(each_block)\n\t\telse:\n\t\t\ttext_list = [block[text_in_block] for block in text_blocks]\n\t\t\ttext = ''.join(text_list)\n\t\t\tcomponents.append(text)\n\n\t\textra_info = {\n\t\t\t\"total_pages\": len(doc),\n\t\t\t\"file_path\": str(file_path)\n\t\t}\n\n\t\tdocuments = self.to_documents(parsed_components=components, extra_info=extra_info)\n\t\treturn documents\n</code></pre>"},{"location":"code_docs/func_modules/paper/parse/parsers/base/#labridge.func_modules.paper.parse.parsers.base.BasePaperParser.parse_paper","title":"<code>labridge.func_modules.paper.parse.parsers.base.BasePaperParser.parse_paper(file_path)</code>","text":"<p>Split the article into main text, methods, extra info (references, extended data.) according to specific separators. For example, separators for Nature are:</p> Example <pre><code>&gt;&gt;&gt; [\n...     (\"Online content\", ),\n...     (\"Methods\", ),\n...     (\"Data availability\", \"Code availability\", \"References\")\n... ]\n</code></pre> PARAMETER DESCRIPTION <code>file_path</code> <p>The paper path.</p> <p> TYPE: <code>Union[str, Path]</code> </p> RETURNS DESCRIPTION <code>List[Document]</code> <p>Tuple[List, Optional[str]]:</p> <ul> <li>The separated paper text (List[str]): For example: [Main text, References 1, Methods, References 2]</li> <li>The title (Optional[str]): Might be None if PyMuPDF failed to extract the doc toc. In that case you may need to search for LLM's help to extract it.</li> </ul> Source code in <code>labridge\\func_modules\\paper\\parse\\parsers\\base.py</code> <pre><code>def parse_paper(self, file_path: Union[str, Path]) -&gt; List[Document]:\n\tr\"\"\"\n\tSplit the article into main text, methods, extra info (references, extended data.) according to specific separators.\n\tFor example, separators for Nature are:\n\n\tExample:\n\t\t```python\n\t\t&gt;&gt;&gt; [\n\t\t... \t(\"Online content\", ),\n\t\t... \t(\"Methods\", ),\n\t\t... \t(\"Data availability\", \"Code availability\", \"References\")\n\t\t... ]\n\t\t```\n\n\tArgs:\n\t\tfile_path (Union[str, Path]): The paper path.\n\n\tReturns:\n\t\tTuple[List, Optional[str]]:\n\n\t\t\t- The separated paper text (List[str]): For example: [Main text, References 1, Methods, References 2]\n\t\t\t- The title (Optional[str]): Might be None if PyMuPDF failed to extract the doc toc. In that case you may\n\t\t\tneed to search for LLM's help to extract it.\n\t\"\"\"\n\tif not isinstance(file_path, str) and not isinstance(file_path, Path):\n\t\traise TypeError(\"file_path must be a string or Path.\")\n\n\tseparators = self.separators\n\tdoc = pymupdf.open(file_path)\n\tpages = [page.get_textpage() for page in doc]\n\n\ttext_blocks = []\n\tsep_p = 0\n\tcomponents = []\n\ttext_in_block = 4\n\tfor idx, text_page in enumerate(pages):\n\t\tpage_blocks = text_page.extractBLOCKS()\n\t\tif idx == 0:\n\t\t\tpage_blocks.pop(0)\n\t\tfor each_block in page_blocks:\n\t\t\tsep_idx = get_sep_idx(each_block[text_in_block], separators, self.separator_tolerance)\n\t\t\tif sep_p &lt; len(separators) and sep_idx &gt;= sep_p:\n\t\t\t\ttext_list = [block[text_in_block] for block in text_blocks]\n\t\t\t\ttext = ''.join(text_list)\n\t\t\t\tcomponents.append(text)\n\t\t\t\tsep_p = sep_idx + 1\n\t\t\t\ttext_blocks = []\n\t\t\ttext_blocks.append(each_block)\n\telse:\n\t\ttext_list = [block[text_in_block] for block in text_blocks]\n\t\ttext = ''.join(text_list)\n\t\tcomponents.append(text)\n\n\textra_info = {\n\t\t\"total_pages\": len(doc),\n\t\t\"file_path\": str(file_path)\n\t}\n\n\tdocuments = self.to_documents(parsed_components=components, extra_info=extra_info)\n\treturn documents\n</code></pre>"},{"location":"code_docs/func_modules/paper/parse/parsers/base/#labridge.func_modules.paper.parse.parsers.base.BasePaperParser.to_documents","title":"<code>labridge.func_modules.paper.parse.parsers.base.BasePaperParser.to_documents(parsed_components, extra_info)</code>","text":"<p>Transform the parsed components to Documents.</p> PARAMETER DESCRIPTION <code>parsed_components</code> <p>The separated component strings.</p> <p> TYPE: <code>List[str]</code> </p> <code>extra_info</code> <p>The extra information will be recorded in the Document's metadata.</p> <p> TYPE: <code>Dict[str, str]</code> </p> RETURNS DESCRIPTION <code>List[Document]</code> <p>List[Document]: The parsed Documents.</p> Source code in <code>labridge\\func_modules\\paper\\parse\\parsers\\base.py</code> <pre><code>def to_documents(\n\tself,\n\tparsed_components: List[str],\n\textra_info: Dict[str, str],\n) -&gt; List[Document]:\n\tr\"\"\"\n\tTransform the parsed components to Documents.\n\n\tArgs:\n\t\tparsed_components (List[str]): The separated component strings.\n\t\textra_info (Dict[str, str]): The extra information will be recorded in the Document's metadata.\n\n\tReturns:\n\t\tList[Document]: The parsed Documents.\n\t\"\"\"\n\tcomponent_names = self.content_names[len(parsed_components)]\n\tdocuments = []\n\n\t# merge texts with the same name.\n\tmerged_component_names = []\n\tmerged_components = []\n\tfor idx, name in enumerate(component_names):\n\t\tif name not in merged_component_names:\n\t\t\tmerged_component_names.append(name)\n\t\t\tmerged_components.append(parsed_components[idx])\n\t\telse:\n\t\t\tname_idx = merged_component_names.index(name)\n\t\t\tmerged_components[name_idx] += parsed_components[idx]\n\n\tfor idx, component in enumerate(merged_components):\n\t\tdoc_info = {CONTENT_TYPE_NAME: merged_component_names[idx]}\n\t\tdoc_info.update(extra_info)\n\t\tdoc = Document(text=merged_components[idx], extra_info=doc_info)\n\t\tdocuments.append(doc)\n\treturn documents\n</code></pre>"},{"location":"code_docs/func_modules/paper/parse/parsers/default_parser/","title":"Default parser","text":""},{"location":"code_docs/func_modules/paper/parse/parsers/default_parser/#labridge.func_modules.paper.parse.parsers.default_parser","title":"<code>labridge.func_modules.paper.parse.parsers.default_parser</code>","text":""},{"location":"code_docs/func_modules/paper/parse/parsers/default_parser/#labridge.func_modules.paper.parse.parsers.default_parser.DefaultPaperParser","title":"<code>labridge.func_modules.paper.parse.parsers.default_parser.DefaultPaperParser</code>","text":"<p>The default paper parser will mark the whole paper content as 'MAINTEXT'</p> Source code in <code>labridge\\func_modules\\paper\\parse\\parsers\\default_parser.py</code> <pre><code>class DefaultPaperParser:\n\tr\"\"\"\n\tThe default paper parser will mark the whole paper content as 'MAINTEXT'\n\t\"\"\"\n\tdef parse_paper(self, file_path: Union[str, Path]) -&gt; List[Document]:\n\t\tr\"\"\"\n\t\tParse the paper.\n\n\t\tArgs:\n\t\t\tfile_path (Union[str, Path]):\n\n\t\tReturns:\n\t\t\tList[Document]: The parsed documents.\n\t\t\"\"\"\n\t\tdoc = pymupdf.open(file_path)\n\t\tpages = [page.get_text().encode(\"utf-8\") for page in doc]\n\t\tpaper_text = ''.join([text for text in pages])\n\n\t\textra_info = {\n\t\t\t\"total_pages\": len(doc),\n\t\t\tCONTENT_TYPE_NAME: \"MainText\"\n\t\t}\n\t\tdoc = Document(text=paper_text, extra_info=extra_info)\n\t\treturn [doc,]\n</code></pre>"},{"location":"code_docs/func_modules/paper/parse/parsers/default_parser/#labridge.func_modules.paper.parse.parsers.default_parser.DefaultPaperParser.parse_paper","title":"<code>labridge.func_modules.paper.parse.parsers.default_parser.DefaultPaperParser.parse_paper(file_path)</code>","text":"<p>Parse the paper.</p> PARAMETER DESCRIPTION <code>file_path</code> <p> TYPE: <code>Union[str, Path]</code> </p> RETURNS DESCRIPTION <code>List[Document]</code> <p>List[Document]: The parsed documents.</p> Source code in <code>labridge\\func_modules\\paper\\parse\\parsers\\default_parser.py</code> <pre><code>def parse_paper(self, file_path: Union[str, Path]) -&gt; List[Document]:\n\tr\"\"\"\n\tParse the paper.\n\n\tArgs:\n\t\tfile_path (Union[str, Path]):\n\n\tReturns:\n\t\tList[Document]: The parsed documents.\n\t\"\"\"\n\tdoc = pymupdf.open(file_path)\n\tpages = [page.get_text().encode(\"utf-8\") for page in doc]\n\tpaper_text = ''.join([text for text in pages])\n\n\textra_info = {\n\t\t\"total_pages\": len(doc),\n\t\tCONTENT_TYPE_NAME: \"MainText\"\n\t}\n\tdoc = Document(text=paper_text, extra_info=extra_info)\n\treturn [doc,]\n</code></pre>"},{"location":"code_docs/func_modules/paper/parse/parsers/ieee_parser/","title":"Ieee parser","text":""},{"location":"code_docs/func_modules/paper/parse/parsers/ieee_parser/#labridge.func_modules.paper.parse.parsers.ieee_parser","title":"<code>labridge.func_modules.paper.parse.parsers.ieee_parser</code>","text":""},{"location":"code_docs/func_modules/paper/parse/parsers/ieee_parser/#labridge.func_modules.paper.parse.parsers.ieee_parser.IEEEPaperParser","title":"<code>labridge.func_modules.paper.parse.parsers.ieee_parser.IEEEPaperParser</code>","text":"<p>               Bases: <code>BasePaperParser</code></p> <p>Parse the paper according to the IEEE template.</p> PARAMETER DESCRIPTION <code>separators</code> <p>Each tuple includes the separators that separate two components. Defaults to <code>IEEE_SEPARATORS</code>.</p> <p> TYPE: <code>List[Tuple[str]]</code> DEFAULT: <code>None</code> </p> <code>content_names</code> <p>Defaults to <code>IEEE_CONTENT_NAMES</code>.</p> <p> TYPE: <code>Dict[int, Tuple[str]</code> DEFAULT: <code>None</code> </p> <code>separator_tolerance</code> <p>The tolerance of mismatch chars.</p> <p> TYPE: <code>int</code> DEFAULT: <code>3</code> </p> Source code in <code>labridge\\func_modules\\paper\\parse\\parsers\\ieee_parser.py</code> <pre><code>class IEEEPaperParser(BasePaperParser):\n\tr\"\"\"\n\tParse the paper according to the IEEE template.\n\n\tArgs:\n\t\tseparators (List[Tuple[str]]): Each tuple includes the separators that separate two components.\n\t\t\tDefaults to `IEEE_SEPARATORS`.\n\t\tcontent_names (Dict[int, Tuple[str]): Key: component index; Value: component name candidates.\n\t\t\tDefaults to `IEEE_CONTENT_NAMES`.\n\t\tseparator_tolerance (int): The tolerance of mismatch chars.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tseparators: List[Tuple[str]] = None,\n\t\tcontent_names: Dict[int, Tuple[str]] = None,\n\t\tseparator_tolerance: int = 3\n\t):\n\t\tseparators = separators or IEEE_SEPARATORS\n\t\tcontent_names = content_names or IEEE_CONTENT_NAMES\n\t\tsuper().__init__(separators, content_names, separator_tolerance)\n\n\tdef parse_title(self, file_path: Union[str, Path]) -&gt; str:\n\t\tr\"\"\" Suggest to use LLM to extract title and other information. \"\"\"\n\t\tdoc = pymupdf.open(file_path)\n\t\tpage = doc[0].get_textpage()\n\n\t\tpage_blocks = page.extractBLOCKS()\n\t\ttitle = page_blocks[0][4].replace(\"\\n\", \"\")\n\t\treturn title\n</code></pre>"},{"location":"code_docs/func_modules/paper/parse/parsers/ieee_parser/#labridge.func_modules.paper.parse.parsers.ieee_parser.IEEEPaperParser.parse_title","title":"<code>labridge.func_modules.paper.parse.parsers.ieee_parser.IEEEPaperParser.parse_title(file_path)</code>","text":"<p>Suggest to use LLM to extract title and other information.</p> Source code in <code>labridge\\func_modules\\paper\\parse\\parsers\\ieee_parser.py</code> <pre><code>def parse_title(self, file_path: Union[str, Path]) -&gt; str:\n\tr\"\"\" Suggest to use LLM to extract title and other information. \"\"\"\n\tdoc = pymupdf.open(file_path)\n\tpage = doc[0].get_textpage()\n\n\tpage_blocks = page.extractBLOCKS()\n\ttitle = page_blocks[0][4].replace(\"\\n\", \"\")\n\treturn title\n</code></pre>"},{"location":"code_docs/func_modules/paper/parse/parsers/nature_parser/","title":"Nature parser","text":""},{"location":"code_docs/func_modules/paper/parse/parsers/nature_parser/#labridge.func_modules.paper.parse.parsers.nature_parser","title":"<code>labridge.func_modules.paper.parse.parsers.nature_parser</code>","text":""},{"location":"code_docs/func_modules/paper/parse/parsers/nature_parser/#labridge.func_modules.paper.parse.parsers.nature_parser.NaturePaperParser","title":"<code>labridge.func_modules.paper.parse.parsers.nature_parser.NaturePaperParser</code>","text":"<p>               Bases: <code>BasePaperParser</code></p> <p>Parse the paper according to the Nature template.</p> PARAMETER DESCRIPTION <code>separators</code> <p>Each tuple includes the separators that separate two components. Defaults to <code>NATURE_SEPARATORS</code>.</p> <p> TYPE: <code>List[Tuple[str]]</code> DEFAULT: <code>None</code> </p> <code>content_names</code> <p>Defaults to <code>NATURE_CONTENT_NAMES</code>.</p> <p> TYPE: <code>Dict[int, Tuple[str]</code> DEFAULT: <code>None</code> </p> <code>separator_tolerance</code> <p>The tolerance of mismatch chars.</p> <p> TYPE: <code>int</code> DEFAULT: <code>3</code> </p> Source code in <code>labridge\\func_modules\\paper\\parse\\parsers\\nature_parser.py</code> <pre><code>class NaturePaperParser(BasePaperParser):\n\tr\"\"\"\n\tParse the paper according to the Nature template.\n\n\tArgs:\n\t\tseparators (List[Tuple[str]]): Each tuple includes the separators that separate two components.\n\t\t\tDefaults to `NATURE_SEPARATORS`.\n\t\tcontent_names (Dict[int, Tuple[str]): Key: component index; Value: component name candidates.\n\t\t\tDefaults to `NATURE_CONTENT_NAMES`.\n\t\tseparator_tolerance (int): The tolerance of mismatch chars.\n\t\"\"\"\n\tdef __init__(self,\n\t\t\t\t separators: List[Tuple[str]] = None,\n\t\t\t\t content_names: Dict[int, Tuple[str]] = None,\n\t\t\t\t separator_tolerance: int = 3):\n\t\tseparators = separators or NATURE_SEPARATORS\n\t\tcontent_names = content_names or NATURE_CONTENT_NAMES\n\t\tsuper().__init__(separators, content_names, separator_tolerance)\n\n\tdef parse_title(self, file_path: Union[str, Path]) -&gt; str:\n\t\tr\"\"\" Suggest to use LLM to extract title and other information. \"\"\"\n\t\tdoc = pymupdf.open(file_path)\n\t\ttoc = doc.get_toc()\n\t\ttitle = None\n\t\ttry:\n\t\t\twhile isinstance(toc[0], list):\n\t\t\t\ttoc = toc[0]\n\t\t\t\ttitle = toc[1]\n\t\texcept IndexError:\n\t\t\tprint(f\"&gt;&gt;&gt; PyMupdf failed to get toc from {file_path}\")\n\t\treturn title\n</code></pre>"},{"location":"code_docs/func_modules/paper/parse/parsers/nature_parser/#labridge.func_modules.paper.parse.parsers.nature_parser.NaturePaperParser.parse_title","title":"<code>labridge.func_modules.paper.parse.parsers.nature_parser.NaturePaperParser.parse_title(file_path)</code>","text":"<p>Suggest to use LLM to extract title and other information.</p> Source code in <code>labridge\\func_modules\\paper\\parse\\parsers\\nature_parser.py</code> <pre><code>def parse_title(self, file_path: Union[str, Path]) -&gt; str:\n\tr\"\"\" Suggest to use LLM to extract title and other information. \"\"\"\n\tdoc = pymupdf.open(file_path)\n\ttoc = doc.get_toc()\n\ttitle = None\n\ttry:\n\t\twhile isinstance(toc[0], list):\n\t\t\ttoc = toc[0]\n\t\t\ttitle = toc[1]\n\texcept IndexError:\n\t\tprint(f\"&gt;&gt;&gt; PyMupdf failed to get toc from {file_path}\")\n\treturn title\n</code></pre>"},{"location":"code_docs/func_modules/paper/prompt/store/dir_summary/","title":"Dir summary","text":""},{"location":"code_docs/func_modules/paper/prompt/store/dir_summary/#labridge.func_modules.paper.prompt.store.dir_summary","title":"<code>labridge.func_modules.paper.prompt.store.dir_summary</code>","text":""},{"location":"code_docs/func_modules/paper/prompt/synthesize/paper_summarize/","title":"Paper summarize","text":""},{"location":"code_docs/func_modules/paper/prompt/synthesize/paper_summarize/#labridge.func_modules.paper.prompt.synthesize.paper_summarize","title":"<code>labridge.func_modules.paper.prompt.synthesize.paper_summarize</code>","text":""},{"location":"code_docs/func_modules/paper/prompt/synthesize/synthesize/","title":"Synthesize","text":""},{"location":"code_docs/func_modules/paper/prompt/synthesize/synthesize/#labridge.func_modules.paper.prompt.synthesize.synthesize","title":"<code>labridge.func_modules.paper.prompt.synthesize.synthesize</code>","text":""},{"location":"code_docs/func_modules/paper/retrieve/paper_retriever/","title":"Paper retriever","text":""},{"location":"code_docs/func_modules/paper/retrieve/paper_retriever/#labridge.func_modules.paper.retrieve.paper_retriever","title":"<code>labridge.func_modules.paper.retrieve.paper_retriever</code>","text":""},{"location":"code_docs/func_modules/paper/retrieve/paper_retriever/#labridge.func_modules.paper.retrieve.paper_retriever.PaperRetriever","title":"<code>labridge.func_modules.paper.retrieve.paper_retriever.PaperRetriever</code>","text":"<p>We use hybrid, multi-level retrieving methods.</p> <p>In the first step, the retriever retrieve the vector index and the summary index to get candidate papers. These two index storages are constructed in the class <code>PaperStorage</code>, refer to its docstring for details.</p> <ul> <li>In the vector index, the paper contents except for references are chunked and embedded. The retriever get <code>vector_similarity_top_k</code> most relevant text chunk from the vector index, then we collect their <code>ref_doc_id</code>.</li> <li>In the summary index, each paper is summarized. Both the summary text and the paper chunks are stored. The retriever search in the summary texts to get <code>summary_similarity_top_k</code> most relevant summaries of docs. Similarly, we collect their <code>doc_id</code>.</li> </ul> <p>We have collected several relevant papers in the first step. Subsequently, we use the <code>PaperSummaryLLMPostSelector</code> to rank these papers according to the relevance between their summaries and the query, the relevance scores are given by the LLM. Among these papers, the LLM selects <code>docs_top_k</code> most relevant papers.</p> <p>Finally, we conduct secondary_retrieve among the text chunks of these luckily selected papers. Note that, in this period, we hide all metadata of these nodes from the LLM and the embed model for the sake of grained retrieving. At last, we will get <code>re_retrieve_top_k</code> text chunks.</p> <p>If the <code>final_use_context</code> is set to True, the prev_node and next_node of each node will be added. If the <code>final_use_summary</code> is set to True, the summary_node corresponding to each_node's doc will be added.</p> PARAMETER DESCRIPTION <code>llm</code> <p>the employed LLM.</p> <p> TYPE: <code>LLM</code> </p> <code>paper_vector_retriever</code> <p>the retriever based on the VectorIndex in paper storage.</p> <p> TYPE: <code>VectorIndexRetriever</code> </p> <code>paper_summary_retriever</code> <p>the retriever based on the DocumentSummaryIndex in the paper storage.</p> <p> TYPE: <code>DocumentSummaryIndexEmbeddingRetriever</code> </p> <code>docs_top_k</code> <p>the number of most relevant docs in the second retrieving step.</p> <p> TYPE: <code>int</code> DEFAULT: <code>2</code> </p> <code>re_retrieve_top_k</code> <p>the number of the finally retrieved nodes.</p> <p> TYPE: <code>int</code> DEFAULT: <code>5</code> </p> <code>final_use_context</code> <p>Whether to add the context nodes of each final node.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>final_use_summary</code> <p>Whether to add the summary node of each final node's doc.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> Source code in <code>labridge\\func_modules\\paper\\retrieve\\paper_retriever.py</code> <pre><code>class PaperRetriever:\n\tr\"\"\"\n\tWe use hybrid, multi-level retrieving methods.\n\n\tIn the first step, the retriever retrieve the vector index and the summary index to get candidate papers.\n\tThese two index storages are constructed in the class `PaperStorage`, refer to its docstring for details.\n\n\t- In the vector index, the paper contents except for references are chunked and embedded. The retriever get\n\t`vector_similarity_top_k` most relevant text chunk from the vector index, then we collect their `ref_doc_id`.\n\t- In the summary index, each paper is summarized. Both the summary text and the paper chunks are stored.\n\tThe retriever search in the summary texts to get `summary_similarity_top_k` most relevant summaries of docs.\n\tSimilarly, we collect their `doc_id`.\n\n\tWe have collected several relevant papers in the first step. Subsequently, we use the `PaperSummaryLLMPostSelector`\n\tto rank these papers according to the relevance between their summaries and the query, the relevance scores are\n\tgiven by the LLM. Among these papers, the LLM selects `docs_top_k` most relevant papers.\n\n\tFinally, we conduct secondary_retrieve among the text chunks of these luckily selected papers.\n\tNote that, in this period, we hide all metadata of these nodes from the LLM and the embed model for the sake of\n\tgrained retrieving. At last, we will get `re_retrieve_top_k` text chunks.\n\n\tIf the `final_use_context` is set to True, the prev_node and next_node of each node will be added.\n\tIf the `final_use_summary` is set to True, the summary_node corresponding to each_node's doc will be added.\n\n\tArgs:\n\t\tllm (LLM): the employed LLM.\n\t\tpaper_vector_retriever (VectorIndexRetriever): the retriever based on the VectorIndex in paper storage.\n\t\tpaper_summary_retriever (DocumentSummaryIndexEmbeddingRetriever):\n\t\t\tthe retriever based on the DocumentSummaryIndex in the paper storage.\n\t\tdocs_top_k (int): the number of most relevant docs in the second retrieving step.\n\t\tre_retrieve_top_k (int): the number of the finally retrieved nodes.\n\t\tfinal_use_context (bool): Whether to add the context nodes of each final node.\n\t\tfinal_use_summary (bool): Whether to add the summary node of each final node's doc.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tllm: LLM,\n\t\tpaper_vector_retriever: VectorIndexRetriever,\n\t\tpaper_summary_retriever: DocumentSummaryIndexEmbeddingRetriever,\n\t\tdocs_top_k: int = 2,\n\t\tre_retrieve_top_k: int = 5,\n\t\tfinal_use_context: bool = True,\n\t\tfinal_use_summary: bool = True\n\t):\n\t\tself.paper_vector_retriever = paper_vector_retriever\n\t\tself.paper_summary_retriever = paper_summary_retriever\n\t\tself.paper_summary_post_selector = PaperSummaryLLMPostSelector(\n\t\t\tsummary_nodes=[],\n\t\t\tllm=llm,\n\t\t\tchoice_top_k=docs_top_k,\n\t\t)\n\t\tself.re_retrieve_top_k = re_retrieve_top_k\n\t\tself.final_use_context = final_use_context\n\t\tself.final_use_summary = final_use_summary\n\t\tself.doc_id_to_summary_id = self.paper_summary_retriever._index._index_struct.doc_id_to_summary_id\n\t\tself.summary_id_to_node_ids = self.paper_summary_retriever._index._index_struct.summary_id_to_node_ids\n\t\tself.retrieved_nodes = []\n\t\troot = Path(__file__)\n\t\tfor i in range(5):\n\t\t\troot = root.parent\n\t\tself.root = root\n\n\tdef _exclude_all_llm_metadata(self, node: BaseNode):\n\t\tr\"\"\" Hidden all metadata of a node to LLM. \"\"\"\n\t\tnode.excluded_llm_metadata_keys.extend(list(node.metadata.keys()))\n\n\tdef _exclude_all_embedding_metadata(self, node: BaseNode):\n\t\tr\"\"\" Hidden all metadata of a node to the embed model. \"\"\"\n\t\tnode.excluded_embed_metadata_keys.extend(list(node.metadata.keys()))\n\n\tdef get_ref_info(self) -&gt; List[PaperInfo]:\n\t\tr\"\"\"\n\t\tGet the reference paper infos\n\n\t\tReturns:\n\t\t\tList[PaperInfo]: The reference paper infos in answering.\n\t\t\"\"\"\n\t\tdoc_ids, doc_titles, doc_possessors = [], [], []\n\t\tref_infos = []\n\t\tfor node_score in self.retrieved_nodes:\n\t\t\tref_doc_id = node_score.node.ref_doc_id\n\t\t\tif ref_doc_id not in doc_ids:\n\t\t\t\tdoc_ids.append(ref_doc_id)\n\t\t\t\ttitle = node_score.node.metadata.get(PAPER_TITLE) or ref_doc_id\n\t\t\t\tpossessor = node_score.node.metadata.get(PAPER_POSSESSOR)\n\t\t\t\trel_path = node_score.node.metadata.get(PAPER_REL_FILE_PATH)\n\t\t\t\tif rel_path is None:\n\t\t\t\t\traise ValueError(\"Invalid database.\")\n\t\t\t\tpaper_info = PaperInfo(\n\t\t\t\t\ttitle=title,\n\t\t\t\t\tpossessor=possessor,\n\t\t\t\t\tfile_path=str(self.root / rel_path),\n\t\t\t\t)\n\t\t\t\tref_infos.append(paper_info)\n\n\t\t\t\tdoc_titles.append(title)\n\t\t\t\tdoc_possessors.append(possessor)\n\t\treturn ref_infos\n\n\tdef _secondary_retrieve(\n\t\tself,\n\t\tfinal_doc_ids: List[str],\n\t\titem_to_be_retrieved: str\n\t) -&gt; Tuple[List[NodeWithScore], List[NodeWithScore]]:\n\t\tr\"\"\"\n\t\tSecondary retrieve among the nodes of the selected papers.\n\n\t\tArgs:\n\t\t\tfinal_doc_ids (List[str]): the doc_ids of the selected papers.\n\t\t\titem_to_be_retrieved (str): the retrieving items.\n\n\t\tReturns:\n\t\t\tthe summary_nodes and the content_nodes:\n\n\t\t\t\t- summary_nodes (List[NodeWithScore]): the summary nodes of these docs.\n\t\t\t\t- content_nodes (List[NodeWithScore]): the retrieved nodes among the chunked nodes of these docs.\n\t\t\"\"\"\n\t\t# get all nodes of these docs.\n\t\tsummary_nodes = []\n\t\tall_doc_nodes = []\n\t\tfor doc_id in final_doc_ids:\n\t\t\tsummary_id = self.doc_id_to_summary_id[doc_id]\n\t\t\tsummary_node = self.paper_summary_retriever._index.docstore.get_node(summary_id)\n\t\t\t# exclude metadata of summary nodes for llm using.\n\t\t\tself._exclude_all_llm_metadata(summary_node)\n\t\t\tsummary_nodes.append(NodeWithScore(node=summary_node))\n\n\t\t\t# all doc nodes.\n\t\t\tdoc_node_ids = self.summary_id_to_node_ids[summary_id]\n\t\t\tdoc_nodes = self.paper_summary_retriever._index.docstore.get_nodes(doc_node_ids)\n\t\t\t# exclude metadata of content nodes\n\t\t\tfor doc_node in doc_nodes:\n\t\t\t\tself._exclude_all_llm_metadata(doc_node)\n\t\t\t\tself._exclude_all_embedding_metadata(doc_node)\n\t\t\tall_doc_nodes.extend(doc_nodes)\n\n\t\tcontent_index = VectorStoreIndex(nodes=all_doc_nodes, embed_model=self.paper_vector_retriever._embed_model)\n\t\tcontent_retriever = content_index.as_retriever(similarity_top_k=self.re_retrieve_top_k)\n\t\tcontent_nodes = content_retriever.retrieve(item_to_be_retrieved)\n\t\treturn summary_nodes, content_nodes\n\n\tasync def _asecondary_retrieve(\n\t\tself,\n\t\tfinal_doc_ids: List[str],\n\t\titem_to_be_retrieved: str\n\t) -&gt; Tuple[List[NodeWithScore], List[NodeWithScore]]:\n\t\tr\"\"\"\n\t\tAsynchronous secondary retrieve among the nodes of the selected papers.\n\n\t\tArgs:\n\t\t\tfinal_doc_ids (List[str]): the doc_ids of the selected papers.\n\t\t\titem_to_be_retrieved (str): the retrieving items.\n\n\t\tReturns:\n\t\t\tthe summary_nodes and the content_nodes:\n\n\t\t\t\t- summary_nodes (List[NodeWithScore]): the summary nodes of these docs.\n\t\t\t\t- content_nodes (List[NodeWithScore]): the retrieved nodes among the chunked nodes of these docs.\n\t\t\"\"\"\n\t\tsummary_nodes = []\n\t\tall_doc_nodes = []\n\t\tfor doc_id in final_doc_ids:\n\t\t\tsummary_id = self.doc_id_to_summary_id[doc_id]\n\t\t\tsummary_node = self.paper_summary_retriever._index.docstore.get_node(summary_id)\n\t\t\t# exclude metadata of summary nodes for llm using.\n\t\t\tself._exclude_all_llm_metadata(summary_node)\n\t\t\tsummary_nodes.append(NodeWithScore(node=summary_node))\n\n\t\t\t# all doc nodes.\n\t\t\tdoc_node_ids = self.summary_id_to_node_ids[summary_id]\n\t\t\tdoc_nodes = self.paper_summary_retriever._index.docstore.get_nodes(doc_node_ids)\n\t\t\t# exclude metadata of content nodes\n\t\t\tfor doc_node in doc_nodes:\n\t\t\t\tself._exclude_all_llm_metadata(doc_node)\n\t\t\t\tself._exclude_all_embedding_metadata(doc_node)\n\t\t\tall_doc_nodes.extend(doc_nodes)\n\n\t\tcontent_index = VectorStoreIndex(nodes=all_doc_nodes, embed_model=self.paper_vector_retriever._embed_model)\n\t\tcontent_retriever = content_index.as_retriever(similarity_top_k=self.re_retrieve_top_k)\n\t\tcontent_nodes = await content_retriever.aretrieve(item_to_be_retrieved)\n\t\treturn summary_nodes, content_nodes\n\n\tdef _get_context(self, content_nodes: List[NodeWithScore]) -&gt; List[NodeWithScore]:\n\t\tr\"\"\"\n\t\tGet the 1-hop context nodes of each content node retrieved in the secondary retrieving.\n\t\t\"\"\"\n\t\tcontent_ids = [node.node.node_id for node in content_nodes]\n\t\textra_ids = []\n\t\tfor node in content_nodes:\n\t\t\tprev_node = node.node.prev_node\n\t\t\tnext_node = node.node.next_node\n\t\t\tif prev_node is not None:\n\t\t\t\tprev_id = node.node.prev_node.node_id\n\t\t\t\tif prev_id not in content_ids:\n\t\t\t\t\textra_ids.append(prev_id)\n\t\t\t\t\tcontent_ids.append(prev_id)\n\n\t\t\tif next_node is not None:\n\t\t\t\tnext_id = node.node.next_node.node_id\n\t\t\t\tif next_id not in content_ids:\n\t\t\t\t\textra_ids.append(next_id)\n\t\t\t\t\tcontent_ids.append(next_id)\n\n\t\tcontext_nodes = self.paper_summary_retriever._index.docstore.get_nodes(extra_ids)\n\t\tcontext_nodes = [NodeWithScore(node=node) for node in context_nodes]\n\t\t# exclude metadata in LLM using.\n\t\tfor node in context_nodes:\n\t\t\tself._exclude_all_llm_metadata(node.node)\n\t\treturn context_nodes\n\n\t@dispatcher.span\n\tdef retrieve(\n\t\tself,\n\t\titem_to_be_retrieved: str,\n\t) -&gt; List[NodeWithScore]:\n\t\tr\"\"\"\n\t\tThis tool is used to retrieve academic information in the Laboratory's shared paper database.\n\t\tIt is useful to help answer the user's academic questions.\n\n\t\tArgs:\n\t\t\titem_to_be_retrieved (str): The things that you want to retrieve in the shared paper database.\n\t\t\"\"\"\n\t\t# This docstring is used as the tool description.\n\t\tvector_nodes = self.paper_vector_retriever.retrieve(item_to_be_retrieved)\n\t\tsummary_chunk_nodes = self.paper_summary_retriever.retrieve(item_to_be_retrieved)\n\n\t\thybrid_doc_ids = set()\n\t\tfor node in summary_chunk_nodes + vector_nodes:\n\t\t\thybrid_doc_ids.add(node.node.ref_doc_id)\n\n\t\tdoc_id_to_summary_id = self.paper_summary_retriever._index._index_struct.doc_id_to_summary_id\n\t\thybrid_summary_ids = [doc_id_to_summary_id[doc_id] for doc_id in hybrid_doc_ids]\n\t\tdoc_summary_nodes = self.paper_summary_retriever._index.docstore.get_nodes(hybrid_summary_ids)\n\n\t\tself.paper_summary_post_selector._summary_nodes = doc_summary_nodes\n\t\tfinal_doc_ids = self.paper_summary_post_selector.select(item_to_be_retrieved)\n\n\t\tsummary_nodes, content_nodes = self._secondary_retrieve(\n\t\t\tfinal_doc_ids=final_doc_ids,\n\t\t\titem_to_be_retrieved=item_to_be_retrieved,\n\t\t)\n\n\t\tfinal_nodes = content_nodes\n\t\tif self.final_use_summary:\n\t\t\tfinal_nodes.extend(summary_nodes)\n\n\t\tif self.final_use_context:\n\t\t\tcontext_nodes = self._get_context(content_nodes)\n\t\t\tfinal_nodes.extend(context_nodes)\n\t\tself.retrieved_nodes = final_nodes\n\t\treturn final_nodes\n\n\t@dispatcher.span\n\tasync def aretrieve(\n\t\tself,\n\t\titem_to_be_retrieved: str,\n\t) -&gt; List[NodeWithScore]:\n\t\tr\"\"\"\n\t\tThis tool is used to retrieve academic information in the Laboratory's shared paper database, which contains\n\t\tabundant research papers. It is useful to help you to answer the user's academic questions.\n\n\t\tArgs:\n\t\t\titem_to_be_retrieved (str): The things that you want to retrieve in the shared paper database.\n\t\t\"\"\"\n\t\tvector_nodes = await self.paper_vector_retriever.aretrieve(item_to_be_retrieved)\n\t\tsummary_chunk_nodes = await self.paper_summary_retriever.aretrieve(item_to_be_retrieved)\n\n\t\thybrid_doc_ids = set()\n\t\tfor node in summary_chunk_nodes + vector_nodes:\n\t\t\thybrid_doc_ids.add(node.node.ref_doc_id)\n\n\t\tdoc_id_to_summary_id = self.paper_summary_retriever._index._index_struct.doc_id_to_summary_id\n\t\thybrid_summary_ids = [doc_id_to_summary_id[doc_id] for doc_id in hybrid_doc_ids]\n\t\tdoc_summary_nodes = self.paper_summary_retriever._index.docstore.get_nodes(hybrid_summary_ids)\n\n\t\tself.paper_summary_post_selector._summary_nodes = doc_summary_nodes\n\t\tfinal_doc_ids = await self.paper_summary_post_selector.aselect(item_to_be_retrieved)\n\n\t\tsummary_nodes, content_nodes = self._secondary_retrieve(\n\t\t\tfinal_doc_ids=final_doc_ids,\n\t\t\titem_to_be_retrieved=item_to_be_retrieved,\n\t\t)\n\n\t\tfinal_nodes = content_nodes\n\t\tif self.final_use_summary:\n\t\t\tfinal_nodes.extend(summary_nodes)\n\n\t\tif self.final_use_context:\n\t\t\tcontext_nodes = self._get_context(content_nodes)\n\t\t\tfinal_nodes.extend(context_nodes)\n\t\tself.retrieved_nodes = final_nodes\n\t\treturn final_nodes\n\n\n\t@classmethod\n\tdef from_storage(\n\t\tcls,\n\t\tllm: Optional[LLM] = None,\n\t\tembed_model: Optional[BaseEmbedding] = None,\n\t\tvector_persist_dir: Optional[Union[Path, str]] = None,\n\t\tpaper_summary_persist_dir: Optional[Union[Path, str]] = None,\n\t\tvector_similarity_top_k: Optional[int] = PAPER_VECTOR_TOP_K,\n\t\tsummary_similarity_top_k: Optional[int] = PAPER_SUMMARY_TOP_K,\n\t\tservice_context: Optional[ServiceContext] = None,\n\t\tdocs_top_k: int = PAPER_TOP_K,\n\t\tre_retrieve_top_k: int = PAPER_RETRIEVE_TOP_K,\n\t\tfinal_use_context: bool = True,\n\t\tfinal_use_summary: bool = True,\n\t):\n\t\tr\"\"\"\n\t\tLoad from an existing storage.\n\t\t\"\"\"\n\t\troot = Path(__file__)\n\t\tfor i in range(5):\n\t\t\troot = root.parent\n\n\t\tllm = llm or llm_from_settings_or_context(Settings, service_context)\n\t\tembed_model = embed_model or embed_model_from_settings_or_context(Settings, service_context)\n\n\t\tvector_persist_dir = vector_persist_dir or root / DEFAULT_PAPER_VECTOR_PERSIST_DIR\n\t\tvector_storage_context = StorageContext.from_defaults(persist_dir=vector_persist_dir)\n\t\tvector_index = load_index_from_storage(\n\t\t\tstorage_context=vector_storage_context,\n\t\t\tindex_id=PAPER_VECTOR_INDEX_ID,\n\t\t\tembed_model=embed_model\n\t\t)\n\t\tvector_retriever = vector_index.as_retriever(similarity_top_k=vector_similarity_top_k)\n\n\t\tpaper_summary_persist_dir = paper_summary_persist_dir or root / DEFAULT_PAPER_SUMMARY_PERSIST_DIR\n\t\tpaper_summary_storage_context = StorageContext.from_defaults(persist_dir=paper_summary_persist_dir)\n\t\tpaper_summary_index = load_index_from_storage(\n\t\t\tstorage_context=paper_summary_storage_context,\n\t\t\tindex_id=PAPER_SUMMARY_INDEX_ID,\n\t\t\tllm=llm,\n\t\t\tembed_model=embed_model\n\t\t)\n\t\tsummary_retriever = paper_summary_index.as_retriever(\n\t\t\tretriever_mode=DocumentSummaryRetrieverMode.EMBEDDING,\n\t\t\tsimilarity_top_k=summary_similarity_top_k)\n\t\treturn cls(\n\t\t\tllm = llm,\n\t\t\tpaper_vector_retriever=vector_retriever,\n\t\t\tpaper_summary_retriever=summary_retriever,\n\t\t\tdocs_top_k=docs_top_k,\n\t\t\tre_retrieve_top_k=re_retrieve_top_k,\n\t\t\tfinal_use_context=final_use_context,\n\t\t\tfinal_use_summary=final_use_summary,\n\t\t)\n</code></pre>"},{"location":"code_docs/func_modules/paper/retrieve/paper_retriever/#labridge.func_modules.paper.retrieve.paper_retriever.PaperRetriever.aretrieve","title":"<code>labridge.func_modules.paper.retrieve.paper_retriever.PaperRetriever.aretrieve(item_to_be_retrieved)</code>  <code>async</code>","text":"<p>This tool is used to retrieve academic information in the Laboratory's shared paper database, which contains abundant research papers. It is useful to help you to answer the user's academic questions.</p> PARAMETER DESCRIPTION <code>item_to_be_retrieved</code> <p>The things that you want to retrieve in the shared paper database.</p> <p> TYPE: <code>str</code> </p> Source code in <code>labridge\\func_modules\\paper\\retrieve\\paper_retriever.py</code> <pre><code>@dispatcher.span\nasync def aretrieve(\n\tself,\n\titem_to_be_retrieved: str,\n) -&gt; List[NodeWithScore]:\n\tr\"\"\"\n\tThis tool is used to retrieve academic information in the Laboratory's shared paper database, which contains\n\tabundant research papers. It is useful to help you to answer the user's academic questions.\n\n\tArgs:\n\t\titem_to_be_retrieved (str): The things that you want to retrieve in the shared paper database.\n\t\"\"\"\n\tvector_nodes = await self.paper_vector_retriever.aretrieve(item_to_be_retrieved)\n\tsummary_chunk_nodes = await self.paper_summary_retriever.aretrieve(item_to_be_retrieved)\n\n\thybrid_doc_ids = set()\n\tfor node in summary_chunk_nodes + vector_nodes:\n\t\thybrid_doc_ids.add(node.node.ref_doc_id)\n\n\tdoc_id_to_summary_id = self.paper_summary_retriever._index._index_struct.doc_id_to_summary_id\n\thybrid_summary_ids = [doc_id_to_summary_id[doc_id] for doc_id in hybrid_doc_ids]\n\tdoc_summary_nodes = self.paper_summary_retriever._index.docstore.get_nodes(hybrid_summary_ids)\n\n\tself.paper_summary_post_selector._summary_nodes = doc_summary_nodes\n\tfinal_doc_ids = await self.paper_summary_post_selector.aselect(item_to_be_retrieved)\n\n\tsummary_nodes, content_nodes = self._secondary_retrieve(\n\t\tfinal_doc_ids=final_doc_ids,\n\t\titem_to_be_retrieved=item_to_be_retrieved,\n\t)\n\n\tfinal_nodes = content_nodes\n\tif self.final_use_summary:\n\t\tfinal_nodes.extend(summary_nodes)\n\n\tif self.final_use_context:\n\t\tcontext_nodes = self._get_context(content_nodes)\n\t\tfinal_nodes.extend(context_nodes)\n\tself.retrieved_nodes = final_nodes\n\treturn final_nodes\n</code></pre>"},{"location":"code_docs/func_modules/paper/retrieve/paper_retriever/#labridge.func_modules.paper.retrieve.paper_retriever.PaperRetriever.from_storage","title":"<code>labridge.func_modules.paper.retrieve.paper_retriever.PaperRetriever.from_storage(llm=None, embed_model=None, vector_persist_dir=None, paper_summary_persist_dir=None, vector_similarity_top_k=PAPER_VECTOR_TOP_K, summary_similarity_top_k=PAPER_SUMMARY_TOP_K, service_context=None, docs_top_k=PAPER_TOP_K, re_retrieve_top_k=PAPER_RETRIEVE_TOP_K, final_use_context=True, final_use_summary=True)</code>  <code>classmethod</code>","text":"<p>Load from an existing storage.</p> Source code in <code>labridge\\func_modules\\paper\\retrieve\\paper_retriever.py</code> <pre><code>@classmethod\ndef from_storage(\n\tcls,\n\tllm: Optional[LLM] = None,\n\tembed_model: Optional[BaseEmbedding] = None,\n\tvector_persist_dir: Optional[Union[Path, str]] = None,\n\tpaper_summary_persist_dir: Optional[Union[Path, str]] = None,\n\tvector_similarity_top_k: Optional[int] = PAPER_VECTOR_TOP_K,\n\tsummary_similarity_top_k: Optional[int] = PAPER_SUMMARY_TOP_K,\n\tservice_context: Optional[ServiceContext] = None,\n\tdocs_top_k: int = PAPER_TOP_K,\n\tre_retrieve_top_k: int = PAPER_RETRIEVE_TOP_K,\n\tfinal_use_context: bool = True,\n\tfinal_use_summary: bool = True,\n):\n\tr\"\"\"\n\tLoad from an existing storage.\n\t\"\"\"\n\troot = Path(__file__)\n\tfor i in range(5):\n\t\troot = root.parent\n\n\tllm = llm or llm_from_settings_or_context(Settings, service_context)\n\tembed_model = embed_model or embed_model_from_settings_or_context(Settings, service_context)\n\n\tvector_persist_dir = vector_persist_dir or root / DEFAULT_PAPER_VECTOR_PERSIST_DIR\n\tvector_storage_context = StorageContext.from_defaults(persist_dir=vector_persist_dir)\n\tvector_index = load_index_from_storage(\n\t\tstorage_context=vector_storage_context,\n\t\tindex_id=PAPER_VECTOR_INDEX_ID,\n\t\tembed_model=embed_model\n\t)\n\tvector_retriever = vector_index.as_retriever(similarity_top_k=vector_similarity_top_k)\n\n\tpaper_summary_persist_dir = paper_summary_persist_dir or root / DEFAULT_PAPER_SUMMARY_PERSIST_DIR\n\tpaper_summary_storage_context = StorageContext.from_defaults(persist_dir=paper_summary_persist_dir)\n\tpaper_summary_index = load_index_from_storage(\n\t\tstorage_context=paper_summary_storage_context,\n\t\tindex_id=PAPER_SUMMARY_INDEX_ID,\n\t\tllm=llm,\n\t\tembed_model=embed_model\n\t)\n\tsummary_retriever = paper_summary_index.as_retriever(\n\t\tretriever_mode=DocumentSummaryRetrieverMode.EMBEDDING,\n\t\tsimilarity_top_k=summary_similarity_top_k)\n\treturn cls(\n\t\tllm = llm,\n\t\tpaper_vector_retriever=vector_retriever,\n\t\tpaper_summary_retriever=summary_retriever,\n\t\tdocs_top_k=docs_top_k,\n\t\tre_retrieve_top_k=re_retrieve_top_k,\n\t\tfinal_use_context=final_use_context,\n\t\tfinal_use_summary=final_use_summary,\n\t)\n</code></pre>"},{"location":"code_docs/func_modules/paper/retrieve/paper_retriever/#labridge.func_modules.paper.retrieve.paper_retriever.PaperRetriever.get_ref_info","title":"<code>labridge.func_modules.paper.retrieve.paper_retriever.PaperRetriever.get_ref_info()</code>","text":"<p>Get the reference paper infos</p> RETURNS DESCRIPTION <code>List[PaperInfo]</code> <p>List[PaperInfo]: The reference paper infos in answering.</p> Source code in <code>labridge\\func_modules\\paper\\retrieve\\paper_retriever.py</code> <pre><code>def get_ref_info(self) -&gt; List[PaperInfo]:\n\tr\"\"\"\n\tGet the reference paper infos\n\n\tReturns:\n\t\tList[PaperInfo]: The reference paper infos in answering.\n\t\"\"\"\n\tdoc_ids, doc_titles, doc_possessors = [], [], []\n\tref_infos = []\n\tfor node_score in self.retrieved_nodes:\n\t\tref_doc_id = node_score.node.ref_doc_id\n\t\tif ref_doc_id not in doc_ids:\n\t\t\tdoc_ids.append(ref_doc_id)\n\t\t\ttitle = node_score.node.metadata.get(PAPER_TITLE) or ref_doc_id\n\t\t\tpossessor = node_score.node.metadata.get(PAPER_POSSESSOR)\n\t\t\trel_path = node_score.node.metadata.get(PAPER_REL_FILE_PATH)\n\t\t\tif rel_path is None:\n\t\t\t\traise ValueError(\"Invalid database.\")\n\t\t\tpaper_info = PaperInfo(\n\t\t\t\ttitle=title,\n\t\t\t\tpossessor=possessor,\n\t\t\t\tfile_path=str(self.root / rel_path),\n\t\t\t)\n\t\t\tref_infos.append(paper_info)\n\n\t\t\tdoc_titles.append(title)\n\t\t\tdoc_possessors.append(possessor)\n\treturn ref_infos\n</code></pre>"},{"location":"code_docs/func_modules/paper/retrieve/paper_retriever/#labridge.func_modules.paper.retrieve.paper_retriever.PaperRetriever.retrieve","title":"<code>labridge.func_modules.paper.retrieve.paper_retriever.PaperRetriever.retrieve(item_to_be_retrieved)</code>","text":"<p>This tool is used to retrieve academic information in the Laboratory's shared paper database. It is useful to help answer the user's academic questions.</p> PARAMETER DESCRIPTION <code>item_to_be_retrieved</code> <p>The things that you want to retrieve in the shared paper database.</p> <p> TYPE: <code>str</code> </p> Source code in <code>labridge\\func_modules\\paper\\retrieve\\paper_retriever.py</code> <pre><code>@dispatcher.span\ndef retrieve(\n\tself,\n\titem_to_be_retrieved: str,\n) -&gt; List[NodeWithScore]:\n\tr\"\"\"\n\tThis tool is used to retrieve academic information in the Laboratory's shared paper database.\n\tIt is useful to help answer the user's academic questions.\n\n\tArgs:\n\t\titem_to_be_retrieved (str): The things that you want to retrieve in the shared paper database.\n\t\"\"\"\n\t# This docstring is used as the tool description.\n\tvector_nodes = self.paper_vector_retriever.retrieve(item_to_be_retrieved)\n\tsummary_chunk_nodes = self.paper_summary_retriever.retrieve(item_to_be_retrieved)\n\n\thybrid_doc_ids = set()\n\tfor node in summary_chunk_nodes + vector_nodes:\n\t\thybrid_doc_ids.add(node.node.ref_doc_id)\n\n\tdoc_id_to_summary_id = self.paper_summary_retriever._index._index_struct.doc_id_to_summary_id\n\thybrid_summary_ids = [doc_id_to_summary_id[doc_id] for doc_id in hybrid_doc_ids]\n\tdoc_summary_nodes = self.paper_summary_retriever._index.docstore.get_nodes(hybrid_summary_ids)\n\n\tself.paper_summary_post_selector._summary_nodes = doc_summary_nodes\n\tfinal_doc_ids = self.paper_summary_post_selector.select(item_to_be_retrieved)\n\n\tsummary_nodes, content_nodes = self._secondary_retrieve(\n\t\tfinal_doc_ids=final_doc_ids,\n\t\titem_to_be_retrieved=item_to_be_retrieved,\n\t)\n\n\tfinal_nodes = content_nodes\n\tif self.final_use_summary:\n\t\tfinal_nodes.extend(summary_nodes)\n\n\tif self.final_use_context:\n\t\tcontext_nodes = self._get_context(content_nodes)\n\t\tfinal_nodes.extend(context_nodes)\n\tself.retrieved_nodes = final_nodes\n\treturn final_nodes\n</code></pre>"},{"location":"code_docs/func_modules/paper/retrieve/paper_retriever/#labridge.func_modules.paper.retrieve.paper_retriever.PaperSummaryLLMPostSelector","title":"<code>labridge.func_modules.paper.retrieve.paper_retriever.PaperSummaryLLMPostSelector</code>","text":"<p>Use LLM to re-rank the retrieved papers obtained by vector_retriever and summary_retriever, according to their summaries.</p> Source code in <code>labridge\\func_modules\\paper\\retrieve\\paper_retriever.py</code> <pre><code>class PaperSummaryLLMPostSelector:\n\tr\"\"\"\n\tUse LLM to re-rank the retrieved papers obtained by vector_retriever and summary_retriever,\n\taccording to their summaries.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tsummary_nodes: List[BaseNode],\n\t\tllm: Optional[LLM] = None,\n\t\tchoice_select_prompt: Optional[BasePromptTemplate] = None,\n\t\tchoice_batch_size: int = 10,\n\t\tchoice_top_k: int = 2,\n\t\tformat_node_batch_fn: Optional[Callable] = None,\n\t\tparse_choice_select_answer_fn: Optional[Callable] = None,\n\t):\n\t\tself._summary_nodes = summary_nodes\n\t\tself._choice_select_prompt = (choice_select_prompt or DOC_CHOICE_SELECT_PROMPT)\n\t\tself._choice_batch_size = choice_batch_size\n\t\tself._choice_top_k = choice_top_k\n\t\tself._format_node_batch_fn = (format_node_batch_fn or default_format_node_batch_fn)\n\t\tself._parse_choice_select_answer_fn = (parse_choice_select_answer_fn or default_parse_choice_select_answer_fn)\n\t\tself._llm = llm or Settings.llm\n\n\tdef select(\n\t\tself,\n\t\titem_to_be_retrieved: str,\n\t) -&gt; List[str]:\n\t\tr\"\"\"\n\t\tSelect from the paper summaries according to the relevance to the retrieving string.\n\n\t\tArgs:\n\t\t\titem_to_be_retrieved (str): The retrieving string.\n\n\t\tReturn the ref_doc_ids, titles, possessors of the selected docs.\n\t\t\"\"\"\n\t\tall_nodes: List[BaseNode] = []\n\t\tall_relevances: List[float] = []\n\t\tfor idx in range(0, len(self._summary_nodes), self._choice_batch_size):\n\t\t\tsummary_nodes = self._summary_nodes[idx: idx + self._choice_batch_size]\n\t\t\tfmt_batch_str = self._format_node_batch_fn(summary_nodes)\n\t\t\t# call each batch independently\n\t\t\traw_response = self._llm.predict(\n\t\t\t\tself._choice_select_prompt,\n\t\t\t\tcontext_str=fmt_batch_str,\n\t\t\t\tquery_str=item_to_be_retrieved,\n\t\t\t)\n\n\t\t\traw_choices, relevances = self._parse_choice_select_answer_fn(raw_response, len(summary_nodes))\n\t\t\tchoice_idxs = [choice - 1 for choice in raw_choices]\n\n\t\t\tchoice_summary_nodes = [summary_nodes[ci] for ci in choice_idxs]\n\n\t\t\tall_nodes.extend(choice_summary_nodes)\n\t\t\tall_relevances.extend(relevances)\n\n\t\tzipped_list = list(zip(all_nodes, all_relevances))\n\t\tsorted_list = sorted(zipped_list, key=lambda x: x[1], reverse=True)\n\t\ttop_k_list = sorted_list[: self._choice_top_k]\n\n\t\tdoc_ids = [node.ref_doc_id for node, relevance in top_k_list]\n\t\treturn doc_ids\n\n\tasync def aselect(\n\t\tself,\n\t\titem_to_be_retrieved: str,\n\t) -&gt; List[str]:\n\t\tr\"\"\"\n\t\tAsynchronously select from the paper summaries according to the relevance to the retrieving string.\n\n\t\tArgs:\n\t\t\titem_to_be_retrieved (str): The retrieving string.\n\n\t\tReturn the ref_doc_ids, titles, possessors of the selected docs.\n\t\t\"\"\"\n\t\tall_nodes: List[BaseNode] = []\n\t\tall_relevances: List[float] = []\n\t\tfor idx in range(0, len(self._summary_nodes), self._choice_batch_size):\n\t\t\tsummary_nodes = self._summary_nodes[idx: idx + self._choice_batch_size]\n\t\t\tfmt_batch_str = self._format_node_batch_fn(summary_nodes)\n\t\t\t# call each batch independently\n\t\t\traw_response = await self._llm.apredict(\n\t\t\t\tself._choice_select_prompt,\n\t\t\t\tcontext_str=fmt_batch_str,\n\t\t\t\tquery_str=item_to_be_retrieved,\n\t\t\t)\n\t\t\traw_choices, relevances = self._parse_choice_select_answer_fn(raw_response, len(summary_nodes))\n\t\t\tchoice_idxs = [choice - 1 for choice in raw_choices]\n\n\t\t\tchoice_summary_nodes = [summary_nodes[ci] for ci in choice_idxs]\n\n\t\t\tall_nodes.extend(choice_summary_nodes)\n\t\t\tall_relevances.extend(relevances)\n\n\t\tzipped_list = list(zip(all_nodes, all_relevances))\n\t\tsorted_list = sorted(zipped_list, key=lambda x: x[1], reverse=True)\n\t\ttop_k_list = sorted_list[: self._choice_top_k]\n\n\t\tdoc_ids = [node.ref_doc_id for node, relevance in top_k_list]\n\t\treturn doc_ids\n</code></pre>"},{"location":"code_docs/func_modules/paper/retrieve/paper_retriever/#labridge.func_modules.paper.retrieve.paper_retriever.PaperSummaryLLMPostSelector.aselect","title":"<code>labridge.func_modules.paper.retrieve.paper_retriever.PaperSummaryLLMPostSelector.aselect(item_to_be_retrieved)</code>  <code>async</code>","text":"<p>Asynchronously select from the paper summaries according to the relevance to the retrieving string.</p> PARAMETER DESCRIPTION <code>item_to_be_retrieved</code> <p>The retrieving string.</p> <p> TYPE: <code>str</code> </p> <p>Return the ref_doc_ids, titles, possessors of the selected docs.</p> Source code in <code>labridge\\func_modules\\paper\\retrieve\\paper_retriever.py</code> <pre><code>async def aselect(\n\tself,\n\titem_to_be_retrieved: str,\n) -&gt; List[str]:\n\tr\"\"\"\n\tAsynchronously select from the paper summaries according to the relevance to the retrieving string.\n\n\tArgs:\n\t\titem_to_be_retrieved (str): The retrieving string.\n\n\tReturn the ref_doc_ids, titles, possessors of the selected docs.\n\t\"\"\"\n\tall_nodes: List[BaseNode] = []\n\tall_relevances: List[float] = []\n\tfor idx in range(0, len(self._summary_nodes), self._choice_batch_size):\n\t\tsummary_nodes = self._summary_nodes[idx: idx + self._choice_batch_size]\n\t\tfmt_batch_str = self._format_node_batch_fn(summary_nodes)\n\t\t# call each batch independently\n\t\traw_response = await self._llm.apredict(\n\t\t\tself._choice_select_prompt,\n\t\t\tcontext_str=fmt_batch_str,\n\t\t\tquery_str=item_to_be_retrieved,\n\t\t)\n\t\traw_choices, relevances = self._parse_choice_select_answer_fn(raw_response, len(summary_nodes))\n\t\tchoice_idxs = [choice - 1 for choice in raw_choices]\n\n\t\tchoice_summary_nodes = [summary_nodes[ci] for ci in choice_idxs]\n\n\t\tall_nodes.extend(choice_summary_nodes)\n\t\tall_relevances.extend(relevances)\n\n\tzipped_list = list(zip(all_nodes, all_relevances))\n\tsorted_list = sorted(zipped_list, key=lambda x: x[1], reverse=True)\n\ttop_k_list = sorted_list[: self._choice_top_k]\n\n\tdoc_ids = [node.ref_doc_id for node, relevance in top_k_list]\n\treturn doc_ids\n</code></pre>"},{"location":"code_docs/func_modules/paper/retrieve/paper_retriever/#labridge.func_modules.paper.retrieve.paper_retriever.PaperSummaryLLMPostSelector.select","title":"<code>labridge.func_modules.paper.retrieve.paper_retriever.PaperSummaryLLMPostSelector.select(item_to_be_retrieved)</code>","text":"<p>Select from the paper summaries according to the relevance to the retrieving string.</p> PARAMETER DESCRIPTION <code>item_to_be_retrieved</code> <p>The retrieving string.</p> <p> TYPE: <code>str</code> </p> <p>Return the ref_doc_ids, titles, possessors of the selected docs.</p> Source code in <code>labridge\\func_modules\\paper\\retrieve\\paper_retriever.py</code> <pre><code>def select(\n\tself,\n\titem_to_be_retrieved: str,\n) -&gt; List[str]:\n\tr\"\"\"\n\tSelect from the paper summaries according to the relevance to the retrieving string.\n\n\tArgs:\n\t\titem_to_be_retrieved (str): The retrieving string.\n\n\tReturn the ref_doc_ids, titles, possessors of the selected docs.\n\t\"\"\"\n\tall_nodes: List[BaseNode] = []\n\tall_relevances: List[float] = []\n\tfor idx in range(0, len(self._summary_nodes), self._choice_batch_size):\n\t\tsummary_nodes = self._summary_nodes[idx: idx + self._choice_batch_size]\n\t\tfmt_batch_str = self._format_node_batch_fn(summary_nodes)\n\t\t# call each batch independently\n\t\traw_response = self._llm.predict(\n\t\t\tself._choice_select_prompt,\n\t\t\tcontext_str=fmt_batch_str,\n\t\t\tquery_str=item_to_be_retrieved,\n\t\t)\n\n\t\traw_choices, relevances = self._parse_choice_select_answer_fn(raw_response, len(summary_nodes))\n\t\tchoice_idxs = [choice - 1 for choice in raw_choices]\n\n\t\tchoice_summary_nodes = [summary_nodes[ci] for ci in choice_idxs]\n\n\t\tall_nodes.extend(choice_summary_nodes)\n\t\tall_relevances.extend(relevances)\n\n\tzipped_list = list(zip(all_nodes, all_relevances))\n\tsorted_list = sorted(zipped_list, key=lambda x: x[1], reverse=True)\n\ttop_k_list = sorted_list[: self._choice_top_k]\n\n\tdoc_ids = [node.ref_doc_id for node, relevance in top_k_list]\n\treturn doc_ids\n</code></pre>"},{"location":"code_docs/func_modules/paper/retrieve/shared_paper_retrieve/","title":"Shared paper retrieve","text":""},{"location":"code_docs/func_modules/paper/retrieve/shared_paper_retrieve/#labridge.func_modules.paper.retrieve.shared_paper_retrieve","title":"<code>labridge.func_modules.paper.retrieve.shared_paper_retrieve</code>","text":""},{"location":"code_docs/func_modules/paper/retrieve/shared_paper_retrieve/#labridge.func_modules.paper.retrieve.shared_paper_retrieve.PaperSummaryLLMPostSelector","title":"<code>labridge.func_modules.paper.retrieve.shared_paper_retrieve.PaperSummaryLLMPostSelector</code>","text":"<p>Use LLM to re-rank the retrieved papers obtained by vector_retriever and summary_retriever, according to their summaries.</p> Source code in <code>labridge\\func_modules\\paper\\retrieve\\shared_paper_retrieve.py</code> <pre><code>class PaperSummaryLLMPostSelector:\n\tr\"\"\"\n\tUse LLM to re-rank the retrieved papers obtained by vector_retriever and summary_retriever,\n\taccording to their summaries.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tsummary_nodes: List[BaseNode],\n\t\tllm: Optional[LLM] = None,\n\t\tchoice_select_prompt: Optional[BasePromptTemplate] = None,\n\t\tchoice_batch_size: int = 10,\n\t\tchoice_top_k: int = PAPER_TOP_K,\n\t\tformat_node_batch_fn: Optional[Callable] = None,\n\t\tparse_choice_select_answer_fn: Optional[Callable] = None,\n\t):\n\t\tself._summary_nodes = summary_nodes\n\t\tself._choice_select_prompt = (choice_select_prompt or DOC_CHOICE_SELECT_PROMPT)\n\t\tself._choice_batch_size = choice_batch_size\n\t\tself._choice_top_k = choice_top_k\n\t\tself._format_node_batch_fn = (format_node_batch_fn or default_format_node_batch_fn)\n\t\tself._parse_choice_select_answer_fn = (parse_choice_select_answer_fn or default_parse_choice_select_answer_fn)\n\t\tself._llm = llm or Settings.llm\n\n\tdef format_batch_summaries(self, batch_summaries: List[str], ) -&gt; str:\n\t\t\"\"\"\n\t\tFormatted batch summaries.\n\t\t\"\"\"\n\t\tfmt_node_txts = []\n\t\tfor idx in range(len(batch_summaries)):\n\t\t\tnumber = idx + 1\n\t\t\tfmt_node_txts.append(\n\t\t\t\tf\"Document {number}:\\n\"\n\t\t\t\tf\"{batch_summaries[idx]}\"\n\t\t\t)\n\t\treturn \"\\n\\n\".join(fmt_node_txts)\n\n\tdef select(\n\t\tself,\n\t\titem_to_be_retrieved: str,\n\t\tpaper_summaries: Dict[str, str]\n\t) -&gt; List[str]:\n\t\tr\"\"\"\n\t\tSelect from the paper summaries according to the relevance to the retrieving string.\n\n\t\tArgs:\n\t\t\titem_to_be_retrieved (str): The retrieving string.\n\t\t\tpaper_summaries (Dict[str, str]): Key: paper_node_id, value: paper summary.\n\n\t\tReturn the ref_doc_ids, titles, possessors of the selected docs.\n\t\t\"\"\"\n\t\tall_paper_ids: List[str] = []\n\t\tall_relevances: List[float] = []\n\n\t\tpaper_ids = list(paper_summaries.keys())\n\t\tsummaries = [paper_summaries[key] for key in paper_ids]\n\n\t\tfor idx in range(0, len(summaries), self._choice_batch_size):\n\t\t\tbatch_summaries = summaries[idx: idx + self._choice_batch_size]\n\t\t\tbatch_paper_ids = paper_ids[idx: idx + self._choice_batch_size]\n\t\t\tfmt_batch_str = self.format_batch_summaries(batch_summaries=batch_summaries)\n\t\t\t# call each batch independently\n\t\t\traw_response = self._llm.predict(\n\t\t\t\tself._choice_select_prompt,\n\t\t\t\tcontext_str=fmt_batch_str,\n\t\t\t\tquery_str=item_to_be_retrieved,\n\t\t\t)\n\t\t\traw_choices, relevances = self._parse_choice_select_answer_fn(raw_response, len(summaries))\n\t\t\tchoice_idxs = [choice - 1 for choice in raw_choices]\n\t\t\tchoice_ids = [batch_paper_ids[ci] for ci in choice_idxs]\n\n\t\t\tall_paper_ids.extend(choice_ids)\n\t\t\tall_relevances.extend(relevances)\n\n\t\tzipped_list = list(zip(all_paper_ids, all_relevances))\n\t\tsorted_list = sorted(zipped_list, key=lambda x: x[1], reverse=True)\n\t\ttop_k_list = sorted_list[: self._choice_top_k]\n\n\t\tselected_paper_ids = [paper_id for paper_id, relevance in top_k_list]\n\t\treturn selected_paper_ids\n\n\tasync def aselect(\n\t\tself,\n\t\titem_to_be_retrieved: str,\n\t\tpaper_summaries: Dict[str, str],\n\t) -&gt; List[str]:\n\t\tr\"\"\"\n\t\tAsynchronously select from the paper summaries according to the relevance to the retrieving string.\n\n\t\tArgs:\n\t\t\titem_to_be_retrieved (str): The retrieving string.\n\t\t\tpaper_summaries (Dict[str, str]): Key: paper_node_id, value: paper summary.\n\n\t\tReturn the ref_doc_ids, titles, possessors of the selected docs.\n\t\t\"\"\"\n\t\tall_paper_ids: List[str] = []\n\t\tall_relevances: List[float] = []\n\n\t\tpaper_ids = list(paper_summaries.keys())\n\t\tsummaries = [paper_summaries[key] for key in paper_ids]\n\n\t\tfor idx in range(0, len(summaries), self._choice_batch_size):\n\t\t\tbatch_summaries = summaries[idx: idx + self._choice_batch_size]\n\t\t\tbatch_paper_ids = paper_ids[idx: idx + self._choice_batch_size]\n\t\t\tfmt_batch_str = self.format_batch_summaries(batch_summaries=batch_summaries)\n\t\t\t# call each batch independently\n\t\t\traw_response = await self._llm.apredict(\n\t\t\t\tself._choice_select_prompt,\n\t\t\t\tcontext_str=fmt_batch_str,\n\t\t\t\tquery_str=item_to_be_retrieved,\n\t\t\t)\n\n\t\t\traw_choices, relevances = self._parse_choice_select_answer_fn(raw_response, len(summaries))\n\t\t\tchoice_idxs = [choice - 1 for choice in raw_choices]\n\t\t\tchoice_ids = [batch_paper_ids[ci] for ci in choice_idxs]\n\n\t\t\tall_paper_ids.extend(choice_ids)\n\t\t\tall_relevances.extend(relevances)\n\n\t\tzipped_list = list(zip(all_paper_ids, all_relevances))\n\t\tsorted_list = sorted(zipped_list, key=lambda x: x[1], reverse=True)\n\t\ttop_k_list = sorted_list[: self._choice_top_k]\n\n\t\tselected_paper_ids = [paper_id for paper_id, relevance in top_k_list]\n\t\treturn selected_paper_ids\n</code></pre>"},{"location":"code_docs/func_modules/paper/retrieve/shared_paper_retrieve/#labridge.func_modules.paper.retrieve.shared_paper_retrieve.PaperSummaryLLMPostSelector.aselect","title":"<code>labridge.func_modules.paper.retrieve.shared_paper_retrieve.PaperSummaryLLMPostSelector.aselect(item_to_be_retrieved, paper_summaries)</code>  <code>async</code>","text":"<p>Asynchronously select from the paper summaries according to the relevance to the retrieving string.</p> PARAMETER DESCRIPTION <code>item_to_be_retrieved</code> <p>The retrieving string.</p> <p> TYPE: <code>str</code> </p> <code>paper_summaries</code> <p> TYPE: <code>Dict[str, str]</code> </p> <p>Return the ref_doc_ids, titles, possessors of the selected docs.</p> Source code in <code>labridge\\func_modules\\paper\\retrieve\\shared_paper_retrieve.py</code> <pre><code>async def aselect(\n\tself,\n\titem_to_be_retrieved: str,\n\tpaper_summaries: Dict[str, str],\n) -&gt; List[str]:\n\tr\"\"\"\n\tAsynchronously select from the paper summaries according to the relevance to the retrieving string.\n\n\tArgs:\n\t\titem_to_be_retrieved (str): The retrieving string.\n\t\tpaper_summaries (Dict[str, str]): Key: paper_node_id, value: paper summary.\n\n\tReturn the ref_doc_ids, titles, possessors of the selected docs.\n\t\"\"\"\n\tall_paper_ids: List[str] = []\n\tall_relevances: List[float] = []\n\n\tpaper_ids = list(paper_summaries.keys())\n\tsummaries = [paper_summaries[key] for key in paper_ids]\n\n\tfor idx in range(0, len(summaries), self._choice_batch_size):\n\t\tbatch_summaries = summaries[idx: idx + self._choice_batch_size]\n\t\tbatch_paper_ids = paper_ids[idx: idx + self._choice_batch_size]\n\t\tfmt_batch_str = self.format_batch_summaries(batch_summaries=batch_summaries)\n\t\t# call each batch independently\n\t\traw_response = await self._llm.apredict(\n\t\t\tself._choice_select_prompt,\n\t\t\tcontext_str=fmt_batch_str,\n\t\t\tquery_str=item_to_be_retrieved,\n\t\t)\n\n\t\traw_choices, relevances = self._parse_choice_select_answer_fn(raw_response, len(summaries))\n\t\tchoice_idxs = [choice - 1 for choice in raw_choices]\n\t\tchoice_ids = [batch_paper_ids[ci] for ci in choice_idxs]\n\n\t\tall_paper_ids.extend(choice_ids)\n\t\tall_relevances.extend(relevances)\n\n\tzipped_list = list(zip(all_paper_ids, all_relevances))\n\tsorted_list = sorted(zipped_list, key=lambda x: x[1], reverse=True)\n\ttop_k_list = sorted_list[: self._choice_top_k]\n\n\tselected_paper_ids = [paper_id for paper_id, relevance in top_k_list]\n\treturn selected_paper_ids\n</code></pre>"},{"location":"code_docs/func_modules/paper/retrieve/shared_paper_retrieve/#labridge.func_modules.paper.retrieve.shared_paper_retrieve.PaperSummaryLLMPostSelector.format_batch_summaries","title":"<code>labridge.func_modules.paper.retrieve.shared_paper_retrieve.PaperSummaryLLMPostSelector.format_batch_summaries(batch_summaries)</code>","text":"<p>Formatted batch summaries.</p> Source code in <code>labridge\\func_modules\\paper\\retrieve\\shared_paper_retrieve.py</code> <pre><code>def format_batch_summaries(self, batch_summaries: List[str], ) -&gt; str:\n\t\"\"\"\n\tFormatted batch summaries.\n\t\"\"\"\n\tfmt_node_txts = []\n\tfor idx in range(len(batch_summaries)):\n\t\tnumber = idx + 1\n\t\tfmt_node_txts.append(\n\t\t\tf\"Document {number}:\\n\"\n\t\t\tf\"{batch_summaries[idx]}\"\n\t\t)\n\treturn \"\\n\\n\".join(fmt_node_txts)\n</code></pre>"},{"location":"code_docs/func_modules/paper/retrieve/shared_paper_retrieve/#labridge.func_modules.paper.retrieve.shared_paper_retrieve.PaperSummaryLLMPostSelector.select","title":"<code>labridge.func_modules.paper.retrieve.shared_paper_retrieve.PaperSummaryLLMPostSelector.select(item_to_be_retrieved, paper_summaries)</code>","text":"<p>Select from the paper summaries according to the relevance to the retrieving string.</p> PARAMETER DESCRIPTION <code>item_to_be_retrieved</code> <p>The retrieving string.</p> <p> TYPE: <code>str</code> </p> <code>paper_summaries</code> <p> TYPE: <code>Dict[str, str]</code> </p> <p>Return the ref_doc_ids, titles, possessors of the selected docs.</p> Source code in <code>labridge\\func_modules\\paper\\retrieve\\shared_paper_retrieve.py</code> <pre><code>def select(\n\tself,\n\titem_to_be_retrieved: str,\n\tpaper_summaries: Dict[str, str]\n) -&gt; List[str]:\n\tr\"\"\"\n\tSelect from the paper summaries according to the relevance to the retrieving string.\n\n\tArgs:\n\t\titem_to_be_retrieved (str): The retrieving string.\n\t\tpaper_summaries (Dict[str, str]): Key: paper_node_id, value: paper summary.\n\n\tReturn the ref_doc_ids, titles, possessors of the selected docs.\n\t\"\"\"\n\tall_paper_ids: List[str] = []\n\tall_relevances: List[float] = []\n\n\tpaper_ids = list(paper_summaries.keys())\n\tsummaries = [paper_summaries[key] for key in paper_ids]\n\n\tfor idx in range(0, len(summaries), self._choice_batch_size):\n\t\tbatch_summaries = summaries[idx: idx + self._choice_batch_size]\n\t\tbatch_paper_ids = paper_ids[idx: idx + self._choice_batch_size]\n\t\tfmt_batch_str = self.format_batch_summaries(batch_summaries=batch_summaries)\n\t\t# call each batch independently\n\t\traw_response = self._llm.predict(\n\t\t\tself._choice_select_prompt,\n\t\t\tcontext_str=fmt_batch_str,\n\t\t\tquery_str=item_to_be_retrieved,\n\t\t)\n\t\traw_choices, relevances = self._parse_choice_select_answer_fn(raw_response, len(summaries))\n\t\tchoice_idxs = [choice - 1 for choice in raw_choices]\n\t\tchoice_ids = [batch_paper_ids[ci] for ci in choice_idxs]\n\n\t\tall_paper_ids.extend(choice_ids)\n\t\tall_relevances.extend(relevances)\n\n\tzipped_list = list(zip(all_paper_ids, all_relevances))\n\tsorted_list = sorted(zipped_list, key=lambda x: x[1], reverse=True)\n\ttop_k_list = sorted_list[: self._choice_top_k]\n\n\tselected_paper_ids = [paper_id for paper_id, relevance in top_k_list]\n\treturn selected_paper_ids\n</code></pre>"},{"location":"code_docs/func_modules/paper/retrieve/shared_paper_retrieve/#labridge.func_modules.paper.retrieve.shared_paper_retrieve.SharedPaperRetriever","title":"<code>labridge.func_modules.paper.retrieve.shared_paper_retrieve.SharedPaperRetriever</code>","text":"Source code in <code>labridge\\func_modules\\paper\\retrieve\\shared_paper_retrieve.py</code> <pre><code>class SharedPaperRetriever:\n\n\tdef __init__(\n\t\tself,\n\t\tllm: LLM,\n\t\tembed_model: BaseEmbedding,\n\t\tshared_vector_index: VectorStoreIndex,\n\t\tvector_similarity_top_k: int = PAPER_VECTOR_TOP_K,\n\t\tpapers_top_k: int = PAPER_TOP_K,\n\t\tre_retrieve_top_k: int = PAPER_RETRIEVE_TOP_K,\n\t\tfinal_use_context: bool = True,\n\t\tfinal_use_summary: bool = True,\n\t):\n\t\tself.paper_summary_post_selector = PaperSummaryLLMPostSelector(\n\t\t\tsummary_nodes=[],\n\t\t\tllm=llm,\n\t\t\tchoice_top_k=papers_top_k,\n\t\t)\n\t\tself.shared_vector_index = shared_vector_index\n\t\tself.shared_paper_retriever = shared_vector_index.as_retriever(similarity_top_k=vector_similarity_top_k)\n\t\tself.vector_similarity_top_k = vector_similarity_top_k\n\t\tself.re_retrieve_top_k = re_retrieve_top_k\n\t\tself.final_use_context = final_use_context\n\t\tself.final_use_summary = final_use_summary\n\t\tself._account_manager = AccountManager()\n\t\troot = Path(__file__)\n\t\tfor i in range(5):\n\t\t\troot = root.parent\n\t\tself.root = root\n\n\t@classmethod\n\tdef from_storage(\n\t\tcls,\n\t\tllm: Optional[LLM] = None,\n\t\tembed_model: Optional[BaseEmbedding] = None,\n\t\tvector_persist_dir: Optional[str] = None,\n\t\tvector_similarity_top_k: Optional[int] = PAPER_VECTOR_TOP_K,\n\t\tpapers_top_k: int = PAPER_TOP_K,\n\t\tre_retrieve_top_k: int = PAPER_RETRIEVE_TOP_K,\n\t\tservice_context: Optional[ServiceContext] = None,\n\t\tfinal_use_context: bool = True,\n\t\tfinal_use_summary: bool = True,\n\t):\n\t\tr\"\"\"\n\t\tLoad from an existing storage.\n\t\t\"\"\"\n\t\troot = Path(__file__)\n\t\tfor i in range(5):\n\t\t\troot = root.parent\n\n\t\tllm = llm or llm_from_settings_or_context(Settings, service_context)\n\t\tembed_model = embed_model or embed_model_from_settings_or_context(Settings, service_context)\n\n\t\tvector_persist_dir = vector_persist_dir or root / SHARED_PAPER_VECTOR_INDEX_PERSIST_DIR\n\t\tvector_storage_context = StorageContext.from_defaults(persist_dir=vector_persist_dir)\n\t\tshared_vector_index = load_index_from_storage(\n\t\t\tstorage_context=vector_storage_context,\n\t\t\tindex_id=SHARED_PAPER_VECTOR_INDEX_ID,\n\t\t\tembed_model=embed_model,\n\t\t)\n\t\treturn cls(\n\t\t\tllm=llm,\n\t\t\tembed_model=embed_model,\n\t\t\tshared_vector_index = shared_vector_index,\n\t\t\tvector_similarity_top_k=vector_similarity_top_k,\n\t\t\tpapers_top_k=papers_top_k,\n\t\t\tre_retrieve_top_k=re_retrieve_top_k,\n\t\t\tfinal_use_context=final_use_context,\n\t\t\tfinal_use_summary=final_use_summary,\n\t\t)\n\n\t@property\n\tdef _chunk_node_filter(self) -&gt; MetadataFilter:\n\t\tchunk_type_filter = MetadataFilter(\n\t\t\tkey=SHARED_PAPER_NODE_TYPE,\n\t\t\tvalue=SharedPaperNodeType.PAPER_CHUNK,\n\t\t\toperator=FilterOperator.EQ,\n\t\t)\n\t\treturn chunk_type_filter\n\n\tdef _user_filter(self, user_id: str) -&gt; MetadataFilter:\n\t\tself._account_manager.check_valid_user(user_id=user_id)\n\t\tuser_id_filter = MetadataFilter(\n\t\t\tkey=PAPER_POSSESSOR,\n\t\t\tvalue=user_id,\n\t\t\toperator=FilterOperator.EQ,\n\t\t)\n\t\treturn user_id_filter\n\n\tdef get_parent_summaries(self, chunk_nodes: List[NodeWithScore]) -&gt; Optional[Dict[str, str]]:\n\t\tpaper_ids = set()\n\t\tfor node_score in chunk_nodes:\n\t\t\tpaper_id = node_score.node.parent_node.node_id\n\t\t\tpaper_ids.add(paper_id)\n\n\t\tpaper_nodes = self.shared_vector_index.docstore.get_nodes(node_ids=list(paper_ids))\n\t\tpaper_themes = {}\n\t\tfor node in paper_nodes:\n\t\t\ttheme = \"\"\n\t\t\tsummary = node.metadata.get(SHARED_PAPER_SUMMARY_KEY, None)\n\t\t\tabstract = node.metadata.get(PAPER_ABSTRACT, None)\n\t\t\tif summary is None and abstract is None:\n\t\t\t\tcontinue\n\n\t\t\tif abstract:\n\t\t\t\ttheme += f\"Abstract:\\n{abstract}\\n\"\n\t\t\tif summary:\n\t\t\t\ttheme += f\"Summary:\\n{summary}\\n\"\n\t\t\tpaper_themes[node.node_id] = theme\n\n\t\tif len(paper_themes.keys()) &lt; 1:\n\t\t\treturn None\n\t\treturn paper_themes\n\n\tdef _reset_retriever(self, target_user_id: str = None):\n\t\tfilters = [self._chunk_node_filter, ]\n\n\t\tif target_user_id is not None:\n\t\t\tfilters.append(self._user_filter(user_id=target_user_id))\n\n\t\tself.shared_paper_retriever._filters = MetadataFilters(filters=filters)\n\t\tself.shared_paper_retriever._similarity_top_k = self.vector_similarity_top_k\n\n\tdef _add_summary_nodes(self, retrieved_nodes: List[NodeWithScore]) -&gt; List[NodeWithScore]:\n\t\tpaper_summaries = self.get_parent_summaries(chunk_nodes=retrieved_nodes)\n\n\t\tsummary_nodes = []\n\t\tfor paper_id in paper_summaries.keys():\n\t\t\tpaper_node = self.shared_vector_index.docstore.get_node(node_id=paper_id)\n\t\t\ttitle = paper_node.metadata[PAPER_TITLE]\n\t\t\tsummary = paper_summaries[paper_id]\n\t\t\tsummary_node = TextNode(\n\t\t\t\ttext=f\"Title: {title}\\n\\nSummary:\\n{summary}\",\n\t\t\t\tmetadata={\n\t\t\t\t\tPAPER_REL_FILE_PATH: paper_node.metadata[PAPER_REL_FILE_PATH],\n\t\t\t\t}\n\t\t\t)\n\t\t\tsummary_nodes.append(NodeWithScore(node=summary_node))\n\n\t\tretrieved_nodes.extend(summary_nodes)\n\t\treturn retrieved_nodes\n\n\tdef _add_context(self, content_nodes: List[NodeWithScore]) -&gt; List[NodeWithScore]:\n\t\tr\"\"\"\n\t\tGet the 1-hop context nodes of each content node retrieved in the secondary retrieving.\n\t\t\"\"\"\n\t\tcontent_ids = [node.node.node_id for node in content_nodes]\n\t\tnew_ids = []\n\t\tfor node in content_nodes:\n\t\t\tprev_node = node.node.prev_node\n\t\t\tnext_node = node.node.next_node\n\t\t\tif prev_node is not None:\n\t\t\t\tprev_id = node.node.prev_node.node_id\n\t\t\t\tif prev_id not in content_ids:\n\t\t\t\t\tcontent_ids.append(prev_id)\n\t\t\t\t\tnew_ids.append(prev_id)\n\n\t\t\tnew_ids.append(node.node_id)\n\n\t\t\tif next_node is not None:\n\t\t\t\tnext_id = node.node.next_node.node_id\n\t\t\t\tif next_id not in content_ids:\n\t\t\t\t\tcontent_ids.append(next_id)\n\t\t\t\t\tnew_ids.append(next_id)\n\n\t\tcontext_nodes = self.shared_vector_index.docstore.get_nodes(new_ids)\n\t\t# exclude metadata in LLM using.\n\t\tself._exclude_all_llm_metadata(nodes=context_nodes)\n\t\tcontext_nodes = [NodeWithScore(node=node) for node in context_nodes]\n\t\treturn context_nodes\n\n\tdef _exclude_all_llm_metadata(self, nodes: List[BaseNode]):\n\t\tr\"\"\" Hidden all metadata of a node to LLM. \"\"\"\n\t\tfor node in nodes:\n\t\t\tnode.excluded_llm_metadata_keys.extend(list(node.metadata.keys()))\n\n\tdef _exclude_all_embedding_metadata(self, nodes: List[BaseNode]):\n\t\tr\"\"\" Hidden all metadata of a node to the embed model. \"\"\"\n\t\tfor node in nodes:\n\t\t\tnode.excluded_embed_metadata_keys.extend(list(node.metadata.keys()))\n\n\tdef secondary_retrieve(\n\t\tself,\n\t\titem_to_be_retrieved: str,\n\t\tpaper_ids: List[str],\n\t) -&gt; List[NodeWithScore]:\n\t\tnode_ids = []\n\t\tfor paper_id in paper_ids:\n\t\t\tpaper_node = self.shared_vector_index.docstore.get_node(node_id=paper_id)\n\t\t\tchunk_ids = [node.node_id for node in paper_node.child_nodes]\n\t\t\tnode_ids.extend(chunk_ids)\n\n\t\tchunk_nodes = self.shared_vector_index.docstore.get_nodes(node_ids=node_ids)\n\t\tself._exclude_all_llm_metadata(nodes=chunk_nodes)\n\t\tself._exclude_all_embedding_metadata(nodes=chunk_nodes)\n\n\t\tcontent_index = VectorStoreIndex(nodes=chunk_nodes, embed_model=self.shared_vector_index._embed_model)\n\t\tcontent_retriever = content_index.as_retriever(similarity_top_k=self.re_retrieve_top_k)\n\t\tretrieved_nodes = content_retriever.retrieve(item_to_be_retrieved)\n\n\t\tif self.final_use_context:\n\t\t\tretrieved_nodes = self._add_context(content_nodes=retrieved_nodes)\n\t\tif self.final_use_summary:\n\t\t\tretrieved_nodes = self._add_summary_nodes(retrieved_nodes=retrieved_nodes)\n\t\treturn retrieved_nodes\n\n\tasync def asecondary_retrieve(\n\t\tself,\n\t\titem_to_be_retrieved: str,\n\t\tpaper_ids: List[str],\n\t) -&gt; List[NodeWithScore]:\n\t\tnode_ids = []\n\t\tfor paper_id in paper_ids:\n\t\t\tpaper_node = self.shared_vector_index.docstore.get_node(node_id=paper_id)\n\t\t\tchunk_ids = [node.node_id for node in paper_node.child_nodes]\n\t\t\tnode_ids.extend(chunk_ids)\n\n\t\tchunk_nodes = self.shared_vector_index.docstore.get_nodes(node_ids=node_ids)\n\t\tself._exclude_all_llm_metadata(nodes=chunk_nodes)\n\t\tself._exclude_all_embedding_metadata(nodes=chunk_nodes)\n\n\t\tcontent_index = VectorStoreIndex(nodes=chunk_nodes, embed_model=self.shared_vector_index._embed_model)\n\t\tcontent_retriever = content_index.as_retriever(similarity_top_k=self.re_retrieve_top_k)\n\t\tretrieved_nodes = await content_retriever.aretrieve(item_to_be_retrieved)\n\n\t\tif self.final_use_context:\n\t\t\tretrieved_nodes = self._add_context(content_nodes=retrieved_nodes)\n\t\tif self.final_use_summary:\n\t\t\tretrieved_nodes = self._add_summary_nodes(retrieved_nodes=retrieved_nodes)\n\t\treturn retrieved_nodes\n\n\tdef retrieve(\n\t\tself,\n\t\titem_to_be_retrieved: str,\n\t\ttarget_user_id: str = None,\n\t) -&gt; List[NodeWithScore]:\n\t\tr\"\"\"\n\t\tThis tool is used to retrieve academic information in the Laboratory's shared paper database.\n\t\tIt is useful to help answer the user's academic questions.\n\n\t\tArgs:\n\t\t\titem_to_be_retrieved (str): The things that you want to retrieve in the shared paper database.\n\t\t\ttarget_user_id (str): If given, the retrieval range will be confined to the papers belonging to the given user.\n\t\t\t\tDefaults to None.\n\t\t\"\"\"\n\t\t# This docstring is used as the tool description.\n\t\tself._reset_retriever(target_user_id=target_user_id)\n\t\tchunk_nodes = self.shared_paper_retriever.retrieve(item_to_be_retrieved)\n\t\tpaper_summaries = self.get_parent_summaries(chunk_nodes=chunk_nodes)\n\t\tif paper_summaries is None:\n\t\t\treturn []\n\n\t\tfinal_paper_ids = self.paper_summary_post_selector.select(\n\t\t\titem_to_be_retrieved=item_to_be_retrieved,\n\t\t\tpaper_summaries=paper_summaries,\n\t\t)\n\n\t\tretrieved_nodes = self.secondary_retrieve(\n\t\t\titem_to_be_retrieved=item_to_be_retrieved,\n\t\t\tpaper_ids=final_paper_ids,\n\t\t)\n\t\treturn retrieved_nodes\n\n\tasync def aretrieve(\n\t\tself,\n\t\titem_to_be_retrieved: str,\n\t\ttarget_user_id: str = None,\n\t) -&gt; List[NodeWithScore]:\n\t\tr\"\"\"\n\t\tThis tool is used to retrieve academic information in the Laboratory's shared paper database.\n\t\tIt is useful to help answer the user's academic questions.\n\n\t\tArgs:\n\t\t\titem_to_be_retrieved (str): The things that you want to retrieve in the shared paper database.\n\t\t\ttarget_user_id (str): If given, the retrieval range will be confined to the papers belonging to the given user.\n\t\t\t\tDefaults to None.\n\t\t\"\"\"\n\t\t# This docstring is used as the tool description.\n\t\t# Retrieve in chunk nodes\n\t\tself._reset_retriever(target_user_id=target_user_id)\n\t\tchunk_nodes = await self.shared_paper_retriever.aretrieve(item_to_be_retrieved)\n\t\tpaper_summaries = self.get_parent_summaries(chunk_nodes=chunk_nodes)\n\t\tif paper_summaries is None:\n\t\t\treturn []\n\n\t\tfinal_paper_ids = await self.paper_summary_post_selector.aselect(\n\t\t\titem_to_be_retrieved=item_to_be_retrieved,\n\t\t\tpaper_summaries=paper_summaries,\n\t\t)\n\t\tretrieved_nodes = await self.asecondary_retrieve(\n\t\t\titem_to_be_retrieved=item_to_be_retrieved,\n\t\t\tpaper_ids=final_paper_ids,\n\t\t)\n\t\treturn retrieved_nodes\n</code></pre>"},{"location":"code_docs/func_modules/paper/retrieve/shared_paper_retrieve/#labridge.func_modules.paper.retrieve.shared_paper_retrieve.SharedPaperRetriever.aretrieve","title":"<code>labridge.func_modules.paper.retrieve.shared_paper_retrieve.SharedPaperRetriever.aretrieve(item_to_be_retrieved, target_user_id=None)</code>  <code>async</code>","text":"<p>This tool is used to retrieve academic information in the Laboratory's shared paper database. It is useful to help answer the user's academic questions.</p> PARAMETER DESCRIPTION <code>item_to_be_retrieved</code> <p>The things that you want to retrieve in the shared paper database.</p> <p> TYPE: <code>str</code> </p> <code>target_user_id</code> <p>If given, the retrieval range will be confined to the papers belonging to the given user. Defaults to None.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> Source code in <code>labridge\\func_modules\\paper\\retrieve\\shared_paper_retrieve.py</code> <pre><code>async def aretrieve(\n\tself,\n\titem_to_be_retrieved: str,\n\ttarget_user_id: str = None,\n) -&gt; List[NodeWithScore]:\n\tr\"\"\"\n\tThis tool is used to retrieve academic information in the Laboratory's shared paper database.\n\tIt is useful to help answer the user's academic questions.\n\n\tArgs:\n\t\titem_to_be_retrieved (str): The things that you want to retrieve in the shared paper database.\n\t\ttarget_user_id (str): If given, the retrieval range will be confined to the papers belonging to the given user.\n\t\t\tDefaults to None.\n\t\"\"\"\n\t# This docstring is used as the tool description.\n\t# Retrieve in chunk nodes\n\tself._reset_retriever(target_user_id=target_user_id)\n\tchunk_nodes = await self.shared_paper_retriever.aretrieve(item_to_be_retrieved)\n\tpaper_summaries = self.get_parent_summaries(chunk_nodes=chunk_nodes)\n\tif paper_summaries is None:\n\t\treturn []\n\n\tfinal_paper_ids = await self.paper_summary_post_selector.aselect(\n\t\titem_to_be_retrieved=item_to_be_retrieved,\n\t\tpaper_summaries=paper_summaries,\n\t)\n\tretrieved_nodes = await self.asecondary_retrieve(\n\t\titem_to_be_retrieved=item_to_be_retrieved,\n\t\tpaper_ids=final_paper_ids,\n\t)\n\treturn retrieved_nodes\n</code></pre>"},{"location":"code_docs/func_modules/paper/retrieve/shared_paper_retrieve/#labridge.func_modules.paper.retrieve.shared_paper_retrieve.SharedPaperRetriever.from_storage","title":"<code>labridge.func_modules.paper.retrieve.shared_paper_retrieve.SharedPaperRetriever.from_storage(llm=None, embed_model=None, vector_persist_dir=None, vector_similarity_top_k=PAPER_VECTOR_TOP_K, papers_top_k=PAPER_TOP_K, re_retrieve_top_k=PAPER_RETRIEVE_TOP_K, service_context=None, final_use_context=True, final_use_summary=True)</code>  <code>classmethod</code>","text":"<p>Load from an existing storage.</p> Source code in <code>labridge\\func_modules\\paper\\retrieve\\shared_paper_retrieve.py</code> <pre><code>@classmethod\ndef from_storage(\n\tcls,\n\tllm: Optional[LLM] = None,\n\tembed_model: Optional[BaseEmbedding] = None,\n\tvector_persist_dir: Optional[str] = None,\n\tvector_similarity_top_k: Optional[int] = PAPER_VECTOR_TOP_K,\n\tpapers_top_k: int = PAPER_TOP_K,\n\tre_retrieve_top_k: int = PAPER_RETRIEVE_TOP_K,\n\tservice_context: Optional[ServiceContext] = None,\n\tfinal_use_context: bool = True,\n\tfinal_use_summary: bool = True,\n):\n\tr\"\"\"\n\tLoad from an existing storage.\n\t\"\"\"\n\troot = Path(__file__)\n\tfor i in range(5):\n\t\troot = root.parent\n\n\tllm = llm or llm_from_settings_or_context(Settings, service_context)\n\tembed_model = embed_model or embed_model_from_settings_or_context(Settings, service_context)\n\n\tvector_persist_dir = vector_persist_dir or root / SHARED_PAPER_VECTOR_INDEX_PERSIST_DIR\n\tvector_storage_context = StorageContext.from_defaults(persist_dir=vector_persist_dir)\n\tshared_vector_index = load_index_from_storage(\n\t\tstorage_context=vector_storage_context,\n\t\tindex_id=SHARED_PAPER_VECTOR_INDEX_ID,\n\t\tembed_model=embed_model,\n\t)\n\treturn cls(\n\t\tllm=llm,\n\t\tembed_model=embed_model,\n\t\tshared_vector_index = shared_vector_index,\n\t\tvector_similarity_top_k=vector_similarity_top_k,\n\t\tpapers_top_k=papers_top_k,\n\t\tre_retrieve_top_k=re_retrieve_top_k,\n\t\tfinal_use_context=final_use_context,\n\t\tfinal_use_summary=final_use_summary,\n\t)\n</code></pre>"},{"location":"code_docs/func_modules/paper/retrieve/shared_paper_retrieve/#labridge.func_modules.paper.retrieve.shared_paper_retrieve.SharedPaperRetriever.retrieve","title":"<code>labridge.func_modules.paper.retrieve.shared_paper_retrieve.SharedPaperRetriever.retrieve(item_to_be_retrieved, target_user_id=None)</code>","text":"<p>This tool is used to retrieve academic information in the Laboratory's shared paper database. It is useful to help answer the user's academic questions.</p> PARAMETER DESCRIPTION <code>item_to_be_retrieved</code> <p>The things that you want to retrieve in the shared paper database.</p> <p> TYPE: <code>str</code> </p> <code>target_user_id</code> <p>If given, the retrieval range will be confined to the papers belonging to the given user. Defaults to None.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> Source code in <code>labridge\\func_modules\\paper\\retrieve\\shared_paper_retrieve.py</code> <pre><code>def retrieve(\n\tself,\n\titem_to_be_retrieved: str,\n\ttarget_user_id: str = None,\n) -&gt; List[NodeWithScore]:\n\tr\"\"\"\n\tThis tool is used to retrieve academic information in the Laboratory's shared paper database.\n\tIt is useful to help answer the user's academic questions.\n\n\tArgs:\n\t\titem_to_be_retrieved (str): The things that you want to retrieve in the shared paper database.\n\t\ttarget_user_id (str): If given, the retrieval range will be confined to the papers belonging to the given user.\n\t\t\tDefaults to None.\n\t\"\"\"\n\t# This docstring is used as the tool description.\n\tself._reset_retriever(target_user_id=target_user_id)\n\tchunk_nodes = self.shared_paper_retriever.retrieve(item_to_be_retrieved)\n\tpaper_summaries = self.get_parent_summaries(chunk_nodes=chunk_nodes)\n\tif paper_summaries is None:\n\t\treturn []\n\n\tfinal_paper_ids = self.paper_summary_post_selector.select(\n\t\titem_to_be_retrieved=item_to_be_retrieved,\n\t\tpaper_summaries=paper_summaries,\n\t)\n\n\tretrieved_nodes = self.secondary_retrieve(\n\t\titem_to_be_retrieved=item_to_be_retrieved,\n\t\tpaper_ids=final_paper_ids,\n\t)\n\treturn retrieved_nodes\n</code></pre>"},{"location":"code_docs/func_modules/paper/retrieve/temporary_paper_retriever/","title":"Temporary paper retriever","text":""},{"location":"code_docs/func_modules/paper/retrieve/temporary_paper_retriever/#labridge.func_modules.paper.retrieve.temporary_paper_retriever","title":"<code>labridge.func_modules.paper.retrieve.temporary_paper_retriever</code>","text":""},{"location":"code_docs/func_modules/paper/retrieve/temporary_paper_retriever/#labridge.func_modules.paper.retrieve.temporary_paper_retriever.RecentPaperRetriever","title":"<code>labridge.func_modules.paper.retrieve.temporary_paper_retriever.RecentPaperRetriever</code>","text":"<p>This class is the retriever that retrieving in the recent papers store of a specific user.</p> PARAMETER DESCRIPTION <code>embed_model</code> <p>The used embedding model. If not specified, the <code>Settings.embed_model</code> will be used.</p> <p> TYPE: <code>BaseEmbedding</code> </p> <code>final_use_context</code> <p>Whether to use the context nodes as parts of the retrieved results.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>first_top_k</code> <p>The <code>similarity_top_k</code> in the first retrieving. Refer to the method <code>retrieve</code> for details.</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> <code>secondary_top_k</code> <p>The <code>similarity_top_k</code> in the secondary retrieving. Refer to the method <code>retrieve</code> for details.</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> Source code in <code>labridge\\func_modules\\paper\\retrieve\\temporary_paper_retriever.py</code> <pre><code>class RecentPaperRetriever:\n\tr\"\"\"\n\tThis class is the retriever that retrieving in the recent papers store of a specific user.\n\n\tArgs:\n\t\tembed_model (BaseEmbedding): The used embedding model. If not specified, the `Settings.embed_model` will be used.\n\t\tfinal_use_context (bool): Whether to use the context nodes as parts of the retrieved results.\n\t\tfirst_top_k (int): The `similarity_top_k` in the first retrieving.\n\t\t\tRefer to the method `retrieve` for details.\n\t\tsecondary_top_k (int): The `similarity_top_k` in the secondary retrieving.\n\t\t\tRefer to the method `retrieve` for details.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tembed_model: BaseEmbedding,\n\t\tfinal_use_context: bool = True,\n\t\tfirst_top_k: int = None,\n\t\tsecondary_top_k: int = None,\n\t):\n\t\tself.paper_store = None\n\t\tself.paper_retriever = None\n\t\tself._embed_model = embed_model or Settings.embed_model\n\t\tself._final_use_context = final_use_context\n\t\tself._first_top_k = first_top_k or RECENT_PAPER_INFO_SIMILARITY_TOP_K\n\t\tself._relevant_top_k = secondary_top_k or RECENT_PAPER_SIMILARITY_TOP_K\n\t\tself.fs = fsspec.filesystem(\"file\")\n\n\tdef _add_context(\n\t\tself,\n\t\tcontent_nodes: List[NodeWithScore]\n\t) -&gt; List[NodeWithScore]:\n\t\tr\"\"\"\n\t\tAdd context nodes for the retrieved nodes.\n\n\t\tArgs:\n\t\t\tcontent_nodes (List[NodeWithScore]): The retrieved nodes.\n\n\t\tReturns:\n\t\t\tList[NodeWithScore]: Concatenated nodes including context nodes.\n\t\t\"\"\"\n\t\tvector_index = self.paper_store.vector_index\n\t\texisting_ids = [node.node_id for node in content_nodes]\n\t\tfinal_nodes = []\n\n\t\tfor node in content_nodes:\n\t\t\tprev_node_info = node.node.prev_node\n\t\t\tnext_node_info = node.node.next_node\n\t\t\tif prev_node_info is not None:\n\t\t\t\tprev_id = prev_node_info.node_id\n\t\t\t\tif prev_id not in existing_ids:\n\t\t\t\t\texisting_ids.append(prev_id)\n\t\t\t\t\tprev_node = vector_index.docstore.get_node(node_id=prev_id)\n\t\t\t\t\tfinal_nodes.append(NodeWithScore(node=prev_node))\n\t\t\tfinal_nodes.append(node)\n\t\t\tif next_node_info is not None:\n\t\t\t\tnext_id = next_node_info.node_id\n\t\t\t\tif next_id not in existing_ids:\n\t\t\t\t\texisting_ids.append(next_id)\n\t\t\t\t\tnext_node = vector_index.docstore.get_node(node_id=next_id)\n\t\t\t\t\tfinal_nodes.append(NodeWithScore(node=next_node))\n\t\treturn final_nodes\n\n\tdef get_paper_retriever(self) -&gt; VectorIndexRetriever:\n\t\tr\"\"\"\n\t\tGet the default paper retriever, with a node_type_filter.\n\n\t\tReturns:\n\t\t\tVectorIndexRetriever: The paper retriever.\n\t\t\"\"\"\n\t\tpaper_retriever = self.paper_store.vector_index.as_retriever(\n\t\t\tsimilarity_top_k=self._relevant_top_k,\n\t\t\tfilters=MetadataFilters(\n\t\t\t\tfilters=[self.node_type_filter]\n\t\t\t),\n\t\t)\n\t\treturn paper_retriever\n\n\t@property\n\tdef node_type_filter(self) -&gt; MetadataFilter:\n\t\tr\"\"\"\n\t\tThe node type filter that filters nodes with type `TMP_PAPER_DOC_NODE_TYPE`.\n\n\t\tReturns:\n\t\t\tMetadataFilter: The node type metadata filter.\n\t\t\"\"\"\n\t\tdoc_node_filter = MetadataFilter(\n\t\t\tkey=TMP_PAPER_NODE_TYPE_KEY,\n\t\t\tvalue=TMP_PAPER_DOC_NODE_TYPE,\n\t\t\toperator=FilterOperator.EQ,\n\t\t)\n\t\treturn doc_node_filter\n\n\tdef get_date_filter(self, date_list: List[str]) -&gt; MetadataFilter:\n\t\tr\"\"\"\n\t\tGet the date filter that filters according to the creation date of nodes.\n\n\t\tArgs:\n\t\t\tdate_list (List[str]): The date candidates. Only nodes created in one of these dates will be retrieved.\n\n\t\tReturns:\n\t\t\tMetadataFilter: The date filter.\n\t\t\"\"\"\n\t\tdate_filter = MetadataFilter(\n\t\t\tkey=TMP_PAPER_DATE,\n\t\t\tvalue=date_list,\n\t\t\toperator=FilterOperator.ANY,\n\t\t)\n\t\treturn date_filter\n\n\tdef reset_retriever(self):\n\t\tr\"\"\"\n\t\tReset the paper retriever:\n\n\t\t- reset the node_ids that confine the retrieving range.\n\t\t- reset the similarity_top_k.\n\t\t- reset the MetadataFilters.\n\n\t\tReturns:\n\t\t\tNone.\n\t\t\"\"\"\n\t\tif self.paper_retriever:\n\t\t\tself.paper_retriever._node_ids = None\n\t\t\tself.paper_retriever._similarity_top_k = self._first_top_k\n\t\t\tself.paper_retriever._filters = MetadataFilters(\n\t\t\t\tfilters=[self.node_type_filter,]\n\t\t\t)\n\n\tdef first_retrieve(self, paper_info: str) -&gt; List[str]:\n\t\tr\"\"\"\n\t\tFirst retrieve: retrieve according to the paper_info.\n\n\t\tArgs:\n\t\t\tpaper_info (str): The information about the paper.\n\n\t\tReturns:\n\t\t\tList[str]: all the node ids of relevant papers.\n\t\t\"\"\"\n\t\tself.paper_retriever._similarity_top_k = self._first_top_k\n\t\tinfo_relevant_nodes = self.paper_retriever.retrieve(paper_info)\n\t\tconfine_node_ids = self.paper_store.get_all_relevant_node_ids(\n\t\t\tnode_ids=[node.node_id for node in info_relevant_nodes]\n\t\t)\n\t\treturn confine_node_ids\n\n\tasync def afirst_retrieve(self, paper_info: str) -&gt; List[str]:\n\t\tr\"\"\"\n\t\tFirst retrieve: retrieve according to the paper_info.\n\n\t\tArgs:\n\t\t\tpaper_info (str): The information about the paper.\n\n\t\tReturns:\n\t\t\tList[str]: all the node ids of relevant papers.\n\t\t\"\"\"\n\t\tself.paper_retriever._similarity_top_k = self._first_top_k\n\t\tinfo_relevant_nodes = await self.paper_retriever.aretrieve(paper_info)\n\t\tconfine_node_ids = self.paper_store.get_all_relevant_node_ids(\n\t\t\tnode_ids=[node.node_id for node in info_relevant_nodes]\n\t\t)\n\t\treturn confine_node_ids\n\n\tdef secondary_retrieve(\n\t\tself,\n\t\titem_to_be_retrieved: str,\n\t\tconfine_node_ids: List[str],\n\t) -&gt; List[NodeWithScore]:\n\t\tr\"\"\"\n\t\tSecondary retrieve in the confined nodes range.\n\n\t\tArgs:\n\t\t\titem_to_be_retrieved (str): The aspects to be retrieved in a paper.\n\t\t\tconfine_node_ids (List[str]): The confined node ids.\n\n\t\tReturns:\n\t\t\tList[NodeWithScore]: The retrieved relevant nodes.\n\t\t\"\"\"\n\t\tself.paper_retriever._node_ids = confine_node_ids\n\t\tnodes = self.paper_retriever.retrieve(item_to_be_retrieved)\n\t\treturn nodes\n\n\tasync def asecondary_retrieve(\n\t\tself,\n\t\titem_to_be_retrieved: str,\n\t\tconfine_node_ids: List[str],\n\t) -&gt; List[NodeWithScore]:\n\t\tr\"\"\"\n\t\tAsynchronous secondary retrieve in the confined nodes range.\n\n\t\tArgs:\n\t\t\titem_to_be_retrieved (str): The aspects to be retrieved in a paper.\n\t\t\tconfine_node_ids (List[str]): The confined node ids.\n\n\t\tReturns:\n\t\t\tList[NodeWithScore]: The retrieved relevant nodes.\n\t\t\"\"\"\n\t\tself.paper_retriever._node_ids = confine_node_ids\n\t\tnodes = await self.paper_retriever.aretrieve(item_to_be_retrieved)\n\t\treturn nodes\n\n\t@dispatcher.span\n\tdef retrieve(\n\t\tself,\n\t\tpaper_info: str,\n\t\titem_to_be_retrieved: str,\n\t\tuser_id: str,\n\t\tstart_date: str = None,\n\t\tend_date: str = None,\n\t\t**kwargs: Any,\n\t) -&gt; List[NodeWithScore]:\n\t\tr\"\"\"\n\t\tThis tool is used to retrieve in the recent papers storage of a specific user.\n\t\tThese information should be provided:\n\t\t1. The paper information, such as title or save path.\n\t\t2. The specific question that you want to obtain answer from the paper.\n\t\t3. The user id.\n\n\t\tArgs:\n\t\t\tpaper_info (str): This argument is necessary.\n\t\t\t\tIt is the relevant information of the paper.\n\t\t\t\tFor example, it can be the paper title, or its save path.\n\t\t\titem_to_be_retrieved (str): This argument is necessary.\n\t\t\t\tIt denotes the specific question that you want to retrieve in a specific paper.\n\t\t\tuser_id (str): This argument is necessary.\n\t\t\t\tThe user_id of a lab member.\n\t\t\tstart_date (str): This argument is optional. It denotes the start date in the format 'Year-Month-Day'.\n\t\t\t\tIf both start_date and end_date are specified, only papers which are added to storage between the\n\t\t\t\tstart_date and end_date will be retrieved.\n\t\t\tend_date: This argument is optional. It denotes the end date in the format 'Year-Month-Day'.\n\t\t\t**kwargs: Other keyword arguments will be ignored.\n\n\t\tReturns:\n\t\t\tThe retrieved results.\n\t\t\"\"\"\n\t\t# This docstring is used as the corresponding tool description.\n\t\tif self.paper_store is None or self.paper_store.user_id != user_id:\n\t\t\tself.paper_store = RecentPaperStore.from_user_id(\n\t\t\t\tuser_id=user_id,\n\t\t\t\tembed_model=self._embed_model,\n\t\t\t)\n\t\t\tif self.fs.exists(paper_info):\n\t\t\t\tprint(f\"Putting {paper_info} into storage.\")\n\t\t\t\tself.paper_store.put(paper_file_path=paper_info)\n\t\t\tself.paper_retriever = self.get_paper_retriever()\n\n\t\tself.reset_retriever()\n\n\t\t# if new file\n\t\tif self.fs.exists(paper_info) and not self.paper_store.file_exists(file_path=paper_info):\n\t\t\tself.paper_store.put(paper_file_path=paper_info)\n\n\t\tif None not in [start_date, end_date]:\n\t\t\t# get the candidate date list.\n\t\t\tdate_list = parse_date_list(start_date_str=start_date, end_date_str=end_date)\n\t\t\tmetadata_filters = MetadataFilters(\n\t\t\t\tfilters=[\n\t\t\t\t\tself.node_type_filter,\n\t\t\t\t\tself.get_date_filter(date_list=date_list),\n\t\t\t\t]\n\t\t\t)\n\t\t\tself.paper_retriever._filters = metadata_filters\n\n\t\tnode_ids_range = self.first_retrieve(paper_info=paper_info)\n\t\trelevant_nodes = self.secondary_retrieve(\n\t\t\titem_to_be_retrieved=item_to_be_retrieved,\n\t\t\tconfine_node_ids=node_ids_range,\n\t\t)\n\t\tif self._final_use_context:\n\t\t\trelevant_nodes = self._add_context(content_nodes=relevant_nodes)\n\n\t\treturn relevant_nodes\n\n\t@dispatcher.span\n\tasync def aretrieve(\n\t\tself,\n\t\tpaper_info: str,\n\t\titem_to_be_retrieved: str,\n\t\tuser_id: str,\n\t\tstart_date: str = None,\n\t\tend_date: str = None,\n\t\t**kwargs: Any,\n\t) -&gt; List[NodeWithScore]:\n\t\tr\"\"\"\n\t\tThis tool is used to retrieve in the recent papers storage of a specific user.\n\t\tThese information should be provided:\n\t\t1. The paper information, such as title or save path.\n\t\t2. The specific question that you want to obtain answer from the paper.\n\t\t3. The user id.\n\n\t\tArgs:\n\t\t\tpaper_info (str): This argument is necessary.\n\t\t\t\tIt is the relevant information of the paper.\n\t\t\t\tFor example, it can be the paper title, or its save path.\n\t\t\titem_to_be_retrieved (str): This argument is necessary.\n\t\t\t\tIt denotes the specific question that you want to retrieve in a specific paper.\n\t\t\tuser_id (str): This argument is necessary.\n\t\t\t\tThe user_id of a lab member.\n\t\t\tstart_date (str): This argument is optional. It denotes the start date in the format 'Year-Month-Day'.\n\t\t\t\tIf both start_date and end_date are specified, only papers which are added to storage between the\n\t\t\t\tstart_date and end_date will be retrieved.\n\t\t\tend_date: This argument is optional. It denotes the end date in the format 'Year-Month-Day'.\n\t\t\t**kwargs: Other keyword arguments will be ignored.\n\n\t\tReturns:\n\t\t\tThe retrieved results.\n\t\t\"\"\"\n\t\t# This docstring is used as the corresponding tool description.\n\t\tif self.paper_store is None or self.paper_store.user_id != user_id:\n\t\t\tself.paper_store = RecentPaperStore.from_user_id(\n\t\t\t\tuser_id=user_id,\n\t\t\t\tembed_model=self._embed_model,\n\t\t\t)\n\t\t\tif self.fs.exists(paper_info):\n\t\t\t\tself.paper_store.put(paper_file_path=paper_info)\n\t\t\tself.paper_retriever = self.get_paper_retriever()\n\n\t\tself.reset_retriever()\n\n\t\tif self.fs.exists(paper_info) and not self.paper_store.file_exists(file_path=paper_info):\n\t\t\tself.paper_store.put(paper_file_path=paper_info)\n\n\t\tif None not in [start_date, end_date]:\n\t\t\t# get the candidate date list.\n\t\t\tdate_list = parse_date_list(start_date_str=start_date, end_date_str=end_date)\n\t\t\tmetadata_filters = MetadataFilters(\n\t\t\t\tfilters=[\n\t\t\t\t\tself.node_type_filter,\n\t\t\t\t\tself.get_date_filter(date_list=date_list),\n\t\t\t\t]\n\t\t\t)\n\t\t\tself.paper_retriever._filters = metadata_filters\n\n\t\tnode_ids_range = await self.afirst_retrieve(paper_info=paper_info)\n\t\trelevant_nodes = await self.asecondary_retrieve(\n\t\t\titem_to_be_retrieved=item_to_be_retrieved,\n\t\t\tconfine_node_ids=node_ids_range,\n\t\t)\n\t\tif self._final_use_context:\n\t\t\trelevant_nodes = self._add_context(content_nodes=relevant_nodes)\n\t\treturn relevant_nodes\n</code></pre>"},{"location":"code_docs/func_modules/paper/retrieve/temporary_paper_retriever/#labridge.func_modules.paper.retrieve.temporary_paper_retriever.RecentPaperRetriever.node_type_filter","title":"<code>labridge.func_modules.paper.retrieve.temporary_paper_retriever.RecentPaperRetriever.node_type_filter: MetadataFilter</code>  <code>property</code>","text":"<p>The node type filter that filters nodes with type <code>TMP_PAPER_DOC_NODE_TYPE</code>.</p> RETURNS DESCRIPTION <code>MetadataFilter</code> <p>The node type metadata filter.</p> <p> TYPE: <code>MetadataFilter</code> </p>"},{"location":"code_docs/func_modules/paper/retrieve/temporary_paper_retriever/#labridge.func_modules.paper.retrieve.temporary_paper_retriever.RecentPaperRetriever.afirst_retrieve","title":"<code>labridge.func_modules.paper.retrieve.temporary_paper_retriever.RecentPaperRetriever.afirst_retrieve(paper_info)</code>  <code>async</code>","text":"<p>First retrieve: retrieve according to the paper_info.</p> PARAMETER DESCRIPTION <code>paper_info</code> <p>The information about the paper.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>List[str]</code> <p>List[str]: all the node ids of relevant papers.</p> Source code in <code>labridge\\func_modules\\paper\\retrieve\\temporary_paper_retriever.py</code> <pre><code>async def afirst_retrieve(self, paper_info: str) -&gt; List[str]:\n\tr\"\"\"\n\tFirst retrieve: retrieve according to the paper_info.\n\n\tArgs:\n\t\tpaper_info (str): The information about the paper.\n\n\tReturns:\n\t\tList[str]: all the node ids of relevant papers.\n\t\"\"\"\n\tself.paper_retriever._similarity_top_k = self._first_top_k\n\tinfo_relevant_nodes = await self.paper_retriever.aretrieve(paper_info)\n\tconfine_node_ids = self.paper_store.get_all_relevant_node_ids(\n\t\tnode_ids=[node.node_id for node in info_relevant_nodes]\n\t)\n\treturn confine_node_ids\n</code></pre>"},{"location":"code_docs/func_modules/paper/retrieve/temporary_paper_retriever/#labridge.func_modules.paper.retrieve.temporary_paper_retriever.RecentPaperRetriever.aretrieve","title":"<code>labridge.func_modules.paper.retrieve.temporary_paper_retriever.RecentPaperRetriever.aretrieve(paper_info, item_to_be_retrieved, user_id, start_date=None, end_date=None, **kwargs)</code>  <code>async</code>","text":"<p>This tool is used to retrieve in the recent papers storage of a specific user. These information should be provided: 1. The paper information, such as title or save path. 2. The specific question that you want to obtain answer from the paper. 3. The user id.</p> PARAMETER DESCRIPTION <code>paper_info</code> <p>This argument is necessary. It is the relevant information of the paper. For example, it can be the paper title, or its save path.</p> <p> TYPE: <code>str</code> </p> <code>item_to_be_retrieved</code> <p>This argument is necessary. It denotes the specific question that you want to retrieve in a specific paper.</p> <p> TYPE: <code>str</code> </p> <code>user_id</code> <p>This argument is necessary. The user_id of a lab member.</p> <p> TYPE: <code>str</code> </p> <code>start_date</code> <p>This argument is optional. It denotes the start date in the format 'Year-Month-Day'. If both start_date and end_date are specified, only papers which are added to storage between the start_date and end_date will be retrieved.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>end_date</code> <p>This argument is optional. It denotes the end date in the format 'Year-Month-Day'.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>**kwargs</code> <p>Other keyword arguments will be ignored.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>List[NodeWithScore]</code> <p>The retrieved results.</p> Source code in <code>labridge\\func_modules\\paper\\retrieve\\temporary_paper_retriever.py</code> <pre><code>@dispatcher.span\nasync def aretrieve(\n\tself,\n\tpaper_info: str,\n\titem_to_be_retrieved: str,\n\tuser_id: str,\n\tstart_date: str = None,\n\tend_date: str = None,\n\t**kwargs: Any,\n) -&gt; List[NodeWithScore]:\n\tr\"\"\"\n\tThis tool is used to retrieve in the recent papers storage of a specific user.\n\tThese information should be provided:\n\t1. The paper information, such as title or save path.\n\t2. The specific question that you want to obtain answer from the paper.\n\t3. The user id.\n\n\tArgs:\n\t\tpaper_info (str): This argument is necessary.\n\t\t\tIt is the relevant information of the paper.\n\t\t\tFor example, it can be the paper title, or its save path.\n\t\titem_to_be_retrieved (str): This argument is necessary.\n\t\t\tIt denotes the specific question that you want to retrieve in a specific paper.\n\t\tuser_id (str): This argument is necessary.\n\t\t\tThe user_id of a lab member.\n\t\tstart_date (str): This argument is optional. It denotes the start date in the format 'Year-Month-Day'.\n\t\t\tIf both start_date and end_date are specified, only papers which are added to storage between the\n\t\t\tstart_date and end_date will be retrieved.\n\t\tend_date: This argument is optional. It denotes the end date in the format 'Year-Month-Day'.\n\t\t**kwargs: Other keyword arguments will be ignored.\n\n\tReturns:\n\t\tThe retrieved results.\n\t\"\"\"\n\t# This docstring is used as the corresponding tool description.\n\tif self.paper_store is None or self.paper_store.user_id != user_id:\n\t\tself.paper_store = RecentPaperStore.from_user_id(\n\t\t\tuser_id=user_id,\n\t\t\tembed_model=self._embed_model,\n\t\t)\n\t\tif self.fs.exists(paper_info):\n\t\t\tself.paper_store.put(paper_file_path=paper_info)\n\t\tself.paper_retriever = self.get_paper_retriever()\n\n\tself.reset_retriever()\n\n\tif self.fs.exists(paper_info) and not self.paper_store.file_exists(file_path=paper_info):\n\t\tself.paper_store.put(paper_file_path=paper_info)\n\n\tif None not in [start_date, end_date]:\n\t\t# get the candidate date list.\n\t\tdate_list = parse_date_list(start_date_str=start_date, end_date_str=end_date)\n\t\tmetadata_filters = MetadataFilters(\n\t\t\tfilters=[\n\t\t\t\tself.node_type_filter,\n\t\t\t\tself.get_date_filter(date_list=date_list),\n\t\t\t]\n\t\t)\n\t\tself.paper_retriever._filters = metadata_filters\n\n\tnode_ids_range = await self.afirst_retrieve(paper_info=paper_info)\n\trelevant_nodes = await self.asecondary_retrieve(\n\t\titem_to_be_retrieved=item_to_be_retrieved,\n\t\tconfine_node_ids=node_ids_range,\n\t)\n\tif self._final_use_context:\n\t\trelevant_nodes = self._add_context(content_nodes=relevant_nodes)\n\treturn relevant_nodes\n</code></pre>"},{"location":"code_docs/func_modules/paper/retrieve/temporary_paper_retriever/#labridge.func_modules.paper.retrieve.temporary_paper_retriever.RecentPaperRetriever.asecondary_retrieve","title":"<code>labridge.func_modules.paper.retrieve.temporary_paper_retriever.RecentPaperRetriever.asecondary_retrieve(item_to_be_retrieved, confine_node_ids)</code>  <code>async</code>","text":"<p>Asynchronous secondary retrieve in the confined nodes range.</p> PARAMETER DESCRIPTION <code>item_to_be_retrieved</code> <p>The aspects to be retrieved in a paper.</p> <p> TYPE: <code>str</code> </p> <code>confine_node_ids</code> <p>The confined node ids.</p> <p> TYPE: <code>List[str]</code> </p> RETURNS DESCRIPTION <code>List[NodeWithScore]</code> <p>List[NodeWithScore]: The retrieved relevant nodes.</p> Source code in <code>labridge\\func_modules\\paper\\retrieve\\temporary_paper_retriever.py</code> <pre><code>async def asecondary_retrieve(\n\tself,\n\titem_to_be_retrieved: str,\n\tconfine_node_ids: List[str],\n) -&gt; List[NodeWithScore]:\n\tr\"\"\"\n\tAsynchronous secondary retrieve in the confined nodes range.\n\n\tArgs:\n\t\titem_to_be_retrieved (str): The aspects to be retrieved in a paper.\n\t\tconfine_node_ids (List[str]): The confined node ids.\n\n\tReturns:\n\t\tList[NodeWithScore]: The retrieved relevant nodes.\n\t\"\"\"\n\tself.paper_retriever._node_ids = confine_node_ids\n\tnodes = await self.paper_retriever.aretrieve(item_to_be_retrieved)\n\treturn nodes\n</code></pre>"},{"location":"code_docs/func_modules/paper/retrieve/temporary_paper_retriever/#labridge.func_modules.paper.retrieve.temporary_paper_retriever.RecentPaperRetriever.first_retrieve","title":"<code>labridge.func_modules.paper.retrieve.temporary_paper_retriever.RecentPaperRetriever.first_retrieve(paper_info)</code>","text":"<p>First retrieve: retrieve according to the paper_info.</p> PARAMETER DESCRIPTION <code>paper_info</code> <p>The information about the paper.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>List[str]</code> <p>List[str]: all the node ids of relevant papers.</p> Source code in <code>labridge\\func_modules\\paper\\retrieve\\temporary_paper_retriever.py</code> <pre><code>def first_retrieve(self, paper_info: str) -&gt; List[str]:\n\tr\"\"\"\n\tFirst retrieve: retrieve according to the paper_info.\n\n\tArgs:\n\t\tpaper_info (str): The information about the paper.\n\n\tReturns:\n\t\tList[str]: all the node ids of relevant papers.\n\t\"\"\"\n\tself.paper_retriever._similarity_top_k = self._first_top_k\n\tinfo_relevant_nodes = self.paper_retriever.retrieve(paper_info)\n\tconfine_node_ids = self.paper_store.get_all_relevant_node_ids(\n\t\tnode_ids=[node.node_id for node in info_relevant_nodes]\n\t)\n\treturn confine_node_ids\n</code></pre>"},{"location":"code_docs/func_modules/paper/retrieve/temporary_paper_retriever/#labridge.func_modules.paper.retrieve.temporary_paper_retriever.RecentPaperRetriever.get_date_filter","title":"<code>labridge.func_modules.paper.retrieve.temporary_paper_retriever.RecentPaperRetriever.get_date_filter(date_list)</code>","text":"<p>Get the date filter that filters according to the creation date of nodes.</p> PARAMETER DESCRIPTION <code>date_list</code> <p>The date candidates. Only nodes created in one of these dates will be retrieved.</p> <p> TYPE: <code>List[str]</code> </p> RETURNS DESCRIPTION <code>MetadataFilter</code> <p>The date filter.</p> <p> TYPE: <code>MetadataFilter</code> </p> Source code in <code>labridge\\func_modules\\paper\\retrieve\\temporary_paper_retriever.py</code> <pre><code>def get_date_filter(self, date_list: List[str]) -&gt; MetadataFilter:\n\tr\"\"\"\n\tGet the date filter that filters according to the creation date of nodes.\n\n\tArgs:\n\t\tdate_list (List[str]): The date candidates. Only nodes created in one of these dates will be retrieved.\n\n\tReturns:\n\t\tMetadataFilter: The date filter.\n\t\"\"\"\n\tdate_filter = MetadataFilter(\n\t\tkey=TMP_PAPER_DATE,\n\t\tvalue=date_list,\n\t\toperator=FilterOperator.ANY,\n\t)\n\treturn date_filter\n</code></pre>"},{"location":"code_docs/func_modules/paper/retrieve/temporary_paper_retriever/#labridge.func_modules.paper.retrieve.temporary_paper_retriever.RecentPaperRetriever.get_paper_retriever","title":"<code>labridge.func_modules.paper.retrieve.temporary_paper_retriever.RecentPaperRetriever.get_paper_retriever()</code>","text":"<p>Get the default paper retriever, with a node_type_filter.</p> RETURNS DESCRIPTION <code>VectorIndexRetriever</code> <p>The paper retriever.</p> <p> TYPE: <code>VectorIndexRetriever</code> </p> Source code in <code>labridge\\func_modules\\paper\\retrieve\\temporary_paper_retriever.py</code> <pre><code>def get_paper_retriever(self) -&gt; VectorIndexRetriever:\n\tr\"\"\"\n\tGet the default paper retriever, with a node_type_filter.\n\n\tReturns:\n\t\tVectorIndexRetriever: The paper retriever.\n\t\"\"\"\n\tpaper_retriever = self.paper_store.vector_index.as_retriever(\n\t\tsimilarity_top_k=self._relevant_top_k,\n\t\tfilters=MetadataFilters(\n\t\t\tfilters=[self.node_type_filter]\n\t\t),\n\t)\n\treturn paper_retriever\n</code></pre>"},{"location":"code_docs/func_modules/paper/retrieve/temporary_paper_retriever/#labridge.func_modules.paper.retrieve.temporary_paper_retriever.RecentPaperRetriever.reset_retriever","title":"<code>labridge.func_modules.paper.retrieve.temporary_paper_retriever.RecentPaperRetriever.reset_retriever()</code>","text":"<p>Reset the paper retriever:</p> <ul> <li>reset the node_ids that confine the retrieving range.</li> <li>reset the similarity_top_k.</li> <li>reset the MetadataFilters.</li> </ul> RETURNS DESCRIPTION <p>None.</p> Source code in <code>labridge\\func_modules\\paper\\retrieve\\temporary_paper_retriever.py</code> <pre><code>def reset_retriever(self):\n\tr\"\"\"\n\tReset the paper retriever:\n\n\t- reset the node_ids that confine the retrieving range.\n\t- reset the similarity_top_k.\n\t- reset the MetadataFilters.\n\n\tReturns:\n\t\tNone.\n\t\"\"\"\n\tif self.paper_retriever:\n\t\tself.paper_retriever._node_ids = None\n\t\tself.paper_retriever._similarity_top_k = self._first_top_k\n\t\tself.paper_retriever._filters = MetadataFilters(\n\t\t\tfilters=[self.node_type_filter,]\n\t\t)\n</code></pre>"},{"location":"code_docs/func_modules/paper/retrieve/temporary_paper_retriever/#labridge.func_modules.paper.retrieve.temporary_paper_retriever.RecentPaperRetriever.retrieve","title":"<code>labridge.func_modules.paper.retrieve.temporary_paper_retriever.RecentPaperRetriever.retrieve(paper_info, item_to_be_retrieved, user_id, start_date=None, end_date=None, **kwargs)</code>","text":"<p>This tool is used to retrieve in the recent papers storage of a specific user. These information should be provided: 1. The paper information, such as title or save path. 2. The specific question that you want to obtain answer from the paper. 3. The user id.</p> PARAMETER DESCRIPTION <code>paper_info</code> <p>This argument is necessary. It is the relevant information of the paper. For example, it can be the paper title, or its save path.</p> <p> TYPE: <code>str</code> </p> <code>item_to_be_retrieved</code> <p>This argument is necessary. It denotes the specific question that you want to retrieve in a specific paper.</p> <p> TYPE: <code>str</code> </p> <code>user_id</code> <p>This argument is necessary. The user_id of a lab member.</p> <p> TYPE: <code>str</code> </p> <code>start_date</code> <p>This argument is optional. It denotes the start date in the format 'Year-Month-Day'. If both start_date and end_date are specified, only papers which are added to storage between the start_date and end_date will be retrieved.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>end_date</code> <p>This argument is optional. It denotes the end date in the format 'Year-Month-Day'.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>**kwargs</code> <p>Other keyword arguments will be ignored.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>List[NodeWithScore]</code> <p>The retrieved results.</p> Source code in <code>labridge\\func_modules\\paper\\retrieve\\temporary_paper_retriever.py</code> <pre><code>@dispatcher.span\ndef retrieve(\n\tself,\n\tpaper_info: str,\n\titem_to_be_retrieved: str,\n\tuser_id: str,\n\tstart_date: str = None,\n\tend_date: str = None,\n\t**kwargs: Any,\n) -&gt; List[NodeWithScore]:\n\tr\"\"\"\n\tThis tool is used to retrieve in the recent papers storage of a specific user.\n\tThese information should be provided:\n\t1. The paper information, such as title or save path.\n\t2. The specific question that you want to obtain answer from the paper.\n\t3. The user id.\n\n\tArgs:\n\t\tpaper_info (str): This argument is necessary.\n\t\t\tIt is the relevant information of the paper.\n\t\t\tFor example, it can be the paper title, or its save path.\n\t\titem_to_be_retrieved (str): This argument is necessary.\n\t\t\tIt denotes the specific question that you want to retrieve in a specific paper.\n\t\tuser_id (str): This argument is necessary.\n\t\t\tThe user_id of a lab member.\n\t\tstart_date (str): This argument is optional. It denotes the start date in the format 'Year-Month-Day'.\n\t\t\tIf both start_date and end_date are specified, only papers which are added to storage between the\n\t\t\tstart_date and end_date will be retrieved.\n\t\tend_date: This argument is optional. It denotes the end date in the format 'Year-Month-Day'.\n\t\t**kwargs: Other keyword arguments will be ignored.\n\n\tReturns:\n\t\tThe retrieved results.\n\t\"\"\"\n\t# This docstring is used as the corresponding tool description.\n\tif self.paper_store is None or self.paper_store.user_id != user_id:\n\t\tself.paper_store = RecentPaperStore.from_user_id(\n\t\t\tuser_id=user_id,\n\t\t\tembed_model=self._embed_model,\n\t\t)\n\t\tif self.fs.exists(paper_info):\n\t\t\tprint(f\"Putting {paper_info} into storage.\")\n\t\t\tself.paper_store.put(paper_file_path=paper_info)\n\t\tself.paper_retriever = self.get_paper_retriever()\n\n\tself.reset_retriever()\n\n\t# if new file\n\tif self.fs.exists(paper_info) and not self.paper_store.file_exists(file_path=paper_info):\n\t\tself.paper_store.put(paper_file_path=paper_info)\n\n\tif None not in [start_date, end_date]:\n\t\t# get the candidate date list.\n\t\tdate_list = parse_date_list(start_date_str=start_date, end_date_str=end_date)\n\t\tmetadata_filters = MetadataFilters(\n\t\t\tfilters=[\n\t\t\t\tself.node_type_filter,\n\t\t\t\tself.get_date_filter(date_list=date_list),\n\t\t\t]\n\t\t)\n\t\tself.paper_retriever._filters = metadata_filters\n\n\tnode_ids_range = self.first_retrieve(paper_info=paper_info)\n\trelevant_nodes = self.secondary_retrieve(\n\t\titem_to_be_retrieved=item_to_be_retrieved,\n\t\tconfine_node_ids=node_ids_range,\n\t)\n\tif self._final_use_context:\n\t\trelevant_nodes = self._add_context(content_nodes=relevant_nodes)\n\n\treturn relevant_nodes\n</code></pre>"},{"location":"code_docs/func_modules/paper/retrieve/temporary_paper_retriever/#labridge.func_modules.paper.retrieve.temporary_paper_retriever.RecentPaperRetriever.secondary_retrieve","title":"<code>labridge.func_modules.paper.retrieve.temporary_paper_retriever.RecentPaperRetriever.secondary_retrieve(item_to_be_retrieved, confine_node_ids)</code>","text":"<p>Secondary retrieve in the confined nodes range.</p> PARAMETER DESCRIPTION <code>item_to_be_retrieved</code> <p>The aspects to be retrieved in a paper.</p> <p> TYPE: <code>str</code> </p> <code>confine_node_ids</code> <p>The confined node ids.</p> <p> TYPE: <code>List[str]</code> </p> RETURNS DESCRIPTION <code>List[NodeWithScore]</code> <p>List[NodeWithScore]: The retrieved relevant nodes.</p> Source code in <code>labridge\\func_modules\\paper\\retrieve\\temporary_paper_retriever.py</code> <pre><code>def secondary_retrieve(\n\tself,\n\titem_to_be_retrieved: str,\n\tconfine_node_ids: List[str],\n) -&gt; List[NodeWithScore]:\n\tr\"\"\"\n\tSecondary retrieve in the confined nodes range.\n\n\tArgs:\n\t\titem_to_be_retrieved (str): The aspects to be retrieved in a paper.\n\t\tconfine_node_ids (List[str]): The confined node ids.\n\n\tReturns:\n\t\tList[NodeWithScore]: The retrieved relevant nodes.\n\t\"\"\"\n\tself.paper_retriever._node_ids = confine_node_ids\n\tnodes = self.paper_retriever.retrieve(item_to_be_retrieved)\n\treturn nodes\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/paper_store/","title":"Paper store","text":""},{"location":"code_docs/func_modules/paper/store/paper_store/#labridge.func_modules.paper.store.paper_store","title":"<code>labridge.func_modules.paper.store.paper_store</code>","text":""},{"location":"code_docs/func_modules/paper/store/paper_store/#labridge.func_modules.paper.store.paper_store.PaperDirectorySummaryStore","title":"<code>labridge.func_modules.paper.store.paper_store.PaperDirectorySummaryStore</code>","text":"<p>This class is used to store the summary of each paper directory. It is useful for storing new papers in proper directories, recommending papers to lab members, etc.</p> <p>Initially, the directory summary store is automatically constructed using LLM to summarize each directory. However, it is not accurate enough, it should be updated according to the relevant research fields information provided by Lab members.</p> <p>Before storing directory summaries, make sure that all target papers have been added to the paper warehouse and stored in the <code>PaperStorage</code>.</p> <p>Each directory summary node is stored in the docstore, two items are recorded:</p> <ol> <li>the possessor of this directory.</li> <li>the summary (relevant research fields) of this directory.</li> </ol> <p>These two items are stored as metadata of th summary node.</p> PARAMETER DESCRIPTION <code>llm</code> <p>the used llm.</p> <p> TYPE: <code>LLM</code> DEFAULT: <code>None</code> </p> <code>embed_model</code> <p>the used embed model.</p> <p> TYPE: <code>BaseEmbedding</code> DEFAULT: <code>None</code> </p> <code>paper_root</code> <p>the directory root of the paper warehouse.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>paper_summary_persist_dir</code> <p>the directory storing the paper summary index.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>directory_summary_persist_dir</code> <p>the directory storing the directory summary index.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>service_context</code> <p>service_context</p> <p> TYPE: <code>ServiceContext</code> DEFAULT: <code>None</code> </p> <code>dir_choice_batch_size</code> <p> TYPE: <code>int</code> DEFAULT: <code>5</code> </p> Source code in <code>labridge\\func_modules\\paper\\store\\paper_store.py</code> <pre><code>class PaperDirectorySummaryStore:\n\tr\"\"\"\n\tThis class is used to store the summary of each paper directory.\n\tIt is useful for storing new papers in proper directories, recommending papers to lab members, etc.\n\n\tInitially, the directory summary store is automatically constructed using LLM to summarize each directory.\n\tHowever, it is not accurate enough, it should be updated according to the relevant research fields information\n\tprovided by Lab members.\n\n\tBefore storing directory summaries, make sure that all target papers have been added to the paper warehouse and\n\tstored in the `PaperStorage`.\n\n\tEach directory summary node is stored in the docstore, two items are recorded:\n\n\t1. the possessor of this directory.\n\t2. the summary (relevant research fields) of this directory.\n\n\tThese two items are stored as metadata of th summary node.\n\n\tArgs:\n\t\tllm (LLM): the used llm.\n\t\tembed_model (BaseEmbedding): the used embed model.\n\t\tpaper_root (str): the directory root of the paper warehouse.\n\t\tpaper_summary_persist_dir (str): the directory storing the paper summary index.\n\t\tdirectory_summary_persist_dir (str): the directory storing the directory summary index.\n\t\tservice_context (ServiceContext): service_context\n\t\tdir_choice_batch_size (int):\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tllm: Optional[LLM] = None,\n\t\tembed_model: Optional[BaseEmbedding] = None,\n\t\tpaper_root: Union[os.PathLike, str] = None,\n\t\tpaper_summary_persist_dir: Union[str, os.PathLike] = None,\n\t\tdirectory_summary_persist_dir: Union[str, os.PathLike] = None,\n\t\tservice_context: Optional[ServiceContext] = None,\n\t\tdir_choice_batch_size: int = 5,\n\t):\n\t\troot = Path(__file__)\n\t\tfor i in range(5):\n\t\t\troot = root.parent\n\t\tself.root = root\n\n\t\tself.llm = llm or llm_from_settings_or_context(Settings, service_context)\n\t\tself.embed_model = embed_model or embed_model_from_settings_or_context(Settings, service_context)\n\t\tself.service_context = service_context\n\t\tself.paper_root = self._path_format(\n\t\t\tpath=paper_root,\n\t\t\tdefault=root / DEFAULT_PAPER_WAREHOUSE_DIR,\n\t\t)\n\t\tself.paper_summary_persist_dir = self._path_format(\n\t\t\tpath=paper_summary_persist_dir,\n\t\t\tdefault=root / DEFAULT_PAPER_SUMMARY_PERSIST_DIR,\n\t\t)\n\t\tself.directory_summary_persist_dir = self._path_format(\n\t\t\tpath=directory_summary_persist_dir,\n\t\t\tdefault=root / DEFAULT_DIRECTORY_SUMMARY_PERSIST_DIR,\n\t\t)\n\t\tif not Path(self.directory_summary_persist_dir).exists():\n\t\t\tself._auto_construct()\n\t\tdirectory_storage_context = StorageContext.from_defaults(persist_dir=self.directory_summary_persist_dir)\n\t\tself.directory_summary_index = load_index_from_storage(\n\t\t\tstorage_context=directory_storage_context,\n\t\t\tindex_id=DIR_SUMMARY_INDEX_ID,\n\t\t\tservice_context=self.service_context,\n\t\t)\n\t\tself.dir_choice_batch_size = dir_choice_batch_size\n\n\n\tdef _path_format(self, path: Union[os.PathLike, str], default: Path) -&gt; str:\n\t\tif path is None:\n\t\t\treturn str(default)\n\t\treturn path\n\n\tdef _auto_summarize_dir(self, directory: str, verbose: bool = False):\n\t\tr\"\"\"\n\t\tAutomatically summarize each directory under the given directory.\n\t\tThe given directory must be under the paper root.\n\t\t\"\"\"\n\t\tif directory != self.paper_root and Path(self.paper_root) not in Path(directory).parents:\n\t\t\traise ValueError(\"Invalid directory. The input directory should be under the paper warehouse.\")\n\n\t\tpaper_summary_storage_context = StorageContext.from_defaults(persist_dir=self.paper_summary_persist_dir)\n\t\tpaper_summary_index = load_index_from_storage(\n\t\t\tstorage_context=paper_summary_storage_context,\n\t\t\tindex_id=PAPER_SUMMARY_INDEX_ID,\n\t\t\tservice_context=self.service_context,\n\t\t)\n\t\tdoc_id_to_summary_id = paper_summary_index.index_struct.doc_id_to_summary_id\n\n\t\tif not Path(self.directory_summary_persist_dir).exists():\n\t\t\trel_paper_root = Path(self.paper_root).relative_to(self.root)\n\t\t\troot_node = TextNode(text=\"\", id_=str(rel_paper_root), )\n\t\t\troot_node.relationships[NodeRelationship.SOURCE] = RelatedNodeInfo(node_id=\"Paper warehouse\", )\n\t\t\tdir_summary_index = DocumentSummaryIndex(\n\t\t\t\tnodes=[root_node, ],\n\t\t\t\tllm=self.llm,\n\t\t\t\tembed_model=self.embed_model,\n\t\t\t\tservice_context=self.service_context,\n\t\t\t\tresponse_synthesizer=get_response_synthesizer(\n\t\t\t\t\tllm=self.llm,\n\t\t\t\t\tresponse_mode=ResponseMode.COMPACT_ACCUMULATE\n\t\t\t\t),\n\t\t\t)\n\t\telse:\n\t\t\tdirectory_storage_context = StorageContext.from_defaults(persist_dir=self.directory_summary_persist_dir)\n\t\t\tdir_summary_index = load_index_from_storage(\n\t\t\t\tstorage_context=directory_storage_context,\n\t\t\t\tindex_id=DIR_SUMMARY_INDEX_ID,\n\t\t\t\tservice_context=self.service_context,\n\t\t\t)\n\t\tdir_id_to_summary_id = dir_summary_index.index_struct.doc_id_to_summary_id\n\n\t\tdef dfs(current_dir: Path):\n\t\t\tif not current_dir.is_dir():\n\t\t\t\treturn\n\n\t\t\tfor child in current_dir.iterdir():\n\t\t\t\tdfs(child)\n\n\t\t\tnodes = []\n\t\t\tcurrent_dir_id = str(current_dir.relative_to(self.root))\n\t\t\tif current_dir_id == DEFAULT_PAPER_WAREHOUSE_DIR:\n\t\t\t\treturn\n\n\t\t\tpossessor = current_dir_id.split('/')[2]\n\t\t\tprint_text(f\"&gt;&gt;&gt; Processing: {current_dir}\", color=\"blue\", end=\"\\n\")\n\t\t\tfor child in current_dir.iterdir():\n\t\t\t\tif not child.is_dir() and child.suffix == \".pdf\":\n\t\t\t\t\trel_paper = str(child.relative_to(self.root))\n\t\t\t\t\tchild_main_text = rel_paper + f\"_{MAINTEXT}\"\n\t\t\t\t\tchild_methods = rel_paper + f\"_{METHODS}\"\n\t\t\t\t\tfor doc_id in (child_main_text, child_methods):\n\t\t\t\t\t\tif doc_id not in doc_id_to_summary_id.keys() and verbose:\n\t\t\t\t\t\t\tprint(f\"{doc_id} not stored into the PaperStorage yet, \"\n\t\t\t\t\t\t\t\t  f\"please insert it into the PaperStorage first.\")\n\t\t\t\t\t\tif doc_id in doc_id_to_summary_id.keys():\n\t\t\t\t\t\t\tsummary_id = doc_id_to_summary_id[doc_id]\n\t\t\t\t\t\t\tpaper_summary_node = paper_summary_index.docstore.get_node(summary_id)\n\t\t\t\t\t\t\t# Get the paper keywords\n\t\t\t\t\t\t\tif PAPER_LEVEL_KEYWORDS in paper_summary_node.metadata.keys():\n\t\t\t\t\t\t\t\tpaper_keywords = paper_summary_node.metadata[PAPER_LEVEL_KEYWORDS]\n\t\t\t\t\t\t\telse:\n\t\t\t\t\t\t\t\t# extract keywords.\n\t\t\t\t\t\t\t\tpaper_keywords = dir_summary_index._response_synthesizer.synthesize(\n\t\t\t\t\t\t\t\t\tquery=PAPER_KEYWORDS_EXTRACT_QUERY,\n\t\t\t\t\t\t\t\t\tnodes=[NodeWithScore(node=paper_summary_node)]\n\t\t\t\t\t\t\t\t)\n\n\t\t\t\t\t\t\t# filter metadata (possessor &amp; paper keywords)\n\t\t\t\t\t\t\tpaper_summary_node.metadata = {\n\t\t\t\t\t\t\t\tPAPER_POSSESSOR: possessor,\n\t\t\t\t\t\t\t\tPAPER_LEVEL_KEYWORDS: paper_keywords,\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tpaper_summary_node.set_content(\"\")\n\t\t\t\t\t\t\tpaper_summary_node.relationships[NodeRelationship.SOURCE] = RelatedNodeInfo(\n\t\t\t\t\t\t\t\tnode_id=current_dir_id,\n\t\t\t\t\t\t\t)\n\t\t\t\t\t\t\tnodes.append(paper_summary_node)\n\t\t\t\telif child.is_dir():\n\t\t\t\t\tchild_dir_id = str(child.relative_to(self.root))\n\t\t\t\t\tif child_dir_id in dir_id_to_summary_id.keys():\n\t\t\t\t\t\tchild_summary_id = dir_id_to_summary_id[child_dir_id]\n\t\t\t\t\t\tdir_summary_node = dir_summary_index.docstore.get_node(child_summary_id)\n\t\t\t\t\t\tdir_summary_node.relationships[NodeRelationship.SOURCE] = RelatedNodeInfo(\n\t\t\t\t\t\t\tnode_id=current_dir_id,\n\t\t\t\t\t\t)\n\t\t\t\t\t\tnodes.append(dir_summary_node)\n\n\t\t\t# Summarize current directory based on its children\n\t\t\tnodes_with_scores = [NodeWithScore(node=n) for n in nodes]\n\n\t\t\tif len(nodes_with_scores) &gt; 0:\n\t\t\t\tsummary_response = dir_summary_index._response_synthesizer.synthesize(\n\t\t\t\t\tquery=DIR_SUMMARIZE_QUERY,\n\t\t\t\t\tnodes=nodes_with_scores,\n\t\t\t\t)\n\n\t\t\t\tsummary_response = cast(Response, summary_response)\n\t\t\t\tdir_summary_node = TextNode(\n\t\t\t\t\ttext=\"\",\n\t\t\t\t\trelationships={NodeRelationship.SOURCE: RelatedNodeInfo(node_id=current_dir_id)},\n\t\t\t\t\tmetadata={\n\t\t\t\t\t\tPAPER_POSSESSOR: possessor,\n\t\t\t\t\t\tPAPER_LEVEL_KEYWORDS: summary_response.response,\n\t\t\t\t\t},\n\t\t\t\t)\n\n\t\t\t\tdir_summary_index.docstore.add_documents([dir_summary_node])\n\t\t\t\tdir_summary_index._index_struct.doc_id_to_summary_id[current_dir_id] = dir_summary_node.node_id\n\n\t\t\t\tid_to_embed_map = embed_nodes([dir_summary_node,], self.embed_model)\n\t\t\t\tnode_with_embedding = dir_summary_node.copy()\n\t\t\t\tnode_with_embedding.embedding = id_to_embed_map[dir_summary_node.node_id]\n\t\t\t\tdir_summary_index._vector_store.add([node_with_embedding, ])\n\t\t\t\tdir_summary_index._storage_context.index_store.add_index_struct(dir_summary_index._index_struct)\n\n\t\tdfs(Path(directory))\n\t\tif dir_summary_index.index_id != DIR_SUMMARY_INDEX_ID:\n\t\t\tdir_summary_index.set_index_id(DIR_SUMMARY_INDEX_ID)\n\t\tdir_summary_index.storage_context.persist(persist_dir=str(self.directory_summary_persist_dir))\n\n\tdef _auto_construct(self):\n\t\tr\"\"\"\n\t\tAutomatically construct the directory summary index based on the paper warehouse.\n\n\t\tDFS the directory tree, directory root: `self.paper_root`.\n\t\tThe summary (relevant research fields) of each directory is synthesized from its child directories.\n\n\t\tEach summary node of a directory: ref_doc_id: the directory path relative to the root.\n\t\t\"\"\"\n\t\tself._auto_summarize_dir(self.paper_root)\n\n\tdef get_dir_nodes(self):\n\t\tr\"\"\" get the valid directory summary nodes \"\"\"\n\t\tdir_id_to_summary_id = self.directory_summary_index._index_struct.doc_id_to_summary_id\n\t\tdir_summary_nodes = []\n\t\tfor dir_id in dir_id_to_summary_id.keys():\n\t\t\tdir_path = self.root / dir_id\n\t\t\tif dir_path.exists():\n\t\t\t\tsummary_id = dir_id_to_summary_id[dir_id]\n\t\t\t\tsummary_node = self.directory_summary_index.docstore.get_node(summary_id)\n\t\t\t\tdir_summary_nodes.append(summary_node)\n\t\treturn dir_summary_nodes\n\n\tdef match_directory_for_new_paper(\n\t\tself,\n\t\tpdf_path: str,\n\t\tpossessor: str,\n\t\tpaper_summary: str = None,\n\t\tverbose: bool=False,\n\t) -&gt; Union[str, None]:\n\t\tr\"\"\"\n\t\tselect the most relevant (and deepest) directory for the new paper.\n\n\t\tArgs:\n\t\t\tpdf_path (str): the path of the new paper.\n\t\t\tpossessor (str): the possessor of this new paper.\n\t\t\tpaper_summary (str): the summary of the new paper.\n\t\t\tverbose (bool): whether to show progress.\n\n\t\tReturns:\n\t\t\tUnion[str, None]:\n\t\t\t\tThe matched directory for the new paper. If no proper directory found, return None.\n\t\t\"\"\"\n\t\tpdf_path = Path(pdf_path)\n\t\tif pdf_path.suffix != \".pdf\":\n\t\t\traise ValueError(\"Only papers with PDF format are supported now.\")\n\t\tpossessor_dir = Path(self.paper_root) / possessor\n\t\tif not possessor_dir.exists():\n\t\t\traise ValueError(f\"The member {possessor} do not exist. Please sign up as a member first.\")\n\n\t\tif paper_summary is None:\n\t\t\tpdf_docs = PyMuPDFReader().load_data(file_path=pdf_path)\n\t\t\t# typically, the first page includes conclusive information of a paper.\n\t\t\tpaper_summary = pdf_docs[0].text\n\n\t\tdir_summary_nodes = self.get_dir_nodes()\n\n\t\tselected_nodes = []\n\t\tselected_relevances = []\n\n\t\tfor idx in range(0, len(dir_summary_nodes), self.dir_choice_batch_size):\n\t\t\tsummary_nodes = dir_summary_nodes[idx: idx + self.dir_choice_batch_size]\n\t\t\tdir_context_str = default_format_node_batch_fn(summary_nodes=summary_nodes)\n\n\t\t\traw_response = self.llm.predict(\n\t\t\t\tDIR_CHOICE_SELECT_PROMPT,\n\t\t\t\tdir_context_str=dir_context_str,\n\t\t\t\tpaper_str=paper_summary,\n\t\t\t)\n\t\t\traw_choices, relevances = default_parse_choice_select_answer_fn(raw_response, len(summary_nodes))\n\t\t\tchoice_idxs = [choice - 1 for choice in raw_choices]\n\t\t\tchoice_summary_nodes = [summary_nodes[ci] for ci in choice_idxs]\n\t\t\tselected_nodes.extend(choice_summary_nodes)\n\t\t\tselected_relevances.extend(relevances)\n\n\t\tif len(selected_nodes) == 0:\n\t\t\treturn None\n\n\t\tzipped_list = list(zip(selected_nodes, selected_relevances))\n\t\tsorted_list = sorted(zipped_list, key=lambda x: x[1], reverse=True)\n\t\t# choose the most relevant and the deepest directory.\n\t\tbest_dir = sorted_list[0][0].ref_doc_id\n\n\t\tif verbose:\n\t\t\tfor node, relevance in sorted_list:\n\t\t\t\tprint_text(f\"&gt;&gt;&gt; dir: {node.ref_doc_id}, relevance: {relevance}\", color=\"blue\", end=\"\\n\")\n\t\tdef sub_dir_nodes(paper_dir: str):\n\t\t\tsub_nodes_with_score = []\n\t\t\tfor node, score in sorted_list:\n\t\t\t\tif Path(paper_dir) in Path(node.ref_doc_id).parents:\n\t\t\t\t\tsub_nodes_with_score.append((node, score))\n\t\t\treturn sub_nodes_with_score\n\n\t\tsub_list = sub_dir_nodes(best_dir)\n\t\twhile len(sub_list) &gt; 0:\n\t\t\tsub_list = sorted(sub_list, key=lambda x: x[1], reverse=True)\n\t\t\tbest_dir = sub_list[0][0].ref_doc_id\n\t\t\tsub_list = sub_dir_nodes(best_dir)\n\t\treturn best_dir\n\n\tdef update(self, dir_description_dict: Dict[str, str]):\n\t\tr\"\"\"\n\t\tUpdate the relevant research fields of each directory.\n\t\tTypically used for manually set each directory's relevant research fields.\n\n\t\tArgs:\n\t\t\tdir_description_dict (Dict[str, str]): the descriptions of the paper directories\n\t\t\t\t- key: the directory path relative to root;\n\t\t\t\t- value: the relevant research fields of the directory.\n\t\t\"\"\"\n\t\tfor dir_id in dir_description_dict.keys():\n\t\t\tself._set_dir_metadata(\n\t\t\t\tdir_id=dir_id,\n\t\t\t\tkey=PAPER_LEVEL_KEYWORDS,\n\t\t\t\tval=dir_description_dict[dir_id],\n\t\t\t)\n\n\tdef _set_dir_metadata(self, dir_id: str, key: str, val: Any):\n\t\tdir_id_to_summary_id = self.directory_summary_index._index_struct.doc_id_to_summary_id\n\t\tnode_collection = self.directory_summary_index.docstore._node_collection\n\n\t\tif dir_id in dir_id_to_summary_id.keys():\n\t\t\tsummary_id = dir_id_to_summary_id[dir_id]\n\t\t\tsummary_store = self.directory_summary_index.docstore._kvstore._data[node_collection][summary_id]\n\t\t\tsummary_store[\"__data__\"][\"metadata\"][key] = val\n\n\t\tself.directory_summary_index.storage_context.persist(persist_dir=self.directory_summary_persist_dir)\n\n\tdef set_possessor_research_categories(self, possessor_category_dict: Dict[str, List[str]]):\n\t\tr\"\"\"\n\t\tSet the research categories of the possessors, this research categories is used to recommend proper new papers\n\t\tto the possessors.\n\n\t\tArgs:\n\t\t\tpossessor_category_dict (Dict[str, List[str]]): the research categories to be set.\n\t\t\t\tIt is a dictionary with:\n\n\t\t\t\t- key: possessor\n\t\t\t\t- value: the list of research categories. For details about research categories,\n\t\t\t\trefer to the class `ArxivCategory`.\n\t\t\"\"\"\n\t\tfor possessor in possessor_category_dict.keys():\n\t\t\tdir_id = str((Path(self.paper_root) / possessor).relative_to(self.root))\n\t\t\tself._set_dir_metadata(\n\t\t\t\tdir_id=dir_id,\n\t\t\t\tkey=DIR_CATEGORY_NAME,\n\t\t\t\tval=possessor_category_dict[possessor],\n\t\t\t)\n\n\tdef add_dir(self, directory: str, verbose: bool = False):\n\t\tr\"\"\"\n\t\tAdd a directory to the paper storage.\n\t\t\"\"\"\n\t\tif Path(self.paper_root) not in Path(directory).parents:\n\t\t\traise ValueError(\"Invalid directory path, please add your documents to the paper warehouse, \"\n\t\t\t\t\t\t\t \"and store them in the PaperStorage first.\")\n\t\tself._auto_summarize_dir(directory=directory, verbose=verbose)\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/paper_store/#labridge.func_modules.paper.store.paper_store.PaperDirectorySummaryStore.add_dir","title":"<code>labridge.func_modules.paper.store.paper_store.PaperDirectorySummaryStore.add_dir(directory, verbose=False)</code>","text":"<p>Add a directory to the paper storage.</p> Source code in <code>labridge\\func_modules\\paper\\store\\paper_store.py</code> <pre><code>def add_dir(self, directory: str, verbose: bool = False):\n\tr\"\"\"\n\tAdd a directory to the paper storage.\n\t\"\"\"\n\tif Path(self.paper_root) not in Path(directory).parents:\n\t\traise ValueError(\"Invalid directory path, please add your documents to the paper warehouse, \"\n\t\t\t\t\t\t \"and store them in the PaperStorage first.\")\n\tself._auto_summarize_dir(directory=directory, verbose=verbose)\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/paper_store/#labridge.func_modules.paper.store.paper_store.PaperDirectorySummaryStore.get_dir_nodes","title":"<code>labridge.func_modules.paper.store.paper_store.PaperDirectorySummaryStore.get_dir_nodes()</code>","text":"<p>get the valid directory summary nodes</p> Source code in <code>labridge\\func_modules\\paper\\store\\paper_store.py</code> <pre><code>def get_dir_nodes(self):\n\tr\"\"\" get the valid directory summary nodes \"\"\"\n\tdir_id_to_summary_id = self.directory_summary_index._index_struct.doc_id_to_summary_id\n\tdir_summary_nodes = []\n\tfor dir_id in dir_id_to_summary_id.keys():\n\t\tdir_path = self.root / dir_id\n\t\tif dir_path.exists():\n\t\t\tsummary_id = dir_id_to_summary_id[dir_id]\n\t\t\tsummary_node = self.directory_summary_index.docstore.get_node(summary_id)\n\t\t\tdir_summary_nodes.append(summary_node)\n\treturn dir_summary_nodes\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/paper_store/#labridge.func_modules.paper.store.paper_store.PaperDirectorySummaryStore.match_directory_for_new_paper","title":"<code>labridge.func_modules.paper.store.paper_store.PaperDirectorySummaryStore.match_directory_for_new_paper(pdf_path, possessor, paper_summary=None, verbose=False)</code>","text":"<p>select the most relevant (and deepest) directory for the new paper.</p> PARAMETER DESCRIPTION <code>pdf_path</code> <p>the path of the new paper.</p> <p> TYPE: <code>str</code> </p> <code>possessor</code> <p>the possessor of this new paper.</p> <p> TYPE: <code>str</code> </p> <code>paper_summary</code> <p>the summary of the new paper.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>verbose</code> <p>whether to show progress.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>Union[str, None]</code> <p>Union[str, None]: The matched directory for the new paper. If no proper directory found, return None.</p> Source code in <code>labridge\\func_modules\\paper\\store\\paper_store.py</code> <pre><code>def match_directory_for_new_paper(\n\tself,\n\tpdf_path: str,\n\tpossessor: str,\n\tpaper_summary: str = None,\n\tverbose: bool=False,\n) -&gt; Union[str, None]:\n\tr\"\"\"\n\tselect the most relevant (and deepest) directory for the new paper.\n\n\tArgs:\n\t\tpdf_path (str): the path of the new paper.\n\t\tpossessor (str): the possessor of this new paper.\n\t\tpaper_summary (str): the summary of the new paper.\n\t\tverbose (bool): whether to show progress.\n\n\tReturns:\n\t\tUnion[str, None]:\n\t\t\tThe matched directory for the new paper. If no proper directory found, return None.\n\t\"\"\"\n\tpdf_path = Path(pdf_path)\n\tif pdf_path.suffix != \".pdf\":\n\t\traise ValueError(\"Only papers with PDF format are supported now.\")\n\tpossessor_dir = Path(self.paper_root) / possessor\n\tif not possessor_dir.exists():\n\t\traise ValueError(f\"The member {possessor} do not exist. Please sign up as a member first.\")\n\n\tif paper_summary is None:\n\t\tpdf_docs = PyMuPDFReader().load_data(file_path=pdf_path)\n\t\t# typically, the first page includes conclusive information of a paper.\n\t\tpaper_summary = pdf_docs[0].text\n\n\tdir_summary_nodes = self.get_dir_nodes()\n\n\tselected_nodes = []\n\tselected_relevances = []\n\n\tfor idx in range(0, len(dir_summary_nodes), self.dir_choice_batch_size):\n\t\tsummary_nodes = dir_summary_nodes[idx: idx + self.dir_choice_batch_size]\n\t\tdir_context_str = default_format_node_batch_fn(summary_nodes=summary_nodes)\n\n\t\traw_response = self.llm.predict(\n\t\t\tDIR_CHOICE_SELECT_PROMPT,\n\t\t\tdir_context_str=dir_context_str,\n\t\t\tpaper_str=paper_summary,\n\t\t)\n\t\traw_choices, relevances = default_parse_choice_select_answer_fn(raw_response, len(summary_nodes))\n\t\tchoice_idxs = [choice - 1 for choice in raw_choices]\n\t\tchoice_summary_nodes = [summary_nodes[ci] for ci in choice_idxs]\n\t\tselected_nodes.extend(choice_summary_nodes)\n\t\tselected_relevances.extend(relevances)\n\n\tif len(selected_nodes) == 0:\n\t\treturn None\n\n\tzipped_list = list(zip(selected_nodes, selected_relevances))\n\tsorted_list = sorted(zipped_list, key=lambda x: x[1], reverse=True)\n\t# choose the most relevant and the deepest directory.\n\tbest_dir = sorted_list[0][0].ref_doc_id\n\n\tif verbose:\n\t\tfor node, relevance in sorted_list:\n\t\t\tprint_text(f\"&gt;&gt;&gt; dir: {node.ref_doc_id}, relevance: {relevance}\", color=\"blue\", end=\"\\n\")\n\tdef sub_dir_nodes(paper_dir: str):\n\t\tsub_nodes_with_score = []\n\t\tfor node, score in sorted_list:\n\t\t\tif Path(paper_dir) in Path(node.ref_doc_id).parents:\n\t\t\t\tsub_nodes_with_score.append((node, score))\n\t\treturn sub_nodes_with_score\n\n\tsub_list = sub_dir_nodes(best_dir)\n\twhile len(sub_list) &gt; 0:\n\t\tsub_list = sorted(sub_list, key=lambda x: x[1], reverse=True)\n\t\tbest_dir = sub_list[0][0].ref_doc_id\n\t\tsub_list = sub_dir_nodes(best_dir)\n\treturn best_dir\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/paper_store/#labridge.func_modules.paper.store.paper_store.PaperDirectorySummaryStore.set_possessor_research_categories","title":"<code>labridge.func_modules.paper.store.paper_store.PaperDirectorySummaryStore.set_possessor_research_categories(possessor_category_dict)</code>","text":"<p>Set the research categories of the possessors, this research categories is used to recommend proper new papers to the possessors.</p> PARAMETER DESCRIPTION <code>possessor_category_dict</code> <p>the research categories to be set. It is a dictionary with:</p> <ul> <li>key: possessor</li> <li>value: the list of research categories. For details about research categories, refer to the class <code>ArxivCategory</code>.</li> </ul> <p> TYPE: <code>Dict[str, List[str]]</code> </p> Source code in <code>labridge\\func_modules\\paper\\store\\paper_store.py</code> <pre><code>def set_possessor_research_categories(self, possessor_category_dict: Dict[str, List[str]]):\n\tr\"\"\"\n\tSet the research categories of the possessors, this research categories is used to recommend proper new papers\n\tto the possessors.\n\n\tArgs:\n\t\tpossessor_category_dict (Dict[str, List[str]]): the research categories to be set.\n\t\t\tIt is a dictionary with:\n\n\t\t\t- key: possessor\n\t\t\t- value: the list of research categories. For details about research categories,\n\t\t\trefer to the class `ArxivCategory`.\n\t\"\"\"\n\tfor possessor in possessor_category_dict.keys():\n\t\tdir_id = str((Path(self.paper_root) / possessor).relative_to(self.root))\n\t\tself._set_dir_metadata(\n\t\t\tdir_id=dir_id,\n\t\t\tkey=DIR_CATEGORY_NAME,\n\t\t\tval=possessor_category_dict[possessor],\n\t\t)\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/paper_store/#labridge.func_modules.paper.store.paper_store.PaperDirectorySummaryStore.update","title":"<code>labridge.func_modules.paper.store.paper_store.PaperDirectorySummaryStore.update(dir_description_dict)</code>","text":"<p>Update the relevant research fields of each directory. Typically used for manually set each directory's relevant research fields.</p> PARAMETER DESCRIPTION <code>dir_description_dict</code> <p>the descriptions of the paper directories - key: the directory path relative to root; - value: the relevant research fields of the directory.</p> <p> TYPE: <code>Dict[str, str]</code> </p> Source code in <code>labridge\\func_modules\\paper\\store\\paper_store.py</code> <pre><code>def update(self, dir_description_dict: Dict[str, str]):\n\tr\"\"\"\n\tUpdate the relevant research fields of each directory.\n\tTypically used for manually set each directory's relevant research fields.\n\n\tArgs:\n\t\tdir_description_dict (Dict[str, str]): the descriptions of the paper directories\n\t\t\t- key: the directory path relative to root;\n\t\t\t- value: the relevant research fields of the directory.\n\t\"\"\"\n\tfor dir_id in dir_description_dict.keys():\n\t\tself._set_dir_metadata(\n\t\t\tdir_id=dir_id,\n\t\t\tkey=PAPER_LEVEL_KEYWORDS,\n\t\t\tval=dir_description_dict[dir_id],\n\t\t)\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/paper_store/#labridge.func_modules.paper.store.paper_store.PaperStorage","title":"<code>labridge.func_modules.paper.store.paper_store.PaperStorage</code>","text":"<p>               Bases: <code>object</code></p> <p>Store the papers in vector index and summary index. The vector index stores the text chunks of the main text (and methods) and their embeddings. The summary index stores the summaries of the papers. Note that they can not share the storage context.</p> PARAMETER DESCRIPTION <code>docs</code> <p>the Documents to be stored.</p> <p> TYPE: <code>List[Document]</code> DEFAULT: <code>None</code> </p> <code>extra_docs</code> <p>extra Documents (like References), they are stored in the docstore of the index.</p> <p> TYPE: <code>List[Document]</code> DEFAULT: <code>None</code> </p> <code>vector_index</code> <p>existing vector index.</p> <p> TYPE: <code>VectorStoreIndex</code> DEFAULT: <code>None</code> </p> <code>vector_persist_dir</code> <p>the store directory of the vector index.</p> <p> TYPE: <code>Union[str, PathLike]</code> DEFAULT: <code>None</code> </p> <code>vector_transformations</code> <p>the transformations used in the construction of the vector index.</p> <p> TYPE: <code>List[TransformComponent]</code> DEFAULT: <code>None</code> </p> <code>paper_summary_index</code> <p>existing summary index.</p> <p> TYPE: <code>DocumentSummaryIndex</code> DEFAULT: <code>None</code> </p> <code>paper_summary_persist_dir</code> <p>the store directory of the summary index.</p> <p> TYPE: <code>Union[str, PathLike]</code> DEFAULT: <code>None</code> </p> <code>paper_summary_query</code> <p>the query used in summarizing the papers.</p> <p> TYPE: <code>str</code> DEFAULT: <code>PAPER_SUMMARIZE_QUERY</code> </p> <code>summary_transformations</code> <p>the transformations used in the construction of the summary index.</p> <p> TYPE: <code>List[TransformComponent]</code> DEFAULT: <code>None</code> </p> <code>summary_synthesizer</code> <p>the synthesizer used in summarizing the papers.</p> <p> TYPE: <code>PaperBatchSummarize</code> DEFAULT: <code>None</code> </p> <code>vector_storage_context</code> <p>the storage context of the vector index.</p> <p> TYPE: <code>StorageContext</code> DEFAULT: <code>None</code> </p> <code>paper_summary_storage_context</code> <p>the storage context of the summary index.</p> <p> TYPE: <code>StorageContext</code> DEFAULT: <code>None</code> </p> <code>service_context</code> <p>the service context.</p> <p> TYPE: <code>ServiceContext</code> DEFAULT: <code>None</code> </p> Source code in <code>labridge\\func_modules\\paper\\store\\paper_store.py</code> <pre><code>class PaperStorage(object):\n\tr\"\"\"\n\tStore the papers in vector index and summary index.\n\tThe vector index stores the text chunks of the main text (and methods) and their embeddings.\n\tThe summary index stores the summaries of the papers.\n\tNote that they can not share the storage context.\n\n\tArgs:\n\t\tdocs (List[Document]): the Documents to be stored.\n\t\textra_docs (List[Document]): extra Documents (like References),\n\t\t\tthey are stored in the docstore of the index.\n\t\tvector_index (VectorStoreIndex): existing vector index.\n\t\tvector_persist_dir (Union[str, os.PathLike]): the store directory of the vector index.\n\t\tvector_transformations (List[TransformComponent]): the transformations used in the construction of the vector index.\n\t\tpaper_summary_index (DocumentSummaryIndex): existing summary index.\n\t\tpaper_summary_persist_dir (Union[str, os.PathLike]): the store directory of the summary index.\n\t\tpaper_summary_query (str): the query used in summarizing the papers.\n\t\tsummary_transformations (List[TransformComponent]): the transformations used in the construction of the summary index.\n\t\tsummary_synthesizer (PaperBatchSummarize): the synthesizer used in summarizing the papers.\n\t\tvector_storage_context (StorageContext): the storage context of the vector index.\n\t\tpaper_summary_storage_context (StorageContext): the storage context of the summary index.\n\t\tservice_context (ServiceContext): the service context.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tdocs: Optional[List[Document]] = None,\n\t\textra_docs: Optional[List[Document]] = None,\n\t\tvector_index: Optional[VectorStoreIndex] = None,\n\t\tvector_persist_dir: Union[str, os.PathLike] = None,\n\t\tvector_transformations: List[TransformComponent] = None,\n\t\tpaper_summary_index: Optional[DocumentSummaryIndex] = None,\n\t\tpaper_summary_persist_dir: Union[str, os.PathLike] = None,\n\t\tpaper_summary_query: str = PAPER_SUMMARIZE_QUERY,\n\t\tsummary_transformations: List[TransformComponent] = None,\n\t\tsummary_synthesizer: Optional[PaperBatchSummarize] = None,\n\t\tvector_storage_context: Optional[StorageContext] = None,\n\t\tpaper_summary_storage_context: Optional[StorageContext] = None,\n\t\tservice_context: Optional[ServiceContext] = None,\n\t):\n\t\troot = Path(__file__)\n\t\tfor i in range(5):\n\t\t\troot = root.parent\n\t\tself.root = root\n\t\tself.llm = llm_from_settings_or_context(Settings, service_context)\n\t\tself.embed_model = embed_model_from_settings_or_context(Settings, service_context)\n\t\tself.service_context = service_context\n\t\tself.vector_persist_dir = vector_persist_dir or self._default_vector_persist_dir()\n\t\tself.paper_summary_persist_dir = paper_summary_persist_dir or self._default_paper_summary_persist_dir()\n\t\tself.vector_transformations = vector_transformations or self._default_vector_transformations()\n\t\tself.summary_transformations = summary_transformations or self._default_summary_transformations()\n\t\tself.summary_synthesizer = summary_synthesizer\n\t\tself.paper_summary_query = paper_summary_query\n\t\tif summary_synthesizer is None:\n\t\t\tself.summary_synthesizer = PaperBatchSummarize(llm=self.llm, max_tokens=8000, overlap_chunk_num=1)\n\n\t\tif (vector_index is None or paper_summary_index is None) and (docs is None or extra_docs is None):\n\t\t\traise ValueError(\"Please provide (docs, extra_docs) or existed (vector_index, summary_index).\")\n\t\tif None not in (vector_index, paper_summary_index):\n\t\t\tassert vector_index.storage_context != paper_summary_index.storage_context\n\t\t\tself.vector_index, self.paper_summary_index = vector_index, paper_summary_index\n\t\t\tself.paper_summary_index._response_synthesizer = self.summary_synthesizer\n\t\t\tself.vector_storage_context = vector_index.storage_context\n\t\t\tself.paper_summary_storage_context = paper_summary_index.storage_context\n\t\telse:\n\t\t\tself.vector_storage_context = vector_storage_context or StorageContext.from_defaults()\n\t\t\tself.paper_summary_storage_context = paper_summary_storage_context or StorageContext.from_defaults()\n\t\t\tself.build_index_from_docs(docs=docs, extra_docs=extra_docs)\n\n\tdef _default_vector_persist_dir(self) -&gt; str:\n\t\treturn str(self.root / DEFAULT_PAPER_VECTOR_PERSIST_DIR)\n\n\tdef _default_paper_summary_persist_dir(self) -&gt; str:\n\t\treturn str(self.root / DEFAULT_PAPER_SUMMARY_PERSIST_DIR)\n\n\tdef _default_vector_transformations(self) -&gt; List[TransformComponent]:\n\t\treturn [SentenceSplitter(chunk_size=1024, chunk_overlap=256, include_metadata=True), ]\n\n\tdef _default_summary_transformations(self) -&gt; List[TransformComponent]:\n\t\treturn [SentenceSplitter(chunk_size=1024, chunk_overlap=256, include_metadata=True), ]\n\n\tdef build_vector_index_from_docs(self, docs: List[Document]) -&gt; VectorStoreIndex:\n\t\tr\"\"\"\n\t\tBuild a vector database from the paper docs.\n\n\t\tArgs:\n\t\t\tdocs (List[Document]): The paper Documents.\n\n\t\tReturns:\n\t\t\tVectorStoreIndex\n\t\t\"\"\"\n\t\tif not self._are_valid_docs(docs):\n\t\t\traise ValueError(f\"Doc not in paper warehouse.\")\n\t\tvector_index = VectorStoreIndex.from_documents(documents=docs,\n\t\t\t\t\t\t\t\t\t\t\t\t\t   storage_context=self.vector_storage_context,\n\t\t\t\t\t\t\t\t\t\t\t\t\t   show_progress=True,\n\t\t\t\t\t\t\t\t\t\t\t\t\t   transformations=self.vector_transformations,\n\t\t\t\t\t\t\t\t\t\t\t\t\t   service_context=self.service_context)\n\t\tvector_index.set_index_id(PAPER_VECTOR_INDEX_ID)\n\t\treturn vector_index\n\n\tdef build_paper_summary_index_from_docs(self, docs: List[Document]) -&gt; DocumentSummaryIndex:\n\t\tr\"\"\"\n\t\tBuild a summary vector database from the paper docs.\n\n\t\tArgs:\n\t\t\tdocs (List[Document]): The paper Documents.\n\n\t\tReturns:\n\t\t\tDocumentSummaryIndex\n\t\t\"\"\"\n\t\tif not self._are_valid_docs(docs):\n\t\t\traise ValueError(f\"Doc not in paper warehouse.\")\n\t\tpaper_summary_index = DocumentSummaryIndex.from_documents(\n\t\t\tdocuments=docs,\n\t\t\tstorage_context=self.paper_summary_storage_context,\n\t\t\tshow_progress=True,\n\t\t\ttransformations=self.summary_transformations,\n\t\t\tsummary_query = self.paper_summary_query,\n\t\t\tservice_context=self.service_context,\n\t\t\tresponse_synthesizer = self.summary_synthesizer,\n\t\t)\n\t\tpaper_summary_index.set_index_id(PAPER_SUMMARY_INDEX_ID)\n\t\treturn paper_summary_index\n\n\tdef build_index_from_docs(\n\t\tself,\n\t\tdocs: List[Document],\n\t\textra_docs: List[Document],\n\t):\n\t\tif not self._are_valid_docs(docs + extra_docs):\n\t\t\traise ValueError(f\"Doc not in paper warehouse.\")\n\n\t\tself.vector_index = self.build_vector_index_from_docs(docs=docs[:1])\n\t\tself.paper_summary_index = self.build_paper_summary_index_from_docs(docs=docs[:1])\n\t\tself.persist()\n\t\tself.insert(paper_docs=docs[1:], extra_docs=extra_docs)\n\t\t# vector_index = self.build_vector_index_from_docs(docs)\n\t\t# paper_summary_index = self.build_paper_summary_index_from_docs(docs)\n\t\t# vector_index.docstore.add_documents(extra_docs)\n\t\t# paper_summary_index.docstore.add_documents(extra_docs)\n\t\t# return vector_index, paper_summary_index\n\n\t@classmethod\n\tdef from_storage(\n\t\tcls,\n\t\tvector_persist_dir: str,\n\t\tpaper_summary_persist_dir: str,\n\t\tvector_transformations: List[TransformComponent] = None,\n\t\tpaper_summary_query: str = PAPER_SUMMARIZE_QUERY,\n\t\tsummary_transformations: List[TransformComponent] = None,\n\t\tsummary_synthesizer: Optional[BaseSynthesizer] = None,\n\t\tservice_context: Optional[ServiceContext] = None,\n\t):\n\t\tr\"\"\" Load from an existing storage. \"\"\"\n\t\troot = Path(__file__)\n\t\tfor i in range(5):\n\t\t\troot = root.parent\n\n\t\tvector_persist_dir = vector_persist_dir or str(root / DEFAULT_PAPER_VECTOR_PERSIST_DIR)\n\t\tpaper_summary_persist_dir = paper_summary_persist_dir or str(root / DEFAULT_PAPER_SUMMARY_PERSIST_DIR)\n\t\tvector_storage_context = StorageContext.from_defaults(persist_dir=vector_persist_dir)\n\t\tpaper_summary_storage_context = StorageContext.from_defaults(persist_dir=paper_summary_persist_dir)\n\n\t\tvector_index = load_index_from_storage(\n\t\t\tstorage_context=vector_storage_context,\n\t\t\tindex_id=PAPER_VECTOR_INDEX_ID,\n\t\t\tservice_context=service_context,\n\t\t)\n\t\tpaper_summary_index = load_index_from_storage(\n\t\t\tstorage_context=paper_summary_storage_context,\n\t\t\tindex_id=PAPER_SUMMARY_INDEX_ID,\n\t\t\tservice_context=service_context,\n\t\t)\n\n\t\treturn cls(\n\t\t\tvector_index=vector_index,\n\t\t\tpaper_summary_index=paper_summary_index,\n\t\t\tvector_transformations=vector_transformations,\n\t\t\tvector_persist_dir=vector_persist_dir,\n\t\t\tpaper_summary_persist_dir=paper_summary_persist_dir,\n\t\t\tpaper_summary_query=paper_summary_query,\n\t\t\tsummary_transformations=summary_transformations,\n\t\t\tsummary_synthesizer=summary_synthesizer,\n\t\t\tservice_context=service_context,\n\t\t)\n\n\tdef _is_valid_doc(self, doc: Document) -&gt; bool:\n\t\tr\"\"\" Judge whether the paper doc is from the paper warehouse. \"\"\"\n\t\tdoc_id = doc.doc_id\n\t\tif CONTENT_TYPE_NAME not in doc.metadata.keys():\n\t\t\treturn False\n\t\tdoc_type = doc.metadata[CONTENT_TYPE_NAME]\n\t\trel_path = doc_id.split(f'_{doc_type}')[0]\n\t\tdoc_path = self.root / rel_path\n\t\treturn doc_path.exists()\n\n\tdef _are_valid_docs(self, docs: List[Document]) -&gt; bool:\n\t\tfor doc in docs:\n\t\t\tif not self._is_valid_doc(doc):\n\t\t\t\tprint(f\"Invalid doc. Doc {doc.doc_id} is not in paper warehouse.\")\n\t\t\t\treturn False\n\t\treturn True\n\n\tdef insert(self, paper_docs: List[Document], extra_docs: List[Document]):\n\t\tr\"\"\"\n\t\tAdd new papers to index.\n\t\tAssert all new papers are already categorized (that is: they are from the organized paper warehouse.)\n\n\t\tEncourage you to build a storage with one paper first, then use `insert` methods to add other papers,\n\t\tbecause we can control the summarize query depending on each doc's type.\n\n\t\tArgs:\n\t\t\tpaper_docs (List[Document]): these docs will be summarized; chunked and vectorized.\n\t\t\textra_docs (List[Document]): these docs are stored in docstore.\n\t\t\"\"\"\n\t\tif not self._are_valid_docs(paper_docs + extra_docs):\n\t\t\traise ValueError(f\"Doc not in paper warehouse.\")\n\n\t\tfor doc in paper_docs:\n\t\t\tdoc_type = doc.metadata[CONTENT_TYPE_NAME]\n\t\t\tif doc_type not in SummarizeQueries.keys():\n\t\t\t\traise ValueError(f'Invalid paper doc type: {doc_type}. Acceptable: {list(SummarizeQueries.keys())}.')\n\t\t\tsum_query = SummarizeQueries[doc_type]\n\t\t\tself.paper_summary_index._response_synthesizer._summary_query = sum_query\n\n\t\t\tif doc.doc_id not in self.paper_summary_index.docstore.get_all_ref_doc_info().keys():\n\t\t\t\tself.paper_summary_index.insert(document=doc)\n\t\t\tif doc.doc_id not in self.vector_index.docstore.get_all_ref_doc_info().keys():\n\t\t\t\tself.vector_index.insert(document=doc)\n\n\t\tself.vector_index.docstore.add_documents(extra_docs)\n\t\tself.paper_summary_index.docstore.add_documents(extra_docs)\n\t\tself.persist()\n\n\tdef persist(self,\n\t\t\t\tvector_persist_dir: Union[str, os.PathLike] = None,\n\t\t\t\tpaper_summary_persist_dir: Union[str, os.PathLike] = None):\n\t\tr\"\"\" Persist to the disk. \"\"\"\n\t\tif vector_persist_dir is None:\n\t\t\tvector_persist_dir = self.vector_persist_dir\n\t\tif paper_summary_persist_dir is None:\n\t\t\tpaper_summary_persist_dir = self.paper_summary_persist_dir\n\t\tself.vector_storage_context.persist(vector_persist_dir)\n\t\tself.paper_summary_storage_context.persist(paper_summary_persist_dir)\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/paper_store/#labridge.func_modules.paper.store.paper_store.PaperStorage.build_paper_summary_index_from_docs","title":"<code>labridge.func_modules.paper.store.paper_store.PaperStorage.build_paper_summary_index_from_docs(docs)</code>","text":"<p>Build a summary vector database from the paper docs.</p> PARAMETER DESCRIPTION <code>docs</code> <p>The paper Documents.</p> <p> TYPE: <code>List[Document]</code> </p> RETURNS DESCRIPTION <code>DocumentSummaryIndex</code> <p>DocumentSummaryIndex</p> Source code in <code>labridge\\func_modules\\paper\\store\\paper_store.py</code> <pre><code>def build_paper_summary_index_from_docs(self, docs: List[Document]) -&gt; DocumentSummaryIndex:\n\tr\"\"\"\n\tBuild a summary vector database from the paper docs.\n\n\tArgs:\n\t\tdocs (List[Document]): The paper Documents.\n\n\tReturns:\n\t\tDocumentSummaryIndex\n\t\"\"\"\n\tif not self._are_valid_docs(docs):\n\t\traise ValueError(f\"Doc not in paper warehouse.\")\n\tpaper_summary_index = DocumentSummaryIndex.from_documents(\n\t\tdocuments=docs,\n\t\tstorage_context=self.paper_summary_storage_context,\n\t\tshow_progress=True,\n\t\ttransformations=self.summary_transformations,\n\t\tsummary_query = self.paper_summary_query,\n\t\tservice_context=self.service_context,\n\t\tresponse_synthesizer = self.summary_synthesizer,\n\t)\n\tpaper_summary_index.set_index_id(PAPER_SUMMARY_INDEX_ID)\n\treturn paper_summary_index\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/paper_store/#labridge.func_modules.paper.store.paper_store.PaperStorage.build_vector_index_from_docs","title":"<code>labridge.func_modules.paper.store.paper_store.PaperStorage.build_vector_index_from_docs(docs)</code>","text":"<p>Build a vector database from the paper docs.</p> PARAMETER DESCRIPTION <code>docs</code> <p>The paper Documents.</p> <p> TYPE: <code>List[Document]</code> </p> RETURNS DESCRIPTION <code>VectorStoreIndex</code> <p>VectorStoreIndex</p> Source code in <code>labridge\\func_modules\\paper\\store\\paper_store.py</code> <pre><code>def build_vector_index_from_docs(self, docs: List[Document]) -&gt; VectorStoreIndex:\n\tr\"\"\"\n\tBuild a vector database from the paper docs.\n\n\tArgs:\n\t\tdocs (List[Document]): The paper Documents.\n\n\tReturns:\n\t\tVectorStoreIndex\n\t\"\"\"\n\tif not self._are_valid_docs(docs):\n\t\traise ValueError(f\"Doc not in paper warehouse.\")\n\tvector_index = VectorStoreIndex.from_documents(documents=docs,\n\t\t\t\t\t\t\t\t\t\t\t\t   storage_context=self.vector_storage_context,\n\t\t\t\t\t\t\t\t\t\t\t\t   show_progress=True,\n\t\t\t\t\t\t\t\t\t\t\t\t   transformations=self.vector_transformations,\n\t\t\t\t\t\t\t\t\t\t\t\t   service_context=self.service_context)\n\tvector_index.set_index_id(PAPER_VECTOR_INDEX_ID)\n\treturn vector_index\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/paper_store/#labridge.func_modules.paper.store.paper_store.PaperStorage.from_storage","title":"<code>labridge.func_modules.paper.store.paper_store.PaperStorage.from_storage(vector_persist_dir, paper_summary_persist_dir, vector_transformations=None, paper_summary_query=PAPER_SUMMARIZE_QUERY, summary_transformations=None, summary_synthesizer=None, service_context=None)</code>  <code>classmethod</code>","text":"<p>Load from an existing storage.</p> Source code in <code>labridge\\func_modules\\paper\\store\\paper_store.py</code> <pre><code>@classmethod\ndef from_storage(\n\tcls,\n\tvector_persist_dir: str,\n\tpaper_summary_persist_dir: str,\n\tvector_transformations: List[TransformComponent] = None,\n\tpaper_summary_query: str = PAPER_SUMMARIZE_QUERY,\n\tsummary_transformations: List[TransformComponent] = None,\n\tsummary_synthesizer: Optional[BaseSynthesizer] = None,\n\tservice_context: Optional[ServiceContext] = None,\n):\n\tr\"\"\" Load from an existing storage. \"\"\"\n\troot = Path(__file__)\n\tfor i in range(5):\n\t\troot = root.parent\n\n\tvector_persist_dir = vector_persist_dir or str(root / DEFAULT_PAPER_VECTOR_PERSIST_DIR)\n\tpaper_summary_persist_dir = paper_summary_persist_dir or str(root / DEFAULT_PAPER_SUMMARY_PERSIST_DIR)\n\tvector_storage_context = StorageContext.from_defaults(persist_dir=vector_persist_dir)\n\tpaper_summary_storage_context = StorageContext.from_defaults(persist_dir=paper_summary_persist_dir)\n\n\tvector_index = load_index_from_storage(\n\t\tstorage_context=vector_storage_context,\n\t\tindex_id=PAPER_VECTOR_INDEX_ID,\n\t\tservice_context=service_context,\n\t)\n\tpaper_summary_index = load_index_from_storage(\n\t\tstorage_context=paper_summary_storage_context,\n\t\tindex_id=PAPER_SUMMARY_INDEX_ID,\n\t\tservice_context=service_context,\n\t)\n\n\treturn cls(\n\t\tvector_index=vector_index,\n\t\tpaper_summary_index=paper_summary_index,\n\t\tvector_transformations=vector_transformations,\n\t\tvector_persist_dir=vector_persist_dir,\n\t\tpaper_summary_persist_dir=paper_summary_persist_dir,\n\t\tpaper_summary_query=paper_summary_query,\n\t\tsummary_transformations=summary_transformations,\n\t\tsummary_synthesizer=summary_synthesizer,\n\t\tservice_context=service_context,\n\t)\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/paper_store/#labridge.func_modules.paper.store.paper_store.PaperStorage.insert","title":"<code>labridge.func_modules.paper.store.paper_store.PaperStorage.insert(paper_docs, extra_docs)</code>","text":"<p>Add new papers to index. Assert all new papers are already categorized (that is: they are from the organized paper warehouse.)</p> <p>Encourage you to build a storage with one paper first, then use <code>insert</code> methods to add other papers, because we can control the summarize query depending on each doc's type.</p> PARAMETER DESCRIPTION <code>paper_docs</code> <p>these docs will be summarized; chunked and vectorized.</p> <p> TYPE: <code>List[Document]</code> </p> <code>extra_docs</code> <p>these docs are stored in docstore.</p> <p> TYPE: <code>List[Document]</code> </p> Source code in <code>labridge\\func_modules\\paper\\store\\paper_store.py</code> <pre><code>def insert(self, paper_docs: List[Document], extra_docs: List[Document]):\n\tr\"\"\"\n\tAdd new papers to index.\n\tAssert all new papers are already categorized (that is: they are from the organized paper warehouse.)\n\n\tEncourage you to build a storage with one paper first, then use `insert` methods to add other papers,\n\tbecause we can control the summarize query depending on each doc's type.\n\n\tArgs:\n\t\tpaper_docs (List[Document]): these docs will be summarized; chunked and vectorized.\n\t\textra_docs (List[Document]): these docs are stored in docstore.\n\t\"\"\"\n\tif not self._are_valid_docs(paper_docs + extra_docs):\n\t\traise ValueError(f\"Doc not in paper warehouse.\")\n\n\tfor doc in paper_docs:\n\t\tdoc_type = doc.metadata[CONTENT_TYPE_NAME]\n\t\tif doc_type not in SummarizeQueries.keys():\n\t\t\traise ValueError(f'Invalid paper doc type: {doc_type}. Acceptable: {list(SummarizeQueries.keys())}.')\n\t\tsum_query = SummarizeQueries[doc_type]\n\t\tself.paper_summary_index._response_synthesizer._summary_query = sum_query\n\n\t\tif doc.doc_id not in self.paper_summary_index.docstore.get_all_ref_doc_info().keys():\n\t\t\tself.paper_summary_index.insert(document=doc)\n\t\tif doc.doc_id not in self.vector_index.docstore.get_all_ref_doc_info().keys():\n\t\t\tself.vector_index.insert(document=doc)\n\n\tself.vector_index.docstore.add_documents(extra_docs)\n\tself.paper_summary_index.docstore.add_documents(extra_docs)\n\tself.persist()\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/paper_store/#labridge.func_modules.paper.store.paper_store.PaperStorage.persist","title":"<code>labridge.func_modules.paper.store.paper_store.PaperStorage.persist(vector_persist_dir=None, paper_summary_persist_dir=None)</code>","text":"<p>Persist to the disk.</p> Source code in <code>labridge\\func_modules\\paper\\store\\paper_store.py</code> <pre><code>def persist(self,\n\t\t\tvector_persist_dir: Union[str, os.PathLike] = None,\n\t\t\tpaper_summary_persist_dir: Union[str, os.PathLike] = None):\n\tr\"\"\" Persist to the disk. \"\"\"\n\tif vector_persist_dir is None:\n\t\tvector_persist_dir = self.vector_persist_dir\n\tif paper_summary_persist_dir is None:\n\t\tpaper_summary_persist_dir = self.paper_summary_persist_dir\n\tself.vector_storage_context.persist(vector_persist_dir)\n\tself.paper_summary_storage_context.persist(paper_summary_persist_dir)\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/shared_paper_store/","title":"Shared paper store","text":""},{"location":"code_docs/func_modules/paper/store/shared_paper_store/#labridge.func_modules.paper.store.shared_paper_store","title":"<code>labridge.func_modules.paper.store.shared_paper_store</code>","text":"<p>Shared paper storage.</p> <p>A Tree-type storage.</p> <p>With members as the first child nodes. (Member Node type)</p> <p>Then recursive DIR nodes, corresponding to the warehouse's dir. (DIR node type)</p> <p>The leaf nodes: paper node. (include summary, abstraction, metadata, Title, ref_filepath) (Paper node type)</p> <p>The child nodes of paper node: doc nodes. () (with overlap) (Doc node type)</p> <p>Another child nodes of paper node: doc nodes for note. (without overlap, more detailed.) (Note Doc node type).</p> <p>Notes: The note of the corresponding context. (Note node type.)</p>"},{"location":"code_docs/func_modules/paper/store/shared_paper_store/#labridge.func_modules.paper.store.shared_paper_store.MarkAsChunk","title":"<code>labridge.func_modules.paper.store.shared_paper_store.MarkAsChunk</code>","text":"<p>               Bases: <code>TransformComponent</code></p> <p>A TransformComponent to mark the node type of each node of the vector index as <code>chunk_node</code>.</p> Source code in <code>labridge\\func_modules\\paper\\store\\shared_paper_store.py</code> <pre><code>class MarkAsChunk(TransformComponent):\n\tr\"\"\"\n\tA TransformComponent to mark the node type of each node of the vector index as `chunk_node`.\n\t\"\"\"\n\n\tdef __call__(self, nodes: List[\"BaseNode\"], **kwargs: Any) -&gt; List[\"BaseNode\"]:\n\t\tfor node in nodes:\n\t\t\tnode.metadata[SHARED_PAPER_NODE_TYPE] = SharedPaperNodeType.PAPER_CHUNK\n\t\treturn nodes\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/shared_paper_store/#labridge.func_modules.paper.store.shared_paper_store.MarkAsChunkForNote","title":"<code>labridge.func_modules.paper.store.shared_paper_store.MarkAsChunkForNote</code>","text":"<p>               Bases: <code>TransformComponent</code></p> <p>A TransformComponent to mark the node type of each node of the notes vector index as <code>chunk_node</code>.</p> Source code in <code>labridge\\func_modules\\paper\\store\\shared_paper_store.py</code> <pre><code>class MarkAsChunkForNote(TransformComponent):\n\tr\"\"\"\n\tA TransformComponent to mark the node type of each node of the notes vector index as `chunk_node`.\n\t\"\"\"\n\n\tdef __call__(self, nodes: List[\"BaseNode\"], **kwargs: Any) -&gt; List[\"BaseNode\"]:\n\t\tfor node in nodes:\n\t\t\tnode.metadata[SHARED_PAPER_NODE_TYPE] = SharedPaperNoteNodeType.PAPER_CHUNK\n\t\treturn nodes\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/shared_paper_store/#labridge.func_modules.paper.store.shared_paper_store.SharedPaperStorage","title":"<code>labridge.func_modules.paper.store.shared_paper_store.SharedPaperStorage</code>","text":"<p>               Bases: <code>object</code></p> <p>This class is for storing shared papers and notes. Two vector databases are used for storage:</p> <ul> <li>Paper vector index: This vector database records the overlapped paper content chunks along with detailed metadata. This database is structured the same as the directory structure of the shared paper warehouse. For example:</li> </ul> <p><pre><code>                                                                                        root_node\n                                                /                               /                               \\                       \\\n                                        user_1                  user_2          ...             user_m          user_n\n                                /                       \\\n                        dir_1_1         ...     dir_1_k\n                        /                               /\n                dir_2_1         ...     Paper_1\n                /       \\                       /       \\\n        Paper_1 Paper_p Chunk_1 Chunk_l\n        /       \\\nChunk_1 Chunk_l\n</code></pre> - Notes vector index: This vector database non-overlapped content chunks of smaller size and corresponding user notes. Each paper uses its DOI as the sign. This database is structured as follows:</p> <pre><code>                                                                                        root_node\n                                        /                                       /                               \\                                       \\\n                                DOI_1                           DOI_2                           DOI_m                           DOI_n\n                        /                       \\                                                                                               /                       \\\n                Chunk_1                 Chunk_k                                                                         Chunk_1                 Chunk_k\n        /                       \\                                                                                                                               /                       \\\nNote_1                  Note_l                                                                                                          Note_1                  Note_l\n</code></pre> <p>The <code>PaperReader</code> is used to parse content and metadata from the paper pdf.</p> Note <p>the metadata <code>Title</code> and <code>DOI</code> is essential. The <code>Title</code> is extracted by LLM, and the <code>DOI</code> is obtained through</p> <p>CrossRef API according to the extracted <code>Title</code>. If any of the two fails in extraction, the paper recording fails.</p> PARAMETER DESCRIPTION <code>llm</code> <p>The used LLM</p> <p> TYPE: <code>LLM</code> </p> <code>vector_index</code> <p>The vector database for storing shared paper contents.</p> <p> TYPE: <code>VectorStoreIndex</code> </p> <code>notes_vector_index</code> <p>The vector database fot storing non-overlapped paper content chunks and their corresponding user notes.</p> <p> TYPE: <code>VectorStoreIndex</code> </p> <code>persist_dir</code> <p>The persist directory of the vector_index.</p> <p> TYPE: <code>str</code> </p> <code>notes_persist_dir</code> <p>The persist directory of the notes_vector_index.</p> <p> TYPE: <code>str</code> </p> Source code in <code>labridge\\func_modules\\paper\\store\\shared_paper_store.py</code> <pre><code>class SharedPaperStorage(object):\n\tr\"\"\"\n\tThis class is for storing shared papers and notes.\n\tTwo vector databases are used for storage:\n\n\t- Paper vector index: This vector database records the overlapped paper content chunks along with detailed metadata.\n\tThis database is structured the same as the directory structure of the shared paper warehouse. For example:\n\n\t```\n\t\t\t\t\t\t\t\t\t\t\t\troot_node\n\t\t\t\t\t\t\t/\t\t\t\t/\t\t\t\t\\\t\t\t\\\n\t\t\t\t\t\tuser_1\t\t\tuser_2\t\t...\t\tuser_m\t\tuser_n\n\t\t\t\t\t/\t\t\t\\\n\t\t\t\tdir_1_1\t\t...\tdir_1_k\n\t\t\t\t/\t\t\t\t/\n\t\t\tdir_2_1\t\t...\tPaper_1\n\t\t\t/\t\\\t\t\t/\t\\\n\t\tPaper_1\tPaper_p\tChunk_1\tChunk_l\n\t\t/\t\\\n\tChunk_1\tChunk_l\n\t```\n\t- Notes vector index: This vector database non-overlapped content chunks of smaller size and corresponding user notes.\n\tEach paper uses its DOI as the sign. This database is structured as follows:\n\n\t```\n\t\t\t\t\t\t\t\t\t\t\t\troot_node\n\t\t\t\t\t\t/\t\t\t\t\t/\t\t\t\t\\\t\t\t\t\t\\\n\t\t\t\t\tDOI_1\t\t\t\tDOI_2\t\t\t\tDOI_m\t\t\t\tDOI_n\n\t\t\t\t/\t\t\t\\\t\t\t\t\t\t\t\t\t\t\t\t/\t\t\t\\\n\t\t\tChunk_1\t\t\tChunk_k\t\t\t\t\t\t\t\t\t\tChunk_1\t\t\tChunk_k\n\t\t/\t\t\t\\\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t/\t\t\t\\\n\tNote_1\t\t\tNote_l\t\t\t\t\t\t\t\t\t\t\t\t\t\tNote_1\t\t\tNote_l\n\t```\n\n\tThe `PaperReader` is used to parse content and metadata from the paper pdf.\n\n\tNote:\n\t\tthe metadata `Title` and `DOI` is essential. The `Title` is extracted by LLM, and the `DOI` is obtained through\n\tCrossRef API according to the extracted `Title`. If any of the two fails in extraction, the paper recording fails.\n\n\tArgs:\n\t\tllm (LLM): The used LLM\n\t\tvector_index (VectorStoreIndex): The vector database for storing shared paper contents.\n\t\tnotes_vector_index (VectorStoreIndex): The vector database fot storing non-overlapped paper content chunks and\n\t\t\ttheir corresponding user notes.\n\t\tpersist_dir (str): The persist directory of the vector_index.\n\t\tnotes_persist_dir (str): The persist directory of the notes_vector_index.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tllm: LLM,\n\t\tvector_index: VectorStoreIndex,\n\t\tnotes_vector_index: VectorStoreIndex,\n\t\tpersist_dir: str,\n\t\tnotes_persist_dir: str,\n\t):\n\t\troot = Path(__file__)\n\t\tfor idx in range(5):\n\t\t\troot = root.parent\n\t\tself._root = root\n\t\tself.vector_index = vector_index\n\t\tself.vector_index.set_index_id(index_id=SHARED_PAPER_VECTOR_INDEX_ID)\n\t\tself.notes_vector_index = notes_vector_index\n\t\tself.notes_vector_index.set_index_id(index_id=SHARED_PAPER_NOTES_INDEX_ID)\n\t\tself.vector_index.set_index_id(SHARED_PAPER_VECTOR_INDEX_ID)\n\t\tself.persist_dir = persist_dir\n\t\tself.notes_persist_dir = notes_persist_dir\n\t\tself._fs = fsspec.filesystem(\"file\")\n\t\tself._account_manager = AccountManager()\n\t\tself.paper_reader = PaperReader(llm=llm)\n\t\tself._summarizer = PaperBatchSummarize(llm=llm)\n\n\t@classmethod\n\tdef from_storage(\n\t\tcls,\n\t\tpersist_dir: str,\n\t\tnotes_persist_dir: str,\n\t\tllm: LLM,\n\t\tembed_model: BaseEmbedding,\n\t):\n\t\tvector_storage_context = StorageContext.from_defaults(persist_dir=persist_dir)\n\t\tvector_index = load_index_from_storage(\n\t\t\tstorage_context=vector_storage_context,\n\t\t\tindex_id=SHARED_PAPER_VECTOR_INDEX_ID,\n\t\t\tembed_model=embed_model,\n\t\t)\n\t\tnotes_storage_context = StorageContext.from_defaults(persist_dir=notes_persist_dir)\n\t\tnotes_vector_index = load_index_from_storage(\n\t\t\tstorage_context=notes_storage_context,\n\t\t\tindex_id=SHARED_PAPER_NOTES_INDEX_ID,\n\t\t\tembed_model=embed_model,\n\t\t)\n\t\treturn cls(\n\t\t\tllm=llm,\n\t\t\tvector_index=vector_index,\n\t\t\tnotes_vector_index=notes_vector_index,\n\t\t\tpersist_dir=persist_dir,\n\t\t\tnotes_persist_dir=notes_persist_dir,\n\t\t)\n\n\t@classmethod\n\tdef from_default(\n\t\tcls,\n\t\tllm: LLM,\n\t\tembed_model: BaseEmbedding,\n\t):\n\t\troot = Path(__file__)\n\t\tfor idx in range(5):\n\t\t\troot = root.parent\n\n\t\tpersist_dir = str(root / SHARED_PAPER_VECTOR_INDEX_PERSIST_DIR)\n\t\tnotes_persist_dir = str(root / SHARED_PAPER_NOTES_INDEX_PERSIST_DIR)\n\t\tfs = fsspec.filesystem(\"file\")\n\t\tif fs.exists(persist_dir):\n\t\t\treturn cls.from_storage(\n\t\t\t\tpersist_dir=persist_dir,\n\t\t\t\tnotes_persist_dir=notes_persist_dir,\n\t\t\t\tllm=llm,\n\t\t\t\tembed_model=embed_model,\n\t\t\t)\n\n\t\troot_node = TextNode(\n\t\t\ttext=f\"Root node for the shared papers\",\n\t\t\tid_=SHARED_PAPER_ROOT_NODE_NAME,\n\t\t\tmetadata={\n\t\t\t\tSHARED_PAPER_NODE_TYPE: SharedPaperNodeType.ROOT,\n\t\t\t}\n\t\t)\n\t\tnodes = [root_node]\n\n\t\taccount_manager = AccountManager()\n\t\tusers = account_manager.get_users()\n\n\t\troot_children = []\n\t\tfor user_id in users:\n\t\t\tuser_node = TextNode(\n\t\t\t\ttext=f\"The papers belonging to the user {user_id}\",\n\t\t\t\tid_=user_id,\n\t\t\t\tmetadata={\n\t\t\t\t\tSHARED_PAPER_NODE_TYPE: SharedPaperNodeType.USER,\n\t\t\t\t}\n\t\t\t)\n\t\t\tnodes.append(user_node)\n\t\t\troot_children.append(RelatedNodeInfo(node_id=user_node.node_id))\n\t\t\tuser_node.relationships[NodeRelationship.PARENT] = RelatedNodeInfo(node_id=root_node.node_id)\n\n\t\troot_node.relationships[NodeRelationship.CHILD] = root_children\n\n\t\tvector_index = VectorStoreIndex(\n\t\t\tnodes=nodes,\n\t\t\tembed_model=embed_model,\n\t\t)\n\n\t\tnotes_root_node = TextNode(\n\t\t\ttext=\"Root node for the paper notes.\",\n\t\t\tid_=SHARED_PAPER_ROOT_NODE_NAME,\n\t\t\tmetadata={\n\t\t\t\tSHARED_PAPER_NODE_TYPE: SharedPaperNoteNodeType.ROOT,\n\t\t\t}\n\t\t)\n\t\tnotes_vector_index = VectorStoreIndex(\n\t\t\tnodes=[notes_root_node],\n\t\t\tembed_model=embed_model,\n\t\t)\n\n\t\treturn cls(\n\t\t\tllm=llm,\n\t\t\tvector_index=vector_index,\n\t\t\tnotes_vector_index=notes_vector_index,\n\t\t\tpersist_dir=persist_dir,\n\t\t\tnotes_persist_dir=notes_persist_dir,\n\t\t)\n\n\t@property\n\tdef _default_overlapped_transformations(self):\n\t\tr\"\"\" Transformations for chunks in vector_index \"\"\"\n\t\treturn [SentenceSplitter(chunk_size=1024, chunk_overlap=256, include_metadata=True), MarkAsChunk()]\n\n\t@property\n\tdef _default_non_overlapped_transformations(self):\n\t\tr\"\"\" Transformation for chunks in notes_vector_index \"\"\"\n\t\treturn [SentenceSplitter(chunk_size=128, chunk_overlap=0, include_metadata=False), MarkAsChunkForNote()]\n\n\tdef _update_node(self, node_id: str, node: BaseNode):\n\t\tr\"\"\" Update a node in the vector_index, if the node with `node_id` does not exist, create one. \"\"\"\n\t\ttry:\n\t\t\tself.vector_index.delete_nodes([node_id])\n\t\texcept:\n\t\t\tpass\n\t\tself.vector_index.insert_nodes([node])\n\n\tdef _update_note_index_node(self, node_id: str, node: BaseNode):\n\t\tr\"\"\" Update a node in the notes_vector_index, if the node with `node_id` does not exist, create one. \"\"\"\n\t\ttry:\n\t\t\tself.notes_vector_index.delete_nodes([node_id])\n\t\texcept:\n\t\t\tpass\n\t\tself.notes_vector_index.insert_nodes([node])\n\n\tdef _get_node(self, node_id: str) -&gt; Optional[BaseNode]:\n\t\tr\"\"\" Get node from the vector_index. \"\"\"\n\t\ttry:\n\t\t\tnode = self.vector_index.docstore.get_node(node_id=node_id, raise_error=True)\n\t\t\treturn node\n\t\texcept ValueError:\n\t\t\treturn None\n\n\tdef _get_nodes(self, node_ids: List[str], node_types: List[str] = None) -&gt; List[BaseNode]:\n\t\tr\"\"\"\n\t\tGet nodes from the vector_index, with optional node type filters.\n\n\t\tArgs:\n\t\t\tnode_ids (List[str]): The ids of the nodes to be obtained.\n\t\t\tnode_types (List[str]): If given, only nodes with types in the given node_types will be selected.\n\n\t\tReturns:\n\t\t\tThe corresponding nodes.\n\t\t\"\"\"\n\t\tnodes = self.vector_index.docstore.get_nodes(node_ids=node_ids, raise_error=True)\n\t\tif node_types is not None:\n\t\t\tnodes = [n for n in nodes if n.metadata[SHARED_PAPER_NODE_TYPE] in node_types]\n\t\treturn nodes\n\n\tdef _get_notes_index_node(self, node_id: str) -&gt; Optional[BaseNode]:\n\t\tr\"\"\" Get node from the notes vector index. \"\"\"\n\t\ttry:\n\t\t\tnode = self.notes_vector_index.docstore.get_node(node_id=node_id, raise_error=True)\n\t\t\treturn node\n\t\texcept ValueError:\n\t\t\treturn None\n\n\tdef _new_dir_node(self, rel_dir_path: str) -&gt; TextNode:\n\t\tr\"\"\" Create a new DIR node in the vector_index. \"\"\"\n\t\tdir_node = TextNode(\n\t\t\ttext=f\"The directory of {rel_dir_path}\",\n\t\t\tid_=rel_dir_path,\n\t\t\tmetadata={\n\t\t\t\tSHARED_PAPER_NODE_TYPE: SharedPaperNodeType.DIR,\n\t\t\t}\n\t\t)\n\t\treturn dir_node\n\n\tdef _insert_as_child_nodes(self, node: BaseNode, child_nodes: List[BaseNode]):\n\t\tr\"\"\"\n\t\tSet the child_nodes of the given node, and set the node as the PARENT of each child node in the child_nodes.\n\n\t\tArgs:\n\t\t\tnode (BaseNode): The parent node.\n\t\t\tchild_nodes (List[BaseNode]): The child nodes.\n\n\t\tReturns:\n\t\t\tNone\n\t\t\"\"\"\n\t\tchildren = node.child_nodes or []\n\t\tfor child in child_nodes:\n\t\t\tchildren.append(\n\t\t\t\tRelatedNodeInfo(node_id=child.node_id)\n\t\t\t)\n\t\t\tchild.relationships[NodeRelationship.PARENT] = RelatedNodeInfo(\n\t\t\t\tnode_id=node.node_id\n\t\t\t)\n\t\tnode.relationships[NodeRelationship.CHILD] = children\n\n\tdef _new_paper_node(self, dir_node: BaseNode, paper_info: dict) -&gt; Tuple[BaseNode, BaseNode]:\n\t\tr\"\"\"\n\t\tCreate a paper node under the given dir_node. Use rel_path as node_id.\n\n\t\tArgs:\n\t\t\tdir_node (BaseNode): The dir_node indicating a specific directory in the paper warehouse.\n\t\t\tpaper_info (dict): The metadata of the info. `PAPER_REL_FILE_PATH` is necessary.\n\n\t\tReturns:\n\t\t\tThe updated dir_node and the created paper_node.\n\n\t\tRaises:\n\t\t\tValueError: If `PAPER_REL_FILE_PATH` is not given in the paper_info.\n\t\t\"\"\"\n\t\tpaper_rel_path = paper_info.get(PAPER_REL_FILE_PATH, None)\n\t\tif paper_rel_path is None:\n\t\t\traise ValueError(f\"Invalid paper metadata, the key: {PAPER_REL_FILE_PATH} is needed.\")\n\n\t\tmetadata = {\n\t\t\tSHARED_PAPER_NODE_TYPE: SharedPaperNodeType.PAPER,\n\t\t}\n\t\tmetadata.update(paper_info)\n\n\t\tpaper_node = TextNode(\n\t\t\ttext=\"\",\n\t\t\tid_=paper_rel_path,\n\t\t\tmetadata=metadata,\n\t\t)\n\t\tself._insert_as_child_nodes(node=dir_node, child_nodes=[paper_node])\n\t\treturn dir_node, paper_node\n\n\tdef _new_doi_node(self, doi: str) -&gt; BaseNode:\n\t\tr\"\"\"\n\t\tCreate a new DOI node in the notes vector index, as the child of the root node.\n\n\t\tArgs:\n\t\t\tdoi (str): The DOI of a paper.\n\n\t\tReturns:\n\t\t\tThe created DOI node.\n\t\t\"\"\"\n\t\tmetadata = {\n\t\t\tSHARED_PAPER_NODE_TYPE: SharedPaperNoteNodeType.DOI,\n\t\t}\n\t\tdoi_node = TextNode(\n\t\t\ttext=f\"DOI: {doi}\",\n\t\t\tid_=doi,\n\t\t\tmetadata=metadata,\n\t\t)\n\n\t\tnote_root_node = self._get_notes_index_node(node_id=SHARED_PAPER_ROOT_NODE_NAME)\n\t\tself._insert_as_child_nodes(node=note_root_node, child_nodes=[doi_node, ])\n\t\tself._update_note_index_node(node_id=note_root_node.node_id, node=note_root_node)\n\t\treturn doi_node\n\n\tdef _new_note_node(self, user_id: str, note: str) -&gt; BaseNode:\n\t\tr\"\"\" Create a new note node. \"\"\"\n\t\tnode = TextNode(\n\t\t\ttext=note,\n\t\t\tmetadata={\n\t\t\t\tSHARED_PAPER_NODE_TYPE: SharedPaperNoteNodeType.NOTE,\n\t\t\t\t\"user_id\": user_id,\n\t\t\t}\n\t\t)\n\t\treturn node\n\n\tdef _is_valid_paper_dir(self, rel_dir: str) -&gt; bool:\n\t\tr\"\"\" Only when the relative dir path is under the `SHARED_PAPER_WAREHOUSE_DIR`, it is valid. \"\"\"\n\t\ttry:\n\t\t\tPath(rel_dir).relative_to(SHARED_PAPER_WAREHOUSE_DIR)\n\t\t\treturn True\n\t\texcept ValueError:\n\t\t\treturn False\n\n\tdef make_dirs(self, rel_dir: str):\n\t\tr\"\"\"\n\t\tRecursively add DIR nodes for a rel_dir.\n\n\t\trelative path to what? match the old vector index.\n\n\t\tArgs:\n\t\t\trel_dir (str): The path of a directory relative to the root.\n\n\t\tReturns:\n\t\t\tNone\n\n\t\tRaises:\n\t\t\tValueError: If the given rel_dir is not valid, that is, the rel_dir is not under the `SHARED_PAPER_WAREHOUSE_DIR`.\n\n\t\t\"\"\"\n\t\tif not self._is_valid_paper_dir(rel_dir=rel_dir):\n\t\t\traise ValueError(f\"The directory {rel_dir} is not under the warehouse {SHARED_PAPER_WAREHOUSE_DIR}.\")\n\n\t\tpath_parts = Path(rel_dir).relative_to(SHARED_PAPER_WAREHOUSE_DIR).parts\n\t\tassert len(path_parts) &gt; 1\n\n\t\tuser_id = path_parts[0]\n\t\tself._account_manager.check_valid_user(user_id=user_id)\n\t\tuser_node = self._get_node(node_id=user_id) or self.add_user_node(user_id=user_id)\n\t\tdir_path = Path(SHARED_PAPER_WAREHOUSE_DIR) / user_id\n\t\t# [node, whether to update]\n\t\tdirs_nodes = [[user_node, False]]\n\n\t\tfor part in path_parts[1:]:\n\t\t\tdir_path = dir_path / part\n\t\t\tdir_node = self._get_node(node_id=str(dir_path))\n\t\t\tif_new_dir = dir_node is None\n\t\t\tif if_new_dir:\n\t\t\t\tdir_node = self._new_dir_node(rel_dir_path=str(dir_path))\n\t\t\t\tparent_node = dirs_nodes[-1][0]\n\t\t\t\tdirs_nodes[-1][1] = True\n\t\t\t\tdir_node.relationships[NodeRelationship.PARENT] = RelatedNodeInfo(\n\t\t\t\t\tnode_id=parent_node.node_id,\n\t\t\t\t)\n\t\t\t\tself._insert_as_child_nodes(node=parent_node, child_nodes=[dir_node])\n\t\t\tdirs_nodes.append([dir_node, if_new_dir])\n\n\t\tto_update_nodes = [pair[0] for pair in dirs_nodes if pair[1]]\n\t\tfor node in to_update_nodes:\n\t\t\tself._update_node(node_id=node.node_id, node=node)\n\n\tdef summarize_paper(self, paper_node_id: str) -&gt; Optional[str]:\n\t\tr\"\"\"\n\t\tSummarize a paper in the shared paper storage.\n\n\t\tArgs:\n\t\t\tpaper_node_id (str): The node id of the corresponding paper node.\n\n\t\tReturns:\n\t\t\tOptional[str]: The summary of th paper. If the paper does not exist, return None.\n\t\t\"\"\"\n\t\tpaper_node = self._get_node(node_id=paper_node_id)\n\t\tif paper_node is None:\n\t\t\treturn None\n\n\t\tsummary = paper_node.metadata.get(SHARED_PAPER_SUMMARY_KEY, None)\n\t\tif summary is not None:\n\t\t\treturn summary\n\n\t\tcontent_ids = [child.node_id for child in paper_node.child_nodes]\n\t\tcontent_nodes = self._get_nodes(\n\t\t\tnode_ids=content_ids,\n\t\t\tnode_types=[SharedPaperNodeType.PAPER_CHUNK]\n\t\t)\n\n\t\tnodes_with_scores = [NodeWithScore(node=n) for n in content_nodes]\n\t\t# get the summary for each doc_id\n\t\tsummary_response = self._summarizer.synthesize(nodes=nodes_with_scores, query=\"\")\n\t\tsummary_response = cast(Response, summary_response)\n\t\tsummary = summary_response.response\n\t\tpaper_node.metadata[SHARED_PAPER_SUMMARY_KEY] = summary\n\t\tself._update_node(node_id=paper_node.node_id, node=paper_node)\n\t\treturn summary\n\n\tasync def asummarize_paper(self, paper_node_id: str) -&gt; Optional[str]:\n\t\tr\"\"\"\n\t\tAsynchronously summarize a paper in the shared paper storage.\n\n\t\tArgs:\n\t\t\tpaper_node_id (str): The node id of the corresponding paper node.\n\n\t\tReturns:\n\t\t\tOptional[str]: The summary of th paper. If the paper does not exist, return None.\n\t\t\"\"\"\n\t\tpaper_node = self._get_node(node_id=paper_node_id)\n\t\tif paper_node is None:\n\t\t\treturn None\n\n\t\tsummary = paper_node.metadata.get(SHARED_PAPER_SUMMARY_KEY, None)\n\t\tif summary is not None:\n\t\t\treturn summary\n\n\t\tcontent_ids = [child.node_id for child in paper_node.child_nodes]\n\t\tcontent_nodes = self._get_nodes(\n\t\t\tnode_ids=content_ids,\n\t\t\tnode_types=[SharedPaperNodeType.PAPER_CHUNK]\n\t\t)\n\n\t\tnodes_with_scores = [NodeWithScore(node=n) for n in content_nodes]\n\t\t# get the summary for each doc_id\n\t\tsummary_response = await self._summarizer.asynthesize(nodes=nodes_with_scores, query=\"\")\n\t\tsummary_response = cast(Response, summary_response)\n\t\tsummary = summary_response.response\n\t\tpaper_node.metadata[SHARED_PAPER_SUMMARY_KEY] = summary\n\t\tself._update_node(node_id=paper_node.node_id, node=paper_node)\n\t\treturn summary\n\n\tdef insert_single_paper(\n\t\tself,\n\t\ttarget_rel_dir: str,\n\t\traw_paper_path: str,\n\t\tpaper_summary: str = None,\n\t\textra_metadata: dict = None,\n\t) -&gt; Optional[str]:\n\t\tr\"\"\"\n\t\tAdd a paper to the shared paper storage.\n\n\t\tArgs:\n\t\t\ttarget_rel_dir (str): The directory into which the new paper is inserted.\n\t\t\traw_paper_path (str): The file path of the paper.\n\t\t\tpaper_summary (str): If the paper has been summarized before, the summary can be provided to save cost.\n\t\t\textra_metadata (dict): Extra metadata obtained from other approaches such as ArXiv.\n\n\t\tReturns:\n\t\t\tOptional[str]: The node id of the new paper node.\n\t\t\t\tReturn None in these situation:\n\n\t\t\t\t- The target_rel_dir is not valid.\n\t\t\t\t- The raw_paper_path does not exist.\n\t\t\t\t- The given paper is not in pdf format.\n\t\t\t\t- The PaperReader fails to read the paper.\n\t\t\"\"\"\n\t\t# Deal with target dir\n\t\tif not self._is_valid_paper_dir(rel_dir=target_rel_dir):\n\t\t\tprint(\"Invalid paper dir.\")\n\t\t\treturn None\n\n\t\tif not self._fs.exists(raw_paper_path):\n\t\t\tprint(\"paper not exists.\")\n\t\t\treturn None\n\n\t\tpaper_name = Path(raw_paper_path).name\n\t\tif Path(raw_paper_path).suffix != \".pdf\":\n\t\t\tprint(\"is not pdf.\")\n\t\t\treturn None\n\n\t\ttarget_dir = self._root / target_rel_dir\n\t\tpaper_path = str(target_dir / paper_name)\n\t\ttarget_dir = str(target_dir)\n\n\t\tif not self._fs.exists(target_dir):\n\t\t\tself._fs.mkdirs(target_dir)\n\n\t\t# Move the paper to the warehouse.\n\t\tif paper_path != raw_paper_path:\n\t\t\tself._fs.cp(raw_paper_path, target_dir)\n\n\t\tread_content = self.paper_reader.read_single_paper(\n\t\t\tfile_path=paper_path,\n\t\t\textra_metadata=extra_metadata,\n\t\t)\n\t\tif read_content is None:\n\t\t\treturn None\n\n\t\tchunk_docs, extra_docs = read_content\n\t\tdir_node = self._get_node(node_id=target_rel_dir)\n\t\tif dir_node is None:\n\t\t\tself.make_dirs(rel_dir=target_rel_dir)\n\t\t\tdir_node = self._get_node(node_id=target_rel_dir)\n\n\t\tpaper_metadata = {\n\t\t\tkey: chunk_docs[0].metadata[key] for key in chunk_docs[0].metadata.keys() if key != CONTENT_TYPE_NAME\n\t\t}\n\t\tif paper_summary:\n\t\t\tpaper_metadata[SHARED_PAPER_SUMMARY_KEY] = paper_summary\n\t\tdir_node, paper_node = self._new_paper_node(dir_node=dir_node, paper_info=paper_metadata)\n\t\tself._update_node(node_id=dir_node.node_id, node=dir_node)\n\n\t\t# overlapped nodes\n\t\toverlapped_chunk_nodes = run_transformations(\n\t\t\tnodes=chunk_docs,\n\t\t\ttransformations=self._default_overlapped_transformations,\n\t\t)\n\t\tself._insert_as_child_nodes(node=paper_node, child_nodes=overlapped_chunk_nodes)\n\t\tfor chunk_node in overlapped_chunk_nodes:\n\t\t\tself._update_node(node_id=chunk_node.node_id, node=chunk_node)\n\n\t\t# insert non-overlapped nodes to notes_index as child nodes of doi node.\n\t\tpaper_doi = paper_metadata[PAPER_DOI]\n\t\tdoi_node = self._new_doi_node(doi=paper_doi)\n\n\t\tfor doc in chunk_docs:\n\t\t\tdoc.metadata = dict()\n\t\tnon_overlapped_chunk_nodes = run_transformations(\n\t\t\tnodes=chunk_docs,\n\t\t\ttransformations=self._default_non_overlapped_transformations,\n\t\t)\n\n\t\tself._insert_as_child_nodes(node=doi_node, child_nodes=non_overlapped_chunk_nodes)\n\t\tfor chunk_node in non_overlapped_chunk_nodes:\n\t\t\tself._update_note_index_node(node_id=chunk_node.node_id, node=chunk_node)\n\t\tself._update_note_index_node(node_id=doi_node.node_id, node=doi_node)\n\n\t\t# extra docs\n\t\tself._insert_as_child_nodes(node=paper_node, child_nodes=extra_docs)\n\t\tfor doc in extra_docs:\n\t\t\tdoc.metadata[SHARED_PAPER_NODE_TYPE] = SharedPaperNodeType.PAPER_EXTRA_INFO\n\t\t\tself._update_node(node_id=doc.node_id, node=doc)\n\n\t\tself._update_node(node_id=paper_node.node_id, node=paper_node)\n\t\treturn paper_node.node_id\n\n\tdef insert_papers(\n\t\tself,\n\t\tuser_id: str,\n\t\tpapers_root_dir: str,\n\t\tpaper_paths: List[str],\n\t\tenable_summarize: bool\n\t) -&gt; Optional[List[str]]:\n\t\tr\"\"\"\n\t\tInsert papers of a user.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user id of a laboratory member.\n\t\t\tpapers_root_dir (str): The raw root directory of these papers,\n\t\t\t\tthe directory structure will be copied to the shared paper warehouse.\n\t\t\tpaper_paths (List[str]): The paths of the papers.\n\t\t\tenable_summarize (bool): Whether to summarize these papers.\n\n\t\tReturns:\n\t\t\tOptional[List[str]]: The paths of failed papers. If no paper fails in recording, return None.\n\t\t\"\"\"\n\n\t\ttarget_dirs = []\n\t\tfor paper_path in paper_paths:\n\t\t\trel_path = str(Path(paper_path).relative_to(papers_root_dir))\n\t\t\ttarget_rel_dir = str(Path(f\"{SHARED_PAPER_WAREHOUSE_DIR}/{user_id}/{rel_path}\").parent)\n\t\t\ttarget_dirs.append(target_rel_dir)\n\n\t\tfailed_papers = []\n\t\tfor idx, paper_path in enumerate(paper_paths):\n\t\t\tpaper_id = self.insert_single_paper(\n\t\t\t\ttarget_rel_dir=target_dirs[idx],\n\t\t\t\traw_paper_path=paper_path,\n\t\t\t)\n\t\t\tif paper_id is None:\n\t\t\t\tfailed_papers.append(paper_path)\n\t\t\t\tcontinue\n\t\t\tif enable_summarize:\n\t\t\t\tself.summarize_paper(paper_node_id=paper_id)\n\t\t\tself.persist_papers()\n\t\t\tself.persist_notes()\n\n\t\tif len(failed_papers) &lt; 1:\n\t\t\treturn None\n\t\treturn failed_papers\n\n\tasync def ainsert_papers(\n\t\tself,\n\t\tuser_id: str,\n\t\tpapers_root_dir: str,\n\t\tpaper_paths: List[str],\n\t\tenable_summarize: bool\n\t) -&gt; Optional[List[str]]:\n\t\tr\"\"\"\n\t\tAsynchronously insert papers of a user.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user id of a laboratory member.\n\t\t\tpapers_root_dir (str): The raw root directory of these papers,\n\t\t\t\tthe directory structure will be copied to the shared paper warehouse.\n\t\t\tpaper_paths (List[str]): The paths of the papers.\n\t\t\tenable_summarize (bool): Whether to summarize these papers.\n\n\t\tReturns:\n\t\t\tOptional[List[str]]: The paths of failed papers. If no paper fails in recording, return None.\n\t\t\"\"\"\n\t\ttarget_dirs = []\n\t\tfor paper_path in paper_paths:\n\t\t\trel_path = str(Path(paper_path).relative_to(papers_root_dir))\n\t\t\ttarget_rel_dir = f\"{SHARED_PAPER_WAREHOUSE_DIR}/{user_id}/{rel_path}\"\n\t\t\ttarget_dirs.append(target_rel_dir)\n\n\t\tfailed_papers = []\n\t\tfor idx, paper_path in enumerate(paper_paths):\n\t\t\tpaper_id = self.insert_single_paper(\n\t\t\t\ttarget_rel_dir=target_dirs[idx],\n\t\t\t\traw_paper_path=paper_path,\n\t\t\t)\n\t\t\tif paper_id is None:\n\t\t\t\tfailed_papers.append(paper_path)\n\t\t\t\tcontinue\n\t\t\tif enable_summarize:\n\t\t\t\tawait self.asummarize_paper(paper_node_id=paper_id)\n\t\t\tself.persist_papers()\n\t\t\tself.persist_notes()\n\n\t\tif len(failed_papers) &lt; 1:\n\t\t\treturn None\n\t\treturn failed_papers\n\n\tdef persist_papers(self, persist_dir: str = None):\n\t\tr\"\"\" Save the vector_index to disk. \"\"\"\n\t\tpersist_dir = persist_dir or self.persist_dir\n\t\tif not self._fs.exists(persist_dir):\n\t\t\tself._fs.makedirs(persist_dir)\n\t\tself.vector_index.storage_context.persist(persist_dir=persist_dir)\n\n\tdef persist_notes(\n\t\tself,\n\t\tnotes_persist_dir: str = None,\n\t):\n\t\tr\"\"\" Save the notes_vector_index to disk. \"\"\"\n\t\tnotes_persist_dir = notes_persist_dir or self.notes_persist_dir\n\t\tif not self._fs.exists(notes_persist_dir):\n\t\t\tself._fs.makedirs(notes_persist_dir)\n\t\tself.notes_vector_index.storage_context.persist(persist_dir=notes_persist_dir)\n\n\tdef insert_note(\n\t\tself,\n\t\tdoi: str,\n\t\tuser_id: str,\n\t\tnotes: Dict[str, str],\n\t):\n\t\tr\"\"\"\n\t\tInsert a note into the notes vector index.\n\n\t\tArgs:\n\t\t\tdoi (str): The DOI of the corresponding paper.\n\t\t\tuser_id (str): The user id of a Lab member.\n\t\t\tnotes (Dict[str, str]): key -- corresponding paper content; value -- the user's note.\n\n\t\tReturns:\n\t\t\tNone\n\t\t\"\"\"\n\t\tdoi_node = self._get_notes_index_node(node_id=doi)\n\t\tif doi_node is None:\n\t\t\treturn\n\n\t\tchunk_ids = [node.node_id for node in doi_node.child_nodes]\n\t\tretriever = self.notes_vector_index.as_retriever(similarity_top_k=1)\n\t\tretriever._node_ids = chunk_ids\n\n\t\trecord = []\n\t\tfor chunk_info in notes.keys():\n\t\t\tretrieved_nodes = retriever.retrieve(chunk_info)\n\t\t\ttarget_node_id = retrieved_nodes[0].node_id\n\t\t\trecord.append((target_node_id, notes[chunk_info]))\n\n\t\tfor target_id, note_str in record:\n\t\t\tchunk_node = self._get_notes_index_node(node_id=target_id)\n\t\t\tnote_node = self._new_note_node(\n\t\t\t\tuser_id=user_id,\n\t\t\t\tnote=note_str,\n\t\t\t)\n\t\t\tself._insert_as_child_nodes(node=chunk_node, child_nodes=[note_node])\n\t\t\tself._update_note_index_node(node_id=chunk_node.node_id, node=chunk_node)\n\t\t\tself._update_note_index_node(node_id=note_node.node_id, node=note_node)\n\t\tself.persist_notes()\n\n\tdef get_notes(\n\t\tself,\n\t\tdoi: str,\n\t\tchunk_info: str,\n\t) -&gt; Optional[List[UserNote]]:\n\t\tr\"\"\"\n\t\tCheck whether there exists any notes corresponding to the given content.\n\n\t\tArgs:\n\t\t\tdoi (str): The DOI of the paper.\n\t\t\tchunk_info (str): The corresponding paper content.\n\n\t\tReturns:\n\t\t\tOptional[List[UserNote]]: If notes exist, return the notes. Otherwise, return None.\n\t\t\"\"\"\n\t\tdoi_node = self._get_notes_index_node(node_id=doi)\n\t\tif doi_node is None:\n\t\t\treturn None\n\t\tchunk_ids = [node.node_id for node in doi_node.child_nodes]\n\t\tretriever = self.notes_vector_index.as_retriever(similarity_top_k=1)\n\t\tretriever._node_ids = chunk_ids\n\t\tretrieved_nodes = retriever.retrieve(chunk_info)\n\t\ttarget_node_id = retrieved_nodes[0].node_id\n\t\tchunk_node = self._get_notes_index_node(node_id=target_node_id)\n\n\t\tnote_ids = [node.node_id for node in chunk_node.child_nodes]\n\t\tif len(note_ids) &lt; 1:\n\t\t\treturn None\n\n\t\tnotes = []\n\t\tfor node_id in note_ids:\n\t\t\tnote_node = self._get_notes_index_node(node_id=node_id)\n\t\t\tnotes.append(\n\t\t\t\tUserNote(\n\t\t\t\t\tuser_id=note_node.metadata[\"user_id\"],\n\t\t\t\t\tnote=note_node.text,\n\t\t\t\t\tdoi=doi,\n\t\t\t\t)\n\t\t\t)\n\t\treturn notes\n\n\tdef add_user_node(self, user_id: str) -&gt; BaseNode:\n\t\tr\"\"\"\n\t\tAdd a user node for a valid user.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user id of a Lab member.\n\n\t\tReturns:\n\t\t\tThe user node\n\t\t\"\"\"\n\t\tuser_node = TextNode(\n\t\t\ttext=f\"Directory for user {user_id}\",\n\t\t\tid_=user_id,\n\t\t\tmetadata={\n\t\t\t\tSHARED_PAPER_NODE_TYPE: SharedPaperNodeType.USER,\n\t\t\t}\n\t\t)\n\t\troot_node = self._get_node(node_id=SHARED_PAPER_ROOT_NODE_NAME)\n\t\tself._insert_as_child_nodes(node=root_node, child_nodes=[user_node])\n\t\tself._update_node(node_id=root_node.node_id, node=root_node)\n\t\tself._update_node(node_id=user_node.node_id, node=user_node)\n\t\treturn user_node\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/shared_paper_store/#labridge.func_modules.paper.store.shared_paper_store.SharedPaperStorage.add_user_node","title":"<code>labridge.func_modules.paper.store.shared_paper_store.SharedPaperStorage.add_user_node(user_id)</code>","text":"<p>Add a user node for a valid user.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user id of a Lab member.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>BaseNode</code> <p>The user node</p> Source code in <code>labridge\\func_modules\\paper\\store\\shared_paper_store.py</code> <pre><code>def add_user_node(self, user_id: str) -&gt; BaseNode:\n\tr\"\"\"\n\tAdd a user node for a valid user.\n\n\tArgs:\n\t\tuser_id (str): The user id of a Lab member.\n\n\tReturns:\n\t\tThe user node\n\t\"\"\"\n\tuser_node = TextNode(\n\t\ttext=f\"Directory for user {user_id}\",\n\t\tid_=user_id,\n\t\tmetadata={\n\t\t\tSHARED_PAPER_NODE_TYPE: SharedPaperNodeType.USER,\n\t\t}\n\t)\n\troot_node = self._get_node(node_id=SHARED_PAPER_ROOT_NODE_NAME)\n\tself._insert_as_child_nodes(node=root_node, child_nodes=[user_node])\n\tself._update_node(node_id=root_node.node_id, node=root_node)\n\tself._update_node(node_id=user_node.node_id, node=user_node)\n\treturn user_node\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/shared_paper_store/#labridge.func_modules.paper.store.shared_paper_store.SharedPaperStorage.ainsert_papers","title":"<code>labridge.func_modules.paper.store.shared_paper_store.SharedPaperStorage.ainsert_papers(user_id, papers_root_dir, paper_paths, enable_summarize)</code>  <code>async</code>","text":"<p>Asynchronously insert papers of a user.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user id of a laboratory member.</p> <p> TYPE: <code>str</code> </p> <code>papers_root_dir</code> <p>The raw root directory of these papers, the directory structure will be copied to the shared paper warehouse.</p> <p> TYPE: <code>str</code> </p> <code>paper_paths</code> <p>The paths of the papers.</p> <p> TYPE: <code>List[str]</code> </p> <code>enable_summarize</code> <p>Whether to summarize these papers.</p> <p> TYPE: <code>bool</code> </p> RETURNS DESCRIPTION <code>Optional[List[str]]</code> <p>Optional[List[str]]: The paths of failed papers. If no paper fails in recording, return None.</p> Source code in <code>labridge\\func_modules\\paper\\store\\shared_paper_store.py</code> <pre><code>async def ainsert_papers(\n\tself,\n\tuser_id: str,\n\tpapers_root_dir: str,\n\tpaper_paths: List[str],\n\tenable_summarize: bool\n) -&gt; Optional[List[str]]:\n\tr\"\"\"\n\tAsynchronously insert papers of a user.\n\n\tArgs:\n\t\tuser_id (str): The user id of a laboratory member.\n\t\tpapers_root_dir (str): The raw root directory of these papers,\n\t\t\tthe directory structure will be copied to the shared paper warehouse.\n\t\tpaper_paths (List[str]): The paths of the papers.\n\t\tenable_summarize (bool): Whether to summarize these papers.\n\n\tReturns:\n\t\tOptional[List[str]]: The paths of failed papers. If no paper fails in recording, return None.\n\t\"\"\"\n\ttarget_dirs = []\n\tfor paper_path in paper_paths:\n\t\trel_path = str(Path(paper_path).relative_to(papers_root_dir))\n\t\ttarget_rel_dir = f\"{SHARED_PAPER_WAREHOUSE_DIR}/{user_id}/{rel_path}\"\n\t\ttarget_dirs.append(target_rel_dir)\n\n\tfailed_papers = []\n\tfor idx, paper_path in enumerate(paper_paths):\n\t\tpaper_id = self.insert_single_paper(\n\t\t\ttarget_rel_dir=target_dirs[idx],\n\t\t\traw_paper_path=paper_path,\n\t\t)\n\t\tif paper_id is None:\n\t\t\tfailed_papers.append(paper_path)\n\t\t\tcontinue\n\t\tif enable_summarize:\n\t\t\tawait self.asummarize_paper(paper_node_id=paper_id)\n\t\tself.persist_papers()\n\t\tself.persist_notes()\n\n\tif len(failed_papers) &lt; 1:\n\t\treturn None\n\treturn failed_papers\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/shared_paper_store/#labridge.func_modules.paper.store.shared_paper_store.SharedPaperStorage.asummarize_paper","title":"<code>labridge.func_modules.paper.store.shared_paper_store.SharedPaperStorage.asummarize_paper(paper_node_id)</code>  <code>async</code>","text":"<p>Asynchronously summarize a paper in the shared paper storage.</p> PARAMETER DESCRIPTION <code>paper_node_id</code> <p>The node id of the corresponding paper node.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Optional[str]</code> <p>Optional[str]: The summary of th paper. If the paper does not exist, return None.</p> Source code in <code>labridge\\func_modules\\paper\\store\\shared_paper_store.py</code> <pre><code>async def asummarize_paper(self, paper_node_id: str) -&gt; Optional[str]:\n\tr\"\"\"\n\tAsynchronously summarize a paper in the shared paper storage.\n\n\tArgs:\n\t\tpaper_node_id (str): The node id of the corresponding paper node.\n\n\tReturns:\n\t\tOptional[str]: The summary of th paper. If the paper does not exist, return None.\n\t\"\"\"\n\tpaper_node = self._get_node(node_id=paper_node_id)\n\tif paper_node is None:\n\t\treturn None\n\n\tsummary = paper_node.metadata.get(SHARED_PAPER_SUMMARY_KEY, None)\n\tif summary is not None:\n\t\treturn summary\n\n\tcontent_ids = [child.node_id for child in paper_node.child_nodes]\n\tcontent_nodes = self._get_nodes(\n\t\tnode_ids=content_ids,\n\t\tnode_types=[SharedPaperNodeType.PAPER_CHUNK]\n\t)\n\n\tnodes_with_scores = [NodeWithScore(node=n) for n in content_nodes]\n\t# get the summary for each doc_id\n\tsummary_response = await self._summarizer.asynthesize(nodes=nodes_with_scores, query=\"\")\n\tsummary_response = cast(Response, summary_response)\n\tsummary = summary_response.response\n\tpaper_node.metadata[SHARED_PAPER_SUMMARY_KEY] = summary\n\tself._update_node(node_id=paper_node.node_id, node=paper_node)\n\treturn summary\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/shared_paper_store/#labridge.func_modules.paper.store.shared_paper_store.SharedPaperStorage.get_notes","title":"<code>labridge.func_modules.paper.store.shared_paper_store.SharedPaperStorage.get_notes(doi, chunk_info)</code>","text":"<p>Check whether there exists any notes corresponding to the given content.</p> PARAMETER DESCRIPTION <code>doi</code> <p>The DOI of the paper.</p> <p> TYPE: <code>str</code> </p> <code>chunk_info</code> <p>The corresponding paper content.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Optional[List[UserNote]]</code> <p>Optional[List[UserNote]]: If notes exist, return the notes. Otherwise, return None.</p> Source code in <code>labridge\\func_modules\\paper\\store\\shared_paper_store.py</code> <pre><code>def get_notes(\n\tself,\n\tdoi: str,\n\tchunk_info: str,\n) -&gt; Optional[List[UserNote]]:\n\tr\"\"\"\n\tCheck whether there exists any notes corresponding to the given content.\n\n\tArgs:\n\t\tdoi (str): The DOI of the paper.\n\t\tchunk_info (str): The corresponding paper content.\n\n\tReturns:\n\t\tOptional[List[UserNote]]: If notes exist, return the notes. Otherwise, return None.\n\t\"\"\"\n\tdoi_node = self._get_notes_index_node(node_id=doi)\n\tif doi_node is None:\n\t\treturn None\n\tchunk_ids = [node.node_id for node in doi_node.child_nodes]\n\tretriever = self.notes_vector_index.as_retriever(similarity_top_k=1)\n\tretriever._node_ids = chunk_ids\n\tretrieved_nodes = retriever.retrieve(chunk_info)\n\ttarget_node_id = retrieved_nodes[0].node_id\n\tchunk_node = self._get_notes_index_node(node_id=target_node_id)\n\n\tnote_ids = [node.node_id for node in chunk_node.child_nodes]\n\tif len(note_ids) &lt; 1:\n\t\treturn None\n\n\tnotes = []\n\tfor node_id in note_ids:\n\t\tnote_node = self._get_notes_index_node(node_id=node_id)\n\t\tnotes.append(\n\t\t\tUserNote(\n\t\t\t\tuser_id=note_node.metadata[\"user_id\"],\n\t\t\t\tnote=note_node.text,\n\t\t\t\tdoi=doi,\n\t\t\t)\n\t\t)\n\treturn notes\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/shared_paper_store/#labridge.func_modules.paper.store.shared_paper_store.SharedPaperStorage.insert_note","title":"<code>labridge.func_modules.paper.store.shared_paper_store.SharedPaperStorage.insert_note(doi, user_id, notes)</code>","text":"<p>Insert a note into the notes vector index.</p> PARAMETER DESCRIPTION <code>doi</code> <p>The DOI of the corresponding paper.</p> <p> TYPE: <code>str</code> </p> <code>user_id</code> <p>The user id of a Lab member.</p> <p> TYPE: <code>str</code> </p> <code>notes</code> <p>key -- corresponding paper content; value -- the user's note.</p> <p> TYPE: <code>Dict[str, str]</code> </p> RETURNS DESCRIPTION <p>None</p> Source code in <code>labridge\\func_modules\\paper\\store\\shared_paper_store.py</code> <pre><code>def insert_note(\n\tself,\n\tdoi: str,\n\tuser_id: str,\n\tnotes: Dict[str, str],\n):\n\tr\"\"\"\n\tInsert a note into the notes vector index.\n\n\tArgs:\n\t\tdoi (str): The DOI of the corresponding paper.\n\t\tuser_id (str): The user id of a Lab member.\n\t\tnotes (Dict[str, str]): key -- corresponding paper content; value -- the user's note.\n\n\tReturns:\n\t\tNone\n\t\"\"\"\n\tdoi_node = self._get_notes_index_node(node_id=doi)\n\tif doi_node is None:\n\t\treturn\n\n\tchunk_ids = [node.node_id for node in doi_node.child_nodes]\n\tretriever = self.notes_vector_index.as_retriever(similarity_top_k=1)\n\tretriever._node_ids = chunk_ids\n\n\trecord = []\n\tfor chunk_info in notes.keys():\n\t\tretrieved_nodes = retriever.retrieve(chunk_info)\n\t\ttarget_node_id = retrieved_nodes[0].node_id\n\t\trecord.append((target_node_id, notes[chunk_info]))\n\n\tfor target_id, note_str in record:\n\t\tchunk_node = self._get_notes_index_node(node_id=target_id)\n\t\tnote_node = self._new_note_node(\n\t\t\tuser_id=user_id,\n\t\t\tnote=note_str,\n\t\t)\n\t\tself._insert_as_child_nodes(node=chunk_node, child_nodes=[note_node])\n\t\tself._update_note_index_node(node_id=chunk_node.node_id, node=chunk_node)\n\t\tself._update_note_index_node(node_id=note_node.node_id, node=note_node)\n\tself.persist_notes()\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/shared_paper_store/#labridge.func_modules.paper.store.shared_paper_store.SharedPaperStorage.insert_papers","title":"<code>labridge.func_modules.paper.store.shared_paper_store.SharedPaperStorage.insert_papers(user_id, papers_root_dir, paper_paths, enable_summarize)</code>","text":"<p>Insert papers of a user.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user id of a laboratory member.</p> <p> TYPE: <code>str</code> </p> <code>papers_root_dir</code> <p>The raw root directory of these papers, the directory structure will be copied to the shared paper warehouse.</p> <p> TYPE: <code>str</code> </p> <code>paper_paths</code> <p>The paths of the papers.</p> <p> TYPE: <code>List[str]</code> </p> <code>enable_summarize</code> <p>Whether to summarize these papers.</p> <p> TYPE: <code>bool</code> </p> RETURNS DESCRIPTION <code>Optional[List[str]]</code> <p>Optional[List[str]]: The paths of failed papers. If no paper fails in recording, return None.</p> Source code in <code>labridge\\func_modules\\paper\\store\\shared_paper_store.py</code> <pre><code>def insert_papers(\n\tself,\n\tuser_id: str,\n\tpapers_root_dir: str,\n\tpaper_paths: List[str],\n\tenable_summarize: bool\n) -&gt; Optional[List[str]]:\n\tr\"\"\"\n\tInsert papers of a user.\n\n\tArgs:\n\t\tuser_id (str): The user id of a laboratory member.\n\t\tpapers_root_dir (str): The raw root directory of these papers,\n\t\t\tthe directory structure will be copied to the shared paper warehouse.\n\t\tpaper_paths (List[str]): The paths of the papers.\n\t\tenable_summarize (bool): Whether to summarize these papers.\n\n\tReturns:\n\t\tOptional[List[str]]: The paths of failed papers. If no paper fails in recording, return None.\n\t\"\"\"\n\n\ttarget_dirs = []\n\tfor paper_path in paper_paths:\n\t\trel_path = str(Path(paper_path).relative_to(papers_root_dir))\n\t\ttarget_rel_dir = str(Path(f\"{SHARED_PAPER_WAREHOUSE_DIR}/{user_id}/{rel_path}\").parent)\n\t\ttarget_dirs.append(target_rel_dir)\n\n\tfailed_papers = []\n\tfor idx, paper_path in enumerate(paper_paths):\n\t\tpaper_id = self.insert_single_paper(\n\t\t\ttarget_rel_dir=target_dirs[idx],\n\t\t\traw_paper_path=paper_path,\n\t\t)\n\t\tif paper_id is None:\n\t\t\tfailed_papers.append(paper_path)\n\t\t\tcontinue\n\t\tif enable_summarize:\n\t\t\tself.summarize_paper(paper_node_id=paper_id)\n\t\tself.persist_papers()\n\t\tself.persist_notes()\n\n\tif len(failed_papers) &lt; 1:\n\t\treturn None\n\treturn failed_papers\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/shared_paper_store/#labridge.func_modules.paper.store.shared_paper_store.SharedPaperStorage.insert_single_paper","title":"<code>labridge.func_modules.paper.store.shared_paper_store.SharedPaperStorage.insert_single_paper(target_rel_dir, raw_paper_path, paper_summary=None, extra_metadata=None)</code>","text":"<p>Add a paper to the shared paper storage.</p> PARAMETER DESCRIPTION <code>target_rel_dir</code> <p>The directory into which the new paper is inserted.</p> <p> TYPE: <code>str</code> </p> <code>raw_paper_path</code> <p>The file path of the paper.</p> <p> TYPE: <code>str</code> </p> <code>paper_summary</code> <p>If the paper has been summarized before, the summary can be provided to save cost.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>extra_metadata</code> <p>Extra metadata obtained from other approaches such as ArXiv.</p> <p> TYPE: <code>dict</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Optional[str]</code> <p>Optional[str]: The node id of the new paper node. Return None in these situation:</p> <ul> <li>The target_rel_dir is not valid.</li> <li>The raw_paper_path does not exist.</li> <li>The given paper is not in pdf format.</li> <li>The PaperReader fails to read the paper.</li> </ul> Source code in <code>labridge\\func_modules\\paper\\store\\shared_paper_store.py</code> <pre><code>def insert_single_paper(\n\tself,\n\ttarget_rel_dir: str,\n\traw_paper_path: str,\n\tpaper_summary: str = None,\n\textra_metadata: dict = None,\n) -&gt; Optional[str]:\n\tr\"\"\"\n\tAdd a paper to the shared paper storage.\n\n\tArgs:\n\t\ttarget_rel_dir (str): The directory into which the new paper is inserted.\n\t\traw_paper_path (str): The file path of the paper.\n\t\tpaper_summary (str): If the paper has been summarized before, the summary can be provided to save cost.\n\t\textra_metadata (dict): Extra metadata obtained from other approaches such as ArXiv.\n\n\tReturns:\n\t\tOptional[str]: The node id of the new paper node.\n\t\t\tReturn None in these situation:\n\n\t\t\t- The target_rel_dir is not valid.\n\t\t\t- The raw_paper_path does not exist.\n\t\t\t- The given paper is not in pdf format.\n\t\t\t- The PaperReader fails to read the paper.\n\t\"\"\"\n\t# Deal with target dir\n\tif not self._is_valid_paper_dir(rel_dir=target_rel_dir):\n\t\tprint(\"Invalid paper dir.\")\n\t\treturn None\n\n\tif not self._fs.exists(raw_paper_path):\n\t\tprint(\"paper not exists.\")\n\t\treturn None\n\n\tpaper_name = Path(raw_paper_path).name\n\tif Path(raw_paper_path).suffix != \".pdf\":\n\t\tprint(\"is not pdf.\")\n\t\treturn None\n\n\ttarget_dir = self._root / target_rel_dir\n\tpaper_path = str(target_dir / paper_name)\n\ttarget_dir = str(target_dir)\n\n\tif not self._fs.exists(target_dir):\n\t\tself._fs.mkdirs(target_dir)\n\n\t# Move the paper to the warehouse.\n\tif paper_path != raw_paper_path:\n\t\tself._fs.cp(raw_paper_path, target_dir)\n\n\tread_content = self.paper_reader.read_single_paper(\n\t\tfile_path=paper_path,\n\t\textra_metadata=extra_metadata,\n\t)\n\tif read_content is None:\n\t\treturn None\n\n\tchunk_docs, extra_docs = read_content\n\tdir_node = self._get_node(node_id=target_rel_dir)\n\tif dir_node is None:\n\t\tself.make_dirs(rel_dir=target_rel_dir)\n\t\tdir_node = self._get_node(node_id=target_rel_dir)\n\n\tpaper_metadata = {\n\t\tkey: chunk_docs[0].metadata[key] for key in chunk_docs[0].metadata.keys() if key != CONTENT_TYPE_NAME\n\t}\n\tif paper_summary:\n\t\tpaper_metadata[SHARED_PAPER_SUMMARY_KEY] = paper_summary\n\tdir_node, paper_node = self._new_paper_node(dir_node=dir_node, paper_info=paper_metadata)\n\tself._update_node(node_id=dir_node.node_id, node=dir_node)\n\n\t# overlapped nodes\n\toverlapped_chunk_nodes = run_transformations(\n\t\tnodes=chunk_docs,\n\t\ttransformations=self._default_overlapped_transformations,\n\t)\n\tself._insert_as_child_nodes(node=paper_node, child_nodes=overlapped_chunk_nodes)\n\tfor chunk_node in overlapped_chunk_nodes:\n\t\tself._update_node(node_id=chunk_node.node_id, node=chunk_node)\n\n\t# insert non-overlapped nodes to notes_index as child nodes of doi node.\n\tpaper_doi = paper_metadata[PAPER_DOI]\n\tdoi_node = self._new_doi_node(doi=paper_doi)\n\n\tfor doc in chunk_docs:\n\t\tdoc.metadata = dict()\n\tnon_overlapped_chunk_nodes = run_transformations(\n\t\tnodes=chunk_docs,\n\t\ttransformations=self._default_non_overlapped_transformations,\n\t)\n\n\tself._insert_as_child_nodes(node=doi_node, child_nodes=non_overlapped_chunk_nodes)\n\tfor chunk_node in non_overlapped_chunk_nodes:\n\t\tself._update_note_index_node(node_id=chunk_node.node_id, node=chunk_node)\n\tself._update_note_index_node(node_id=doi_node.node_id, node=doi_node)\n\n\t# extra docs\n\tself._insert_as_child_nodes(node=paper_node, child_nodes=extra_docs)\n\tfor doc in extra_docs:\n\t\tdoc.metadata[SHARED_PAPER_NODE_TYPE] = SharedPaperNodeType.PAPER_EXTRA_INFO\n\t\tself._update_node(node_id=doc.node_id, node=doc)\n\n\tself._update_node(node_id=paper_node.node_id, node=paper_node)\n\treturn paper_node.node_id\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/shared_paper_store/#labridge.func_modules.paper.store.shared_paper_store.SharedPaperStorage.make_dirs","title":"<code>labridge.func_modules.paper.store.shared_paper_store.SharedPaperStorage.make_dirs(rel_dir)</code>","text":"<p>Recursively add DIR nodes for a rel_dir.</p> <p>relative path to what? match the old vector index.</p> PARAMETER DESCRIPTION <code>rel_dir</code> <p>The path of a directory relative to the root.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <p>None</p> RAISES DESCRIPTION <code>ValueError</code> <p>If the given rel_dir is not valid, that is, the rel_dir is not under the <code>SHARED_PAPER_WAREHOUSE_DIR</code>.</p> Source code in <code>labridge\\func_modules\\paper\\store\\shared_paper_store.py</code> <pre><code>def make_dirs(self, rel_dir: str):\n\tr\"\"\"\n\tRecursively add DIR nodes for a rel_dir.\n\n\trelative path to what? match the old vector index.\n\n\tArgs:\n\t\trel_dir (str): The path of a directory relative to the root.\n\n\tReturns:\n\t\tNone\n\n\tRaises:\n\t\tValueError: If the given rel_dir is not valid, that is, the rel_dir is not under the `SHARED_PAPER_WAREHOUSE_DIR`.\n\n\t\"\"\"\n\tif not self._is_valid_paper_dir(rel_dir=rel_dir):\n\t\traise ValueError(f\"The directory {rel_dir} is not under the warehouse {SHARED_PAPER_WAREHOUSE_DIR}.\")\n\n\tpath_parts = Path(rel_dir).relative_to(SHARED_PAPER_WAREHOUSE_DIR).parts\n\tassert len(path_parts) &gt; 1\n\n\tuser_id = path_parts[0]\n\tself._account_manager.check_valid_user(user_id=user_id)\n\tuser_node = self._get_node(node_id=user_id) or self.add_user_node(user_id=user_id)\n\tdir_path = Path(SHARED_PAPER_WAREHOUSE_DIR) / user_id\n\t# [node, whether to update]\n\tdirs_nodes = [[user_node, False]]\n\n\tfor part in path_parts[1:]:\n\t\tdir_path = dir_path / part\n\t\tdir_node = self._get_node(node_id=str(dir_path))\n\t\tif_new_dir = dir_node is None\n\t\tif if_new_dir:\n\t\t\tdir_node = self._new_dir_node(rel_dir_path=str(dir_path))\n\t\t\tparent_node = dirs_nodes[-1][0]\n\t\t\tdirs_nodes[-1][1] = True\n\t\t\tdir_node.relationships[NodeRelationship.PARENT] = RelatedNodeInfo(\n\t\t\t\tnode_id=parent_node.node_id,\n\t\t\t)\n\t\t\tself._insert_as_child_nodes(node=parent_node, child_nodes=[dir_node])\n\t\tdirs_nodes.append([dir_node, if_new_dir])\n\n\tto_update_nodes = [pair[0] for pair in dirs_nodes if pair[1]]\n\tfor node in to_update_nodes:\n\t\tself._update_node(node_id=node.node_id, node=node)\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/shared_paper_store/#labridge.func_modules.paper.store.shared_paper_store.SharedPaperStorage.persist_notes","title":"<code>labridge.func_modules.paper.store.shared_paper_store.SharedPaperStorage.persist_notes(notes_persist_dir=None)</code>","text":"<p>Save the notes_vector_index to disk.</p> Source code in <code>labridge\\func_modules\\paper\\store\\shared_paper_store.py</code> <pre><code>def persist_notes(\n\tself,\n\tnotes_persist_dir: str = None,\n):\n\tr\"\"\" Save the notes_vector_index to disk. \"\"\"\n\tnotes_persist_dir = notes_persist_dir or self.notes_persist_dir\n\tif not self._fs.exists(notes_persist_dir):\n\t\tself._fs.makedirs(notes_persist_dir)\n\tself.notes_vector_index.storage_context.persist(persist_dir=notes_persist_dir)\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/shared_paper_store/#labridge.func_modules.paper.store.shared_paper_store.SharedPaperStorage.persist_papers","title":"<code>labridge.func_modules.paper.store.shared_paper_store.SharedPaperStorage.persist_papers(persist_dir=None)</code>","text":"<p>Save the vector_index to disk.</p> Source code in <code>labridge\\func_modules\\paper\\store\\shared_paper_store.py</code> <pre><code>def persist_papers(self, persist_dir: str = None):\n\tr\"\"\" Save the vector_index to disk. \"\"\"\n\tpersist_dir = persist_dir or self.persist_dir\n\tif not self._fs.exists(persist_dir):\n\t\tself._fs.makedirs(persist_dir)\n\tself.vector_index.storage_context.persist(persist_dir=persist_dir)\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/shared_paper_store/#labridge.func_modules.paper.store.shared_paper_store.SharedPaperStorage.summarize_paper","title":"<code>labridge.func_modules.paper.store.shared_paper_store.SharedPaperStorage.summarize_paper(paper_node_id)</code>","text":"<p>Summarize a paper in the shared paper storage.</p> PARAMETER DESCRIPTION <code>paper_node_id</code> <p>The node id of the corresponding paper node.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Optional[str]</code> <p>Optional[str]: The summary of th paper. If the paper does not exist, return None.</p> Source code in <code>labridge\\func_modules\\paper\\store\\shared_paper_store.py</code> <pre><code>def summarize_paper(self, paper_node_id: str) -&gt; Optional[str]:\n\tr\"\"\"\n\tSummarize a paper in the shared paper storage.\n\n\tArgs:\n\t\tpaper_node_id (str): The node id of the corresponding paper node.\n\n\tReturns:\n\t\tOptional[str]: The summary of th paper. If the paper does not exist, return None.\n\t\"\"\"\n\tpaper_node = self._get_node(node_id=paper_node_id)\n\tif paper_node is None:\n\t\treturn None\n\n\tsummary = paper_node.metadata.get(SHARED_PAPER_SUMMARY_KEY, None)\n\tif summary is not None:\n\t\treturn summary\n\n\tcontent_ids = [child.node_id for child in paper_node.child_nodes]\n\tcontent_nodes = self._get_nodes(\n\t\tnode_ids=content_ids,\n\t\tnode_types=[SharedPaperNodeType.PAPER_CHUNK]\n\t)\n\n\tnodes_with_scores = [NodeWithScore(node=n) for n in content_nodes]\n\t# get the summary for each doc_id\n\tsummary_response = self._summarizer.synthesize(nodes=nodes_with_scores, query=\"\")\n\tsummary_response = cast(Response, summary_response)\n\tsummary = summary_response.response\n\tpaper_node.metadata[SHARED_PAPER_SUMMARY_KEY] = summary\n\tself._update_node(node_id=paper_node.node_id, node=paper_node)\n\treturn summary\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/temporary_store/","title":"Temporary store","text":""},{"location":"code_docs/func_modules/paper/store/temporary_store/#labridge.func_modules.paper.store.temporary_store","title":"<code>labridge.func_modules.paper.store.temporary_store</code>","text":""},{"location":"code_docs/func_modules/paper/store/temporary_store/#labridge.func_modules.paper.store.temporary_store.RecentPaperStore","title":"<code>labridge.func_modules.paper.store.temporary_store.RecentPaperStore</code>","text":"<p>               Bases: <code>object</code></p> <p>This class stores the recent papers of a specific user. It is constructed as a tree, with a root node.</p> <p>Different papers are inserted as child nodes of the root node, the node_id is the absolute file path (in the recent paper warehouse) of the paper.</p> <p>For each paper node, TextNodes recording paper contents are stored as its child nodes. Like:</p> <pre><code>                                                                                root_node\n                                                                        /                               \\\n                                                                   /                             \\\n                                                                Paper1                                  Paper2\n                                                /               ...                             \\\n                                        node_1                                          node_n\n</code></pre> PARAMETER DESCRIPTION <code>vector_index</code> <p>The vector database storing recent papers.</p> <p> TYPE: <code>VectorStoreIndex</code> </p> <code>persist_dir</code> <p>The persist directory of the vector database.</p> <p> TYPE: <code>persist_dir</code> </p> Note <p>The metadata <code>date</code> and <code>time</code> is recorded in a list format for the convenience of metadata filtering. For example: ['2024-08-10'], ['09:05:03'].</p> Source code in <code>labridge\\func_modules\\paper\\store\\temporary_store.py</code> <pre><code>class RecentPaperStore(object):\n\tr\"\"\"\n\tThis class stores the recent papers of a specific user.\n\tIt is constructed as a tree, with a root node.\n\n\tDifferent papers are inserted as child nodes of the root node,\n\tthe node_id is the absolute file path (in the recent paper warehouse) of the paper.\n\n\tFor each paper node, TextNodes recording paper contents are stored as its child nodes.\n\tLike:\n\n\t```\n\t\t\t\t\t\t\t\t\t\t\troot_node\n\t\t\t\t\t\t\t\t\t\t/\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t   /\t\t\t\t \\\n\t\t\t\t\t\t\t\t\tPaper1\t\t\t\t\tPaper2\n\t\t\t\t\t\t\t/\t\t...\t\t\t\t\\\n\t\t\t\t\t\tnode_1  \t\t\t\t\tnode_n\n\t```\n\n\tArgs:\n\t\tvector_index (VectorStoreIndex): The vector database storing recent papers.\n\t\tpersist_dir (persist_dir): The persist directory of the vector database.\n\n\tNote:\n\t\tThe metadata `date` and `time` is recorded in a list format for the convenience of metadata filtering.\n\t\tFor example: ['2024-08-10'], ['09:05:03'].\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tvector_index: VectorStoreIndex,\n\t\tpersist_dir: str\n\t):\n\t\troot = Path(__file__)\n\t\tfor idx in range(5):\n\t\t\troot = root.parent\n\t\tself._root = root\n\t\tself.vector_index = vector_index\n\t\tself.vector_index.set_index_id(TMP_PAPER_VECTOR_INDEX_ID)\n\t\tself.persist_dir = persist_dir\n\t\tself._user_id = self.user_id\n\t\tself._fs = fsspec.filesystem(\"file\")\n\n\t@classmethod\n\tdef from_storage(\n\t\tcls,\n\t\tpersist_dir: str,\n\t\tembed_model: BaseEmbedding,\n\t):\n\t\tr\"\"\"\n\t\tLoad from a existing storage.\n\n\t\tArgs:\n\t\t\tpersist_dir (str): The persist directory of the existing storage.\n\t\t\tembed_model (BaseEmbedding): The used embedding model.\n\n\t\tReturns:\n\t\t\tRecentPaperStore\n\t\t\"\"\"\n\t\tvector_storage_context = StorageContext.from_defaults(persist_dir=persist_dir)\n\t\tvector_index = load_index_from_storage(\n\t\t\tstorage_context=vector_storage_context,\n\t\t\tindex_id=TMP_PAPER_VECTOR_INDEX_ID,\n\t\t\tembed_model=embed_model,\n\t\t)\n\t\treturn cls(\n\t\t\tvector_index=vector_index,\n\t\t\tpersist_dir=persist_dir,\n\t\t)\n\n\t@property\n\tdef user_id(self) -&gt; str:\n\t\tr\"\"\" Return the user_id of this RecentPaperStore \"\"\"\n\t\tuser_id = Path(self.persist_dir).relative_to(self._root / TMP_PAPER_VECTOR_INDEX_PERSIST_DIR)\n\t\treturn str(user_id)\n\n\t@classmethod\n\tdef from_user_id(\n\t\tcls,\n\t\tuser_id: str,\n\t\tembed_model: BaseEmbedding,\n\t):\n\t\tr\"\"\"\n\t\tConstruct from a user_id.\n\t\tIf the corresponding persist_dir of the user does not exist, a new RecentPaperStore will be created for the user.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user_id of a Lab member.\n\t\t\tembed_model (BaseEmbedding): The used embedding model.\n\n\t\tReturns:\n\t\t\tRecentPaperStore\n\t\t\"\"\"\n\t\taccount_manager = AccountManager()\n\n\t\tif user_id not in account_manager.get_users():\n\t\t\traise ValueError(f\"Invalid user id: {user_id}.\")\n\n\t\troot = Path(__file__)\n\t\tfor idx in range(5):\n\t\t\troot = root.parent\n\n\t\tfs = fsspec.filesystem(\"file\")\n\t\tpaper_dir = str(root / f\"{TMP_PAPER_WAREHOUSE_DIR}/{user_id}\")\n\t\tif not fs.exists(paper_dir):\n\t\t\tfs.mkdirs(paper_dir)\n\n\t\tpersist_dir = str(root / f\"{TMP_PAPER_VECTOR_INDEX_PERSIST_DIR}/{user_id}\")\n\t\tif fs.exists(persist_dir):\n\t\t\treturn cls.from_storage(\n\t\t\t\tpersist_dir=persist_dir,\n\t\t\t\tembed_model=embed_model,\n\t\t\t)\n\n\t\t# root node\n\t\troot_node = TextNode(\n\t\t\ttext=f\"Root node for the temporary papers of {user_id}\",\n\t\t\tid_=TMP_PAPER_ROOT_NODE_NAME,\n\t\t)\n\t\tnodes = [root_node]\n\t\tvector_index = VectorStoreIndex(\n\t\t\tnodes=nodes,\n\t\t\tembed_model=embed_model,\n\t\t)\n\t\treturn cls(\n\t\t\tvector_index=vector_index,\n\t\t\tpersist_dir=persist_dir,\n\t\t)\n\n\tdef _check_valid_paper(self, paper_file_path: str):\n\t\tr\"\"\" Check whether the paper path is valid. \"\"\"\n\t\tif not self._fs.exists(paper_file_path):\n\t\t\traise ValueError(f\"{paper_file_path} is not a valid file path, it does not exist.\")\n\n\t\tsuffix = Path(paper_file_path).suffix\n\t\tif suffix != \".pdf\":\n\t\t\traise ValueError(f\"Only support .pdf format.\")\n\n\tdef check_valid_paper(self, paper_file_path: str):\n\t\tr\"\"\"\n\t\tCheck whether the paper path is valid or not.\n\n\t\t1. Whether the paper_file_path exists.\n\t\t2. Whether the suffix is `.pdf`.\n\n\t\tArgs:\n\t\t\tpaper_file_path (str): The paper path.\n\n\t\tReturns:\n\t\t\tNone\n\n\t\tRaises:\n\t\t\tValueError: If the paper_file_path is not valid.\n\t\t\"\"\"\n\t\tself._check_valid_paper(paper_file_path=paper_file_path)\n\n\tdef _update_node(\n\t\tself,\n\t\tnode_id: str,\n\t\tnode: BaseNode,\n\t):\n\t\tr\"\"\" Update an existing node in vector index. \"\"\"\n\t\tself.vector_index.delete_nodes([node_id])\n\t\tself.vector_index.insert_nodes([node])\n\n\tdef _delete_nodes(self, node_ids: List[str]):\n\t\tr\"\"\" Delete a node from the vector index. \"\"\"\n\t\tself.vector_index.delete_nodes(node_ids=node_ids)\n\n\tdef _get_node(self, node_id: str) -&gt; BaseNode:\n\t\tr\"\"\" Get a node from the vector index according to node_id. \"\"\"\n\t\treturn self.vector_index.docstore.get_node(node_id)\n\n\tdef _get_nodes(self, node_ids: List[str]) -&gt; List[BaseNode]:\n\t\tr\"\"\" Get nodes from the vector index according to node_ids. \"\"\"\n\t\treturn self.vector_index.docstore.get_nodes(node_ids)\n\n\tdef _default_transformations(self) -&gt; List[TransformComponent]:\n\t\treturn [SentenceSplitter(chunk_size=1024, chunk_overlap=256, include_metadata=True), ]\n\n\tdef file_exists(self, file_path: str) -&gt; bool:\n\t\tr\"\"\"\n\t\tJudge whether a paper exists in the RecentPaperStore according to its filename.\n\n\t\tArgs:\n\t\t\tfile_path (str): The file path of the paper.\n\n\t\tReturns:\n\t\t\tbool: Whether the paper exist or not.\n\t\t\"\"\"\n\t\tfile_name = Path(file_path).name\n\t\tuser_papers_dir = self._root / f\"{TMP_PAPER_WAREHOUSE_DIR}/{self.user_id}\"\n\t\tpaper_file_path = str(user_papers_dir / file_name)\n\n\t\ttry:\n\t\t\tself._get_node(node_id=paper_file_path)\n\t\t\treturn True\n\t\texcept ValueError:\n\t\t\treturn False\n\n\tdef put(self, paper_file_path: str, extra_metadata: dict = None):\n\t\tr\"\"\"\n\t\tput a new paper into the vector index.\n\n\t\tArgs:\n\t\t\tpaper_file_path (str): The absolute path of the paper.\n\t\t\textra_metadata (dict): Extra metadata of the paper.\n\t\t\t\tFor example, if the paper is downloaded from arXiv,\n\t\t\t\tmuch structured information will be provided by the downloader.\n\n\t\tReturns:\n\t\t\tNone\n\t\t\"\"\"\n\t\ttry:\n\t\t\tself._check_valid_paper(paper_file_path=paper_file_path)\n\t\texcept ValueError:\n\t\t\treturn\n\n\t\tfile_name = Path(paper_file_path).name\n\t\tuser_papers_dir = self._root / f\"{TMP_PAPER_WAREHOUSE_DIR}/{self.user_id}\"\n\t\tstore_file_path = str(user_papers_dir / file_name)\n\n\t\ttry:\n\t\t\t_ = self._get_node(node_id=store_file_path)\n\t\t\tprint(f\"{store_file_path} already exists in the temporary papers of user {self._user_id}.\")\n\t\t\treturn\n\t\texcept ValueError:\n\t\t\tpass\n\n\t\tif str(Path(paper_file_path).parent) != str(user_papers_dir):\n\t\t\tself._fs.cp(paper_file_path, str(user_papers_dir))\n\n\t\troot_node = self._get_node(node_id=TMP_PAPER_ROOT_NODE_NAME)\n\t\tpapers = root_node.child_nodes or []\n\n\t\tdate, h_m_s = get_time()\n\t\tpaper_node = TextNode(\n\t\t\tid_=store_file_path,\n\t\t\ttext=f\"The paper {store_file_path}\",\n\t\t\tmetadata={\n\t\t\t\tTMP_PAPER_DATE: [date,],\n\t\t\t\tTMP_PAPER_TIME: [h_m_s,],\n\t\t\t}\n\t\t)\n\t\tpapers.append(RelatedNodeInfo(node_id=paper_node.node_id))\n\t\troot_node.relationships[NodeRelationship.CHILD] = papers\n\t\tself._update_node(node_id=TMP_PAPER_ROOT_NODE_NAME, node=root_node)\n\n\t\t# read the paper:\n\t\treader = SimpleDirectoryReader(\n\t\t\tinput_files=[store_file_path],\n\t\t\tfile_metadata=tmp_paper_get_file_metadata,\n\t\t\tfilename_as_id=True,\n\t\t)\n\t\tdocuments = reader.load_data()\n\n\t\tfor doc in documents:\n\t\t\tself.vector_index.docstore.set_document_hash(doc.get_doc_id(), doc.hash)\n\n\t\tdoc_nodes = run_transformations(\n\t\t\tnodes=documents,\n\t\t\ttransformations=self._default_transformations()\n\t\t)\n\n\t\tchild_nodes = []\n\t\tfor doc_node in doc_nodes:\n\t\t\tchild_nodes.append(RelatedNodeInfo(node_id=doc_node.node_id))\n\t\t\tdoc_node.relationships[NodeRelationship.PARENT] = RelatedNodeInfo(node_id=paper_node.node_id)\n\t\t\tnew_metadata = {\n\t\t\t\tTMP_PAPER_NODE_TYPE_KEY: TMP_PAPER_DOC_NODE_TYPE,\n\t\t\t\tTMP_PAPER_DATE: [date],\n\t\t\t\tTMP_PAPER_TIME: [h_m_s],\n\t\t\t}\n\t\t\tif extra_metadata:\n\t\t\t\tnew_metadata.update(extra_metadata)\n\n\t\t\tdoc_node.metadata.update(new_metadata)\n\t\t\tdoc_node.excluded_llm_metadata_keys.append(TMP_PAPER_NODE_TYPE_KEY)\n\t\t\tdoc_node.excluded_embed_metadata_keys.append(TMP_PAPER_NODE_TYPE_KEY)\n\n\t\tpaper_node.relationships[NodeRelationship.CHILD] = child_nodes\n\t\tnodes = doc_nodes + [paper_node]\n\t\tself.vector_index.insert_nodes(nodes=nodes)\n\n\tdef get_summary_node(self, paper_file_path: str) -&gt; Optional[BaseNode]:\n\t\tr\"\"\"\n\t\tGet the summary node of a paper.\n\n\t\tArgs:\n\t\t\tpaper_file_path (str): The file path of the paper, equally the node_id of the paper_node.\n\n\t\tReturns:\n\t\t\tOptional[BaseNode]: The summary node the paper. If it does not exist, return None.\n\t\t\"\"\"\n\t\tsummary_id = f\"{TMP_PAPER_SUMMARY_NODE_PREFIX}{paper_file_path}\"\n\t\ttry:\n\t\t\tsummary_node = self._get_node(node_id=summary_id)\n\t\t\treturn summary_node\n\t\texcept Exception as e:\n\t\t\tprint(f\"Summary node of {paper_file_path} does not exist. {e}\")\n\t\t\treturn None\n\n\tdef get_paper_node(self, paper_file_path: str) -&gt; Optional[BaseNode]:\n\t\tr\"\"\"\n\t\tGet the paper_node of a paper.\n\n\t\tArgs:\n\t\t\tpaper_file_path (str): The file path of the paper, equally the node_id of the paper_node.\n\n\t\tReturns:\n\t\t\tOptional[BaseNode]: The paper node.\n\n\t\tRaises:\n\t\t\tValueError: If the paper node does not exist.\n\t\t\"\"\"\n\t\tself._check_valid_paper(paper_file_path=paper_file_path)\n\t\ttry:\n\t\t\tpaper_node = self._get_node(node_id=paper_file_path)\n\t\t\treturn paper_node\n\t\texcept Exception:\n\t\t\traise ValueError(f\"{paper_file_path} does not exists in the temporary papers of user {self._user_id}.\")\n\n\tdef insert_summary_node(self, paper_file_path: str, summary_node: TextNode):\n\t\tself._check_valid_paper(paper_file_path=paper_file_path)\n\t\tpaper_node = self.get_paper_node(paper_file_path=paper_file_path)\n\n\t\tsummary_node.id_ = f\"{TMP_PAPER_SUMMARY_NODE_PREFIX}{paper_file_path}\"\n\t\tsummary_node.relationships[NodeRelationship.PARENT] = RelatedNodeInfo(node_id=paper_node.node_id)\n\n\t\tpaper_docs = paper_node.child_nodes\n\t\tpaper_docs.append(\n\t\t\tRelatedNodeInfo(node_id=summary_node.node_id)\n\t\t)\n\t\tdoc_node = self._get_node(node_id=paper_docs[0].node_id)\n\t\tsummary_node.metadata.update(doc_node.metadata)\n\n\t\tpaper_node.relationships[NodeRelationship.CHILD] = paper_docs\n\t\tself._update_node(node_id=paper_node.node_id, node=paper_node)\n\t\tself.vector_index.insert_nodes(nodes=[summary_node])\n\n\tdef get_paper_nodes(self, paper_file_path: str) -&gt; Optional[List[BaseNode]]:\n\t\tr\"\"\"\n\t\tGet the doc nodes of a paper.\n\n\t\tArgs:\n\t\t\tpaper_file_path (str): The file path of the paper, equally the node_id of the paper_node.\n\n\t\tReturns:\n\t\t\tOptional[List[BaseNode]]: The doc nodes of the paper.\n\n\t\tRaises:\n\t\t\tValueError: If the paper does not exist.\n\n\t\t\"\"\"\n\t\tself._check_valid_paper(paper_file_path=paper_file_path)\n\t\tpaper_node = self.get_paper_node(paper_file_path=paper_file_path)\n\t\tdoc_nodes = paper_node.child_nodes\n\t\tdoc_ids = [node.node_id for node in doc_nodes]\n\t\tpaper_nodes = self._get_nodes(node_ids=doc_ids)\n\t\treturn paper_nodes\n\n\tdef get_all_relevant_node_ids(self, node_ids: List[str]) -&gt; Optional[List[str]]:\n\t\tr\"\"\"\n\t\tGet all the ids of the nodes that are belong to the same papers with the input node_ids.\n\n\t\tArgs:\n\t\t\tnode_ids (List[str]): The node ids.\n\n\t\tReturns:\n\t\t\tOptional[List[str]]: The relevant doc nodes. If no relevant node exists, return None.\n\t\t\"\"\"\n\t\tpaper_ids = set()\n\t\tfor node_id in node_ids:\n\t\t\ttry:\n\t\t\t\tnode = self._get_node(node_id=node_id)\n\t\t\t\tpaper_id = node.parent_node.node_id\n\t\t\t\tpaper_ids.add(paper_id)\n\t\t\texcept Exception:\n\t\t\t\tcontinue\n\t\tif len(paper_ids) &lt; 1:\n\t\t\treturn None\n\n\t\tall_ids = []\n\t\tfor paper_id in paper_ids:\n\t\t\tpaper_nodes = self.get_paper_nodes(paper_file_path=paper_id)\n\t\t\tall_ids.extend([node.node_id for node in paper_nodes])\n\t\treturn all_ids\n\n\tdef delete(self, paper_file_path: str):\n\t\tr\"\"\"\n\t\tDelete a paper from the recent paper vector index and the recent paper warehouse.\n\n\t\tArgs:\n\t\t\tpaper_file_path (str): The file path of the paper, equally the node_id of the paper_node.\n\t\t\"\"\"\n\t\tself._check_valid_paper(paper_file_path=paper_file_path)\n\t\tpaper_node = self.get_paper_node(paper_file_path=paper_file_path)\n\t\tdoc_nodes = paper_node.child_nodes\n\t\tdelete_ids = [paper_node.node_id]\n\t\tdelete_ids.extend([doc_node.node_id for doc_node in doc_nodes])\n\t\tself._delete_nodes(node_ids=delete_ids)\n\n\t\troot_node = self._get_node(node_id=TMP_PAPER_ROOT_NODE_NAME)\n\t\tpapers = root_node.child_nodes\n\t\tfor paper in papers:\n\t\t\tif paper.node_id == paper_file_path:\n\t\t\t\tpapers.remove(paper)\n\t\troot_node.relationships[NodeRelationship.CHILD] = papers\n\t\tself._update_node(node_id=TMP_PAPER_ROOT_NODE_NAME, node=root_node)\n\t\ttry:\n\t\t\tPath(paper_file_path).relative_to(TMP_PAPER_WAREHOUSE_DIR)\n\t\t\tself._fs.rm(paper_file_path)\n\t\texcept ValueError:\n\t\t\tpass\n\n\tdef persist(self, persist_dir: str = None):\n\t\tr\"\"\"\n\t\tPersis to the disk.\n\n\t\tArgs:\n\t\t\tpersist_dir (str): The save directory. Defaults to `self.persist_dir`\n\t\t\"\"\"\n\t\tpersist_dir = persist_dir or self.persist_dir\n\t\tif not self._fs.exists(persist_dir):\n\t\t\tself._fs.makedirs(persist_dir)\n\t\tself.vector_index.storage_context.persist(persist_dir=persist_dir)\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/temporary_store/#labridge.func_modules.paper.store.temporary_store.RecentPaperStore.user_id","title":"<code>labridge.func_modules.paper.store.temporary_store.RecentPaperStore.user_id: str</code>  <code>property</code>","text":"<p>Return the user_id of this RecentPaperStore</p>"},{"location":"code_docs/func_modules/paper/store/temporary_store/#labridge.func_modules.paper.store.temporary_store.RecentPaperStore.check_valid_paper","title":"<code>labridge.func_modules.paper.store.temporary_store.RecentPaperStore.check_valid_paper(paper_file_path)</code>","text":"<p>Check whether the paper path is valid or not.</p> <ol> <li>Whether the paper_file_path exists.</li> <li>Whether the suffix is <code>.pdf</code>.</li> </ol> PARAMETER DESCRIPTION <code>paper_file_path</code> <p>The paper path.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <p>None</p> RAISES DESCRIPTION <code>ValueError</code> <p>If the paper_file_path is not valid.</p> Source code in <code>labridge\\func_modules\\paper\\store\\temporary_store.py</code> <pre><code>def check_valid_paper(self, paper_file_path: str):\n\tr\"\"\"\n\tCheck whether the paper path is valid or not.\n\n\t1. Whether the paper_file_path exists.\n\t2. Whether the suffix is `.pdf`.\n\n\tArgs:\n\t\tpaper_file_path (str): The paper path.\n\n\tReturns:\n\t\tNone\n\n\tRaises:\n\t\tValueError: If the paper_file_path is not valid.\n\t\"\"\"\n\tself._check_valid_paper(paper_file_path=paper_file_path)\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/temporary_store/#labridge.func_modules.paper.store.temporary_store.RecentPaperStore.delete","title":"<code>labridge.func_modules.paper.store.temporary_store.RecentPaperStore.delete(paper_file_path)</code>","text":"<p>Delete a paper from the recent paper vector index and the recent paper warehouse.</p> PARAMETER DESCRIPTION <code>paper_file_path</code> <p>The file path of the paper, equally the node_id of the paper_node.</p> <p> TYPE: <code>str</code> </p> Source code in <code>labridge\\func_modules\\paper\\store\\temporary_store.py</code> <pre><code>def delete(self, paper_file_path: str):\n\tr\"\"\"\n\tDelete a paper from the recent paper vector index and the recent paper warehouse.\n\n\tArgs:\n\t\tpaper_file_path (str): The file path of the paper, equally the node_id of the paper_node.\n\t\"\"\"\n\tself._check_valid_paper(paper_file_path=paper_file_path)\n\tpaper_node = self.get_paper_node(paper_file_path=paper_file_path)\n\tdoc_nodes = paper_node.child_nodes\n\tdelete_ids = [paper_node.node_id]\n\tdelete_ids.extend([doc_node.node_id for doc_node in doc_nodes])\n\tself._delete_nodes(node_ids=delete_ids)\n\n\troot_node = self._get_node(node_id=TMP_PAPER_ROOT_NODE_NAME)\n\tpapers = root_node.child_nodes\n\tfor paper in papers:\n\t\tif paper.node_id == paper_file_path:\n\t\t\tpapers.remove(paper)\n\troot_node.relationships[NodeRelationship.CHILD] = papers\n\tself._update_node(node_id=TMP_PAPER_ROOT_NODE_NAME, node=root_node)\n\ttry:\n\t\tPath(paper_file_path).relative_to(TMP_PAPER_WAREHOUSE_DIR)\n\t\tself._fs.rm(paper_file_path)\n\texcept ValueError:\n\t\tpass\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/temporary_store/#labridge.func_modules.paper.store.temporary_store.RecentPaperStore.file_exists","title":"<code>labridge.func_modules.paper.store.temporary_store.RecentPaperStore.file_exists(file_path)</code>","text":"<p>Judge whether a paper exists in the RecentPaperStore according to its filename.</p> PARAMETER DESCRIPTION <code>file_path</code> <p>The file path of the paper.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>Whether the paper exist or not.</p> <p> TYPE: <code>bool</code> </p> Source code in <code>labridge\\func_modules\\paper\\store\\temporary_store.py</code> <pre><code>def file_exists(self, file_path: str) -&gt; bool:\n\tr\"\"\"\n\tJudge whether a paper exists in the RecentPaperStore according to its filename.\n\n\tArgs:\n\t\tfile_path (str): The file path of the paper.\n\n\tReturns:\n\t\tbool: Whether the paper exist or not.\n\t\"\"\"\n\tfile_name = Path(file_path).name\n\tuser_papers_dir = self._root / f\"{TMP_PAPER_WAREHOUSE_DIR}/{self.user_id}\"\n\tpaper_file_path = str(user_papers_dir / file_name)\n\n\ttry:\n\t\tself._get_node(node_id=paper_file_path)\n\t\treturn True\n\texcept ValueError:\n\t\treturn False\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/temporary_store/#labridge.func_modules.paper.store.temporary_store.RecentPaperStore.from_storage","title":"<code>labridge.func_modules.paper.store.temporary_store.RecentPaperStore.from_storage(persist_dir, embed_model)</code>  <code>classmethod</code>","text":"<p>Load from a existing storage.</p> PARAMETER DESCRIPTION <code>persist_dir</code> <p>The persist directory of the existing storage.</p> <p> TYPE: <code>str</code> </p> <code>embed_model</code> <p>The used embedding model.</p> <p> TYPE: <code>BaseEmbedding</code> </p> RETURNS DESCRIPTION <p>RecentPaperStore</p> Source code in <code>labridge\\func_modules\\paper\\store\\temporary_store.py</code> <pre><code>@classmethod\ndef from_storage(\n\tcls,\n\tpersist_dir: str,\n\tembed_model: BaseEmbedding,\n):\n\tr\"\"\"\n\tLoad from a existing storage.\n\n\tArgs:\n\t\tpersist_dir (str): The persist directory of the existing storage.\n\t\tembed_model (BaseEmbedding): The used embedding model.\n\n\tReturns:\n\t\tRecentPaperStore\n\t\"\"\"\n\tvector_storage_context = StorageContext.from_defaults(persist_dir=persist_dir)\n\tvector_index = load_index_from_storage(\n\t\tstorage_context=vector_storage_context,\n\t\tindex_id=TMP_PAPER_VECTOR_INDEX_ID,\n\t\tembed_model=embed_model,\n\t)\n\treturn cls(\n\t\tvector_index=vector_index,\n\t\tpersist_dir=persist_dir,\n\t)\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/temporary_store/#labridge.func_modules.paper.store.temporary_store.RecentPaperStore.from_user_id","title":"<code>labridge.func_modules.paper.store.temporary_store.RecentPaperStore.from_user_id(user_id, embed_model)</code>  <code>classmethod</code>","text":"<p>Construct from a user_id. If the corresponding persist_dir of the user does not exist, a new RecentPaperStore will be created for the user.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user_id of a Lab member.</p> <p> TYPE: <code>str</code> </p> <code>embed_model</code> <p>The used embedding model.</p> <p> TYPE: <code>BaseEmbedding</code> </p> RETURNS DESCRIPTION <p>RecentPaperStore</p> Source code in <code>labridge\\func_modules\\paper\\store\\temporary_store.py</code> <pre><code>@classmethod\ndef from_user_id(\n\tcls,\n\tuser_id: str,\n\tembed_model: BaseEmbedding,\n):\n\tr\"\"\"\n\tConstruct from a user_id.\n\tIf the corresponding persist_dir of the user does not exist, a new RecentPaperStore will be created for the user.\n\n\tArgs:\n\t\tuser_id (str): The user_id of a Lab member.\n\t\tembed_model (BaseEmbedding): The used embedding model.\n\n\tReturns:\n\t\tRecentPaperStore\n\t\"\"\"\n\taccount_manager = AccountManager()\n\n\tif user_id not in account_manager.get_users():\n\t\traise ValueError(f\"Invalid user id: {user_id}.\")\n\n\troot = Path(__file__)\n\tfor idx in range(5):\n\t\troot = root.parent\n\n\tfs = fsspec.filesystem(\"file\")\n\tpaper_dir = str(root / f\"{TMP_PAPER_WAREHOUSE_DIR}/{user_id}\")\n\tif not fs.exists(paper_dir):\n\t\tfs.mkdirs(paper_dir)\n\n\tpersist_dir = str(root / f\"{TMP_PAPER_VECTOR_INDEX_PERSIST_DIR}/{user_id}\")\n\tif fs.exists(persist_dir):\n\t\treturn cls.from_storage(\n\t\t\tpersist_dir=persist_dir,\n\t\t\tembed_model=embed_model,\n\t\t)\n\n\t# root node\n\troot_node = TextNode(\n\t\ttext=f\"Root node for the temporary papers of {user_id}\",\n\t\tid_=TMP_PAPER_ROOT_NODE_NAME,\n\t)\n\tnodes = [root_node]\n\tvector_index = VectorStoreIndex(\n\t\tnodes=nodes,\n\t\tembed_model=embed_model,\n\t)\n\treturn cls(\n\t\tvector_index=vector_index,\n\t\tpersist_dir=persist_dir,\n\t)\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/temporary_store/#labridge.func_modules.paper.store.temporary_store.RecentPaperStore.get_all_relevant_node_ids","title":"<code>labridge.func_modules.paper.store.temporary_store.RecentPaperStore.get_all_relevant_node_ids(node_ids)</code>","text":"<p>Get all the ids of the nodes that are belong to the same papers with the input node_ids.</p> PARAMETER DESCRIPTION <code>node_ids</code> <p>The node ids.</p> <p> TYPE: <code>List[str]</code> </p> RETURNS DESCRIPTION <code>Optional[List[str]]</code> <p>Optional[List[str]]: The relevant doc nodes. If no relevant node exists, return None.</p> Source code in <code>labridge\\func_modules\\paper\\store\\temporary_store.py</code> <pre><code>def get_all_relevant_node_ids(self, node_ids: List[str]) -&gt; Optional[List[str]]:\n\tr\"\"\"\n\tGet all the ids of the nodes that are belong to the same papers with the input node_ids.\n\n\tArgs:\n\t\tnode_ids (List[str]): The node ids.\n\n\tReturns:\n\t\tOptional[List[str]]: The relevant doc nodes. If no relevant node exists, return None.\n\t\"\"\"\n\tpaper_ids = set()\n\tfor node_id in node_ids:\n\t\ttry:\n\t\t\tnode = self._get_node(node_id=node_id)\n\t\t\tpaper_id = node.parent_node.node_id\n\t\t\tpaper_ids.add(paper_id)\n\t\texcept Exception:\n\t\t\tcontinue\n\tif len(paper_ids) &lt; 1:\n\t\treturn None\n\n\tall_ids = []\n\tfor paper_id in paper_ids:\n\t\tpaper_nodes = self.get_paper_nodes(paper_file_path=paper_id)\n\t\tall_ids.extend([node.node_id for node in paper_nodes])\n\treturn all_ids\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/temporary_store/#labridge.func_modules.paper.store.temporary_store.RecentPaperStore.get_paper_node","title":"<code>labridge.func_modules.paper.store.temporary_store.RecentPaperStore.get_paper_node(paper_file_path)</code>","text":"<p>Get the paper_node of a paper.</p> PARAMETER DESCRIPTION <code>paper_file_path</code> <p>The file path of the paper, equally the node_id of the paper_node.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Optional[BaseNode]</code> <p>Optional[BaseNode]: The paper node.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If the paper node does not exist.</p> Source code in <code>labridge\\func_modules\\paper\\store\\temporary_store.py</code> <pre><code>def get_paper_node(self, paper_file_path: str) -&gt; Optional[BaseNode]:\n\tr\"\"\"\n\tGet the paper_node of a paper.\n\n\tArgs:\n\t\tpaper_file_path (str): The file path of the paper, equally the node_id of the paper_node.\n\n\tReturns:\n\t\tOptional[BaseNode]: The paper node.\n\n\tRaises:\n\t\tValueError: If the paper node does not exist.\n\t\"\"\"\n\tself._check_valid_paper(paper_file_path=paper_file_path)\n\ttry:\n\t\tpaper_node = self._get_node(node_id=paper_file_path)\n\t\treturn paper_node\n\texcept Exception:\n\t\traise ValueError(f\"{paper_file_path} does not exists in the temporary papers of user {self._user_id}.\")\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/temporary_store/#labridge.func_modules.paper.store.temporary_store.RecentPaperStore.get_paper_nodes","title":"<code>labridge.func_modules.paper.store.temporary_store.RecentPaperStore.get_paper_nodes(paper_file_path)</code>","text":"<p>Get the doc nodes of a paper.</p> PARAMETER DESCRIPTION <code>paper_file_path</code> <p>The file path of the paper, equally the node_id of the paper_node.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Optional[List[BaseNode]]</code> <p>Optional[List[BaseNode]]: The doc nodes of the paper.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If the paper does not exist.</p> Source code in <code>labridge\\func_modules\\paper\\store\\temporary_store.py</code> <pre><code>def get_paper_nodes(self, paper_file_path: str) -&gt; Optional[List[BaseNode]]:\n\tr\"\"\"\n\tGet the doc nodes of a paper.\n\n\tArgs:\n\t\tpaper_file_path (str): The file path of the paper, equally the node_id of the paper_node.\n\n\tReturns:\n\t\tOptional[List[BaseNode]]: The doc nodes of the paper.\n\n\tRaises:\n\t\tValueError: If the paper does not exist.\n\n\t\"\"\"\n\tself._check_valid_paper(paper_file_path=paper_file_path)\n\tpaper_node = self.get_paper_node(paper_file_path=paper_file_path)\n\tdoc_nodes = paper_node.child_nodes\n\tdoc_ids = [node.node_id for node in doc_nodes]\n\tpaper_nodes = self._get_nodes(node_ids=doc_ids)\n\treturn paper_nodes\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/temporary_store/#labridge.func_modules.paper.store.temporary_store.RecentPaperStore.get_summary_node","title":"<code>labridge.func_modules.paper.store.temporary_store.RecentPaperStore.get_summary_node(paper_file_path)</code>","text":"<p>Get the summary node of a paper.</p> PARAMETER DESCRIPTION <code>paper_file_path</code> <p>The file path of the paper, equally the node_id of the paper_node.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Optional[BaseNode]</code> <p>Optional[BaseNode]: The summary node the paper. If it does not exist, return None.</p> Source code in <code>labridge\\func_modules\\paper\\store\\temporary_store.py</code> <pre><code>def get_summary_node(self, paper_file_path: str) -&gt; Optional[BaseNode]:\n\tr\"\"\"\n\tGet the summary node of a paper.\n\n\tArgs:\n\t\tpaper_file_path (str): The file path of the paper, equally the node_id of the paper_node.\n\n\tReturns:\n\t\tOptional[BaseNode]: The summary node the paper. If it does not exist, return None.\n\t\"\"\"\n\tsummary_id = f\"{TMP_PAPER_SUMMARY_NODE_PREFIX}{paper_file_path}\"\n\ttry:\n\t\tsummary_node = self._get_node(node_id=summary_id)\n\t\treturn summary_node\n\texcept Exception as e:\n\t\tprint(f\"Summary node of {paper_file_path} does not exist. {e}\")\n\t\treturn None\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/temporary_store/#labridge.func_modules.paper.store.temporary_store.RecentPaperStore.persist","title":"<code>labridge.func_modules.paper.store.temporary_store.RecentPaperStore.persist(persist_dir=None)</code>","text":"<p>Persis to the disk.</p> PARAMETER DESCRIPTION <code>persist_dir</code> <p>The save directory. Defaults to <code>self.persist_dir</code></p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> Source code in <code>labridge\\func_modules\\paper\\store\\temporary_store.py</code> <pre><code>def persist(self, persist_dir: str = None):\n\tr\"\"\"\n\tPersis to the disk.\n\n\tArgs:\n\t\tpersist_dir (str): The save directory. Defaults to `self.persist_dir`\n\t\"\"\"\n\tpersist_dir = persist_dir or self.persist_dir\n\tif not self._fs.exists(persist_dir):\n\t\tself._fs.makedirs(persist_dir)\n\tself.vector_index.storage_context.persist(persist_dir=persist_dir)\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/temporary_store/#labridge.func_modules.paper.store.temporary_store.RecentPaperStore.put","title":"<code>labridge.func_modules.paper.store.temporary_store.RecentPaperStore.put(paper_file_path, extra_metadata=None)</code>","text":"<p>put a new paper into the vector index.</p> PARAMETER DESCRIPTION <code>paper_file_path</code> <p>The absolute path of the paper.</p> <p> TYPE: <code>str</code> </p> <code>extra_metadata</code> <p>Extra metadata of the paper. For example, if the paper is downloaded from arXiv, much structured information will be provided by the downloader.</p> <p> TYPE: <code>dict</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <p>None</p> Source code in <code>labridge\\func_modules\\paper\\store\\temporary_store.py</code> <pre><code>def put(self, paper_file_path: str, extra_metadata: dict = None):\n\tr\"\"\"\n\tput a new paper into the vector index.\n\n\tArgs:\n\t\tpaper_file_path (str): The absolute path of the paper.\n\t\textra_metadata (dict): Extra metadata of the paper.\n\t\t\tFor example, if the paper is downloaded from arXiv,\n\t\t\tmuch structured information will be provided by the downloader.\n\n\tReturns:\n\t\tNone\n\t\"\"\"\n\ttry:\n\t\tself._check_valid_paper(paper_file_path=paper_file_path)\n\texcept ValueError:\n\t\treturn\n\n\tfile_name = Path(paper_file_path).name\n\tuser_papers_dir = self._root / f\"{TMP_PAPER_WAREHOUSE_DIR}/{self.user_id}\"\n\tstore_file_path = str(user_papers_dir / file_name)\n\n\ttry:\n\t\t_ = self._get_node(node_id=store_file_path)\n\t\tprint(f\"{store_file_path} already exists in the temporary papers of user {self._user_id}.\")\n\t\treturn\n\texcept ValueError:\n\t\tpass\n\n\tif str(Path(paper_file_path).parent) != str(user_papers_dir):\n\t\tself._fs.cp(paper_file_path, str(user_papers_dir))\n\n\troot_node = self._get_node(node_id=TMP_PAPER_ROOT_NODE_NAME)\n\tpapers = root_node.child_nodes or []\n\n\tdate, h_m_s = get_time()\n\tpaper_node = TextNode(\n\t\tid_=store_file_path,\n\t\ttext=f\"The paper {store_file_path}\",\n\t\tmetadata={\n\t\t\tTMP_PAPER_DATE: [date,],\n\t\t\tTMP_PAPER_TIME: [h_m_s,],\n\t\t}\n\t)\n\tpapers.append(RelatedNodeInfo(node_id=paper_node.node_id))\n\troot_node.relationships[NodeRelationship.CHILD] = papers\n\tself._update_node(node_id=TMP_PAPER_ROOT_NODE_NAME, node=root_node)\n\n\t# read the paper:\n\treader = SimpleDirectoryReader(\n\t\tinput_files=[store_file_path],\n\t\tfile_metadata=tmp_paper_get_file_metadata,\n\t\tfilename_as_id=True,\n\t)\n\tdocuments = reader.load_data()\n\n\tfor doc in documents:\n\t\tself.vector_index.docstore.set_document_hash(doc.get_doc_id(), doc.hash)\n\n\tdoc_nodes = run_transformations(\n\t\tnodes=documents,\n\t\ttransformations=self._default_transformations()\n\t)\n\n\tchild_nodes = []\n\tfor doc_node in doc_nodes:\n\t\tchild_nodes.append(RelatedNodeInfo(node_id=doc_node.node_id))\n\t\tdoc_node.relationships[NodeRelationship.PARENT] = RelatedNodeInfo(node_id=paper_node.node_id)\n\t\tnew_metadata = {\n\t\t\tTMP_PAPER_NODE_TYPE_KEY: TMP_PAPER_DOC_NODE_TYPE,\n\t\t\tTMP_PAPER_DATE: [date],\n\t\t\tTMP_PAPER_TIME: [h_m_s],\n\t\t}\n\t\tif extra_metadata:\n\t\t\tnew_metadata.update(extra_metadata)\n\n\t\tdoc_node.metadata.update(new_metadata)\n\t\tdoc_node.excluded_llm_metadata_keys.append(TMP_PAPER_NODE_TYPE_KEY)\n\t\tdoc_node.excluded_embed_metadata_keys.append(TMP_PAPER_NODE_TYPE_KEY)\n\n\tpaper_node.relationships[NodeRelationship.CHILD] = child_nodes\n\tnodes = doc_nodes + [paper_node]\n\tself.vector_index.insert_nodes(nodes=nodes)\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/temporary_store/#labridge.func_modules.paper.store.temporary_store.tmp_paper_get_file_metadata","title":"<code>labridge.func_modules.paper.store.temporary_store.tmp_paper_get_file_metadata(file_path)</code>","text":"<p>Record these metadata in each doc node:</p> <ul> <li>the absolute file path of the paper.</li> <li>the date when the file is put in.</li> <li>the time when the file is put in.</li> </ul> Source code in <code>labridge\\func_modules\\paper\\store\\temporary_store.py</code> <pre><code>def tmp_paper_get_file_metadata(file_path: str) -&gt; Dict[str, Any]:\n\tr\"\"\"\n\tRecord these metadata in each doc node:\n\n\t- the absolute file path of the paper.\n\t- the date when the file is put in.\n\t- the time when the file is put in.\n\t\"\"\"\n\tdate, h_m_s = get_time()\n\tmetadata = {\n\t\tTMP_PAPER_FILE_PATH_KEY: file_path,\n\t\tTMP_PAPER_DATE: [date,],\n\t\tTMP_PAPER_TIME: [h_m_s,],\n\t}\n\treturn metadata\n</code></pre>"},{"location":"code_docs/func_modules/paper/synthesizer/summarize/","title":"Summarize","text":""},{"location":"code_docs/func_modules/paper/synthesizer/summarize/#labridge.func_modules.paper.synthesizer.summarize","title":"<code>labridge.func_modules.paper.synthesizer.summarize</code>","text":""},{"location":"code_docs/func_modules/paper/synthesizer/summarize/#labridge.func_modules.paper.synthesizer.summarize.PaperBatchSummarize","title":"<code>labridge.func_modules.paper.synthesizer.summarize.PaperBatchSummarize</code>","text":"<p>               Bases: <code>BaseSynthesizer</code></p> <p>Summarize a paper in a batch style (Because of the video memory limits).</p> <ul> <li>Firstly, the paper contents are seperated into overlapped batches, with no batch exceeds the max_tokens.</li> <li>The batch contents are then summarized individually.</li> <li>Finally, those summaries are summarized to get the summary of the paper.</li> </ul> PARAMETER DESCRIPTION <code>llm</code> <p>The used LLM.</p> <p> TYPE: <code>LLM</code> DEFAULT: <code>None</code> </p> <code>max_tokens</code> <p>The max_tokens of a batch, set a proper value according to the video memory size.</p> <p> TYPE: <code>int</code> DEFAULT: <code>SUMMARIZE_MAX_TOKENS</code> </p> <code>overlap_chunk_num</code> <p>The overlap chunks between two adjacent batches.</p> <p> TYPE: <code>int</code> DEFAULT: <code>SUMMARIZE_OVERLAP_CHUNK_NUM</code> </p> <code>summary_query</code> <p>The summary prompt in the batch summary.</p> <p> TYPE: <code>str</code> DEFAULT: <code>PAPER_SUMMARIZE_QUERY</code> </p> <code>secondary_query</code> <p>The summary prompt in the final summary.</p> <p> TYPE: <code>str</code> DEFAULT: <code>PAPER_SECONDARY_SUMMARIZE_QUERY</code> </p> Source code in <code>labridge\\func_modules\\paper\\synthesizer\\summarize.py</code> <pre><code>class PaperBatchSummarize(BaseSynthesizer):\n\tr\"\"\"\n\tSummarize a paper in a batch style (Because of the video memory limits).\n\n\t- Firstly, the paper contents are seperated into overlapped batches, with no batch exceeds the max_tokens.\n\t- The batch contents are then summarized individually.\n\t- Finally, those summaries are summarized to get the summary of the paper.\n\n\tArgs:\n\t\tllm (LLM): The used LLM.\n\t\tmax_tokens (int): The max_tokens of a batch, set a proper value according to the video memory size.\n\t\toverlap_chunk_num (int): The overlap chunks between two adjacent batches.\n\t\tsummary_query (str): The summary prompt in the batch summary.\n\t\tsecondary_query (str): The summary prompt in the final summary.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tllm: LLM = None,\n\t\tmax_tokens: int = SUMMARIZE_MAX_TOKENS,\n\t\toverlap_chunk_num: int = SUMMARIZE_OVERLAP_CHUNK_NUM,\n\t\tsummary_query: str = PAPER_SUMMARIZE_QUERY,\n\t\tsecondary_query: str = PAPER_SECONDARY_SUMMARIZE_QUERY,\n\t):\n\t\tsuper().__init__(llm=llm)\n\t\tself._summary_template = DEFAULT_TREE_SUMMARIZE_PROMPT_SEL\n\t\tself._synthesizer = get_response_synthesizer(\n\t\t\tllm=self._llm,\n\t\t\tresponse_mode=ResponseMode.TREE_SUMMARIZE,\n\t\t)\n\t\tself._tokenizer = global_tokenizer or get_tokenizer()\n\t\tself._max_tokens = max_tokens\n\t\tself._overlap_chunk_num = overlap_chunk_num\n\t\tself._summary_query = summary_query\n\t\tself._secondary_query = secondary_query\n\n\n\t@property\n\tdef summary_query(self) -&gt; str:\n\t\treturn self._summary_query\n\n\t@summary_query.setter\n\tdef summary_query(self, value: str):\n\t\tself._summary_query = value\n\n\t@property\n\tdef secondary_query(self) -&gt; str:\n\t\treturn self._secondary_query\n\n\t@secondary_query.setter\n\tdef secondary_query(self, value: str):\n\t\tself._secondary_query = value\n\n\tdef _get_prompts(self) -&gt; PromptDictType:\n\t\t\"\"\"Get prompts.\"\"\"\n\t\treturn {\"summary_template\": self._summary_template}\n\n\tdef _update_prompts(self, prompts: PromptDictType) -&gt; None:\n\t\t\"\"\" Update prompts.\"\"\"\n\t\tif \"summary_template\" in prompts:\n\t\t\tself._summary_template = prompts[\"summary_template\"]\n\n\tdef _calculate_batch_size(self, text_chunks: Sequence[str]) -&gt; Tuple[bool, int]:\n\t\tr\"\"\"\n\t\tDecide whether to use batch mode and the batch size, according to the `text_chunks` and `self.max_tokens`.\n\n\t\tArgs:\n\t\t\ttext_chunks (Sequence[str]): The chunks of a paper.\n\n\t\tReturns:\n\t\t\tTuple[bool, int]:\n\t\t\t\t- batch_mode (bool): Whether to use batch summarize.\n\t\t\t\t- batch_size (int): Batch size in batch summarizing.\n\t\t\"\"\"\n\t\ttoken_num, max_node_tokens = 0, 0\n\t\tbatch_mode = False\n\t\tfor chunk in text_chunks:\n\t\t\ttokens = len(\n\t\t\t\tself._tokenizer(chunk)\n\t\t\t)\n\t\t\ttoken_num += tokens\n\t\t\tmax_node_tokens = max(tokens, max_node_tokens)\n\n\t\tif token_num &lt; self._max_tokens:\n\t\t\treturn batch_mode, 0\n\n\t\tbatch_mode = True\n\t\tbatch_size = self._max_tokens // max_node_tokens\n\t\treturn batch_mode, batch_size\n\n\tdef batch_chunks(self, text_chunks: Sequence[str], batch_size: int):\n\t\tr\"\"\"\n\t\tYield batch chunks according to the `batch_size` and `self._overlap_chunk_num`.\n\n\t\tArgs:\n\t\t\ttext_chunks (Sequence[str]): The chunks of a paper.\n\t\t\tbatch_size (int): The calculated batch size.\n\n\t\tReturns:\n\t\t\tSequence[str]: A batch.\n\t\t\"\"\"\n\t\tn = len(text_chunks)\n\t\tfor start in range(0, n, batch_size - self._overlap_chunk_num):\n\t\t\tyield text_chunks[start: start + batch_size]\n\n\tdef batch_get_response(self, batch_chunks: Sequence[str], query_str: str) -&gt; RESPONSE_TEXT_TYPE:\n\t\tr\"\"\"\n\t\tBatch summarize.\n\n\t\tArgs:\n\t\t\tbatch_chunks (Sequence[str]): A batch of chunks.\n\t\t\tquery_str (str): The batch query prompt.\n\n\t\tReturns:\n\t\t\tRESPONSE_TEXT_TYPE: The summary.\n\t\t\"\"\"\n\t\tsummary_template = self._summary_template.partial_format(query_str=query_str)\n\t\tresponse = self._llm.predict(\n\t\t\tsummary_template,\n\t\t\tcontext_str=\"\\n\".join(batch_chunks),\n\t\t)\n\t\treturn response\n\n\tasync def abatch_get_response(self, batch_chunks: Sequence[str], query_str: str) -&gt; RESPONSE_TEXT_TYPE:\n\t\tr\"\"\"\n\t\tAsynchronously batch summarize.\n\n\t\tArgs:\n\t\t\tbatch_chunks (Sequence[str]): A batch of chunks.\n\t\t\tquery_str (str): The batch query prompt.\n\n\t\tReturns:\n\t\t\tRESPONSE_TEXT_TYPE: The summary.\n\t\t\"\"\"\n\t\tsummary_template = self._summary_template.partial_format(query_str=query_str)\n\t\tresponse = await self._llm.apredict(\n\t\t\tsummary_template,\n\t\t\tcontext_str=\"\\n\".join(batch_chunks),\n\t\t)\n\t\treturn response\n\n\tdef get_response(\n        self,\n        query_str: str,\n        text_chunks: Sequence[str],\n        **response_kwargs: Any,\n    ) -&gt; RESPONSE_TEXT_TYPE:\n\t\tr\"\"\"\n\t\tSummarize a paper.\n\n\t\tArgs:\n\t\t\tquery_str (str): Not used.\n\t\t\ttext_chunks (Sequence[str]): The text chunks of a paper.\n\t\t\t**response_kwargs (Any): Not used.\n\n\t\tReturns:\n\t\t\tRESPONSE_TEXT_TYPE: The summary.\n\t\t\"\"\"\n\t\tbatch_mode, batch_size = self._calculate_batch_size(text_chunks=text_chunks)\n\n\t\tprint(\"summary batch size: \", batch_size)\n\t\tprint(\"Total chunks: \", len(text_chunks))\n\t\tprint(text_chunks[0])\n\t\tif not batch_mode:\n\t\t\treturn self.batch_get_response(\n\t\t\t\tbatch_chunks=text_chunks,\n\t\t\t\tquery_str=self.summary_query,\n\t\t\t)\n\n\t\tsummary_texts = []\n\t\tfor chunks in self.batch_chunks(text_chunks=text_chunks, batch_size=batch_size):\n\n\n\t\t\tresponse = self.batch_get_response(\n\t\t\t\tbatch_chunks=chunks,\n\t\t\t\tquery_str=self.summary_query\n\t\t\t)\n\t\t\tsummary_texts.append(response)\n\n\t\tfinal_response = self.batch_get_response(\n\t\t\tbatch_chunks=summary_texts,\n\t\t\tquery_str=self.secondary_query,\n\t\t)\n\t\treturn final_response\n\n\tasync def aget_response(\n        self,\n        query_str: str,\n        text_chunks: Sequence[str],\n        **response_kwargs: Any,\n    ) -&gt; RESPONSE_TEXT_TYPE:\n\t\tr\"\"\"\n\t\tSummarize a paper.\n\n\t\tArgs:\n\t\t\tquery_str (str): Not used.\n\t\t\ttext_chunks (Sequence[str]): The text chunks of a paper.\n\t\t\t**response_kwargs (Any): Not used.\n\n\t\tReturns:\n\t\t\tRESPONSE_TEXT_TYPE: The summary.\n\t\t\"\"\"\n\t\tbatch_mode, batch_size = self._calculate_batch_size(text_chunks=text_chunks)\n\t\tif not batch_mode:\n\t\t\treturn await self.abatch_get_response(\n\t\t\t\tbatch_chunks=text_chunks,\n\t\t\t\tquery_str=self.summary_query,\n\t\t\t)\n\n\t\ttasks = [\n\t\t\tself.abatch_get_response(\n\t\t\t\tbatch_chunks=batch_chunks,\n\t\t\t\tquery_str=self.summary_query,\n\t\t\t) for batch_chunks in self.batch_chunks(text_chunks=text_chunks, batch_size=batch_size)\n\t\t]\n\n\t\tsummary_texts = await asyncio.gather(*tasks)\n\n\t\tfinal_response = self.batch_get_response(\n\t\t\tbatch_chunks=summary_texts,\n\t\t\tquery_str=self.secondary_query,\n\t\t)\n\t\treturn final_response\n\n\t@dispatcher.span\n\tdef synthesize(self, query: QueryType, nodes: List[NodeWithScore],\n\t\tadditional_source_nodes: Optional[Sequence[NodeWithScore]] = None, **response_kwargs: Any, ) -&gt; RESPONSE_TYPE:\n\t\tdispatcher.event(SynthesizeStartEvent(query=query, ))\n\n\t\tif len(nodes) == 0:\n\t\t\tif self._streaming:\n\t\t\t\tempty_response = StreamingResponse(response_gen=empty_response_generator())\n\t\t\t\tdispatcher.event(SynthesizeEndEvent(query=query, response=empty_response, ))\n\t\t\t\treturn empty_response\n\t\t\telse:\n\t\t\t\tempty_response = Response(\"Empty Response\")\n\t\t\t\tdispatcher.event(SynthesizeEndEvent(query=query, response=empty_response, ))\n\t\t\t\treturn empty_response\n\n\t\tif isinstance(query, str):\n\t\t\tquery = QueryBundle(query_str=query)\n\n\t\twith self._callback_manager.event(CBEventType.SYNTHESIZE,\n\t\t\t\tpayload={EventPayload.QUERY_STR: query.query_str}, ) as event:\n\t\t\tresponse_str = self.get_response(query_str=query.query_str,\n\t\t\t\ttext_chunks=[n.node.get_content(metadata_mode=MetadataMode.NONE) for n in nodes], **response_kwargs, )\n\n\t\t\tadditional_source_nodes = additional_source_nodes or []\n\t\t\tsource_nodes = list(nodes) + list(additional_source_nodes)\n\n\t\t\tresponse = self._prepare_response_output(response_str, source_nodes)\n\n\t\t\tevent.on_end(payload={EventPayload.RESPONSE: response})\n\n\t\tdispatcher.event(SynthesizeEndEvent(query=query, response=response, ))\n\t\treturn response\n\n\t@dispatcher.span\n\tasync def asynthesize(self, query: QueryType, nodes: List[NodeWithScore],\n\t\tadditional_source_nodes: Optional[Sequence[NodeWithScore]] = None, **response_kwargs: Any, ) -&gt; RESPONSE_TYPE:\n\t\tdispatcher.event(SynthesizeStartEvent(query=query, ))\n\t\tif len(nodes) == 0:\n\t\t\tif self._streaming:\n\t\t\t\tempty_response = AsyncStreamingResponse(response_gen=empty_response_agenerator())\n\t\t\t\tdispatcher.event(SynthesizeEndEvent(query=query, response=empty_response, ))\n\t\t\t\treturn empty_response\n\t\t\telse:\n\t\t\t\tempty_response = Response(\"Empty Response\")\n\t\t\t\tdispatcher.event(SynthesizeEndEvent(query=query, response=empty_response, ))\n\t\t\t\treturn empty_response\n\n\t\tif isinstance(query, str):\n\t\t\tquery = QueryBundle(query_str=query)\n\n\t\twith self._callback_manager.event(CBEventType.SYNTHESIZE,\n\t\t\t\tpayload={EventPayload.QUERY_STR: query.query_str}, ) as event:\n\t\t\tresponse_str = await self.aget_response(query_str=query.query_str,\n\t\t\t\ttext_chunks=[n.node.get_content(metadata_mode=MetadataMode.NONE) for n in nodes], **response_kwargs, )\n\n\t\t\tadditional_source_nodes = additional_source_nodes or []\n\t\t\tsource_nodes = list(nodes) + list(additional_source_nodes)\n\n\t\t\tresponse = self._prepare_response_output(response_str, source_nodes)\n\n\t\t\tevent.on_end(payload={EventPayload.RESPONSE: response})\n\n\t\tdispatcher.event(SynthesizeEndEvent(query=query, response=response, ))\n\t\treturn response\n</code></pre>"},{"location":"code_docs/func_modules/paper/synthesizer/summarize/#labridge.func_modules.paper.synthesizer.summarize.PaperBatchSummarize.abatch_get_response","title":"<code>labridge.func_modules.paper.synthesizer.summarize.PaperBatchSummarize.abatch_get_response(batch_chunks, query_str)</code>  <code>async</code>","text":"<p>Asynchronously batch summarize.</p> PARAMETER DESCRIPTION <code>batch_chunks</code> <p>A batch of chunks.</p> <p> TYPE: <code>Sequence[str]</code> </p> <code>query_str</code> <p>The batch query prompt.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>RESPONSE_TEXT_TYPE</code> <p>The summary.</p> <p> TYPE: <code>RESPONSE_TEXT_TYPE</code> </p> Source code in <code>labridge\\func_modules\\paper\\synthesizer\\summarize.py</code> <pre><code>async def abatch_get_response(self, batch_chunks: Sequence[str], query_str: str) -&gt; RESPONSE_TEXT_TYPE:\n\tr\"\"\"\n\tAsynchronously batch summarize.\n\n\tArgs:\n\t\tbatch_chunks (Sequence[str]): A batch of chunks.\n\t\tquery_str (str): The batch query prompt.\n\n\tReturns:\n\t\tRESPONSE_TEXT_TYPE: The summary.\n\t\"\"\"\n\tsummary_template = self._summary_template.partial_format(query_str=query_str)\n\tresponse = await self._llm.apredict(\n\t\tsummary_template,\n\t\tcontext_str=\"\\n\".join(batch_chunks),\n\t)\n\treturn response\n</code></pre>"},{"location":"code_docs/func_modules/paper/synthesizer/summarize/#labridge.func_modules.paper.synthesizer.summarize.PaperBatchSummarize.aget_response","title":"<code>labridge.func_modules.paper.synthesizer.summarize.PaperBatchSummarize.aget_response(query_str, text_chunks, **response_kwargs)</code>  <code>async</code>","text":"<p>Summarize a paper.</p> PARAMETER DESCRIPTION <code>query_str</code> <p>Not used.</p> <p> TYPE: <code>str</code> </p> <code>text_chunks</code> <p>The text chunks of a paper.</p> <p> TYPE: <code>Sequence[str]</code> </p> <code>**response_kwargs</code> <p>Not used.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>RESPONSE_TEXT_TYPE</code> <p>The summary.</p> <p> TYPE: <code>RESPONSE_TEXT_TYPE</code> </p> Source code in <code>labridge\\func_modules\\paper\\synthesizer\\summarize.py</code> <pre><code>\tasync def aget_response(\n        self,\n        query_str: str,\n        text_chunks: Sequence[str],\n        **response_kwargs: Any,\n    ) -&gt; RESPONSE_TEXT_TYPE:\n\t\tr\"\"\"\n\t\tSummarize a paper.\n\n\t\tArgs:\n\t\t\tquery_str (str): Not used.\n\t\t\ttext_chunks (Sequence[str]): The text chunks of a paper.\n\t\t\t**response_kwargs (Any): Not used.\n\n\t\tReturns:\n\t\t\tRESPONSE_TEXT_TYPE: The summary.\n\t\t\"\"\"\n\t\tbatch_mode, batch_size = self._calculate_batch_size(text_chunks=text_chunks)\n\t\tif not batch_mode:\n\t\t\treturn await self.abatch_get_response(\n\t\t\t\tbatch_chunks=text_chunks,\n\t\t\t\tquery_str=self.summary_query,\n\t\t\t)\n\n\t\ttasks = [\n\t\t\tself.abatch_get_response(\n\t\t\t\tbatch_chunks=batch_chunks,\n\t\t\t\tquery_str=self.summary_query,\n\t\t\t) for batch_chunks in self.batch_chunks(text_chunks=text_chunks, batch_size=batch_size)\n\t\t]\n\n\t\tsummary_texts = await asyncio.gather(*tasks)\n\n\t\tfinal_response = self.batch_get_response(\n\t\t\tbatch_chunks=summary_texts,\n\t\t\tquery_str=self.secondary_query,\n\t\t)\n\t\treturn final_response\n</code></pre>"},{"location":"code_docs/func_modules/paper/synthesizer/summarize/#labridge.func_modules.paper.synthesizer.summarize.PaperBatchSummarize.batch_chunks","title":"<code>labridge.func_modules.paper.synthesizer.summarize.PaperBatchSummarize.batch_chunks(text_chunks, batch_size)</code>","text":"<p>Yield batch chunks according to the <code>batch_size</code> and <code>self._overlap_chunk_num</code>.</p> PARAMETER DESCRIPTION <code>text_chunks</code> <p>The chunks of a paper.</p> <p> TYPE: <code>Sequence[str]</code> </p> <code>batch_size</code> <p>The calculated batch size.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <p>Sequence[str]: A batch.</p> Source code in <code>labridge\\func_modules\\paper\\synthesizer\\summarize.py</code> <pre><code>def batch_chunks(self, text_chunks: Sequence[str], batch_size: int):\n\tr\"\"\"\n\tYield batch chunks according to the `batch_size` and `self._overlap_chunk_num`.\n\n\tArgs:\n\t\ttext_chunks (Sequence[str]): The chunks of a paper.\n\t\tbatch_size (int): The calculated batch size.\n\n\tReturns:\n\t\tSequence[str]: A batch.\n\t\"\"\"\n\tn = len(text_chunks)\n\tfor start in range(0, n, batch_size - self._overlap_chunk_num):\n\t\tyield text_chunks[start: start + batch_size]\n</code></pre>"},{"location":"code_docs/func_modules/paper/synthesizer/summarize/#labridge.func_modules.paper.synthesizer.summarize.PaperBatchSummarize.batch_get_response","title":"<code>labridge.func_modules.paper.synthesizer.summarize.PaperBatchSummarize.batch_get_response(batch_chunks, query_str)</code>","text":"<p>Batch summarize.</p> PARAMETER DESCRIPTION <code>batch_chunks</code> <p>A batch of chunks.</p> <p> TYPE: <code>Sequence[str]</code> </p> <code>query_str</code> <p>The batch query prompt.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>RESPONSE_TEXT_TYPE</code> <p>The summary.</p> <p> TYPE: <code>RESPONSE_TEXT_TYPE</code> </p> Source code in <code>labridge\\func_modules\\paper\\synthesizer\\summarize.py</code> <pre><code>def batch_get_response(self, batch_chunks: Sequence[str], query_str: str) -&gt; RESPONSE_TEXT_TYPE:\n\tr\"\"\"\n\tBatch summarize.\n\n\tArgs:\n\t\tbatch_chunks (Sequence[str]): A batch of chunks.\n\t\tquery_str (str): The batch query prompt.\n\n\tReturns:\n\t\tRESPONSE_TEXT_TYPE: The summary.\n\t\"\"\"\n\tsummary_template = self._summary_template.partial_format(query_str=query_str)\n\tresponse = self._llm.predict(\n\t\tsummary_template,\n\t\tcontext_str=\"\\n\".join(batch_chunks),\n\t)\n\treturn response\n</code></pre>"},{"location":"code_docs/func_modules/paper/synthesizer/summarize/#labridge.func_modules.paper.synthesizer.summarize.PaperBatchSummarize.get_response","title":"<code>labridge.func_modules.paper.synthesizer.summarize.PaperBatchSummarize.get_response(query_str, text_chunks, **response_kwargs)</code>","text":"<p>Summarize a paper.</p> PARAMETER DESCRIPTION <code>query_str</code> <p>Not used.</p> <p> TYPE: <code>str</code> </p> <code>text_chunks</code> <p>The text chunks of a paper.</p> <p> TYPE: <code>Sequence[str]</code> </p> <code>**response_kwargs</code> <p>Not used.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>RESPONSE_TEXT_TYPE</code> <p>The summary.</p> <p> TYPE: <code>RESPONSE_TEXT_TYPE</code> </p> Source code in <code>labridge\\func_modules\\paper\\synthesizer\\summarize.py</code> <pre><code>\tdef get_response(\n        self,\n        query_str: str,\n        text_chunks: Sequence[str],\n        **response_kwargs: Any,\n    ) -&gt; RESPONSE_TEXT_TYPE:\n\t\tr\"\"\"\n\t\tSummarize a paper.\n\n\t\tArgs:\n\t\t\tquery_str (str): Not used.\n\t\t\ttext_chunks (Sequence[str]): The text chunks of a paper.\n\t\t\t**response_kwargs (Any): Not used.\n\n\t\tReturns:\n\t\t\tRESPONSE_TEXT_TYPE: The summary.\n\t\t\"\"\"\n\t\tbatch_mode, batch_size = self._calculate_batch_size(text_chunks=text_chunks)\n\n\t\tprint(\"summary batch size: \", batch_size)\n\t\tprint(\"Total chunks: \", len(text_chunks))\n\t\tprint(text_chunks[0])\n\t\tif not batch_mode:\n\t\t\treturn self.batch_get_response(\n\t\t\t\tbatch_chunks=text_chunks,\n\t\t\t\tquery_str=self.summary_query,\n\t\t\t)\n\n\t\tsummary_texts = []\n\t\tfor chunks in self.batch_chunks(text_chunks=text_chunks, batch_size=batch_size):\n\n\n\t\t\tresponse = self.batch_get_response(\n\t\t\t\tbatch_chunks=chunks,\n\t\t\t\tquery_str=self.summary_query\n\t\t\t)\n\t\t\tsummary_texts.append(response)\n\n\t\tfinal_response = self.batch_get_response(\n\t\t\tbatch_chunks=summary_texts,\n\t\t\tquery_str=self.secondary_query,\n\t\t)\n\t\treturn final_response\n</code></pre>"},{"location":"code_docs/func_modules/reference/base/","title":"Base","text":""},{"location":"code_docs/func_modules/reference/base/#labridge.func_modules.reference.base","title":"<code>labridge.func_modules.reference.base</code>","text":""},{"location":"code_docs/func_modules/reference/base/#labridge.func_modules.reference.base.RefInfoBase","title":"<code>labridge.func_modules.reference.base.RefInfoBase</code>","text":"<p>This is the base class for reference information.</p> Source code in <code>labridge\\func_modules\\reference\\base.py</code> <pre><code>class RefInfoBase:\n\tr\"\"\"\n\tThis is the base class for reference information.\n\t\"\"\"\n\n\t@abstractmethod\n\tdef dumps(self):\n\t\tr\"\"\" Dump an object of the class to a string in JSON format. \"\"\"\n\n\t@classmethod\n\t@abstractmethod\n\tdef loads(cls, info_str):\n\t\tr\"\"\" Load an object of the class from a string in JSON format. \"\"\"\n</code></pre>"},{"location":"code_docs/func_modules/reference/base/#labridge.func_modules.reference.base.RefInfoBase.dumps","title":"<code>labridge.func_modules.reference.base.RefInfoBase.dumps()</code>  <code>abstractmethod</code>","text":"<p>Dump an object of the class to a string in JSON format.</p> Source code in <code>labridge\\func_modules\\reference\\base.py</code> <pre><code>@abstractmethod\ndef dumps(self):\n\tr\"\"\" Dump an object of the class to a string in JSON format. \"\"\"\n</code></pre>"},{"location":"code_docs/func_modules/reference/base/#labridge.func_modules.reference.base.RefInfoBase.loads","title":"<code>labridge.func_modules.reference.base.RefInfoBase.loads(info_str)</code>  <code>abstractmethod</code> <code>classmethod</code>","text":"<p>Load an object of the class from a string in JSON format.</p> Source code in <code>labridge\\func_modules\\reference\\base.py</code> <pre><code>@classmethod\n@abstractmethod\ndef loads(cls, info_str):\n\tr\"\"\" Load an object of the class from a string in JSON format. \"\"\"\n</code></pre>"},{"location":"code_docs/func_modules/reference/instrument/","title":"Instrument","text":""},{"location":"code_docs/func_modules/reference/instrument/#labridge.func_modules.reference.instrument","title":"<code>labridge.func_modules.reference.instrument</code>","text":""},{"location":"code_docs/func_modules/reference/instrument/#labridge.func_modules.reference.instrument.InstrumentInfo","title":"<code>labridge.func_modules.reference.instrument.InstrumentInfo</code>","text":"<p>               Bases: <code>RefInfoBase</code></p> <p>This class contains the information of an instrument, including:</p> PARAMETER DESCRIPTION <code>instrument_id</code> <p>The name of the instrument.</p> <p> TYPE: <code>str</code> </p> <code>super_users</code> <p>The super-users of the instrument.</p> <p> TYPE: <code>List[str]</code> </p> Source code in <code>labridge\\func_modules\\reference\\instrument.py</code> <pre><code>class InstrumentInfo(RefInfoBase):\n\tr\"\"\"\n\tThis class contains the information of an instrument, including:\n\n\tArgs:\n\t\tinstrument_id (str): The name of the instrument.\n\t\tsuper_users (List[str]): The super-users of the instrument.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tinstrument_id: str,\n\t\tsuper_users: List[str],\n\t):\n\t\tself.instrument_id = instrument_id\n\t\tself.super_users = super_users\n\n\tdef dumps(self) -&gt; str:\n\t\tr\"\"\" Dump to a string in JSON format. \"\"\"\n\t\tinfo_dict = {\n\t\t\tREF_TYPE: InstrumentInfo.__name__,\n\t\t\t\"instrument_id\": self.instrument_id,\n\t\t\t\"super_users\": self.super_users,\n\t\t}\n\t\treturn json.dumps(info_dict)\n\n\t@classmethod\n\tdef loads(\n\t\tcls,\n\t\tinfo_str: str,\n\t):\n\t\tr\"\"\" Load from a string in JSON format. \"\"\"\n\t\ttry:\n\t\t\tinfo_dict = json.loads(info_str)\n\t\t\tinstrument_id = info_dict[\"instrument_id\"]\n\t\t\tsuper_users = info_dict[\"super_users\"]\n\t\t\treturn cls(\n\t\t\t\tinstrument_id=instrument_id,\n\t\t\t\tsuper_users=super_users,\n\t\t\t)\n\t\texcept Exception:\n\t\t\traise ValueError(\"Invalid Instrument info string.\")\n</code></pre>"},{"location":"code_docs/func_modules/reference/instrument/#labridge.func_modules.reference.instrument.InstrumentInfo.dumps","title":"<code>labridge.func_modules.reference.instrument.InstrumentInfo.dumps()</code>","text":"<p>Dump to a string in JSON format.</p> Source code in <code>labridge\\func_modules\\reference\\instrument.py</code> <pre><code>def dumps(self) -&gt; str:\n\tr\"\"\" Dump to a string in JSON format. \"\"\"\n\tinfo_dict = {\n\t\tREF_TYPE: InstrumentInfo.__name__,\n\t\t\"instrument_id\": self.instrument_id,\n\t\t\"super_users\": self.super_users,\n\t}\n\treturn json.dumps(info_dict)\n</code></pre>"},{"location":"code_docs/func_modules/reference/instrument/#labridge.func_modules.reference.instrument.InstrumentInfo.loads","title":"<code>labridge.func_modules.reference.instrument.InstrumentInfo.loads(info_str)</code>  <code>classmethod</code>","text":"<p>Load from a string in JSON format.</p> Source code in <code>labridge\\func_modules\\reference\\instrument.py</code> <pre><code>@classmethod\ndef loads(\n\tcls,\n\tinfo_str: str,\n):\n\tr\"\"\" Load from a string in JSON format. \"\"\"\n\ttry:\n\t\tinfo_dict = json.loads(info_str)\n\t\tinstrument_id = info_dict[\"instrument_id\"]\n\t\tsuper_users = info_dict[\"super_users\"]\n\t\treturn cls(\n\t\t\tinstrument_id=instrument_id,\n\t\t\tsuper_users=super_users,\n\t\t)\n\texcept Exception:\n\t\traise ValueError(\"Invalid Instrument info string.\")\n</code></pre>"},{"location":"code_docs/func_modules/reference/paper/","title":"Paper","text":""},{"location":"code_docs/func_modules/reference/paper/#labridge.func_modules.reference.paper","title":"<code>labridge.func_modules.reference.paper</code>","text":""},{"location":"code_docs/func_modules/reference/paper/#labridge.func_modules.reference.paper.PaperInfo","title":"<code>labridge.func_modules.reference.paper.PaperInfo</code>","text":"<p>               Bases: <code>RefInfoBase</code></p> <p>This class contains the information of a paper, including:</p> PARAMETER DESCRIPTION <code>title</code> <p>The title of the paper.</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>The file path of the paper.</p> <p> TYPE: <code>str</code> </p> <code>possessor</code> <p>The user that possesses the paper.</p> <p> TYPE: <code>str</code> </p> Source code in <code>labridge\\func_modules\\reference\\paper.py</code> <pre><code>class PaperInfo(RefInfoBase):\n\tr\"\"\"\n\tThis class contains the information of a paper, including:\n\n\tArgs:\n\t\ttitle (str): The title of the paper.\n\t\tfile_path (str): The file path of the paper.\n\t\tpossessor (str): The user that possesses the paper.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\ttitle: str,\n\t\tfile_path: str,\n\t\tpossessor: str,\n\t):\n\t\tself.title = title\n\t\tself.file_path = file_path\n\t\tself.possessor = possessor\n\n\tdef dumps(self) -&gt; str:\n\t\tr\"\"\" Dump to a string in JSON format. \"\"\"\n\t\tinfo_dict = {\n\t\t\tREF_TYPE: PaperInfo.__name__,\n\t\t\t\"title\": self.title,\n\t\t\t\"file_path\": self.file_path,\n\t\t\t\"possessor\": self.possessor,\n\t\t}\n\t\treturn json.dumps(info_dict)\n\n\t@classmethod\n\tdef loads(cls, info_str: str):\n\t\tr\"\"\" Load from a string in JSON format. \"\"\"\n\t\ttry:\n\t\t\tinfo_dict = json.loads(info_str)\n\t\t\ttitle = info_dict[\"title\"]\n\t\t\tfile_path = info_dict[\"file_path\"]\n\t\t\tpossessor = info_dict[\"possessor\"]\n\t\t\treturn cls(\n\t\t\t\ttitle=title,\n\t\t\t\tfile_path=file_path,\n\t\t\t\tpossessor=possessor,\n\t\t\t)\n\t\texcept Exception:\n\t\t\traise ValueError(\"Invalid paper info string.\")\n</code></pre>"},{"location":"code_docs/func_modules/reference/paper/#labridge.func_modules.reference.paper.PaperInfo.dumps","title":"<code>labridge.func_modules.reference.paper.PaperInfo.dumps()</code>","text":"<p>Dump to a string in JSON format.</p> Source code in <code>labridge\\func_modules\\reference\\paper.py</code> <pre><code>def dumps(self) -&gt; str:\n\tr\"\"\" Dump to a string in JSON format. \"\"\"\n\tinfo_dict = {\n\t\tREF_TYPE: PaperInfo.__name__,\n\t\t\"title\": self.title,\n\t\t\"file_path\": self.file_path,\n\t\t\"possessor\": self.possessor,\n\t}\n\treturn json.dumps(info_dict)\n</code></pre>"},{"location":"code_docs/func_modules/reference/paper/#labridge.func_modules.reference.paper.PaperInfo.loads","title":"<code>labridge.func_modules.reference.paper.PaperInfo.loads(info_str)</code>  <code>classmethod</code>","text":"<p>Load from a string in JSON format.</p> Source code in <code>labridge\\func_modules\\reference\\paper.py</code> <pre><code>@classmethod\ndef loads(cls, info_str: str):\n\tr\"\"\" Load from a string in JSON format. \"\"\"\n\ttry:\n\t\tinfo_dict = json.loads(info_str)\n\t\ttitle = info_dict[\"title\"]\n\t\tfile_path = info_dict[\"file_path\"]\n\t\tpossessor = info_dict[\"possessor\"]\n\t\treturn cls(\n\t\t\ttitle=title,\n\t\t\tfile_path=file_path,\n\t\t\tpossessor=possessor,\n\t\t)\n\texcept Exception:\n\t\traise ValueError(\"Invalid paper info string.\")\n</code></pre>"},{"location":"code_docs/interact/authorize/authorize/","title":"Authorize","text":""},{"location":"code_docs/interact/authorize/authorize/#labridge.interact.authorize.authorize","title":"<code>labridge.interact.authorize.authorize</code>","text":""},{"location":"code_docs/interact/authorize/authorize/#labridge.interact.authorize.authorize.aoperation_authorize","title":"<code>labridge.interact.authorize.authorize.aoperation_authorize(user_id, op_name, kwargs_str, authorize_strict_mode=False, llm=None, embed_model=None, verbose=False)</code>  <code>async</code>","text":"<p>This function is used to query the user whether to execute a specific operation.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user that will make decisions.</p> <p> TYPE: <code>str</code> </p> <code>op_name</code> <p>The operation to be executed.</p> <p> TYPE: <code>str</code> </p> <code>kwargs_str</code> <p>The keyword arguments of the operation function, which is dumped as a json string.</p> <p> TYPE: <code>str</code> </p> <code>authorize_strict_mode</code> <p>If it is set to True, the operation will be executed only when the user response the <code>STRICT_AGREE_WORDS</code>. Defaults to False.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>llm</code> <p>The used LLM. Defaults to None. If set to None, the Settings.llm will be used.</p> <p> TYPE: <code>LLM</code> DEFAULT: <code>None</code> </p> <code>embed_model</code> <p>The used embedding model. Defaults to None. If set to None, the Settings.embed_model will be used.</p> <p> TYPE: <code>BaseEmbedding</code> DEFAULT: <code>None</code> </p> <code>verbose</code> <p>Whether to show the progress.</p> <p> TYPE: <code>str</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>callback_log</code> <p>the log string.</p> <p> TYPE: <code>str</code> </p> Source code in <code>labridge\\interact\\authorize\\authorize.py</code> <pre><code>async def aoperation_authorize(\n\tuser_id: str,\n\top_name: str,\n\tkwargs_str: str,\n\tauthorize_strict_mode: bool = False,\n\tllm: LLM = None,\n\tembed_model: BaseEmbedding = None,\n\tverbose: bool = False,\n) -&gt; OperationOutputLog:\n\tr\"\"\"\n\tThis function is used to query the user whether to execute a specific operation.\n\n\tArgs:\n\t\tuser_id (str): The user that will make decisions.\n\t\top_name (str): The operation to be executed.\n\t\tkwargs_str (str): The keyword arguments of the operation function, which is dumped as a json string.\n\t\tauthorize_strict_mode (bool): If it is set to True, the operation will be executed only when the user response\n\t\t\tthe `STRICT_AGREE_WORDS`. Defaults to False.\n\t\tllm (LLM): The used LLM. Defaults to None. If set to None, the Settings.llm will be used.\n\t\tembed_model (BaseEmbedding): The used embedding model. Defaults to None.\n\t\t\tIf set to None, the Settings.embed_model will be used.\n\t\tverbose (str): Whether to show the progress.\n\n\tReturns:\n\t\tcallback_log (str): the log string.\n\n\t\"\"\"\n\tif op_name not in CALL_BACK_OPS:\n\t\traise ValueError(f\"{op_name} is not a valid callback operation name.\")\n\n\toperation_class = getattr(callback, op_name)\n\tif not issubclass(operation_class, CallBackOperationBase):\n\t\traise ValueError(f\"{op_name} should be a subclass of 'CallBackOperationBase'.\")\n\n\tllm = llm or Settings.llm\n\tembed_model = embed_model or Settings.embed_model\n\n\toperation = operation_class(\n\t\tllm=llm,\n\t\tembed_model=embed_model,\n\t\tverbose=verbose,\n\t\top_name=op_name,\n\t)\n\tkwargs = json.loads(kwargs_str)\n\top_description = operation.operation_description(**kwargs)\n\tif authorize_strict_mode:\n\t\tquery_str = STRICT_AUTHORIZE_QUERY_TMPL.format(\n\t\t\tstrict_agree_str=\",\".join(STRICT_AGREE_WORDS),\n\t\t\toperation_description=op_description,\n\t\t)\n\telse:\n\t\tquery_str = AUTHORIZE_QUERY_TMPL.format(operation_description=op_description)\n\n\t# TODO: send the operation description to the user.\n\tChatBuffer.put_agent_reply(\n\t\tuser_id=user_id,\n\t\treply_str=query_str,\n\t\tinner_chat=True,\n\t)\n\n\t# TODO: wait for the user response.\n\tuser_msg: PackedUserMessage = await ChatBuffer.get_user_msg(user_id=user_id)\n\tif user_msg is None:\n\t\traise ValueError(\"Invalid user msg.\")\n\n\tuser_response = user_msg.user_msg\n\n\tagree = False\n\tif authorize_strict_mode:\n\t\tif user_response.encode(\"utf-8\").isalpha():\n\t\t\tuser_response = user_response.lower()\n\t\tagree = user_response in STRICT_AGREE_WORDS\n\telse:\n\t\tjudgement = await llm.apredict(\n\t\t\tprompt=AUTHORIZATION_ANALYZE_PROMPT,\n\t\t\tagree_word=ANALYZE_AGREE_WORD,\n\t\t\tdisagree_word=ANALYZE_DISAGREE_WORD,\n\t\t\tuser_response=user_response,\n\t\t)\n\t\tagree = analyze_agree(llm_response=judgement)\n\n\tif agree:\n\t\t# TODO: I need an operation buffer to store operations. two operation class: 1. real time, 2. buffer.\n\t\tcallback_log = operation.do_operation(**kwargs)\n\t\treturn callback_log\n\telse:\n\t\tcallback_log_str = (f\"The assistant tries to obtain the authorization from user {user_id} to perform an operation.\"\n\t\t\t\t\t\tf\"The user disagreed, so this operation does not be performed.\\n\"\n\t\t\t\t\t\tf\"The operation is described as follows:\\n{op_description}\\n\\n\"\n\t\t\t\t\t\tf\"The user's response is as follows:\\n{user_response}\")\n\t\treturn OperationOutputLog(\n\t\t\toperation_name=op_name,\n\t\t\toperation_output=callback_log_str,\n\t\t\tlog_to_user=None,\n\t\t\tlog_to_system={\n\t\t\t\tOP_DESCRIPTION: callback_log_str,\n\t\t\t\tOP_REFERENCES: None,\n\t\t\t},\n\t\t\toperation_abort=True,\n\t\t)\n</code></pre>"},{"location":"code_docs/interact/authorize/authorize/#labridge.interact.authorize.authorize.operation_authorize","title":"<code>labridge.interact.authorize.authorize.operation_authorize(user_id, op_name, kwargs_str, authorize_strict_mode=False, llm=None, embed_model=None, verbose=False)</code>","text":"<p>This function is used to query the user whether to execute a specific operation.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user that will make decisions.</p> <p> TYPE: <code>str</code> </p> <code>op_name</code> <p>The operation to be executed.</p> <p> TYPE: <code>str</code> </p> <code>kwargs_str</code> <p>The keyword arguments of the operation function, which is dumped as a json string.</p> <p> TYPE: <code>str</code> </p> <code>authorize_strict_mode</code> <p>If it is set to True, the operation will be executed only when the user response the <code>STRICT_AGREE_WORDS</code>. Defaults to False.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>llm</code> <p>The used LLM. Defaults to None. If set to None, the Settings.llm will be used.</p> <p> TYPE: <code>LLM</code> DEFAULT: <code>None</code> </p> <code>embed_model</code> <p>The used embedding model. Defaults to None. If set to None, the Settings.embed_model will be used.</p> <p> TYPE: <code>BaseEmbedding</code> DEFAULT: <code>None</code> </p> <code>verbose</code> <p>Whether to show the progress.</p> <p> TYPE: <code>str</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>callback_log</code> <p>the log string.</p> <p> TYPE: <code>str</code> </p> Source code in <code>labridge\\interact\\authorize\\authorize.py</code> <pre><code>def operation_authorize(\n\tuser_id: str,\n\top_name: str,\n\tkwargs_str: str,\n\tauthorize_strict_mode: bool = False,\n\tllm: LLM = None,\n\tembed_model: BaseEmbedding = None,\n\tverbose: bool = False,\n) -&gt; OperationOutputLog:\n\tr\"\"\"\n\tThis function is used to query the user whether to execute a specific operation.\n\n\tArgs:\n\t\tuser_id (str): The user that will make decisions.\n\t\top_name (str): The operation to be executed.\n\t\tkwargs_str (str): The keyword arguments of the operation function, which is dumped as a json string.\n\t\tauthorize_strict_mode (bool): If it is set to True, the operation will be executed only when the user response\n\t\t\tthe `STRICT_AGREE_WORDS`. Defaults to False.\n\t\tllm (LLM): The used LLM. Defaults to None. If set to None, the Settings.llm will be used.\n\t\tembed_model (BaseEmbedding): The used embedding model. Defaults to None.\n\t\t\tIf set to None, the Settings.embed_model will be used.\n\t\tverbose (str): Whether to show the progress.\n\n\tReturns:\n\t\tcallback_log (str): the log string.\n\n\t\"\"\"\n\tif op_name not in CALL_BACK_OPS:\n\t\traise ValueError(f\"{op_name} is not a valid callback operation name.\")\n\n\toperation_class = getattr(callback, op_name)\n\tif not issubclass(operation_class, CallBackOperationBase):\n\t\traise ValueError(f\"{op_name} should be a subclass of 'CallBackOperationBase'.\")\n\n\tllm = llm or Settings.llm\n\tembed_model = embed_model or Settings.embed_model\n\n\toperation = operation_class(\n\t\tllm=llm,\n\t\tembed_model=embed_model,\n\t\tverbose=verbose,\n\t\top_name=op_name,\n\t)\n\n\tkwargs = json.loads(kwargs_str)\n\top_description = operation.operation_description(**kwargs)\n\tif authorize_strict_mode:\n\t\tquery_str = STRICT_AUTHORIZE_QUERY_TMPL.format(\n\t\t\tstrict_agree_str=\",\".join(STRICT_AGREE_WORDS),\n\t\t\toperation_description=op_description,\n\t\t)\n\telse:\n\t\tquery_str = AUTHORIZE_QUERY_TMPL.format(operation_description=op_description)\n\n\t# TODO: send the operation description to the user.\n\tprint(query_str)\n\n\t# TODO: wait for the user response.\n\tuser_msg: PackedUserMessage = ChatBuffer.test_get_user_text(user_id=user_id)\n\tuser_response = user_msg.user_msg\n\n\tagree = False\n\tprint(\"Here 1 ....\")\n\tif authorize_strict_mode:\n\t\tif user_response.encode(\"utf-8\").isalpha():\n\t\t\tuser_response = user_response.lower()\n\t\tagree = user_response in STRICT_AGREE_WORDS\n\telse:\n\t\tjudgement = llm.predict(\n\t\t\tprompt=AUTHORIZATION_ANALYZE_PROMPT,\n\t\t\tagree_word=ANALYZE_AGREE_WORD,\n\t\t\tdisagree_word=ANALYZE_DISAGREE_WORD,\n\t\t\tuser_response=user_response,\n\t\t)\n\t\tagree = analyze_agree(llm_response=judgement)\n\t\tprint(\"Here 2 ....\")\n\n\tif agree:\n\t\t# TODO: I need an operation buffer to store operations.\n\t\tcallback_log = operation.do_operation(**kwargs)\n\t\tprint(\"Here\", callback_log.dumps())\n\t\treturn callback_log\n\telse:\n\t\tcallback_log_str = (\n\t\t\tf\"The assistant tries to obtain the authorization from user {user_id} to perform an operation.\"\n\t\t\tf\"The user disagreed, so this operation does not be performed.\\n\"\n\t\t\tf\"The operation is described as follows:\\n{op_description}\\n\\n\"\n\t\t\tf\"The user's response is as follows:\\n{user_response}\"\n\t\t)\n\t\treturn OperationOutputLog(\n\t\t\toperation_name=op_name,\n\t\t\toperation_output=callback_log_str,\n\t\t\tlog_to_user=None,\n\t\t\tlog_to_system={\n\t\t\t\tOP_DESCRIPTION: callback_log_str,\n\t\t\t\tOP_REFERENCES: None,\n\t\t\t},\n\t\t\toperation_abort=True,\n\t\t)\n</code></pre>"},{"location":"code_docs/interact/collect/pipeline/","title":"Pipeline","text":""},{"location":"code_docs/interact/collect/pipeline/#labridge.interact.collect.pipeline","title":"<code>labridge.interact.collect.pipeline</code>","text":""},{"location":"code_docs/interact/collect/pipeline/#labridge.interact.collect.pipeline.acollect_info_from_user","title":"<code>labridge.interact.collect.pipeline.acollect_info_from_user(user_id, required_infos, query_str, llm=None)</code>  <code>async</code>","text":"<p>This is an asynchronous pipeline to collect information from the user.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user id of a Lab member.</p> <p> TYPE: <code>str</code> </p> <code>required_infos</code> <p>The required information.</p> <p> TYPE: <code>List[CollectingInfoBase]</code> </p> <code>query_str</code> <p>The query string to be sent to the user.</p> <p> TYPE: <code>str</code> </p> <code>llm</code> <p>The used LLM.</p> <p> TYPE: <code>LLM</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <p>Optional[Dict[str, str]]: The collected information.</p> <ul> <li>key: The information name.</li> <li>value: The collected information.</li> </ul> <p>If the user aborts the collecting, return None.</p> Source code in <code>labridge\\interact\\collect\\pipeline.py</code> <pre><code>async def acollect_info_from_user(\n\tuser_id: str,\n\trequired_infos: List[CollectingInfoBase],\n\tquery_str: str,\n\tllm: LLM = None,\n):\n\tr\"\"\"\n\tThis is an asynchronous pipeline to collect information from the user.\n\n\tArgs:\n\t\tuser_id (str): The user id of a Lab member.\n\t\trequired_infos (List[CollectingInfoBase]): The required information.\n\t\tquery_str (str): The query string to be sent to the user.\n\t\tllm (LLM): The used LLM.\n\n\tReturns:\n\t\tOptional[Dict[str, str]]:\n\t\t\tThe collected information.\n\n\t\t\t- key: The information name.\n\t\t\t- value: The collected information.\n\n\t\t\tIf the user aborts the collecting, return None.\n\t\"\"\"\n\t# TODO: Send query_str to User\n\tprint(f\"Assistant: {query_str}\")\n\tllm = llm or Settings.llm\n\n\tcommon_info_collector = CommonInfoCollector(\n\t\tllm=llm,\n\t\trequired_infos=required_infos,\n\t)\n\tselect_info_collector = SelectInfoCollector(\n\t\tllm=llm,\n\t\trequired_infos=required_infos,\n\t)\n\n\tabort = False\n\theader_sent = False\n\n\twhile not abort and not select_info_collector.collected:\n\t\tquery = query_str if not header_sent else None\n\t\tabort = await select_info_collector.acollect(user_id=user_id, query_str=query)\n\t\theader_sent = True\n\tselect_modify = True\n\twhile not abort and select_modify:\n\t\tselect_modify, abort = await select_info_collector.amodify(user_id=user_id)\n\n\twhile not abort and not common_info_collector.collected:\n\t\tquery = query_str if not header_sent else None\n\t\tabort = await common_info_collector.acollect(user_id=user_id, query_str=query)\n\t\theader_sent = True\n\tcommon_modify = True\n\twhile not abort and common_modify:\n\t\tcommon_modify, abort = await common_info_collector.amodify(user_id=user_id)\n\n\tif abort:\n\t\treturn None\n\n\toutput_dict = {}\n\tcommon_info_dict = common_info_collector.collected_infos\n\tselect_info_dict = select_info_collector.collected_infos\n\tif common_info_dict is not None:\n\t\toutput_dict.update(common_info_dict)\n\tif select_info_dict is not None:\n\t\toutput_dict.update(select_info_dict)\n\treturn output_dict\n</code></pre>"},{"location":"code_docs/interact/collect/pipeline/#labridge.interact.collect.pipeline.collect_info_from_user","title":"<code>labridge.interact.collect.pipeline.collect_info_from_user(user_id, required_infos, query_str, llm=None)</code>","text":"<p>This is a pipeline to collect information from the user.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user id of a Lab member.</p> <p> TYPE: <code>str</code> </p> <code>required_infos</code> <p>The required information.</p> <p> TYPE: <code>List[CollectingInfoBase]</code> </p> <code>query_str</code> <p>The query string to be sent to the user.</p> <p> TYPE: <code>str</code> </p> <code>llm</code> <p>The used LLM.</p> <p> TYPE: <code>LLM</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Optional[Dict[str, str]]</code> <p>Optional[Dict[str, str]]: The collected information.</p> <ul> <li>key: The information name.</li> <li>value: The collected information.</li> </ul> <p>If the user aborts the collecting, return None.</p> Source code in <code>labridge\\interact\\collect\\pipeline.py</code> <pre><code>def collect_info_from_user(\n\tuser_id: str,\n\trequired_infos: List[CollectingInfoBase],\n\tquery_str: str,\n\tllm: LLM = None,\n) -&gt; Optional[Dict[str, str]]:\n\tr\"\"\"\n\tThis is a pipeline to collect information from the user.\n\n\tArgs:\n\t\tuser_id (str): The user id of a Lab member.\n\t\trequired_infos (List[CollectingInfoBase]): The required information.\n\t\tquery_str (str): The query string to be sent to the user.\n\t\tllm (LLM): The used LLM.\n\n\tReturns:\n\t\tOptional[Dict[str, str]]:\n\t\t\tThe collected information.\n\n\t\t\t- key: The information name.\n\t\t\t- value: The collected information.\n\n\t\t\tIf the user aborts the collecting, return None.\n\t\"\"\"\n\t# # TODO: Send query_str to User\n\tprint(f\"Assistant: {query_str}\")\n\tllm = llm or Settings.llm\n\n\t# for info in required_infos:\n\t# \tprint(info.info_name)\n\n\tcommon_info_collector = CommonInfoCollector(\n\t\tllm=llm,\n\t\trequired_infos=required_infos,\n\t)\n\tselect_info_collector = SelectInfoCollector(\n\t\tllm=llm,\n\t\trequired_infos=required_infos,\n\t)\n\n\tabort = False\n\theader_sent = False\n\n\twhile not abort and not select_info_collector.collected:\n\t\tquery = query_str if not header_sent else None\n\t\tabort = select_info_collector.collect(user_id=user_id, query_str=query)\n\t\theader_sent = True\n\tselect_modify = True\n\twhile not abort and select_modify:\n\t\tselect_modify, abort = select_info_collector.modify(user_id=user_id)\n\n\twhile not abort and not common_info_collector.collected:\n\t\tquery = query_str if not header_sent else None\n\t\tabort = common_info_collector.collect(user_id=user_id, query_str=query)\n\t\theader_sent = True\n\tcommon_modify = True\n\twhile not abort and common_modify:\n\t\tcommon_modify, abort = common_info_collector.modify(user_id=user_id)\n\n\tif abort:\n\t\treturn None\n\n\toutput_dict = {}\n\tcommon_info_dict = common_info_collector.collected_infos\n\tselect_info_dict = select_info_collector.collected_infos\n\tif common_info_dict is not None:\n\t\toutput_dict.update(common_info_dict)\n\tif select_info_dict is not None:\n\t\toutput_dict.update(select_info_dict)\n\treturn output_dict\n</code></pre>"},{"location":"code_docs/interact/collect/utils/","title":"Utils","text":""},{"location":"code_docs/interact/collect/utils/#labridge.interact.collect.utils","title":"<code>labridge.interact.collect.utils</code>","text":""},{"location":"code_docs/interact/collect/utils/#labridge.interact.collect.utils.acondition_analyze","title":"<code>labridge.interact.collect.utils.acondition_analyze(llm, prompt, condition_true_word, **kwargs)</code>  <code>async</code>","text":"<p>Asynchronously choose from two conditions according to the input.</p> PARAMETER DESCRIPTION <code>llm</code> <p>The used LLM.</p> <p> TYPE: <code>LLM</code> </p> <code>prompt</code> <p>The prompt template.</p> <p> TYPE: <code>PromptTemplate</code> </p> <code>condition_true_word</code> <p>The word that the LLM is supposed to output in the True condition.</p> <p> TYPE: <code>str</code> </p> <code>**kwargs</code> <p> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True condition or False.</p> <p> TYPE: <code>bool</code> </p> Source code in <code>labridge\\interact\\collect\\utils.py</code> <pre><code>async def acondition_analyze(\n\tllm: LLM,\n\tprompt: PromptTemplate,\n\tcondition_true_word: str,\n\t**kwargs,\n) -&gt; bool:\n\tr\"\"\"\n\tAsynchronously choose from two conditions according to the input.\n\n\tArgs:\n\t\tllm (LLM): The used LLM.\n\t\tprompt (PromptTemplate): The prompt template.\n\t\tcondition_true_word (str): The word that the LLM is supposed to output in the True condition.\n\t\t**kwargs:\n\n\tReturns:\n\t\tbool: True condition or False.\n\t\"\"\"\n\tllm_response = await llm.apredict(\n\t\tprompt=prompt,\n\t\t**kwargs,\n\t)\n\n\tllm_str = filter(lambda x: x.isalpha(), [char for char in llm_response])\n\tllm_str = \"\".join(llm_str)\n\treturn llm_str == condition_true_word\n</code></pre>"},{"location":"code_docs/interact/collect/utils/#labridge.interact.collect.utils.condition_analyze","title":"<code>labridge.interact.collect.utils.condition_analyze(llm, prompt, condition_true_word, **kwargs)</code>","text":"<p>Choose from two conditions according to the input.</p> PARAMETER DESCRIPTION <code>llm</code> <p>The used LLM.</p> <p> TYPE: <code>LLM</code> </p> <code>prompt</code> <p>The prompt template.</p> <p> TYPE: <code>PromptTemplate</code> </p> <code>condition_true_word</code> <p>The word that the LLM is supposed to output in the True condition.</p> <p> TYPE: <code>str</code> </p> <code>**kwargs</code> <p> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True condition or False.</p> <p> TYPE: <code>bool</code> </p> Source code in <code>labridge\\interact\\collect\\utils.py</code> <pre><code>def condition_analyze(\n\tllm: LLM,\n\tprompt: PromptTemplate,\n\tcondition_true_word: str,\n\t**kwargs,\n) -&gt; bool:\n\tr\"\"\"\n\tChoose from two conditions according to the input.\n\n\tArgs:\n\t\tllm (LLM): The used LLM.\n\t\tprompt (PromptTemplate): The prompt template.\n\t\tcondition_true_word (str): The word that the LLM is supposed to output in the True condition.\n\t\t**kwargs:\n\n\tReturns:\n\t\tbool: True condition or False.\n\t\"\"\"\n\tllm_response = llm.predict(\n\t\tprompt=prompt,\n\t\t**kwargs,\n\t)\n\n\tllm_str = filter(lambda x: x.isalpha(), [char for char in llm_response])\n\tllm_str = \"\".join(llm_str)\n\treturn llm_str.lower() == condition_true_word.lower()\n</code></pre>"},{"location":"code_docs/interact/collect/collector/common_collector/","title":"Common collector","text":""},{"location":"code_docs/interact/collect/collector/common_collector/#labridge.interact.collect.collector.common_collector","title":"<code>labridge.interact.collect.collector.common_collector</code>","text":""},{"location":"code_docs/interact/collect/collector/common_collector/#labridge.interact.collect.collector.common_collector.CommonInfoCollector","title":"<code>labridge.interact.collect.collector.common_collector.CommonInfoCollector</code>","text":"<p>Collect CommonInfo from the user. refer to <code>..types.common_info.CollectingCommonInfo</code> for the detail of CommonInfo.</p> PARAMETER DESCRIPTION <code>llm</code> <p>The used LLM.</p> <p> TYPE: <code>LLM</code> </p> <code>required_infos</code> <p>The required infos.</p> <p> TYPE: <code>List[CollectingInfoBase]</code> </p> Source code in <code>labridge\\interact\\collect\\collector\\common_collector.py</code> <pre><code>class CommonInfoCollector:\n\tr\"\"\"\n\tCollect CommonInfo from the user.\n\trefer to `..types.common_info.CollectingCommonInfo` for the detail of CommonInfo.\n\n\tArgs:\n\t\tllm (LLM): The used LLM.\n\t\trequired_infos (List[CollectingInfoBase]): The required infos.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tllm: LLM,\n\t\trequired_infos: List[CollectingInfoBase],\n\t):\n\t\tself._llm = llm\n\t\tself._common_infos = self.get_common_infos(required_infos=required_infos)\n\t\tself._collect_manager = CollectManager(llm=llm)\n\n\tdef get_common_infos(\n\t\tself,\n\t\trequired_infos: List[CollectingInfoBase],\n\t) -&gt; CollectingCommonInfo:\n\t\tr\"\"\"\n\t\tChoose the CollectingCommonInfo from the required_infos.\n\n\t\tArgs:\n\t\t\trequired_infos (List[CollectingInfoBase]): The required infos.\n\n\t\tReturns:\n\t\t\tCollectingCommonInfo: All required CollectingCommonInfo are aggregated in a  CollectingCommonInfo.\n\t\t\t\tIf no CollectingCommonInfo required, return None.\n\t\t\"\"\"\n\t\tcommon_info = None\n\t\tfor info in required_infos:\n\t\t\tif isinstance(info, CollectingCommonInfo):\n\t\t\t\tif common_info is None:\n\t\t\t\t\tcommon_info = copy.deepcopy(info)\n\t\t\t\telse:\n\t\t\t\t\tcommon_info.insert_info(info)\n\t\treturn common_info\n\n\t@property\n\tdef collecting_keys(self) -&gt; Optional[List[str]]:\n\t\tr\"\"\" The information to be collected currently. \"\"\"\n\t\tif self._common_infos is None:\n\t\t\treturn None\n\n\t\treturn self._common_infos.collecting_keys\n\n\t@property\n\tdef collected_infos(self) -&gt; Optional[Dict[str, str]]:\n\t\tr\"\"\" The Collected Common information. \"\"\"\n\t\tif self._common_infos is None:\n\t\t\treturn None\n\n\t\treturn self._common_infos.collected_infos\n\n\t@property\n\tdef collected(self):\n\t\tr\"\"\" Whether all Common information are collected or not. \"\"\"\n\t\tif self._common_infos is None:\n\t\t\treturn True\n\n\t\treturn self._common_infos.collected\n\n\t@property\n\tdef collecting_query(self) -&gt; str:\n\t\tr\"\"\" This query will be sent to user to collect rest Common information. \"\"\"\n\t\tquery_to_user = f\"{COLLECT_COMMON_INFO_QUERY}\\n\"\n\t\tfor key in self.collecting_keys:\n\t\t\tquery_to_user += f\"\\t{key}\\n\"\n\t\treturn query_to_user\n\n\tdef collect(\n\t\tself,\n\t\tuser_id: str,\n\t\tquery_str: Optional[str] = None,\n\t) -&gt; bool:\n\t\tr\"\"\"\n\t\tCollect the Common information.\n\n\t\tReturns:\n\t\t\tbool: Whether the user aborts the collecting process.\n\t\t\"\"\"\n\t\tif self._common_infos is None:\n\t\t\treturn False\n\n\t\tquery_to_user = self.collecting_query\n\t\tif query_str:\n\t\t\tquery_to_user = \"\\n\".join([query_str, query_to_user])\n\n\t\t# TODO: send the message to the user.\n\t\tprint(query_to_user)\n\n\t\t# TODO: receive the message from the user.\n\t\tuser_msg = ChatBuffer.test_get_user_text(user_id=user_id)\n\t\tuser_response = user_msg.user_msg\n\t\tabort = self._collect_manager.analyze_whether_abort(user_response=user_response)\n\t\tif abort:\n\t\t\treturn abort\n\n\t\tfor batch_info_dict in self._common_infos.info_content():\n\t\t\tpredict_kwargs = {\n\t\t\t\t\"prompt\": COLLECT_COMMON_INFO_PROMPT,\n\t\t\t\tCollectPromptKeys.user_response_key: user_response,\n\t\t\t}\n\t\t\tpredict_kwargs.update(batch_info_dict)\n\t\t\textract_info = self._llm.predict(**predict_kwargs)\n\t\t\tnew_info_dict = parse_common_collected_info(\n\t\t\t\textract_info=extract_info,\n\t\t\t\tinfo_keys=self._common_infos.collecting_keys,\n\t\t\t)\n\t\t\tself._common_infos.update_collected_info(collected_info_dict=new_info_dict)\n\t\treturn abort\n\n\tasync def acollect(\n\t\tself,\n\t\tuser_id: str,\n\t\tquery_str: Optional[str] = None,\n\t) -&gt; bool:\n\t\tr\"\"\"\n\t\tAsynchronously collect the Common information.\n\n\t\tReturns:\n\t\t\tbool: Whether the user aborts the collecting process.\n\t\t\"\"\"\n\t\tif self._common_infos is None:\n\t\t\treturn False\n\n\t\tquery_to_user = self.collecting_query\n\t\tif query_str:\n\t\t\tquery_to_user = \"\\n\".join([query_str, query_to_user])\n\n\t\t# TODO: send the message to the user.\n\t\tChatBuffer.put_agent_reply(\n\t\t\tuser_id=user_id,\n\t\t\treply_str=query_to_user,\n\t\t\tinner_chat=True,\n\t\t)\n\n\t\t# TODO: receive the message from the user.\n\t\tuser_msg = await ChatBuffer.get_user_msg(user_id=user_id)\n\n\n\n\n\t\tuser_response = user_msg.user_msg\n\n\t\tabort = await self._collect_manager.async_analyze_whether_abort(user_response=user_response)\n\t\tif abort:\n\t\t\treturn abort\n\n\t\tfor batch_info_dict in self._common_infos.info_content():\n\t\t\tpredict_kwargs = {\n\t\t\t\t\"prompt\": COLLECT_COMMON_INFO_PROMPT,\n\t\t\t\tCollectPromptKeys.user_response_key: user_response,\n\t\t\t}\n\t\t\tpredict_kwargs.update(batch_info_dict)\n\t\t\textract_info = await self._llm.apredict(**predict_kwargs)\n\t\t\tnew_info_dict = parse_common_collected_info(\n\t\t\t\textract_info=extract_info,\n\t\t\t\tinfo_keys=self._common_infos.collecting_keys,\n\t\t\t)\n\t\t\tself._common_infos.update_collected_info(collected_info_dict=new_info_dict)\n\t\treturn abort\n\n\tdef modify(self, user_id: str) -&gt; Tuple[bool, bool]:\n\t\tr\"\"\"\n\t\tModify the collected information according to the user's comment.\n\n\t\tReturns:\n\t\t\tTuple[str, str]:\n\t\t\t\t- doing_modify: Whether the user thinks the collected information need modification.\n\t\t\t\t- abort: Whether the user aborts the collection process.\n\t\t\"\"\"\n\t\tif self._common_infos is None:\n\t\t\treturn False, False\n\n\t\tdoing_modify = True\n\t\tabort = False\n\t\twhile doing_modify and not abort:\n\t\t\tquery_to_user =self._collect_manager.verify_query(collected_info_dict=self.collected_infos)\n\t\t\t# TODO: send the message to the user.\n\t\t\tprint(query_to_user)\n\t\t\t# TODO: receive the message from the user.\n\t\t\tuser_msg = ChatBuffer.test_get_user_text(user_id=user_id)\n\t\t\tuser_response = user_msg.user_msg\n\t\t\tabort = self._collect_manager.analyze_whether_abort(user_response=user_response)\n\t\t\tif abort:\n\t\t\t\tbreak\n\t\t\tdoing_modify = self._collect_manager.analyze_whether_modify(\n\t\t\t\tuser_response=user_response,\n\t\t\t\tcollected_info_dict=self.collected_infos\n\t\t\t)\n\t\t\tif doing_modify:\n\t\t\t\tself.single_modify(user_response=user_response)\n\t\treturn doing_modify, abort\n\n\tasync def amodify(self, user_id: str) -&gt; Tuple[bool, bool]:\n\t\tr\"\"\"\n\t\tAsynchronously modify the collected information according to the user's comment.\n\n\t\tReturns:\n\t\t\tTuple[str, str]:\n\t\t\t\t- doing_modify: Whether the user thinks the collected information need modification.\n\t\t\t\t- abort: Whether the user aborts the collection process.\n\t\t\"\"\"\n\t\tif self._common_infos is None:\n\t\t\treturn False, False\n\n\t\tdoing_modify = True\n\t\tabort = False\n\t\twhile doing_modify and not abort:\n\t\t\tquery_to_user = self._collect_manager.verify_query(collected_info_dict=self.collected_infos)\n\t\t\t# TODO: send the message to the user.\n\t\t\tChatBuffer.put_agent_reply(\n\t\t\t\tuser_id=user_id,\n\t\t\t\treply_str=query_to_user,\n\t\t\t\tinner_chat=True,\n\t\t\t)\n\t\t\t# TODO: receive the message from the user.\n\t\t\tuser_msg = await ChatBuffer.get_user_msg(user_id=user_id)\n\t\t\tuser_response = user_msg.user_msg\n\t\t\tabort = await self._collect_manager.async_analyze_whether_abort(user_response=user_response)\n\t\t\tif abort:\n\t\t\t\tbreak\n\t\t\tdoing_modify = await self._collect_manager.async_analyze_whether_modify(\n\t\t\t\tuser_response=user_response,\n\t\t\t\tcollected_info_dict=self.collected_infos\n\t\t\t)\n\t\t\tif doing_modify:\n\t\t\t\tawait self.asingle_modify(user_response=user_response)\n\t\treturn doing_modify, abort\n\n\n\tdef single_modify(self, user_response: str):\n\t\tr\"\"\"\n\t\tModify the collected information according to the user's comment.\n\n\t\tArgs:\n\t\t\tuser_response (str): The user's comment.\n\n\t\tReturns:\n\t\t\tNone\n\t\t\"\"\"\n\t\tfor batch_info_dict in self._common_infos.modify_info_content():\n\t\t\tpredict_kwargs = {\n\t\t\t\t\"prompt\": MODIFY_COMMON_INFO_PROMPT,\n\t\t\t\tModifyPromptKeys.user_comment_key: user_response,\n\t\t\t}\n\t\t\tpredict_kwargs.update(batch_info_dict)\n\t\t\textract_info = self._llm.predict(**predict_kwargs)\n\t\t\tnew_info_dict = parse_common_collected_info(\n\t\t\t\textract_info=extract_info,\n\t\t\t\tinfo_keys=list(self._common_infos.required_infos.keys()),\n\t\t\t)\n\t\t\tprint(\"modified: \", new_info_dict)\n\t\t\tself._common_infos.update_collected_info(collected_info_dict=new_info_dict)\n\n\tasync def asingle_modify(self, user_response: str):\n\t\tr\"\"\"\n\t\tAsynchronously modify the collected information according to the user's comment.\n\n\t\tArgs:\n\t\t\tuser_response (str): The user's comment.\n\n\t\tReturns:\n\t\t\tNone\n\t\t\"\"\"\n\t\tfor batch_info_dict in self._common_infos.modify_info_content():\n\t\t\tpredict_kwargs = {\n\t\t\t\t\"prompt\": MODIFY_COMMON_INFO_PROMPT,\n\t\t\t\tModifyPromptKeys.user_comment_key: user_response,\n\t\t\t}\n\t\t\tpredict_kwargs.update(batch_info_dict)\n\t\t\textract_info = await self._llm.apredict(**predict_kwargs)\n\t\t\tnew_info_dict = parse_common_collected_info(\n\t\t\t\textract_info=extract_info,\n\t\t\t\tinfo_keys=list(self._common_infos.required_infos.keys()),\n\t\t\t)\n\t\t\tprint(\"modified: \", new_info_dict)\n\t\t\tself._common_infos.update_collected_info(collected_info_dict=new_info_dict)\n</code></pre>"},{"location":"code_docs/interact/collect/collector/common_collector/#labridge.interact.collect.collector.common_collector.CommonInfoCollector.collected","title":"<code>labridge.interact.collect.collector.common_collector.CommonInfoCollector.collected</code>  <code>property</code>","text":"<p>Whether all Common information are collected or not.</p>"},{"location":"code_docs/interact/collect/collector/common_collector/#labridge.interact.collect.collector.common_collector.CommonInfoCollector.collected_infos","title":"<code>labridge.interact.collect.collector.common_collector.CommonInfoCollector.collected_infos: Optional[Dict[str, str]]</code>  <code>property</code>","text":"<p>The Collected Common information.</p>"},{"location":"code_docs/interact/collect/collector/common_collector/#labridge.interact.collect.collector.common_collector.CommonInfoCollector.collecting_keys","title":"<code>labridge.interact.collect.collector.common_collector.CommonInfoCollector.collecting_keys: Optional[List[str]]</code>  <code>property</code>","text":"<p>The information to be collected currently.</p>"},{"location":"code_docs/interact/collect/collector/common_collector/#labridge.interact.collect.collector.common_collector.CommonInfoCollector.collecting_query","title":"<code>labridge.interact.collect.collector.common_collector.CommonInfoCollector.collecting_query: str</code>  <code>property</code>","text":"<p>This query will be sent to user to collect rest Common information.</p>"},{"location":"code_docs/interact/collect/collector/common_collector/#labridge.interact.collect.collector.common_collector.CommonInfoCollector.acollect","title":"<code>labridge.interact.collect.collector.common_collector.CommonInfoCollector.acollect(user_id, query_str=None)</code>  <code>async</code>","text":"<p>Asynchronously collect the Common information.</p> RETURNS DESCRIPTION <code>bool</code> <p>Whether the user aborts the collecting process.</p> <p> TYPE: <code>bool</code> </p> Source code in <code>labridge\\interact\\collect\\collector\\common_collector.py</code> <pre><code>async def acollect(\n\tself,\n\tuser_id: str,\n\tquery_str: Optional[str] = None,\n) -&gt; bool:\n\tr\"\"\"\n\tAsynchronously collect the Common information.\n\n\tReturns:\n\t\tbool: Whether the user aborts the collecting process.\n\t\"\"\"\n\tif self._common_infos is None:\n\t\treturn False\n\n\tquery_to_user = self.collecting_query\n\tif query_str:\n\t\tquery_to_user = \"\\n\".join([query_str, query_to_user])\n\n\t# TODO: send the message to the user.\n\tChatBuffer.put_agent_reply(\n\t\tuser_id=user_id,\n\t\treply_str=query_to_user,\n\t\tinner_chat=True,\n\t)\n\n\t# TODO: receive the message from the user.\n\tuser_msg = await ChatBuffer.get_user_msg(user_id=user_id)\n\n\n\n\n\tuser_response = user_msg.user_msg\n\n\tabort = await self._collect_manager.async_analyze_whether_abort(user_response=user_response)\n\tif abort:\n\t\treturn abort\n\n\tfor batch_info_dict in self._common_infos.info_content():\n\t\tpredict_kwargs = {\n\t\t\t\"prompt\": COLLECT_COMMON_INFO_PROMPT,\n\t\t\tCollectPromptKeys.user_response_key: user_response,\n\t\t}\n\t\tpredict_kwargs.update(batch_info_dict)\n\t\textract_info = await self._llm.apredict(**predict_kwargs)\n\t\tnew_info_dict = parse_common_collected_info(\n\t\t\textract_info=extract_info,\n\t\t\tinfo_keys=self._common_infos.collecting_keys,\n\t\t)\n\t\tself._common_infos.update_collected_info(collected_info_dict=new_info_dict)\n\treturn abort\n</code></pre>"},{"location":"code_docs/interact/collect/collector/common_collector/#labridge.interact.collect.collector.common_collector.CommonInfoCollector.amodify","title":"<code>labridge.interact.collect.collector.common_collector.CommonInfoCollector.amodify(user_id)</code>  <code>async</code>","text":"<p>Asynchronously modify the collected information according to the user's comment.</p> RETURNS DESCRIPTION <code>Tuple[bool, bool]</code> <p>Tuple[str, str]: - doing_modify: Whether the user thinks the collected information need modification. - abort: Whether the user aborts the collection process.</p> Source code in <code>labridge\\interact\\collect\\collector\\common_collector.py</code> <pre><code>async def amodify(self, user_id: str) -&gt; Tuple[bool, bool]:\n\tr\"\"\"\n\tAsynchronously modify the collected information according to the user's comment.\n\n\tReturns:\n\t\tTuple[str, str]:\n\t\t\t- doing_modify: Whether the user thinks the collected information need modification.\n\t\t\t- abort: Whether the user aborts the collection process.\n\t\"\"\"\n\tif self._common_infos is None:\n\t\treturn False, False\n\n\tdoing_modify = True\n\tabort = False\n\twhile doing_modify and not abort:\n\t\tquery_to_user = self._collect_manager.verify_query(collected_info_dict=self.collected_infos)\n\t\t# TODO: send the message to the user.\n\t\tChatBuffer.put_agent_reply(\n\t\t\tuser_id=user_id,\n\t\t\treply_str=query_to_user,\n\t\t\tinner_chat=True,\n\t\t)\n\t\t# TODO: receive the message from the user.\n\t\tuser_msg = await ChatBuffer.get_user_msg(user_id=user_id)\n\t\tuser_response = user_msg.user_msg\n\t\tabort = await self._collect_manager.async_analyze_whether_abort(user_response=user_response)\n\t\tif abort:\n\t\t\tbreak\n\t\tdoing_modify = await self._collect_manager.async_analyze_whether_modify(\n\t\t\tuser_response=user_response,\n\t\t\tcollected_info_dict=self.collected_infos\n\t\t)\n\t\tif doing_modify:\n\t\t\tawait self.asingle_modify(user_response=user_response)\n\treturn doing_modify, abort\n</code></pre>"},{"location":"code_docs/interact/collect/collector/common_collector/#labridge.interact.collect.collector.common_collector.CommonInfoCollector.asingle_modify","title":"<code>labridge.interact.collect.collector.common_collector.CommonInfoCollector.asingle_modify(user_response)</code>  <code>async</code>","text":"<p>Asynchronously modify the collected information according to the user's comment.</p> PARAMETER DESCRIPTION <code>user_response</code> <p>The user's comment.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <p>None</p> Source code in <code>labridge\\interact\\collect\\collector\\common_collector.py</code> <pre><code>async def asingle_modify(self, user_response: str):\n\tr\"\"\"\n\tAsynchronously modify the collected information according to the user's comment.\n\n\tArgs:\n\t\tuser_response (str): The user's comment.\n\n\tReturns:\n\t\tNone\n\t\"\"\"\n\tfor batch_info_dict in self._common_infos.modify_info_content():\n\t\tpredict_kwargs = {\n\t\t\t\"prompt\": MODIFY_COMMON_INFO_PROMPT,\n\t\t\tModifyPromptKeys.user_comment_key: user_response,\n\t\t}\n\t\tpredict_kwargs.update(batch_info_dict)\n\t\textract_info = await self._llm.apredict(**predict_kwargs)\n\t\tnew_info_dict = parse_common_collected_info(\n\t\t\textract_info=extract_info,\n\t\t\tinfo_keys=list(self._common_infos.required_infos.keys()),\n\t\t)\n\t\tprint(\"modified: \", new_info_dict)\n\t\tself._common_infos.update_collected_info(collected_info_dict=new_info_dict)\n</code></pre>"},{"location":"code_docs/interact/collect/collector/common_collector/#labridge.interact.collect.collector.common_collector.CommonInfoCollector.collect","title":"<code>labridge.interact.collect.collector.common_collector.CommonInfoCollector.collect(user_id, query_str=None)</code>","text":"<p>Collect the Common information.</p> RETURNS DESCRIPTION <code>bool</code> <p>Whether the user aborts the collecting process.</p> <p> TYPE: <code>bool</code> </p> Source code in <code>labridge\\interact\\collect\\collector\\common_collector.py</code> <pre><code>def collect(\n\tself,\n\tuser_id: str,\n\tquery_str: Optional[str] = None,\n) -&gt; bool:\n\tr\"\"\"\n\tCollect the Common information.\n\n\tReturns:\n\t\tbool: Whether the user aborts the collecting process.\n\t\"\"\"\n\tif self._common_infos is None:\n\t\treturn False\n\n\tquery_to_user = self.collecting_query\n\tif query_str:\n\t\tquery_to_user = \"\\n\".join([query_str, query_to_user])\n\n\t# TODO: send the message to the user.\n\tprint(query_to_user)\n\n\t# TODO: receive the message from the user.\n\tuser_msg = ChatBuffer.test_get_user_text(user_id=user_id)\n\tuser_response = user_msg.user_msg\n\tabort = self._collect_manager.analyze_whether_abort(user_response=user_response)\n\tif abort:\n\t\treturn abort\n\n\tfor batch_info_dict in self._common_infos.info_content():\n\t\tpredict_kwargs = {\n\t\t\t\"prompt\": COLLECT_COMMON_INFO_PROMPT,\n\t\t\tCollectPromptKeys.user_response_key: user_response,\n\t\t}\n\t\tpredict_kwargs.update(batch_info_dict)\n\t\textract_info = self._llm.predict(**predict_kwargs)\n\t\tnew_info_dict = parse_common_collected_info(\n\t\t\textract_info=extract_info,\n\t\t\tinfo_keys=self._common_infos.collecting_keys,\n\t\t)\n\t\tself._common_infos.update_collected_info(collected_info_dict=new_info_dict)\n\treturn abort\n</code></pre>"},{"location":"code_docs/interact/collect/collector/common_collector/#labridge.interact.collect.collector.common_collector.CommonInfoCollector.get_common_infos","title":"<code>labridge.interact.collect.collector.common_collector.CommonInfoCollector.get_common_infos(required_infos)</code>","text":"<p>Choose the CollectingCommonInfo from the required_infos.</p> PARAMETER DESCRIPTION <code>required_infos</code> <p>The required infos.</p> <p> TYPE: <code>List[CollectingInfoBase]</code> </p> RETURNS DESCRIPTION <code>CollectingCommonInfo</code> <p>All required CollectingCommonInfo are aggregated in a  CollectingCommonInfo. If no CollectingCommonInfo required, return None.</p> <p> TYPE: <code>CollectingCommonInfo</code> </p> Source code in <code>labridge\\interact\\collect\\collector\\common_collector.py</code> <pre><code>def get_common_infos(\n\tself,\n\trequired_infos: List[CollectingInfoBase],\n) -&gt; CollectingCommonInfo:\n\tr\"\"\"\n\tChoose the CollectingCommonInfo from the required_infos.\n\n\tArgs:\n\t\trequired_infos (List[CollectingInfoBase]): The required infos.\n\n\tReturns:\n\t\tCollectingCommonInfo: All required CollectingCommonInfo are aggregated in a  CollectingCommonInfo.\n\t\t\tIf no CollectingCommonInfo required, return None.\n\t\"\"\"\n\tcommon_info = None\n\tfor info in required_infos:\n\t\tif isinstance(info, CollectingCommonInfo):\n\t\t\tif common_info is None:\n\t\t\t\tcommon_info = copy.deepcopy(info)\n\t\t\telse:\n\t\t\t\tcommon_info.insert_info(info)\n\treturn common_info\n</code></pre>"},{"location":"code_docs/interact/collect/collector/common_collector/#labridge.interact.collect.collector.common_collector.CommonInfoCollector.modify","title":"<code>labridge.interact.collect.collector.common_collector.CommonInfoCollector.modify(user_id)</code>","text":"<p>Modify the collected information according to the user's comment.</p> RETURNS DESCRIPTION <code>Tuple[bool, bool]</code> <p>Tuple[str, str]: - doing_modify: Whether the user thinks the collected information need modification. - abort: Whether the user aborts the collection process.</p> Source code in <code>labridge\\interact\\collect\\collector\\common_collector.py</code> <pre><code>def modify(self, user_id: str) -&gt; Tuple[bool, bool]:\n\tr\"\"\"\n\tModify the collected information according to the user's comment.\n\n\tReturns:\n\t\tTuple[str, str]:\n\t\t\t- doing_modify: Whether the user thinks the collected information need modification.\n\t\t\t- abort: Whether the user aborts the collection process.\n\t\"\"\"\n\tif self._common_infos is None:\n\t\treturn False, False\n\n\tdoing_modify = True\n\tabort = False\n\twhile doing_modify and not abort:\n\t\tquery_to_user =self._collect_manager.verify_query(collected_info_dict=self.collected_infos)\n\t\t# TODO: send the message to the user.\n\t\tprint(query_to_user)\n\t\t# TODO: receive the message from the user.\n\t\tuser_msg = ChatBuffer.test_get_user_text(user_id=user_id)\n\t\tuser_response = user_msg.user_msg\n\t\tabort = self._collect_manager.analyze_whether_abort(user_response=user_response)\n\t\tif abort:\n\t\t\tbreak\n\t\tdoing_modify = self._collect_manager.analyze_whether_modify(\n\t\t\tuser_response=user_response,\n\t\t\tcollected_info_dict=self.collected_infos\n\t\t)\n\t\tif doing_modify:\n\t\t\tself.single_modify(user_response=user_response)\n\treturn doing_modify, abort\n</code></pre>"},{"location":"code_docs/interact/collect/collector/common_collector/#labridge.interact.collect.collector.common_collector.CommonInfoCollector.single_modify","title":"<code>labridge.interact.collect.collector.common_collector.CommonInfoCollector.single_modify(user_response)</code>","text":"<p>Modify the collected information according to the user's comment.</p> PARAMETER DESCRIPTION <code>user_response</code> <p>The user's comment.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <p>None</p> Source code in <code>labridge\\interact\\collect\\collector\\common_collector.py</code> <pre><code>def single_modify(self, user_response: str):\n\tr\"\"\"\n\tModify the collected information according to the user's comment.\n\n\tArgs:\n\t\tuser_response (str): The user's comment.\n\n\tReturns:\n\t\tNone\n\t\"\"\"\n\tfor batch_info_dict in self._common_infos.modify_info_content():\n\t\tpredict_kwargs = {\n\t\t\t\"prompt\": MODIFY_COMMON_INFO_PROMPT,\n\t\t\tModifyPromptKeys.user_comment_key: user_response,\n\t\t}\n\t\tpredict_kwargs.update(batch_info_dict)\n\t\textract_info = self._llm.predict(**predict_kwargs)\n\t\tnew_info_dict = parse_common_collected_info(\n\t\t\textract_info=extract_info,\n\t\t\tinfo_keys=list(self._common_infos.required_infos.keys()),\n\t\t)\n\t\tprint(\"modified: \", new_info_dict)\n\t\tself._common_infos.update_collected_info(collected_info_dict=new_info_dict)\n</code></pre>"},{"location":"code_docs/interact/collect/collector/select_collector/","title":"Select collector","text":""},{"location":"code_docs/interact/collect/collector/select_collector/#labridge.interact.collect.collector.select_collector","title":"<code>labridge.interact.collect.collector.select_collector</code>","text":""},{"location":"code_docs/interact/collect/collector/select_collector/#labridge.interact.collect.collector.select_collector.SelectInfoCollector","title":"<code>labridge.interact.collect.collector.select_collector.SelectInfoCollector</code>","text":"<p>Collect SelectInfo from the user. refer to <code>..types.select_info.CollectingSelectInfo</code> for the detail of SelectInfo.</p> PARAMETER DESCRIPTION <code>llm</code> <p>The used LLM.</p> <p> TYPE: <code>LLM</code> </p> <code>required_infos</code> <p>The required infos.</p> <p> TYPE: <code>List[CollectingInfoBase]</code> </p> Source code in <code>labridge\\interact\\collect\\collector\\select_collector.py</code> <pre><code>class SelectInfoCollector:\n\tr\"\"\"\n\tCollect SelectInfo from the user.\n\trefer to `..types.select_info.CollectingSelectInfo` for the detail of SelectInfo.\n\n\tArgs:\n\t\tllm (LLM): The used LLM.\n\t\trequired_infos (List[CollectingInfoBase]): The required infos.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tllm: LLM,\n\t\trequired_infos: List[CollectingInfoBase],\n\t):\n\t\tself._llm = llm\n\t\tself._select_infos = self.get_select_infos(required_infos=required_infos)\n\t\tself._collect_manager = CollectManager(llm=llm)\n\n\tdef get_select_infos(\n\t\tself,\n\t\trequired_infos: List[CollectingInfoBase],\n\t) -&gt; List[CollectingSelectInfo]:\n\t\tr\"\"\"\n\t\tChoose the CollectingSelectInfo from the required_infos.\n\n\t\tArgs:\n\t\t\trequired_infos (List[CollectingInfoBase]): The required infos.\n\n\t\tReturns:\n\t\t\tList[CollectingSelectInfo]: All required CollectingSelectInfo. They will be collected one by one.\n\t\t\"\"\"\n\t\tselect_infos = []\n\t\tfor info in required_infos:\n\t\t\tif isinstance(info, CollectingSelectInfo):\n\t\t\t\tselect_infos.append(info)\n\t\treturn select_infos\n\n\tdef collect_single_info(\n\t\tself,\n\t\tinfo: CollectingSelectInfo,\n\t\tuser_id: str,\n\t\tquery_str: Optional[str] = None,\n\t) -&gt; bool:\n\t\tr\"\"\"\n\t\tCollect a SelectInfo from the user.\n\n\t\tArgs:\n\t\t\tinfo (CollectingSelectInfo): The info waiting for the user's selection.\n\t\t\tuser_id (str): The user id of a Lab member.\n\n\t\tReturns:\n\t\t\tbool: Whether the user aborts the collecting process.\n\t\t\"\"\"\n\t\t# TODO: send to user:\n\t\tquery_to_user = self.collecting_query(info=info)\n\t\tif query_str:\n\t\t\tquery_to_user = \"\\n\".join([query_str, query_to_user])\n\n\t\tprint(\"Assistant: \", query_to_user)\n\n\t\t# TODO: receive from user.\n\t\tuser_msg = ChatBuffer.test_get_user_text(user_id=user_id)\n\t\tuser_response = user_msg.user_msg\n\n\t\tabort = self._collect_manager.analyze_whether_abort(user_response=user_response)\n\t\tif abort:\n\t\t\treturn abort\n\n\t\tpredict_kwargs = {\n\t\t\t\"prompt\": COLLECT_SELECT_INFO_PROMPT,\n\t\t\tCollectPromptKeys.user_response_key: user_response,\n\t\t}\n\n\t\tall_choices, all_relevances = [], []\n\t\tfor batch_info_dict, batch_candidates in info.info_content():\n\t\t\tpredict_kwargs.update(batch_info_dict)\n\t\t\traw_response = self._llm.predict(**predict_kwargs)\n\n\t\t\traw_choices, relevances = default_parse_choice_select_answer_fn(raw_response, len(batch_candidates))\n\t\t\tchoice_idxs = [choice - 1 for choice in raw_choices]\n\t\t\tbatch_choices = [batch_candidates[ci] for ci in choice_idxs]\n\n\t\t\tall_choices.extend(batch_choices)\n\t\t\tall_relevances.extend(relevances)\n\n\t\tif all_choices:\n\t\t\tzipped_list = list(zip(all_choices, all_relevances))\n\t\t\tsorted_list = sorted(zipped_list, key=lambda x: x[1], reverse=True)\n\t\t\tcollected_info, score = sorted_list[0]\n\t\t\tinfo.update_collected_info(\n\t\t\t\tcollected_info_dict={info.info_name: collected_info}\n\t\t\t)\n\t\treturn abort\n\n\tasync def acollect_single_info(\n\t\tself,\n\t\tinfo: CollectingSelectInfo,\n\t\tuser_id: str,\n\t\tquery_str: Optional[str] = None,\n\t) -&gt; bool:\n\t\tr\"\"\"\n\t\tAsynchronously collect a SelectInfo from the user.\n\n\t\tArgs:\n\t\t\tinfo (CollectingSelectInfo): The info waiting for the user's selection.\n\t\t\tuser_id (str): The user id of a Lab member.\n\n\t\tReturns:\n\t\t\tbool: Whether the user aborts the collecting process.\n\t\t\"\"\"\n\t\t# TODO: send to user:\n\t\tquery_to_user = self.collecting_query(info=info)\n\t\tif query_str:\n\t\t\tquery_to_user = \"\\n\".join([query_str, query_to_user])\n\n\t\tChatBuffer.put_agent_reply(\n\t\t\tuser_id=user_id,\n\t\t\treply_str=query_to_user,\n\t\t\tinner_chat=True,\n\t\t)\n\n\t\t# TODO: receive from user.\n\t\tuser_msg = await ChatBuffer.get_user_msg(user_id=user_id)\n\t\tuser_response = user_msg.user_msg\n\n\t\tabort = await self._collect_manager.async_analyze_whether_abort(user_response=user_response)\n\t\tif abort:\n\t\t\treturn abort\n\n\t\tpredict_kwargs = {\n\t\t\t\"prompt\": COLLECT_SELECT_INFO_PROMPT,\n\t\t\tCollectPromptKeys.user_response_key: user_response,\n\t\t}\n\n\t\tall_choices, all_relevances = [], []\n\t\tfor batch_info_dict, batch_candidates in info.info_content():\n\t\t\tpredict_kwargs.update(batch_info_dict)\n\t\t\traw_response = await self._llm.apredict(**predict_kwargs)\n\n\t\t\traw_choices, relevances = default_parse_choice_select_answer_fn(raw_response, len(batch_candidates))\n\t\t\tchoice_idxs = [choice - 1 for choice in raw_choices]\n\t\t\tbatch_choices = [batch_candidates[ci] for ci in choice_idxs]\n\n\t\t\tall_choices.extend(batch_choices)\n\t\t\tall_relevances.extend(relevances)\n\n\t\tif all_choices:\n\t\t\tzipped_list = list(zip(all_choices, all_relevances))\n\t\t\tsorted_list = sorted(zipped_list, key=lambda x: x[1], reverse=True)\n\t\t\tcollected_info, score = sorted_list[0]\n\t\t\tinfo.update_collected_info(\n\t\t\t\tcollected_info_dict={info.info_name: collected_info}\n\t\t\t)\n\t\treturn abort\n\n\tdef collect(\n\t\tself,\n\t\tuser_id: str,\n\t\tquery_str: Optional[str] = None,\n\t) -&gt; bool:\n\t\tr\"\"\"\n\t\tCollect all SelectInfo.\n\n\t\tReturns:\n\t\t\tbool: Whether the user aborts the collecting process.\n\t\t\"\"\"\n\t\tfor info in self._select_infos:\n\t\t\tabort = self.collect_single_info(info=info, user_id=user_id, query_str=query_str)\n\t\t\tif abort:\n\t\t\t\treturn True\n\t\treturn False\n\n\tasync def acollect(\n\t\tself,\n\t\tuser_id: str,\n\t\tquery_str: Optional[str] = None,\n\t) -&gt; bool:\n\t\tr\"\"\"\n\t\tAsynchronously collect all SelectInfo.\n\n\t\tReturns:\n\t\t\tbool: Whether the user aborts the collecting process.\n\t\t\"\"\"\n\t\tfor info in self._select_infos:\n\t\t\tabort = await self.acollect_single_info(info=info, user_id=user_id, query_str=query_str)\n\t\t\tif abort:\n\t\t\t\treturn True\n\t\treturn False\n\n\tdef collecting_query(self, info: CollectingSelectInfo) -&gt; str:\n\t\tr\"\"\"\n\t\tThis query will be sent to user to collect rest Common information\n\n\t\tArgs:\n\t\t\tinfo (CollectingSelectInfo): The SelectInfo to be collected.\n\n\t\tReturns:\n\t\t\tThe query.\n\t\t\"\"\"\n\t\tif info is None:\n\t\t\treturn \"\"\n\t\tquery_to_user = f\"{COLLECT_SELECT_INFO_QUERY}\\n\"\n\t\tfor key in info.collecting_keys:\n\t\t\tquery_to_user += f\"\\t{key}\\n\"\n\t\tquery_to_user += \"Candidates:\\n\"\n\t\tfor choice in info.candidates:\n\t\t\tquery_to_user += f\"\\t{choice}\\n\"\n\t\treturn query_to_user\n\n\tdef modify_single_info(self, user_response: str,  info: CollectingSelectInfo):\n\t\tr\"\"\"\n\t\tModify a collected SelectInfo according to the user's comment.\n\n\t\tArgs:\n\t\t\tuser_response (str): The user's comment.\n\t\t\tinfo (CollectingSelectInfo): The collected SelectInfo.\n\n\t\tReturns:\n\t\t\tNone\n\t\t\"\"\"\n\t\tpredict_kwargs = {\n\t\t\t\"prompt\": MODIFY_SELECT_INFO_PROMPT,\n\t\t\tModifyPromptKeys.user_comment_key: user_response,\n\t\t}\n\n\t\tall_choices, all_possibilities = [], []\n\t\tfor batch_info_dict, batch_candidates in info.modify_info_content():\n\t\t\tpredict_kwargs.update(batch_info_dict)\n\t\t\traw_response = self._llm.predict(**predict_kwargs)\n\n\t\t\traw_choices, possibilities = default_parse_choice_select_answer_fn(raw_response, len(batch_candidates))\n\t\t\tchoice_idxs = [choice - 1 for choice in raw_choices]\n\t\t\tbatch_choices = [batch_candidates[ci] for ci in choice_idxs]\n\n\t\t\tall_choices.extend(batch_choices)\n\t\t\tall_possibilities.extend(possibilities)\n\n\t\tzipped_list = list(zip(all_choices, all_possibilities))\n\t\tsorted_list = sorted(zipped_list, key=lambda x: x[1], reverse=True)\n\t\tif sorted_list:\n\t\t\tcollected_info, score = sorted_list[0]\n\t\t\tif score &gt;= SELECT_MIN_SCORE:\n\t\t\t\tinfo.update_collected_info(\n\t\t\t\t\tcollected_info_dict={info.info_name: collected_info}\n\t\t\t\t)\n\n\tasync def amodify_single_info(self, user_response: str,  info: CollectingSelectInfo):\n\t\tr\"\"\"\n\t\tAsynchronously modify a collected SelectInfo according to the user's comment.\n\n\t\tArgs:\n\t\t\tuser_response (str): The user's comment.\n\t\t\tinfo (CollectingSelectInfo): The collected SelectInfo.\n\n\t\tReturns:\n\t\t\tNone\n\t\t\"\"\"\n\t\tpredict_kwargs = {\n\t\t\t\"prompt\": MODIFY_SELECT_INFO_PROMPT,\n\t\t\tModifyPromptKeys.user_comment_key: user_response,\n\t\t}\n\n\t\tall_choices, all_possibilities = [], []\n\t\tfor batch_info_dict, batch_candidates in info.modify_info_content():\n\t\t\tpredict_kwargs.update(batch_info_dict)\n\t\t\traw_response = await self._llm.apredict(**predict_kwargs)\n\n\t\t\traw_choices, possibilities = default_parse_choice_select_answer_fn(raw_response, len(batch_candidates))\n\t\t\tchoice_idxs = [choice - 1 for choice in raw_choices]\n\t\t\tbatch_choices = [batch_candidates[ci] for ci in choice_idxs]\n\n\t\t\tall_choices.extend(batch_choices)\n\t\t\tall_possibilities.extend(possibilities)\n\n\t\tzipped_list = list(zip(all_choices, all_possibilities))\n\t\tsorted_list = sorted(zipped_list, key=lambda x: x[1], reverse=True)\n\t\tif sorted_list:\n\t\t\tcollected_info, score = sorted_list[0]\n\t\t\tif score &gt;= SELECT_MIN_SCORE:\n\t\t\t\tinfo.update_collected_info(\n\t\t\t\t\tcollected_info_dict={info.info_name: collected_info}\n\t\t\t\t)\n\n\tdef modify(self, user_id: str) -&gt; Tuple[bool, bool]:\n\t\tr\"\"\"\n\t\tModify the collected SelectInfo according to the user's comment.\n\n\t\tReturns:\n\t\t\tTuple[str, str]:\n\t\t\t\t- doing_modify: Whether the user thinks the collected information need modification.\n\t\t\t\t- abort: Whether the user aborts the collection process.\n\t\t\"\"\"\n\t\tif len(self._select_infos) &lt; 1:\n\t\t\treturn False, False\n\n\t\tdoing_modify = True\n\t\tabort = False\n\t\twhile doing_modify and not abort:\n\t\t\tquery_to_user =self._collect_manager.verify_query(collected_info_dict=self.collected_infos)\n\t\t\t# TODO: send the message to the user.\n\t\t\tprint(query_to_user)\n\n\t\t\t# TODO: receive the message from the user.\n\t\t\tuser_msg = ChatBuffer.test_get_user_text(user_id=user_id)\n\t\t\tuser_response = user_msg.user_msg\n\t\t\tabort = self._collect_manager.analyze_whether_abort(user_response=user_response)\n\t\t\tif abort:\n\t\t\t\tbreak\n\t\t\tdoing_modify = self._collect_manager.analyze_whether_modify(\n\t\t\t\tuser_response=user_response,\n\t\t\t\tcollected_info_dict=self.collected_infos\n\t\t\t)\n\t\t\tif doing_modify:\n\t\t\t\tself.single_modify(user_response=user_response)\n\t\treturn doing_modify, abort\n\n\tasync def amodify(self, user_id: str) -&gt; Tuple[bool, bool]:\n\t\tr\"\"\"\n\t\tAsynchronously modify the collected SelectInfo according to the user's comment.\n\n\t\tReturns:\n\t\t\tTuple[str, str]:\n\t\t\t\t- doing_modify: Whether the user thinks the collected information need modification.\n\t\t\t\t- abort: Whether the user aborts the collection process.\n\t\t\"\"\"\n\t\tif len(self._select_infos) &lt; 1:\n\t\t\treturn False, False\n\n\t\tdoing_modify = True\n\t\tabort = False\n\t\twhile doing_modify and not abort:\n\t\t\tquery_to_user =self._collect_manager.verify_query(collected_info_dict=self.collected_infos)\n\t\t\t# TODO: send the message to the user.\n\t\t\tChatBuffer.put_agent_reply(\n\t\t\t\tuser_id=user_id,\n\t\t\t\treply_str=query_to_user,\n\t\t\t\tinner_chat=True,\n\t\t\t)\n\n\t\t\t# TODO: receive the message from the user.\n\t\t\tuser_msg = await ChatBuffer.get_user_msg(user_id=user_id)\n\t\t\tuser_response = user_msg.user_msg\n\t\t\tabort = await self._collect_manager.async_analyze_whether_abort(user_response=user_response)\n\t\t\tif abort:\n\t\t\t\tbreak\n\t\t\tdoing_modify = await self._collect_manager.async_analyze_whether_modify(\n\t\t\t\tuser_response=user_response,\n\t\t\t\tcollected_info_dict=self.collected_infos\n\t\t\t)\n\t\t\tif doing_modify:\n\t\t\t\tawait self.asingle_modify(user_response=user_response)\n\t\treturn doing_modify, abort\n\n\n\tdef single_modify(self, user_response: str):\n\t\tr\"\"\" Modify \"\"\"\n\t\tfor info in self._select_infos:\n\t\t\tself.modify_single_info(user_response=user_response, info=info)\n\n\tasync def asingle_modify(self, user_response: str):\n\t\tr\"\"\" Asynchronously modify \"\"\"\n\t\tfor info in self._select_infos:\n\t\t\tawait self.amodify_single_info(user_response=user_response, info=info)\n\n\t@property\n\tdef collecting_keys(self) -&gt; List[str]:\n\t\tr\"\"\"\n\t\tThe SelectInfo to be collected currently.\n\t\t\"\"\"\n\t\tcollecting = []\n\t\tfor info in self._select_infos:\n\t\t\tcollecting.extend(info.collecting_keys)\n\t\treturn collecting\n\n\t@property\n\tdef collected_infos(self) -&gt; Dict[str, str]:\n\t\tr\"\"\" The Collected SelectInfo. \"\"\"\n\t\tinfos = {}\n\t\tfor info in self._select_infos:\n\t\t\tinfos.update(info.collected_infos)\n\t\treturn infos\n\n\t@property\n\tdef collected(self):\n\t\tr\"\"\" Whether all SelectInfo are collected or not. \"\"\"\n\t\tfor info in self._select_infos:\n\t\t\tif not info.collected:\n\t\t\t\treturn False\n\t\treturn True\n</code></pre>"},{"location":"code_docs/interact/collect/collector/select_collector/#labridge.interact.collect.collector.select_collector.SelectInfoCollector.collected","title":"<code>labridge.interact.collect.collector.select_collector.SelectInfoCollector.collected</code>  <code>property</code>","text":"<p>Whether all SelectInfo are collected or not.</p>"},{"location":"code_docs/interact/collect/collector/select_collector/#labridge.interact.collect.collector.select_collector.SelectInfoCollector.collected_infos","title":"<code>labridge.interact.collect.collector.select_collector.SelectInfoCollector.collected_infos: Dict[str, str]</code>  <code>property</code>","text":"<p>The Collected SelectInfo.</p>"},{"location":"code_docs/interact/collect/collector/select_collector/#labridge.interact.collect.collector.select_collector.SelectInfoCollector.collecting_keys","title":"<code>labridge.interact.collect.collector.select_collector.SelectInfoCollector.collecting_keys: List[str]</code>  <code>property</code>","text":"<p>The SelectInfo to be collected currently.</p>"},{"location":"code_docs/interact/collect/collector/select_collector/#labridge.interact.collect.collector.select_collector.SelectInfoCollector.acollect","title":"<code>labridge.interact.collect.collector.select_collector.SelectInfoCollector.acollect(user_id, query_str=None)</code>  <code>async</code>","text":"<p>Asynchronously collect all SelectInfo.</p> RETURNS DESCRIPTION <code>bool</code> <p>Whether the user aborts the collecting process.</p> <p> TYPE: <code>bool</code> </p> Source code in <code>labridge\\interact\\collect\\collector\\select_collector.py</code> <pre><code>async def acollect(\n\tself,\n\tuser_id: str,\n\tquery_str: Optional[str] = None,\n) -&gt; bool:\n\tr\"\"\"\n\tAsynchronously collect all SelectInfo.\n\n\tReturns:\n\t\tbool: Whether the user aborts the collecting process.\n\t\"\"\"\n\tfor info in self._select_infos:\n\t\tabort = await self.acollect_single_info(info=info, user_id=user_id, query_str=query_str)\n\t\tif abort:\n\t\t\treturn True\n\treturn False\n</code></pre>"},{"location":"code_docs/interact/collect/collector/select_collector/#labridge.interact.collect.collector.select_collector.SelectInfoCollector.acollect_single_info","title":"<code>labridge.interact.collect.collector.select_collector.SelectInfoCollector.acollect_single_info(info, user_id, query_str=None)</code>  <code>async</code>","text":"<p>Asynchronously collect a SelectInfo from the user.</p> PARAMETER DESCRIPTION <code>info</code> <p>The info waiting for the user's selection.</p> <p> TYPE: <code>CollectingSelectInfo</code> </p> <code>user_id</code> <p>The user id of a Lab member.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>Whether the user aborts the collecting process.</p> <p> TYPE: <code>bool</code> </p> Source code in <code>labridge\\interact\\collect\\collector\\select_collector.py</code> <pre><code>async def acollect_single_info(\n\tself,\n\tinfo: CollectingSelectInfo,\n\tuser_id: str,\n\tquery_str: Optional[str] = None,\n) -&gt; bool:\n\tr\"\"\"\n\tAsynchronously collect a SelectInfo from the user.\n\n\tArgs:\n\t\tinfo (CollectingSelectInfo): The info waiting for the user's selection.\n\t\tuser_id (str): The user id of a Lab member.\n\n\tReturns:\n\t\tbool: Whether the user aborts the collecting process.\n\t\"\"\"\n\t# TODO: send to user:\n\tquery_to_user = self.collecting_query(info=info)\n\tif query_str:\n\t\tquery_to_user = \"\\n\".join([query_str, query_to_user])\n\n\tChatBuffer.put_agent_reply(\n\t\tuser_id=user_id,\n\t\treply_str=query_to_user,\n\t\tinner_chat=True,\n\t)\n\n\t# TODO: receive from user.\n\tuser_msg = await ChatBuffer.get_user_msg(user_id=user_id)\n\tuser_response = user_msg.user_msg\n\n\tabort = await self._collect_manager.async_analyze_whether_abort(user_response=user_response)\n\tif abort:\n\t\treturn abort\n\n\tpredict_kwargs = {\n\t\t\"prompt\": COLLECT_SELECT_INFO_PROMPT,\n\t\tCollectPromptKeys.user_response_key: user_response,\n\t}\n\n\tall_choices, all_relevances = [], []\n\tfor batch_info_dict, batch_candidates in info.info_content():\n\t\tpredict_kwargs.update(batch_info_dict)\n\t\traw_response = await self._llm.apredict(**predict_kwargs)\n\n\t\traw_choices, relevances = default_parse_choice_select_answer_fn(raw_response, len(batch_candidates))\n\t\tchoice_idxs = [choice - 1 for choice in raw_choices]\n\t\tbatch_choices = [batch_candidates[ci] for ci in choice_idxs]\n\n\t\tall_choices.extend(batch_choices)\n\t\tall_relevances.extend(relevances)\n\n\tif all_choices:\n\t\tzipped_list = list(zip(all_choices, all_relevances))\n\t\tsorted_list = sorted(zipped_list, key=lambda x: x[1], reverse=True)\n\t\tcollected_info, score = sorted_list[0]\n\t\tinfo.update_collected_info(\n\t\t\tcollected_info_dict={info.info_name: collected_info}\n\t\t)\n\treturn abort\n</code></pre>"},{"location":"code_docs/interact/collect/collector/select_collector/#labridge.interact.collect.collector.select_collector.SelectInfoCollector.amodify","title":"<code>labridge.interact.collect.collector.select_collector.SelectInfoCollector.amodify(user_id)</code>  <code>async</code>","text":"<p>Asynchronously modify the collected SelectInfo according to the user's comment.</p> RETURNS DESCRIPTION <code>Tuple[bool, bool]</code> <p>Tuple[str, str]: - doing_modify: Whether the user thinks the collected information need modification. - abort: Whether the user aborts the collection process.</p> Source code in <code>labridge\\interact\\collect\\collector\\select_collector.py</code> <pre><code>async def amodify(self, user_id: str) -&gt; Tuple[bool, bool]:\n\tr\"\"\"\n\tAsynchronously modify the collected SelectInfo according to the user's comment.\n\n\tReturns:\n\t\tTuple[str, str]:\n\t\t\t- doing_modify: Whether the user thinks the collected information need modification.\n\t\t\t- abort: Whether the user aborts the collection process.\n\t\"\"\"\n\tif len(self._select_infos) &lt; 1:\n\t\treturn False, False\n\n\tdoing_modify = True\n\tabort = False\n\twhile doing_modify and not abort:\n\t\tquery_to_user =self._collect_manager.verify_query(collected_info_dict=self.collected_infos)\n\t\t# TODO: send the message to the user.\n\t\tChatBuffer.put_agent_reply(\n\t\t\tuser_id=user_id,\n\t\t\treply_str=query_to_user,\n\t\t\tinner_chat=True,\n\t\t)\n\n\t\t# TODO: receive the message from the user.\n\t\tuser_msg = await ChatBuffer.get_user_msg(user_id=user_id)\n\t\tuser_response = user_msg.user_msg\n\t\tabort = await self._collect_manager.async_analyze_whether_abort(user_response=user_response)\n\t\tif abort:\n\t\t\tbreak\n\t\tdoing_modify = await self._collect_manager.async_analyze_whether_modify(\n\t\t\tuser_response=user_response,\n\t\t\tcollected_info_dict=self.collected_infos\n\t\t)\n\t\tif doing_modify:\n\t\t\tawait self.asingle_modify(user_response=user_response)\n\treturn doing_modify, abort\n</code></pre>"},{"location":"code_docs/interact/collect/collector/select_collector/#labridge.interact.collect.collector.select_collector.SelectInfoCollector.amodify_single_info","title":"<code>labridge.interact.collect.collector.select_collector.SelectInfoCollector.amodify_single_info(user_response, info)</code>  <code>async</code>","text":"<p>Asynchronously modify a collected SelectInfo according to the user's comment.</p> PARAMETER DESCRIPTION <code>user_response</code> <p>The user's comment.</p> <p> TYPE: <code>str</code> </p> <code>info</code> <p>The collected SelectInfo.</p> <p> TYPE: <code>CollectingSelectInfo</code> </p> RETURNS DESCRIPTION <p>None</p> Source code in <code>labridge\\interact\\collect\\collector\\select_collector.py</code> <pre><code>async def amodify_single_info(self, user_response: str,  info: CollectingSelectInfo):\n\tr\"\"\"\n\tAsynchronously modify a collected SelectInfo according to the user's comment.\n\n\tArgs:\n\t\tuser_response (str): The user's comment.\n\t\tinfo (CollectingSelectInfo): The collected SelectInfo.\n\n\tReturns:\n\t\tNone\n\t\"\"\"\n\tpredict_kwargs = {\n\t\t\"prompt\": MODIFY_SELECT_INFO_PROMPT,\n\t\tModifyPromptKeys.user_comment_key: user_response,\n\t}\n\n\tall_choices, all_possibilities = [], []\n\tfor batch_info_dict, batch_candidates in info.modify_info_content():\n\t\tpredict_kwargs.update(batch_info_dict)\n\t\traw_response = await self._llm.apredict(**predict_kwargs)\n\n\t\traw_choices, possibilities = default_parse_choice_select_answer_fn(raw_response, len(batch_candidates))\n\t\tchoice_idxs = [choice - 1 for choice in raw_choices]\n\t\tbatch_choices = [batch_candidates[ci] for ci in choice_idxs]\n\n\t\tall_choices.extend(batch_choices)\n\t\tall_possibilities.extend(possibilities)\n\n\tzipped_list = list(zip(all_choices, all_possibilities))\n\tsorted_list = sorted(zipped_list, key=lambda x: x[1], reverse=True)\n\tif sorted_list:\n\t\tcollected_info, score = sorted_list[0]\n\t\tif score &gt;= SELECT_MIN_SCORE:\n\t\t\tinfo.update_collected_info(\n\t\t\t\tcollected_info_dict={info.info_name: collected_info}\n\t\t\t)\n</code></pre>"},{"location":"code_docs/interact/collect/collector/select_collector/#labridge.interact.collect.collector.select_collector.SelectInfoCollector.asingle_modify","title":"<code>labridge.interact.collect.collector.select_collector.SelectInfoCollector.asingle_modify(user_response)</code>  <code>async</code>","text":"<p>Asynchronously modify</p> Source code in <code>labridge\\interact\\collect\\collector\\select_collector.py</code> <pre><code>async def asingle_modify(self, user_response: str):\n\tr\"\"\" Asynchronously modify \"\"\"\n\tfor info in self._select_infos:\n\t\tawait self.amodify_single_info(user_response=user_response, info=info)\n</code></pre>"},{"location":"code_docs/interact/collect/collector/select_collector/#labridge.interact.collect.collector.select_collector.SelectInfoCollector.collect","title":"<code>labridge.interact.collect.collector.select_collector.SelectInfoCollector.collect(user_id, query_str=None)</code>","text":"<p>Collect all SelectInfo.</p> RETURNS DESCRIPTION <code>bool</code> <p>Whether the user aborts the collecting process.</p> <p> TYPE: <code>bool</code> </p> Source code in <code>labridge\\interact\\collect\\collector\\select_collector.py</code> <pre><code>def collect(\n\tself,\n\tuser_id: str,\n\tquery_str: Optional[str] = None,\n) -&gt; bool:\n\tr\"\"\"\n\tCollect all SelectInfo.\n\n\tReturns:\n\t\tbool: Whether the user aborts the collecting process.\n\t\"\"\"\n\tfor info in self._select_infos:\n\t\tabort = self.collect_single_info(info=info, user_id=user_id, query_str=query_str)\n\t\tif abort:\n\t\t\treturn True\n\treturn False\n</code></pre>"},{"location":"code_docs/interact/collect/collector/select_collector/#labridge.interact.collect.collector.select_collector.SelectInfoCollector.collect_single_info","title":"<code>labridge.interact.collect.collector.select_collector.SelectInfoCollector.collect_single_info(info, user_id, query_str=None)</code>","text":"<p>Collect a SelectInfo from the user.</p> PARAMETER DESCRIPTION <code>info</code> <p>The info waiting for the user's selection.</p> <p> TYPE: <code>CollectingSelectInfo</code> </p> <code>user_id</code> <p>The user id of a Lab member.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>Whether the user aborts the collecting process.</p> <p> TYPE: <code>bool</code> </p> Source code in <code>labridge\\interact\\collect\\collector\\select_collector.py</code> <pre><code>def collect_single_info(\n\tself,\n\tinfo: CollectingSelectInfo,\n\tuser_id: str,\n\tquery_str: Optional[str] = None,\n) -&gt; bool:\n\tr\"\"\"\n\tCollect a SelectInfo from the user.\n\n\tArgs:\n\t\tinfo (CollectingSelectInfo): The info waiting for the user's selection.\n\t\tuser_id (str): The user id of a Lab member.\n\n\tReturns:\n\t\tbool: Whether the user aborts the collecting process.\n\t\"\"\"\n\t# TODO: send to user:\n\tquery_to_user = self.collecting_query(info=info)\n\tif query_str:\n\t\tquery_to_user = \"\\n\".join([query_str, query_to_user])\n\n\tprint(\"Assistant: \", query_to_user)\n\n\t# TODO: receive from user.\n\tuser_msg = ChatBuffer.test_get_user_text(user_id=user_id)\n\tuser_response = user_msg.user_msg\n\n\tabort = self._collect_manager.analyze_whether_abort(user_response=user_response)\n\tif abort:\n\t\treturn abort\n\n\tpredict_kwargs = {\n\t\t\"prompt\": COLLECT_SELECT_INFO_PROMPT,\n\t\tCollectPromptKeys.user_response_key: user_response,\n\t}\n\n\tall_choices, all_relevances = [], []\n\tfor batch_info_dict, batch_candidates in info.info_content():\n\t\tpredict_kwargs.update(batch_info_dict)\n\t\traw_response = self._llm.predict(**predict_kwargs)\n\n\t\traw_choices, relevances = default_parse_choice_select_answer_fn(raw_response, len(batch_candidates))\n\t\tchoice_idxs = [choice - 1 for choice in raw_choices]\n\t\tbatch_choices = [batch_candidates[ci] for ci in choice_idxs]\n\n\t\tall_choices.extend(batch_choices)\n\t\tall_relevances.extend(relevances)\n\n\tif all_choices:\n\t\tzipped_list = list(zip(all_choices, all_relevances))\n\t\tsorted_list = sorted(zipped_list, key=lambda x: x[1], reverse=True)\n\t\tcollected_info, score = sorted_list[0]\n\t\tinfo.update_collected_info(\n\t\t\tcollected_info_dict={info.info_name: collected_info}\n\t\t)\n\treturn abort\n</code></pre>"},{"location":"code_docs/interact/collect/collector/select_collector/#labridge.interact.collect.collector.select_collector.SelectInfoCollector.collecting_query","title":"<code>labridge.interact.collect.collector.select_collector.SelectInfoCollector.collecting_query(info)</code>","text":"<p>This query will be sent to user to collect rest Common information</p> PARAMETER DESCRIPTION <code>info</code> <p>The SelectInfo to be collected.</p> <p> TYPE: <code>CollectingSelectInfo</code> </p> RETURNS DESCRIPTION <code>str</code> <p>The query.</p> Source code in <code>labridge\\interact\\collect\\collector\\select_collector.py</code> <pre><code>def collecting_query(self, info: CollectingSelectInfo) -&gt; str:\n\tr\"\"\"\n\tThis query will be sent to user to collect rest Common information\n\n\tArgs:\n\t\tinfo (CollectingSelectInfo): The SelectInfo to be collected.\n\n\tReturns:\n\t\tThe query.\n\t\"\"\"\n\tif info is None:\n\t\treturn \"\"\n\tquery_to_user = f\"{COLLECT_SELECT_INFO_QUERY}\\n\"\n\tfor key in info.collecting_keys:\n\t\tquery_to_user += f\"\\t{key}\\n\"\n\tquery_to_user += \"Candidates:\\n\"\n\tfor choice in info.candidates:\n\t\tquery_to_user += f\"\\t{choice}\\n\"\n\treturn query_to_user\n</code></pre>"},{"location":"code_docs/interact/collect/collector/select_collector/#labridge.interact.collect.collector.select_collector.SelectInfoCollector.get_select_infos","title":"<code>labridge.interact.collect.collector.select_collector.SelectInfoCollector.get_select_infos(required_infos)</code>","text":"<p>Choose the CollectingSelectInfo from the required_infos.</p> PARAMETER DESCRIPTION <code>required_infos</code> <p>The required infos.</p> <p> TYPE: <code>List[CollectingInfoBase]</code> </p> RETURNS DESCRIPTION <code>List[CollectingSelectInfo]</code> <p>List[CollectingSelectInfo]: All required CollectingSelectInfo. They will be collected one by one.</p> Source code in <code>labridge\\interact\\collect\\collector\\select_collector.py</code> <pre><code>def get_select_infos(\n\tself,\n\trequired_infos: List[CollectingInfoBase],\n) -&gt; List[CollectingSelectInfo]:\n\tr\"\"\"\n\tChoose the CollectingSelectInfo from the required_infos.\n\n\tArgs:\n\t\trequired_infos (List[CollectingInfoBase]): The required infos.\n\n\tReturns:\n\t\tList[CollectingSelectInfo]: All required CollectingSelectInfo. They will be collected one by one.\n\t\"\"\"\n\tselect_infos = []\n\tfor info in required_infos:\n\t\tif isinstance(info, CollectingSelectInfo):\n\t\t\tselect_infos.append(info)\n\treturn select_infos\n</code></pre>"},{"location":"code_docs/interact/collect/collector/select_collector/#labridge.interact.collect.collector.select_collector.SelectInfoCollector.modify","title":"<code>labridge.interact.collect.collector.select_collector.SelectInfoCollector.modify(user_id)</code>","text":"<p>Modify the collected SelectInfo according to the user's comment.</p> RETURNS DESCRIPTION <code>Tuple[bool, bool]</code> <p>Tuple[str, str]: - doing_modify: Whether the user thinks the collected information need modification. - abort: Whether the user aborts the collection process.</p> Source code in <code>labridge\\interact\\collect\\collector\\select_collector.py</code> <pre><code>def modify(self, user_id: str) -&gt; Tuple[bool, bool]:\n\tr\"\"\"\n\tModify the collected SelectInfo according to the user's comment.\n\n\tReturns:\n\t\tTuple[str, str]:\n\t\t\t- doing_modify: Whether the user thinks the collected information need modification.\n\t\t\t- abort: Whether the user aborts the collection process.\n\t\"\"\"\n\tif len(self._select_infos) &lt; 1:\n\t\treturn False, False\n\n\tdoing_modify = True\n\tabort = False\n\twhile doing_modify and not abort:\n\t\tquery_to_user =self._collect_manager.verify_query(collected_info_dict=self.collected_infos)\n\t\t# TODO: send the message to the user.\n\t\tprint(query_to_user)\n\n\t\t# TODO: receive the message from the user.\n\t\tuser_msg = ChatBuffer.test_get_user_text(user_id=user_id)\n\t\tuser_response = user_msg.user_msg\n\t\tabort = self._collect_manager.analyze_whether_abort(user_response=user_response)\n\t\tif abort:\n\t\t\tbreak\n\t\tdoing_modify = self._collect_manager.analyze_whether_modify(\n\t\t\tuser_response=user_response,\n\t\t\tcollected_info_dict=self.collected_infos\n\t\t)\n\t\tif doing_modify:\n\t\t\tself.single_modify(user_response=user_response)\n\treturn doing_modify, abort\n</code></pre>"},{"location":"code_docs/interact/collect/collector/select_collector/#labridge.interact.collect.collector.select_collector.SelectInfoCollector.modify_single_info","title":"<code>labridge.interact.collect.collector.select_collector.SelectInfoCollector.modify_single_info(user_response, info)</code>","text":"<p>Modify a collected SelectInfo according to the user's comment.</p> PARAMETER DESCRIPTION <code>user_response</code> <p>The user's comment.</p> <p> TYPE: <code>str</code> </p> <code>info</code> <p>The collected SelectInfo.</p> <p> TYPE: <code>CollectingSelectInfo</code> </p> RETURNS DESCRIPTION <p>None</p> Source code in <code>labridge\\interact\\collect\\collector\\select_collector.py</code> <pre><code>def modify_single_info(self, user_response: str,  info: CollectingSelectInfo):\n\tr\"\"\"\n\tModify a collected SelectInfo according to the user's comment.\n\n\tArgs:\n\t\tuser_response (str): The user's comment.\n\t\tinfo (CollectingSelectInfo): The collected SelectInfo.\n\n\tReturns:\n\t\tNone\n\t\"\"\"\n\tpredict_kwargs = {\n\t\t\"prompt\": MODIFY_SELECT_INFO_PROMPT,\n\t\tModifyPromptKeys.user_comment_key: user_response,\n\t}\n\n\tall_choices, all_possibilities = [], []\n\tfor batch_info_dict, batch_candidates in info.modify_info_content():\n\t\tpredict_kwargs.update(batch_info_dict)\n\t\traw_response = self._llm.predict(**predict_kwargs)\n\n\t\traw_choices, possibilities = default_parse_choice_select_answer_fn(raw_response, len(batch_candidates))\n\t\tchoice_idxs = [choice - 1 for choice in raw_choices]\n\t\tbatch_choices = [batch_candidates[ci] for ci in choice_idxs]\n\n\t\tall_choices.extend(batch_choices)\n\t\tall_possibilities.extend(possibilities)\n\n\tzipped_list = list(zip(all_choices, all_possibilities))\n\tsorted_list = sorted(zipped_list, key=lambda x: x[1], reverse=True)\n\tif sorted_list:\n\t\tcollected_info, score = sorted_list[0]\n\t\tif score &gt;= SELECT_MIN_SCORE:\n\t\t\tinfo.update_collected_info(\n\t\t\t\tcollected_info_dict={info.info_name: collected_info}\n\t\t\t)\n</code></pre>"},{"location":"code_docs/interact/collect/collector/select_collector/#labridge.interact.collect.collector.select_collector.SelectInfoCollector.single_modify","title":"<code>labridge.interact.collect.collector.select_collector.SelectInfoCollector.single_modify(user_response)</code>","text":"<p>Modify</p> Source code in <code>labridge\\interact\\collect\\collector\\select_collector.py</code> <pre><code>def single_modify(self, user_response: str):\n\tr\"\"\" Modify \"\"\"\n\tfor info in self._select_infos:\n\t\tself.modify_single_info(user_response=user_response, info=info)\n</code></pre>"},{"location":"code_docs/interact/collect/manager/collect_manager/","title":"Collect manager","text":""},{"location":"code_docs/interact/collect/manager/collect_manager/#labridge.interact.collect.manager.collect_manager","title":"<code>labridge.interact.collect.manager.collect_manager</code>","text":""},{"location":"code_docs/interact/collect/manager/collect_manager/#labridge.interact.collect.manager.collect_manager.CollectManager","title":"<code>labridge.interact.collect.manager.collect_manager.CollectManager</code>","text":"<p>This manager judges whether to abort the collecting process according to the user's response, and whether the collected information need modification.</p> PARAMETER DESCRIPTION <code>llm</code> <p>The used LLM.</p> <p> TYPE: <code>LLM</code> </p> Source code in <code>labridge\\interact\\collect\\manager\\collect_manager.py</code> <pre><code>class CollectManager:\n\tr\"\"\"\n\tThis manager judges whether to abort the collecting process according to the user's response,\n\tand whether the collected information need modification.\n\n\tArgs:\n\t\tllm (LLM): The used LLM.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tllm: LLM,\n\t):\n\t\tself._llm = llm\n\n\tdef analyze_whether_abort(self, user_response: str) -&gt; bool:\n\t\tr\"\"\"\n\t\tWhether the user tends to abort.\n\n\t\tArgs:\n\t\t\tuser_response (str): The user's response.\n\n\t\tReturns:\n\t\t\tbool: Whether to abort or not.\n\t\t\"\"\"\n\t\tabort = condition_analyze(\n\t\t\tllm=self._llm,\n\t\t\tprompt=COLLECT_ABORT_PROMPT,\n\t\t\tcondition_true_word=COLLECT_ABORT_WORD,\n\t\t\tabort_word=COLLECT_ABORT_WORD,\n\t\t\tcontinue_word=COLLECT_CONTINUE_WORD,\n\t\t\tuser_response=user_response,\n\t\t)\n\t\treturn abort\n\n\tasync def async_analyze_whether_abort(self, user_response: str) -&gt; bool:\n\t\tr\"\"\"\n\t\tAsync version.\n\t\tWhether the user tends to abort.\n\n\t\tArgs:\n\t\t\tuser_response (str): The user's response.\n\n\t\tReturns:\n\t\t\tbool: Whether to abort or not.\n\t\t\"\"\"\n\t\tabort = await acondition_analyze(\n\t\t\tllm=self._llm,\n\t\t\tprompt=COLLECT_ABORT_PROMPT,\n\t\t\tcondition_true_word=COLLECT_ABORT_WORD,\n\t\t\tabort_word=COLLECT_ABORT_WORD,\n\t\t\tcontinue_word=COLLECT_CONTINUE_WORD,\n\t\t\tuser_response=user_response,\n\t\t)\n\t\treturn abort\n\n\tasync def async_analyze_whether_modify(\n\t\tself,\n\t\tuser_response: str,\n\t\tcollected_info_dict: Dict[str, str],\n\t) -&gt; bool:\n\t\tr\"\"\"\n\t\tAsync version.\n\t\tWhether the user thinks the collected information need modification.\n\n\t\tArgs:\n\t\t\tuser_response (str): The user's response.\n\n\t\tReturns:\n\t\t\tbool: Whether to modify or not.\n\t\t\"\"\"\n\t\tdo_modify = await acondition_analyze(\n\t\t\tllm=self._llm,\n\t\t\tprompt=WHETHER_MODIFY_INFO_PROMPT,\n\t\t\tcondition_true_word=DO_MODIFY_WORD,\n\t\t\tdo_modify_word=DO_MODIFY_WORD,\n\t\t\tnot_modify_word=NOT_MODIFY_WORD,\n\t\t\tcollected_infos_str=json.dumps(collected_info_dict),\n\t\t\tuser_comment_str=user_response,\n\t\t)\n\t\treturn do_modify\n\n\tdef analyze_whether_modify(\n\t\tself,\n\t\tuser_response: str,\n\t\tcollected_info_dict: Dict[str, str],\n\t) -&gt; bool:\n\t\tr\"\"\"\n\t\tWhether the user thinks the collected information need modification.\n\n\t\tArgs:\n\t\t\tuser_response (str): The user's response.\n\n\t\tReturns:\n\t\t\tbool: Whether to modify or not.\n\t\t\"\"\"\n\t\tdo_modify = condition_analyze(\n\t\t\tllm=self._llm,\n\t\t\tprompt=WHETHER_MODIFY_INFO_PROMPT,\n\t\t\tcondition_true_word=DO_MODIFY_WORD,\n\t\t\tdo_modify_word=DO_MODIFY_WORD,\n\t\t\tnot_modify_word=NOT_MODIFY_WORD,\n\t\t\tcollected_infos_str=json.dumps(collected_info_dict),\n\t\t\tuser_comment_str=user_response,\n\t\t)\n\t\treturn do_modify\n\n\tdef verify_query(self, collected_info_dict: Dict[str, str]) -&gt; str:\n\t\tr\"\"\" This query will be sent to the user to verify the correctness of the collected information. \"\"\"\n\t\tverify_str = f\"{VERIFY_COLLECTED_INFO_QUERY}\\n\"\n\t\tfor key in collected_info_dict.keys():\n\t\t\tverify_str += f\"{key}:\\n\\t{collected_info_dict[key]}\\n\"\n\t\treturn verify_str\n</code></pre>"},{"location":"code_docs/interact/collect/manager/collect_manager/#labridge.interact.collect.manager.collect_manager.CollectManager.analyze_whether_abort","title":"<code>labridge.interact.collect.manager.collect_manager.CollectManager.analyze_whether_abort(user_response)</code>","text":"<p>Whether the user tends to abort.</p> PARAMETER DESCRIPTION <code>user_response</code> <p>The user's response.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>Whether to abort or not.</p> <p> TYPE: <code>bool</code> </p> Source code in <code>labridge\\interact\\collect\\manager\\collect_manager.py</code> <pre><code>def analyze_whether_abort(self, user_response: str) -&gt; bool:\n\tr\"\"\"\n\tWhether the user tends to abort.\n\n\tArgs:\n\t\tuser_response (str): The user's response.\n\n\tReturns:\n\t\tbool: Whether to abort or not.\n\t\"\"\"\n\tabort = condition_analyze(\n\t\tllm=self._llm,\n\t\tprompt=COLLECT_ABORT_PROMPT,\n\t\tcondition_true_word=COLLECT_ABORT_WORD,\n\t\tabort_word=COLLECT_ABORT_WORD,\n\t\tcontinue_word=COLLECT_CONTINUE_WORD,\n\t\tuser_response=user_response,\n\t)\n\treturn abort\n</code></pre>"},{"location":"code_docs/interact/collect/manager/collect_manager/#labridge.interact.collect.manager.collect_manager.CollectManager.analyze_whether_modify","title":"<code>labridge.interact.collect.manager.collect_manager.CollectManager.analyze_whether_modify(user_response, collected_info_dict)</code>","text":"<p>Whether the user thinks the collected information need modification.</p> PARAMETER DESCRIPTION <code>user_response</code> <p>The user's response.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>Whether to modify or not.</p> <p> TYPE: <code>bool</code> </p> Source code in <code>labridge\\interact\\collect\\manager\\collect_manager.py</code> <pre><code>def analyze_whether_modify(\n\tself,\n\tuser_response: str,\n\tcollected_info_dict: Dict[str, str],\n) -&gt; bool:\n\tr\"\"\"\n\tWhether the user thinks the collected information need modification.\n\n\tArgs:\n\t\tuser_response (str): The user's response.\n\n\tReturns:\n\t\tbool: Whether to modify or not.\n\t\"\"\"\n\tdo_modify = condition_analyze(\n\t\tllm=self._llm,\n\t\tprompt=WHETHER_MODIFY_INFO_PROMPT,\n\t\tcondition_true_word=DO_MODIFY_WORD,\n\t\tdo_modify_word=DO_MODIFY_WORD,\n\t\tnot_modify_word=NOT_MODIFY_WORD,\n\t\tcollected_infos_str=json.dumps(collected_info_dict),\n\t\tuser_comment_str=user_response,\n\t)\n\treturn do_modify\n</code></pre>"},{"location":"code_docs/interact/collect/manager/collect_manager/#labridge.interact.collect.manager.collect_manager.CollectManager.async_analyze_whether_abort","title":"<code>labridge.interact.collect.manager.collect_manager.CollectManager.async_analyze_whether_abort(user_response)</code>  <code>async</code>","text":"<p>Async version. Whether the user tends to abort.</p> PARAMETER DESCRIPTION <code>user_response</code> <p>The user's response.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>Whether to abort or not.</p> <p> TYPE: <code>bool</code> </p> Source code in <code>labridge\\interact\\collect\\manager\\collect_manager.py</code> <pre><code>async def async_analyze_whether_abort(self, user_response: str) -&gt; bool:\n\tr\"\"\"\n\tAsync version.\n\tWhether the user tends to abort.\n\n\tArgs:\n\t\tuser_response (str): The user's response.\n\n\tReturns:\n\t\tbool: Whether to abort or not.\n\t\"\"\"\n\tabort = await acondition_analyze(\n\t\tllm=self._llm,\n\t\tprompt=COLLECT_ABORT_PROMPT,\n\t\tcondition_true_word=COLLECT_ABORT_WORD,\n\t\tabort_word=COLLECT_ABORT_WORD,\n\t\tcontinue_word=COLLECT_CONTINUE_WORD,\n\t\tuser_response=user_response,\n\t)\n\treturn abort\n</code></pre>"},{"location":"code_docs/interact/collect/manager/collect_manager/#labridge.interact.collect.manager.collect_manager.CollectManager.async_analyze_whether_modify","title":"<code>labridge.interact.collect.manager.collect_manager.CollectManager.async_analyze_whether_modify(user_response, collected_info_dict)</code>  <code>async</code>","text":"<p>Async version. Whether the user thinks the collected information need modification.</p> PARAMETER DESCRIPTION <code>user_response</code> <p>The user's response.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>Whether to modify or not.</p> <p> TYPE: <code>bool</code> </p> Source code in <code>labridge\\interact\\collect\\manager\\collect_manager.py</code> <pre><code>async def async_analyze_whether_modify(\n\tself,\n\tuser_response: str,\n\tcollected_info_dict: Dict[str, str],\n) -&gt; bool:\n\tr\"\"\"\n\tAsync version.\n\tWhether the user thinks the collected information need modification.\n\n\tArgs:\n\t\tuser_response (str): The user's response.\n\n\tReturns:\n\t\tbool: Whether to modify or not.\n\t\"\"\"\n\tdo_modify = await acondition_analyze(\n\t\tllm=self._llm,\n\t\tprompt=WHETHER_MODIFY_INFO_PROMPT,\n\t\tcondition_true_word=DO_MODIFY_WORD,\n\t\tdo_modify_word=DO_MODIFY_WORD,\n\t\tnot_modify_word=NOT_MODIFY_WORD,\n\t\tcollected_infos_str=json.dumps(collected_info_dict),\n\t\tuser_comment_str=user_response,\n\t)\n\treturn do_modify\n</code></pre>"},{"location":"code_docs/interact/collect/manager/collect_manager/#labridge.interact.collect.manager.collect_manager.CollectManager.verify_query","title":"<code>labridge.interact.collect.manager.collect_manager.CollectManager.verify_query(collected_info_dict)</code>","text":"<p>This query will be sent to the user to verify the correctness of the collected information.</p> Source code in <code>labridge\\interact\\collect\\manager\\collect_manager.py</code> <pre><code>def verify_query(self, collected_info_dict: Dict[str, str]) -&gt; str:\n\tr\"\"\" This query will be sent to the user to verify the correctness of the collected information. \"\"\"\n\tverify_str = f\"{VERIFY_COLLECTED_INFO_QUERY}\\n\"\n\tfor key in collected_info_dict.keys():\n\t\tverify_str += f\"{key}:\\n\\t{collected_info_dict[key]}\\n\"\n\treturn verify_str\n</code></pre>"},{"location":"code_docs/interact/collect/types/common_info/","title":"Common info","text":""},{"location":"code_docs/interact/collect/types/common_info/#labridge.interact.collect.types.common_info","title":"<code>labridge.interact.collect.types.common_info</code>","text":""},{"location":"code_docs/interact/collect/types/common_info/#labridge.interact.collect.types.common_info.CollectingCommonInfo","title":"<code>labridge.interact.collect.types.common_info.CollectingCommonInfo</code>","text":"<p>               Bases: <code>CollectingBatchInfoBase</code></p> <p>This class defines the common information to be collected from the user. The common information can be collected in batch mode.</p> PARAMETER DESCRIPTION <code>info_name</code> <p>The name of the information to be collected.</p> <p> TYPE: <code>str</code> </p> <code>info_description</code> <p>The description of the information to be collected.</p> <p> TYPE: <code>str</code> </p> Source code in <code>labridge\\interact\\collect\\types\\common_info.py</code> <pre><code>class CollectingCommonInfo(CollectingBatchInfoBase):\n\tr\"\"\"\n\tThis class defines the common information to be collected from the user.\n\tThe common information can be collected in batch mode.\n\n\tArgs:\n\t\tinfo_name (str): The name of the information to be collected.\n\t\tinfo_description (str): The description of the information to be collected.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tinfo_name: str,\n\t\tinfo_description: str,\n\t):\n\t\tself.info_dict = {\n\t\t\tCollectPromptKeys.required_infos_key: {info_name: info_description}\n\t\t}\n\t\tsuper().__init__(\n\t\t\tinfo_name=info_name,\n\t\t\tinfo_description=info_description,\n\t\t\tinfo_type=CollectingInfoType.COMMON,\n\t\t)\n\n\tdef insert_info(self, info: CollectingInfoBase):\n\t\tr\"\"\"\n\t\tInsert a new CommonInfo to current one.\n\n\t\tArgs:\n\t\t\tinfo (CollectingInfoBase): The new CollectingCommonInfo.\n\n\t\tReturns:\n\t\t\tNone.\n\t\t\"\"\"\n\t\tself.info_dict[CollectPromptKeys.required_infos_key].update(\n\t\t\t{info.info_name: info.info_description}\n\t\t)\n\n\tdef _collected(self) -&gt; bool:\n\t\tr\"\"\" Whether all information is collected. \"\"\"\n\t\treturn len(self.collecting_keys) == 0\n\n\tdef _required_infos(self) -&gt; Dict[str, str]:\n\t\tr\"\"\" Return the required information names and descriptions. \"\"\"\n\t\treturn self.info_dict[CollectPromptKeys.required_infos_key]\n\n\tdef update_collected_info(self, collected_info_dict: Dict[str, str]):\n\t\tr\"\"\" Update the collected information. \"\"\"\n\t\tfor key in collected_info_dict.keys():\n\t\t\tif key in self.required_infos:\n\t\t\t\tself._collected_infos[key] = collected_info_dict[key]\n\n\tdef _collecting_keys(self) -&gt; List[str]:\n\t\tr\"\"\" Return the information names to be collected currently. \"\"\"\n\t\tcollecting_keys = set(self.required_infos.keys()) - set(self._collected_infos.keys())\n\t\treturn list(collecting_keys)\n\n\tdef info_content(self) -&gt; Iterator[Dict[str, str]]:\n\t\tr\"\"\" Yield a batch of information names and descriptions to the LLM for extraction \"\"\"\n\t\tinfo_keys = self.collecting_keys\n\t\tinfo_num = len(info_keys)\n\t\tstart = 0\n\t\twhile start &lt; info_num:\n\t\t\tbatch_keys = info_keys[start: start + COMMON_COLLECT_BATCH_SIZE]\n\t\t\tstart += COMMON_COLLECT_BATCH_SIZE\n\t\t\tbatch_info = {key: self.required_infos[key] for key in batch_keys}\n\t\t\tyield {\n\t\t\t\tCollectPromptKeys.required_infos_key: json.dumps(batch_info),\n\t\t\t\tCollectPromptKeys.extra_info_key: DEFAULT_EXTRA_INFO,\n\t\t\t}\n\n\tdef modify_info_content(self) -&gt; Iterator[Dict[str, str]]:\n\t\tr\"\"\" Yield a batch of information names, descriptions and collected content to the LLM for modification. \"\"\"\n\t\tinfo_keys = list(self.collected_infos.keys())\n\t\tinfo_num = len(info_keys)\n\t\tstart = 0\n\t\twhile start &lt; info_num:\n\t\t\tbatch_keys = info_keys[start: start + COMMON_COLLECT_BATCH_SIZE]\n\t\t\tstart += COMMON_COLLECT_BATCH_SIZE\n\t\t\tbatch_info = {key: self.required_infos[key] for key in batch_keys}\n\t\t\tbatch_collected_info = {key: self.collected_infos[key] for key in batch_keys}\n\t\t\tyield {\n\t\t\t\tModifyPromptKeys.required_infos_key: json.dumps(batch_info),\n\t\t\t\tModifyPromptKeys.collected_infos_key: json.dumps(batch_collected_info),\n\t\t\t\tModifyPromptKeys.extra_info_key: DEFAULT_EXTRA_INFO,\n\t\t\t}\n</code></pre>"},{"location":"code_docs/interact/collect/types/common_info/#labridge.interact.collect.types.common_info.CollectingCommonInfo.info_content","title":"<code>labridge.interact.collect.types.common_info.CollectingCommonInfo.info_content()</code>","text":"<p>Yield a batch of information names and descriptions to the LLM for extraction</p> Source code in <code>labridge\\interact\\collect\\types\\common_info.py</code> <pre><code>def info_content(self) -&gt; Iterator[Dict[str, str]]:\n\tr\"\"\" Yield a batch of information names and descriptions to the LLM for extraction \"\"\"\n\tinfo_keys = self.collecting_keys\n\tinfo_num = len(info_keys)\n\tstart = 0\n\twhile start &lt; info_num:\n\t\tbatch_keys = info_keys[start: start + COMMON_COLLECT_BATCH_SIZE]\n\t\tstart += COMMON_COLLECT_BATCH_SIZE\n\t\tbatch_info = {key: self.required_infos[key] for key in batch_keys}\n\t\tyield {\n\t\t\tCollectPromptKeys.required_infos_key: json.dumps(batch_info),\n\t\t\tCollectPromptKeys.extra_info_key: DEFAULT_EXTRA_INFO,\n\t\t}\n</code></pre>"},{"location":"code_docs/interact/collect/types/common_info/#labridge.interact.collect.types.common_info.CollectingCommonInfo.insert_info","title":"<code>labridge.interact.collect.types.common_info.CollectingCommonInfo.insert_info(info)</code>","text":"<p>Insert a new CommonInfo to current one.</p> PARAMETER DESCRIPTION <code>info</code> <p>The new CollectingCommonInfo.</p> <p> TYPE: <code>CollectingInfoBase</code> </p> RETURNS DESCRIPTION <p>None.</p> Source code in <code>labridge\\interact\\collect\\types\\common_info.py</code> <pre><code>def insert_info(self, info: CollectingInfoBase):\n\tr\"\"\"\n\tInsert a new CommonInfo to current one.\n\n\tArgs:\n\t\tinfo (CollectingInfoBase): The new CollectingCommonInfo.\n\n\tReturns:\n\t\tNone.\n\t\"\"\"\n\tself.info_dict[CollectPromptKeys.required_infos_key].update(\n\t\t{info.info_name: info.info_description}\n\t)\n</code></pre>"},{"location":"code_docs/interact/collect/types/common_info/#labridge.interact.collect.types.common_info.CollectingCommonInfo.modify_info_content","title":"<code>labridge.interact.collect.types.common_info.CollectingCommonInfo.modify_info_content()</code>","text":"<p>Yield a batch of information names, descriptions and collected content to the LLM for modification.</p> Source code in <code>labridge\\interact\\collect\\types\\common_info.py</code> <pre><code>def modify_info_content(self) -&gt; Iterator[Dict[str, str]]:\n\tr\"\"\" Yield a batch of information names, descriptions and collected content to the LLM for modification. \"\"\"\n\tinfo_keys = list(self.collected_infos.keys())\n\tinfo_num = len(info_keys)\n\tstart = 0\n\twhile start &lt; info_num:\n\t\tbatch_keys = info_keys[start: start + COMMON_COLLECT_BATCH_SIZE]\n\t\tstart += COMMON_COLLECT_BATCH_SIZE\n\t\tbatch_info = {key: self.required_infos[key] for key in batch_keys}\n\t\tbatch_collected_info = {key: self.collected_infos[key] for key in batch_keys}\n\t\tyield {\n\t\t\tModifyPromptKeys.required_infos_key: json.dumps(batch_info),\n\t\t\tModifyPromptKeys.collected_infos_key: json.dumps(batch_collected_info),\n\t\t\tModifyPromptKeys.extra_info_key: DEFAULT_EXTRA_INFO,\n\t\t}\n</code></pre>"},{"location":"code_docs/interact/collect/types/common_info/#labridge.interact.collect.types.common_info.CollectingCommonInfo.update_collected_info","title":"<code>labridge.interact.collect.types.common_info.CollectingCommonInfo.update_collected_info(collected_info_dict)</code>","text":"<p>Update the collected information.</p> Source code in <code>labridge\\interact\\collect\\types\\common_info.py</code> <pre><code>def update_collected_info(self, collected_info_dict: Dict[str, str]):\n\tr\"\"\" Update the collected information. \"\"\"\n\tfor key in collected_info_dict.keys():\n\t\tif key in self.required_infos:\n\t\t\tself._collected_infos[key] = collected_info_dict[key]\n</code></pre>"},{"location":"code_docs/interact/collect/types/info_base/","title":"Info base","text":""},{"location":"code_docs/interact/collect/types/info_base/#labridge.interact.collect.types.info_base","title":"<code>labridge.interact.collect.types.info_base</code>","text":""},{"location":"code_docs/interact/collect/types/info_base/#labridge.interact.collect.types.info_base.CollectingBatchInfoBase","title":"<code>labridge.interact.collect.types.info_base.CollectingBatchInfoBase</code>","text":"<p>               Bases: <code>CollectingInfoBase</code></p> <p>The CollectingInfo which can be collected in a batch mode.</p> Source code in <code>labridge\\interact\\collect\\types\\info_base.py</code> <pre><code>class CollectingBatchInfoBase(CollectingInfoBase):\n\tr\"\"\"\n\tThe CollectingInfo which can be collected in a batch mode.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tinfo_name: str,\n\t\tinfo_description: str,\n\t\tinfo_type: CollectingInfoType,\n\t):\n\t\tsuper().__init__(\n\t\t\tinfo_name=info_name,\n\t\t\tinfo_description=info_description,\n\t\t\tinfo_type=info_type,\n\t\t\tbatch_mode=True,\n\t\t)\n\n\t@abstractmethod\n\tdef insert_info(self, **kwargs):\n\t\tr\"\"\" insert info \"\"\"\n</code></pre>"},{"location":"code_docs/interact/collect/types/info_base/#labridge.interact.collect.types.info_base.CollectingBatchInfoBase.insert_info","title":"<code>labridge.interact.collect.types.info_base.CollectingBatchInfoBase.insert_info(**kwargs)</code>  <code>abstractmethod</code>","text":"<p>insert info</p> Source code in <code>labridge\\interact\\collect\\types\\info_base.py</code> <pre><code>@abstractmethod\ndef insert_info(self, **kwargs):\n\tr\"\"\" insert info \"\"\"\n</code></pre>"},{"location":"code_docs/interact/collect/types/info_base/#labridge.interact.collect.types.info_base.CollectingInfoBase","title":"<code>labridge.interact.collect.types.info_base.CollectingInfoBase</code>","text":"<p>This is the base class for the CollectingInfo.</p> PARAMETER DESCRIPTION <code>info_name</code> <p>The information name.</p> <p> TYPE: <code>str</code> </p> <code>info_description</code> <p>The information description.</p> <p> TYPE: <code>str</code> </p> <code>info_type</code> <p>The information type.</p> <p> TYPE: <code>CollectingInfoType</code> </p> <code>batch_mode</code> <p>Whether the information can be collected in a batch mode.</p> <p> TYPE: <code>bool</code> </p> Source code in <code>labridge\\interact\\collect\\types\\info_base.py</code> <pre><code>class CollectingInfoBase:\n\tr\"\"\"\n\tThis is the base class for the CollectingInfo.\n\n\tArgs:\n\t\tinfo_name (str): The information name.\n\t\tinfo_description (str): The information description.\n\t\tinfo_type (CollectingInfoType): The information type.\n\t\tbatch_mode (bool): Whether the information can be collected in a batch mode.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tinfo_name: str,\n\t\tinfo_description: str,\n\t\tinfo_type: CollectingInfoType,\n\t\tbatch_mode: bool,\n\t):\n\t\tself.info_name = info_name\n\t\tself.info_description = info_description\n\t\tself.info_type = info_type\n\t\tself._batch_mode = batch_mode\n\t\tself._collect_finish = False\n\t\tself._collected_infos = {}\n\n\t@abstractmethod\n\tdef info_content(self) -&gt; Dict[str, str]:\n\t\tr\"\"\" Yield the information to the LLM for extraction. \"\"\"\n\n\t@abstractmethod\n\tdef _required_infos(self) -&gt; Dict[str, str]:\n\t\tr\"\"\" Required infos \"\"\"\n\n\t@abstractmethod\n\tdef update_collected_info(self, collected_info):\n\t\tr\"\"\" Update self._collected_infos \"\"\"\n\n\t@property\n\tdef required_infos(self) -&gt; Dict[str, str]:\n\t\tr\"\"\" Required infos \"\"\"\n\t\treturn self._required_infos()\n\n\t@property\n\tdef batch_mode(self) -&gt; bool:\n\t\treturn self._batch_mode\n\n\t@abstractmethod\n\tdef _collected(self) -&gt; bool:\n\t\tr\"\"\" Whether the collecting process ends. \"\"\"\n\n\t@property\n\tdef collected(self) -&gt; bool:\n\t\tr\"\"\" Whether all required infos are collected. \"\"\"\n\t\treturn self._collected()\n\n\t@property\n\tdef collected_infos(self) -&gt; dict:\n\t\tr\"\"\" Return the collected info . \"\"\"\n\t\treturn self._collected_infos\n\n\t@abstractmethod\n\tdef _collecting_keys(self) -&gt; List[str]:\n\t\tr\"\"\" The keys in collecting. \"\"\"\n\n\t@property\n\tdef collecting_keys(self) -&gt; List[str]:\n\t\tr\"\"\" The collecting information names. \"\"\"\n\t\treturn self._collecting_keys()\n</code></pre>"},{"location":"code_docs/interact/collect/types/info_base/#labridge.interact.collect.types.info_base.CollectingInfoBase.collected","title":"<code>labridge.interact.collect.types.info_base.CollectingInfoBase.collected: bool</code>  <code>property</code>","text":"<p>Whether all required infos are collected.</p>"},{"location":"code_docs/interact/collect/types/info_base/#labridge.interact.collect.types.info_base.CollectingInfoBase.collected_infos","title":"<code>labridge.interact.collect.types.info_base.CollectingInfoBase.collected_infos: dict</code>  <code>property</code>","text":"<p>Return the collected info .</p>"},{"location":"code_docs/interact/collect/types/info_base/#labridge.interact.collect.types.info_base.CollectingInfoBase.collecting_keys","title":"<code>labridge.interact.collect.types.info_base.CollectingInfoBase.collecting_keys: List[str]</code>  <code>property</code>","text":"<p>The collecting information names.</p>"},{"location":"code_docs/interact/collect/types/info_base/#labridge.interact.collect.types.info_base.CollectingInfoBase.required_infos","title":"<code>labridge.interact.collect.types.info_base.CollectingInfoBase.required_infos: Dict[str, str]</code>  <code>property</code>","text":"<p>Required infos</p>"},{"location":"code_docs/interact/collect/types/info_base/#labridge.interact.collect.types.info_base.CollectingInfoBase.info_content","title":"<code>labridge.interact.collect.types.info_base.CollectingInfoBase.info_content()</code>  <code>abstractmethod</code>","text":"<p>Yield the information to the LLM for extraction.</p> Source code in <code>labridge\\interact\\collect\\types\\info_base.py</code> <pre><code>@abstractmethod\ndef info_content(self) -&gt; Dict[str, str]:\n\tr\"\"\" Yield the information to the LLM for extraction. \"\"\"\n</code></pre>"},{"location":"code_docs/interact/collect/types/info_base/#labridge.interact.collect.types.info_base.CollectingInfoBase.update_collected_info","title":"<code>labridge.interact.collect.types.info_base.CollectingInfoBase.update_collected_info(collected_info)</code>  <code>abstractmethod</code>","text":"<p>Update self._collected_infos</p> Source code in <code>labridge\\interact\\collect\\types\\info_base.py</code> <pre><code>@abstractmethod\ndef update_collected_info(self, collected_info):\n\tr\"\"\" Update self._collected_infos \"\"\"\n</code></pre>"},{"location":"code_docs/interact/collect/types/select_info/","title":"Select info","text":""},{"location":"code_docs/interact/collect/types/select_info/#labridge.interact.collect.types.select_info","title":"<code>labridge.interact.collect.types.select_info</code>","text":""},{"location":"code_docs/interact/collect/types/select_info/#labridge.interact.collect.types.select_info.CollectingSelectInfo","title":"<code>labridge.interact.collect.types.select_info.CollectingSelectInfo</code>","text":"<p>               Bases: <code>CollectingInfoBase</code></p> <p>This class defines the select information to be collected from the user. The select information should be selected between several given choices.</p> PARAMETER DESCRIPTION <code>info_name</code> <p>The name of the information to be collected.</p> <p> TYPE: <code>str</code> </p> <code>info_description</code> <p>The description of the information to be collected.</p> <p> TYPE: <code>str</code> </p> <code>choices</code> <p>The given choices.</p> <ul> <li>key (str): The choice.</li> <li>value (str): The description of the choice.</li> </ul> <p> TYPE: <code>Dict[str, str]</code> </p> Source code in <code>labridge\\interact\\collect\\types\\select_info.py</code> <pre><code>class CollectingSelectInfo(CollectingInfoBase):\n\tr\"\"\"\n\tThis class defines the select information to be collected from the user.\n\tThe select information should be selected between several given choices.\n\n\tArgs:\n\t\tinfo_name (str): The name of the information to be collected.\n\t\tinfo_description (str): The description of the information to be collected.\n\t\tchoices (Dict[str, str]):\n\t\t\tThe given choices.\n\n\t\t\t- key (str): The choice.\n\t\t\t- value (str): The description of the choice.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tinfo_name: str,\n\t\tinfo_description: str,\n\t\tchoices: Dict[str, str],\n\t):\n\t\tself._choices = choices\n\t\tsuper().__init__(\n\t\t\tinfo_name=info_name,\n\t\t\tinfo_description=info_description,\n\t\t\tinfo_type=CollectingInfoType.SELECT,\n\t\t\tbatch_mode=False,\n\t\t)\n\n\tdef _collected(self) -&gt; bool:\n\t\tr\"\"\" Whether all information is collected. \"\"\"\n\t\treturn self.info_name in self._collected_infos.keys()\n\n\tdef update_collected_info(self, collected_info_dict: Dict[str, str]):\n\t\tr\"\"\" Update the collected information. \"\"\"\n\t\tif self.info_name in collected_info_dict:\n\t\t\tself._collected_infos[self.info_name] = collected_info_dict[self.info_name]\n\n\tdef _required_infos(self) -&gt; Dict[str, str]:\n\t\tr\"\"\" Return the required information names and descriptions. \"\"\"\n\t\treturn {self.info_name: self.info_description}\n\n\tdef _collecting_keys(self) -&gt; List[str]:\n\t\tr\"\"\" Return the information names to be collected currently. \"\"\"\n\t\tif self.collected:\n\t\t\treturn []\n\t\treturn [self.info_name]\n\n\t@property\n\tdef candidates(self) -&gt; List[str]:\n\t\tr\"\"\" Get the candidates \"\"\"\n\t\treturn list(self._choices.keys())\n\n\tdef _extra_info_format(self, choice_keys: List[str]) -&gt; str:\n\t\tr\"\"\" The prompt format for selecting. \"\"\"\n\t\tcontents = []\n\t\tfor idx, key in enumerate(choice_keys):\n\t\t\tcontent = f\"Paragraph {idx + 1}\\n\"\n\t\t\tcontent += f\"Name: {key}\\nDescription: {self._choices[key]}\".strip()\n\t\t\tcontents.append(content)\n\t\tchoices_str = \"\\n\\n\".join(contents)\n\t\treturn choices_str\n\n\tdef info_content(self) -&gt; Iterator[Tuple[Dict[str, str], List[str]]]:\n\t\tr\"\"\" Yield the information name, description and corresponding choices to the LLM for selection. \"\"\"\n\t\trequired_infos_str = json.dumps({self.info_name: self.info_description})\n\t\tcandidates = self.candidates\n\t\tif not self.collected:\n\t\t\tfor idx in range(0, len(candidates), SELECT_CHOICE_BATCH_SIZE):\n\t\t\t\textra_info = self._extra_info_format(choice_keys=candidates[idx: idx + SELECT_CHOICE_BATCH_SIZE])\n\t\t\t\tyield {\n\t\t\t\t\tCollectPromptKeys.required_infos_key: required_infos_str,\n\t\t\t\t\tCollectPromptKeys.extra_info_key: extra_info,\n\t\t\t\t}, candidates[idx: idx + SELECT_CHOICE_BATCH_SIZE]\n\n\tdef modify_info_content(self) -&gt; Iterator[Tuple[Dict[str, str], List[str]]]:\n\t\tr\"\"\" Yield the information name, description, collected content and corresponding choices to the LLM for modification. \"\"\"\n\t\trequired_infos_str = json.dumps({self.info_name: self.info_description})\n\t\tcandidates = self.candidates\n\t\tfor idx in range(0, len(candidates), SELECT_CHOICE_BATCH_SIZE):\n\t\t\textra_info = self._extra_info_format(choice_keys=candidates[idx: idx + SELECT_CHOICE_BATCH_SIZE])\n\t\t\tyield {\n\t\t\t\tCollectPromptKeys.required_infos_key: required_infos_str,\n\t\t\t\tModifyPromptKeys.collected_infos_key: json.dumps(self.collected_infos),\n\t\t\t\tCollectPromptKeys.extra_info_key: extra_info,\n\t\t\t}, candidates[idx: idx + SELECT_CHOICE_BATCH_SIZE]\n</code></pre>"},{"location":"code_docs/interact/collect/types/select_info/#labridge.interact.collect.types.select_info.CollectingSelectInfo.candidates","title":"<code>labridge.interact.collect.types.select_info.CollectingSelectInfo.candidates: List[str]</code>  <code>property</code>","text":"<p>Get the candidates</p>"},{"location":"code_docs/interact/collect/types/select_info/#labridge.interact.collect.types.select_info.CollectingSelectInfo.info_content","title":"<code>labridge.interact.collect.types.select_info.CollectingSelectInfo.info_content()</code>","text":"<p>Yield the information name, description and corresponding choices to the LLM for selection.</p> Source code in <code>labridge\\interact\\collect\\types\\select_info.py</code> <pre><code>def info_content(self) -&gt; Iterator[Tuple[Dict[str, str], List[str]]]:\n\tr\"\"\" Yield the information name, description and corresponding choices to the LLM for selection. \"\"\"\n\trequired_infos_str = json.dumps({self.info_name: self.info_description})\n\tcandidates = self.candidates\n\tif not self.collected:\n\t\tfor idx in range(0, len(candidates), SELECT_CHOICE_BATCH_SIZE):\n\t\t\textra_info = self._extra_info_format(choice_keys=candidates[idx: idx + SELECT_CHOICE_BATCH_SIZE])\n\t\t\tyield {\n\t\t\t\tCollectPromptKeys.required_infos_key: required_infos_str,\n\t\t\t\tCollectPromptKeys.extra_info_key: extra_info,\n\t\t\t}, candidates[idx: idx + SELECT_CHOICE_BATCH_SIZE]\n</code></pre>"},{"location":"code_docs/interact/collect/types/select_info/#labridge.interact.collect.types.select_info.CollectingSelectInfo.modify_info_content","title":"<code>labridge.interact.collect.types.select_info.CollectingSelectInfo.modify_info_content()</code>","text":"<p>Yield the information name, description, collected content and corresponding choices to the LLM for modification.</p> Source code in <code>labridge\\interact\\collect\\types\\select_info.py</code> <pre><code>def modify_info_content(self) -&gt; Iterator[Tuple[Dict[str, str], List[str]]]:\n\tr\"\"\" Yield the information name, description, collected content and corresponding choices to the LLM for modification. \"\"\"\n\trequired_infos_str = json.dumps({self.info_name: self.info_description})\n\tcandidates = self.candidates\n\tfor idx in range(0, len(candidates), SELECT_CHOICE_BATCH_SIZE):\n\t\textra_info = self._extra_info_format(choice_keys=candidates[idx: idx + SELECT_CHOICE_BATCH_SIZE])\n\t\tyield {\n\t\t\tCollectPromptKeys.required_infos_key: required_infos_str,\n\t\t\tModifyPromptKeys.collected_infos_key: json.dumps(self.collected_infos),\n\t\t\tCollectPromptKeys.extra_info_key: extra_info,\n\t\t}, candidates[idx: idx + SELECT_CHOICE_BATCH_SIZE]\n</code></pre>"},{"location":"code_docs/interact/collect/types/select_info/#labridge.interact.collect.types.select_info.CollectingSelectInfo.update_collected_info","title":"<code>labridge.interact.collect.types.select_info.CollectingSelectInfo.update_collected_info(collected_info_dict)</code>","text":"<p>Update the collected information.</p> Source code in <code>labridge\\interact\\collect\\types\\select_info.py</code> <pre><code>def update_collected_info(self, collected_info_dict: Dict[str, str]):\n\tr\"\"\" Update the collected information. \"\"\"\n\tif self.info_name in collected_info_dict:\n\t\tself._collected_infos[self.info_name] = collected_info_dict[self.info_name]\n</code></pre>"},{"location":"code_docs/interact/prompt/authorize/analyze_agree/","title":"Analyze agree","text":""},{"location":"code_docs/interact/prompt/authorize/analyze_agree/#labridge.interact.prompt.authorize.analyze_agree","title":"<code>labridge.interact.prompt.authorize.analyze_agree</code>","text":""},{"location":"code_docs/interact/prompt/collect/collect_info/common_info/","title":"Common info","text":""},{"location":"code_docs/interact/prompt/collect/collect_info/common_info/#labridge.interact.prompt.collect.collect_info.common_info","title":"<code>labridge.interact.prompt.collect.collect_info.common_info</code>","text":""},{"location":"code_docs/interact/prompt/collect/collect_info/prompt_keys/","title":"Prompt keys","text":""},{"location":"code_docs/interact/prompt/collect/collect_info/prompt_keys/#labridge.interact.prompt.collect.collect_info.prompt_keys","title":"<code>labridge.interact.prompt.collect.collect_info.prompt_keys</code>","text":""},{"location":"code_docs/interact/prompt/collect/collect_info/select_info/","title":"Select info","text":""},{"location":"code_docs/interact/prompt/collect/collect_info/select_info/#labridge.interact.prompt.collect.collect_info.select_info","title":"<code>labridge.interact.prompt.collect.collect_info.select_info</code>","text":""},{"location":"code_docs/interact/prompt/collect/manager/abort/","title":"Abort","text":""},{"location":"code_docs/interact/prompt/collect/manager/abort/#labridge.interact.prompt.collect.manager.abort","title":"<code>labridge.interact.prompt.collect.manager.abort</code>","text":""},{"location":"code_docs/interact/prompt/collect/manager/do_modify/","title":"Do modify","text":""},{"location":"code_docs/interact/prompt/collect/manager/do_modify/#labridge.interact.prompt.collect.manager.do_modify","title":"<code>labridge.interact.prompt.collect.manager.do_modify</code>","text":""},{"location":"code_docs/interact/prompt/collect/manager/verify/","title":"Verify","text":""},{"location":"code_docs/interact/prompt/collect/manager/verify/#labridge.interact.prompt.collect.manager.verify","title":"<code>labridge.interact.prompt.collect.manager.verify</code>","text":""},{"location":"code_docs/interact/prompt/collect/modify_info/common_info/","title":"Common info","text":""},{"location":"code_docs/interact/prompt/collect/modify_info/common_info/#labridge.interact.prompt.collect.modify_info.common_info","title":"<code>labridge.interact.prompt.collect.modify_info.common_info</code>","text":""},{"location":"code_docs/interact/prompt/collect/modify_info/prompt_keys/","title":"Prompt keys","text":""},{"location":"code_docs/interact/prompt/collect/modify_info/prompt_keys/#labridge.interact.prompt.collect.modify_info.prompt_keys","title":"<code>labridge.interact.prompt.collect.modify_info.prompt_keys</code>","text":""},{"location":"code_docs/interact/prompt/collect/modify_info/select_info/","title":"Select info","text":""},{"location":"code_docs/interact/prompt/collect/modify_info/select_info/#labridge.interact.prompt.collect.modify_info.select_info","title":"<code>labridge.interact.prompt.collect.modify_info.select_info</code>","text":""},{"location":"code_docs/interface/http_server/","title":"Http server","text":""},{"location":"code_docs/interface/http_server/#labridge.interface.http_server","title":"<code>labridge.interface.http_server</code>","text":""},{"location":"code_docs/interface/utils/","title":"Utils","text":""},{"location":"code_docs/interface/utils/#labridge.interface.utils","title":"<code>labridge.interface.utils</code>","text":""},{"location":"code_docs/models/local/mindspore_models/","title":"Mindspore models","text":""},{"location":"code_docs/models/local/mindspore_models/#labridge.models.local.mindspore_models","title":"<code>labridge.models.local.mindspore_models</code>","text":""},{"location":"code_docs/models/local/mindspore_models/#labridge.models.local.mindspore_models.MindsporeEmbedding","title":"<code>labridge.models.local.mindspore_models.MindsporeEmbedding</code>","text":"<p>               Bases: <code>BaseEmbedding</code></p> <p>The Embedding model based on Mindspore framework and MindNLP.</p> ATTRIBUTE DESCRIPTION <code>cache_folder</code> <p>Cache folder for Hugging Face files.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>normalize</code> <p>Normalize embeddings or not.</p> <p> TYPE: <code>bool</code> </p> <code>query_instruction</code> <p>Instruction to prepend to query text.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>text_instruction</code> <p>Instruction to prepend to text.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>_embed_model</code> <p>The loaded embedding model.</p> <p> TYPE: <code>SentenceTransformer</code> </p> <code>_device</code> <p>The deployed device.</p> <p> TYPE: <code>str</code> </p> Source code in <code>labridge\\models\\local\\mindspore_models.py</code> <pre><code>class MindsporeEmbedding(BaseEmbedding):\n\tr\"\"\"\n\tThe Embedding model based on Mindspore framework and MindNLP.\n\n\tAttributes:\n\t\tcache_folder (Optional[str]): Cache folder for Hugging Face files.\n\t\tnormalize (bool): Normalize embeddings or not.\n\t\tquery_instruction (Optional[str]): Instruction to prepend to query text.\n\t\ttext_instruction (Optional[str]): Instruction to prepend to text.\n\t\t_embed_model (SentenceTransformer): The loaded embedding model.\n\t\t_device (str): The deployed device.\n\t\"\"\"\n\tcache_folder: Optional[str] = Field(\n\t\tdescription=\"Cache folder for Hugging Face files.\"\n\t)\n\tnormalize: bool = Field(\n\t\tdefault=True,\n\t\tdescription=\"Normalize embeddings or not.\"\n\t)\n\tquery_instruction: Optional[str] = Field(\n\t\tdescription=\"Instruction to prepend to query text.\"\n\t)\n\ttext_instruction: Optional[str] = Field(\n\t\tdescription=\"Instruction to prepend to text.\"\n\t)\n\t_embed_model: Any = PrivateAttr()\n\t_device: str = PrivateAttr()\n\n\tdef __init__(\n\t\tself,\n\t\tmodel_name: str = DEFAULT_MINDSPORE_EMBEDDING,\n\t\tdevice: str = \"Ascend\",\n\t\tquery_instruction: Optional[str] = None,\n\t\ttext_instruction: Optional[str] = None,\n\t\tnormalize: bool = True,\n\t\tembed_batch_size: int = DEFAULT_EMBED_BATCH_SIZE,\n\t\tcache_folder: Optional[str] = None,\n\t):\n\t\tsuper().__init__(\n\t\t\tmodel_name=model_name,\n\t\t\tembed_batch_size=embed_batch_size,\n\t\t\tnormalize = normalize,\n\t\t)\n\t\tcache_folder = cache_folder or get_cache_dir()\n\t\tself._device = device\n\n\t\tself._embed_model = SentenceTransformer(\n\t\t\tmodel_name_or_path=model_name,\n\t\t\tdevice=\"CPU\",\n\t\t\tcache_folder=cache_folder,\n\t\t\tprompts={\n\t\t\t\t\"query\": query_instruction\n\t\t\t\t\t\t or get_query_instruct_for_model_name(model_name),\n\t\t\t\t\"text\": text_instruction\n\t\t\t\t\t\tor get_text_instruct_for_model_name(model_name),\n\t\t\t}\n\t\t)\n\n\tdef _get_query_embedding(self, query: str) -&gt; Embedding:\n\t\tr\"\"\" Get the embeddings of a query from the Mindspore embedding model. \"\"\"\n\t\treturn self._embed(query, prompt_name=\"query\")\n\n\tdef _embed(\n\t\tself,\n\t\tsentences: str,\n\t\tprompt_name: Optional[str] = None,\n\t) -&gt; Embedding:\n\t\tr\"\"\" Mindspore embedding. \"\"\"\n\t\tembedding = self._embed_model.encode(\n\t\t\tsentences,\n\t\t\tprompt_name=prompt_name,\n\t\t\tbatch_size=self.embed_batch_size,\n\t\t\tnormalize_embeddings=True,\n\t\t)\n\t\treturn list(embedding.numpy())\n\n\tasync def _aget_query_embedding(self, query: str) -&gt; Embedding:\n\t\treturn self._get_query_embedding(query=query)\n\n\tdef _get_text_embedding(self, text: str) -&gt; Embedding:\n\t\tr\"\"\" Get the embeddings of a text from the Mindspore embedding model. \"\"\"\n\t\treturn self._embed(text, prompt_name=\"text\")\n</code></pre>"},{"location":"code_docs/models/local/mindspore_models/#labridge.models.local.mindspore_models.MindsporeLLM","title":"<code>labridge.models.local.mindspore_models.MindsporeLLM</code>","text":"<p>               Bases: <code>CustomLLM</code></p> <p>The LLM based on Mindspore framework and MindNLP.</p> ATTRIBUTE DESCRIPTION <code>model_name</code> <p>The model name to use from HuggingFace or local model directory.</p> <p> TYPE: <code>str</code> </p> <code>tokenizer_name</code> <p>The name of the tokenizer to use from HuggingFace.</p> <p> TYPE: <code>str</code> </p> <code>context_window</code> <p>The maximum number of tokens available for input.</p> <p> TYPE: <code>int</code> </p> <code>max_new_tokens</code> <p>The maximum number of tokens to generate.</p> <p> TYPE: <code>int</code> </p> <code>generate_kwargs</code> <p>The kwargs to pass to the model during generation.</p> <p> TYPE: <code>dict</code> </p> <code>is_chat_model</code> <p>is a chat model or not.</p> <p> TYPE: <code>bool</code> </p> <code>_model</code> <p>The loaded model.</p> <p> TYPE: <code>AutoModelForCausalLM</code> </p> <code>_tokenizer</code> <p>The loaded tokenizer.</p> <p> TYPE: <code>AutoTokenizer</code> </p> Source code in <code>labridge\\models\\local\\mindspore_models.py</code> <pre><code>class MindsporeLLM(CustomLLM):\n\tr\"\"\"\n\tThe LLM based on Mindspore framework and MindNLP.\n\n\tAttributes:\n\t\tmodel_name (str): The model name to use from HuggingFace or local model directory.\n\t\ttokenizer_name (str): The name of the tokenizer to use from HuggingFace.\n\t\tcontext_window (int): The maximum number of tokens available for input.\n\t\tmax_new_tokens (int): The maximum number of tokens to generate.\n\t\tgenerate_kwargs (dict): The kwargs to pass to the model during generation.\n\t\tis_chat_model (bool): is a chat model or not.\n\t\t_model (AutoModelForCausalLM): The loaded model.\n\t\t_tokenizer (AutoTokenizer): The loaded tokenizer.\n\t\"\"\"\n\tnum_output: int = 1024\n\n\tmodel_name: str = Field(\n\t\tdefault=DEFAULT_MINDSPORE_MODEL,\n\t\tdescription=(\n\t\t\t\"The model name to use from HuggingFace. \"\n\t\t),\n\t)\n\ttokenizer_name: str = Field(\n\t\tdefault=DEFAULT_MINDSPORE_MODEL,\n\t\tdescription=(\n\t\t\t\"The name of the tokenizer to use from HuggingFace. \"\n\t\t\t\"Unused if `tokenizer` is passed in directly.\"\n\t\t),\n\t)\n\tcontext_window: int = Field(\n\t\tdefault=DEFAULT_CONTEXT_WINDOW,\n\t\tdescription=\"The maximum number of tokens available for input.\",\n\t\tgt=0,\n\t)\n\tmax_new_tokens: int = Field(\n\t\tdefault=DEFAULT_NUM_OUTPUTS,\n\t\tdescription=\"The maximum number of tokens to generate.\",\n\t\tgt=0,\n\t)\n\tgenerate_kwargs: dict = Field(\n\t\tdefault=DEFAULT_MINDSPORE_GENERATE_KWARGS,\n\t\t# default_factory=dict,\n\t\tdescription=\"The kwargs to pass to the model during generation.\",\n\t)\n\tis_chat_model: bool = Field(\n\t\tdefault=False,\n\t\tdescription=(\n\t\t\t\tLLMMetadata.__fields__[\"is_chat_model\"].field_info.description\n\t\t\t\t+ \" Be sure to verify that you either pass an appropriate tokenizer \"\n\t\t\t\t\"that can convert prompts to properly formatted chat messages or a \"\n\t\t\t\t\"`messages_to_prompt` that does so.\"\n\t\t),\n\t)\n\n\t_model: Any = PrivateAttr()\n\t_tokenizer: Any = PrivateAttr()\n\n\tdef __init__(\n\t\tself,\n\t\tmodel_name: str = DEFAULT_MINDSPORE_MODEL,\n\t\ttokenizer_name: str = DEFAULT_MINDSPORE_MODEL,\n\t\tcontext_window: int = DEFAULT_CONTEXT_WINDOW,\n\t\tmax_new_tokens: int = DEFAULT_NUM_OUTPUTS,\n\t\tgenerate_kwargs: Optional[dict] = None,\n\t\tis_chat_model: Optional[bool] = False,\n\t\tsystem_prompt: str = \"\",\n\t\tmessages_to_prompt: Optional[Callable[[Sequence[ChatMessage]], str]] = None,\n\t\tcompletion_to_prompt: Optional[Callable[[str], str]] = None,\n\t):\n\t\tself._model = AutoModelForCausalLM.from_pretrained(\n\t\t\tpretrained_model_name_or_path=model_name,\n\t\t\tmirror='modelscope',\n\t\t\tms_dtype=mindspore.float16,\n\t\t).eval()\n\n\t\tconfig_dict = self._model.config.to_dict()\n\t\tmodel_context_window = int(\n\t\t\tconfig_dict.get(\"max_position_embeddings\", context_window)\n\t\t)\n\t\tif model_context_window and model_context_window &lt; context_window:\n\t\t\tcontext_window = model_context_window\n\n\t\tself._tokenizer = AutoTokenizer.from_pretrained(\n\t\t\tpretrained_model_name_or_path=model_name,\n\t\t\tmirror='modelscope',\n\t\t\tmax_length=context_window,\n\t\t)\n\t\tsuper().__init__(\n\t\t\tcontext_window=context_window,\n\t\t\tmax_new_tokens=max_new_tokens,\n\t\t\ttokenizer_name=tokenizer_name,\n\t\t\tmodel_name=model_name,\n\t\t\tgenerate_kwargs=generate_kwargs or DEFAULT_MINDSPORE_GENERATE_KWARGS,\n\t\t\tis_chat_model=is_chat_model,\n\t\t\tsystem_prompt = system_prompt,\n\t\t\tmessages_to_prompt=messages_to_prompt,\n\t\t\tcompletion_to_prompt=completion_to_prompt,\n\t\t)\n\n\t@property\n\tdef metadata(self) -&gt; LLMMetadata:\n\t\t\"\"\"Get LLM metadata.\"\"\"\n\t\treturn LLMMetadata(\n\t\t\tcontext_window=self.context_window,\n\t\t\tnum_output=self.max_new_tokens,\n\t\t\tmodel_name=self.model_name,\n\t\t\tis_chat_model=self.is_chat_model,\n\t\t)\n\n\t@llm_completion_callback()\n\tdef complete(self, prompt: str, **kwargs: Any) -&gt; CompletionResponse:\n\t\tr\"\"\" Get response from the Mindspore LLM. \"\"\"\n\t\tinputs = self._tokenizer(prompt, return_tensors=\"ms\")\n\t\toutputs = self._model.generate(**inputs, **self.generate_kwargs)\n\t\toutputs = outputs[:, inputs['input_ids'].shape[1]:]\n\t\tresponse_text = self._tokenizer.decode(outputs[0], skip_special_tokens=True)\n\t\treturn CompletionResponse(text=response_text)\n\n\t@llm_completion_callback()\n\tdef stream_complete(self, prompt: str, **kwargs: Any) -&gt; CompletionResponseGen:\n\t\tr\"\"\" Get response from the Mindspore LLM. \"\"\"\n\t\tinputs = self._tokenizer(prompt, return_tensors=\"ms\")\n\t\toutputs = self._model.generate(**inputs, **self.generate_kwargs)\n\t\toutputs = outputs[:, inputs['input_ids'].shape[1]:]\n\t\tresponse_text = self._tokenizer.decode(outputs[0], skip_special_tokens=True)\n\t\tgen_tokens = \"\"\n\t\tfor token in response_text:\n\t\t\tgen_tokens += token\n\t\t\tyield CompletionResponse(text=gen_tokens, delta=token)\n</code></pre>"},{"location":"code_docs/models/local/mindspore_models/#labridge.models.local.mindspore_models.MindsporeLLM.metadata","title":"<code>labridge.models.local.mindspore_models.MindsporeLLM.metadata: LLMMetadata</code>  <code>property</code>","text":"<p>Get LLM metadata.</p>"},{"location":"code_docs/models/local/mindspore_models/#labridge.models.local.mindspore_models.MindsporeLLM.complete","title":"<code>labridge.models.local.mindspore_models.MindsporeLLM.complete(prompt, **kwargs)</code>","text":"<p>Get response from the Mindspore LLM.</p> Source code in <code>labridge\\models\\local\\mindspore_models.py</code> <pre><code>@llm_completion_callback()\ndef complete(self, prompt: str, **kwargs: Any) -&gt; CompletionResponse:\n\tr\"\"\" Get response from the Mindspore LLM. \"\"\"\n\tinputs = self._tokenizer(prompt, return_tensors=\"ms\")\n\toutputs = self._model.generate(**inputs, **self.generate_kwargs)\n\toutputs = outputs[:, inputs['input_ids'].shape[1]:]\n\tresponse_text = self._tokenizer.decode(outputs[0], skip_special_tokens=True)\n\treturn CompletionResponse(text=response_text)\n</code></pre>"},{"location":"code_docs/models/local/mindspore_models/#labridge.models.local.mindspore_models.MindsporeLLM.stream_complete","title":"<code>labridge.models.local.mindspore_models.MindsporeLLM.stream_complete(prompt, **kwargs)</code>","text":"<p>Get response from the Mindspore LLM.</p> Source code in <code>labridge\\models\\local\\mindspore_models.py</code> <pre><code>@llm_completion_callback()\ndef stream_complete(self, prompt: str, **kwargs: Any) -&gt; CompletionResponseGen:\n\tr\"\"\" Get response from the Mindspore LLM. \"\"\"\n\tinputs = self._tokenizer(prompt, return_tensors=\"ms\")\n\toutputs = self._model.generate(**inputs, **self.generate_kwargs)\n\toutputs = outputs[:, inputs['input_ids'].shape[1]:]\n\tresponse_text = self._tokenizer.decode(outputs[0], skip_special_tokens=True)\n\tgen_tokens = \"\"\n\tfor token in response_text:\n\t\tgen_tokens += token\n\t\tyield CompletionResponse(text=gen_tokens, delta=token)\n</code></pre>"},{"location":"code_docs/models/remote/remote_models/","title":"Remote models","text":""},{"location":"code_docs/models/remote/remote_models/#labridge.models.remote.remote_models","title":"<code>labridge.models.remote.remote_models</code>","text":""},{"location":"code_docs/models/remote/remote_models/#labridge.models.remote.remote_models.AsyncModelClient","title":"<code>labridge.models.remote.remote_models.AsyncModelClient</code>","text":"<p>               Bases: <code>object</code></p> <p>This is an asynchronous client to communicate with a LLM deployed on a server through HTTP.</p> PARAMETER DESCRIPTION <code>base_url</code> <p>The base URL of the server.</p> <p> TYPE: <code>URL</code> </p> <code>model_type</code> <p>LLM or Embed.</p> <p> TYPE: <code>RemoteModelType</code> </p> <code>timeout</code> <p>The timeout of a request.</p> <p> TYPE: <code>Timeout</code> DEFAULT: <code>None</code> </p> <code>limits</code> <p>The limits configuration to use.</p> <p> TYPE: <code>Limits</code> DEFAULT: <code>None</code> </p> Source code in <code>labridge\\models\\remote\\remote_models.py</code> <pre><code>class AsyncModelClient(object):\n\tr\"\"\"\n\tThis is an asynchronous client to communicate with a LLM deployed on a server through HTTP.\n\n\tArgs:\n\t\tbase_url (URL): The base URL of the server.\n\t\tmodel_type (RemoteModelType): LLM or Embed.\n\t\ttimeout (Timeout): The timeout of a request.\n\t\tlimits (Limits): The limits configuration to use.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tmodel_type: RemoteModelType,\n\t\ttimeout: Timeout = None,\n\t\tlimits: Limits = None,\n\t):\n\t\tself._model_type = model_type\n\t\tself._timeout = timeout or DEFAULT_LLM_TIMEOUT\n\t\tself._limits = limits or DEFAULT_LLM_LIMITS\n\t\tself._client = httpx.AsyncClient(\n\t\t\ttimeout=self._timeout,\n\t\t\tlimits=self._limits,\n\t\t)\n\n\tdef formatted_input(self, input_str: str) -&gt; dict:\n\t\tr\"\"\" Pack the query string in a JSON format to send to the server. \"\"\"\n\t\treturn {\n\t\t\t\"text\": input_str,\n\t\t}\n\n\tasync def arequest(self, url: URL, input_str: str):\n\t\tr\"\"\"\n\t\tAsynchronous version.\n\n\t\tSend the query string to the server's model and get the results.\n\n\t\tArgs:\n\t\t\turl (URL): The server's serve URL.\n\t\t\tinput_str (str): The query string.\n\n\t\tReturns:\n\t\t\tUnion[str, List[float]]: The results of a remote LLM or remote embedding model.\n\t\t\"\"\"\n\t\tquery = self.formatted_input(input_str=input_str)\n\n\t\tresponse = await self._client.send(\n\t\t\trequest=Request(\n\t\t\t\tmethod=\"post\",\n\t\t\t\turl=url,\n\t\t\t\tjson=query\n\t\t\t)\n\t\t)\n\t\toutput_dict = json.loads(response.text)\n\t\toutput = output_dict[\"output\"]\n\t\treturn output\n</code></pre>"},{"location":"code_docs/models/remote/remote_models/#labridge.models.remote.remote_models.AsyncModelClient.arequest","title":"<code>labridge.models.remote.remote_models.AsyncModelClient.arequest(url, input_str)</code>  <code>async</code>","text":"<p>Asynchronous version.</p> <p>Send the query string to the server's model and get the results.</p> PARAMETER DESCRIPTION <code>url</code> <p>The server's serve URL.</p> <p> TYPE: <code>URL</code> </p> <code>input_str</code> <p>The query string.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <p>Union[str, List[float]]: The results of a remote LLM or remote embedding model.</p> Source code in <code>labridge\\models\\remote\\remote_models.py</code> <pre><code>async def arequest(self, url: URL, input_str: str):\n\tr\"\"\"\n\tAsynchronous version.\n\n\tSend the query string to the server's model and get the results.\n\n\tArgs:\n\t\turl (URL): The server's serve URL.\n\t\tinput_str (str): The query string.\n\n\tReturns:\n\t\tUnion[str, List[float]]: The results of a remote LLM or remote embedding model.\n\t\"\"\"\n\tquery = self.formatted_input(input_str=input_str)\n\n\tresponse = await self._client.send(\n\t\trequest=Request(\n\t\t\tmethod=\"post\",\n\t\t\turl=url,\n\t\t\tjson=query\n\t\t)\n\t)\n\toutput_dict = json.loads(response.text)\n\toutput = output_dict[\"output\"]\n\treturn output\n</code></pre>"},{"location":"code_docs/models/remote/remote_models/#labridge.models.remote.remote_models.AsyncModelClient.formatted_input","title":"<code>labridge.models.remote.remote_models.AsyncModelClient.formatted_input(input_str)</code>","text":"<p>Pack the query string in a JSON format to send to the server.</p> Source code in <code>labridge\\models\\remote\\remote_models.py</code> <pre><code>def formatted_input(self, input_str: str) -&gt; dict:\n\tr\"\"\" Pack the query string in a JSON format to send to the server. \"\"\"\n\treturn {\n\t\t\"text\": input_str,\n\t}\n</code></pre>"},{"location":"code_docs/models/remote/remote_models/#labridge.models.remote.remote_models.ModelClient","title":"<code>labridge.models.remote.remote_models.ModelClient</code>","text":"<p>               Bases: <code>object</code></p> <p>This is a client to communicate with a LLM deployed on a server through HTTP.</p> PARAMETER DESCRIPTION <code>base_url</code> <p>The base URL of the server.</p> <p> TYPE: <code>URL</code> </p> <code>model_type</code> <p>LLM or Embed.</p> <p> TYPE: <code>RemoteModelType</code> </p> <code>timeout</code> <p>The timeout of a request.</p> <p> TYPE: <code>Timeout</code> DEFAULT: <code>None</code> </p> <code>limits</code> <p>The limits configuration to use.</p> <p> TYPE: <code>Limits</code> DEFAULT: <code>None</code> </p> Source code in <code>labridge\\models\\remote\\remote_models.py</code> <pre><code>class ModelClient(object):\n\tr\"\"\"\n\tThis is a client to communicate with a LLM deployed on a server through HTTP.\n\n\tArgs:\n\t\tbase_url (URL): The base URL of the server.\n\t\tmodel_type (RemoteModelType): LLM or Embed.\n\t\ttimeout (Timeout): The timeout of a request.\n\t\tlimits (Limits): The limits configuration to use.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tbase_url: URL,\n\t\tmodel_type: RemoteModelType,\n\t\ttimeout: Timeout = None,\n\t\tlimits: Limits = None,\n\t):\n\t\tself._model_type = model_type\n\t\tself._timeout = timeout or DEFAULT_LLM_TIMEOUT\n\t\tself._limits = limits or DEFAULT_LLM_LIMITS\n\t\tself._client = httpx.Client(\n\t\t\tbase_url=base_url,\n\t\t\ttimeout=self._timeout,\n\t\t\tlimits=self._limits,\n\t\t)\n\n\tdef formatted_input(self, input_str: str) -&gt; dict:\n\t\tr\"\"\" Pack the query string in a JSON format to send to the server. \"\"\"\n\t\treturn {\n\t\t\t\"text\": input_str,\n\t\t}\n\n\tdef request(self, url: URL, input_str: str) -&gt; Union[str, List[float]]:\n\t\tr\"\"\"\n\t\tSend the query string to the server's model and get the results.\n\n\t\tArgs:\n\t\t\turl (URL): The server's serve URL.\n\t\t\tinput_str (str): The query string.\n\n\t\tReturns:\n\t\t\tUnion[str, List[float]]: The results of a remote LLM or remote embedding model.\n\t\t\"\"\"\n\t\tquery = self.formatted_input(input_str=input_str)\n\n\t\tresponse = self._client.send(\n\t\t\trequest=Request(\n\t\t\t\tmethod=\"post\",\n\t\t\t\turl=url,\n\t\t\t\tjson=query\n\t\t\t)\n\t\t)\n\t\toutput_dict = json.loads(response.text)\n\t\toutput = output_dict[\"output\"]\n\t\treturn output\n</code></pre>"},{"location":"code_docs/models/remote/remote_models/#labridge.models.remote.remote_models.ModelClient.formatted_input","title":"<code>labridge.models.remote.remote_models.ModelClient.formatted_input(input_str)</code>","text":"<p>Pack the query string in a JSON format to send to the server.</p> Source code in <code>labridge\\models\\remote\\remote_models.py</code> <pre><code>def formatted_input(self, input_str: str) -&gt; dict:\n\tr\"\"\" Pack the query string in a JSON format to send to the server. \"\"\"\n\treturn {\n\t\t\"text\": input_str,\n\t}\n</code></pre>"},{"location":"code_docs/models/remote/remote_models/#labridge.models.remote.remote_models.ModelClient.request","title":"<code>labridge.models.remote.remote_models.ModelClient.request(url, input_str)</code>","text":"<p>Send the query string to the server's model and get the results.</p> PARAMETER DESCRIPTION <code>url</code> <p>The server's serve URL.</p> <p> TYPE: <code>URL</code> </p> <code>input_str</code> <p>The query string.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Union[str, List[float]]</code> <p>Union[str, List[float]]: The results of a remote LLM or remote embedding model.</p> Source code in <code>labridge\\models\\remote\\remote_models.py</code> <pre><code>def request(self, url: URL, input_str: str) -&gt; Union[str, List[float]]:\n\tr\"\"\"\n\tSend the query string to the server's model and get the results.\n\n\tArgs:\n\t\turl (URL): The server's serve URL.\n\t\tinput_str (str): The query string.\n\n\tReturns:\n\t\tUnion[str, List[float]]: The results of a remote LLM or remote embedding model.\n\t\"\"\"\n\tquery = self.formatted_input(input_str=input_str)\n\n\tresponse = self._client.send(\n\t\trequest=Request(\n\t\t\tmethod=\"post\",\n\t\t\turl=url,\n\t\t\tjson=query\n\t\t)\n\t)\n\toutput_dict = json.loads(response.text)\n\toutput = output_dict[\"output\"]\n\treturn output\n</code></pre>"},{"location":"code_docs/models/remote/remote_models/#labridge.models.remote.remote_models.RemoteLLM","title":"<code>labridge.models.remote.remote_models.RemoteLLM</code>","text":"<p>               Bases: <code>CustomLLM</code></p> <p>A remote LLM deployed on the server.</p> ATTRIBUTE DESCRIPTION <code>context_window</code> <p>The maximum number of tokens available for input.</p> <p> TYPE: <code>int</code> </p> <code>num_output</code> <p>The maximum number of tokens to generate.</p> <p> TYPE: <code>int</code> </p> <code>model_name</code> <p>The model name to use from HuggingFace or local model directory.</p> <p> TYPE: <code>str</code> </p> <code>is_chat_model</code> <p>is a chat model or not.</p> <p> TYPE: <code>bool</code> </p> <code>base_url</code> <p>The base URL of the server.</p> <p> TYPE: <code>str</code> </p> <code>llm_url</code> <p>Server's URL for receiving local inputs.</p> <p> TYPE: <code>str</code> </p> <code>async_llm_url</code> <p>Server's URL for asynchronously receiving local inputs.</p> <p> TYPE: <code>str</code> </p> <code>_client</code> <p>The local client.</p> <p> TYPE: <code>ModelClient</code> </p> <code>_async_client</code> <p>The asynchronous local client.</p> <p> TYPE: <code>AsyncModelClient</code> </p> Source code in <code>labridge\\models\\remote\\remote_models.py</code> <pre><code>class RemoteLLM(CustomLLM):\n\tr\"\"\"\n\tA remote LLM deployed on the server.\n\n\tAttributes:\n\t\tcontext_window (int): The maximum number of tokens available for input.\n\t\tnum_output (int): The maximum number of tokens to generate.\n\t\tmodel_name (str): The model name to use from HuggingFace or local model directory.\n\t\tis_chat_model (bool): is a chat model or not.\n\t\tbase_url (str): The base URL of the server.\n\t\tllm_url (str): Server's URL for receiving local inputs.\n\t\tasync_llm_url (str): Server's URL for asynchronously receiving local inputs.\n\t\t_client (ModelClient): The local client.\n\t\t_async_client (AsyncModelClient): The asynchronous local client.\n\t\"\"\"\n\tcontext_window: int = 16000 # useless\n\tnum_output: int = 1024\t# useless\n\tmodel_name: str = \"remote\"\n\tis_chat_model: bool = False\n\n\tbase_url: str = Field(\n\t\tdefault=DEFAULT_BASE_URL,\n\t\tdescription=\"Base URL\",\n\t)\n\tllm_url: str = Field(\n\t\tdefault=DEFAULT_LLM_URL,\n\t\tdescription=\"URL for receiving local inputs\"\n\t)\n\tasync_llm_url: str = Field(\n\t\tdefault=DEFAULT_ASYNC_LLM_URL,\n\t\tdescription=\"URL for asynchronously receiving local inputs\"\n\t)\n\n\t_client: ModelClient = PrivateAttr()\n\t_async_client: AsyncModelClient = PrivateAttr()\n\n\tdef __init__(\n\t\tself,\n\t\tbase_url: str,\n\t\tllm_url: str,\n\t\tasync_llm_url: str,\n\t\tcontext_window: int = 16000,\n\t\tnum_output: int = 1024,\n\t\tmodel_name: str = \"remote\",\n\t\tis_chat_model: bool = False,\n\n\t):\n\t\tbase_url = base_url or DEFAULT_BASE_URL\n\t\tllm_url = llm_url or DEFAULT_LLM_URL\n\t\tasync_llm_url = async_llm_url or DEFAULT_ASYNC_LLM_URL\n\t\tself._client = ModelClient(\n\t\t\tbase_url=URL(base_url),\n\t\t\tmodel_type=RemoteModelType.LLM,\n\t\t)\n\t\tself._async_client = AsyncModelClient(\n\t\t\tmodel_type=RemoteModelType.LLM,\n\t\t)\n\t\tsuper().__init__(\n\t\t\tbase_url=base_url,\n\t\t\tllm_url=llm_url,\n\t\t\tasync_llm_url = async_llm_url,\n\t\t\tcontext_window=context_window,\n\t\t\tnum_output=num_output,\n\t\t\tmodel_name=model_name,\n\t\t\tis_chat_model=is_chat_model,\n\t\t)\n\n\t@property\n\tdef metadata(self) -&gt; LLMMetadata:\n\t\t\"\"\"Get LLM metadata.\"\"\"\n\t\treturn LLMMetadata(\n\t\t\tcontext_window=self.context_window,\n\t\t\tnum_output=self.num_output,\n\t\t\tmodel_name=self.model_name,\n\t\t)\n\n\t@llm_completion_callback()\n\tdef complete(self, prompt: str, **kwargs: Any) -&gt; CompletionResponse:\n\t\tr\"\"\" Get response from the Remote LLM. \"\"\"\n\t\ttry:\n\t\t\tresponse = self._client.request(\n\t\t\t\turl=URL(self.llm_url),\n\t\t\t\tinput_str=prompt,\n\t\t\t)\n\t\t\treturn CompletionResponse(text=response)\n\t\texcept Exception as e:\n\t\t\treturn CompletionResponse(text=e)\n\n\n\t@llm_completion_callback()\n\tasync def acomplete(self, prompt: str, **kwargs: Any) -&gt; CompletionResponse:\n\t\tr\"\"\" Asynchronously get response from the Remote LLM. \"\"\"\n\t\ttry:\n\t\t\tprint(\"User: \", prompt)\n\t\t\tresponse = await self._async_client.arequest(\n\t\t\t\turl=URL(self.async_llm_url),\n\t\t\t\tinput_str=prompt,\n\t\t\t)\n\t\t\treturn CompletionResponse(text=response)\n\t\texcept Exception as e:\n\t\t\treturn CompletionResponse(text=e)\n\n\t@llm_completion_callback()\n\tdef stream_complete(self, prompt: str, **kwargs: Any) -&gt; CompletionResponseGen:\n\t\ttry:\n\t\t\tresponse = self._client.request(\n\t\t\t\turl=URL(self.llm_url),\n\t\t\t\tinput_str=prompt,\n\t\t\t)\n\t\texcept Exception as e:\n\t\t\tresponse = e\n\n\t\tgen_tokens = \"\"\n\t\tfor token in response:\n\t\t\tgen_tokens += token\n\t\t\tyield CompletionResponse(text=response, delta=token)\n</code></pre>"},{"location":"code_docs/models/remote/remote_models/#labridge.models.remote.remote_models.RemoteLLM.metadata","title":"<code>labridge.models.remote.remote_models.RemoteLLM.metadata: LLMMetadata</code>  <code>property</code>","text":"<p>Get LLM metadata.</p>"},{"location":"code_docs/models/remote/remote_models/#labridge.models.remote.remote_models.RemoteLLM.acomplete","title":"<code>labridge.models.remote.remote_models.RemoteLLM.acomplete(prompt, **kwargs)</code>  <code>async</code>","text":"<p>Asynchronously get response from the Remote LLM.</p> Source code in <code>labridge\\models\\remote\\remote_models.py</code> <pre><code>@llm_completion_callback()\nasync def acomplete(self, prompt: str, **kwargs: Any) -&gt; CompletionResponse:\n\tr\"\"\" Asynchronously get response from the Remote LLM. \"\"\"\n\ttry:\n\t\tprint(\"User: \", prompt)\n\t\tresponse = await self._async_client.arequest(\n\t\t\turl=URL(self.async_llm_url),\n\t\t\tinput_str=prompt,\n\t\t)\n\t\treturn CompletionResponse(text=response)\n\texcept Exception as e:\n\t\treturn CompletionResponse(text=e)\n</code></pre>"},{"location":"code_docs/models/remote/remote_models/#labridge.models.remote.remote_models.RemoteLLM.complete","title":"<code>labridge.models.remote.remote_models.RemoteLLM.complete(prompt, **kwargs)</code>","text":"<p>Get response from the Remote LLM.</p> Source code in <code>labridge\\models\\remote\\remote_models.py</code> <pre><code>@llm_completion_callback()\ndef complete(self, prompt: str, **kwargs: Any) -&gt; CompletionResponse:\n\tr\"\"\" Get response from the Remote LLM. \"\"\"\n\ttry:\n\t\tresponse = self._client.request(\n\t\t\turl=URL(self.llm_url),\n\t\t\tinput_str=prompt,\n\t\t)\n\t\treturn CompletionResponse(text=response)\n\texcept Exception as e:\n\t\treturn CompletionResponse(text=e)\n</code></pre>"},{"location":"code_docs/models/remote/remote_server/","title":"Remote server","text":""},{"location":"code_docs/models/remote/remote_server/#labridge.models.remote.remote_server","title":"<code>labridge.models.remote.remote_server</code>","text":""},{"location":"code_docs/tools/utils/","title":"Utils","text":""},{"location":"code_docs/tools/utils/#labridge.tools.utils","title":"<code>labridge.tools.utils</code>","text":""},{"location":"code_docs/tools/utils/#labridge.tools.utils.create_schema_from_fn_or_method","title":"<code>labridge.tools.utils.create_schema_from_fn_or_method(name, func, additional_fields=None)</code>","text":"<p>Create schema from function.</p> Source code in <code>labridge\\tools\\utils.py</code> <pre><code>def create_schema_from_fn_or_method(\n    name: str,\n    func: Callable[..., Any],\n    additional_fields: Optional[\n        List[Union[Tuple[str, Type, Any], Tuple[str, Type]]]\n    ] = None,\n) -&gt; Type[BaseModel]:\n\t\"\"\"Create schema from function.\"\"\"\n\tfields = {}\n\tparams = signature(func).parameters\n\tfor param_name in params:\n\t\tif param_name in [\"self\", \"cls\"]:\n\t\t\tcontinue\n\t\tparam_type = params[param_name].annotation\n\t\tparam_default = params[param_name].default\n\n\t\tif param_type is params[param_name].empty:\n\t\t\tparam_type = Any\n\n\t\tif param_default is params[param_name].empty:\n\t\t\t# Required field\n\t\t\tfields[param_name] = (param_type, FieldInfo())\n\t\telif isinstance(param_default, FieldInfo):\n\t\t\t# Field with pydantic.Field as default value\n\t\t\tfields[param_name] = (param_type, param_default)\n\t\telse:\n\t\t\tfields[param_name] = (param_type, FieldInfo(default=param_default))\n\n\tadditional_fields = additional_fields or []\n\tfor field_info in additional_fields:\n\t\tif len(field_info) == 3:\n\t\t\tfield_info = cast(Tuple[str, Type, Any], field_info)\n\t\t\tfield_name, field_type, field_default = field_info\n\t\t\tfields[field_name] = (field_type, FieldInfo(default=field_default))\n\t\telif len(field_info) == 2:\n\t\t\t# Required field has no default value\n\t\t\tfield_info = cast(Tuple[str, Type], field_info)\n\t\t\tfield_name, field_type = field_info\n\t\t\tfields[field_name] = (field_type, FieldInfo())\n\t\telse:\n\t\t\traise ValueError(\n\t\t\t\tf\"Invalid additional field info: {field_info}. \"\n\t\t\t\t\"Must be a tuple of length 2 or 3.\"\n\t\t\t)\n\n\treturn create_model(name, **fields)  # type: ignore\n</code></pre>"},{"location":"code_docs/tools/utils/#labridge.tools.utils.get_extra_str_to_user","title":"<code>labridge.tools.utils.get_extra_str_to_user(tool_logs)</code>","text":"<p>The <code>log_to_user</code> and the value of the key <code>references</code> in ToolLog will be presented to the user.</p> Source code in <code>labridge\\tools\\utils.py</code> <pre><code>def get_extra_str_to_user(tool_logs: List[ToolLog]) -&gt; str:\n\tr\"\"\"\n\tThe `log_to_user` and the value of the key `references` in ToolLog will be presented to the user.\n\t\"\"\"\n\tstr_list = []\n\n\textra_refs_dict = get_all_ref_info(tool_logs=tool_logs)\n\n\tfor log in tool_logs:\n\t\tif log.log_to_user is not None:\n\t\t\tstr_list.append(log.log_to_user.strip())\n\n\tfor ref_type in extra_refs_dict.keys():\n\t\tfn = REF_INFO_TO_STR_FUNC_DICT[ref_type]\n\t\tref_str = fn(extra_refs_dict[ref_type])\n\t\tstr_list.append(ref_str.strip())\n\treturn \"\\n\".join(str_list)\n</code></pre>"},{"location":"code_docs/tools/utils/#labridge.tools.utils.get_ref_file_paths","title":"<code>labridge.tools.utils.get_ref_file_paths(tool_logs)</code>","text":"Source code in <code>labridge\\tools\\utils.py</code> <pre><code>def get_ref_file_paths(tool_logs: List[ToolLog]) -&gt; List[str]:\n\tr\"\"\"\n\n\t\"\"\"\n\textra_refs_dict = get_all_ref_info(tool_logs=tool_logs)\n\n\tfile_paths = []\n\tfor ref_type in extra_refs_dict.keys():\n\t\tif ref_type in REF_INFO_TO_FILE_PATH_FUNC_DICT.keys():\n\t\t\tfn = REF_INFO_TO_FILE_PATH_FUNC_DICT[ref_type]\n\t\t\tpaths = fn(extra_refs_dict[ref_type])\n\t\t\tfile_paths.extend(paths)\n\treturn file_paths\n</code></pre>"},{"location":"code_docs/tools/utils/#labridge.tools.utils.pack_tool_output","title":"<code>labridge.tools.utils.pack_tool_output(tool_output, tool_log=None)</code>","text":"<p>Pack the tool output and tool log in a dict and dump to string.</p> PARAMETER DESCRIPTION <code>tool_output</code> <p>The tool output string.</p> <p> TYPE: <code>str</code> </p> <code>tool_log</code> <p>The tool log string.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>str</code> <p>The dumped tool output and log.</p> Source code in <code>labridge\\tools\\utils.py</code> <pre><code>def pack_tool_output(tool_output: str, tool_log: str = None) -&gt; str:\n\tr\"\"\"\n\tPack the tool output and tool log in a dict and dump to string.\n\n\tArgs:\n\t\ttool_output (str): The tool output string.\n\t\ttool_log (str): The tool log string.\n\n\tReturns:\n\t\tThe dumped tool output and log.\n\t\"\"\"\n\ttool_out_dict = {\n\t\t\"tool_output\": tool_output,\n\t\t\"tool_log\": tool_log,\n\t}\n\ttool_out_str = json.dumps(tool_out_dict)\n\treturn tool_out_str\n</code></pre>"},{"location":"code_docs/tools/utils/#labridge.tools.utils.unpack_tool_output","title":"<code>labridge.tools.utils.unpack_tool_output(tool_out_json)</code>","text":"<p>Unpack the tool output string and tool log string from</p> PARAMETER DESCRIPTION <code>tool_out_json</code> <p> TYPE: <code>str</code> </p> Source code in <code>labridge\\tools\\utils.py</code> <pre><code>def unpack_tool_output(tool_out_json: str) -&gt; Tuple[str, Optional[str]]:\n\tr\"\"\"\n\tUnpack the tool output string and tool log string from\n\n\tArgs:\n\t\ttool_out_json:\n\n\tReturns:\n\n\t\"\"\"\n\ttry:\n\t\ttool_out_dict = json.loads(tool_out_json)\n\t\ttool_output, tool_log = tool_out_dict[\"tool_output\"], tool_out_dict[\"tool_log\"]\n\t\treturn tool_output, tool_log\n\texcept Exception:\n\t\treturn tool_out_json, None\n</code></pre>"},{"location":"code_docs/tools/utils/#labridge.tools.utils.whether_abort_tool","title":"<code>labridge.tools.utils.whether_abort_tool(tool_output)</code>","text":"<p>Whether a tool is aborted during execution.</p> PARAMETER DESCRIPTION <code>tool_output</code> <p>The tool output of a tool.</p> <p> TYPE: <code>ToolOutput</code> </p> RETURNS DESCRIPTION <code>Optional[bool]</code> <p>Optional[bool]:</p> <ul> <li>If the tool's execution is aborted, return True.</li> <li>If the tool's execution is performed normally, return False.</li> <li>If error raises in this function, return None.</li> </ul> Source code in <code>labridge\\tools\\utils.py</code> <pre><code>def whether_abort_tool(tool_output: ToolOutput) -&gt; Optional[bool]:\n\tr\"\"\"\n\tWhether a tool is aborted during execution.\n\n\tArgs:\n\t\ttool_output (ToolOutput): The tool output of a tool.\n\n\tReturns:\n\t\tOptional[bool]:\n\n\t\t\t- If the tool's execution is aborted, return True.\n\t\t\t- If the tool's execution is performed normally, return False.\n\t\t\t- If error raises in this function, return None.\n\n\t\"\"\"\n\ttry:\n\t\t_, create_log_str = unpack_tool_output(tool_output.content)\n\t\tcreate_log = ToolLog.loads(log_str=create_log_str)\n\t\t# if the user abort in the creation pipeline\n\t\treturn create_log.tool_abort\n\texcept ValueError:\n\t\treturn None\n</code></pre>"},{"location":"code_docs/tools/base/function_base_tools/","title":"Function base tools","text":""},{"location":"code_docs/tools/base/function_base_tools/#labridge.tools.base.function_base_tools","title":"<code>labridge.tools.base.function_base_tools</code>","text":""},{"location":"code_docs/tools/base/function_base_tools/#labridge.tools.base.function_base_tools.CallBackBaseTool","title":"<code>labridge.tools.base.function_base_tools.CallBackBaseTool</code>","text":"<p>               Bases: <code>FunctionBaseTool</code></p> <p>This is base of tools that will execute operations that need authorization. Refer to the <code>callback</code> module for details.</p> PARAMETER DESCRIPTION <code>fn</code> <p>The function or method that will be called by the agent.</p> <p> TYPE: <code>Callable</code> </p> <code>async_fn</code> <p>The asynchronous version of <code>fn</code>.</p> <p> TYPE: <code>Callable</code> </p> <code>callback_operation</code> <p>The operation that needs the user's authorization.</p> <p> TYPE: <code>CallBackOperationBase</code> </p> <code>tool_name</code> <p>The tool name.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>return_direct</code> <p>Whether to return the tool output directly in Reasoning &amp; Acting process.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> Source code in <code>labridge\\tools\\base\\function_base_tools.py</code> <pre><code>class CallBackBaseTool(FunctionBaseTool):\n\tr\"\"\"\n\tThis is base of tools that will execute operations that need authorization.\n\tRefer to the `callback` module for details.\n\n\tArgs:\n\t\tfn (Callable): The function or method that will be called by the agent.\n\t\tasync_fn (Callable): The asynchronous version of `fn`.\n\t\tcallback_operation (CallBackOperationBase): The operation that needs the user's authorization.\n\t\ttool_name (str): The tool name.\n\t\treturn_direct (bool): Whether to return the tool output directly in Reasoning &amp; Acting process.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tfn: Callable[..., Any],\n\t\tasync_fn: Callable[..., Any],\n\t\tcallback_operation: CallBackOperationBase,\n\t\ttool_name: str = None,\n\t\treturn_direct: bool = False,\n\t):\n\t\tself._callback_operation = callback_operation\n\t\tsuper().__init__(\n\t\t\tfn=fn,\n\t\t\tasync_fn=async_fn,\n\t\t\ttool_name=tool_name,\n\t\t\treturn_direct=return_direct,\n\t\t)\n\n\t@abstractmethod\n\tdef log(self, **kwargs: Any) -&gt; ToolLog:\n\t\tr\"\"\" Return the log json string, describing the tool's operation. \"\"\"\n</code></pre>"},{"location":"code_docs/tools/base/function_base_tools/#labridge.tools.base.function_base_tools.CallBackBaseTool.log","title":"<code>labridge.tools.base.function_base_tools.CallBackBaseTool.log(**kwargs)</code>  <code>abstractmethod</code>","text":"<p>Return the log json string, describing the tool's operation.</p> Source code in <code>labridge\\tools\\base\\function_base_tools.py</code> <pre><code>@abstractmethod\ndef log(self, **kwargs: Any) -&gt; ToolLog:\n\tr\"\"\" Return the log json string, describing the tool's operation. \"\"\"\n</code></pre>"},{"location":"code_docs/tools/base/function_base_tools/#labridge.tools.base.function_base_tools.FuncOutputWithLog","title":"<code>labridge.tools.base.function_base_tools.FuncOutputWithLog</code>","text":"<p>This class is the output format of the function in a FunctionBaseTool.</p> PARAMETER DESCRIPTION <code>fn_output</code> <p>The output of the function.</p> <p> TYPE: <code>str</code> </p> <code>fn_log</code> <p>The log of the function.</p> <p> TYPE: <code>Union[str, Dict[str, Any]]</code> </p> Source code in <code>labridge\\tools\\base\\function_base_tools.py</code> <pre><code>class FuncOutputWithLog:\n\tr\"\"\"\n\tThis class is the output format of the function in a FunctionBaseTool.\n\n\tArgs:\n\t\tfn_output (str): The output of the function.\n\t\tfn_log (Union[str, Dict[str, Any]]): The log of the function.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tfn_output: Optional[str],\n\t\tfn_log: Union[str, Dict[str, Any]]\n\t):\n\t\tself.fn_output = fn_output\n\t\tself.fn_log = fn_log\n</code></pre>"},{"location":"code_docs/tools/base/function_base_tools/#labridge.tools.base.function_base_tools.FunctionBaseTool","title":"<code>labridge.tools.base.function_base_tools.FunctionBaseTool</code>","text":"<p>               Bases: <code>CheckBaseTool</code></p> <p>This tool is the base of function-type or method-type tools.</p> PARAMETER DESCRIPTION <code>fn</code> <p>The function or method that will be called by the agent.</p> <p> TYPE: <code>Callable</code> </p> <code>async_fn</code> <p>The asynchronous version of <code>fn</code>.</p> <p> TYPE: <code>Callable</code> DEFAULT: <code>None</code> </p> <code>tool_name</code> <p>The tool name. If not specified, the <code>fn.__name__</code> will be used as the tool name.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>return_direct</code> <p>Whether to return the tool output directly in the Reasoning &amp; Acting process. Refer to <code>ReactAgent</code> for details.</p> <p> TYPE: <code>str</code> DEFAULT: <code>False</code> </p> Source code in <code>labridge\\tools\\base\\function_base_tools.py</code> <pre><code>class FunctionBaseTool(CheckBaseTool):\n\tr\"\"\"\n\tThis tool is the base of function-type or method-type tools.\n\n\tArgs:\n\t\tfn (Callable): The function or method that will be called by the agent.\n\t\tasync_fn (Callable): The asynchronous version of `fn`.\n\t\ttool_name (str): The tool name. If not specified, the `fn.__name__` will be used as the tool name.\n\t\treturn_direct (str): Whether to return the tool output directly in the Reasoning &amp; Acting process.\n\t\t\tRefer to `ReactAgent` for details.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tfn: Callable[..., Any],\n\t\tasync_fn: Callable[..., Any] = None,\n\t\ttool_name: str = None,\n\t\treturn_direct: bool = False,\n\t):\n\t\tname = tool_name or fn.__name__\n\t\tdocstring = fn.__doc__\n\t\tdescription = f\"{name}{signature(fn)}\\n{docstring}\"\n\t\tfn_schema = create_schema_from_fn_or_method(f\"{name}\", fn, additional_fields=None)\n\t\tmetadata = ToolMetadata(\n\t\t\tname=name,\n\t\t\tdescription=description,\n\t\t\tfn_schema=fn_schema,\n\t\t\treturn_direct=return_direct,\n\t\t)\n\n\t\tself._fn = fn\n\t\tif async_fn is not None:\n\t\t\tself._async_fn = async_fn\n\t\telse:\n\t\t\tself._async_fn = sync_to_async(self._fn)\n\t\tsuper().__init__(metadata=metadata)\n\n\t@abstractmethod\n\tdef log(self, **kwargs: Any) -&gt; ToolLog:\n\t\tr\"\"\" Return the log json string, describing the tool's operation. \"\"\"\n\n\tdef call(self, **kwargs: Any) -&gt; ToolOutput:\n\t\t\"\"\" Call, return output and log. \"\"\"\n\t\tchecked_kwargs = self._get_input(**kwargs)\n\t\toutput_with_log = self._fn(**checked_kwargs)\n\n\t\tif not isinstance(output_with_log, FuncOutputWithLog):\n\t\t\traise ValueError(\"The function of a function tool must output 'FuncOutputWithLog'.\")\n\n\t\tfn_output = output_with_log.fn_output\n\t\tfn_log = output_with_log.fn_log\n\t\tif not isinstance(fn_log, dict):\n\t\t\tfn_log = {\"fn_log\": fn_log}\n\t\telse:\n\t\t\tfn_log = fn_log\n\n\t\tchecked_kwargs.update(fn_log)\n\t\ttool_log = self.log(**checked_kwargs)\n\t\ttool_output = pack_tool_output(tool_output=fn_output, tool_log=tool_log.dumps())\n\n\t\treturn ToolOutput(\n\t\t\tcontent=str(tool_output),\n\t\t\ttool_name=self.metadata.name,\n\t\t\traw_input={\"kwargs\": kwargs},\n\t\t\traw_output=tool_output,\n\t\t)\n\n\tasync def acall(self, **kwargs: Any) -&gt; ToolOutput:\n\t\t\"\"\" Asynchronous Call. \"\"\"\n\t\tchecked_kwargs = self._get_input(**kwargs)\n\t\toutput_with_log = await self._async_fn(**checked_kwargs)\n\t\tif not isinstance(output_with_log, FuncOutputWithLog):\n\t\t\traise ValueError(\"The function of a function tool must output 'FuncOutputWithLog'.\")\n\n\t\tfn_output = output_with_log.fn_output\n\t\tfn_log = output_with_log.fn_log\n\t\tif not isinstance(fn_log, dict):\n\t\t\tfn_log = {\"fn_log\": fn_log}\n\t\telse:\n\t\t\tfn_log = fn_log\n\n\t\tchecked_kwargs.update(fn_log)\n\t\ttool_log = self.log(**checked_kwargs)\n\t\ttool_output = pack_tool_output(tool_output=fn_output, tool_log=tool_log.dumps())\n\t\treturn ToolOutput(\n\t\t\tcontent=str(tool_output),\n\t\t\ttool_name=self.metadata.name,\n\t\t\traw_input={\"kwargs\": kwargs},\n\t\t\traw_output=tool_output,\n\t\t)\n</code></pre>"},{"location":"code_docs/tools/base/function_base_tools/#labridge.tools.base.function_base_tools.FunctionBaseTool.acall","title":"<code>labridge.tools.base.function_base_tools.FunctionBaseTool.acall(**kwargs)</code>  <code>async</code>","text":"<p>Asynchronous Call.</p> Source code in <code>labridge\\tools\\base\\function_base_tools.py</code> <pre><code>async def acall(self, **kwargs: Any) -&gt; ToolOutput:\n\t\"\"\" Asynchronous Call. \"\"\"\n\tchecked_kwargs = self._get_input(**kwargs)\n\toutput_with_log = await self._async_fn(**checked_kwargs)\n\tif not isinstance(output_with_log, FuncOutputWithLog):\n\t\traise ValueError(\"The function of a function tool must output 'FuncOutputWithLog'.\")\n\n\tfn_output = output_with_log.fn_output\n\tfn_log = output_with_log.fn_log\n\tif not isinstance(fn_log, dict):\n\t\tfn_log = {\"fn_log\": fn_log}\n\telse:\n\t\tfn_log = fn_log\n\n\tchecked_kwargs.update(fn_log)\n\ttool_log = self.log(**checked_kwargs)\n\ttool_output = pack_tool_output(tool_output=fn_output, tool_log=tool_log.dumps())\n\treturn ToolOutput(\n\t\tcontent=str(tool_output),\n\t\ttool_name=self.metadata.name,\n\t\traw_input={\"kwargs\": kwargs},\n\t\traw_output=tool_output,\n\t)\n</code></pre>"},{"location":"code_docs/tools/base/function_base_tools/#labridge.tools.base.function_base_tools.FunctionBaseTool.call","title":"<code>labridge.tools.base.function_base_tools.FunctionBaseTool.call(**kwargs)</code>","text":"<p>Call, return output and log.</p> Source code in <code>labridge\\tools\\base\\function_base_tools.py</code> <pre><code>def call(self, **kwargs: Any) -&gt; ToolOutput:\n\t\"\"\" Call, return output and log. \"\"\"\n\tchecked_kwargs = self._get_input(**kwargs)\n\toutput_with_log = self._fn(**checked_kwargs)\n\n\tif not isinstance(output_with_log, FuncOutputWithLog):\n\t\traise ValueError(\"The function of a function tool must output 'FuncOutputWithLog'.\")\n\n\tfn_output = output_with_log.fn_output\n\tfn_log = output_with_log.fn_log\n\tif not isinstance(fn_log, dict):\n\t\tfn_log = {\"fn_log\": fn_log}\n\telse:\n\t\tfn_log = fn_log\n\n\tchecked_kwargs.update(fn_log)\n\ttool_log = self.log(**checked_kwargs)\n\ttool_output = pack_tool_output(tool_output=fn_output, tool_log=tool_log.dumps())\n\n\treturn ToolOutput(\n\t\tcontent=str(tool_output),\n\t\ttool_name=self.metadata.name,\n\t\traw_input={\"kwargs\": kwargs},\n\t\traw_output=tool_output,\n\t)\n</code></pre>"},{"location":"code_docs/tools/base/function_base_tools/#labridge.tools.base.function_base_tools.FunctionBaseTool.log","title":"<code>labridge.tools.base.function_base_tools.FunctionBaseTool.log(**kwargs)</code>  <code>abstractmethod</code>","text":"<p>Return the log json string, describing the tool's operation.</p> Source code in <code>labridge\\tools\\base\\function_base_tools.py</code> <pre><code>@abstractmethod\ndef log(self, **kwargs: Any) -&gt; ToolLog:\n\tr\"\"\" Return the log json string, describing the tool's operation. \"\"\"\n</code></pre>"},{"location":"code_docs/tools/base/tool_base/","title":"Tool base","text":""},{"location":"code_docs/tools/base/tool_base/#labridge.tools.base.tool_base","title":"<code>labridge.tools.base.tool_base</code>","text":""},{"location":"code_docs/tools/base/tool_base/#labridge.tools.base.tool_base.CheckBaseTool","title":"<code>labridge.tools.base.tool_base.CheckBaseTool</code>","text":"<p>               Bases: <code>AsyncBaseTool</code></p> <p>The base tool that will check the input keyword arguments according to the tool's fn_schema.</p> PARAMETER DESCRIPTION <code>metadata</code> <p>the tool's metadata.</p> <p> TYPE: <code>ToolMetadata</code> </p> Source code in <code>labridge\\tools\\base\\tool_base.py</code> <pre><code>class CheckBaseTool(AsyncBaseTool):\n\tr\"\"\"\n\tThe base tool that will check the input keyword arguments according to the tool's fn_schema.\n\n\tArgs:\n\t\tmetadata (ToolMetadata): the tool's metadata.\n\t\"\"\"\n\n\tdef __init__(self, metadata: ToolMetadata):\n\t\tself._metadata = metadata\n\t\tsuper().__init__()\n\n\t@property\n\tdef metadata(self) -&gt; ToolMetadata:\n\t\treturn self._metadata\n\n\tdef _get_input(self, **kwargs: Any) -&gt; dict:\n\t\tr\"\"\" Parse the required keyword arguments from the provided keyword arguments. \"\"\"\n\t\tfn_schema = json.loads(self.metadata.fn_schema_str)\n\t\targument_keys = list(fn_schema[\"properties\"].keys())\n\t\trequired_kwargs = fn_schema[\"required\"]\n\t\tmissing_keys = []\n\t\tfor key in required_kwargs:\n\t\t\tif key not in kwargs:\n\t\t\t\tmissing_keys.append(key)\n\t\tif len(missing_keys) &gt; 0:\n\t\t\tmissing_keys = ','.join(missing_keys)\n\t\t\traise ValueError(f\"The required parameters are not provided: {missing_keys}\")\n\n\t\tif \"kwargs\" in argument_keys:\n\t\t\treturn kwargs\n\n\t\treturn {key: kwargs[key] for key in argument_keys}\n\n\t@abstractmethod\n\tdef call(self, **kwargs) -&gt; ToolOutput:\n\t\tr\"\"\" Tool call \"\"\"\n\n\t@abstractmethod\n\tasync def acall(self, **kwargs) -&gt; ToolOutput:\n\t\tr\"\"\" Asynchronously tool call \"\"\"\n</code></pre>"},{"location":"code_docs/tools/base/tool_base/#labridge.tools.base.tool_base.CheckBaseTool.acall","title":"<code>labridge.tools.base.tool_base.CheckBaseTool.acall(**kwargs)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Asynchronously tool call</p> Source code in <code>labridge\\tools\\base\\tool_base.py</code> <pre><code>@abstractmethod\nasync def acall(self, **kwargs) -&gt; ToolOutput:\n\tr\"\"\" Asynchronously tool call \"\"\"\n</code></pre>"},{"location":"code_docs/tools/base/tool_base/#labridge.tools.base.tool_base.CheckBaseTool.call","title":"<code>labridge.tools.base.tool_base.CheckBaseTool.call(**kwargs)</code>  <code>abstractmethod</code>","text":"<p>Tool call</p> Source code in <code>labridge\\tools\\base\\tool_base.py</code> <pre><code>@abstractmethod\ndef call(self, **kwargs) -&gt; ToolOutput:\n\tr\"\"\" Tool call \"\"\"\n</code></pre>"},{"location":"code_docs/tools/base/tool_base/#labridge.tools.base.tool_base.QueryEngineBaseTool","title":"<code>labridge.tools.base.tool_base.QueryEngineBaseTool</code>","text":"<p>               Bases: <code>QueryEngineTool</code></p> Source code in <code>labridge\\tools\\base\\tool_base.py</code> <pre><code>class QueryEngineBaseTool(QueryEngineTool):\n\tdef __init__(\n\t\tself,\n\t\tquery_engine: BaseQueryEngine,\n\t\tname: str,\n\t\tdescription: str,\n\t\treturn_direct: bool = False,\n\t\tresolve_input_errors: bool = True,\n\t):\n\t\tmetadata = ToolMetadata(name=name, description=description, return_direct=return_direct)\n\t\tsuper().__init__(\n\t\t\tquery_engine=query_engine,\n\t\t\tmetadata=metadata,\n\t\t\tresolve_input_errors=resolve_input_errors,\n\t\t)\n\n\t@abstractmethod\n\tdef log(self) -&gt; ToolLog:\n\t\tr\"\"\" Return the ToolLog, describing the tool's operation. \"\"\"\n\n\tdef call(self, *args: Any, **kwargs: Any) -&gt; ToolOutput:\n\t\tquery_str = self._get_query_str(*args, **kwargs)\n\t\tresponse = self._query_engine.query(query_str)\n\t\ttool_log = self.log()\n\t\tresponse = pack_tool_output(tool_output=str(response), tool_log=tool_log.dumps())\n\t\treturn ToolOutput(\n\t\t\tcontent=response,\n\t\t\ttool_name=self.metadata.name,\n\t\t\traw_input={\"input\": query_str},\n\t\t\traw_output=response,\n\t\t)\n\n\tasync def acall(self, *args: Any, **kwargs: Any) -&gt; ToolOutput:\n\t\tquery_str = self._get_query_str(*args, **kwargs)\n\t\tresponse = await self._query_engine.aquery(query_str)\n\t\ttool_log = self.log()\n\t\tresponse = pack_tool_output(tool_output=str(response), tool_log=tool_log.dumps())\n\t\treturn ToolOutput(\n\t\t\tcontent=response,\n\t\t\ttool_name=self.metadata.name,\n\t\t\traw_input={\"input\": query_str},\n\t\t\traw_output=response,\n\t\t)\n</code></pre>"},{"location":"code_docs/tools/base/tool_base/#labridge.tools.base.tool_base.QueryEngineBaseTool.log","title":"<code>labridge.tools.base.tool_base.QueryEngineBaseTool.log()</code>  <code>abstractmethod</code>","text":"<p>Return the ToolLog, describing the tool's operation.</p> Source code in <code>labridge\\tools\\base\\tool_base.py</code> <pre><code>@abstractmethod\ndef log(self) -&gt; ToolLog:\n\tr\"\"\" Return the ToolLog, describing the tool's operation. \"\"\"\n</code></pre>"},{"location":"code_docs/tools/base/tool_base/#labridge.tools.base.tool_base.RetrieverBaseTool","title":"<code>labridge.tools.base.tool_base.RetrieverBaseTool</code>","text":"<p>               Bases: <code>CheckBaseTool</code></p> <p>This is the base of retrieving tools.</p> PARAMETER DESCRIPTION <code>name</code> <p>The tool name.</p> <p> TYPE: <code>str</code> </p> <code>retriever</code> <p>The retriever that retrieves in something.</p> <p> TYPE: <code>Any</code> </p> <code>retrieve_fn</code> <p>The retrieving function or method that will be called by the agent.</p> <p> TYPE: <code>Callable</code> </p> <code>description</code> <p>The tool description. If not specified, the tool description will be set as the docstring of the <code>retrieve_fn</code>.</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> Source code in <code>labridge\\tools\\base\\tool_base.py</code> <pre><code>class RetrieverBaseTool(CheckBaseTool):\n\tr\"\"\"\n\tThis is the base of retrieving tools.\n\n\tArgs:\n\t\tname (str): The tool name.\n\t\tretriever (Any): The retriever that retrieves in something.\n\t\tretrieve_fn (Callable): The retrieving function or method that will be called by the agent.\n\t\tdescription (Optional[str]): The tool description. If not specified, the tool description will be set as the\n\t\t\tdocstring of the `retrieve_fn`.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tname: str,\n\t\tretriever: Any,\n\t\tretrieve_fn: Callable,\n\t\tdescription: Optional[str] = None,\n\t):\n\t\tfn_schema = self._get_retriever_fn_schema(name=name, fn=retrieve_fn)\n\t\tdescription = description or self._retriever_fn_description_from_docstring(name=name, fn=retrieve_fn)\n\n\t\tself._retriever = retriever\n\t\tmetadata = ToolMetadata(\n\t\t\tname=name,\n\t\t\tdescription=description,\n\t\t\tfn_schema=fn_schema,\n\t\t)\n\t\tsuper().__init__(metadata=metadata)\n\n\tdef _get_retriever_fn_schema(self, name: str, fn: Callable) -&gt; Type[BaseModel]:\n\t\tr\"\"\" Get the fn_schema from the provided function or method. \"\"\"\n\t\tfn_schema = create_schema_from_fn_or_method(name=name, func=fn)\n\t\treturn fn_schema\n\n\tdef _retriever_fn_description_from_docstring(self, name: str, fn: Callable) -&gt; str:\n\t\tr\"\"\" Get the tool description from docstring of the function. \"\"\"\n\t\tdocstring = fn.__doc__\n\t\tdescription = f\"{name}{signature(fn)}\\n{docstring}\"\n\t\treturn description\n\n\t@abstractmethod\n\tdef log(self, log_dict: dict) -&gt; ToolLog:\n\t\tr\"\"\" Return the ToolLog with log string in a specific format. \"\"\"\n\n\t@abstractmethod\n\tdef _retrieve(self, retrieve_kwargs: dict) -&gt; List[NodeWithScore]:\n\t\tr\"\"\" Use the retriever to retrieve relevant nodes. \"\"\"\n\n\t@abstractmethod\n\tasync def _aretrieve(self, retrieve_kwargs: dict) -&gt; List[NodeWithScore]:\n\t\tr\"\"\" Asynchronously use the retriever to retrieve relevant nodes. \"\"\"\n\n\t@abstractmethod\n\tdef _nodes_to_tool_output(self, nodes: List[NodeWithScore]) -&gt; Tuple[str, dict]:\n\t\tr\"\"\" output the retrieved contents in a specific format, and the output log. \"\"\"\n\n\t@abstractmethod\n\tdef get_ref_info(self, nodes: List[NodeWithScore]) -&gt; List[RefInfoBase]:\n\t\tr\"\"\" Get the reference infos from the retrieved nodes. \"\"\"\n\n\t@property\n\tdef retriever(self) -&gt; BaseRetriever:\n\t\treturn self._retriever\n\n\t@property\n\tdef metadata(self) -&gt; ToolMetadata:\n\t\treturn self._metadata\n\n\tdef call(self, **kwargs: Any) -&gt; ToolOutput:\n\t\tr\"\"\"\n\t\tCall the retrieving function or method, and pack the output and logs.\n\n\t\tArgs:\n\t\t\t**kwargs: The keyword arguments will be provided by the agent.\n\n\t\tReturns:\n\t\t\tToolOutput: The tool output and logs.\n\n\t\t\"\"\"\n\t\tretrieve_kwargs = self._get_input(**kwargs)\n\t\tnodes = self._retrieve(retrieve_kwargs=retrieve_kwargs)\n\t\tretrieve_output, output_log_dict = self._nodes_to_tool_output(nodes=nodes)\n\t\toutput_log_dict.update(retrieve_kwargs)\n\t\ttool_log = self.log(log_dict=output_log_dict)\n\n\t\tcontent = pack_tool_output(tool_output=retrieve_output, tool_log=tool_log.dumps())\n\t\treturn ToolOutput(\n\t\t\tcontent=content,\n\t\t\ttool_name=self.metadata.name,\n\t\t\traw_input={\"input\": retrieve_kwargs},\n\t\t\traw_output=nodes,\n\t\t)\n\n\tasync def acall(self, **kwargs: Any) -&gt; ToolOutput:\n\t\tr\"\"\"\n\t\tAsynchronously call the retrieving function or method, and pack the output and logs.\n\n\t\tArgs:\n\t\t\t**kwargs: The keyword arguments will be provided by the agent.\n\n\t\tReturns:\n\t\t\tToolOutput: The tool output and logs.\n\n\t\t\"\"\"\n\t\tretrieve_kwargs = self._get_input(**kwargs)\n\t\tnodes = await self._aretrieve(retrieve_kwargs=retrieve_kwargs)\n\t\tretrieve_output, output_log_dict = self._nodes_to_tool_output(nodes=nodes)\n\t\toutput_log_dict.update(retrieve_kwargs)\n\t\ttool_log = self.log(log_dict=output_log_dict)\n\n\t\tcontent = pack_tool_output(tool_output=retrieve_output, tool_log=tool_log.dumps())\n\t\treturn ToolOutput(\n\t\t\tcontent=content,\n\t\t\ttool_name=self.metadata.name,\n\t\t\traw_input={\"input\": retrieve_kwargs},\n\t\t\traw_output=nodes,\n\t\t)\n</code></pre>"},{"location":"code_docs/tools/base/tool_base/#labridge.tools.base.tool_base.RetrieverBaseTool.acall","title":"<code>labridge.tools.base.tool_base.RetrieverBaseTool.acall(**kwargs)</code>  <code>async</code>","text":"<p>Asynchronously call the retrieving function or method, and pack the output and logs.</p> PARAMETER DESCRIPTION <code>**kwargs</code> <p>The keyword arguments will be provided by the agent.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>ToolOutput</code> <p>The tool output and logs.</p> <p> TYPE: <code>ToolOutput</code> </p> Source code in <code>labridge\\tools\\base\\tool_base.py</code> <pre><code>async def acall(self, **kwargs: Any) -&gt; ToolOutput:\n\tr\"\"\"\n\tAsynchronously call the retrieving function or method, and pack the output and logs.\n\n\tArgs:\n\t\t**kwargs: The keyword arguments will be provided by the agent.\n\n\tReturns:\n\t\tToolOutput: The tool output and logs.\n\n\t\"\"\"\n\tretrieve_kwargs = self._get_input(**kwargs)\n\tnodes = await self._aretrieve(retrieve_kwargs=retrieve_kwargs)\n\tretrieve_output, output_log_dict = self._nodes_to_tool_output(nodes=nodes)\n\toutput_log_dict.update(retrieve_kwargs)\n\ttool_log = self.log(log_dict=output_log_dict)\n\n\tcontent = pack_tool_output(tool_output=retrieve_output, tool_log=tool_log.dumps())\n\treturn ToolOutput(\n\t\tcontent=content,\n\t\ttool_name=self.metadata.name,\n\t\traw_input={\"input\": retrieve_kwargs},\n\t\traw_output=nodes,\n\t)\n</code></pre>"},{"location":"code_docs/tools/base/tool_base/#labridge.tools.base.tool_base.RetrieverBaseTool.call","title":"<code>labridge.tools.base.tool_base.RetrieverBaseTool.call(**kwargs)</code>","text":"<p>Call the retrieving function or method, and pack the output and logs.</p> PARAMETER DESCRIPTION <code>**kwargs</code> <p>The keyword arguments will be provided by the agent.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>ToolOutput</code> <p>The tool output and logs.</p> <p> TYPE: <code>ToolOutput</code> </p> Source code in <code>labridge\\tools\\base\\tool_base.py</code> <pre><code>def call(self, **kwargs: Any) -&gt; ToolOutput:\n\tr\"\"\"\n\tCall the retrieving function or method, and pack the output and logs.\n\n\tArgs:\n\t\t**kwargs: The keyword arguments will be provided by the agent.\n\n\tReturns:\n\t\tToolOutput: The tool output and logs.\n\n\t\"\"\"\n\tretrieve_kwargs = self._get_input(**kwargs)\n\tnodes = self._retrieve(retrieve_kwargs=retrieve_kwargs)\n\tretrieve_output, output_log_dict = self._nodes_to_tool_output(nodes=nodes)\n\toutput_log_dict.update(retrieve_kwargs)\n\ttool_log = self.log(log_dict=output_log_dict)\n\n\tcontent = pack_tool_output(tool_output=retrieve_output, tool_log=tool_log.dumps())\n\treturn ToolOutput(\n\t\tcontent=content,\n\t\ttool_name=self.metadata.name,\n\t\traw_input={\"input\": retrieve_kwargs},\n\t\traw_output=nodes,\n\t)\n</code></pre>"},{"location":"code_docs/tools/base/tool_base/#labridge.tools.base.tool_base.RetrieverBaseTool.get_ref_info","title":"<code>labridge.tools.base.tool_base.RetrieverBaseTool.get_ref_info(nodes)</code>  <code>abstractmethod</code>","text":"<p>Get the reference infos from the retrieved nodes.</p> Source code in <code>labridge\\tools\\base\\tool_base.py</code> <pre><code>@abstractmethod\ndef get_ref_info(self, nodes: List[NodeWithScore]) -&gt; List[RefInfoBase]:\n\tr\"\"\" Get the reference infos from the retrieved nodes. \"\"\"\n</code></pre>"},{"location":"code_docs/tools/base/tool_base/#labridge.tools.base.tool_base.RetrieverBaseTool.log","title":"<code>labridge.tools.base.tool_base.RetrieverBaseTool.log(log_dict)</code>  <code>abstractmethod</code>","text":"<p>Return the ToolLog with log string in a specific format.</p> Source code in <code>labridge\\tools\\base\\tool_base.py</code> <pre><code>@abstractmethod\ndef log(self, log_dict: dict) -&gt; ToolLog:\n\tr\"\"\" Return the ToolLog with log string in a specific format. \"\"\"\n</code></pre>"},{"location":"code_docs/tools/base/tool_log/","title":"Tool log","text":""},{"location":"code_docs/tools/base/tool_log/#labridge.tools.base.tool_log","title":"<code>labridge.tools.base.tool_log</code>","text":""},{"location":"code_docs/tools/base/tool_log/#labridge.tools.base.tool_log.ToolLog","title":"<code>labridge.tools.base.tool_log.ToolLog</code>","text":"<p>               Bases: <code>object</code></p> <p>This class record the log of a specific tool. The <code>log_to_user</code> and <code>references</code> in <code>log_to_system</code> will be presented to the users.</p> PARAMETER DESCRIPTION <code>tool_name</code> <p>The tool name.</p> <p> TYPE: <code>str</code> </p> <code>log_to_user</code> <p>This log might be presented to the users.</p> <p> TYPE: <code>str</code> </p> <code>log_to_system</code> <p>This log is more structured, specifically, it is a dictionary in JSON format. The keys 'operation_description' and 'references' are required. The values of <code>references</code> are either None or List[str], where the <code>str</code> is in JSON format.</p> <p> TYPE: <code>dict</code> </p> Source code in <code>labridge\\tools\\base\\tool_log.py</code> <pre><code>class ToolLog(object):\n\tr\"\"\"\n\tThis class record the log of a specific tool.\n\tThe `log_to_user` and `references` in `log_to_system` will be presented to the users.\n\n\tArgs:\n\t\ttool_name (str): The tool name.\n\t\tlog_to_user (str): This log might be presented to the users.\n\t\tlog_to_system (dict): This log is more structured, specifically, it is a dictionary in JSON format.\n\t\t\tThe keys 'operation_description' and 'references' are required. The values of `references` are either\n\t\t\tNone or List[str], where the `str` is in JSON format.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\ttool_name: str,\n\t\tlog_to_user: Optional[str],\n\t\tlog_to_system: Dict[str, Union[str, Optional[List[str]]]],\n\t\ttool_abort: Optional[bool] = False,\n\t):\n\t\tself.tool_name = tool_name\n\t\tself.log_to_user = log_to_user\n\t\tself.tool_abort = tool_abort\n\n\t\tfor key in LOG_TO_SYSTEM_KEYS:\n\t\t\tif key not in log_to_system.keys():\n\t\t\t\traise ValueError(f\"The key {key} is required in the log_to_system.\")\n\n\t\tref = log_to_system[TOOL_REFERENCES]\n\t\tif ref and not isinstance(ref, list):\n\t\t\traise ValueError(f\"The value of '{TOOL_REFERENCES}' can only be list or None.\")\n\t\tself.log_to_system = log_to_system\n\n\t@classmethod\n\tdef construct(\n\t\tcls,\n\t\ttool_name: str,\n\t\ttool_op_description: str,\n\t\ttool_references: Optional[List[str]] = None,\n\t\tlog_to_user: str = None,\n\t\ttool_abort: Optional[bool] = False,\n\t):\n\t\treturn cls(\n\t\t\ttool_name=tool_name,\n\t\t\tlog_to_user=log_to_user,\n\t\t\tlog_to_system={\n\t\t\t\tTOOL_OP_DESCRIPTION: tool_op_description,\n\t\t\t\tTOOL_REFERENCES: tool_references,\n\t\t\t},\n\t\t\ttool_abort=tool_abort,\n\t\t)\n\n\tdef dumps(self) -&gt; str:\n\t\tr\"\"\"\n\t\tDump to a string.\n\n\t\tReturns:\n\t\t\tstr: the dumped string.\n\t\t\"\"\"\n\t\tlogs = {\n\t\t\t\"tool_name\": self.tool_name,\n\t\t\t\"log_to_user\": self.log_to_user,\n\t\t\t\"log_to_system\": self.log_to_system,\n\t\t\t\"tool_abort\": self.tool_abort,\n\t\t}\n\t\treturn json.dumps(logs)\n\n\t@classmethod\n\tdef loads(\n\t\tcls,\n\t\tlog_str: str,\n\t):\n\t\tr\"\"\"\n\t\tLoad from a string.\n\n\t\tArgs:\n\t\t\tlog_str (str): The dumped string of a ToolLog object.\n\n\t\tReturns:\n\t\t\tThe loaded ToolLog object.\n\t\t\"\"\"\n\t\ttry:\n\t\t\tlogs = json.loads(log_str)\n\t\t\ttool_name = logs[\"tool_name\"]\n\t\t\tlog_to_user = logs[\"log_to_user\"]\n\t\t\tlog_to_system = logs[\"log_to_system\"]\n\t\t\ttool_abort = logs[\"tool_abort\"]\n\t\t\treturn cls(\n\t\t\t\ttool_name=tool_name,\n\t\t\t\tlog_to_user=log_to_user,\n\t\t\t\tlog_to_system=log_to_system,\n\t\t\t\ttool_abort=tool_abort,\n\t\t\t)\n\t\texcept Exception:\n\t\t\traise ValueError(\"Invalid tool log string.\")\n</code></pre>"},{"location":"code_docs/tools/base/tool_log/#labridge.tools.base.tool_log.ToolLog.dumps","title":"<code>labridge.tools.base.tool_log.ToolLog.dumps()</code>","text":"<p>Dump to a string.</p> RETURNS DESCRIPTION <code>str</code> <p>the dumped string.</p> <p> TYPE: <code>str</code> </p> Source code in <code>labridge\\tools\\base\\tool_log.py</code> <pre><code>def dumps(self) -&gt; str:\n\tr\"\"\"\n\tDump to a string.\n\n\tReturns:\n\t\tstr: the dumped string.\n\t\"\"\"\n\tlogs = {\n\t\t\"tool_name\": self.tool_name,\n\t\t\"log_to_user\": self.log_to_user,\n\t\t\"log_to_system\": self.log_to_system,\n\t\t\"tool_abort\": self.tool_abort,\n\t}\n\treturn json.dumps(logs)\n</code></pre>"},{"location":"code_docs/tools/base/tool_log/#labridge.tools.base.tool_log.ToolLog.loads","title":"<code>labridge.tools.base.tool_log.ToolLog.loads(log_str)</code>  <code>classmethod</code>","text":"<p>Load from a string.</p> PARAMETER DESCRIPTION <code>log_str</code> <p>The dumped string of a ToolLog object.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <p>The loaded ToolLog object.</p> Source code in <code>labridge\\tools\\base\\tool_log.py</code> <pre><code>@classmethod\ndef loads(\n\tcls,\n\tlog_str: str,\n):\n\tr\"\"\"\n\tLoad from a string.\n\n\tArgs:\n\t\tlog_str (str): The dumped string of a ToolLog object.\n\n\tReturns:\n\t\tThe loaded ToolLog object.\n\t\"\"\"\n\ttry:\n\t\tlogs = json.loads(log_str)\n\t\ttool_name = logs[\"tool_name\"]\n\t\tlog_to_user = logs[\"log_to_user\"]\n\t\tlog_to_system = logs[\"log_to_system\"]\n\t\ttool_abort = logs[\"tool_abort\"]\n\t\treturn cls(\n\t\t\ttool_name=tool_name,\n\t\t\tlog_to_user=log_to_user,\n\t\t\tlog_to_system=log_to_system,\n\t\t\ttool_abort=tool_abort,\n\t\t)\n\texcept Exception:\n\t\traise ValueError(\"Invalid tool log string.\")\n</code></pre>"},{"location":"code_docs/tools/common/date_time/","title":"Date time","text":""},{"location":"code_docs/tools/common/date_time/#labridge.tools.common.date_time","title":"<code>labridge.tools.common.date_time</code>","text":""},{"location":"code_docs/tools/common/date_time/#labridge.tools.common.date_time.get_current_date_time","title":"<code>labridge.tools.common.date_time.get_current_date_time()</code>","text":"<p>This function is used to get the date of today, current time. If you are not sure about current date or time, use this tool to help you.</p> <p>The returned date is of the following format: \"Year-Month-Day\". The returned time is of the following format: \"Hour:Minute:Time\".</p> Source code in <code>labridge\\tools\\common\\date_time.py</code> <pre><code>def get_current_date_time() -&gt; FuncOutputWithLog:\n\tr\"\"\"\n\tThis function is used to get the date of today, current time.\n\tIf you are not sure about current date or time, use this tool to help you.\n\n\tThe returned date is of the following format: \"Year-Month-Day\".\n\tThe returned time is of the following format: \"Hour:Minute:Time\".\n\t\"\"\"\n\ttoday = datetime.datetime.today()\n\tcurrent_date = today.date().strftime(DATE_FORMAT)\n\tcurrent_time = today.time().strftime(TIME_FORMAT)\n\tcurrent_weekday = today.weekday() + 1\n\n\tdatetime_str = (\n\t\tf\"Today is {current_date}\\n\"\n\t\tf\"Today is the No.{current_weekday} day in a week.\\n\"\n\t\tf\"Current time is {current_time}\\n\"\n\t)\n\treturn FuncOutputWithLog(\n\t\tfn_output=datetime_str,\n\t\tfn_log=\"\",\n\t)\n</code></pre>"},{"location":"code_docs/tools/common/date_time/#labridge.tools.common.date_time.get_date_time_from_now","title":"<code>labridge.tools.common.date_time.get_date_time_from_now(backward, days)</code>","text":"<p>This function is used to infer the exact date that a statement means. such as '3 days ago', '2 months later'.</p> PARAMETER DESCRIPTION <code>backward</code> <p>the direction, if the statement means the date earlier than now, it is set to <code>True</code>. Otherwise, it is <code>False</code>.</p> <p> TYPE: <code>bool</code> </p> <code>days</code> <p>the number of days</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>FuncOutputWithLog</code> <p>the result date.</p> Source code in <code>labridge\\tools\\common\\date_time.py</code> <pre><code>def get_date_time_from_now(backward: bool, days: int) -&gt; FuncOutputWithLog:\n\tr\"\"\"\n\tThis function is used to infer the exact date that a statement means. such as '3 days ago', '2 months later'.\n\n\tArgs:\n\t\tbackward (bool): the direction, if the statement means the date earlier than now, it is set to `True`.\n\t\t\tOtherwise, it is `False`.\n\t\tdays (int): the number of days\n\n\tReturns:\n\t\tthe result date.\n\t\"\"\"\n\ttoday = datetime.datetime.today()\n\tif backward:\n\t\tresult_datetime = today - datetime.timedelta(days=days)\n\telse:\n\t\tresult_datetime = today + datetime.timedelta(days=days)\n\n\tresult_date = result_datetime.date().strftime(DATE_FORMAT)\n\tresult_weekday = result_datetime.weekday() + 1\n\tdirection_str = \"ago\" if backward else \"later\"\n\tdatetime_str = (\n\t\tf\"{days} days {direction_str} is {result_date}\\n\"\n\t\tf\"the No.{result_weekday} day in a week.\\n\"\n\t)\n\treturn FuncOutputWithLog(\n\t\tfn_output=datetime_str,\n\t\tfn_log=\"\",\n\t)\n</code></pre>"},{"location":"code_docs/tools/instrument/retrieve/","title":"Retrieve","text":""},{"location":"code_docs/tools/instrument/retrieve/#labridge.tools.instrument.retrieve","title":"<code>labridge.tools.instrument.retrieve</code>","text":""},{"location":"code_docs/tools/instrument/retrieve/#labridge.tools.instrument.retrieve.InstrumentRetrieverTool","title":"<code>labridge.tools.instrument.retrieve.InstrumentRetrieverTool</code>","text":"<p>               Bases: <code>RetrieverBaseTool</code></p> Source code in <code>labridge\\tools\\instrument\\retrieve.py</code> <pre><code>class InstrumentRetrieverTool(RetrieverBaseTool):\n\tdef __init__(\n\t\tself,\n\t\tllm: LLM = None,\n\t\tembed_model: BaseEmbedding = None,\n\t\tmetadata_mode: MetadataMode = MetadataMode.NONE,\n\t):\n\t\tinstrument_retriever = InstrumentRetriever(\n\t\t\tllm=llm,\n\t\t\tembed_model=embed_model,\n\t\t)\n\t\tself.metadata_mode = metadata_mode\n\t\tself.super_user_manager = InstrumentSuperUserManager()\n\t\tsuper().__init__(\n\t\t\tretriever=instrument_retriever,\n\t\t\tname=InstrumentRetrieverTool.__name__,\n\t\t\tretrieve_fn=InstrumentRetriever.retrieve\n\t\t)\n\n\tdef log(self, log_dict: dict) -&gt; ToolLog:\n\t\tref_infos: List[InstrumentInfo] = log_dict[TOOL_LOG_REF_INFO_KEY]\n\t\tinstrument_infos = [info.dumps() for info in ref_infos]\n\n\t\tlog_to_user = None\n\t\tlog_to_system = {\n\t\t\tTOOL_OP_DESCRIPTION: f\"Use the {self.metadata.name} to retrieve the instrument docs.\",\n\t\t\tTOOL_REFERENCES: instrument_infos,\n\t\t}\n\n\t\treturn ToolLog(\n\t\t\ttool_name=self.metadata.name,\n\t\t\tlog_to_user=log_to_user,\n\t\t\tlog_to_system=log_to_system,\n\t\t)\n\n\tdef _retrieve(self, retrieve_kwargs: dict) -&gt; List[NodeWithScore]:\n\t\tnodes = self._retriever.retrieve(**retrieve_kwargs)\n\t\treturn nodes\n\n\tasync def _aretrieve(self, retrieve_kwargs: dict) -&gt; List[NodeWithScore]:\n\t\tnodes = await self._retriever.aretrieve(**retrieve_kwargs)\n\t\treturn nodes\n\n\tdef get_ref_info(self, nodes: List[NodeWithScore]) -&gt; List[RefInfoBase]:\n\t\tr\"\"\" Get the reference infos from the retrieved nodes. \"\"\"\n\t\tinstrument_infos = []\n\t\tinstrument_set = set()\n\t\tfor node in nodes:\n\t\t\tinstrument_id = node.metadata.get(INSTRUMENT_NAME_KEY, node.node_id)\n\t\t\t# TODO: Add node type and filter.\n\t\t\tif instrument_id == INSTRUMENT_ROOT_NODE_NAME or instrument_id in instrument_set:\n\t\t\t\tcontinue\n\t\t\tinstrument_set.add(instrument_id)\n\t\t\tsuper_users = self.super_user_manager.get_super_users(\n\t\t\t\tinstrument_id=instrument_id,\n\t\t\t)\n\t\t\tinfo = InstrumentInfo(\n\t\t\t\tinstrument_id=instrument_id,\n\t\t\t\tsuper_users=super_users,\n\t\t\t)\n\t\t\tinstrument_infos.append(info)\n\t\treturn instrument_infos\n\n\tdef _nodes_to_tool_output(self, nodes: List[NodeWithScore]) -&gt; Tuple[str, dict]:\n\t\tr\"\"\" output the retrieved contents in a specific format. \"\"\"\n\t\toutput = \"\"\n\t\theader = f\"Have retrieved the docs of several relevant instruments:\\n\\n\"\n\t\toutput += header\n\n\t\tif len(nodes) &lt; 1:\n\t\t\toutput += \"No relevant instrument contents found.\"\n\n\t\tref_infos = self.get_ref_info(nodes=nodes)\n\t\tlog_dict = {\n\t\t\tTOOL_LOG_REF_INFO_KEY: ref_infos,\n\t\t}\n\n\t\tinstrument_docs = dict()\n\t\tfor node in nodes:\n\t\t\tinstrument_id = node.metadata.get(INSTRUMENT_NAME_KEY, node.node_id)\n\t\t\t# TODO: Add node type and filter.\n\t\t\tif instrument_id == INSTRUMENT_ROOT_NODE_NAME:\n\t\t\t\tcontinue\n\t\t\tif instrument_id not in instrument_docs:\n\t\t\t\tinstrument_docs[instrument_id] = []\n\t\t\tinstrument_docs[instrument_id].append(node)\n\n\t\tfor instrument_id in instrument_docs.keys():\n\t\t\tinstrument_content = f\"Instrument Name: {instrument_id}\\n\"\n\t\t\tfor idx, node in enumerate(instrument_docs[instrument_id]):\n\t\t\t\tinstrument_content += (\n\t\t\t\t\tf\"Retrieved content {idx + 1}:\\n\"\n\t\t\t\t\tf\"{node.node.get_content(metadata_mode=self.metadata_mode)}\\n\"\n\t\t\t)\n\t\t\toutput += f\"{instrument_content}\\n\"\n\t\treturn output, log_dict\n</code></pre>"},{"location":"code_docs/tools/instrument/retrieve/#labridge.tools.instrument.retrieve.InstrumentRetrieverTool.get_ref_info","title":"<code>labridge.tools.instrument.retrieve.InstrumentRetrieverTool.get_ref_info(nodes)</code>","text":"<p>Get the reference infos from the retrieved nodes.</p> Source code in <code>labridge\\tools\\instrument\\retrieve.py</code> <pre><code>def get_ref_info(self, nodes: List[NodeWithScore]) -&gt; List[RefInfoBase]:\n\tr\"\"\" Get the reference infos from the retrieved nodes. \"\"\"\n\tinstrument_infos = []\n\tinstrument_set = set()\n\tfor node in nodes:\n\t\tinstrument_id = node.metadata.get(INSTRUMENT_NAME_KEY, node.node_id)\n\t\t# TODO: Add node type and filter.\n\t\tif instrument_id == INSTRUMENT_ROOT_NODE_NAME or instrument_id in instrument_set:\n\t\t\tcontinue\n\t\tinstrument_set.add(instrument_id)\n\t\tsuper_users = self.super_user_manager.get_super_users(\n\t\t\tinstrument_id=instrument_id,\n\t\t)\n\t\tinfo = InstrumentInfo(\n\t\t\tinstrument_id=instrument_id,\n\t\t\tsuper_users=super_users,\n\t\t)\n\t\tinstrument_infos.append(info)\n\treturn instrument_infos\n</code></pre>"},{"location":"code_docs/tools/interact/collect_and_authorize/","title":"Collect and authorize","text":""},{"location":"code_docs/tools/interact/collect_and_authorize/#labridge.tools.interact.collect_and_authorize","title":"<code>labridge.tools.interact.collect_and_authorize</code>","text":""},{"location":"code_docs/tools/interact/collect_and_authorize/#labridge.tools.interact.collect_and_authorize.CollectAndAuthorizeTool","title":"<code>labridge.tools.interact.collect_and_authorize.CollectAndAuthorizeTool</code>","text":"<p>               Bases: <code>CallBackBaseTool</code></p> <p>This tool is the template for tools whose process involves information collection from users and the getting final operation authorization from the user.</p> PARAMETER DESCRIPTION <code>tool_fn</code> <p>The function that executes the entire process of a specific tool.</p> <p> TYPE: <code>Callable</code> </p> <code>tool_async_fn</code> <p>The function that asynchronously executes the entire process of a specific tool.</p> <p> TYPE: <code>Callable</code> </p> <code>callback_operation</code> <p>The operation that needs the user's authorization.</p> <p> TYPE: <code>CallBackOperationBase</code> </p> <code>tool_name</code> <p>The tool name, recommend the name of the specified tool class.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>llm</code> <p>The used large language model.</p> <p> TYPE: <code>LLM</code> DEFAULT: <code>None</code> </p> <code>embed_model</code> <p>The used embedding model.</p> <p> TYPE: <code>BaseEmbedding</code> DEFAULT: <code>None</code> </p> <code>verbose</code> <p>Whether to show the inner progress.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> Source code in <code>labridge\\tools\\interact\\collect_and_authorize.py</code> <pre><code>class CollectAndAuthorizeTool(CallBackBaseTool):\n\tr\"\"\"\n\tThis tool is the template for tools whose process involves information collection from users\n\tand the getting final operation authorization from the user.\n\n\tArgs:\n\t\ttool_fn (Callable): The function that executes the entire process of a specific tool.\n\t\ttool_async_fn (Callable): The function that asynchronously executes the entire process of a specific tool.\n\t\tcallback_operation (CallBackOperationBase): The operation that needs the user's authorization.\n\t\ttool_name (str): The tool name, recommend the name of the specified tool class.\n\t\tllm (LLM): The used large language model.\n\t\tembed_model (BaseEmbedding): The used embedding model.\n\t\tverbose (bool): Whether to show the inner progress.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\ttool_fn: Callable[..., Any],\n\t\ttool_async_fn: Callable[..., Any],\n\t\tcallback_operation: CallBackOperationBase,\n\t\ttool_name: str = None,\n\t\tllm: LLM = None,\n\t\tembed_model: BaseEmbedding = None,\n\t\tverbose: bool = False,\n\t):\n\t\tself._llm = llm or Settings.llm\n\t\tself._embed_model = embed_model or Settings.embed_model\n\t\tself._verbose = verbose\n\t\tsuper().__init__(\n\t\t\tfn=tool_fn,\n\t\t\tasync_fn=tool_async_fn,\n\t\t\ttool_name=tool_name,\n\t\t\tcallback_operation=callback_operation,\n\t\t)\n\n\t@abstractmethod\n\tdef required_infos(self) -&gt; List[CollectingInfoBase]:\n\t\tr\"\"\" The required infos. \"\"\"\n\n\n\t@abstractmethod\n\tdef required_info_dict(self) -&gt; Dict[str, str]:\n\t\tr\"\"\" The required info names and their descriptions \"\"\"\n\n\tdef log(self, **kwargs: Any) -&gt; ToolLog:\n\t\tr\"\"\"\n\t\tRecord the tool's logs.\n\n\t\tArgs:\n\t\t\t**kwargs: The input keyword arguments and the (output, log) of the callback operation.\n\n\t\tReturns:\n\t\t\ttool_log (ToolLog): The tool logs, including tool_to_user and tool_to_system.\n\t\t\"\"\"\n\t\tuser_id = kwargs[\"user_id\"]\n\t\tcollected_info = \",\".join(list(self.required_info_dict().keys()))\n\t\tlog_to_system_str = (\n\t\t\tf\"Have collected these information from the user {user_id}:\\n\"\n\t\t\tf\"{collected_info}\\n\"\n\t\t\tf\"Then try to do the following operation.\\n\"\n\t\t)\n\n\t\top_log: OperationOutputLog = kwargs[\"operation_log\"]\n\t\tif not isinstance(op_log, OperationOutputLog):\n\t\t\traise ValueError(\"The operation_log must be 'OperationOutputLog'.\")\n\n\t\tlog_to_system_str += op_log.log_to_system[OP_DESCRIPTION]\n\n\t\tlog_to_user = op_log.log_to_user\n\t\tlog_to_system = {\n\t\t\tTOOL_OP_DESCRIPTION: log_to_system_str,\n\t\t\tTOOL_REFERENCES: op_log.log_to_system[OP_REFERENCES],\n\t\t}\n\n\t\ttool_log = ToolLog(\n\t\t\ttool_name=self.metadata.name,\n\t\t\tlog_to_user=log_to_user,\n\t\t\tlog_to_system=log_to_system,\n\t\t\ttool_abort=op_log.operation_abort,\n\t\t)\n\t\treturn tool_log\n\n\tdef collect_and_authorize(\n\t\tself,\n\t\tuser_id: str,\n\t\tquery_str: str,\n\t) -&gt; FuncOutputWithLog:\n\t\tr\"\"\"\n\t\tThis Method is a template method can be reused in subclass to reduce code redundancy.\n\n\t\tFirstly, this method will collect the required infos from the user.\n\t\tThen, the agent will generate the operation description according to the collected information.\n\t\tFinally, the agent will ask for the user's authorization to execute the operation.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user_id of a lab member.\n\t\t\tquery_str (str): The query from the user.\n\n\t\tReturns:\n\t\t\toutput_log (FuncOutputWithLog):\n\t\t\t\tincluding the output of the callback operation and the tool's log.\n\t\t\"\"\"\n\t\tinfo_dict = collect_info_from_user(\n\t\t\tuser_id=user_id,\n\t\t\trequired_infos=self.required_infos(),\n\t\t\tquery_str=query_str,\n\t\t)\n\n\t\tif info_dict is None:\n\t\t\top_name = self._callback_operation.__name__\n\t\t\toperation_log_str = (\n\t\t\t\tf\"The user {user_id} aborts this operation {op_name}.\"\n\t\t\t)\n\t\t\toperation_log = OperationOutputLog(\n\t\t\t\toperation_name=op_name,\n\t\t\t\toperation_output=None,\n\t\t\t\tlog_to_user=None,\n\t\t\t\tlog_to_system={\n\t\t\t\t\tOP_DESCRIPTION: operation_log_str,\n\t\t\t\t\tOP_REFERENCES: None,\n\t\t\t\t},\n\t\t\t\toperation_abort=True,\n\t\t\t)\n\t\t\tlog_dict = {\"operation_log\": operation_log}\n\n\t\t\treturn FuncOutputWithLog(\n\t\t\t\tfn_output=f\"The user {user_id} abort the collecting process in the operation {op_name}\",\n\t\t\t\tfn_log=log_dict,\n\t\t\t)\n\n\t\top_name = self._callback_operation.__name__\n\t\tkwargs = {\"user_id\": user_id, }\n\t\tfor key in self.required_info_dict().keys():\n\t\t\tkwargs[key] = info_dict[key]\n\t\tkwargs_str = json.dumps(kwargs)\n\t\toperation_log = operation_authorize(\n\t\t\tuser_id=user_id,\n\t\t\top_name=op_name,\n\t\t\tkwargs_str=kwargs_str,\n\t\t\tllm=self._llm,\n\t\t\tembed_model=self._embed_model,\n\t\t\tverbose=self._verbose,\n\t\t)\n\t\tlog = {\"operation_log\": operation_log}\n\t\tfn_output = f\"Have done the operation {op_name} with the agreement of the user {user_id}.\"\n\t\tif operation_log.operation_output is not None:\n\t\t\tfn_output += f\"\\nOperation output:\\n{operation_log.operation_output}\"\n\t\treturn FuncOutputWithLog(\n\t\t\tfn_output=fn_output,\n\t\t\tfn_log=log,\n\t\t)\n\n\tasync def acollect_and_authorize(\n\t\tself,\n\t\tuser_id: str,\n\t\tquery_str: str,\n\t) -&gt; FuncOutputWithLog:\n\t\tr\"\"\"\n\t\tThis Method is an asynchronous version template method can be reused in subclass to reduce code redundancy.\n\n\t\tFirstly, this method will collect the required infos from the user.\n\t\tThen, the agent will generate the operation description according to the collected information.\n\t\tFinally, the agent will ask for the user's authorization to execute the operation.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user_id of a lab member.\n\t\t\tquery_str (str): The query from the user.\n\n\t\tReturns:\n\t\t\toutput_log (FuncOutputWithLog):\n\t\t\t\tincluding the output of the callback operation and the tool's log.\n\t\t\"\"\"\n\t\tinfo_dict = await acollect_info_from_user(\n\t\t\tuser_id=user_id,\n\t\t\trequired_infos=self.required_infos(),\n\t\t\tquery_str=query_str,\n\t\t)\n\n\t\top_name = self._callback_operation.__name__\n\t\tif info_dict is None:\n\t\t\toperation_log_str = (\n\t\t\t\tf\"The user {user_id} abort this operation.\"\n\t\t\t)\n\t\t\toperation_log = OperationOutputLog(\n\t\t\t\toperation_name=self._callback_operation.__name__,\n\t\t\t\toperation_output=None,\n\t\t\t\tlog_to_user=None,\n\t\t\t\tlog_to_system={\n\t\t\t\t\tOP_DESCRIPTION: operation_log_str,\n\t\t\t\t\tOP_REFERENCES: None,\n\t\t\t\t},\n\t\t\t\toperation_abort=True,\n\t\t\t)\n\t\t\tlog_dict = {\"operation_log\": operation_log}\n\t\t\treturn FuncOutputWithLog(\n\t\t\t\tfn_output=f\"The user {user_id} abort the collecting process in the operation {op_name}\",\n\t\t\t\tfn_log=log_dict,\n\t\t\t)\n\n\t\tkwargs = {\"user_id\": user_id, }\n\t\tfor key in self.required_info_dict().keys():\n\t\t\tkwargs[key] = info_dict[key]\n\t\tkwargs_str = json.dumps(kwargs)\n\t\toperation_log = await aoperation_authorize(\n\t\t\tuser_id=user_id,\n\t\t\top_name=op_name,\n\t\t\tkwargs_str=kwargs_str,\n\t\t\tllm=self._llm,\n\t\t\tembed_model=self._embed_model,\n\t\t\tverbose=self._verbose,\n\t\t)\n\t\tprint(\"Here: after refuse: \", operation_log)\n\t\tlog_dict = {\"operation_log\": operation_log}\n\t\tfn_output = f\"Have done the operation {op_name} with the agreement of the user {user_id}.\"\n\t\tif operation_log.operation_output is not None:\n\t\t\tfn_output += f\"\\nOperation output:\\n{operation_log.operation_output}\"\n\t\treturn FuncOutputWithLog(\n\t\t\tfn_output=fn_output,\n\t\t\tfn_log=log_dict,\n\t\t)\n</code></pre>"},{"location":"code_docs/tools/interact/collect_and_authorize/#labridge.tools.interact.collect_and_authorize.CollectAndAuthorizeTool.acollect_and_authorize","title":"<code>labridge.tools.interact.collect_and_authorize.CollectAndAuthorizeTool.acollect_and_authorize(user_id, query_str)</code>  <code>async</code>","text":"<p>This Method is an asynchronous version template method can be reused in subclass to reduce code redundancy.</p> <p>Firstly, this method will collect the required infos from the user. Then, the agent will generate the operation description according to the collected information. Finally, the agent will ask for the user's authorization to execute the operation.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user_id of a lab member.</p> <p> TYPE: <code>str</code> </p> <code>query_str</code> <p>The query from the user.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>output_log</code> <p>including the output of the callback operation and the tool's log.</p> <p> TYPE: <code>FuncOutputWithLog</code> </p> Source code in <code>labridge\\tools\\interact\\collect_and_authorize.py</code> <pre><code>async def acollect_and_authorize(\n\tself,\n\tuser_id: str,\n\tquery_str: str,\n) -&gt; FuncOutputWithLog:\n\tr\"\"\"\n\tThis Method is an asynchronous version template method can be reused in subclass to reduce code redundancy.\n\n\tFirstly, this method will collect the required infos from the user.\n\tThen, the agent will generate the operation description according to the collected information.\n\tFinally, the agent will ask for the user's authorization to execute the operation.\n\n\tArgs:\n\t\tuser_id (str): The user_id of a lab member.\n\t\tquery_str (str): The query from the user.\n\n\tReturns:\n\t\toutput_log (FuncOutputWithLog):\n\t\t\tincluding the output of the callback operation and the tool's log.\n\t\"\"\"\n\tinfo_dict = await acollect_info_from_user(\n\t\tuser_id=user_id,\n\t\trequired_infos=self.required_infos(),\n\t\tquery_str=query_str,\n\t)\n\n\top_name = self._callback_operation.__name__\n\tif info_dict is None:\n\t\toperation_log_str = (\n\t\t\tf\"The user {user_id} abort this operation.\"\n\t\t)\n\t\toperation_log = OperationOutputLog(\n\t\t\toperation_name=self._callback_operation.__name__,\n\t\t\toperation_output=None,\n\t\t\tlog_to_user=None,\n\t\t\tlog_to_system={\n\t\t\t\tOP_DESCRIPTION: operation_log_str,\n\t\t\t\tOP_REFERENCES: None,\n\t\t\t},\n\t\t\toperation_abort=True,\n\t\t)\n\t\tlog_dict = {\"operation_log\": operation_log}\n\t\treturn FuncOutputWithLog(\n\t\t\tfn_output=f\"The user {user_id} abort the collecting process in the operation {op_name}\",\n\t\t\tfn_log=log_dict,\n\t\t)\n\n\tkwargs = {\"user_id\": user_id, }\n\tfor key in self.required_info_dict().keys():\n\t\tkwargs[key] = info_dict[key]\n\tkwargs_str = json.dumps(kwargs)\n\toperation_log = await aoperation_authorize(\n\t\tuser_id=user_id,\n\t\top_name=op_name,\n\t\tkwargs_str=kwargs_str,\n\t\tllm=self._llm,\n\t\tembed_model=self._embed_model,\n\t\tverbose=self._verbose,\n\t)\n\tprint(\"Here: after refuse: \", operation_log)\n\tlog_dict = {\"operation_log\": operation_log}\n\tfn_output = f\"Have done the operation {op_name} with the agreement of the user {user_id}.\"\n\tif operation_log.operation_output is not None:\n\t\tfn_output += f\"\\nOperation output:\\n{operation_log.operation_output}\"\n\treturn FuncOutputWithLog(\n\t\tfn_output=fn_output,\n\t\tfn_log=log_dict,\n\t)\n</code></pre>"},{"location":"code_docs/tools/interact/collect_and_authorize/#labridge.tools.interact.collect_and_authorize.CollectAndAuthorizeTool.collect_and_authorize","title":"<code>labridge.tools.interact.collect_and_authorize.CollectAndAuthorizeTool.collect_and_authorize(user_id, query_str)</code>","text":"<p>This Method is a template method can be reused in subclass to reduce code redundancy.</p> <p>Firstly, this method will collect the required infos from the user. Then, the agent will generate the operation description according to the collected information. Finally, the agent will ask for the user's authorization to execute the operation.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user_id of a lab member.</p> <p> TYPE: <code>str</code> </p> <code>query_str</code> <p>The query from the user.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>output_log</code> <p>including the output of the callback operation and the tool's log.</p> <p> TYPE: <code>FuncOutputWithLog</code> </p> Source code in <code>labridge\\tools\\interact\\collect_and_authorize.py</code> <pre><code>def collect_and_authorize(\n\tself,\n\tuser_id: str,\n\tquery_str: str,\n) -&gt; FuncOutputWithLog:\n\tr\"\"\"\n\tThis Method is a template method can be reused in subclass to reduce code redundancy.\n\n\tFirstly, this method will collect the required infos from the user.\n\tThen, the agent will generate the operation description according to the collected information.\n\tFinally, the agent will ask for the user's authorization to execute the operation.\n\n\tArgs:\n\t\tuser_id (str): The user_id of a lab member.\n\t\tquery_str (str): The query from the user.\n\n\tReturns:\n\t\toutput_log (FuncOutputWithLog):\n\t\t\tincluding the output of the callback operation and the tool's log.\n\t\"\"\"\n\tinfo_dict = collect_info_from_user(\n\t\tuser_id=user_id,\n\t\trequired_infos=self.required_infos(),\n\t\tquery_str=query_str,\n\t)\n\n\tif info_dict is None:\n\t\top_name = self._callback_operation.__name__\n\t\toperation_log_str = (\n\t\t\tf\"The user {user_id} aborts this operation {op_name}.\"\n\t\t)\n\t\toperation_log = OperationOutputLog(\n\t\t\toperation_name=op_name,\n\t\t\toperation_output=None,\n\t\t\tlog_to_user=None,\n\t\t\tlog_to_system={\n\t\t\t\tOP_DESCRIPTION: operation_log_str,\n\t\t\t\tOP_REFERENCES: None,\n\t\t\t},\n\t\t\toperation_abort=True,\n\t\t)\n\t\tlog_dict = {\"operation_log\": operation_log}\n\n\t\treturn FuncOutputWithLog(\n\t\t\tfn_output=f\"The user {user_id} abort the collecting process in the operation {op_name}\",\n\t\t\tfn_log=log_dict,\n\t\t)\n\n\top_name = self._callback_operation.__name__\n\tkwargs = {\"user_id\": user_id, }\n\tfor key in self.required_info_dict().keys():\n\t\tkwargs[key] = info_dict[key]\n\tkwargs_str = json.dumps(kwargs)\n\toperation_log = operation_authorize(\n\t\tuser_id=user_id,\n\t\top_name=op_name,\n\t\tkwargs_str=kwargs_str,\n\t\tllm=self._llm,\n\t\tembed_model=self._embed_model,\n\t\tverbose=self._verbose,\n\t)\n\tlog = {\"operation_log\": operation_log}\n\tfn_output = f\"Have done the operation {op_name} with the agreement of the user {user_id}.\"\n\tif operation_log.operation_output is not None:\n\t\tfn_output += f\"\\nOperation output:\\n{operation_log.operation_output}\"\n\treturn FuncOutputWithLog(\n\t\tfn_output=fn_output,\n\t\tfn_log=log,\n\t)\n</code></pre>"},{"location":"code_docs/tools/interact/collect_and_authorize/#labridge.tools.interact.collect_and_authorize.CollectAndAuthorizeTool.log","title":"<code>labridge.tools.interact.collect_and_authorize.CollectAndAuthorizeTool.log(**kwargs)</code>","text":"<p>Record the tool's logs.</p> PARAMETER DESCRIPTION <code>**kwargs</code> <p>The input keyword arguments and the (output, log) of the callback operation.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>tool_log</code> <p>The tool logs, including tool_to_user and tool_to_system.</p> <p> TYPE: <code>ToolLog</code> </p> Source code in <code>labridge\\tools\\interact\\collect_and_authorize.py</code> <pre><code>def log(self, **kwargs: Any) -&gt; ToolLog:\n\tr\"\"\"\n\tRecord the tool's logs.\n\n\tArgs:\n\t\t**kwargs: The input keyword arguments and the (output, log) of the callback operation.\n\n\tReturns:\n\t\ttool_log (ToolLog): The tool logs, including tool_to_user and tool_to_system.\n\t\"\"\"\n\tuser_id = kwargs[\"user_id\"]\n\tcollected_info = \",\".join(list(self.required_info_dict().keys()))\n\tlog_to_system_str = (\n\t\tf\"Have collected these information from the user {user_id}:\\n\"\n\t\tf\"{collected_info}\\n\"\n\t\tf\"Then try to do the following operation.\\n\"\n\t)\n\n\top_log: OperationOutputLog = kwargs[\"operation_log\"]\n\tif not isinstance(op_log, OperationOutputLog):\n\t\traise ValueError(\"The operation_log must be 'OperationOutputLog'.\")\n\n\tlog_to_system_str += op_log.log_to_system[OP_DESCRIPTION]\n\n\tlog_to_user = op_log.log_to_user\n\tlog_to_system = {\n\t\tTOOL_OP_DESCRIPTION: log_to_system_str,\n\t\tTOOL_REFERENCES: op_log.log_to_system[OP_REFERENCES],\n\t}\n\n\ttool_log = ToolLog(\n\t\ttool_name=self.metadata.name,\n\t\tlog_to_user=log_to_user,\n\t\tlog_to_system=log_to_system,\n\t\ttool_abort=op_log.operation_abort,\n\t)\n\treturn tool_log\n</code></pre>"},{"location":"code_docs/tools/interact/collect_and_authorize/#labridge.tools.interact.collect_and_authorize.CollectAndAuthorizeTool.required_info_dict","title":"<code>labridge.tools.interact.collect_and_authorize.CollectAndAuthorizeTool.required_info_dict()</code>  <code>abstractmethod</code>","text":"<p>The required info names and their descriptions</p> Source code in <code>labridge\\tools\\interact\\collect_and_authorize.py</code> <pre><code>@abstractmethod\ndef required_info_dict(self) -&gt; Dict[str, str]:\n\tr\"\"\" The required info names and their descriptions \"\"\"\n</code></pre>"},{"location":"code_docs/tools/interact/collect_and_authorize/#labridge.tools.interact.collect_and_authorize.CollectAndAuthorizeTool.required_infos","title":"<code>labridge.tools.interact.collect_and_authorize.CollectAndAuthorizeTool.required_infos()</code>  <code>abstractmethod</code>","text":"<p>The required infos.</p> Source code in <code>labridge\\tools\\interact\\collect_and_authorize.py</code> <pre><code>@abstractmethod\ndef required_infos(self) -&gt; List[CollectingInfoBase]:\n\tr\"\"\" The required infos. \"\"\"\n</code></pre>"},{"location":"code_docs/tools/memory/chat/retrieve/","title":"Retrieve","text":""},{"location":"code_docs/tools/memory/chat/retrieve/#labridge.tools.memory.chat.retrieve","title":"<code>labridge.tools.memory.chat.retrieve</code>","text":""},{"location":"code_docs/tools/memory/chat/retrieve/#labridge.tools.memory.chat.retrieve.ChatMemoryRetrieverTool","title":"<code>labridge.tools.memory.chat.retrieve.ChatMemoryRetrieverTool</code>","text":"<p>               Bases: <code>RetrieverBaseTool</code></p> <p>This tool is used to retrieve in the permanent chat memory of a user or a chat group.</p> PARAMETER DESCRIPTION <code>chat_memory_retriever</code> <p>The chat memory retriever.</p> <p> TYPE: <code>ChatMemoryRetriever</code> DEFAULT: <code>None</code> </p> <code>metadata_mode</code> <p>The metadata mode, defaults to <code>MetadataMode.LLM</code>.</p> <p> TYPE: <code>MetadataMode</code> DEFAULT: <code>LLM</code> </p> Source code in <code>labridge\\tools\\memory\\chat\\retrieve.py</code> <pre><code>class ChatMemoryRetrieverTool(RetrieverBaseTool):\n\tr\"\"\"\n\tThis tool is used to retrieve in the permanent chat memory of a user or a chat group.\n\n\tArgs:\n\t\tchat_memory_retriever (ChatMemoryRetriever): The chat memory retriever.\n\t\tmetadata_mode (MetadataMode): The metadata mode, defaults to `MetadataMode.LLM`.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tchat_memory_retriever: ChatMemoryRetriever = None,\n\t\tmetadata_mode: MetadataMode = MetadataMode.LLM,\n\t):\n\t\tself.metadata_mode = metadata_mode\n\n\t\tchat_memory_retriever = chat_memory_retriever or ChatMemoryRetriever()\n\t\tsuper().__init__(\n\t\t\tretriever=chat_memory_retriever,\n\t\t\tname=ChatMemoryRetrieverTool.__name__,\n\t\t\tretrieve_fn=ChatMemoryRetriever.retrieve,\n\t\t)\n\n\tdef get_ref_info(self, nodes: List[NodeWithScore]) -&gt; List[RefInfoBase]:\n\t\tr\"\"\" Get the reference infos from the retrieved nodes. \"\"\"\n\t\treturn []\n\n\tdef log(self, log_dict) -&gt; ToolLog:\n\t\tr\"\"\" tool log \"\"\"\n\t\titem = log_dict[\"item_to_be_retrieved\"]\n\t\tmemory_id = log_dict[\"memory_id\"]\n\t\tstart_date = log_dict[\"start_date\"]\n\t\tend_date = log_dict[\"end_date\"]\n\t\tlog_string = (\n\t\t\tf\"Using {self.metadata.name} to retrieve '{item}' in the chat history memory with memory_id: '{memory_id}'\\n\"\n\t\t\tf\"Retrieve date is ranging from {start_date} to {end_date}\\n\"\n\t\t)\n\n\t\tlog_to_user = None\n\t\tlog_to_system = {\n\t\t\tTOOL_OP_DESCRIPTION: log_string,\n\t\t\tTOOL_REFERENCES: None,\n\t\t}\n\t\treturn ToolLog(\n\t\t\ttool_name=self.metadata.name,\n\t\t\tlog_to_user=log_to_user,\n\t\t\tlog_to_system=log_to_system,\n\t\t)\n\n\tdef _retrieve(self, retrieve_kwargs: dict) -&gt; List[NodeWithScore]:\n\t\tr\"\"\" Use the retriever to retrieve relevant nodes. \"\"\"\n\t\tnodes = self._retriever.retrieve(**retrieve_kwargs)\n\t\treturn nodes\n\n\tasync def _aretrieve(self, retrieve_kwargs: dict) -&gt; List[NodeWithScore]:\n\t\tr\"\"\" Asynchronously use the retriever to retrieve relevant nodes. \"\"\"\n\t\tnodes = await self._retriever.aretrieve(**retrieve_kwargs)\n\t\treturn nodes\n\n\tdef _nodes_to_tool_output(self, nodes: List[NodeWithScore]) -&gt; Tuple[str, dict]:\n\t\tr\"\"\" output the retrieved contents in a specific format. \"\"\"\n\t\tif nodes:\n\t\t\toutput = f\"Have retrieved relevant conversations in the chat memory\\n\\n\"\n\t\t\tcontents = []\n\t\t\tfor idx, node in enumerate(nodes):\n\t\t\t\tnode_content = (\n\t\t\t\t\tf\"Conversation {idx + 1}:\\n\"\n\t\t\t\t\tf\"{node.node.get_content(metadata_mode=self.metadata_mode)}\"\n\t\t\t\t)\n\t\t\t\tcontents.append(node_content.strip())\n\t\t\toutput += \"\\n\\n\".join(contents)\n\t\telse:\n\t\t\toutput = \"No Relevant chat history found.\"\n\n\t\toutput_log = dict()\n\t\treturn output, output_log\n</code></pre>"},{"location":"code_docs/tools/memory/chat/retrieve/#labridge.tools.memory.chat.retrieve.ChatMemoryRetrieverTool.get_ref_info","title":"<code>labridge.tools.memory.chat.retrieve.ChatMemoryRetrieverTool.get_ref_info(nodes)</code>","text":"<p>Get the reference infos from the retrieved nodes.</p> Source code in <code>labridge\\tools\\memory\\chat\\retrieve.py</code> <pre><code>def get_ref_info(self, nodes: List[NodeWithScore]) -&gt; List[RefInfoBase]:\n\tr\"\"\" Get the reference infos from the retrieved nodes. \"\"\"\n\treturn []\n</code></pre>"},{"location":"code_docs/tools/memory/chat/retrieve/#labridge.tools.memory.chat.retrieve.ChatMemoryRetrieverTool.log","title":"<code>labridge.tools.memory.chat.retrieve.ChatMemoryRetrieverTool.log(log_dict)</code>","text":"<p>tool log</p> Source code in <code>labridge\\tools\\memory\\chat\\retrieve.py</code> <pre><code>def log(self, log_dict) -&gt; ToolLog:\n\tr\"\"\" tool log \"\"\"\n\titem = log_dict[\"item_to_be_retrieved\"]\n\tmemory_id = log_dict[\"memory_id\"]\n\tstart_date = log_dict[\"start_date\"]\n\tend_date = log_dict[\"end_date\"]\n\tlog_string = (\n\t\tf\"Using {self.metadata.name} to retrieve '{item}' in the chat history memory with memory_id: '{memory_id}'\\n\"\n\t\tf\"Retrieve date is ranging from {start_date} to {end_date}\\n\"\n\t)\n\n\tlog_to_user = None\n\tlog_to_system = {\n\t\tTOOL_OP_DESCRIPTION: log_string,\n\t\tTOOL_REFERENCES: None,\n\t}\n\treturn ToolLog(\n\t\ttool_name=self.metadata.name,\n\t\tlog_to_user=log_to_user,\n\t\tlog_to_system=log_to_system,\n\t)\n</code></pre>"},{"location":"code_docs/tools/memory/experiment/insert/","title":"Insert","text":""},{"location":"code_docs/tools/memory/experiment/insert/#labridge.tools.memory.experiment.insert","title":"<code>labridge.tools.memory.experiment.insert</code>","text":""},{"location":"code_docs/tools/memory/experiment/insert/#labridge.tools.memory.experiment.insert.CreateNewExperimentLogTool","title":"<code>labridge.tools.memory.experiment.insert.CreateNewExperimentLogTool</code>","text":"<p>               Bases: <code>CollectAndAuthorizeTool</code></p> <p>This tool is used to create a new experiment record in the user's experiment log storage. It is a <code>CollectAndAuthorizeTool</code> that needs information collection and authorization.</p> PARAMETER DESCRIPTION <code>llm</code> <p>The used LLM.</p> <p> TYPE: <code>LLM</code> DEFAULT: <code>None</code> </p> <code>embed_model</code> <p>The used embedding model.</p> <p> TYPE: <code>BaseEmbedding</code> DEFAULT: <code>None</code> </p> <code>verbose</code> <p>Whether to show the inner progress.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> Source code in <code>labridge\\tools\\memory\\experiment\\insert.py</code> <pre><code>class CreateNewExperimentLogTool(CollectAndAuthorizeTool):\n\tr\"\"\"\n\tThis tool is used to create a new experiment record in the user's experiment log storage.\n\tIt is a `CollectAndAuthorizeTool` that needs information collection and authorization.\n\n\tArgs:\n\t\tllm (LLM): The used LLM.\n\t\tembed_model (BaseEmbedding): The used embedding model.\n\t\tverbose (bool): Whether to show the inner progress.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tllm: LLM = None,\n\t\tembed_model: BaseEmbedding = None,\n\t\tverbose: bool = False\n\t):\n\t\tsuper().__init__(\n\t\t\ttool_fn=self.create_new_experiment_log,\n\t\t\ttool_async_fn=self.acreate_new_experiment_log,\n\t\t\ttool_name=CreateNewExperimentLogTool.__name__,\n\t\t\tcallback_operation=CreateNewExperimentLogOperation,\n\t\t\tllm=llm,\n\t\t\tembed_model=embed_model,\n\t\t\tverbose=verbose,\n\t\t)\n\n\tdef required_info_dict(self) -&gt; Dict[str, str]:\n\t\tr\"\"\"\n\t\tThe required information.\n\n\t\tReturns:\n\t\t\tDict[str, str]:\n\n\t\t\t\t- key: the information name.\n\t\t\t\t- value: the information description.\n\t\t\"\"\"\n\t\treturn NEW_EXPERIMENT_REQUIRED_INFOS\n\n\tdef required_infos(self) -&gt; List[CollectingInfoBase]:\n\t\tr\"\"\"\n\t\tThe required infos.\n\n\t\tReturns:\n\t\t\tList[CollectingInfoBase]:\n\t\t\t\tReturn the packed info in CollectingInfoBase, such as `CollectingCommonInfo`.\n\t\t\"\"\"\n\t\tinfos = []\n\t\tinfo_dict = self.required_info_dict()\n\t\tfor key in info_dict.keys():\n\t\t\tcommon_info = CollectingCommonInfo(\n\t\t\t\tinfo_name=key,\n\t\t\t\tinfo_description=info_dict[key],\n\t\t\t)\n\t\t\tinfos.append(common_info)\n\t\treturn infos\n\n\tdef create_new_experiment_log(\n\t\tself,\n\t\tuser_id: str,\n\t) -&gt; FuncOutputWithLog:\n\t\tr\"\"\"\n\t\tThis tool is used to create a new experiment log record for the user.\n\t\tThis tool is only used when the user asks for creating a new experiment log record, or other tools call this tool.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user_id of a lab member.\n\n\t\tReturns:\n\t\t\tThe tool's output and log.\n\t\t\"\"\"\n\t\t# This docstring is used as the tool description.\n\t\treturn self.collect_and_authorize(\n\t\t\tuser_id=user_id,\n\t\t\tquery_str=COLLECT_NEW_EXPERIMENT_INFO_QUERY,\n\t\t)\n\n\tasync def acreate_new_experiment_log(\n\t\tself,\n\t\tuser_id: str,\n\t) -&gt; FuncOutputWithLog:\n\t\tr\"\"\"\n\t\tThis tool is used to create a new experiment log record for the user.\n\t\tThis tool is only used when the user asks for creating a new experiment log record,\n\t\tor when other tools call this tool.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user_id of a lab member.\n\n\t\tReturns:\n\t\t\tThe tool's output and log.\n\t\t\"\"\"\n\t\toutput = await self.acollect_and_authorize(\n\t\t\tuser_id=user_id,\n\t\t\tquery_str=COLLECT_NEW_EXPERIMENT_INFO_QUERY,\n\t\t)\n\t\tprint(\"Here: \", output.fn_output)\n\t\tprint(\"Here: \", output.fn_log)\n\t\treturn output\n</code></pre>"},{"location":"code_docs/tools/memory/experiment/insert/#labridge.tools.memory.experiment.insert.CreateNewExperimentLogTool.acreate_new_experiment_log","title":"<code>labridge.tools.memory.experiment.insert.CreateNewExperimentLogTool.acreate_new_experiment_log(user_id)</code>  <code>async</code>","text":"<p>This tool is used to create a new experiment log record for the user. This tool is only used when the user asks for creating a new experiment log record, or when other tools call this tool.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user_id of a lab member.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>FuncOutputWithLog</code> <p>The tool's output and log.</p> Source code in <code>labridge\\tools\\memory\\experiment\\insert.py</code> <pre><code>async def acreate_new_experiment_log(\n\tself,\n\tuser_id: str,\n) -&gt; FuncOutputWithLog:\n\tr\"\"\"\n\tThis tool is used to create a new experiment log record for the user.\n\tThis tool is only used when the user asks for creating a new experiment log record,\n\tor when other tools call this tool.\n\n\tArgs:\n\t\tuser_id (str): The user_id of a lab member.\n\n\tReturns:\n\t\tThe tool's output and log.\n\t\"\"\"\n\toutput = await self.acollect_and_authorize(\n\t\tuser_id=user_id,\n\t\tquery_str=COLLECT_NEW_EXPERIMENT_INFO_QUERY,\n\t)\n\tprint(\"Here: \", output.fn_output)\n\tprint(\"Here: \", output.fn_log)\n\treturn output\n</code></pre>"},{"location":"code_docs/tools/memory/experiment/insert/#labridge.tools.memory.experiment.insert.CreateNewExperimentLogTool.create_new_experiment_log","title":"<code>labridge.tools.memory.experiment.insert.CreateNewExperimentLogTool.create_new_experiment_log(user_id)</code>","text":"<p>This tool is used to create a new experiment log record for the user. This tool is only used when the user asks for creating a new experiment log record, or other tools call this tool.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user_id of a lab member.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>FuncOutputWithLog</code> <p>The tool's output and log.</p> Source code in <code>labridge\\tools\\memory\\experiment\\insert.py</code> <pre><code>def create_new_experiment_log(\n\tself,\n\tuser_id: str,\n) -&gt; FuncOutputWithLog:\n\tr\"\"\"\n\tThis tool is used to create a new experiment log record for the user.\n\tThis tool is only used when the user asks for creating a new experiment log record, or other tools call this tool.\n\n\tArgs:\n\t\tuser_id (str): The user_id of a lab member.\n\n\tReturns:\n\t\tThe tool's output and log.\n\t\"\"\"\n\t# This docstring is used as the tool description.\n\treturn self.collect_and_authorize(\n\t\tuser_id=user_id,\n\t\tquery_str=COLLECT_NEW_EXPERIMENT_INFO_QUERY,\n\t)\n</code></pre>"},{"location":"code_docs/tools/memory/experiment/insert/#labridge.tools.memory.experiment.insert.CreateNewExperimentLogTool.required_info_dict","title":"<code>labridge.tools.memory.experiment.insert.CreateNewExperimentLogTool.required_info_dict()</code>","text":"<p>The required information.</p> RETURNS DESCRIPTION <code>Dict[str, str]</code> <p>Dict[str, str]:</p> <ul> <li>key: the information name.</li> <li>value: the information description.</li> </ul> Source code in <code>labridge\\tools\\memory\\experiment\\insert.py</code> <pre><code>def required_info_dict(self) -&gt; Dict[str, str]:\n\tr\"\"\"\n\tThe required information.\n\n\tReturns:\n\t\tDict[str, str]:\n\n\t\t\t- key: the information name.\n\t\t\t- value: the information description.\n\t\"\"\"\n\treturn NEW_EXPERIMENT_REQUIRED_INFOS\n</code></pre>"},{"location":"code_docs/tools/memory/experiment/insert/#labridge.tools.memory.experiment.insert.CreateNewExperimentLogTool.required_infos","title":"<code>labridge.tools.memory.experiment.insert.CreateNewExperimentLogTool.required_infos()</code>","text":"<p>The required infos.</p> RETURNS DESCRIPTION <code>List[CollectingInfoBase]</code> <p>List[CollectingInfoBase]: Return the packed info in CollectingInfoBase, such as <code>CollectingCommonInfo</code>.</p> Source code in <code>labridge\\tools\\memory\\experiment\\insert.py</code> <pre><code>def required_infos(self) -&gt; List[CollectingInfoBase]:\n\tr\"\"\"\n\tThe required infos.\n\n\tReturns:\n\t\tList[CollectingInfoBase]:\n\t\t\tReturn the packed info in CollectingInfoBase, such as `CollectingCommonInfo`.\n\t\"\"\"\n\tinfos = []\n\tinfo_dict = self.required_info_dict()\n\tfor key in info_dict.keys():\n\t\tcommon_info = CollectingCommonInfo(\n\t\t\tinfo_name=key,\n\t\t\tinfo_description=info_dict[key],\n\t\t)\n\t\tinfos.append(common_info)\n\treturn infos\n</code></pre>"},{"location":"code_docs/tools/memory/experiment/insert/#labridge.tools.memory.experiment.insert.RecordExperimentLogTool","title":"<code>labridge.tools.memory.experiment.insert.RecordExperimentLogTool</code>","text":"<p>               Bases: <code>FunctionBaseTool</code></p> <p>This tool is used to record the experiment log for users. Use this tool When the user asks you to record anything about his/her experiment.</p> <ul> <li>If the recorded experiment in progress is valid (That is, current time is not beyond this experiment's duration), the experiment log will be directly record to the record of the experiment in progress.</li> <li>If the recorded experiment in progress is not valid, this tool will implicitly call the <code>SetCurrentExperimentTool</code> to set current experiment (Output the tool call requirement in the tool output.).</li> </ul> PARAMETER DESCRIPTION <code>llm</code> <p>The used LLM. If not specified, the <code>Settings.llm</code> will be used.</p> <p> TYPE: <code>LLM</code> DEFAULT: <code>None</code> </p> <code>embed_model</code> <p>The used embedding model. If not specified, the <code>Settings.embed_model</code> will be used.</p> <p> TYPE: <code>BaseEmbedding</code> DEFAULT: <code>None</code> </p> <code>verbose</code> <p>Whether to show the inner progress.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> Source code in <code>labridge\\tools\\memory\\experiment\\insert.py</code> <pre><code>class RecordExperimentLogTool(FunctionBaseTool):\n\tr\"\"\"\n\tThis tool is used to record the experiment log for users.\n\tUse this tool When the user asks you to record anything about his/her experiment.\n\n\t- If the recorded experiment in progress is valid (That is, current time is not beyond this experiment's duration),\n\tthe experiment log will be directly record to the record of the experiment in progress.\n\t- If the recorded experiment in progress is not valid, this tool will implicitly call the `SetCurrentExperimentTool`\n\tto set current experiment (Output the tool call requirement in the tool output.).\n\n\tArgs:\n\t\tllm (LLM): The used LLM. If not specified, the `Settings.llm` will be used.\n\t\tembed_model (BaseEmbedding): The used embedding model. If not specified, the `Settings.embed_model` will be used.\n\t\tverbose (bool): Whether to show the inner progress.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tllm: LLM = None,\n\t\tembed_model: BaseEmbedding = None,\n\t\tverbose: bool = False,\n\t):\n\t\tself._llm = llm or Settings.llm\n\t\tself._embed_model = embed_model or Settings.embed_model\n\t\tself._verbose = verbose\n\t\tsuper().__init__(\n\t\t\tfn=self.record_log,\n\t\t\tasync_fn=self.arecord_log,\n\t\t\ttool_name=RecordExperimentLogTool.__name__,\n\t\t)\n\n\tdef log(self, **kwargs: Any) -&gt; ToolLog:\n\t\tr\"\"\"\n\t\tRecord the tool log.\n\n\t\tArgs:\n\t\t\t**kwargs (Any): The input keyword arguments and the (output, log) of the executed operation.\n\n\t\tReturns:\n\n\t\t\"\"\"\n\t\top_log: OperationOutputLog = kwargs[\"operation_log\"]\n\n\t\treturn ToolLog.construct(\n\t\t\ttool_name=self.metadata.name,\n\t\t\ttool_op_description=op_log.log_to_system[OP_DESCRIPTION],\n\t\t)\n\n\tdef record_log(\n\t\tself,\n\t\tuser_id: str,\n\t\tlog_str: str,\n\t\tattached_file_path: str = None,\n\t\t**kwargs,\n\t) -&gt; FuncOutputWithLog:\n\t\tr\"\"\"\n\t\tThis tool is used to record the experiment log of the experiment in progress for a user.\n\n\t\tIf the no experiment record exists or experiment in progress is not valid, this tool will call\n\t\tthe corresponding tools to help the user.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user_id of a lab member.\n\t\t\tlog_str (str): The experiment log to be recorded.\n\t\t\tattached_file_path (str): The path of the attached file, If the user attaches a file along with the experiment log.\n\t\t\t\tDefaults to None.\n\n\t\tReturns:\n\t\t\tThe tool output and log.\n\t\t\"\"\"\n\t\t# This docstring is used as the tool description.\n\t\texpr_log_store = ExperimentLog.from_user_id(\n\t\t\tuser_id=user_id,\n\t\t\tembed_model=self._embed_model,\n\t\t)\n\n\t\t# If no experiment log record exists.\n\t\tif expr_log_store.get_all_experiments() is None:\n\t\t\tcreate_tool = CreateNewExperimentLogTool(\n\t\t\t\tllm=self._llm,\n\t\t\t\tembed_model=self._embed_model,\n\t\t\t)\n\t\t\tcreate_output = create_tool.call(user_id=user_id)\n\t\t\tabort = whether_abort_tool(tool_output=create_output)\n\t\t\tif abort is None or abort:\n\t\t\t\tstatus = (\n\t\t\t\t\tf\"The user does not want to continue, and abort the create experiment operation.\"\n\t\t\t\t\tf\"This conversation should be ended.\"\n\t\t\t\t)\n\t\t\t\tif abort is None:\n\t\t\t\t\tstatus = f\"The tool output of the CreateNewExperimentLogTool is invalid.\"\n\n\t\t\t\top_log = OperationOutputLog.construct(\n\t\t\t\t\toperation_name=create_tool.metadata.name,\n\t\t\t\t\top_description=status,\n\t\t\t\t\toperation_output=status,\n\t\t\t\t)\n\t\t\t\treturn FuncOutputWithLog(\n\t\t\t\t\tfn_output=status,\n\t\t\t\t\tfn_log={\"operation_log\": op_log}\n\t\t\t\t)\n\n\t\t# If current experiment in progress is not valid.\n\t\trecent_expr = expr_log_store.get_recent_experiment()\n\t\tif recent_expr is None:\n\t\t\tset_tool = SetCurrentExperimentTool(\n\t\t\t\tllm=self._llm,\n\t\t\t\tembed_model=self._embed_model,\n\t\t\t)\n\n\t\t\tset_output = set_tool.call(user_id=user_id)\n\t\t\tabort = whether_abort_tool(tool_output=set_output)\n\t\t\tif abort is None or abort:\n\t\t\t\tstatus = (\n\t\t\t\t\tf\"The user does not want to continue, and abort the set experiment operation.\"\n\t\t\t\t\tf\"This conversation should be ended.\"\n\t\t\t\t)\n\t\t\t\tif abort is None:\n\t\t\t\t\tstatus = f\"The tool output of the SetCurrentExperimentTool is invalid.\"\n\n\t\t\t\top_log = OperationOutputLog.construct(\n\t\t\t\t\toperation_name=set_tool.metadata.name,\n\t\t\t\t\top_description=status,\n\t\t\t\t\toperation_output=status,\n\t\t\t\t)\n\t\t\t\treturn FuncOutputWithLog(\n\t\t\t\t\tfn_output=status,\n\t\t\t\t\tfn_log={\"operation_log\": op_log},\n\t\t\t\t)\n\n\t\t\t# reload\n\t\t\texpr_log_store = ExperimentLog.from_user_id(\n\t\t\t\tuser_id=user_id,\n\t\t\t\tembed_model=self._embed_model,\n\t\t\t)\n\t\t\trecent_expr = expr_log_store.get_recent_experiment()\n\n\t\texpr_log_store.put(\n\t\t\texperiment_name=recent_expr,\n\t\t\tlog_str=log_str,\n\t\t\tattached_file_path=attached_file_path,\n\t\t)\n\t\texpr_log_store.persist()\n\n\t\top_log_str = (\n\t\t\tf\"Have put a new experiment log into the experiment log store of the user: {user_id}.\\n\" \n\t\t\tf\"Experiment name: {recent_expr}\\n\"\n\t\t)\n\t\top_log = OperationOutputLog.construct(\n\t\t\toperation_name=self.metadata.name,\n\t\t\top_description=op_log_str,\n\t\t\toperation_output=op_log_str,\n\t\t)\n\t\treturn FuncOutputWithLog(\n\t\t\tfn_output=f\"Have record the log {log_str}\",\n\t\t\tfn_log={\"operation_log\": op_log}\n\t\t)\n\n\tasync def arecord_log(\n\t\tself,\n\t\tuser_id: str,\n\t\tlog_str: str,\n\t\tattached_file_path: str = None,\n\t\t**kwargs,\n\t) -&gt; FuncOutputWithLog:\n\t\tr\"\"\"\n\t\tThis tool is used to record the experiment log of the experiment in progress for a user.\n\n\t\tIf the no experiment record exists or experiment in progress is not valid, this tool will call\n\t\tthe corresponding tools to help the user.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user_id of a lab member.\n\t\t\tlog_str (str): The experiment log to be recorded.\n\t\t\tattached_file_path (str): The path of the attached file, If the user attaches a file along with the experiment log.\n\t\t\t\tDefaults to None.\n\n\t\tReturns:\n\t\t\tThe tool output and log.\n\t\t\"\"\"\n\t\t# This docstring is used as the tool description.\n\t\texpr_log_store = ExperimentLog.from_user_id(\n\t\t\tuser_id=user_id,\n\t\t\tembed_model=self._embed_model,\n\t\t)\n\n\t\t# If no experiment log record exists.\n\t\tif expr_log_store.get_all_experiments() is None:\n\t\t\tcreate_tool = CreateNewExperimentLogTool(\n\t\t\t\tllm=self._llm,\n\t\t\t\tembed_model=self._embed_model,\n\t\t\t)\n\t\t\tcreate_output = await create_tool.acall(user_id=user_id)\n\n\t\t\tabort = whether_abort_tool(tool_output=create_output)\n\t\t\tif abort is None or abort:\n\t\t\t\tstatus = f\"The user does not want to continue, and abort the create experiment operation.\"\n\t\t\t\tif abort is None:\n\t\t\t\t\tstatus = f\"The tool output of the CreateNewExperimentLogTool is invalid.\"\n\n\t\t\t\top_log = OperationOutputLog.construct(\n\t\t\t\t\toperation_name=create_tool.metadata.name,\n\t\t\t\t\top_description=status,\n\t\t\t\t\toperation_output=status,\n\t\t\t\t)\n\t\t\t\treturn FuncOutputWithLog(\n\t\t\t\t\tfn_output=status,\n\t\t\t\t\tfn_log={\"operation_log\": op_log}\n\t\t\t\t)\n\n\t\t# If current experiment in progress is not valid.\n\t\trecent_expr = expr_log_store.get_recent_experiment()\n\t\tif recent_expr is None:\n\t\t\tset_tool = SetCurrentExperimentTool(\n\t\t\t\tllm=self._llm,\n\t\t\t\tembed_model=self._embed_model,\n\t\t\t)\n\t\t\tset_output = await set_tool.acall(user_id=user_id)\n\n\t\t\tabort = whether_abort_tool(tool_output=set_output)\n\t\t\tif abort is None or abort:\n\t\t\t\tstatus = f\"The user does not want to continue, and abort the set experiment operation.\"\n\t\t\t\tif abort is None:\n\t\t\t\t\tstatus = f\"The tool output of the SetCurrentExperimentTool is invalid.\"\n\n\t\t\t\top_log = OperationOutputLog.construct(\n\t\t\t\t\toperation_name=set_tool.metadata.name,\n\t\t\t\t\top_description=status,\n\t\t\t\t\toperation_output=status,\n\t\t\t\t)\n\t\t\t\treturn FuncOutputWithLog(\n\t\t\t\t\tfn_output=status,\n\t\t\t\t\tfn_log={\"operation_log\": op_log},\n\t\t\t\t)\n\n\t\t\t# reload\n\t\t\texpr_log_store = ExperimentLog.from_user_id(\n\t\t\t\tuser_id=user_id,\n\t\t\t\tembed_model=self._embed_model,\n\t\t\t)\n\t\t\trecent_expr = expr_log_store.get_recent_experiment()\n\n\t\texpr_log_store.put(\n\t\t\texperiment_name=recent_expr,\n\t\t\tlog_str=log_str,\n\t\t\tattached_file_path=attached_file_path,\n\t\t)\n\t\texpr_log_store.persist()\n\n\t\top_log_str = (\n\t\t\tf\"Have put a new experiment log into the experiment log store of the user: {user_id}.\\n\"\n\t\t\tf\"Experiment name: {recent_expr}\\n\"\n\t\t)\n\t\top_log = OperationOutputLog.construct(\n\t\t\toperation_name=self.metadata.name,\n\t\t\top_description=op_log_str,\n\t\t\toperation_output=op_log_str,\n\t\t)\n\t\treturn FuncOutputWithLog(\n\t\t\tfn_output=f\"Have record the log {log_str}\",\n\t\t\tfn_log={\"operation_log\": op_log}\n\t\t)\n</code></pre>"},{"location":"code_docs/tools/memory/experiment/insert/#labridge.tools.memory.experiment.insert.RecordExperimentLogTool.arecord_log","title":"<code>labridge.tools.memory.experiment.insert.RecordExperimentLogTool.arecord_log(user_id, log_str, attached_file_path=None, **kwargs)</code>  <code>async</code>","text":"<p>This tool is used to record the experiment log of the experiment in progress for a user.</p> <p>If the no experiment record exists or experiment in progress is not valid, this tool will call the corresponding tools to help the user.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user_id of a lab member.</p> <p> TYPE: <code>str</code> </p> <code>log_str</code> <p>The experiment log to be recorded.</p> <p> TYPE: <code>str</code> </p> <code>attached_file_path</code> <p>The path of the attached file, If the user attaches a file along with the experiment log. Defaults to None.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>FuncOutputWithLog</code> <p>The tool output and log.</p> Source code in <code>labridge\\tools\\memory\\experiment\\insert.py</code> <pre><code>async def arecord_log(\n\tself,\n\tuser_id: str,\n\tlog_str: str,\n\tattached_file_path: str = None,\n\t**kwargs,\n) -&gt; FuncOutputWithLog:\n\tr\"\"\"\n\tThis tool is used to record the experiment log of the experiment in progress for a user.\n\n\tIf the no experiment record exists or experiment in progress is not valid, this tool will call\n\tthe corresponding tools to help the user.\n\n\tArgs:\n\t\tuser_id (str): The user_id of a lab member.\n\t\tlog_str (str): The experiment log to be recorded.\n\t\tattached_file_path (str): The path of the attached file, If the user attaches a file along with the experiment log.\n\t\t\tDefaults to None.\n\n\tReturns:\n\t\tThe tool output and log.\n\t\"\"\"\n\t# This docstring is used as the tool description.\n\texpr_log_store = ExperimentLog.from_user_id(\n\t\tuser_id=user_id,\n\t\tembed_model=self._embed_model,\n\t)\n\n\t# If no experiment log record exists.\n\tif expr_log_store.get_all_experiments() is None:\n\t\tcreate_tool = CreateNewExperimentLogTool(\n\t\t\tllm=self._llm,\n\t\t\tembed_model=self._embed_model,\n\t\t)\n\t\tcreate_output = await create_tool.acall(user_id=user_id)\n\n\t\tabort = whether_abort_tool(tool_output=create_output)\n\t\tif abort is None or abort:\n\t\t\tstatus = f\"The user does not want to continue, and abort the create experiment operation.\"\n\t\t\tif abort is None:\n\t\t\t\tstatus = f\"The tool output of the CreateNewExperimentLogTool is invalid.\"\n\n\t\t\top_log = OperationOutputLog.construct(\n\t\t\t\toperation_name=create_tool.metadata.name,\n\t\t\t\top_description=status,\n\t\t\t\toperation_output=status,\n\t\t\t)\n\t\t\treturn FuncOutputWithLog(\n\t\t\t\tfn_output=status,\n\t\t\t\tfn_log={\"operation_log\": op_log}\n\t\t\t)\n\n\t# If current experiment in progress is not valid.\n\trecent_expr = expr_log_store.get_recent_experiment()\n\tif recent_expr is None:\n\t\tset_tool = SetCurrentExperimentTool(\n\t\t\tllm=self._llm,\n\t\t\tembed_model=self._embed_model,\n\t\t)\n\t\tset_output = await set_tool.acall(user_id=user_id)\n\n\t\tabort = whether_abort_tool(tool_output=set_output)\n\t\tif abort is None or abort:\n\t\t\tstatus = f\"The user does not want to continue, and abort the set experiment operation.\"\n\t\t\tif abort is None:\n\t\t\t\tstatus = f\"The tool output of the SetCurrentExperimentTool is invalid.\"\n\n\t\t\top_log = OperationOutputLog.construct(\n\t\t\t\toperation_name=set_tool.metadata.name,\n\t\t\t\top_description=status,\n\t\t\t\toperation_output=status,\n\t\t\t)\n\t\t\treturn FuncOutputWithLog(\n\t\t\t\tfn_output=status,\n\t\t\t\tfn_log={\"operation_log\": op_log},\n\t\t\t)\n\n\t\t# reload\n\t\texpr_log_store = ExperimentLog.from_user_id(\n\t\t\tuser_id=user_id,\n\t\t\tembed_model=self._embed_model,\n\t\t)\n\t\trecent_expr = expr_log_store.get_recent_experiment()\n\n\texpr_log_store.put(\n\t\texperiment_name=recent_expr,\n\t\tlog_str=log_str,\n\t\tattached_file_path=attached_file_path,\n\t)\n\texpr_log_store.persist()\n\n\top_log_str = (\n\t\tf\"Have put a new experiment log into the experiment log store of the user: {user_id}.\\n\"\n\t\tf\"Experiment name: {recent_expr}\\n\"\n\t)\n\top_log = OperationOutputLog.construct(\n\t\toperation_name=self.metadata.name,\n\t\top_description=op_log_str,\n\t\toperation_output=op_log_str,\n\t)\n\treturn FuncOutputWithLog(\n\t\tfn_output=f\"Have record the log {log_str}\",\n\t\tfn_log={\"operation_log\": op_log}\n\t)\n</code></pre>"},{"location":"code_docs/tools/memory/experiment/insert/#labridge.tools.memory.experiment.insert.RecordExperimentLogTool.log","title":"<code>labridge.tools.memory.experiment.insert.RecordExperimentLogTool.log(**kwargs)</code>","text":"<p>Record the tool log.</p> PARAMETER DESCRIPTION <code>**kwargs</code> <p>The input keyword arguments and the (output, log) of the executed operation.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> Source code in <code>labridge\\tools\\memory\\experiment\\insert.py</code> <pre><code>def log(self, **kwargs: Any) -&gt; ToolLog:\n\tr\"\"\"\n\tRecord the tool log.\n\n\tArgs:\n\t\t**kwargs (Any): The input keyword arguments and the (output, log) of the executed operation.\n\n\tReturns:\n\n\t\"\"\"\n\top_log: OperationOutputLog = kwargs[\"operation_log\"]\n\n\treturn ToolLog.construct(\n\t\ttool_name=self.metadata.name,\n\t\ttool_op_description=op_log.log_to_system[OP_DESCRIPTION],\n\t)\n</code></pre>"},{"location":"code_docs/tools/memory/experiment/insert/#labridge.tools.memory.experiment.insert.RecordExperimentLogTool.record_log","title":"<code>labridge.tools.memory.experiment.insert.RecordExperimentLogTool.record_log(user_id, log_str, attached_file_path=None, **kwargs)</code>","text":"<p>This tool is used to record the experiment log of the experiment in progress for a user.</p> <p>If the no experiment record exists or experiment in progress is not valid, this tool will call the corresponding tools to help the user.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user_id of a lab member.</p> <p> TYPE: <code>str</code> </p> <code>log_str</code> <p>The experiment log to be recorded.</p> <p> TYPE: <code>str</code> </p> <code>attached_file_path</code> <p>The path of the attached file, If the user attaches a file along with the experiment log. Defaults to None.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>FuncOutputWithLog</code> <p>The tool output and log.</p> Source code in <code>labridge\\tools\\memory\\experiment\\insert.py</code> <pre><code>def record_log(\n\tself,\n\tuser_id: str,\n\tlog_str: str,\n\tattached_file_path: str = None,\n\t**kwargs,\n) -&gt; FuncOutputWithLog:\n\tr\"\"\"\n\tThis tool is used to record the experiment log of the experiment in progress for a user.\n\n\tIf the no experiment record exists or experiment in progress is not valid, this tool will call\n\tthe corresponding tools to help the user.\n\n\tArgs:\n\t\tuser_id (str): The user_id of a lab member.\n\t\tlog_str (str): The experiment log to be recorded.\n\t\tattached_file_path (str): The path of the attached file, If the user attaches a file along with the experiment log.\n\t\t\tDefaults to None.\n\n\tReturns:\n\t\tThe tool output and log.\n\t\"\"\"\n\t# This docstring is used as the tool description.\n\texpr_log_store = ExperimentLog.from_user_id(\n\t\tuser_id=user_id,\n\t\tembed_model=self._embed_model,\n\t)\n\n\t# If no experiment log record exists.\n\tif expr_log_store.get_all_experiments() is None:\n\t\tcreate_tool = CreateNewExperimentLogTool(\n\t\t\tllm=self._llm,\n\t\t\tembed_model=self._embed_model,\n\t\t)\n\t\tcreate_output = create_tool.call(user_id=user_id)\n\t\tabort = whether_abort_tool(tool_output=create_output)\n\t\tif abort is None or abort:\n\t\t\tstatus = (\n\t\t\t\tf\"The user does not want to continue, and abort the create experiment operation.\"\n\t\t\t\tf\"This conversation should be ended.\"\n\t\t\t)\n\t\t\tif abort is None:\n\t\t\t\tstatus = f\"The tool output of the CreateNewExperimentLogTool is invalid.\"\n\n\t\t\top_log = OperationOutputLog.construct(\n\t\t\t\toperation_name=create_tool.metadata.name,\n\t\t\t\top_description=status,\n\t\t\t\toperation_output=status,\n\t\t\t)\n\t\t\treturn FuncOutputWithLog(\n\t\t\t\tfn_output=status,\n\t\t\t\tfn_log={\"operation_log\": op_log}\n\t\t\t)\n\n\t# If current experiment in progress is not valid.\n\trecent_expr = expr_log_store.get_recent_experiment()\n\tif recent_expr is None:\n\t\tset_tool = SetCurrentExperimentTool(\n\t\t\tllm=self._llm,\n\t\t\tembed_model=self._embed_model,\n\t\t)\n\n\t\tset_output = set_tool.call(user_id=user_id)\n\t\tabort = whether_abort_tool(tool_output=set_output)\n\t\tif abort is None or abort:\n\t\t\tstatus = (\n\t\t\t\tf\"The user does not want to continue, and abort the set experiment operation.\"\n\t\t\t\tf\"This conversation should be ended.\"\n\t\t\t)\n\t\t\tif abort is None:\n\t\t\t\tstatus = f\"The tool output of the SetCurrentExperimentTool is invalid.\"\n\n\t\t\top_log = OperationOutputLog.construct(\n\t\t\t\toperation_name=set_tool.metadata.name,\n\t\t\t\top_description=status,\n\t\t\t\toperation_output=status,\n\t\t\t)\n\t\t\treturn FuncOutputWithLog(\n\t\t\t\tfn_output=status,\n\t\t\t\tfn_log={\"operation_log\": op_log},\n\t\t\t)\n\n\t\t# reload\n\t\texpr_log_store = ExperimentLog.from_user_id(\n\t\t\tuser_id=user_id,\n\t\t\tembed_model=self._embed_model,\n\t\t)\n\t\trecent_expr = expr_log_store.get_recent_experiment()\n\n\texpr_log_store.put(\n\t\texperiment_name=recent_expr,\n\t\tlog_str=log_str,\n\t\tattached_file_path=attached_file_path,\n\t)\n\texpr_log_store.persist()\n\n\top_log_str = (\n\t\tf\"Have put a new experiment log into the experiment log store of the user: {user_id}.\\n\" \n\t\tf\"Experiment name: {recent_expr}\\n\"\n\t)\n\top_log = OperationOutputLog.construct(\n\t\toperation_name=self.metadata.name,\n\t\top_description=op_log_str,\n\t\toperation_output=op_log_str,\n\t)\n\treturn FuncOutputWithLog(\n\t\tfn_output=f\"Have record the log {log_str}\",\n\t\tfn_log={\"operation_log\": op_log}\n\t)\n</code></pre>"},{"location":"code_docs/tools/memory/experiment/insert/#labridge.tools.memory.experiment.insert.SetCurrentExperimentTool","title":"<code>labridge.tools.memory.experiment.insert.SetCurrentExperimentTool</code>","text":"<p>               Bases: <code>CollectAndAuthorizeTool</code></p> <p>This tool is used to set the experiment in progress for a user.</p> PARAMETER DESCRIPTION <code>llm</code> <p>The used LLM.</p> <p> TYPE: <code>LLM</code> DEFAULT: <code>None</code> </p> <code>embed_model</code> <p>The used embedding model.</p> <p> TYPE: <code>BaseEmbedding</code> DEFAULT: <code>None</code> </p> <code>verbose</code> <p>Whether to show the inner progress.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> Source code in <code>labridge\\tools\\memory\\experiment\\insert.py</code> <pre><code>class SetCurrentExperimentTool(CollectAndAuthorizeTool):\n\tr\"\"\"\n\tThis tool is used to set the experiment in progress for a user.\n\n\tArgs:\n\t\tllm (LLM): The used LLM.\n\t\tembed_model (BaseEmbedding): The used embedding model.\n\t\tverbose (bool): Whether to show the inner progress.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tllm: LLM = None,\n\t\tembed_model: BaseEmbedding = None,\n\t\tverbose: bool = False,\n\t):\n\t\tself.expr_log_store = None\n\t\tsuper().__init__(\n\t\t\ttool_fn=self.set_current_experiment,\n\t\t\ttool_async_fn=self.aset_current_experiment,\n\t\t\ttool_name=SetCurrentExperimentTool.__name__,\n\t\t\tcallback_operation=SetCurrentExperimentOperation,\n\t\t\tllm=llm,\n\t\t\tembed_model=embed_model,\n\t\t\tverbose=verbose,\n\t\t)\n\n\tdef required_info_dict(self) -&gt; Dict[str, str]:\n\t\tr\"\"\"\n\t\tThe required information.\n\n\t\tReturns:\n\t\t\tDict[str, str]:\n\n\t\t\t\t- key: the information name.\n\t\t\t\t- value: the information description.\n\t\t\"\"\"\n\t\treturn SET_CURRENT_EXPERIMENT_REQUIRED_INFOS\n\n\tdef required_infos(self) -&gt; List[CollectingInfoBase]:\n\t\tr\"\"\"\n\t\tThe required infos.\n\n\t\tReturns:\n\t\t\tList[CollectingInfoBase]:\n\t\t\t\tReturn the packed info in CollectingInfoBase, such as `CollectingCommonInfo` and `CollectingSelectInfo`.\n\t\t\"\"\"\n\t\texperiments = self.expr_log_store.get_all_experiments_with_description()\n\t\tselect_name_info = CollectingSelectInfo(\n\t\t\tinfo_name=CURRENT_EXPERIMENT_NAME_KEY,\n\t\t\tinfo_description=self.required_info_dict()[CURRENT_EXPERIMENT_NAME_KEY],\n\t\t\tchoices=experiments,\n\t\t)\n\n\t\tduration_info = CollectingCommonInfo(\n\t\t\tinfo_name=CURRENT_EXPERIMENT_DURATION_KEY,\n\t\t\tinfo_description=self.required_info_dict()[CURRENT_EXPERIMENT_DURATION_KEY]\n\t\t)\n\t\treturn [select_name_info, duration_info]\n\n\tdef set_experiment_log_store(self, user_id: str):\n\t\tr\"\"\"\n\t\tLoad the user's experiment log storage.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user_id of a lab member.\n\t\t\"\"\"\n\t\tif self.expr_log_store is None or self.expr_log_store.user_id != user_id:\n\t\t\tself.expr_log_store = ExperimentLog.from_user_id(\n\t\t\t\tuser_id=user_id,\n\t\t\t\tembed_model=self._embed_model,\n\t\t\t)\n\n\tdef set_current_experiment(\n\t\tself,\n\t\tuser_id: str,\n\t) -&gt; FuncOutputWithLog:\n\t\tr\"\"\"\n\t\tThis tool is used to set the experiment in progress for the user, through interacting with the user.\n\t\tThis tool is used ONLY when the user ask for setting his/her experiment in progress,\n\t\tor when other tools call this tool.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user_id of a lab member.\n\n\t\tReturns:\n\t\t\tThe tool output and log.\n\t\t\"\"\"\n\t\t# This docstring is used as tool description.\n\t\tself.set_experiment_log_store(user_id=user_id)\n\n\t\texpr_list = self.expr_log_store.get_all_experiments()\n\n\t\tif expr_list is None:\n\t\t\tcreate_tool = CreateNewExperimentLogTool(\n\t\t\t\tllm=self._llm,\n\t\t\t\tembed_model=self._embed_model,\n\t\t\t)\n\t\t\tcreate_output = create_tool.call(user_id=user_id)\n\n\t\t\tabort = whether_abort_tool(tool_output=create_output)\n\t\t\tif abort is None or abort:\n\t\t\t\tstatus = (\n\t\t\t\t\tf\"The user does not want to continue, and abort the set experiment operation.\"\n\t\t\t\t\tf\"This conversation should be ended.\"\n\t\t\t\t)\n\t\t\t\tif abort is None:\n\t\t\t\t\tstatus = f\"The tool output of the CreateNewExperimentLogTool is invalid.\"\n\t\t\t\tfn_log = OperationOutputLog.construct(\n\t\t\t\t\toperation_name=create_tool.metadata.name,\n\t\t\t\t\toperation_output=status,\n\t\t\t\t\top_description=status,\n\t\t\t\t\toperation_abort=True,\n\t\t\t\t)\n\t\t\t\treturn FuncOutputWithLog(\n\t\t\t\t\tfn_output=status,\n\t\t\t\t\tfn_log={\"operation_log\": fn_log},\n\t\t\t\t)\n\n\t\tquery_str = SET_CURRENT_EXPERIMENT_MSG\n\t\toutput_log = self.collect_and_authorize(\n\t\t\tuser_id=user_id,\n\t\t\tquery_str=query_str,\n\t\t)\n\t\treturn output_log\n\n\tasync def aset_current_experiment(\n\t\tself,\n\t\tuser_id: str,\n\t) -&gt; FuncOutputWithLog:\n\t\tr\"\"\"\n\t\tThis tool is used to set the experiment in progress for the user, through interacting with the user.\n\t\tThis tool is used ONLY when the user ask for setting his/her experiment in progress,\n\t\tor when other tools call this tool.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user_id of a lab member.\n\n\t\tReturns:\n\t\t\tThe tool output and log.\n\t\t\"\"\"\n\t\tself.set_experiment_log_store(user_id=user_id)\n\t\texpr_list = self.expr_log_store.get_all_experiments()\n\t\tif expr_list is None:\n\t\t\tcreate_tool = CreateNewExperimentLogTool(\n\t\t\t\tllm=self._llm,\n\t\t\t\tembed_model=self._embed_model,\n\t\t\t)\n\t\t\tcreate_output = await create_tool.acall(user_id=user_id)\n\t\t\tabort = whether_abort_tool(tool_output=create_output)\n\t\t\tif abort is None or abort:\n\t\t\t\tstatus = (\n\t\t\t\t\tf\"The user does not want to continue, and abort the set experiment operation.\"\n\t\t\t\t\tf\"This conversation should be ended.\"\n\t\t\t\t)\n\t\t\t\tif abort is None:\n\t\t\t\t\tstatus = f\"The tool output of the CreateNewExperimentLogTool is invalid.\"\n\t\t\t\tfn_log = OperationOutputLog.construct(\n\t\t\t\t\toperation_name=create_tool.metadata.name,\n\t\t\t\t\toperation_output=status,\n\t\t\t\t\top_description=status,\n\t\t\t\t\toperation_abort=True,\n\t\t\t\t)\n\t\t\t\treturn FuncOutputWithLog(\n\t\t\t\t\tfn_output=status,\n\t\t\t\t\tfn_log={\"operation_log\": fn_log},\n\t\t\t\t)\n\n\t\tquery_str = SET_CURRENT_EXPERIMENT_MSG\n\t\toutput_log = await self.acollect_and_authorize(\n\t\t\tuser_id=user_id,\n\t\t\tquery_str=query_str,\n\t\t)\n\t\treturn output_log\n</code></pre>"},{"location":"code_docs/tools/memory/experiment/insert/#labridge.tools.memory.experiment.insert.SetCurrentExperimentTool.aset_current_experiment","title":"<code>labridge.tools.memory.experiment.insert.SetCurrentExperimentTool.aset_current_experiment(user_id)</code>  <code>async</code>","text":"<p>This tool is used to set the experiment in progress for the user, through interacting with the user. This tool is used ONLY when the user ask for setting his/her experiment in progress, or when other tools call this tool.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user_id of a lab member.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>FuncOutputWithLog</code> <p>The tool output and log.</p> Source code in <code>labridge\\tools\\memory\\experiment\\insert.py</code> <pre><code>async def aset_current_experiment(\n\tself,\n\tuser_id: str,\n) -&gt; FuncOutputWithLog:\n\tr\"\"\"\n\tThis tool is used to set the experiment in progress for the user, through interacting with the user.\n\tThis tool is used ONLY when the user ask for setting his/her experiment in progress,\n\tor when other tools call this tool.\n\n\tArgs:\n\t\tuser_id (str): The user_id of a lab member.\n\n\tReturns:\n\t\tThe tool output and log.\n\t\"\"\"\n\tself.set_experiment_log_store(user_id=user_id)\n\texpr_list = self.expr_log_store.get_all_experiments()\n\tif expr_list is None:\n\t\tcreate_tool = CreateNewExperimentLogTool(\n\t\t\tllm=self._llm,\n\t\t\tembed_model=self._embed_model,\n\t\t)\n\t\tcreate_output = await create_tool.acall(user_id=user_id)\n\t\tabort = whether_abort_tool(tool_output=create_output)\n\t\tif abort is None or abort:\n\t\t\tstatus = (\n\t\t\t\tf\"The user does not want to continue, and abort the set experiment operation.\"\n\t\t\t\tf\"This conversation should be ended.\"\n\t\t\t)\n\t\t\tif abort is None:\n\t\t\t\tstatus = f\"The tool output of the CreateNewExperimentLogTool is invalid.\"\n\t\t\tfn_log = OperationOutputLog.construct(\n\t\t\t\toperation_name=create_tool.metadata.name,\n\t\t\t\toperation_output=status,\n\t\t\t\top_description=status,\n\t\t\t\toperation_abort=True,\n\t\t\t)\n\t\t\treturn FuncOutputWithLog(\n\t\t\t\tfn_output=status,\n\t\t\t\tfn_log={\"operation_log\": fn_log},\n\t\t\t)\n\n\tquery_str = SET_CURRENT_EXPERIMENT_MSG\n\toutput_log = await self.acollect_and_authorize(\n\t\tuser_id=user_id,\n\t\tquery_str=query_str,\n\t)\n\treturn output_log\n</code></pre>"},{"location":"code_docs/tools/memory/experiment/insert/#labridge.tools.memory.experiment.insert.SetCurrentExperimentTool.required_info_dict","title":"<code>labridge.tools.memory.experiment.insert.SetCurrentExperimentTool.required_info_dict()</code>","text":"<p>The required information.</p> RETURNS DESCRIPTION <code>Dict[str, str]</code> <p>Dict[str, str]:</p> <ul> <li>key: the information name.</li> <li>value: the information description.</li> </ul> Source code in <code>labridge\\tools\\memory\\experiment\\insert.py</code> <pre><code>def required_info_dict(self) -&gt; Dict[str, str]:\n\tr\"\"\"\n\tThe required information.\n\n\tReturns:\n\t\tDict[str, str]:\n\n\t\t\t- key: the information name.\n\t\t\t- value: the information description.\n\t\"\"\"\n\treturn SET_CURRENT_EXPERIMENT_REQUIRED_INFOS\n</code></pre>"},{"location":"code_docs/tools/memory/experiment/insert/#labridge.tools.memory.experiment.insert.SetCurrentExperimentTool.required_infos","title":"<code>labridge.tools.memory.experiment.insert.SetCurrentExperimentTool.required_infos()</code>","text":"<p>The required infos.</p> RETURNS DESCRIPTION <code>List[CollectingInfoBase]</code> <p>List[CollectingInfoBase]: Return the packed info in CollectingInfoBase, such as <code>CollectingCommonInfo</code> and <code>CollectingSelectInfo</code>.</p> Source code in <code>labridge\\tools\\memory\\experiment\\insert.py</code> <pre><code>def required_infos(self) -&gt; List[CollectingInfoBase]:\n\tr\"\"\"\n\tThe required infos.\n\n\tReturns:\n\t\tList[CollectingInfoBase]:\n\t\t\tReturn the packed info in CollectingInfoBase, such as `CollectingCommonInfo` and `CollectingSelectInfo`.\n\t\"\"\"\n\texperiments = self.expr_log_store.get_all_experiments_with_description()\n\tselect_name_info = CollectingSelectInfo(\n\t\tinfo_name=CURRENT_EXPERIMENT_NAME_KEY,\n\t\tinfo_description=self.required_info_dict()[CURRENT_EXPERIMENT_NAME_KEY],\n\t\tchoices=experiments,\n\t)\n\n\tduration_info = CollectingCommonInfo(\n\t\tinfo_name=CURRENT_EXPERIMENT_DURATION_KEY,\n\t\tinfo_description=self.required_info_dict()[CURRENT_EXPERIMENT_DURATION_KEY]\n\t)\n\treturn [select_name_info, duration_info]\n</code></pre>"},{"location":"code_docs/tools/memory/experiment/insert/#labridge.tools.memory.experiment.insert.SetCurrentExperimentTool.set_current_experiment","title":"<code>labridge.tools.memory.experiment.insert.SetCurrentExperimentTool.set_current_experiment(user_id)</code>","text":"<p>This tool is used to set the experiment in progress for the user, through interacting with the user. This tool is used ONLY when the user ask for setting his/her experiment in progress, or when other tools call this tool.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user_id of a lab member.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>FuncOutputWithLog</code> <p>The tool output and log.</p> Source code in <code>labridge\\tools\\memory\\experiment\\insert.py</code> <pre><code>def set_current_experiment(\n\tself,\n\tuser_id: str,\n) -&gt; FuncOutputWithLog:\n\tr\"\"\"\n\tThis tool is used to set the experiment in progress for the user, through interacting with the user.\n\tThis tool is used ONLY when the user ask for setting his/her experiment in progress,\n\tor when other tools call this tool.\n\n\tArgs:\n\t\tuser_id (str): The user_id of a lab member.\n\n\tReturns:\n\t\tThe tool output and log.\n\t\"\"\"\n\t# This docstring is used as tool description.\n\tself.set_experiment_log_store(user_id=user_id)\n\n\texpr_list = self.expr_log_store.get_all_experiments()\n\n\tif expr_list is None:\n\t\tcreate_tool = CreateNewExperimentLogTool(\n\t\t\tllm=self._llm,\n\t\t\tembed_model=self._embed_model,\n\t\t)\n\t\tcreate_output = create_tool.call(user_id=user_id)\n\n\t\tabort = whether_abort_tool(tool_output=create_output)\n\t\tif abort is None or abort:\n\t\t\tstatus = (\n\t\t\t\tf\"The user does not want to continue, and abort the set experiment operation.\"\n\t\t\t\tf\"This conversation should be ended.\"\n\t\t\t)\n\t\t\tif abort is None:\n\t\t\t\tstatus = f\"The tool output of the CreateNewExperimentLogTool is invalid.\"\n\t\t\tfn_log = OperationOutputLog.construct(\n\t\t\t\toperation_name=create_tool.metadata.name,\n\t\t\t\toperation_output=status,\n\t\t\t\top_description=status,\n\t\t\t\toperation_abort=True,\n\t\t\t)\n\t\t\treturn FuncOutputWithLog(\n\t\t\t\tfn_output=status,\n\t\t\t\tfn_log={\"operation_log\": fn_log},\n\t\t\t)\n\n\tquery_str = SET_CURRENT_EXPERIMENT_MSG\n\toutput_log = self.collect_and_authorize(\n\t\tuser_id=user_id,\n\t\tquery_str=query_str,\n\t)\n\treturn output_log\n</code></pre>"},{"location":"code_docs/tools/memory/experiment/insert/#labridge.tools.memory.experiment.insert.SetCurrentExperimentTool.set_experiment_log_store","title":"<code>labridge.tools.memory.experiment.insert.SetCurrentExperimentTool.set_experiment_log_store(user_id)</code>","text":"<p>Load the user's experiment log storage.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user_id of a lab member.</p> <p> TYPE: <code>str</code> </p> Source code in <code>labridge\\tools\\memory\\experiment\\insert.py</code> <pre><code>def set_experiment_log_store(self, user_id: str):\n\tr\"\"\"\n\tLoad the user's experiment log storage.\n\n\tArgs:\n\t\tuser_id (str): The user_id of a lab member.\n\t\"\"\"\n\tif self.expr_log_store is None or self.expr_log_store.user_id != user_id:\n\t\tself.expr_log_store = ExperimentLog.from_user_id(\n\t\t\tuser_id=user_id,\n\t\t\tembed_model=self._embed_model,\n\t\t)\n</code></pre>"},{"location":"code_docs/tools/memory/experiment/retrieve/","title":"Retrieve","text":""},{"location":"code_docs/tools/memory/experiment/retrieve/#labridge.tools.memory.experiment.retrieve","title":"<code>labridge.tools.memory.experiment.retrieve</code>","text":""},{"location":"code_docs/tools/memory/experiment/retrieve/#labridge.tools.memory.experiment.retrieve.ExperimentLogRetrieveTool","title":"<code>labridge.tools.memory.experiment.retrieve.ExperimentLogRetrieveTool</code>","text":"<p>               Bases: <code>RetrieverBaseTool</code></p> <p>This tool is used to retrieve the relevant experiment log in the user's experiment log storage. The tool description is set as the docstring of the method <code>retrieve</code> of the <code>retriever</code>.</p> PARAMETER DESCRIPTION <code>embed_model</code> <p>The used embedding model. If not specified, the <code>Setting.embed_model</code> will be used.</p> <p> TYPE: <code>BaseEmbedding</code> DEFAULT: <code>None</code> </p> <code>final_use_context</code> <p>Whether to add the context nodes to the final retrieving results.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>relevant_top_k</code> <p>The top-k relevant nodes will be used as the retrieved results.</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> Source code in <code>labridge\\tools\\memory\\experiment\\retrieve.py</code> <pre><code>class ExperimentLogRetrieveTool(RetrieverBaseTool):\n\tr\"\"\"\n\tThis tool is used to retrieve the relevant experiment log in the user's experiment log storage.\n\tThe tool description is set as the docstring of the method `retrieve` of the `retriever`.\n\n\tArgs:\n\t\tembed_model (BaseEmbedding): The used embedding model. If not specified, the `Setting.embed_model` will be used.\n\t\tfinal_use_context (bool): Whether to add the context nodes to the final retrieving results.\n\t\trelevant_top_k (int): The top-k relevant nodes will be used as the retrieved results.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tembed_model: BaseEmbedding = None,\n\t\tfinal_use_context: bool = True,\n\t\trelevant_top_k: int = None,\n\t):\n\t\tretriever = ExperimentLogRetriever(\n\t\t\tembed_model=embed_model,\n\t\t\tfinal_use_context=final_use_context,\n\t\t\trelevant_top_k=relevant_top_k,\n\t\t)\n\t\tsuper().__init__(\n\t\t\tname=ExperimentLogRetrieveTool.__name__,\n\t\t\tretriever=retriever,\n\t\t\tretrieve_fn=retriever.retrieve,\n\t\t)\n\n\tdef log(self, log_dict: dict) -&gt; ToolLog:\n\t\tr\"\"\"\n\t\tRecord the tool log.\n\n\t\tArgs:\n\t\t\tlog_dict (dict): Including the input keyword arguments and the (output, log) of retrieving.\n\n\t\tReturns:\n\t\t\tThe tool log.\n\t\t\"\"\"\n\t\tuser_id = log_dict[\"memory_id\"]\n\t\titem_to_be_retrieved = log_dict[\"item_to_be_retrieved\"]\n\t\tstart_date = log_dict.get(\"start_date\", None)\n\t\tend_date = log_dict.get(\"end_date\", None)\n\n\t\tref_infos: List[ExperimentLogRefInfo] = log_dict.get(TOOL_LOG_REF_INFO_KEY)\n\n\t\tlog_string = (\n\t\t\tf\"Retrieve in the experiment log memory of the user: {user_id}.\\n\"\n\t\t\tf\"retrieve string: {item_to_be_retrieved}\\n\"\n\t\t)\n\t\tif None not in [start_date, end_date]:\n\t\t\tlog_string += (\n\t\t\t\tf\"start_date: {start_date}\\n\"\n\t\t\t\tf\"end_date: {end_date}\"\n\t\t\t)\n\n\t\tlog_to_user = None\n\t\tlog_to_system = {\n\t\t\tTOOL_OP_DESCRIPTION: log_string,\n\t\t\tTOOL_REFERENCES: [ref_info.dumps() for ref_info in ref_infos],\n\t\t}\n\t\treturn ToolLog(\n\t\t\tlog_to_user=log_to_user,\n\t\t\tlog_to_system=log_to_system,\n\t\t\ttool_name=self.metadata.name,\n\t\t)\n\n\tdef get_ref_info(self, nodes: List[NodeWithScore]) -&gt; List[ExperimentLogRefInfo]:\n\t\tr\"\"\"\n\t\tGet the reference paper infos\n\n\t\tReturns:\n\t\t\tList[PaperInfo]: The reference paper infos in answering.\n\t\t\"\"\"\n\t\tref_infos = []\n\t\tfor node_score in nodes:\n\t\t\tmetadata = node_score.node.metadata\n\t\t\tlog_str = node_score.node.text\n\t\t\texperiment_name = node_score.node.parent_node.node_id\n\t\t\tattachment_path = metadata.get(EXPERIMENT_LOG_ATTACHMENT_KEY, None)\n\t\t\tdate = metadata.get(LOG_DATE_NAME)\n\t\t\th_m_s = metadata.get(LOG_TIME_NAME)\n\t\t\tlog_ref_info = ExperimentLogRefInfo(\n\t\t\t\tdate_time=f\"{date} {h_m_s}\",\n\t\t\t\tlog_str=log_str,\n\t\t\t\tattachment_path=attachment_path,\n\t\t\t\texperiment_name=experiment_name,\n\t\t\t)\n\t\t\tref_infos.append(log_ref_info)\n\t\treturn ref_infos\n\n\tdef _retrieve(self, retrieve_kwargs: dict) -&gt; List[NodeWithScore]:\n\t\tr\"\"\" Use the retriever to retrieve relevant nodes. \"\"\"\n\t\tnodes = self._retriever.retrieve(**retrieve_kwargs)\n\t\treturn nodes\n\n\tasync def _aretrieve(self, retrieve_kwargs: dict) -&gt; List[NodeWithScore]:\n\t\tr\"\"\" Asynchronously use the retriever to retrieve relevant nodes. \"\"\"\n\t\tnodes = await self._retriever.aretrieve(**retrieve_kwargs)\n\t\treturn nodes\n\n\tdef _nodes_to_tool_output(self, nodes: List[NodeWithScore]) -&gt; Tuple[str, dict]:\n\t\tr\"\"\" output the retrieved contents in a specific format, and the output log. \"\"\"\n\t\texpr_nodes_dict = {}\n\n\t\tref_infos = self.get_ref_info(nodes=nodes)\n\t\tlog_dict = {\n\t\t\tTOOL_LOG_REF_INFO_KEY: ref_infos,\n\t\t}\n\n\t\tfor node in nodes:\n\t\t\texpr_node = node.node.parent_node\n\t\t\tif expr_node is not None:\n\t\t\t\tif expr_node.node_id not in expr_nodes_dict.keys():\n\t\t\t\t\texpr_nodes_dict[expr_node.node_id] = [node]\n\t\t\t\telse:\n\t\t\t\t\texpr_nodes_dict[expr_node.node_id].append(node)\n\n\t\tif expr_nodes_dict:\n\t\t\tmsg = \"Have retrieved the following experiment logs:\"\n\t\t\tcontents = [msg]\n\t\t\tfor expr_name in expr_nodes_dict.keys():\n\t\t\t\tmsg = f\"The following logs are from the experiment: {expr_name}\"\n\t\t\t\tcontents.append(msg)\n\t\t\t\tfor idx, node in enumerate(expr_nodes_dict[expr_name]):\n\t\t\t\t\tcontent_str = (\n\t\t\t\t\t\tf\"Log {idx + 1}:\\n\"\n\t\t\t\t\t\tf\"{node.node.get_content(metadata_mode=MetadataMode.LLM)}\"\n\t\t\t\t\t)\n\t\t\t\t\tcontents.append(content_str.strip())\n\t\t\toutput_str = \"\\n\\n\".join(contents)\n\t\telse:\n\t\t\toutput_str = \"Have retrieved nothing relevant.\"\n\t\treturn output_str, log_dict\n</code></pre>"},{"location":"code_docs/tools/memory/experiment/retrieve/#labridge.tools.memory.experiment.retrieve.ExperimentLogRetrieveTool.get_ref_info","title":"<code>labridge.tools.memory.experiment.retrieve.ExperimentLogRetrieveTool.get_ref_info(nodes)</code>","text":"<p>Get the reference paper infos</p> RETURNS DESCRIPTION <code>List[ExperimentLogRefInfo]</code> <p>List[PaperInfo]: The reference paper infos in answering.</p> Source code in <code>labridge\\tools\\memory\\experiment\\retrieve.py</code> <pre><code>def get_ref_info(self, nodes: List[NodeWithScore]) -&gt; List[ExperimentLogRefInfo]:\n\tr\"\"\"\n\tGet the reference paper infos\n\n\tReturns:\n\t\tList[PaperInfo]: The reference paper infos in answering.\n\t\"\"\"\n\tref_infos = []\n\tfor node_score in nodes:\n\t\tmetadata = node_score.node.metadata\n\t\tlog_str = node_score.node.text\n\t\texperiment_name = node_score.node.parent_node.node_id\n\t\tattachment_path = metadata.get(EXPERIMENT_LOG_ATTACHMENT_KEY, None)\n\t\tdate = metadata.get(LOG_DATE_NAME)\n\t\th_m_s = metadata.get(LOG_TIME_NAME)\n\t\tlog_ref_info = ExperimentLogRefInfo(\n\t\t\tdate_time=f\"{date} {h_m_s}\",\n\t\t\tlog_str=log_str,\n\t\t\tattachment_path=attachment_path,\n\t\t\texperiment_name=experiment_name,\n\t\t)\n\t\tref_infos.append(log_ref_info)\n\treturn ref_infos\n</code></pre>"},{"location":"code_docs/tools/memory/experiment/retrieve/#labridge.tools.memory.experiment.retrieve.ExperimentLogRetrieveTool.log","title":"<code>labridge.tools.memory.experiment.retrieve.ExperimentLogRetrieveTool.log(log_dict)</code>","text":"<p>Record the tool log.</p> PARAMETER DESCRIPTION <code>log_dict</code> <p>Including the input keyword arguments and the (output, log) of retrieving.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>ToolLog</code> <p>The tool log.</p> Source code in <code>labridge\\tools\\memory\\experiment\\retrieve.py</code> <pre><code>def log(self, log_dict: dict) -&gt; ToolLog:\n\tr\"\"\"\n\tRecord the tool log.\n\n\tArgs:\n\t\tlog_dict (dict): Including the input keyword arguments and the (output, log) of retrieving.\n\n\tReturns:\n\t\tThe tool log.\n\t\"\"\"\n\tuser_id = log_dict[\"memory_id\"]\n\titem_to_be_retrieved = log_dict[\"item_to_be_retrieved\"]\n\tstart_date = log_dict.get(\"start_date\", None)\n\tend_date = log_dict.get(\"end_date\", None)\n\n\tref_infos: List[ExperimentLogRefInfo] = log_dict.get(TOOL_LOG_REF_INFO_KEY)\n\n\tlog_string = (\n\t\tf\"Retrieve in the experiment log memory of the user: {user_id}.\\n\"\n\t\tf\"retrieve string: {item_to_be_retrieved}\\n\"\n\t)\n\tif None not in [start_date, end_date]:\n\t\tlog_string += (\n\t\t\tf\"start_date: {start_date}\\n\"\n\t\t\tf\"end_date: {end_date}\"\n\t\t)\n\n\tlog_to_user = None\n\tlog_to_system = {\n\t\tTOOL_OP_DESCRIPTION: log_string,\n\t\tTOOL_REFERENCES: [ref_info.dumps() for ref_info in ref_infos],\n\t}\n\treturn ToolLog(\n\t\tlog_to_user=log_to_user,\n\t\tlog_to_system=log_to_system,\n\t\ttool_name=self.metadata.name,\n\t)\n</code></pre>"},{"location":"code_docs/tools/paper/download/arxiv_download/","title":"Arxiv download","text":""},{"location":"code_docs/tools/paper/download/arxiv_download/#labridge.tools.paper.download.arxiv_download","title":"<code>labridge.tools.paper.download.arxiv_download</code>","text":""},{"location":"code_docs/tools/paper/download/arxiv_download/#labridge.tools.paper.download.arxiv_download.ArXivSearchDownloadTool","title":"<code>labridge.tools.paper.download.arxiv_download.ArXivSearchDownloadTool</code>","text":"<p>               Bases: <code>CallBackBaseTool</code></p> <p>This tool is used to search and download papers from arXiv.org for the user.</p> PARAMETER DESCRIPTION <code>llm</code> <p>The used LLM.</p> <p> TYPE: <code>LLM</code> DEFAULT: <code>None</code> </p> <code>embed_model</code> <p>The used embedding model.</p> <p> TYPE: <code>BaseEmbedding</code> DEFAULT: <code>None</code> </p> <code>verbose</code> <p>Whether to show the inner progress.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>max_results_num</code> <p>The maximum search results that are presented to the user. The actually used value is <code>min(max_results_num, MAX_SEARCH_RESULTS_NUM)</code>.</p> <p> TYPE: <code>int</code> DEFAULT: <code>3</code> </p> Source code in <code>labridge\\tools\\paper\\download\\arxiv_download.py</code> <pre><code>class ArXivSearchDownloadTool(CallBackBaseTool):\n\tr\"\"\"\n\tThis tool is used to search and download papers from arXiv.org for the user.\n\n\tArgs:\n\t\tllm (LLM): The used LLM.\n\t\tembed_model (BaseEmbedding): The used embedding model.\n\t\tverbose (bool): Whether to show the inner progress.\n\t\tmax_results_num (int): The maximum search results that are presented to the user.\n\t\t\tThe actually used value is `min(max_results_num, MAX_SEARCH_RESULTS_NUM)`.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tllm: LLM = None,\n\t\tembed_model: BaseEmbedding = None,\n\t\tverbose: bool = False,\n\t\tmax_results_num: int = 3,\n\t):\n\t\tself._llm = llm or Settings.llm\n\t\tself._embed_model = embed_model or Settings.embed_model\n\t\tself._verbose = verbose\n\t\tself._max_results_num = min(max_results_num, MAX_SEARCH_RESULTS_NUM)\n\t\tsuper().__init__(\n\t\t\tfn=self.search_download_pipeline,\n\t\t\tasync_fn=self.asearch_download_pipeline,\n\t\t\ttool_name=ArXivSearchDownloadTool.__name__,\n\t\t\tcallback_operation=ArxivDownloadOperation,\n\t\t)\n\t\tself.account_manager = AccountManager()\n\n\tdef _user_select_results(self, user_id: str, results: List[Result]) -&gt; Tuple[List[int], str]:\n\t\tr\"\"\" Let the user select among the candidate papers \"\"\"\n\t\tselect_info = self._select_query(results=results)\n\t\t# TODO: Send the query str to the user.\n\t\tprint(USER_SELECT_ARXIV_PAPERS_QUERY)\n\t\tprint(select_info)\n\t\t# TODO receive the message from the user.\n\t\tuser_msg = ChatBuffer.test_get_user_text(user_id=user_id)\n\t\tuser_response = user_msg.user_msg\n\t\tif user_response is None:\n\t\t\traise RuntimeError(\"The User does not reply.\")\n\n\t\tnumbers = self._parse_user_select(\n\t\t\tuser_response=user_response,\n\t\t\tresult_num=len(results),\n\t\t)\n\t\tindices = [n - 1 for n in numbers]\n\t\treturn indices, user_response\n\n\tasync def _auser_select_results(self, user_id: str, results: List[Result]) -&gt; Tuple[List[int], str]:\n\t\tr\"\"\" Let the user select among the candidate papers \"\"\"\n\t\tselect_info = self._select_query(results=results)\n\t\t# TODO: Send the query str to the user.\n\t\tChatBuffer.put_agent_reply(\n\t\t\tuser_id=user_id,\n\t\t\treply_str=USER_SELECT_ARXIV_PAPERS_QUERY,\n\t\t\tinner_chat=True,\n\t\t\textra_info=select_info,\n\t\t)\n\n\t\t# TODO receive the message from the user.\n\t\tuser_msg = await ChatBuffer.get_user_msg(user_id=user_id)\n\t\tuser_response = user_msg.user_msg\n\n\t\tnumbers = self._parse_user_select(\n\t\t\tuser_response=user_response,\n\t\t\tresult_num=len(results),\n\t\t)\n\t\tindices = [n - 1 for n in numbers]\n\t\treturn indices, user_response\n\n\t@staticmethod\n\tdef _parse_user_select(user_response: str, result_num: int) -&gt; List[int]:\n\t\tr\"\"\" parse the user response to select numbers \"\"\"\n\t\tnumbers = []\n\t\tdigit_stack = []\n\t\tfor char in user_response:\n\t\t\tif char.isdigit():\n\t\t\t\tdigit_stack.append(char)\n\t\t\telse:\n\t\t\t\tif digit_stack:\n\t\t\t\t\tnumber = int(\"\".join(digit_stack))\n\t\t\t\t\tif 0 &lt; number &lt;= result_num:\n\t\t\t\t\t\tnumbers.append(int(number))\n\t\t\t\t\tdigit_stack = []\n\t\telse:\n\t\t\tif digit_stack:\n\t\t\t\tnumber = int(\"\".join(digit_stack))\n\t\t\t\tif 0 &lt; number &lt;= result_num:\n\t\t\t\t\tnumbers.append(int(number))\n\t\treturn numbers\n\n\t@staticmethod\n\tdef _select_query(results: List[Result]) -&gt; str:\n\t\tr\"\"\" The message including the searched paper infos. \"\"\"\n\t\tpapers = []\n\t\tfor idx, result in enumerate(results):\n\t\t\tpaper_info = ARXIV_PAPER_INFO_TMPL.format(\n\t\t\t\tpaper_idx=idx + 1,\n\t\t\t\ttitle=result.title,\n\t\t\t\tabstract=result.summary,\n\t\t\t)\n\t\t\tpapers.append(paper_info)\n\t\tquery_str = \"\\n\\n\".join(papers)\n\t\treturn query_str\n\n\tdef log(self, *args, **kwargs) -&gt; ToolLog:\n\t\top_log: OperationOutputLog = kwargs[\"operation_log\"]\n\n\t\tif not isinstance(op_log, OperationOutputLog):\n\t\t\traise ValueError(\"operation_log must be 'OperationLog'.\")\n\n\t\tlog_to_user = op_log.log_to_user\n\t\tlog_to_system = {\n\t\t\tTOOL_OP_DESCRIPTION: op_log.log_to_system[OP_DESCRIPTION],\n\t\t\tTOOL_REFERENCES: op_log.log_to_system[OP_REFERENCES],\n\t\t}\n\n\t\treturn ToolLog(\n\t\t\ttool_name=self.metadata.name,\n\t\t\tlog_to_system=log_to_system,\n\t\t\tlog_to_user=log_to_user,\n\t\t)\n\n\tdef search_download_pipeline(\n\t\tself,\n\t\tuser_id: str,\n\t\tsearch_str: str,\n\t\t**kwargs,\n\t) -&gt; FuncOutputWithLog:\n\t\tr\"\"\"\n\t\tThis tool is used to search relevant papers in arXiv and download the papers that the user is interested in.\n\t\tWhen using the tool, be sure that the search_str MUST be English.\n\t\tIf the user do not use English, translate the search string to English first.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user_id of a lab member.\n\t\t\tsearch_str (str): The string that is used to search in arXiv.\n\n\t\tReturns:\n\t\t\tFuncOutputWithLog: the operation output and log.\n\t\t\"\"\"\n\t\tself.account_manager.check_valid_user(user_id=user_id)\n\n\t\tresults = search_arxiv(search_str=search_str, max_results_num=self._max_results_num)\n\t\tindices, user_response = self._user_select_results(user_id=user_id, results=results)\n\n\t\tif len(indices) &lt; 1:\n\t\t\toperation_log_str = (\n\t\t\t\tf\"The user has no interest to the searched papers, end download operation.\\n\"\n\t\t\t\tf\"This is the user's response: {user_response}\"\n\t\t\t)\n\t\t\toperation_log = OperationOutputLog(\n\t\t\t\toperation_name=self._callback_operation.__name__,\n\t\t\t\toperation_output=None,\n\t\t\t\tlog_to_user=None,\n\t\t\t\tlog_to_system={\n\t\t\t\t\tOP_DESCRIPTION: operation_log_str,\n\t\t\t\t\tOP_REFERENCES: None,\n\t\t\t\t}\n\t\t\t)\n\t\t\tlog_dict = {\"operation_log\": operation_log}\n\t\t\treturn FuncOutputWithLog(\n\t\t\t\tfn_output=operation_log_str,\n\t\t\t\tfn_log=log_dict,\n\t\t\t)\n\n\t\tpaper_infos = list()\n\t\tfor idx in indices:\n\t\t\tpaper = results[idx]\n\t\t\tpaper_infos.append(\n\t\t\t\t{\n\t\t\t\t\t\"title\": paper.title,\n\t\t\t\t\t\"abstract\": paper.summary,\n\t\t\t\t\t\"pdf_url\": paper.pdf_url,\n\t\t\t\t}\n\t\t\t)\n\n\t\top_name = ArxivDownloadOperation.__name__\n\t\tkwargs = {\n\t\t\t\"user_id\": user_id,\n\t\t\t\"paper_infos\": paper_infos\n\t\t}\n\t\tkwargs_str = json.dumps(kwargs)\n\t\toperation_log = operation_authorize(\n\t\t\tuser_id=user_id,\n\t\t\top_name=op_name,\n\t\t\tkwargs_str=kwargs_str,\n\t\t\tllm=self._llm,\n\t\t\tembed_model=self._embed_model,\n\t\t\tverbose=self._verbose,\n\t\t)\n\t\tlog_dict = {\"operation_log\": operation_log}\n\t\treturn FuncOutputWithLog(\n\t\t\tfn_output=f\"Have downloaded papers for user {user_id}\",\n\t\t\tfn_log=log_dict,\n\t\t)\n\n\tasync def asearch_download_pipeline(\n\t\tself,\n\t\tuser_id: str,\n\t\tsearch_str: str,\n\t\t**kwargs,\n\t) -&gt; FuncOutputWithLog:\n\t\tr\"\"\"\n\t\tThis tool is used to search relevant papers in arXiv and download the papers that the user is interested in.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user_id of a lab member.\n\t\t\tsearch_str (str): The search string.\n\n\t\tReturns:\n\t\t\tFuncOutputWithLog: the operation output and log.\n\t\t\"\"\"\n\t\tself.account_manager.check_valid_user(user_id=user_id)\n\n\t\tresults = search_arxiv(search_str=search_str, max_results_num=self._max_results_num)\n\t\tindices, user_response = await self._auser_select_results(user_id=user_id, results=results)\n\n\t\tif len(indices) &lt; 1:\n\t\t\toperation_log_str = (\n\t\t\t\tf\"The user has no interest to the searched papers, end download operation.\\n\"\n\t\t\t\tf\"This is the user's response: {user_response}\"\n\t\t\t)\n\t\t\toperation_log = OperationOutputLog(\n\t\t\t\toperation_name=self._callback_operation.__name__,\n\t\t\t\toperation_output=None,\n\t\t\t\tlog_to_user=None,\n\t\t\t\tlog_to_system={OP_DESCRIPTION: operation_log_str,\n\t\t\t\t\tOP_REFERENCES: None,\n\t\t\t\t}\n\t\t\t)\n\t\t\tlog_dict = {\"operation_log\": operation_log}\n\t\t\treturn FuncOutputWithLog(\n\t\t\t\tfn_output=operation_log_str,\n\t\t\t\tfn_log=log_dict,\n\t\t\t)\n\n\t\tpaper_infos = list()\n\t\tfor idx in indices:\n\t\t\tpaper = results[idx]\n\t\t\tpaper_infos.append(\n\t\t\t\t{\n\t\t\t\t\t\"title\": paper.title,\n\t\t\t\t\t\"abstract\": paper.summary,\n\t\t\t\t\t\"pdf_url\": paper.pdf_url,\n\t\t\t\t}\n\t\t\t)\n\n\t\top_name = ArxivDownloadOperation.__name__\n\t\tkwargs = {\n\t\t\t\"user_id\": user_id,\n\t\t\t\"paper_infos\": paper_infos\n\t\t}\n\t\tkwargs_str = json.dumps(kwargs)\n\t\toperation_log = await aoperation_authorize(\n\t\t\tuser_id=user_id,\n\t\t\top_name=op_name,\n\t\t\tkwargs_str=kwargs_str,\n\t\t\tllm=self._llm,\n\t\t\tembed_model=self._embed_model,\n\t\t\tverbose=self._verbose,\n\t\t)\n\t\tlog_dict = {\"operation_log\": operation_log}\n\t\treturn FuncOutputWithLog(\n\t\t\tfn_output=f\"Have downloaded papers for user {user_id}\",\n\t\t\tfn_log=log_dict,\n\t\t)\n</code></pre>"},{"location":"code_docs/tools/paper/download/arxiv_download/#labridge.tools.paper.download.arxiv_download.ArXivSearchDownloadTool.asearch_download_pipeline","title":"<code>labridge.tools.paper.download.arxiv_download.ArXivSearchDownloadTool.asearch_download_pipeline(user_id, search_str, **kwargs)</code>  <code>async</code>","text":"<p>This tool is used to search relevant papers in arXiv and download the papers that the user is interested in.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user_id of a lab member.</p> <p> TYPE: <code>str</code> </p> <code>search_str</code> <p>The search string.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>FuncOutputWithLog</code> <p>the operation output and log.</p> <p> TYPE: <code>FuncOutputWithLog</code> </p> Source code in <code>labridge\\tools\\paper\\download\\arxiv_download.py</code> <pre><code>async def asearch_download_pipeline(\n\tself,\n\tuser_id: str,\n\tsearch_str: str,\n\t**kwargs,\n) -&gt; FuncOutputWithLog:\n\tr\"\"\"\n\tThis tool is used to search relevant papers in arXiv and download the papers that the user is interested in.\n\n\tArgs:\n\t\tuser_id (str): The user_id of a lab member.\n\t\tsearch_str (str): The search string.\n\n\tReturns:\n\t\tFuncOutputWithLog: the operation output and log.\n\t\"\"\"\n\tself.account_manager.check_valid_user(user_id=user_id)\n\n\tresults = search_arxiv(search_str=search_str, max_results_num=self._max_results_num)\n\tindices, user_response = await self._auser_select_results(user_id=user_id, results=results)\n\n\tif len(indices) &lt; 1:\n\t\toperation_log_str = (\n\t\t\tf\"The user has no interest to the searched papers, end download operation.\\n\"\n\t\t\tf\"This is the user's response: {user_response}\"\n\t\t)\n\t\toperation_log = OperationOutputLog(\n\t\t\toperation_name=self._callback_operation.__name__,\n\t\t\toperation_output=None,\n\t\t\tlog_to_user=None,\n\t\t\tlog_to_system={OP_DESCRIPTION: operation_log_str,\n\t\t\t\tOP_REFERENCES: None,\n\t\t\t}\n\t\t)\n\t\tlog_dict = {\"operation_log\": operation_log}\n\t\treturn FuncOutputWithLog(\n\t\t\tfn_output=operation_log_str,\n\t\t\tfn_log=log_dict,\n\t\t)\n\n\tpaper_infos = list()\n\tfor idx in indices:\n\t\tpaper = results[idx]\n\t\tpaper_infos.append(\n\t\t\t{\n\t\t\t\t\"title\": paper.title,\n\t\t\t\t\"abstract\": paper.summary,\n\t\t\t\t\"pdf_url\": paper.pdf_url,\n\t\t\t}\n\t\t)\n\n\top_name = ArxivDownloadOperation.__name__\n\tkwargs = {\n\t\t\"user_id\": user_id,\n\t\t\"paper_infos\": paper_infos\n\t}\n\tkwargs_str = json.dumps(kwargs)\n\toperation_log = await aoperation_authorize(\n\t\tuser_id=user_id,\n\t\top_name=op_name,\n\t\tkwargs_str=kwargs_str,\n\t\tllm=self._llm,\n\t\tembed_model=self._embed_model,\n\t\tverbose=self._verbose,\n\t)\n\tlog_dict = {\"operation_log\": operation_log}\n\treturn FuncOutputWithLog(\n\t\tfn_output=f\"Have downloaded papers for user {user_id}\",\n\t\tfn_log=log_dict,\n\t)\n</code></pre>"},{"location":"code_docs/tools/paper/download/arxiv_download/#labridge.tools.paper.download.arxiv_download.ArXivSearchDownloadTool.search_download_pipeline","title":"<code>labridge.tools.paper.download.arxiv_download.ArXivSearchDownloadTool.search_download_pipeline(user_id, search_str, **kwargs)</code>","text":"<p>This tool is used to search relevant papers in arXiv and download the papers that the user is interested in. When using the tool, be sure that the search_str MUST be English. If the user do not use English, translate the search string to English first.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user_id of a lab member.</p> <p> TYPE: <code>str</code> </p> <code>search_str</code> <p>The string that is used to search in arXiv.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>FuncOutputWithLog</code> <p>the operation output and log.</p> <p> TYPE: <code>FuncOutputWithLog</code> </p> Source code in <code>labridge\\tools\\paper\\download\\arxiv_download.py</code> <pre><code>def search_download_pipeline(\n\tself,\n\tuser_id: str,\n\tsearch_str: str,\n\t**kwargs,\n) -&gt; FuncOutputWithLog:\n\tr\"\"\"\n\tThis tool is used to search relevant papers in arXiv and download the papers that the user is interested in.\n\tWhen using the tool, be sure that the search_str MUST be English.\n\tIf the user do not use English, translate the search string to English first.\n\n\tArgs:\n\t\tuser_id (str): The user_id of a lab member.\n\t\tsearch_str (str): The string that is used to search in arXiv.\n\n\tReturns:\n\t\tFuncOutputWithLog: the operation output and log.\n\t\"\"\"\n\tself.account_manager.check_valid_user(user_id=user_id)\n\n\tresults = search_arxiv(search_str=search_str, max_results_num=self._max_results_num)\n\tindices, user_response = self._user_select_results(user_id=user_id, results=results)\n\n\tif len(indices) &lt; 1:\n\t\toperation_log_str = (\n\t\t\tf\"The user has no interest to the searched papers, end download operation.\\n\"\n\t\t\tf\"This is the user's response: {user_response}\"\n\t\t)\n\t\toperation_log = OperationOutputLog(\n\t\t\toperation_name=self._callback_operation.__name__,\n\t\t\toperation_output=None,\n\t\t\tlog_to_user=None,\n\t\t\tlog_to_system={\n\t\t\t\tOP_DESCRIPTION: operation_log_str,\n\t\t\t\tOP_REFERENCES: None,\n\t\t\t}\n\t\t)\n\t\tlog_dict = {\"operation_log\": operation_log}\n\t\treturn FuncOutputWithLog(\n\t\t\tfn_output=operation_log_str,\n\t\t\tfn_log=log_dict,\n\t\t)\n\n\tpaper_infos = list()\n\tfor idx in indices:\n\t\tpaper = results[idx]\n\t\tpaper_infos.append(\n\t\t\t{\n\t\t\t\t\"title\": paper.title,\n\t\t\t\t\"abstract\": paper.summary,\n\t\t\t\t\"pdf_url\": paper.pdf_url,\n\t\t\t}\n\t\t)\n\n\top_name = ArxivDownloadOperation.__name__\n\tkwargs = {\n\t\t\"user_id\": user_id,\n\t\t\"paper_infos\": paper_infos\n\t}\n\tkwargs_str = json.dumps(kwargs)\n\toperation_log = operation_authorize(\n\t\tuser_id=user_id,\n\t\top_name=op_name,\n\t\tkwargs_str=kwargs_str,\n\t\tllm=self._llm,\n\t\tembed_model=self._embed_model,\n\t\tverbose=self._verbose,\n\t)\n\tlog_dict = {\"operation_log\": operation_log}\n\treturn FuncOutputWithLog(\n\t\tfn_output=f\"Have downloaded papers for user {user_id}\",\n\t\tfn_log=log_dict,\n\t)\n</code></pre>"},{"location":"code_docs/tools/paper/download/arxiv_download/#labridge.tools.paper.download.arxiv_download.search_arxiv","title":"<code>labridge.tools.paper.download.arxiv_download.search_arxiv(search_str, max_results_num=3)</code>","text":"<p>Search in aXiv.org</p> PARAMETER DESCRIPTION <code>search_str</code> <p>the search string.</p> <p> TYPE: <code>str</code> </p> <code>max_results_num</code> <p>the maximum number of returned results. Defaults to 3.</p> <p> TYPE: <code>int</code> DEFAULT: <code>3</code> </p> RETURNS DESCRIPTION <code>List[Result]</code> <p>the paper info results.</p> Source code in <code>labridge\\tools\\paper\\download\\arxiv_download.py</code> <pre><code>def search_arxiv(search_str: str, max_results_num: int = 3) -&gt; List[Result]:\n\tr\"\"\"\n\tSearch in aXiv.org\n\n\tArgs:\n\t\tsearch_str (str): the search string.\n\t\tmax_results_num (int): the maximum number of returned results. Defaults to 3.\n\n\tReturns:\n\t\tthe paper info results.\n\t\"\"\"\n\tsearcher = ArxivSearcher(max_results_num=max_results_num)\n\tresults = searcher.search(search_str)\n\tif len(results) &lt; 1:\n\t\traise ValueError(\"Do not find relevant papers.\")\n\n\treturn results\n</code></pre>"},{"location":"code_docs/tools/paper/shared_papers/query/","title":"Query","text":""},{"location":"code_docs/tools/paper/shared_papers/query/#labridge.tools.paper.shared_papers.query","title":"<code>labridge.tools.paper.shared_papers.query</code>","text":"<p>All functions in this file need the authorization of the users before execution.</p> <p>All Interactions should be returned as tool output.</p>"},{"location":"code_docs/tools/paper/shared_papers/query/#labridge.tools.paper.shared_papers.query.PaperQueryTool","title":"<code>labridge.tools.paper.shared_papers.query.PaperQueryTool</code>","text":"<p>               Bases: <code>QueryEngineBaseTool</code></p> <p>This tool is used to answer the query with access to the shared paper storage.</p> Source code in <code>labridge\\tools\\paper\\shared_papers\\query.py</code> <pre><code>class PaperQueryTool(QueryEngineBaseTool):\n\tr\"\"\"\n\tThis tool is used to answer the query with access to the shared paper storage.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tpaper_query_engine: PaperQueryEngine,\n\t\tname=PAPER_QUERY_TOOL_NAME,\n\t\tdescription=PAPER_QUERY_TOOL_DESCRIPTION,\n\t):\n\t\tsuper().__init__(\n\t\t\tquery_engine=paper_query_engine,\n\t\t\tname=name,\n\t\t\tdescription=description,\n\t\t)\n\n\tdef log(self) -&gt; ToolLog:\n\t\tr\"\"\"\n\t\tGet the log: specifically, the references.\n\t\t\"\"\"\n\t\tref_infos: List[PaperInfo] = self.query_engine.get_ref_info()\n\n\t\tlog_to_user = None\n\t\tlog_to_system = {\n\t\t\tTOOL_OP_DESCRIPTION: f\"User the {self.metadata.name} to answer the user's query.\",\n\t\t\tTOOL_REFERENCES: [ref_info.dumps() for ref_info in ref_infos]\n\t\t}\n\t\treturn ToolLog(\n\t\t\ttool_name=self.metadata.name,\n\t\t\tlog_to_user=log_to_user,\n\t\t\tlog_to_system=log_to_system,\n\t\t)\n</code></pre>"},{"location":"code_docs/tools/paper/shared_papers/query/#labridge.tools.paper.shared_papers.query.PaperQueryTool.log","title":"<code>labridge.tools.paper.shared_papers.query.PaperQueryTool.log()</code>","text":"<p>Get the log: specifically, the references.</p> Source code in <code>labridge\\tools\\paper\\shared_papers\\query.py</code> <pre><code>def log(self) -&gt; ToolLog:\n\tr\"\"\"\n\tGet the log: specifically, the references.\n\t\"\"\"\n\tref_infos: List[PaperInfo] = self.query_engine.get_ref_info()\n\n\tlog_to_user = None\n\tlog_to_system = {\n\t\tTOOL_OP_DESCRIPTION: f\"User the {self.metadata.name} to answer the user's query.\",\n\t\tTOOL_REFERENCES: [ref_info.dumps() for ref_info in ref_infos]\n\t}\n\treturn ToolLog(\n\t\ttool_name=self.metadata.name,\n\t\tlog_to_user=log_to_user,\n\t\tlog_to_system=log_to_system,\n\t)\n</code></pre>"},{"location":"code_docs/tools/paper/shared_papers/retriever/","title":"Retriever","text":""},{"location":"code_docs/tools/paper/shared_papers/retriever/#labridge.tools.paper.shared_papers.retriever","title":"<code>labridge.tools.paper.shared_papers.retriever</code>","text":""},{"location":"code_docs/tools/paper/shared_papers/retriever/#labridge.tools.paper.shared_papers.retriever.SharedPaperRetrieverTool","title":"<code>labridge.tools.paper.shared_papers.retriever.SharedPaperRetrieverTool</code>","text":"<p>               Bases: <code>RetrieverBaseTool</code></p> <p>This tool is used to retrieve in the shared papers storage of the laboratory.</p> <p>Multi-level, hybrid retrieving is used for accurate results. For details of retrieving, refer to the docstring of <code>PaperRetriever</code>.</p> PARAMETER DESCRIPTION <code>llm</code> <p>The used LLM.</p> <p> TYPE: <code>LLM</code> DEFAULT: <code>None</code> </p> <code>embed_model</code> <p>The used embedding model.</p> <p> TYPE: <code>BaseEmbedding</code> DEFAULT: <code>None</code> </p> <code>vector_similarity_top_k</code> <p>The top-k of content-based retrieving. Defaults to <code>PAPER_VECTOR_TOP_K</code>.</p> <p> TYPE: <code>int</code> DEFAULT: <code>PAPER_VECTOR_TOP_K</code> </p> <code>summary_similarity_top_k</code> <p>The top-k of summary-based retrieving. Defaults tp <code>PAPER_SUMMARY_TOP_K</code>.</p> <p> TYPE: <code>int</code> DEFAULT: <code>PAPER_SUMMARY_TOP_K</code> </p> <code>docs_top_k</code> <p>The top-k docs will be selected. Defaults to <code>PAPER_TOP_K</code>.</p> <p> TYPE: <code>int</code> DEFAULT: <code>PAPER_TOP_K</code> </p> <code>re_retrieve_top_k</code> <p>The top-k of retrieving among the selected <code>docs_top_k</code> docs. Defaults to <code>PAPER_RETRIEVE_TOP_K</code>.</p> <p> TYPE: <code>int</code> DEFAULT: <code>PAPER_RETRIEVE_TOP_K</code> </p> <code>final_use_context</code> <p>Whether to use the context nodes of the retrieved nodes as parts of results. Defaults to True.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>final_use_summary</code> <p>Whether to use the summary nodes of the retrieved nodes' relevant docs as parts of results. Defaults to True.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> Source code in <code>labridge\\tools\\paper\\shared_papers\\retriever.py</code> <pre><code>class SharedPaperRetrieverTool(RetrieverBaseTool):\n\tr\"\"\"\n\tThis tool is used to retrieve in the shared papers storage of the laboratory.\n\n\tMulti-level, hybrid retrieving is used for accurate results.\n\tFor details of retrieving, refer to the docstring of `PaperRetriever`.\n\n\tArgs:\n\t\tllm (LLM): The used LLM.\n\t\tembed_model (BaseEmbedding): The used embedding model.\n\t\tvector_similarity_top_k (int): The top-k of content-based retrieving. Defaults to `PAPER_VECTOR_TOP_K`.\n\t\tsummary_similarity_top_k (int): The top-k of summary-based retrieving. Defaults tp `PAPER_SUMMARY_TOP_K`.\n\t\tdocs_top_k (int): The top-k docs will be selected. Defaults to `PAPER_TOP_K`.\n\t\tre_retrieve_top_k (int): The top-k of retrieving among the selected `docs_top_k` docs.\n\t\t\tDefaults to `PAPER_RETRIEVE_TOP_K`.\n\t\tfinal_use_context (bool): Whether to use the context nodes of the retrieved nodes as parts of results.\n\t\t\tDefaults to True.\n\t\tfinal_use_summary (bool): Whether to use the summary nodes of the retrieved nodes' relevant docs as parts of results.\n\t\t\tDefaults to True.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tllm: LLM = None,\n\t\tembed_model: BaseEmbedding = None,\n\t\tvector_similarity_top_k: int = PAPER_VECTOR_TOP_K,\n\t\tsummary_similarity_top_k: int = PAPER_SUMMARY_TOP_K,\n\t\tdocs_top_k: int = PAPER_TOP_K,\n\t\tre_retrieve_top_k: int = PAPER_RETRIEVE_TOP_K,\n\t\tfinal_use_context: bool = True,\n\t\tfinal_use_summary: bool = True,\n\t):\n\t\tself._llm = llm or Settings.llm\n\t\tself._embed_model = embed_model or Settings.embed_model\n\t\tpaper_retriever = PaperRetriever.from_storage(\n\t\t\tllm=self._llm,\n\t\t\tembed_model=self._embed_model,\n\t\t\tvector_similarity_top_k=vector_similarity_top_k,\n\t\t\tsummary_similarity_top_k=summary_similarity_top_k,\n\t\t\tdocs_top_k=docs_top_k,\n\t\t\tre_retrieve_top_k=re_retrieve_top_k,\n\t\t\tfinal_use_context=final_use_context,\n\t\t\tfinal_use_summary=final_use_summary,\n\t\t)\n\t\tsuper().__init__(\n\t\t\tname=SharedPaperRetrieverTool.__name__,\n\t\t\tretriever=paper_retriever,\n\t\t\tretrieve_fn=paper_retriever.retrieve,\n\t\t)\n\t\troot = Path(__file__)\n\t\tfor i in range(5):\n\t\t\troot = root.parent\n\t\tself.root = root\n\n\tdef log(self, log_dict: dict) -&gt; ToolLog:\n\t\tr\"\"\" Return the ToolLog with log string in a specific format. \"\"\"\n\t\titem_to_be_retrieved = log_dict[\"item_to_be_retrieved\"]\n\n\t\tref_infos: List[PaperInfo] = log_dict.get(TOOL_LOG_REF_INFO_KEY)\n\n\t\top_log = (\n\t\t\tf\"Retrieve in the shared papers.\\n\"\n\t\t\tf\"retrieve string: {item_to_be_retrieved}\\n\"\n\t\t)\n\t\tlog_to_user = None\n\t\tlog_to_system = {\n\t\t\tTOOL_OP_DESCRIPTION: op_log,\n\t\t\tTOOL_REFERENCES: [ref_info.dumps() for ref_info in ref_infos]\n\t\t}\n\t\treturn ToolLog(\n\t\t\ttool_name=self.metadata.name,\n\t\t\tlog_to_user=log_to_user,\n\t\t\tlog_to_system=log_to_system,\n\t\t)\n\n\tdef _retrieve(self, retrieve_kwargs: dict) -&gt; List[NodeWithScore]:\n\t\tr\"\"\" Use the retriever to retrieve relevant nodes. \"\"\"\n\t\tnodes = self._retriever.retrieve(**retrieve_kwargs)\n\t\treturn nodes\n\n\tasync def _aretrieve(self, retrieve_kwargs: dict) -&gt; List[NodeWithScore]:\n\t\tr\"\"\" Asynchronously use the retriever to retrieve relevant nodes. \"\"\"\n\t\tnodes = await self._retriever.aretrieve(**retrieve_kwargs)\n\t\treturn nodes\n\n\tdef get_ref_info(self, nodes: List[NodeWithScore]) -&gt; List[PaperInfo]:\n\t\tr\"\"\"\n\t\tGet the reference paper infos\n\n\t\tReturns:\n\t\t\tList[PaperInfo]: The reference paper infos in answering.\n\t\t\"\"\"\n\t\tdoc_ids, doc_titles, doc_possessors = [], [], []\n\t\tref_infos = []\n\t\tfor node_score in nodes:\n\t\t\tref_doc_id = node_score.node.ref_doc_id\n\t\t\tif ref_doc_id not in doc_ids:\n\t\t\t\tdoc_ids.append(ref_doc_id)\n\t\t\t\ttitle = node_score.node.metadata.get(PAPER_TITLE) or ref_doc_id\n\t\t\t\tpossessor = node_score.node.metadata.get(PAPER_POSSESSOR)\n\t\t\t\trel_path = node_score.node.metadata.get(PAPER_REL_FILE_PATH)\n\t\t\t\tif rel_path is None:\n\t\t\t\t\traise ValueError(\"Invalid database.\")\n\t\t\t\tpaper_info = PaperInfo(\n\t\t\t\t\ttitle=title,\n\t\t\t\t\tpossessor=possessor,\n\t\t\t\t\tfile_path=str(self.root / rel_path),\n\t\t\t\t)\n\t\t\t\tref_infos.append(paper_info)\n\n\t\t\t\tdoc_titles.append(title)\n\t\t\t\tdoc_possessors.append(possessor)\n\t\treturn ref_infos\n\n\tdef _nodes_to_tool_output(self, nodes: List[NodeWithScore]) -&gt; Tuple[str, dict]:\n\t\tr\"\"\" output the retrieved contents in a specific format, and the output log. \"\"\"\n\t\tref_infos = self.get_ref_info(nodes=nodes)\n\t\tlog_dict = {\n\t\t\tTOOL_LOG_REF_INFO_KEY: ref_infos,\n\t\t}\n\n\t\tpaper_contents = {}\n\t\tfor node in nodes:\n\t\t\tdoc_name = node.node.ref_doc_id\n\t\t\tif doc_name not in paper_contents:\n\t\t\t\tpaper_contents[doc_name] = [node.get_content(metadata_mode=MetadataMode.LLM)]\n\t\t\telse:\n\t\t\t\tpaper_contents[doc_name].append(node.get_content(metadata_mode=MetadataMode.LLM))\n\n\t\tif paper_contents:\n\t\t\tcontent_str = \"Have retrieved the following contents: \\n\"\n\t\t\tcontents = []\n\t\t\tfor doc_name in paper_contents.keys():\n\t\t\t\teach_str = f\"Following contents are from the paper: {doc_name}:\\n\"\n\t\t\t\teach_str += \"\\n\".join(paper_contents[doc_name])\n\t\t\t\tcontents.append(each_str.strip())\n\t\t\tcontent_str += \"\\n\\n\".join(contents)\n\t\telse:\n\t\t\tcontent_str = \"Have retrieved nothing.\\n\"\n\t\treturn content_str, log_dict\n</code></pre>"},{"location":"code_docs/tools/paper/shared_papers/retriever/#labridge.tools.paper.shared_papers.retriever.SharedPaperRetrieverTool.get_ref_info","title":"<code>labridge.tools.paper.shared_papers.retriever.SharedPaperRetrieverTool.get_ref_info(nodes)</code>","text":"<p>Get the reference paper infos</p> RETURNS DESCRIPTION <code>List[PaperInfo]</code> <p>List[PaperInfo]: The reference paper infos in answering.</p> Source code in <code>labridge\\tools\\paper\\shared_papers\\retriever.py</code> <pre><code>def get_ref_info(self, nodes: List[NodeWithScore]) -&gt; List[PaperInfo]:\n\tr\"\"\"\n\tGet the reference paper infos\n\n\tReturns:\n\t\tList[PaperInfo]: The reference paper infos in answering.\n\t\"\"\"\n\tdoc_ids, doc_titles, doc_possessors = [], [], []\n\tref_infos = []\n\tfor node_score in nodes:\n\t\tref_doc_id = node_score.node.ref_doc_id\n\t\tif ref_doc_id not in doc_ids:\n\t\t\tdoc_ids.append(ref_doc_id)\n\t\t\ttitle = node_score.node.metadata.get(PAPER_TITLE) or ref_doc_id\n\t\t\tpossessor = node_score.node.metadata.get(PAPER_POSSESSOR)\n\t\t\trel_path = node_score.node.metadata.get(PAPER_REL_FILE_PATH)\n\t\t\tif rel_path is None:\n\t\t\t\traise ValueError(\"Invalid database.\")\n\t\t\tpaper_info = PaperInfo(\n\t\t\t\ttitle=title,\n\t\t\t\tpossessor=possessor,\n\t\t\t\tfile_path=str(self.root / rel_path),\n\t\t\t)\n\t\t\tref_infos.append(paper_info)\n\n\t\t\tdoc_titles.append(title)\n\t\t\tdoc_possessors.append(possessor)\n\treturn ref_infos\n</code></pre>"},{"location":"code_docs/tools/paper/shared_papers/retriever/#labridge.tools.paper.shared_papers.retriever.SharedPaperRetrieverTool.log","title":"<code>labridge.tools.paper.shared_papers.retriever.SharedPaperRetrieverTool.log(log_dict)</code>","text":"<p>Return the ToolLog with log string in a specific format.</p> Source code in <code>labridge\\tools\\paper\\shared_papers\\retriever.py</code> <pre><code>def log(self, log_dict: dict) -&gt; ToolLog:\n\tr\"\"\" Return the ToolLog with log string in a specific format. \"\"\"\n\titem_to_be_retrieved = log_dict[\"item_to_be_retrieved\"]\n\n\tref_infos: List[PaperInfo] = log_dict.get(TOOL_LOG_REF_INFO_KEY)\n\n\top_log = (\n\t\tf\"Retrieve in the shared papers.\\n\"\n\t\tf\"retrieve string: {item_to_be_retrieved}\\n\"\n\t)\n\tlog_to_user = None\n\tlog_to_system = {\n\t\tTOOL_OP_DESCRIPTION: op_log,\n\t\tTOOL_REFERENCES: [ref_info.dumps() for ref_info in ref_infos]\n\t}\n\treturn ToolLog(\n\t\ttool_name=self.metadata.name,\n\t\tlog_to_user=log_to_user,\n\t\tlog_to_system=log_to_system,\n\t)\n</code></pre>"},{"location":"code_docs/tools/paper/shared_papers/utils/","title":"Utils","text":""},{"location":"code_docs/tools/paper/shared_papers/utils/#labridge.tools.paper.shared_papers.utils","title":"<code>labridge.tools.paper.shared_papers.utils</code>","text":""},{"location":"code_docs/tools/paper/shared_papers/utils/#labridge.tools.paper.shared_papers.utils.ref_papers_file_path","title":"<code>labridge.tools.paper.shared_papers.utils.ref_papers_file_path(ref_infos)</code>","text":"<p>Get all file paths of the PaperInfos.</p> Source code in <code>labridge\\tools\\paper\\shared_papers\\utils.py</code> <pre><code>def ref_papers_file_path(ref_infos: List[PaperInfo]) -&gt; List[str]:\n\tr\"\"\" Get all file paths of the PaperInfos. \"\"\"\n\treturn [paper_info.file_path for paper_info in ref_infos]\n</code></pre>"},{"location":"code_docs/tools/paper/shared_papers/utils/#labridge.tools.paper.shared_papers.utils.ref_papers_str_to_user","title":"<code>labridge.tools.paper.shared_papers.utils.ref_papers_str_to_user(ref_infos)</code>","text":"<p>Transform the relevant PaperInfos into formatted strings that will be added as extra info of the assistant's answer.</p> PARAMETER DESCRIPTION <code>ref_infos</code> <p>The reference paper infos.</p> <p> TYPE: <code>List[PaperInfo]</code> </p> RETURNS DESCRIPTION <code>str</code> <p>The formatted string.</p> <p> TYPE: <code>str</code> </p> Source code in <code>labridge\\tools\\paper\\shared_papers\\utils.py</code> <pre><code>def ref_papers_str_to_user(ref_infos: List[PaperInfo]) -&gt; str:\n\tr\"\"\"\n\tTransform the relevant PaperInfos into formatted strings\n\tthat will be added as extra info of the assistant's answer.\n\n\tArgs:\n\t\tref_infos (List[PaperInfo]): The reference paper infos.\n\n\tReturns:\n\t\tstr: The formatted string.\n\t\"\"\"\n\treferences, ref_titles, valid_refs = [], [], []\n\n\tfor paper_info in ref_infos:\n\t\tif paper_info.title not in ref_titles:\n\t\t\tref_titles.append(paper_info.title)\n\t\t\tvalid_refs.append(paper_info)\n\n\tref_str = f\"**REFERENCE:**\\n\"\n\tfor paper_info in valid_refs:\n\t\tpaper_str = f\"\\t**Title:** {paper_info.title}\\n\"\n\t\tpaper_str += f\"\\t\u200b\u8fd9\u200b\u7bc7\u6587\u7ae0\u200b\u7531\u200b{paper_info.possessor}\u200b\u6301\u6709\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u4e0e\u200bta\u200b\u591a\u591a\u200b\u4ea4\u6d41\u200b\u54e6\u200b\u3002\"\n\t\treferences.append(paper_str)\n\tref_str += \"\\n\".join(references)\n\treturn ref_str\n</code></pre>"},{"location":"code_docs/tools/paper/temporary_papers/insert/","title":"Insert","text":""},{"location":"code_docs/tools/paper/temporary_papers/insert/#labridge.tools.paper.temporary_papers.insert","title":"<code>labridge.tools.paper.temporary_papers.insert</code>","text":""},{"location":"code_docs/tools/paper/temporary_papers/insert/#labridge.tools.paper.temporary_papers.insert.AddNewRecentPaperTool","title":"<code>labridge.tools.paper.temporary_papers.insert.AddNewRecentPaperTool</code>","text":"<p>               Bases: <code>CallBackBaseTool</code></p> <p>This tool is used to add a new paper into a specific user's recent papers storage.</p> PARAMETER DESCRIPTION <code>llm</code> <p>The used LLM. If not specified, the <code>Settings.llm</code> will be used.</p> <p> TYPE: <code>LLM</code> DEFAULT: <code>None</code> </p> <code>embed_model</code> <p>The used embedding model. If not specified, the <code>Settings.embed_model</code> will be used.</p> <p> TYPE: <code>BaseEmbedding</code> DEFAULT: <code>None</code> </p> <code>verbose</code> <p>Whether to show the inner progress.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> Source code in <code>labridge\\tools\\paper\\temporary_papers\\insert.py</code> <pre><code>class AddNewRecentPaperTool(CallBackBaseTool):\n\tr\"\"\"\n\tThis tool is used to add a new paper into a specific user's recent papers storage.\n\n\tArgs:\n\t\tllm (LLM): The used LLM. If not specified, the `Settings.llm` will be used.\n\t\tembed_model (BaseEmbedding): The used embedding model. If not specified, the `Settings.embed_model` will be used.\n\t\tverbose (bool): Whether to show the inner progress.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tllm: LLM = None,\n\t\tembed_model: BaseEmbedding = None,\n\t\tverbose: bool = False,\n\t):\n\t\tself._llm = llm or Settings.llm\n\t\tself._embed_model = embed_model or Settings.embed_model\n\t\tself._verbose = verbose\n\t\tsuper().__init__(\n\t\t\tfn=self.add_paper,\n\t\t\tasync_fn=self.a_add_paper,\n\t\t\ttool_name=AddNewRecentPaperTool.__name__,\n\t\t\tcallback_operation=AddNewRecentPaperOperation,\n\t\t)\n\n\tdef log(self, **kwargs: Any) -&gt; ToolLog:\n\t\top_log = kwargs[\"operation_log\"]\n\t\tif not isinstance(op_log, OperationOutputLog):\n\t\t\traise ValueError(\"operation_log must be 'OperationLog'.\")\n\t\tlog_to_user = op_log.log_to_user\n\t\tlog_to_system = op_log.log_to_system\n\t\treturn ToolLog(\n\t\t\ttool_name=self.metadata.name,\n\t\t\tlog_to_user=log_to_user,\n\t\t\tlog_to_system=log_to_system,\n\t\t)\n\n\tdef add_paper(\n\t\tself,\n\t\tuser_id: str,\n\t\tpaper_file_path: str,\n\t) -&gt; FuncOutputWithLog:\n\t\tr\"\"\"\n\t\tThis tool is used to add a new paper to a specific user's recent papers storage.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user_id of a lab member.\n\t\t\tpaper_file_path (str): The file path of the paper to be added. Browse the chat context or tool logs\n\t\t\t\tto get the correct and valid file path.\n\n\t\tReturns:\n\t\t\tFuncOutputWithLog: The output and log.\n\t\t\"\"\"\n\t\t# This docstring is used as the tool description.\n\t\top_name = self._callback_operation.__name__\n\t\tkwargs = {\n\t\t\t\"user_id\": user_id,\n\t\t\t\"paper_file_path\": paper_file_path,\n\t\t}\n\n\t\tkwargs_str = json.dumps(kwargs)\n\t\toperation_log = operation_authorize(\n\t\t\tuser_id=user_id,\n\t\t\top_name=op_name,\n\t\t\tkwargs_str=kwargs_str,\n\t\t\tllm=self._llm,\n\t\t\tembed_model=self._embed_model,\n\t\t\tverbose=self._verbose,\n\t\t)\n\t\tlog_dict = {\"operation_log\": operation_log}\n\n\t\treturn FuncOutputWithLog(\n\t\t\tfn_output=f\"Have Added the paper {paper_file_path} to recent papers of the user {user_id}\",\n\t\t\tfn_log=log_dict,\n\t\t)\n\n\tasync def a_add_paper(\n\t\tself,\n\t\tuser_id: str,\n\t\tpaper_file_path: str,\n\t) -&gt; FuncOutputWithLog:\n\t\tr\"\"\"\n\t\tThis tool is used to add a new paper to a specific user's recent papers storage.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user_id of a lab member.\n\t\t\tpaper_file_path (str): The file path of the paper to be added. Browse the chat context or tool logs\n\t\t\t\tto get the correct and valid file path.\n\n\t\tReturns:\n\t\t\tFuncOutputWithLog: The output and log.\n\t\t\"\"\"\n\t\t# This docstring is used as the tool description.\n\t\top_name = self._callback_operation.__name__\n\t\tkwargs = {\n\t\t\t\"user_id\": user_id,\n\t\t\t\"paper_file_path\": paper_file_path,\n\t\t}\n\n\t\tkwargs_str = json.dumps(kwargs)\n\t\toperation_log = await aoperation_authorize(\n\t\t\tuser_id=user_id,\n\t\t\top_name=op_name,\n\t\t\tkwargs_str=kwargs_str,\n\t\t\tllm=self._llm,\n\t\t\tembed_model=self._embed_model,\n\t\t\tverbose=self._verbose,\n\t\t)\n\n\t\tlog_dict = {\"operation_log\": operation_log}\n\t\treturn FuncOutputWithLog(\n\t\t\tfn_output=f\"Have Added the paper {paper_file_path} to recent papers of the user {user_id}\",\n\t\t\tfn_log=log_dict,\n\t\t)\n</code></pre>"},{"location":"code_docs/tools/paper/temporary_papers/insert/#labridge.tools.paper.temporary_papers.insert.AddNewRecentPaperTool.a_add_paper","title":"<code>labridge.tools.paper.temporary_papers.insert.AddNewRecentPaperTool.a_add_paper(user_id, paper_file_path)</code>  <code>async</code>","text":"<p>This tool is used to add a new paper to a specific user's recent papers storage.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user_id of a lab member.</p> <p> TYPE: <code>str</code> </p> <code>paper_file_path</code> <p>The file path of the paper to be added. Browse the chat context or tool logs to get the correct and valid file path.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>FuncOutputWithLog</code> <p>The output and log.</p> <p> TYPE: <code>FuncOutputWithLog</code> </p> Source code in <code>labridge\\tools\\paper\\temporary_papers\\insert.py</code> <pre><code>async def a_add_paper(\n\tself,\n\tuser_id: str,\n\tpaper_file_path: str,\n) -&gt; FuncOutputWithLog:\n\tr\"\"\"\n\tThis tool is used to add a new paper to a specific user's recent papers storage.\n\n\tArgs:\n\t\tuser_id (str): The user_id of a lab member.\n\t\tpaper_file_path (str): The file path of the paper to be added. Browse the chat context or tool logs\n\t\t\tto get the correct and valid file path.\n\n\tReturns:\n\t\tFuncOutputWithLog: The output and log.\n\t\"\"\"\n\t# This docstring is used as the tool description.\n\top_name = self._callback_operation.__name__\n\tkwargs = {\n\t\t\"user_id\": user_id,\n\t\t\"paper_file_path\": paper_file_path,\n\t}\n\n\tkwargs_str = json.dumps(kwargs)\n\toperation_log = await aoperation_authorize(\n\t\tuser_id=user_id,\n\t\top_name=op_name,\n\t\tkwargs_str=kwargs_str,\n\t\tllm=self._llm,\n\t\tembed_model=self._embed_model,\n\t\tverbose=self._verbose,\n\t)\n\n\tlog_dict = {\"operation_log\": operation_log}\n\treturn FuncOutputWithLog(\n\t\tfn_output=f\"Have Added the paper {paper_file_path} to recent papers of the user {user_id}\",\n\t\tfn_log=log_dict,\n\t)\n</code></pre>"},{"location":"code_docs/tools/paper/temporary_papers/insert/#labridge.tools.paper.temporary_papers.insert.AddNewRecentPaperTool.add_paper","title":"<code>labridge.tools.paper.temporary_papers.insert.AddNewRecentPaperTool.add_paper(user_id, paper_file_path)</code>","text":"<p>This tool is used to add a new paper to a specific user's recent papers storage.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user_id of a lab member.</p> <p> TYPE: <code>str</code> </p> <code>paper_file_path</code> <p>The file path of the paper to be added. Browse the chat context or tool logs to get the correct and valid file path.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>FuncOutputWithLog</code> <p>The output and log.</p> <p> TYPE: <code>FuncOutputWithLog</code> </p> Source code in <code>labridge\\tools\\paper\\temporary_papers\\insert.py</code> <pre><code>def add_paper(\n\tself,\n\tuser_id: str,\n\tpaper_file_path: str,\n) -&gt; FuncOutputWithLog:\n\tr\"\"\"\n\tThis tool is used to add a new paper to a specific user's recent papers storage.\n\n\tArgs:\n\t\tuser_id (str): The user_id of a lab member.\n\t\tpaper_file_path (str): The file path of the paper to be added. Browse the chat context or tool logs\n\t\t\tto get the correct and valid file path.\n\n\tReturns:\n\t\tFuncOutputWithLog: The output and log.\n\t\"\"\"\n\t# This docstring is used as the tool description.\n\top_name = self._callback_operation.__name__\n\tkwargs = {\n\t\t\"user_id\": user_id,\n\t\t\"paper_file_path\": paper_file_path,\n\t}\n\n\tkwargs_str = json.dumps(kwargs)\n\toperation_log = operation_authorize(\n\t\tuser_id=user_id,\n\t\top_name=op_name,\n\t\tkwargs_str=kwargs_str,\n\t\tllm=self._llm,\n\t\tembed_model=self._embed_model,\n\t\tverbose=self._verbose,\n\t)\n\tlog_dict = {\"operation_log\": operation_log}\n\n\treturn FuncOutputWithLog(\n\t\tfn_output=f\"Have Added the paper {paper_file_path} to recent papers of the user {user_id}\",\n\t\tfn_log=log_dict,\n\t)\n</code></pre>"},{"location":"code_docs/tools/paper/temporary_papers/paper_retriever/","title":"Paper retriever","text":""},{"location":"code_docs/tools/paper/temporary_papers/paper_retriever/#labridge.tools.paper.temporary_papers.paper_retriever","title":"<code>labridge.tools.paper.temporary_papers.paper_retriever</code>","text":""},{"location":"code_docs/tools/paper/temporary_papers/paper_retriever/#labridge.tools.paper.temporary_papers.paper_retriever.RecentPaperRetrieveTool","title":"<code>labridge.tools.paper.temporary_papers.paper_retriever.RecentPaperRetrieveTool</code>","text":"<p>               Bases: <code>RetrieverBaseTool</code></p> <p>This tool is used to retrieve in the recent papers store of a specific user. A multilevel retrieving strategy is used. For details, refer to the <code>RecentPaperRetriever</code>. (start_date, end_date) can be provided to confine the retrieving range.</p> PARAMETER DESCRIPTION <code>embed_model</code> <p>The used embedding model. If not specified, The <code>Settings.embed_model</code> will be used.</p> <p> TYPE: <code>BaseEmbedding</code> DEFAULT: <code>None</code> </p> <code>first_top_k</code> <p>The similarity_top_k in the first retrieving. Defaults to <code>RECENT_PAPER_INFO_SIMILARITY_TOP_K</code>.</p> <p> TYPE: <code>int</code> DEFAULT: <code>RECENT_PAPER_INFO_SIMILARITY_TOP_K</code> </p> <code>secondary_top_k</code> <p>The similarity_top_k in the secondary retrieving. Defaults to <code>RECENT_PAPER_SIMILARITY_TOP_K</code>.</p> <p> TYPE: <code>int</code> DEFAULT: <code>RECENT_PAPER_SIMILARITY_TOP_K</code> </p> Source code in <code>labridge\\tools\\paper\\temporary_papers\\paper_retriever.py</code> <pre><code>class RecentPaperRetrieveTool(RetrieverBaseTool):\n\tr\"\"\"\n\tThis tool is used to retrieve in the recent papers store of a specific user.\n\tA multilevel retrieving strategy is used. For details, refer to the `RecentPaperRetriever`.\n\t(start_date, end_date) can be provided to confine the retrieving range.\n\n\tArgs:\n\t\tembed_model (BaseEmbedding): The used embedding model. If not specified, The `Settings.embed_model` will be used.\n\t\tfirst_top_k (int): The similarity_top_k in the first retrieving.\n\t\t\tDefaults to `RECENT_PAPER_INFO_SIMILARITY_TOP_K`.\n\t\tsecondary_top_k (int): The similarity_top_k in the secondary retrieving.\n\t\t\tDefaults to `RECENT_PAPER_SIMILARITY_TOP_K`.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tembed_model: BaseEmbedding = None,\n\t\tfirst_top_k: int = RECENT_PAPER_INFO_SIMILARITY_TOP_K,\n\t\tsecondary_top_k: int = RECENT_PAPER_SIMILARITY_TOP_K,\n\t\tuse_context: bool = False,\n\n\t):\n\t\tretriever = RecentPaperRetriever(\n\t\t\tembed_model=embed_model,\n\t\t\tfinal_use_context=use_context,\n\t\t\tfirst_top_k=first_top_k,\n\t\t\tsecondary_top_k=secondary_top_k,\n\t\t)\n\t\tsuper().__init__(\n\t\t\tname=RecentPaperRetrieveTool.__name__,\n\t\t\tretriever=retriever,\n\t\t\tretrieve_fn=retriever.retrieve,\n\t\t)\n\n\tdef log(self, log_dict: dict) -&gt; ToolLog:\n\t\tr\"\"\"\n\t\tRecord the tool log.\n\n\t\tArgs:\n\t\t\tlog_dict (dict): Including the input keyword arguments and the retrieving logs.\n\n\t\tReturns:\n\t\t\tToolLog: The packed tool log.\n\t\t\"\"\"\n\t\tuser_id = log_dict[\"user_id\"]\n\t\titem_to_be_retrieved = log_dict[\"item_to_be_retrieved\"]\n\t\tpaper_file_path = log_dict.get(\"paper_file_path\", None)\n\t\tstart_date = log_dict.get(\"start_date\", None)\n\t\tend_date = log_dict.get(\"end_date\", None)\n\n\t\top_log = (\n\t\t\tf\"Retrieve in the recent papers of the user: {user_id}.\\n\"\n\t\t\tf\"retrieve string: {item_to_be_retrieved}\\n\"\n\t\t)\n\t\tif paper_file_path is not None:\n\t\t\top_log += f\"target paper file path: {paper_file_path}\\n\"\n\t\tif None not in [start_date, end_date]:\n\t\t\top_log += (\n\t\t\t\tf\"start_date: {start_date}\\n\"\n\t\t\t\tf\"end_date: {end_date}\"\n\t\t\t)\n\n\t\tlog_to_user = None\n\t\tlog_to_system = {\n\t\t\tTOOL_OP_DESCRIPTION: op_log,\n\t\t\tTOOL_REFERENCES: None,\n\t\t}\n\n\t\treturn ToolLog(\n\t\t\ttool_name=self.metadata.name,\n\t\t\tlog_to_user=log_to_user,\n\t\t\tlog_to_system=log_to_system,\n\t\t)\n\n\tdef get_ref_info(self, nodes: List[NodeWithScore]) -&gt; List[RefInfoBase]:\n\t\tr\"\"\" Get the reference infos from the retrieved nodes. \"\"\"\n\t\treturn []\n\n\tdef _retrieve(self, retrieve_kwargs: dict) -&gt; List[NodeWithScore]:\n\t\tr\"\"\" Use the retriever to retrieve relevant nodes. \"\"\"\n\t\tnodes = self._retriever.retrieve(**retrieve_kwargs)\n\t\treturn nodes\n\n\tasync def _aretrieve(self, retrieve_kwargs: dict) -&gt; List[NodeWithScore]:\n\t\tr\"\"\" Asynchronously use the retriever to retrieve relevant nodes. \"\"\"\n\t\tnodes = await self._retriever.aretrieve(**retrieve_kwargs)\n\t\treturn nodes\n\n\tdef _nodes_to_tool_output(self, nodes: List[NodeWithScore]) -&gt; Tuple[str, dict]:\n\t\tr\"\"\" output the retrieved contents in a specific format, and the output log. \"\"\"\n\t\tpaper_contents = {}\n\n\t\tfor node in nodes:\n\t\t\tfile_path = node.node.parent_node.node_id\n\t\t\tif file_path not in paper_contents:\n\t\t\t\tpaper_contents[file_path] = [node.get_content(metadata_mode=MetadataMode.LLM)]\n\t\t\telse:\n\t\t\t\tpaper_contents[file_path].append(node.get_content(metadata_mode=MetadataMode.LLM))\n\n\t\tif paper_contents:\n\t\t\tcontent_str = \"Have retrieved the following content: \\n\"\n\t\t\tcontents = []\n\t\t\tfor paper_path in paper_contents.keys():\n\t\t\t\teach_str = f\"Following contents are from the paper stored in {paper_path}:\\n\"\n\t\t\t\teach_str += \"\\n\".join(paper_contents[paper_path])\n\t\t\t\tcontents.append(each_str.strip())\n\t\t\tcontent_str += \"\\n\\n\".join(contents)\n\t\telse:\n\t\t\tcontent_str = \"Have retrieved nothing.\\n\"\n\t\treturn content_str, dict()\n</code></pre>"},{"location":"code_docs/tools/paper/temporary_papers/paper_retriever/#labridge.tools.paper.temporary_papers.paper_retriever.RecentPaperRetrieveTool.get_ref_info","title":"<code>labridge.tools.paper.temporary_papers.paper_retriever.RecentPaperRetrieveTool.get_ref_info(nodes)</code>","text":"<p>Get the reference infos from the retrieved nodes.</p> Source code in <code>labridge\\tools\\paper\\temporary_papers\\paper_retriever.py</code> <pre><code>def get_ref_info(self, nodes: List[NodeWithScore]) -&gt; List[RefInfoBase]:\n\tr\"\"\" Get the reference infos from the retrieved nodes. \"\"\"\n\treturn []\n</code></pre>"},{"location":"code_docs/tools/paper/temporary_papers/paper_retriever/#labridge.tools.paper.temporary_papers.paper_retriever.RecentPaperRetrieveTool.log","title":"<code>labridge.tools.paper.temporary_papers.paper_retriever.RecentPaperRetrieveTool.log(log_dict)</code>","text":"<p>Record the tool log.</p> PARAMETER DESCRIPTION <code>log_dict</code> <p>Including the input keyword arguments and the retrieving logs.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>ToolLog</code> <p>The packed tool log.</p> <p> TYPE: <code>ToolLog</code> </p> Source code in <code>labridge\\tools\\paper\\temporary_papers\\paper_retriever.py</code> <pre><code>def log(self, log_dict: dict) -&gt; ToolLog:\n\tr\"\"\"\n\tRecord the tool log.\n\n\tArgs:\n\t\tlog_dict (dict): Including the input keyword arguments and the retrieving logs.\n\n\tReturns:\n\t\tToolLog: The packed tool log.\n\t\"\"\"\n\tuser_id = log_dict[\"user_id\"]\n\titem_to_be_retrieved = log_dict[\"item_to_be_retrieved\"]\n\tpaper_file_path = log_dict.get(\"paper_file_path\", None)\n\tstart_date = log_dict.get(\"start_date\", None)\n\tend_date = log_dict.get(\"end_date\", None)\n\n\top_log = (\n\t\tf\"Retrieve in the recent papers of the user: {user_id}.\\n\"\n\t\tf\"retrieve string: {item_to_be_retrieved}\\n\"\n\t)\n\tif paper_file_path is not None:\n\t\top_log += f\"target paper file path: {paper_file_path}\\n\"\n\tif None not in [start_date, end_date]:\n\t\top_log += (\n\t\t\tf\"start_date: {start_date}\\n\"\n\t\t\tf\"end_date: {end_date}\"\n\t\t)\n\n\tlog_to_user = None\n\tlog_to_system = {\n\t\tTOOL_OP_DESCRIPTION: op_log,\n\t\tTOOL_REFERENCES: None,\n\t}\n\n\treturn ToolLog(\n\t\ttool_name=self.metadata.name,\n\t\tlog_to_user=log_to_user,\n\t\tlog_to_system=log_to_system,\n\t)\n</code></pre>"},{"location":"code_docs/tools/paper/temporary_papers/paper_summarize/","title":"Paper summarize","text":""},{"location":"code_docs/tools/paper/temporary_papers/paper_summarize/#labridge.tools.paper.temporary_papers.paper_summarize","title":"<code>labridge.tools.paper.temporary_papers.paper_summarize</code>","text":""},{"location":"code_docs/tools/paper/temporary_papers/paper_summarize/#labridge.tools.paper.temporary_papers.paper_summarize.RecentPaperSummarizeTool","title":"<code>labridge.tools.paper.temporary_papers.paper_summarize.RecentPaperSummarizeTool</code>","text":"<p>               Bases: <code>CallBackBaseTool</code></p> <p>This tool summarize a recent paper of a user (stored in the RecentPaperStore).</p> PARAMETER DESCRIPTION <code>llm</code> <p>The used llm.</p> <p> TYPE: <code>LLM</code> DEFAULT: <code>None</code> </p> <code>embed_model</code> <p>The used embedding model.</p> <p> TYPE: <code>BaseEmbedding</code> DEFAULT: <code>None</code> </p> Source code in <code>labridge\\tools\\paper\\temporary_papers\\paper_summarize.py</code> <pre><code>class RecentPaperSummarizeTool(CallBackBaseTool):\n\tr\"\"\"\n\tThis tool summarize a recent paper of a user (stored in the RecentPaperStore).\n\n\tArgs:\n\t\tllm (LLM): The used llm.\n\t\tembed_model (BaseEmbedding): The used embedding model.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tllm: LLM = None,\n\t\tembed_model: BaseEmbedding = None,\n\t\tverbose: bool = False,\n\t):\n\t\tself._llm = llm or Settings.llm\n\t\tself._embed_model = embed_model or Settings.embed_model\n\t\tself._verbose = verbose\n\t\tsuper().__init__(\n\t\t\tfn=self.summarize_paper,\n\t\t\tasync_fn=self.asummarize_paper,\n\t\t\ttool_name=RecentPaperSummarizeTool.__name__,\n\t\t\tcallback_operation=PaperSummarizeOperation,\n\t\t\treturn_direct=True,\n\t\t)\n\n\tdef summarize_paper(\n\t\tself,\n\t\tuser_id: str,\n\t\tpaper_file_path: str,\n\t) -&gt; FuncOutputWithLog:\n\t\tr\"\"\"\n\t\tThis tool is used to summarize a paper that is stored in a specific user's recent papers storage.\n\t\tThis tool is used ONLY when the user explicitly ask for a summarization of the paper.\n\t\tDO NOT use this tool by yourself.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user_id of a lab member.\n\t\t\tpaper_file_path (str): The file path of a specific paper. Browse the chat context to get the correct\n\t\t\t\tand valid file path of the paper.\n\n\t\tReturns:\n\t\t\tThe summary of the paper.\n\t\t\"\"\"\n\t\t# This docstring is used as the tool description.\n\t\top_name = self._callback_operation.__name__\n\t\tkwargs = {\"user_id\": user_id, \"paper_file_path\": paper_file_path}\n\t\tkwargs_str = json.dumps(kwargs)\n\t\toperation_log = operation_authorize(\n\t\t\tuser_id=user_id,\n\t\t\top_name=op_name,\n\t\t\tkwargs_str=kwargs_str,\n\t\t\tllm=self._llm,\n\t\t\tembed_model=self._embed_model,\n\t\t\tverbose=self._verbose,\n\t\t)\n\t\tfn_output = operation_log.operation_output\n\t\tfn_log = {\"operation_log\": operation_log}\n\t\treturn FuncOutputWithLog(\n\t\t\tfn_output=fn_output,\n\t\t\tfn_log=fn_log,\n\t\t)\n\n\tasync def asummarize_paper(\n\t\tself,\n\t\tuser_id: str,\n\t\tpaper_file_path: str,\n\t) -&gt; FuncOutputWithLog:\n\t\tr\"\"\"\n\t\tThis tool is used to summarize a paper that is stored in a specific user's recent papers storage.\n\t\tThis tool is used ONLY when the user explicitly ask for a summarization of the paper.\n\t\tDO NOT use this tool by yourself.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user_id of a lab member.\n\t\t\tpaper_file_path (str): The file path of a specific paper. Browse the chat context to get the correct\n\t\t\t\tand valid file path of the paper.\n\n\t\tReturns:\n\t\t\tThe summary of the paper.\n\t\t\"\"\"\n\t\t# This docstring is used as the tool description.\n\t\top_name = self._callback_operation.__name__\n\t\tkwargs = {\"user_id\": user_id, \"paper_file_path\": paper_file_path}\n\t\tkwargs_str = json.dumps(kwargs)\n\t\toperation_log = await aoperation_authorize(\n\t\t\tuser_id=user_id,\n\t\t\top_name=op_name,\n\t\t\tkwargs_str=kwargs_str,\n\t\t\tllm=self._llm,\n\t\t\tembed_model=self._embed_model,\n\t\t\tverbose=self._verbose,\n\t\t)\n\t\tfn_output = operation_log.operation_output\n\t\tfn_log = {\"operation_log\": operation_log}\n\t\treturn FuncOutputWithLog(\n\t\t\tfn_output=fn_output,\n\t\t\tfn_log=fn_log,\n\t\t)\n\n\tdef log(self, **kwargs: Any) -&gt; ToolLog:\n\t\tpaper_file_path = kwargs[\"paper_file_path\"]\n\t\tuser_id = kwargs[\"user_id\"]\n\t\tlog_str = f\"Summarize the paper {paper_file_path} for the user {user_id}.\"\n\t\tlog_to_user = None\n\t\tlog_to_system = {\n\t\t\tTOOL_OP_DESCRIPTION: log_str,\n\t\t\tTOOL_REFERENCES: None,\n\t\t}\n\n\t\treturn ToolLog(\n\t\t\ttool_name=self.metadata.name,\n\t\t\tlog_to_user=log_to_user,\n\t\t\tlog_to_system=log_to_system,\n\t\t)\n</code></pre>"},{"location":"code_docs/tools/paper/temporary_papers/paper_summarize/#labridge.tools.paper.temporary_papers.paper_summarize.RecentPaperSummarizeTool.asummarize_paper","title":"<code>labridge.tools.paper.temporary_papers.paper_summarize.RecentPaperSummarizeTool.asummarize_paper(user_id, paper_file_path)</code>  <code>async</code>","text":"<p>This tool is used to summarize a paper that is stored in a specific user's recent papers storage. This tool is used ONLY when the user explicitly ask for a summarization of the paper. DO NOT use this tool by yourself.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user_id of a lab member.</p> <p> TYPE: <code>str</code> </p> <code>paper_file_path</code> <p>The file path of a specific paper. Browse the chat context to get the correct and valid file path of the paper.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>FuncOutputWithLog</code> <p>The summary of the paper.</p> Source code in <code>labridge\\tools\\paper\\temporary_papers\\paper_summarize.py</code> <pre><code>async def asummarize_paper(\n\tself,\n\tuser_id: str,\n\tpaper_file_path: str,\n) -&gt; FuncOutputWithLog:\n\tr\"\"\"\n\tThis tool is used to summarize a paper that is stored in a specific user's recent papers storage.\n\tThis tool is used ONLY when the user explicitly ask for a summarization of the paper.\n\tDO NOT use this tool by yourself.\n\n\tArgs:\n\t\tuser_id (str): The user_id of a lab member.\n\t\tpaper_file_path (str): The file path of a specific paper. Browse the chat context to get the correct\n\t\t\tand valid file path of the paper.\n\n\tReturns:\n\t\tThe summary of the paper.\n\t\"\"\"\n\t# This docstring is used as the tool description.\n\top_name = self._callback_operation.__name__\n\tkwargs = {\"user_id\": user_id, \"paper_file_path\": paper_file_path}\n\tkwargs_str = json.dumps(kwargs)\n\toperation_log = await aoperation_authorize(\n\t\tuser_id=user_id,\n\t\top_name=op_name,\n\t\tkwargs_str=kwargs_str,\n\t\tllm=self._llm,\n\t\tembed_model=self._embed_model,\n\t\tverbose=self._verbose,\n\t)\n\tfn_output = operation_log.operation_output\n\tfn_log = {\"operation_log\": operation_log}\n\treturn FuncOutputWithLog(\n\t\tfn_output=fn_output,\n\t\tfn_log=fn_log,\n\t)\n</code></pre>"},{"location":"code_docs/tools/paper/temporary_papers/paper_summarize/#labridge.tools.paper.temporary_papers.paper_summarize.RecentPaperSummarizeTool.summarize_paper","title":"<code>labridge.tools.paper.temporary_papers.paper_summarize.RecentPaperSummarizeTool.summarize_paper(user_id, paper_file_path)</code>","text":"<p>This tool is used to summarize a paper that is stored in a specific user's recent papers storage. This tool is used ONLY when the user explicitly ask for a summarization of the paper. DO NOT use this tool by yourself.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user_id of a lab member.</p> <p> TYPE: <code>str</code> </p> <code>paper_file_path</code> <p>The file path of a specific paper. Browse the chat context to get the correct and valid file path of the paper.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>FuncOutputWithLog</code> <p>The summary of the paper.</p> Source code in <code>labridge\\tools\\paper\\temporary_papers\\paper_summarize.py</code> <pre><code>def summarize_paper(\n\tself,\n\tuser_id: str,\n\tpaper_file_path: str,\n) -&gt; FuncOutputWithLog:\n\tr\"\"\"\n\tThis tool is used to summarize a paper that is stored in a specific user's recent papers storage.\n\tThis tool is used ONLY when the user explicitly ask for a summarization of the paper.\n\tDO NOT use this tool by yourself.\n\n\tArgs:\n\t\tuser_id (str): The user_id of a lab member.\n\t\tpaper_file_path (str): The file path of a specific paper. Browse the chat context to get the correct\n\t\t\tand valid file path of the paper.\n\n\tReturns:\n\t\tThe summary of the paper.\n\t\"\"\"\n\t# This docstring is used as the tool description.\n\top_name = self._callback_operation.__name__\n\tkwargs = {\"user_id\": user_id, \"paper_file_path\": paper_file_path}\n\tkwargs_str = json.dumps(kwargs)\n\toperation_log = operation_authorize(\n\t\tuser_id=user_id,\n\t\top_name=op_name,\n\t\tkwargs_str=kwargs_str,\n\t\tllm=self._llm,\n\t\tembed_model=self._embed_model,\n\t\tverbose=self._verbose,\n\t)\n\tfn_output = operation_log.operation_output\n\tfn_log = {\"operation_log\": operation_log}\n\treturn FuncOutputWithLog(\n\t\tfn_output=fn_output,\n\t\tfn_log=fn_log,\n\t)\n</code></pre>"},{"location":"demonstration/","title":"\u5e94\u7528\u200b\u5c55\u793a","text":"<p>\u200b\u6211\u4eec\u200b\u5728\u200b\u901a\u8fc7\u200b\u4e00\u4e9b\u200b\u5e94\u7528\u200b\u4f8b\u5b50\u200b\u5c55\u793a\u200bLabridge\u200b\u5982\u4f55\u200b\u6784\u5efa\u200b\u5b9e\u9a8c\u5ba4\u200b\u6c9f\u901a\u200b\u5408\u4f5c\u200b\u7684\u200b\u6865\u6881\u200b</p> <ul> <li>example1</li> </ul>"},{"location":"demonstration/developer_mode/comment_mode/","title":"\u5728\u200b Acting phase \u200b\u8bc4\u8bba","text":"<p>\u200b\u5982\u679c\u200b\u4f60\u200b\u6253\u5f00\u200b\u8bc4\u8bba\u200b\u6a21\u5f0f\u200b\uff0c\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u5728\u200bLabridge\u200b\u7684\u200b Acting phase \u200b\u5bf9\u200bta\u200b\u7684\u200b\u52a8\u4f5c\u200b\u6240\u200b\u5f97\u5230\u200b\u7684\u200bobservation\u200b\u8fdb\u884c\u200b\u8bc4\u8bba\u200b\uff0cLabridge\u200b\u4f1a\u200b\u53c2\u8003\u200b\u4f60\u200b\u7684\u200b\u8bc4\u8bba\u200b\u8fdb\u884c\u200b\u4e0b\u200b\u4e00\u6b65\u200b\u51b3\u7b56\u200b\u3002</p>"},{"location":"demonstration/developer_mode/comment_mode/#_1","title":"\u8bc4\u8bba\u200b\u6a21\u5f0f\u200b\u8bbe\u7f6e","text":"<p>\u200b\u5728\u200b\u8fd9\u4e2a\u200b\u4f8b\u5b50\u200b\u4e2d\u200b\uff0c\u200b\u6211\u4eec\u200b\u540c\u65f6\u200b\u6253\u5f00\u200b\u4e86\u200b\u6307\u4ee4\u200b\u6a21\u5f0f\u200b\u4e0e\u200b\u8bc4\u8bba\u200b\u6a21\u5f0f\u200b\u3002</p> <p></p>"},{"location":"demonstration/developer_mode/comment_mode/#_2","title":"\u793a\u4f8b","text":""},{"location":"demonstration/developer_mode/instruct_mode/","title":"\u5728\u200b reasoning phase \u200b\u6307\u5bfc\u200b\u601d\u8003","text":"<p>\u200b\u5982\u679c\u200b\u4f60\u200b\u6253\u5f00\u200b\u4e86\u200b\u6307\u4ee4\u200b\u6a21\u5f0f\u200b\uff0cLabridge\u200b\u4f1a\u200b\u5728\u200b Reasoning phase \u200b\u5c06\u200bta\u200b\u7684\u200b\u601d\u8003\u200b\u51b3\u7b56\u200b\u5c55\u73b0\u200b\u7ed9\u200b\u4f60\u200b\uff0c\u200b\u5e76\u200b\u6839\u636e\u200b\u4f60\u200b\u7684\u200b\u6307\u5bfc\u200b\u8fdb\u884c\u200b\u8c03\u6574\u200b\u3002</p>"},{"location":"demonstration/developer_mode/instruct_mode/#_1","title":"\u6307\u4ee4\u200b\u6a21\u5f0f\u200b\u8bbe\u7f6e\u200b:","text":""},{"location":"demonstration/developer_mode/instruct_mode/#_2","title":"\u793a\u4f8b\u200b:","text":""},{"location":"demonstration/experiment_log/record_log/","title":"\u5b9e\u9a8c\u200b\u65e5\u5fd7\u200b\u8bb0\u5f55","text":""},{"location":"demonstration/experiment_log/retrieve_log/","title":"\u5b9e\u9a8c\u200b\u65e5\u5fd7\u200b QA","text":""},{"location":"demonstration/instrument/instrument_docs/","title":"\u4eea\u5668\u200b\u4fe1\u606f\u200b QA","text":""},{"location":"demonstration/paper/paper_download/","title":"\u6587\u732e\u200b\u4e0b\u8f7d","text":""},{"location":"demonstration/paper/recent_papers_qa/","title":"\u8fd1\u671f\u200b\u6587\u732e\u200b QA","text":"<p>\u200b\u57fa\u4e8e\u200b\u5728\u200b\u6587\u732e\u200b\u4e0b\u8f7d\u200b\u4e2d\u200b\u4e0b\u8f7d\u200b\u7684\u200b\u6587\u732e\u200b:</p> <p></p>"},{"location":"demonstration/paper/shared_papers/","title":"\u5171\u4eab\u200b\u6587\u732e\u200b QA","text":""},{"location":"deployment/","title":"\u57fa\u4e8e\u200b\u6607\u200b\u817e\u200b\u8f6f\u786c\u4ef6\u200b\u7684\u200b\u9879\u76ee\u200b\u90e8\u7f72","text":"<p>\u200b\u57fa\u4e8e\u200b\u6607\u200b\u817e\u200b\u7684\u200b\u8f6f\u786c\u4ef6\u200b\u751f\u6001\u200b\uff0c\u200b\u6211\u4eec\u200b\u5bf9\u200bLabridge\u200b\u7684\u200b\u9879\u76ee\u200b\u90e8\u7f72\u200b\u91c7\u7528\u200b\u4e86\u200b\u591a\u5c42\u6b21\u200b\u7684\u200b\u90e8\u7f72\u200b\u65b9\u5f0f\u200b\u3002</p> <p></p>"},{"location":"deployment/#ailabridge","title":"\u6607\u200b\u817e\u200bAI\u200b\u82af\u7247\u200b\u52a0\u901f\u200bLabridge\u200b\u8fd0\u884c","text":"<p>\u200b\u6211\u4eec\u200b\u91c7\u7528\u200b\u642d\u8f7d\u200b\u6607\u200b\u817e\u200bAI\u200b\u82af\u7247\u200b\u7684\u200b OrangePi \u200b\u8fdb\u884c\u200bEmbedding\u200b\u6a21\u578b\u200b\u7684\u200b\u90e8\u7f72\u200b\uff0c\u200b\u5176\u200b\u642d\u8f7d\u200b\u7684\u200b\u6607\u200b\u817e\u200bAI\u200b\u82af\u7247\u200b\u5177\u5907\u200b 20TOPS (FP16) AI\u200b\u7b97\u529b\u200b\uff0c</p> <p>\u200b\u5145\u5206\u200b\u52a0\u901f\u200bLabridge\u200b\u7684\u200b\u4fe1\u606f\u68c0\u7d22\u200b\uff0c\u200b\u53d1\u6325\u200b\u6570\u636e\u200b\u672c\u5730\u200b\u90e8\u7f72\u200b\u7684\u200b\u4f18\u52bf\u200b\uff0c\u200b\u4fdd\u969c\u200b\u6570\u636e\u5b89\u5168\u200b\u3002</p> <p>\u200b\u540c\u65f6\u200b\uff0c\u200b\u5927\u200b\u8bed\u8a00\u200b\u6a21\u578b\u200b (LLM) \u200b\u90e8\u7f72\u200b\u5728\u200bGPU\u200b\u670d\u52a1\u5668\u200b\uff0c\u200b\u901a\u8fc7\u200bHTTP\u200b\u4e0e\u200bEmbedding\u200b\u6a21\u578b\u200b\u8fdb\u884c\u200b\u901a\u4fe1\u200b\u3002</p>"},{"location":"deployment/#labridge","title":"\u6607\u200b\u601d\u8d4b\u200b\u80fd\u200bLabridge","text":"<p>\u200b\u4e0d\u8bba\u662f\u200bEmbedding\u200b\u6a21\u578b\u200b\u8fd8\u662f\u200bLLM\uff0c\u200b\u90fd\u200b\u4f9d\u8d56\u4e8e\u200b Mindspore \u200b\u6df1\u5ea6\u200b\u5b66\u4e60\u200b\u6846\u67b6\u200b\u4e0e\u200b MindNLP \u200b\u81ea\u7136\u8bed\u8a00\u200b\u5904\u7406\u200b\u5957\u4ef6\u200b\u5b9e\u73b0\u200b\uff0c</p> <p>\u200b\u6607\u200b\u817e\u200b\u7684\u200b\u8f6f\u4ef6\u200b\u751f\u6001\u200b\u8d4b\u4e88\u200b\u4e86\u200bLabridge\u200b\u7075\u9b42\u200b\u4e0e\u200b\u667a\u80fd\u200b\u5f15\u64ce\u200b\u3002</p>"},{"location":"function_modules/chat_history/","title":"\u4ea4\u4e92\u200b\u65e5\u5fd7","text":""},{"location":"function_modules/chat_history/#_2","title":"\u201c\u200b\u6e29\u6545\u800c\u77e5\u65b0\u200b\u201d","text":"<p>\u200b\u9664\u4e86\u200b\u4e3a\u200b\u5f53\u524d\u200b\u4f1a\u8bdd\u200b\u670d\u52a1\u200b\u7684\u200bshort-term memory\u200b\u4e4b\u5916\u200b\uff0cLabridge\u200b\u4f1a\u200b\u4fdd\u5b58\u200b\u4e0e\u200b\u5b9e\u9a8c\u5ba4\u200b\u6bcf\u4e2a\u200b\u6210\u5458\u200b\u95f4\u200b\u7684\u200b\u4ea4\u4e92\u200b\u65e5\u5fd7\u200b\uff0c \u200b\u4ea4\u4e92\u200b\u65e5\u5fd7\u200b\u7684\u200b\u5185\u5bb9\u200b\u5305\u62ec\u200b\uff1a</p>"},{"location":"function_modules/chat_history/#_3","title":"\u804a\u5929\u8bb0\u5f55","text":"<p>\u200b\u4ee5\u200b\u5355\u6b21\u200b QA \u200b\u4e3a\u200b\u5355\u5143\u200b\uff0c\u200b\u8bb0\u5f55\u200b\u4e0b\u200b\u6210\u5458\u200b\u4e0e\u200bLabridge\u200b\u4e4b\u95f4\u200b\u7684\u200b\u804a\u5929\u8bb0\u5f55\u200b\u3002</p>"},{"location":"function_modules/chat_history/#_4","title":"\u5de5\u5177\u200b\u8c03\u7528\u200b\u65e5\u5fd7","text":"<p>\u200b\u5982\u679c\u200b\u5728\u200bQA\u200b\u7684\u200b\u8fc7\u7a0b\u200b\u4e2d\u200b\uff0cLabridge\u200b\u8c03\u7528\u200b\u4e86\u200b\u67d0\u4e9b\u200b\u5de5\u5177\u200b(Tools)\uff0c\u200b\u76f8\u5173\u200b\u5de5\u5177\u200b\u7684\u200b\u65e5\u5fd7\u200b(ToolLog)\u200b\u540c\u6837\u200b\u4f1a\u200b\u8bb0\u5f55\u200b\u5728\u200b\u672c\u6b21\u200bQA\u200b\u7684\u200b\u8bb0\u5f55\u200b\u4e2d\u200b\u3002 \u200b\u5173\u4e8e\u200b <code>ToolLog</code> \u200b\u7684\u200b\u6570\u636e\u7ed3\u6784\u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>tools.base.tool_log</code>\u3002</p> <p>\u200b\u4ee5\u4e0a\u200b\u4fe1\u606f\u200b\u5c06\u200b\u8bb0\u5f55\u200b\u4e3a\u200b\u5411\u91cf\u200b\u6570\u636e\u5e93\u200b\uff0c\u200b\u4f9b\u200bLabridge\u200b\u5728\u200b\u5408\u9002\u200b\u7684\u200b\u65f6\u673a\u200b\u8fdb\u884c\u200b\u68c0\u7d22\u200b\uff0c\u200b\u4e3a\u200bLabridge\u200b\u63d0\u4f9b\u200b\u957f\u671f\u200b\u8bb0\u5fc6\u200b\u7684\u200b\u529f\u80fd\u200b\u3002</p> <p>\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u8fdb\u4e00\u6b65\u200b\u4e86\u89e3\u200b\u4ea4\u4e92\u200b\u65e5\u5fd7\u200b\u5411\u91cf\u200b\u6570\u636e\u5e93\u200b\u7684\u200b\u7ed3\u6784\u200b\u4e0e\u200b\u68c0\u7d22\u200b</p>"},{"location":"function_modules/chat_history/short-term_history/","title":"\u77ed\u671f\u200b\u8bb0\u5fc6","text":"<p>Labridge\u200b\u4e3a\u200b\u6bcf\u4f4d\u200b\u6210\u5458\u200b\u6216\u200b\u6210\u5458\u200b\u5c0f\u7ec4\u200b\u5b58\u50a8\u200b\u4e00\u6bb5\u200b\u8fd1\u671f\u200b\u7684\u200b\u4ea4\u4e92\u200b\u8bb0\u5f55\u200b\uff0c\u200b\u8be5\u200b\u4ea4\u4e92\u200b\u8bb0\u5f55\u200b\u4e3a\u200b\u961f\u5217\u200b\u5f0f\u200b\u7ed3\u6784\u200b\uff0c\u200b\u5176\u200b\u957f\u5ea6\u200b\u56fa\u5b9a\u200b\u3002</p> <p>\u200b\u6bcf\u6b21\u200b\u4e0e\u200b\u6210\u5458\u200b\u8fdb\u884c\u200b\u4ea4\u4e92\u200b\uff0c\u200b\u76f8\u5e94\u200b\u7684\u200b\u4ea4\u4e92\u200b\u8bb0\u5f55\u200b\u4f1a\u200b\u4e0e\u200b\u8be5\u200b\u6210\u5458\u200b\u5f53\u524d\u200b\u7684\u200b\u6d88\u606f\u200b\u4f5c\u4e3a\u200b\u63d0\u793a\u200b\u8bcd\u200b\u7684\u200b\u4e00\u90e8\u5206\u200b\u8f93\u5165\u200b\u7ed9\u200b LLM\u3002</p> <p>\u200b\u7528\u6237\u200b\u53ef\u4ee5\u200b\u624b\u52a8\u200b\u6e05\u7a7a\u200b\u8be5\u200b\u77ed\u671f\u200b\u8bb0\u5fc6\u200b\u5f00\u542f\u200b\u65b0\u200b\u7684\u200b\u8bdd\u9898\u200b\uff0c\u200b\u907f\u514d\u200b\u5386\u53f2\u200b\u4f1a\u8bdd\u200b\u7684\u200b\u5e72\u6270\u200b\u3002</p>"},{"location":"function_modules/chat_history/long-term_history/retrieve/","title":"\u4ea4\u4e92\u200b\u65e5\u5fd7\u200b\u68c0\u7d22","text":"<p>\u200b\u4ea4\u4e92\u200b\u65e5\u5fd7\u200b\u68c0\u7d22\u200b\u7684\u200b\u7279\u70b9\u200b\u662f\u200b\u4e0e\u200b\u65f6\u95f4\u200b\u5f3a\u200b\u76f8\u5173\u200b\uff0c\u200b\u56e0\u6b64\u200bLabridge\u200b\u91c7\u7528\u200b\u76f8\u4f3c\u6027\u200b\u68c0\u7d22\u200b + \u200b\u65f6\u95f4\u200b\u6233\u200b\u8fc7\u6ee4\u200b\u7684\u200b\u68c0\u7d22\u200b\u65b9\u5f0f\u200b\u6765\u200b\u8fdb\u884c\u200b\u4ea4\u4e92\u200b\u65e5\u5fd7\u200b\u68c0\u7d22\u200b\u3002</p> <p></p>"},{"location":"function_modules/chat_history/long-term_history/retrieve/#_2","title":"\u65f6\u95f4\u200b\u6233\u200b\u8fc7\u6ee4\u200b\uff1a","text":"<p>\u200b\u6bcf\u4e2a\u200b QA \u200b\u65e5\u5fd7\u200b\u8282\u70b9\u200b\u90fd\u200b\u8bb0\u5f55\u200b\u4e86\u200b\u76f8\u5e94\u200b\u7684\u200b\u65f6\u95f4\u200b\u6233\u200b\uff0cLabridge\u200b\u6839\u636e\u200b\u8f93\u5165\u200b\u7684\u200b\u5f00\u59cb\u200b\u65f6\u95f4\u200b\u4e0e\u200b\u7ed3\u675f\u200b\u65f6\u95f4\u200b\u6765\u200b\u5bf9\u200b\u65e5\u5fd7\u200b\u8282\u70b9\u200b\u8fdb\u884c\u200b\u8fc7\u6ee4\u200b\uff0c\u200b\u7f29\u5c0f\u200b\u68c0\u7d22\u200b\u8303\u56f4\u200b\u3002</p>"},{"location":"function_modules/chat_history/long-term_history/retrieve/#_3","title":"\u76f8\u4f3c\u6027\u200b\u68c0\u7d22\u200b\uff1a","text":"<p>\u200b\u5728\u200b\u7ecf\u8fc7\u200b\u8fc7\u6ee4\u200b\u7f29\u5c0f\u200b\u8303\u56f4\u200b\u540e\u200b\u7684\u200b\u65e5\u5fd7\u200b\u8282\u70b9\u200b\u4e2d\u200b\uff0c\u200b\u6839\u636e\u200bQuery\u200b\u7684\u200b<code>Embedding\u200b\u5411\u91cf\u200b</code>\u200b\u4e0e\u200b QA \u200b\u65e5\u5fd7\u200b\u5411\u91cf\u200b\u7684\u200b\u76f8\u4f3c\u6027\u200b\u68c0\u7d22\u200b\u51fa\u200b\u6700\u200b\u76f8\u4f3c\u200b\u7684\u200b<code>relevant_top_k</code>\u200b\u6761\u200b\u4ea4\u4e92\u200b\u65e5\u5fd7\u200b\u3002</p>"},{"location":"function_modules/chat_history/long-term_history/retrieve/#_4","title":"\u6dfb\u52a0\u200b\u4e0a\u4e0b\u6587\u200b\uff1a","text":"<p>\u200b\u7531\u4e8e\u200bLabridge\u200b\u4e0e\u200b\u6210\u5458\u200b\u4e4b\u95f4\u200b\u7684\u200b\u4ea4\u4e92\u200b\u5f80\u5f80\u200b\u662f\u200b\u8fde\u7eed\u200b\u7684\u200b\u591a\u8f6e\u200b <code>QA</code>\uff0c\u200b\u56e0\u6b64\u200b\u4e3a\u200b\u6240\u6709\u200b\u68c0\u7d22\u200b\u7ed3\u679c\u200b\u6dfb\u52a0\u200b\u4e0a\u4e0b\u6587\u200b(\u200b\u5373\u200b\u4e4b\u524d\u200b\u7684\u200bQA\u200b\u4e0e\u200b\u4e4b\u540e\u200b\u7684\u200bQA)\uff0c\u200b\u4fdd\u8bc1\u200b\u4ea4\u4e92\u200b\u65e5\u5fd7\u200b\u7684\u200b\u5b8c\u6574\u6027\u200b\u3002</p>"},{"location":"function_modules/chat_history/long-term_history/retrieve/#_5","title":"\u6309\u200b\u65f6\u95f4\u200b\u91cd\u6392\u200b\uff1a","text":"<p>\u200b\u4ea4\u4e92\u200b\u65e5\u5fd7\u200b\u7684\u200b\u7279\u70b9\u200b\u662f\u200b\u65f6\u95f4\u200b\u5355\u5411\u6027\u200b\uff0c\u200b\u65e5\u5fd7\u200b\u4e4b\u95f4\u200b\u7684\u200b\u987a\u5e8f\u200b\u5f88\u5927\u200b\u7a0b\u5ea6\u200b\u5f71\u54cd\u200b\u5bf9\u8bdd\u200b\u7684\u200b\u8bed\u4e49\u200b\uff0c\u200b\u56e0\u6b64\u200b\u5728\u200b\u6dfb\u52a0\u200b\u4e0a\u4e0b\u6587\u200b\u540e\u200b\uff0c\u200b\u5bf9\u200b\u5f97\u5230\u200b\u7684\u200b QA \u200b\u65e5\u5fd7\u200b\u8282\u70b9\u200b\u8fdb\u884c\u200b\u53bb\u200b\u91cd\u200b\u4e0e\u200b\u6392\u5e8f\u200b\uff0c\u200b\u4fdd\u8bc1\u200b\u4ea4\u4e92\u200b\u65e5\u5fd7\u200b\u7684\u200b\u8fde\u8d2f\u6027\u200b\u3002</p> <p>\u200b\u5173\u4e8e\u200b\u4ea4\u4e92\u200b\u65e5\u5fd7\u200b\u68c0\u7d22\u200b\u7684\u200b\u5177\u4f53\u200b\u7ec6\u8282\u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Func_modules.memory.chat.retrieve</code></p>"},{"location":"function_modules/chat_history/long-term_history/store/","title":"\u4ea4\u4e92\u200b\u65e5\u5fd7\u200b\u5b58\u50a8\u200b\u7ed3\u6784","text":"<p>\u200b\u4ea4\u4e92\u200b\u65e5\u5fd7\u200b\u4ee5\u200b\u5355\u8f6e\u200b QA \u200b\u4e3a\u200b\u57fa\u672c\u200b\u5355\u5143\u200b\uff0c\u200b\u5185\u5bb9\u200b\u5305\u542b\u200b\u804a\u5929\u8bb0\u5f55\u200b\u4e0e\u200b\u671f\u95f4\u200b\u7684\u200b\u5de5\u5177\u200b\u65e5\u5fd7\u200b\u3002\u200b\u4e3a\u200b\u6bcf\u4f4d\u200b\u6210\u5458\u200b\u6216\u200b\u6210\u5458\u200b\u5c0f\u7ec4\u200b\u5b58\u50a8\u200b\u72ec\u7acb\u200b\u7684\u200b\u5411\u91cf\u200b\u6570\u636e\u5e93\u200b\u3002</p> <p>\u200b\u6bcf\u4e2a\u200b\u5411\u91cf\u200b\u6570\u636e\u5e93\u200b\u7684\u200b\u7ed3\u6784\u200b\u7c7b\u4f3c\u200b\u4e8e\u200b\u4e00\u4e2a\u200b\u53cc\u5411\u200b\u94fe\u8868\u200b\u7684\u200b\u7ed3\u6784\u200b\u3002</p> <p></p> <ul> <li>\u200b\u6700\u200b\u5f00\u59cb\u200b\u7684\u200b\u8282\u70b9\u200b\u4e3a\u200b\u521d\u59cb\u200b\u8282\u70b9\u200b(first node)\uff0c\u200b\u521d\u59cb\u200b\u8282\u70b9\u200b\u4e2d\u200b\u5b58\u50a8\u200b\u4e86\u200b\u8be5\u200b\u6570\u636e\u5e93\u200b\u7684\u200b\u6240\u5c5e\u200b\u5bf9\u8c61\u200b\uff0c\u200b\u4e0e\u200b\u8be5\u200b\u6570\u636e\u5e93\u200b\u7684\u200b\u63cf\u8ff0\u200b\u3002\u200b\u989d\u5916\u200b\u4fe1\u606f\u200b\u5305\u62ec\u200b\u8be5\u200b\u6570\u636e\u5e93\u200b\u7684\u200b\u521b\u5efa\u200b\u65f6\u95f4\u200b\u3002</li> <li>\u200b\u65b0\u200b\u52a0\u5165\u200b\u7684\u200b QA \u200b\u65e5\u5fd7\u200b\u5355\u5143\u200b\u5c06\u200b\u4f5c\u4e3a\u200b\u6700\u540e\u200b\u4e00\u4e2a\u200b\u8282\u70b9\u200b\u52a0\u5165\u200b\u8be5\u200b\u94fe\u8868\u200b\u7ed3\u6784\u200b\uff0c\u200b\u8be5\u200b\u8282\u70b9\u200b\u4e2d\u200b\u5b58\u50a8\u200b\u4e86\u200b QA \u200b\u7684\u200b\u65e5\u5fd7\u200b\uff0c\u200b\u989d\u5916\u200b\u4fe1\u606f\u200b\u5305\u62ec\u200b\u8be5\u200b QA \u200b\u7684\u200b\u53d1\u751f\u200b\u65f6\u95f4\u200b(<code>date</code> <code>time</code>)\u3002</li> </ul> <p>\u200b\u5728\u200b\u6bcf\u6b21\u200b\u4e0e\u200b\u6210\u5458\u200b\u8fdb\u884c\u200b\u4ea4\u4e92\u200b\uff0c\u200b\u6216\u200b\u5728\u200b\u6210\u5458\u200b\u5c0f\u7ec4\u200b\u7684\u200b\u7fa4\u804a\u200b\u4e2d\u200b\u4ea4\u4e92\u200b\u540e\u200b\uff0c\u200b\u4ea4\u4e92\u200b\u65e5\u5fd7\u200b\u90fd\u200b\u4f1a\u200b\u88ab\u200b\u8bb0\u5f55\u200b\u5728\u200b\u76f8\u5e94\u200b\u7684\u200b\u5411\u91cf\u200b\u6570\u636e\u5e93\u200b\u4e2d\u200b\uff0c\u200b\u5e76\u200b\u6301\u4e45\u200b\u5316\u200b\u3002</p> <p>\u200b\u5173\u4e8e\u200b\u4ea4\u4e92\u200b\u65e5\u5fd7\u200b\u5b58\u50a8\u200b\u7ed3\u6784\u200b\u7684\u200b\u7ec6\u8282\u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Func_modules.memory.chat.store</code></p>"},{"location":"function_modules/experiment_log/","title":"\u5b9e\u9a8c\u200b\u65e5\u5fd7","text":""},{"location":"function_modules/experiment_log/#_2","title":"\u201c\u200b\u4f60\u200b\u7684\u200b\u6bcf\u200b\u4e00\u4e2a\u200b\u5b9e\u9a8c\u200b\u7ed3\u679c\u200b\uff0c\u200b\u90fd\u200b\u6709\u200b\u53ef\u80fd\u200b\u6539\u53d8\u200b\u4e16\u754c\u200b\u201d","text":"<p>\u200b\u7814\u7a76\u8005\u200b\u4eec\u200b\u901a\u8fc7\u200b\u5b9e\u9a8c\u200b\u6765\u200b\u63a2\u7d22\u200b\u4eba\u7c7b\u200b\u77e5\u8bc6\u200b\u7684\u200b\u8fb9\u754c\u200b\uff0c\u200b\u867d\u7136\u200b\u5927\u90e8\u5206\u200b\u63a2\u7d22\u200b\u90fd\u200b\u662f\u200b\u201c\u200b\u5931\u8d25\u200b\u7684\u200b\u201d\uff0c\u200b\u4f46\u200b\u968f\u7740\u200b\u7814\u7a76\u8005\u200b\u8ba4\u77e5\u200b\u7684\u200b\u53d8\u5316\u200b\uff0c \u200b\u6216\u8bb8\u200b\u53ef\u4ee5\u200b\u4ece\u200b\u201c\u200b\u5931\u8d25\u200b\u201d\u200b\u7684\u200b\u5b9e\u9a8c\u200b\u7ed3\u679c\u200b\u4e2d\u200b\u53d1\u6398\u200b\u51fa\u65b0\u200b\u7684\u200b\u4ef7\u503c\u200b\uff1b\u200b\u53c8\u200b\u6216\u8005\u200b\u5176\u5b83\u200b\u65b9\u5411\u200b\u7684\u200b\u7814\u7a76\u8005\u200b\u80fd\u200b\u4ece\u200b\u53e6\u200b\u4e00\u4e2a\u200b\u89d2\u5ea6\u200b\u53d1\u73b0\u200b\u5b83\u200b\u72ec\u7279\u200b\u7684\u200b\u4ef7\u503c\u200b\u3002</p> <p>\u200b\u56e0\u6b64\u200b\u6bcf\u200b\u4e00\u6b21\u200b\u7684\u200b\u5b9e\u9a8c\u200b\u7ed3\u679c\u200b\u90fd\u200b\u503c\u5f97\u200b\u8be6\u7ec6\u200b\u8bb0\u5f55\u200b\uff0cLabridge\u200b\u4e3a\u200b\u5b9e\u9a8c\u5ba4\u200b\u6210\u5458\u200b\u4eec\u200b\u63d0\u4f9b\u200b\u5b9e\u9a8c\u200b\u65e5\u5fd7\u200b\u8bb0\u5f55\u200b\u7684\u200b\u529f\u80fd\u200b\uff1a</p>"},{"location":"function_modules/experiment_log/#_3","title":"\u4e2a\u4eba\u200b\u5b9e\u9a8c\u200b\u65e5\u5fd7\u200b\u8bb0\u5f55\u200b\uff1a","text":"<p>Labridge\u200b\u4e3a\u200b\u5b9e\u9a8c\u5ba4\u200b\u6bcf\u4e2a\u200b\u6210\u5458\u200b\u72ec\u7acb\u200b\u5730\u200b\u8bb0\u5f55\u200b\u5176\u200b\u4e2a\u4eba\u200b\u5b9e\u9a8c\u200b\u65e5\u5fd7\u200b, \u200b\u5e76\u200b\u534f\u52a9\u200b\u6210\u5458\u200b\u68b3\u7406\u200b\u3001\u200b\u6574\u5408\u200b\u5b9e\u9a8c\u200b\u7ed3\u679c\u200b\u3002</p>"},{"location":"function_modules/experiment_log/#_4","title":"\u5171\u4eab\u200b\u5b9e\u9a8c\u200b\u65e5\u5fd7\u200b\u8bb0\u5f55\u200b\uff1a","text":"<p>Labridge\u200b\u540c\u65f6\u200b\u4e3a\u200b\u6574\u4e2a\u200b\u5b9e\u9a8c\u5ba4\u200b\u8bb0\u5f55\u200b\u5171\u4eab\u200b\u5b9e\u9a8c\u200b\u7ed3\u679c\u200b\u8bb0\u5f55\u200b\uff0c \u200b\u6210\u5458\u200b\u4eec\u200b\u53ef\u4ee5\u200b\u5c06\u200b\u81ea\u5df1\u200b\u7684\u200b\u5b9e\u9a8c\u200b\u7ed3\u679c\u200b\u52a0\u5165\u200b\u5230\u200b\u5171\u4eab\u200b\u8bb0\u5f55\u200b\u4e2d\u200b\uff0c\u200b\u4f9b\u200b\u6240\u6709\u200b\u6210\u5458\u200b\u68c0\u7d22\u200b\u4e0e\u200b\u9605\u89c8\u200b\u3002</p>"},{"location":"function_modules/experiment_log/personal_experiment/","title":"\u4e2a\u4eba\u200b\u5b9e\u9a8c\u200b\u65e5\u5fd7","text":"<p>Labridge\u200b\u4e3a\u200b\u5b9e\u9a8c\u5ba4\u200b\u7684\u200b\u6bcf\u4f4d\u200b\u6210\u5458\u200b\u8bb0\u5f55\u200b\u5176\u200b\u5b9e\u9a8c\u200b\u65e5\u5fd7\u200b\u3002</p>"},{"location":"function_modules/experiment_log/personal_experiment/#_2","title":"\u4e2a\u4eba\u200b\u5b9e\u9a8c\u200b\u65e5\u5fd7\u200b\u5b58\u50a8\u200b\u7ed3\u6784","text":"<p>\u200b\u6210\u5458\u200b\u7684\u200b\u6bcf\u4e2a\u200b\u5b9e\u9a8c\u200b\u5bf9\u5e94\u200b\u7684\u200b\u8bb0\u5f55\u200b\u5b58\u50a8\u200b\u5728\u200b\u4e2a\u4eba\u200b\u5b9e\u9a8c\u200b\u65e5\u5fd7\u200b\u5411\u91cf\u200b\u6570\u636e\u5e93\u200b</p>"},{"location":"function_modules/experiment_log/personal_experiment/#_3","title":"\u4e2a\u4eba\u200b\u5b9e\u9a8c\u200b\u65e5\u5fd7\u200b\u68c0\u7d22","text":"<p>Labridge\u200b\u4ece\u200b\u5b9e\u9a8c\u200b\u65e5\u5fd7\u200b\u8bb0\u5f55\u200b\u4e2d\u200b\u68c0\u7d22\u200b\u4fe1\u606f\u200b\u534f\u52a9\u200b\u6210\u5458\u200b\u8fdb\u884c\u200b\u5b9e\u9a8c\u200b\u3002</p>"},{"location":"function_modules/experiment_log/personal_experiment/#_4","title":"\u4e2a\u4eba\u200b\u5b9e\u9a8c\u200b\u65e5\u5fd7\u200b\u7ba1\u7406","text":"<p>Labridge\u200b\u901a\u8fc7\u200b\u8c03\u7528\u200b\u5de5\u5177\u200b(Tools)\u200b\u4e3a\u200b\u6210\u5458\u200b\u7ba1\u7406\u200b\u5176\u200b\u5b9e\u9a8c\u200b\u65e5\u5fd7\u200b\uff0c\u200b\u5177\u4f53\u200b\u7ec6\u8282\u200b\u53c2\u89c1\u200b <code>Agent\u200b\u4e0e\u200b\u53ef\u7528\u200b\u5de5\u5177\u200b</code></p>"},{"location":"function_modules/experiment_log/personal_experiment/retrieve/","title":"\u4e2a\u4eba\u200b\u5b9e\u9a8c\u200b\u65e5\u5fd7\u200b\u68c0\u7d22","text":"<p>\u200b\u5b9e\u9a8c\u200b\u65e5\u5fd7\u200b\u4e0e\u200b\u65f6\u95f4\u200b\u6709\u5173\u200b\uff0c\u200b\u56e0\u6b64\u200bLabridge\u200b\u6839\u636e\u200b\u5b9e\u9a8c\u200b\u65e5\u5fd7\u200b\u7684\u200b\u5b58\u50a8\u200b\u7ed3\u6784\u200b\u91c7\u7528\u200b\u591a\u7ea7\u200b\u68c0\u7d22\u200b + \u200b\u65f6\u95f4\u200b\u6233\u200b\u8fc7\u6ee4\u200b\u7684\u200b\u68c0\u7d22\u200b\u65b9\u5f0f\u200b</p> <p></p>"},{"location":"function_modules/experiment_log/personal_experiment/retrieve/#_2","title":"\u7b2c\u4e00\u6b65\u200b\u68c0\u7d22","text":"<p>\u200b\u5728\u200b\u7b2c\u4e00\u6b65\u200b\u68c0\u7d22\u200b\u4e2d\u200b\uff0cLabridge\u200b\u6839\u636e\u200bQuery\u200b\u5411\u91cf\u200b\u4e0e\u200b\u6240\u6709\u200b\u5b9e\u9a8c\u200b\u8282\u70b9\u200b\u7684\u200b\u5b9e\u9a8c\u200b\u63cf\u8ff0\u200b\u4e4b\u95f4\u200b\u7684\u200b\u76f8\u4f3c\u6027\u200b\uff0c\u200b\u68c0\u7d22\u200b\u51fa\u200b\u6700\u200b\u6709\u200b\u53ef\u80fd\u200b\u7684\u200b <code>experiment_top_k</code> \u200b\u4e2a\u200b\u5b9e\u9a8c\u200b\u3002 \u200b\u540c\u65f6\u200b\uff0cLabridge\u200b\u5728\u200b\u6240\u6709\u200b\u7684\u200b\u65e5\u5fd7\u200b\u7c7b\u578b\u200b\u7684\u200b\u8282\u70b9\u200b\u4e2d\u200b\uff0c\u200b\u6839\u636e\u200b\u76f8\u4f3c\u6027\u200b\u68c0\u7d22\u200b\u51fa\u200b\u6700\u200b\u76f8\u4f3c\u200b\u7684\u200b <code>first_top_k</code> \u200b\u65e5\u5fd7\u200b\u8282\u70b9\u200b\uff0c\u200b\u5e76\u200b\u83b7\u53d6\u200b\u5b83\u4eec\u200b\u5bf9\u5e94\u200b\u7684\u200b\u5b9e\u9a8c\u200b\u8282\u70b9\u200b\u3002</p> <p>\u200b\u8fd9\u4e9b\u200b\u68c0\u7d22\u200b\u6240\u5f97\u200b\u7684\u200b\u5b9e\u9a8c\u200b\u8282\u70b9\u200b\u5c06\u200b\u4f5c\u4e3a\u200b\u4e0b\u200b\u4e00\u6b65\u200b\u68c0\u7d22\u200b\u7684\u200b\u8303\u56f4\u200b\u3002</p>"},{"location":"function_modules/experiment_log/personal_experiment/retrieve/#_3","title":"\u7b2c\u4e8c\u6b65\u200b\u68c0\u7d22","text":"<p>\u200b\u5728\u200b\u7b2c\u4e00\u6b65\u200b\u68c0\u7d22\u200b\u6240\u5f97\u200b\u7684\u200b\u5b9e\u9a8c\u200b\u8282\u70b9\u200b\u8303\u56f4\u200b\u5185\u200b\uff0cLabridge\u200b\u5728\u200b\u8fd9\u4e9b\u200b\u5b9e\u9a8c\u200b\u8282\u70b9\u200b\u7684\u200b\u65e5\u5fd7\u200b\u8282\u70b9\u200b\u4e2d\u200b\u68c0\u7d22\u200b\u51fa\u200b <code>second_top_k</code> \u200b\u4e2a\u200b\u65e5\u5fd7\u200b\u8282\u70b9\u200b\uff0c\u200b\u4f5c\u4e3a\u200b\u68c0\u7d22\u200b\u7ed3\u679c\u200b\u3002</p>"},{"location":"function_modules/experiment_log/personal_experiment/retrieve/#_4","title":"\u65f6\u95f4\u200b\u6233\u200b\u8fc7\u6ee4","text":"<p>\u200b\u5728\u200b\u7b2c\u4e8c\u6b65\u200b\u68c0\u7d22\u200b\u4e2d\u200b\uff0cLabridge\u200b\u4f1a\u200b\u6839\u636e\u200b\u8f93\u5165\u200b\u7684\u200b\u8d77\u6b62\u200b\u65f6\u95f4\u200b\uff08\u200b\u5982\u679c\u200b\u63d0\u4f9b\u200b\u4e86\u200b\uff09\u200b\u8fdb\u884c\u200b\u65f6\u95f4\u200b\u6233\u200b\u8fc7\u6ee4\u200b\u3002\u200b\u6700\u7ec8\u200b\u68c0\u7d22\u200b\u51fa\u200b\u7684\u200b\u5b9e\u9a8c\u200b\u65e5\u5fd7\u200b\u5185\u5bb9\u200b\u5c06\u200b\u63d0\u4f9b\u200b\u7ed9\u200b LLM \u200b\u4f5c\u4e3a\u200b\u8f93\u5165\u200b\u3002</p> <p>\u200b\u5173\u4e8e\u200b\u4e2a\u4eba\u200b\u5b9e\u9a8c\u200b\u65e5\u5fd7\u200b\u68c0\u7d22\u200b\u7684\u200b\u5177\u4f53\u200b\u7ec6\u8282\u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Func_modules.memory.experiment.retrieve_log</code></p>"},{"location":"function_modules/experiment_log/personal_experiment/store/","title":"\u4e2a\u4eba\u200b\u5b9e\u9a8c\u200b\u65e5\u5fd7\u200b\u5b58\u50a8\u200b\u7ed3\u6784","text":"<p>\u200b\u5b9e\u9a8c\u200b\u65e5\u5fd7\u200b\u5b58\u50a8\u200b\u4e8e\u200b\u4e00\u4e2a\u200b\u5411\u91cf\u200b\u6570\u636e\u5e93\u200b\u4e2d\u200b\uff0c\u200b\u7ed3\u6784\u200b\u5982\u4e0b\u200b\u56fe\u200b\u6240\u793a\u200b\u3002</p> <p></p> <ul> <li>\u200b\u6570\u636e\u5e93\u200b\u4e2d\u200b\u5b58\u5728\u200b\u4e00\u4e2a\u200b\u6839\u200b\u8282\u70b9\u200b\uff0c\u200b\u6240\u6709\u200b\u7684\u200b\u5b9e\u9a8c\u200b\u8282\u70b9\u200b\u662f\u200b\u8be5\u200b\u6839\u200b\u8282\u70b9\u200b\u7684\u200b\u5b50\u200b\u8282\u70b9\u200b\u3002</li> <li> <p>\u200b\u6bcf\u4e2a\u200b\u5b9e\u9a8c\u200b\u8282\u70b9\u200b\u5305\u542b\u200b\u5982\u4e0b\u200b\u4fe1\u606f\u200b\uff1a</p> </li> <li> <p>\u200b\u5b9e\u9a8c\u200b\u540d\u79f0\u200b</p> </li> <li>\u200b\u5b9e\u9a8c\u200b\u63cf\u8ff0\u200b</li> <li>\u200b\u5b9e\u9a8c\u200b\u76f8\u5173\u200b\u7684\u200b\u4eea\u5668\u8bbe\u5907\u200b</li> <li>\u200b\u672c\u200b\u5b9e\u9a8c\u200b\u8bb0\u5f55\u200b\u521b\u5efa\u200b\u7684\u200b\u65f6\u95f4\u200b</li> <li>\u200b\u5bf9\u4e8e\u200b\u6bcf\u4e2a\u200b\u5b9e\u9a8c\u200b\uff0c\u200b\u5b9e\u9a8c\u200b\u65e5\u5fd7\u200b\u88ab\u200b\u8bb0\u5f55\u200b\u4e3a\u200b\u5b9e\u9a8c\u200b\u8282\u70b9\u200b\u7684\u200b\u5b50\u200b\u8282\u70b9\u200b\uff0c\u200b\u65e5\u5fd7\u200b\u8282\u70b9\u200b\u95f4\u200b\u6309\u200b\u65f6\u95f4\u200b\u987a\u5e8f\u200b\u5f62\u6210\u200b\u7c7b\u4f3c\u200b\u53cc\u5411\u200b\u94fe\u8868\u200b\u7684\u200b\u7ed3\u6784\u200b\u3002</li> <li> <p>\u200b\u65e5\u5fd7\u200b\u8282\u70b9\u200b\u5305\u542b\u200b\u5982\u4e0b\u200b\u4fe1\u606f\u200b\uff1a</p> </li> <li> <p>\u200b\u5b9e\u9a8c\u200b\u7ed3\u679c\u200b</p> </li> <li>\u200b\u8bb0\u5f55\u65f6\u95f4\u200b</li> </ul> <p>\u200b\u5f53\u200b\u5b9e\u9a8c\u5ba4\u200b\u6210\u5458\u200b\u8981\u6c42\u200bLabridge\u200b\u5e2e\u52a9\u200b\u8bb0\u5f55\u200b\u5b9e\u9a8c\u200b\u7ed3\u679c\u200b\u65f6\u200b\uff0cLabridge\u200b\u4f1a\u200b\u5c06\u200b\u8be5\u200b\u5b9e\u9a8c\u200b\u7ed3\u679c\u200b\u8bb0\u5f55\u200b\u8fdb\u5176\u200b\u5b9e\u9a8c\u200b\u65e5\u5fd7\u200b\u6570\u636e\u5e93\u200b\u4e2d\u200b\u7684\u200b\u5bf9\u5e94\u200b\u5b9e\u9a8c\u200b\u8bb0\u5f55\u200b\u4e2d\u200b\u3002</p> <p>\u200b\u66f4\u200b\u591a\u200b\u6709\u5173\u200b\u4e2a\u4eba\u200b\u5b9e\u9a8c\u200b\u65e5\u5fd7\u200b\u5b58\u50a8\u200b\u7ed3\u6784\u200b\u7684\u200b\u7ec6\u8282\u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Func_modules.memory.experiment.experiment_log</code></p>"},{"location":"function_modules/experiment_log/shared_experiment/","title":"\u5171\u4eab\u200b\u5b9e\u9a8c\u200b\u65e5\u5fd7","text":""},{"location":"function_modules/experiment_log/shared_experiment/#to-be-continued","title":"TO BE CONTINUED ...","text":""},{"location":"function_modules/instrument/","title":"\u5b9e\u9a8c\u200b\u4eea\u5668\u200b\u4fe1\u606f","text":""},{"location":"function_modules/instrument/#_2","title":"\u201c\u200b\u541b\u5b50\u200b\u5584\u5047\u200b\u4e8e\u7269\u200b\u4e5f\u200b\u201d","text":"<p>\u200b\u5b9e\u9a8c\u200b\u4eea\u5668\u200b\u662f\u200b\u7814\u7a76\u8005\u200b\u63a2\u7d22\u200b\u53d1\u73b0\u200b\u7684\u200b\u5de5\u5177\u200b\uff0c\u200b\u5de5\u4e8e\u200b\u5584\u200b\u5176\u4e8b\u200b\uff0c\u200b\u5fc5\u5148\u5229\u5176\u5668\u200b\u3002\u200b\u7814\u7a76\u8005\u200b\u5e94\u8be5\u200b\u5bf9\u200b\u6bcf\u4e2a\u200b\u4eea\u5668\u200b\u7684\u200b\u4fe1\u606f\u200b\u4e86\u5982\u6307\u638c\u200b\uff0c\u200b\u624d\u80fd\u200b\u514b\u670d\u200b\u5b9e\u9a8c\u200b\u8fc7\u7a0b\u200b\u4e2d\u200b\u7684\u200b\u56f0\u96be\u200b\uff0c\u200b\u83b7\u5f97\u200b\u53ef\u4fe1\u200b\u7684\u200b\u7ed3\u679c\u200b\u3002</p> <p>Labridge\u200b\u6574\u5408\u200b\u5b9e\u9a8c\u5ba4\u200b\u7684\u200b\u6240\u6709\u200b\u79d1\u5b66\u200b\u4eea\u5668\u8bbe\u5907\u200b\u7684\u200b\u4f7f\u7528\u200b\u89c4\u8303\u200b\u3001\u200b\u4f7f\u7528\u624b\u518c\u200b\u3001\u200b\u6ce8\u610f\u4e8b\u9879\u200b\uff0c\u200b\u534f\u52a9\u200b\u5b9e\u9a8c\u5ba4\u200b\u6210\u5458\u200b\u4eec\u200b\u4e86\u89e3\u200b\u5b9e\u9a8c\u200b\u4eea\u5668\u200b\u7684\u200b\u4f7f\u7528\u200b\u3001\u200b\u534f\u52a9\u200b\u8fdb\u884c\u200b\u4eea\u5668\u200b\u7ba1\u7406\u200b\u3001\u200b\u7b80\u5316\u200b\u5b9e\u9a8c\u200b\u64cd\u4f5c\u200b\u57f9\u8bad\u200b\u3002</p>"},{"location":"function_modules/instrument/#_3","title":"\u5b9e\u9a8c\u5ba4\u200b\u4eea\u5668\u200b\u4fe1\u606f\u5e93","text":"<p>Labridge\u200b\u5c06\u200b\u5b9e\u9a8c\u5ba4\u200b\u6240\u6709\u200b\u4eea\u5668\u200b\u7684\u200b\u76f8\u5173\u200b\u4fe1\u606f\u200b\u6574\u5408\u200b\u4e3a\u200b\u4eea\u5668\u200b\u4fe1\u606f\u5e93\u200b\uff0c\u200b\u81f4\u529b\u4e8e\u200b\u51cf\u5c11\u200b\u6210\u5458\u200b\u5728\u200b\u5b9e\u9a8c\u200b\u4eea\u5668\u200b\u65b9\u9762\u200b\u7684\u200b\u5b66\u4e60\u200b\u3001\u200b\u64cd\u4f5c\u200b\u6210\u672c\u200b\u3002</p>"},{"location":"function_modules/instrument/#_4","title":"\u5b9e\u9a8c\u200b\u4eea\u5668\u200b\u4fe1\u606f\u68c0\u7d22","text":"<p>Labridge\u200b\u5728\u200b\u4eea\u5668\u200b\u4fe1\u606f\u5e93\u200b\u7684\u200b\u5185\u5bb9\u200b\u4e2d\u200b\u8fdb\u884c\u200b\u68c0\u7d22\u200b\uff0c\u200b\u4ee5\u200b\u56de\u7b54\u200b\u5b9e\u9a8c\u5ba4\u200b\u6210\u5458\u200b\u5173\u4e8e\u200b\u4eea\u5668\u200b\u7684\u200b\u95ee\u9898\u200b\uff0c\u200b\u5e76\u200b\u7ed9\u51fa\u200b\u76f8\u5e94\u200b\u4eea\u5668\u200b\u7684\u200b Super Users\u3002</p>"},{"location":"function_modules/instrument/#_5","title":"\u5b9e\u9a8c\u200b\u4eea\u5668\u200b\u7ba1\u7406","text":"<p>Labridge\u200b\u901a\u8fc7\u200b\u8c03\u7528\u200b\u5de5\u5177\u200b(Tools)\u200b\u4e3a\u200b\u6210\u5458\u200b\u7ba1\u7406\u200b\u5176\u200b\u5b9e\u9a8c\u200b\u65e5\u5fd7\u200b\uff0c\u200b\u5177\u4f53\u200b\u7ec6\u8282\u200b\u53c2\u89c1\u200b <code>Agent\u200b\u4e0e\u200b\u53ef\u7528\u200b\u5de5\u5177\u200b</code></p>"},{"location":"function_modules/instrument/retrieve/","title":"\u4eea\u5668\u200b\u4fe1\u606f\u68c0\u7d22","text":"<p>Labridge\u200b\u4f7f\u7528\u200b\u591a\u7ea7\u200b\u68c0\u7d22\u200b\u7684\u200b\u65b9\u5f0f\u200b\u68c0\u7d22\u200b\u76f8\u5173\u200b\u4eea\u5668\u200b\u4fe1\u606f\u200b</p> <p></p>"},{"location":"function_modules/instrument/retrieve/#_2","title":"\u7b2c\u4e00\u6b65\u200b\u68c0\u7d22","text":"<p>\u200b\u5728\u200b\u7b2c\u4e00\u6b65\u200b\u68c0\u7d22\u200b\u4e2d\u200b\uff0cLabridge\u200b\u4f7f\u7528\u200b LLM \u200b\u5bf9\u200bQuery\u200b\u6587\u672c\u200b\u4e0e\u200b\u5404\u200b\u5b9e\u9a8c\u200b\u4eea\u5668\u200b\u4e4b\u95f4\u200b\u7684\u200b\u76f8\u5173\u6027\u200b\uff08\u200b\u4f9d\u636e\u200b\u4eea\u5668\u200b\u63cf\u8ff0\u200b\uff09\u200b\u8fdb\u884c\u200b\u6253\u5206\u200b\uff0c\u200b\u7b5b\u9009\u200b\u51fa\u200b\u6700\u200b\u76f8\u5173\u200b\u7684\u200b <code>instrument_top_k</code> \u200b\u4e2a\u200b\u4eea\u5668\u200b\u3002</p>"},{"location":"function_modules/instrument/retrieve/#_3","title":"\u7b2c\u4e8c\u6b65\u200b\u68c0\u7d22\u200b\uff1a","text":"<p>\u200b\u5c06\u200b\u68c0\u7d22\u200b\u8303\u56f4\u200b\u9650\u5b9a\u200b\u4e3a\u200b\u7b2c\u4e00\u6b65\u200b\u68c0\u7d22\u200b\u6240\u5f97\u200b\u7684\u200b\u4eea\u5668\u200b\uff0c\u200b\u5728\u200b\u8fd9\u4e9b\u200b\u4eea\u5668\u200b\u7684\u200b\u4fe1\u606f\u200b\u4e2d\u200b\u8fdb\u884c\u200b\u76f8\u4f3c\u6027\u200b\u68c0\u7d22\u200b\uff0c\u200b\u5f97\u5230\u200b\u4e0e\u200bQuery\u200b\u5411\u91cf\u200b\u6700\u200b\u76f8\u5173\u200b\u7684\u200b <code>top_k</code> \u200b\u6761\u200b\u4fe1\u606f\u200b\u3002 \u200b\u8fd9\u4e9b\u200b\u4fe1\u606f\u200b\u4f5c\u4e3a\u200b\u68c0\u7d22\u200b\u7ed3\u679c\u200b\u63d0\u4f9b\u200b\u7ed9\u200b LLM \u200b\u4f5c\u4e3a\u200b\u53c2\u8003\u200b\u4fe1\u606f\u200b\u3002</p> <p>\u200b\u5173\u4e8e\u200b\u4eea\u5668\u200b\u4fe1\u606f\u68c0\u7d22\u200b\u7684\u200b\u7ec6\u8282\u200b\uff0c\u200b\u8bf7\u200b\u53c2\u8003\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Func_modules.instrument.retrieve.instrument_retrieve</code></p>"},{"location":"function_modules/instrument/store/","title":"\u4eea\u5668\u200b\u4fe1\u606f\u200b\u5b58\u50a8\u200b\u7ed3\u6784","text":"<p>\u200b\u5b9e\u9a8c\u200b\u4eea\u5668\u200b\u4fe1\u606f\u200b\u5b58\u50a8\u200b\u4e8e\u200b\u4e00\u4e2a\u200b\u5411\u91cf\u200b\u6570\u636e\u5e93\u200b\u4e2d\u200b, \u200b\u5176\u200b\u7ed3\u6784\u200b\u5982\u4e0b\u200b\u56fe\u200b\u6240\u793a\u200b\u3002</p> <p></p> <ul> <li>\u200b\u6570\u636e\u5e93\u200b\u4e2d\u200b\u5b58\u5728\u200b\u4e00\u4e2a\u200b\u6839\u200b\u8282\u70b9\u200b\uff0c\u200b\u6240\u6709\u200b\u7684\u200b\u4eea\u5668\u200b\u8282\u70b9\u200b\u662f\u200b\u8be5\u200b\u6839\u200b\u8282\u70b9\u200b\u7684\u200b\u5b50\u200b\u8282\u70b9\u200b\u3002</li> <li> <p>\u200b\u6bcf\u4e2a\u200b\u4eea\u5668\u200b\u8282\u70b9\u200b\u5305\u542b\u200b\u5982\u4e0b\u200b\u4fe1\u606f\u200b\uff1a</p> </li> <li> <p>\u200b\u4eea\u5668\u200b\u540d\u79f0\u200b</p> </li> <li>\u200b\u4eea\u5668\u200b\u63cf\u8ff0\u200b</li> <li>Super Users (\u200b\u8d1f\u8d23\u7ba1\u7406\u200b\u4eea\u5668\u200b\u4fe1\u606f\u200b\u3001\u200b\u5bf9\u200b\u4eea\u5668\u200b\u5177\u6709\u200b\u5b8c\u5168\u200b\u6743\u9650\u200b\u7684\u200b\u5b9e\u9a8c\u5ba4\u200b\u6210\u5458\u200b)</li> <li>\u200b\u5bf9\u4e8e\u200b\u6bcf\u4e2a\u200b\u4eea\u5668\u200b\uff0c\u200b\u4eea\u5668\u200b\u4fe1\u606f\u200b\u88ab\u200b\u8bb0\u5f55\u200b\u4e3a\u200b\u4eea\u5668\u200b\u8282\u70b9\u200b\u7684\u200b\u5b50\u200b\u8282\u70b9\u200b\uff0c\u200b\u5982\u200b\u4f7f\u7528\u200b\u89c4\u8303\u200b\uff0c\u200b\u64cd\u4f5c\u624b\u518c\u200b\uff0c\u200b\u4eea\u5668\u200b\u53c2\u6570\u200b\u7b49\u200b\u3002</li> </ul> <p>\u200b\u66f4\u200b\u591a\u200b\u5173\u4e8e\u200b\u4eea\u5668\u200b\u4fe1\u606f\u200b\u5b58\u50a8\u200b\u7ed3\u6784\u200b\u7684\u200b\u7ec6\u8282\u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Func_modules.instrument.store.instrument_store</code></p>"},{"location":"function_modules/paper/","title":"\u6587\u732e\u200b\u7ba1\u7406","text":""},{"location":"function_modules/paper/#_2","title":"\u201c\u200b\u5728\u200b\u77e5\u8bc6\u200b\u7684\u200b\u6d41\u52a8\u200b\u4e2d\u200b\u50ac\u5316\u200b\u65b0\u200b\u77e5\u8bc6\u200b\u7684\u200b\u8bde\u751f\u200b\u201d","text":"<p>\u200b\u4e00\u4e2a\u200b\u4f18\u79c0\u200b\u7684\u200b\u7814\u7a76\u8005\u200b\u5e94\u8be5\u200b\u8ffd\u8e2a\u200b\u7814\u7a76\u200b\u9886\u57df\u200b\u5185\u200b\u7684\u200b\u6700\u65b0\u200b\u7814\u7a76\u6210\u679c\u200b\uff0c\u200b\u540c\u65f6\u200b\u4fdd\u6301\u200b\u5bf9\u200b\u65b0\u200b\u9886\u57df\u200b\u7684\u200b\u597d\u5947\u200b\u4e0e\u200b\u5f00\u653e\u200b\uff0c\u200b\u56e0\u4e3a\u200b\u8bb8\u591a\u200b\u4f1f\u5927\u200b\u7684\u200b\u79d1\u5b66\u200b\u6210\u5c31\u200b\u5f80\u5f80\u200b\u6765\u81ea\u200b\u4e8e\u200b\u4e0d\u540c\u200b\u9886\u57df\u200b\u95f4\u200b\u7684\u200b\u601d\u7ef4\u200b\u78b0\u649e\u200b\u3002</p> <p>\u200b\u56e0\u6b64\u200b\u6587\u732e\u200b\u7ba1\u7406\u200b\u662f\u200b\u4e00\u4e2a\u200b\u79d1\u5b66\u200b\u5b9e\u9a8c\u5ba4\u200b\u81f3\u5173\u91cd\u8981\u200b\u7684\u200b\u90e8\u5206\u200b\u4e4b\u4e00\u200b\u3002\u200b\u6211\u4eec\u200b\u5e0c\u671b\u200bLabridge\u200b\u80fd\u591f\u200b\u5e2e\u52a9\u200b\u7814\u7a76\u8005\u200b\u4eec\u200b\u7ba1\u7406\u200b\u8fd9\u4e9b\u200b\u5b9d\u8d35\u200b\u7684\u200b\u77e5\u8bc6\u200b\u8d22\u5bcc\u200b\uff0c\u200b\u5e76\u200b\u6784\u5efa\u200b\u5b9e\u9a8c\u5ba4\u200b\u7684\u200b\u5171\u4eab\u200b\u6587\u732e\u200b\u77e5\u8bc6\u5e93\u200b\uff0c \u200b\u4e3a\u200b\u5b9e\u9a8c\u5ba4\u200b\u6210\u5458\u200b\u4e4b\u95f4\u200b\u7684\u200b\u79d1\u7814\u200b\u4ea4\u6d41\u200b\u4e0e\u200b\u5408\u4f5c\u200b\u63d0\u4f9b\u200b\u5e73\u53f0\u200b\u3002</p> <p></p> <p>Labridge\u200b\u901a\u8fc7\u200b\u5982\u4e0b\u200b\u65b9\u5f0f\u200b\u4fc3\u8fdb\u200b\u6587\u732e\u200b\u77e5\u8bc6\u200b\u7684\u200b\u6d41\u52a8\u200b\u4e0e\u200b\u77e5\u8bc6\u200b\u7684\u200b\u4ea4\u53c9\u200b\u878d\u5408\u200b\uff1a</p>"},{"location":"function_modules/paper/#_3","title":"\u5b9e\u9a8c\u5ba4\u200b\u5171\u4eab\u200b\u6587\u732e\u200b\u5e93\u200b\uff1a","text":"<p>Labridge\u200b\u6536\u96c6\u200b\u5b9e\u9a8c\u5ba4\u200b\u6240\u6709\u200b\u6210\u5458\u200b\u7684\u200b\u6587\u732e\u200b\u6784\u6210\u200b\u5171\u4eab\u200b\u77e5\u8bc6\u5e93\u200b\u3002Labridge\u200b\u4f1a\u200b\u4f9d\u636e\u200b\u5171\u4eab\u200b\u77e5\u8bc6\u5e93\u200b\u7684\u200b\u5185\u5bb9\u200b\u56de\u7b54\u200b\u5b9e\u9a8c\u5ba4\u200b\u6210\u5458\u200b\u7684\u200b\u76f8\u5173\u200b\u95ee\u9898\u200b\uff0c \u200b\u5e76\u200b\u63d0\u4f9b\u200b\u53c2\u8003\u200b\u5185\u5bb9\u200b\u7684\u200b\u6765\u6e90\u200b\uff08\u200b\u5982\u200b\u8fd9\u7bc7\u200b\u6587\u732e\u200b\u6765\u81ea\u200b\u4e8e\u200b\u6210\u5458\u200bXXX\uff09\u3002\u200b\u8ba9\u200b\u77e5\u8bc6\u200b\u7684\u200b\u6d41\u52a8\u200b\u4e0d\u200b\u53d7\u200b\u65f6\u95f4\u200b\u4e0e\u200b\u7a7a\u95f4\u200b\u7684\u200b\u9650\u5236\u200b\u3002</p>"},{"location":"function_modules/paper/#_4","title":"\u4e2a\u4eba\u200b\u8fd1\u671f\u200b\u6587\u732e\u200b\uff1a","text":"<p>Labridge\u200b\u4e3a\u200b\u6bcf\u4f4d\u200b\u5b9e\u9a8c\u200b\u6210\u5458\u200b\u63d0\u4f9b\u200b\u4e2a\u4eba\u200b\u7684\u200b\u8fd1\u671f\u200b\u6587\u732e\u200b\u5e93\u200b\uff0c\u200b\u4ee5\u200b\u8bb0\u5f55\u200b\u8be5\u200b\u6210\u5458\u200b\u8fd1\u671f\u200b\u901a\u8fc7\u200bLabridge\u200b\u4ece\u200b\u671f\u520a\u200b\u7f51\u7ad9\u200b\u4e0b\u8f7d\u200b\u3001\u200b\u5411\u200bLabridge\u200b\u4e0a\u4f20\u200b\u7684\u200b\u6587\u732e\u200b\u3002 Labridge\u200b\u57fa\u4e8e\u200b\u8fd1\u671f\u200b\u6587\u732e\u200b\u5e93\u200b\u534f\u52a9\u200b\u6bcf\u4f4d\u200b\u6210\u5458\u200b\u66f4\u597d\u200b\u5730\u200b\u7406\u89e3\u200bta\u200b\u6700\u8fd1\u200b\u611f\u5174\u8da3\u200b\u7684\u200b\u7814\u7a76\u200b\u5185\u5bb9\u200b\u3002\u200b\u5e76\u200b\u652f\u6301\u200b\u6210\u5458\u200b\u901a\u8fc7\u200b\u81ea\u7136\u8bed\u8a00\u200b\u7ba1\u7406\u200b\u4e2a\u4eba\u200b\u7684\u200b\u6587\u732e\u200b\u5e93\u200b\u3002</p>"},{"location":"function_modules/paper/#_5","title":"\u6587\u732e\u200b\u641c\u7d22\u200b\u4e0e\u200b\u4e0b\u8f7d\u200b\uff1a","text":"<p>Labridge\u200b\u63d0\u4f9b\u200b\u81ea\u7136\u8bed\u8a00\u200b\u4ea4\u4e92\u200b\u7684\u200b\u6587\u732e\u200b\u641c\u7d22\u200b\u4e0e\u200b\u4e0b\u8f7d\u5de5\u5177\u200b\uff0c\u200b\u8ba9\u200b\u7814\u7a76\u8005\u200b\u4fdd\u6301\u200b\u5bf9\u200b\u9886\u57df\u200b\u6700\u65b0\u200b\u7814\u7a76\u200b\u52a8\u6001\u200b\u7684\u200b\u8ffd\u8e2a\u200b\u3002 Labridge\u200b\u76ee\u524d\u200b\u652f\u6301\u200b\u5728\u200b\u5982\u4e0b\u200b\u671f\u520a\u200b\u7f51\u7ad9\u200b\u8fdb\u884c\u200b\u641c\u7d22\u200b\u4e0e\u200b\u4e0b\u8f7d\u200b\uff1a</p> <ul> <li>arXiv</li> </ul>"},{"location":"function_modules/paper/shared_papers/","title":"\u5171\u4eab\u200b\u6587\u732e\u200b\u77e5\u8bc6\u5e93","text":"<p>Labridge\u200b\u6536\u96c6\u200b\u5b9e\u9a8c\u5ba4\u200b\u6210\u5458\u200b\u7684\u200b\u6587\u732e\u200b\u6784\u6210\u200b\u5171\u4eab\u200b\u6587\u732e\u200b\u77e5\u8bc6\u5e93\u200b\u3002</p>"},{"location":"function_modules/paper/shared_papers/#_2","title":"\u5171\u4eab\u200b\u6587\u732e\u200b\u5e93\u200b\u6784\u5efa","text":"<p>\u200b\u5171\u4eab\u200b\u6587\u732e\u200b\u77e5\u8bc6\u5e93\u200b\u7684\u200b\u6784\u5efa\u200b\u5305\u62ec\u200b\u5982\u4e0b\u200b\u65b9\u9762\u200b\uff1a</p> <ul> <li>\u200b\u6587\u732e\u200b\u89e3\u6790\u200b\u4e0e\u200b\u4fe1\u606f\u63d0\u53d6\u200b\uff1a \u200b\u4e3a\u4e86\u200b\u4f7f\u200b\u6784\u5efa\u200b\u7684\u200b\u5171\u4eab\u200b\u6587\u732e\u200b\u77e5\u8bc6\u5e93\u200b\u652f\u6301\u200b\u66f4\u52a0\u200b\u7cbe\u51c6\u200b\u7684\u200b\u68c0\u7d22\u200b\uff0c\u200b\u6211\u4eec\u200b\u5bf9\u200b\u6536\u96c6\u200b\u7684\u200b\u6587\u732e\u200b\u6587\u4ef6\u200b\u8fdb\u884c\u200b\u7ec6\u81f4\u200b\u7684\u200b\u89e3\u6790\u200b\u4e0e\u200b\u5185\u5bb9\u200b\u63d0\u53d6\u200b\u3002</li> <li>\u200b\u6587\u732e\u6570\u636e\u5e93\u200b\u6784\u5efa\u200b\uff1a \u200b\u57fa\u4e8e\u200b\u63d0\u53d6\u200b\u51fa\u200b\u7684\u200b\u6587\u732e\u200b\u5185\u5bb9\u200b\u4e0e\u200b\u4fe1\u606f\u200b\uff0cLabridge\u200b\u6784\u5efa\u200b\u6587\u732e\u200b\u7684\u200bSummary\u200b\u5411\u91cf\u200b\u6570\u636e\u5e93\u200b\u4ee5\u53ca\u200b\u5185\u5bb9\u200b\u5411\u91cf\u200b\u6570\u636e\u5e93\u200b\u3002</li> </ul>"},{"location":"function_modules/paper/shared_papers/#_3","title":"\u5171\u4eab\u200b\u6587\u732e\u200b\u5e93\u200b\u68c0\u7d22","text":"<p>\u200b\u5728\u200b\u5171\u4eab\u200b\u6587\u732e\u200b\u5e93\u200b\u6784\u5efa\u200b\u5b8c\u6210\u200b\u540e\u200b\uff0cLabridge\u200b\u4f1a\u200b\u57fa\u4e8e\u200b\u8be5\u200b\u6587\u732e\u200b\u5e93\u200b\u68c0\u7d22\u200b\u6587\u732e\u200b\u5e76\u200b\u56de\u7b54\u200b\u5b9e\u9a8c\u5ba4\u200b\u6210\u5458\u200b\u7684\u200b\u95ee\u9898\u200b\u3002</p> <ul> <li>\u200b\u6587\u732e\u6570\u636e\u5e93\u200b\u68c0\u7d22\u200b:  Labridge\u200b\u91c7\u7528\u200b\u591a\u200b\u5c42\u7ea7\u200b\u3001\u200b\u6df7\u5408\u5f0f\u200b\u7684\u200b\u68c0\u7d22\u200b\u65b9\u5f0f\u200b\u4fdd\u8bc1\u200b\u68c0\u7d22\u200b\u7ed3\u679c\u200b\u7684\u200b\u51c6\u786e\u6027\u200b\u3002</li> </ul>"},{"location":"function_modules/paper/shared_papers/parse/","title":"\u6587\u732e\u200b\u5185\u5bb9\u200b\u89e3\u6790\u200b\u4e0e\u200b\u63d0\u53d6","text":"<p>\u200b\u4e3a\u4e86\u200b\u4f7f\u200b\u6784\u5efa\u200b\u7684\u200b\u5171\u4eab\u200b\u6587\u732e\u200b\u77e5\u8bc6\u5e93\u200b\u652f\u6301\u200b\u66f4\u52a0\u200b\u7cbe\u51c6\u200b\u7684\u200b\u68c0\u7d22\u200b\uff0c\u200b\u6211\u4eec\u200b\u5bf9\u200b\u6536\u96c6\u200b\u7684\u200b\u6587\u732e\u200b\u6587\u4ef6\u200b\u8fdb\u884c\u200b\u7ec6\u81f4\u200b\u7684\u200b\u89e3\u6790\u200b\u4e0e\u200b\u5185\u5bb9\u200b\u63d0\u53d6\u200b\u3002</p> <p></p>"},{"location":"function_modules/paper/shared_papers/parse/#_2","title":"\u6587\u732e\u200b\u6765\u6e90\u200b\u5206\u6790\u200b\uff1a","text":"<p>\u200b\u6211\u4eec\u200b\u901a\u8fc7\u200b \u200b\u7ed3\u6784\u5316\u200bPDF\u200b\u89e3\u6790\u200b\u3001\u200b\u5173\u952e\u5b57\u200b\u9891\u6b21\u200b\u5206\u6790\u200b\u3001LLM\u200b\u8f85\u52a9\u200b\u5206\u6790\u200b \u200b\u7b49\u200b\u591a\u79cd\u624b\u6bb5\u200b\u5bf9\u200b\u4e00\u7bc7\u200bPDF\u200b\u6587\u732e\u200b\u7684\u200b\u6765\u6e90\u200b\u8fdb\u884c\u200b\u5206\u6790\u200b\uff0c \u200b\u5982\u8be5\u200b\u6587\u732e\u200b\u6765\u81ea\u200b\u4e8e\u200b<code>Nature</code>\u3001<code>IEEE</code>\u200b\u7b49\u200b\u3002 \u200b\u5177\u4f53\u200b\u7684\u200b\u7ec6\u8282\u200b\u8bf7\u200b\u53c2\u8003\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b:<code>Fun_modules.paper.parse.extractors.source_analyze</code></p>"},{"location":"function_modules/paper/shared_papers/parse/#_3","title":"\u6587\u732e\u200b\u7ed3\u6784\u5316\u200b\u89e3\u6790\u200b\uff1a","text":"<p>\u200b\u6839\u636e\u200b\u5206\u6790\u200b\u51fa\u200b\u7684\u200b\u6587\u732e\u200b\u6765\u6e90\u200b\uff0c\u200b\u6211\u4eec\u200b\u4f7f\u7528\u200b\u76f8\u5e94\u200b\u7684\u200b\u89e3\u6790\u200b\u6a21\u677f\u200b\u5bf9\u200b\u6587\u732e\u200b\u8fdb\u884c\u200b\u89e3\u6790\u200b\uff0c\u200b\u5982\u200b\u5c06\u200b\u5176\u200b\u5185\u5bb9\u200b\u4e2d\u200b\u7684\u200b  <code>Abstract</code>, <code>MainText</code>, <code>Methods</code>, <code>References</code> \u200b\u7b49\u200b\u63d0\u53d6\u200b\u51fa\u6765\u200b\uff0c\u200b\u4ee5\u200b\u652f\u6301\u200b\u66f4\u200b\u7cbe\u51c6\u200b\u7684\u200b\u6587\u732e\u200b\u5e93\u200b\u68c0\u7d22\u200b\u3002 Labridge\u200b\u76ee\u524d\u200b\u652f\u6301\u200b\u7684\u200b\u89e3\u6790\u200b\u6a21\u677f\u200b\u5305\u62ec\u200b\uff1a   - Nature Parser: \u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Fun_modules.paper.parse.parsers.nature_parser</code>   - IEEE Parser: \u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Fun_modules.paper.parse.parsers.ieee_parser</code></p>"},{"location":"function_modules/paper/shared_papers/parse/#metadata","title":"Metadata\u200b\u63d0\u53d6\u200b\uff1a","text":"<p>Labridge\u200b\u5229\u7528\u200b LLM \u200b\u5bf9\u200b\u6587\u732e\u200b\u7684\u200bMetadata\u200b\u8fdb\u884c\u200b\u63d0\u53d6\u200b\uff0c\u200b\u5982\u200b \u200b\u6587\u7ae0\u200b\u6807\u9898\u200b\u3001\u200b\u6587\u7ae0\u200b\u5173\u952e\u8bcd\u200b\u3001\u200b\u4f5c\u8005\u200b\u4fe1\u606f\u200b\u3001\u200b\u4f5c\u8005\u200b\u5355\u4f4d\u200b\u3001\u200b\u53d1\u8868\u200b\u65f6\u95f4\u200b \u200b\u7b49\u200b\u3002 Labridge\u200b\u4ece\u200b\u671f\u520a\u200b\u7f51\u7ad9\u200b\u4e0a\u200b\u4e0b\u8f7d\u200b\u7684\u200b\u6587\u732e\u200b\u5f80\u5f80\u200b\u5df2\u7ecf\u200b\u5305\u542b\u200b\u4e86\u200b\u5145\u5206\u200b\u7684\u200bMetadata,\u200b\u5bf9\u4e8e\u200b\u8fd9\u200b\u7c7b\u200b\u6587\u732e\u200b\uff0c\u200b\u5728\u200b\u672c\u200b\u73af\u8282\u200b\u4f1a\u200b\u5bf9\u200b\u5176\u4e2d\u200b\u672a\u200b\u63d0\u4f9b\u200b\u7684\u200bMetdata\u200b\u8fdb\u884c\u200b\u8865\u5145\u200b\u3002 \u200b\u5177\u4f53\u200b\u7ec6\u8282\u200b\u53c2\u89c1\u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Fun_modules.paper.parse.extractors.metadata_extract</code></p> Metadata\u200b\u63d0\u53d6\u200b\u793a\u4f8b"},{"location":"function_modules/paper/shared_papers/retrieve/","title":"\u5171\u4eab\u200b\u6587\u732e\u200b\u5e93\u200b\u68c0\u7d22","text":"<p>Labridge\u200b\u5c06\u200b\u5728\u200b\u6784\u5efa\u200b\u597d\u200b\u7684\u200b\u5171\u4eab\u200b\u6587\u732e\u200b\u5e93\u4e2d\u200b\u8fdb\u884c\u200b\u68c0\u7d22\u200b\uff0c\u200b\u4ee5\u200b\u83b7\u5f97\u200b\u89e3\u51b3\u95ee\u9898\u200b\u6240\u200b\u9700\u8981\u200b\u7684\u200b\u4fe1\u606f\u200b\u3002</p> <p>\u200b\u6211\u4eec\u200b\u4f7f\u7528\u200b\u4e86\u200b\u591a\u200b\u5c42\u7ea7\u200b\u3001\u200b\u6df7\u5408\u5f0f\u200b\u7684\u200b\u68c0\u7d22\u200b\u65b9\u5f0f\u200b\u6765\u200b\u63d0\u9ad8\u200b\u68c0\u7d22\u200b\u7ed3\u679c\u200b\u7684\u200b\u51c6\u786e\u6027\u200b\u3002\u200b\u5177\u4f53\u200b\u7684\u200b\u7ec6\u8282\u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Fun_modules.paper.retrieve.shared_paper_retrieve</code></p> <p></p>"},{"location":"function_modules/paper/shared_papers/retrieve/#_2","title":"\u7b2c\u4e00\u6b65\u200b\u68c0\u7d22\u200b\uff1a","text":"<p>\u200b\u5728\u200b\u7b2c\u4e00\u6b65\u200b\u68c0\u7d22\u200b\u4e2d\u200b\uff0c\u200b\u6211\u4eec\u200b\u5728\u200b\u5171\u4eab\u200b\u6587\u732e\u200b\u5e93\u4e2d\u200b\u7684\u200b\u5185\u5bb9\u200b\u5411\u91cf\u200b\u6570\u636e\u5e93\u200b\u4e2d\u200b\u641c\u7d22\u200b\u4e0e\u200b\u95ee\u9898\u200b\u5411\u91cf\u200b\u6700\u200b\u76f8\u4f3c\u200b\u7684\u200b<code>vector_similarity_top_k</code>\u200b\u4e2a\u200b\u6587\u672c\u200b\u5757\u200b\uff0c\u200b\u5e76\u200b\u83b7\u53d6\u200b\u5b83\u4eec\u200b\u6240\u5c5e\u200b\u7684\u200b\u6587\u732e\u200b\u8282\u70b9\u200b\u3002 \u200b\u5982\u679c\u200b\u5236\u5b9a\u200b\u4e86\u200b\u7279\u5b9a\u200b\u7684\u200b <code>user_id</code>, \u200b\u5c06\u200b\u4ec5\u200b\u5728\u200b\u8be5\u200b\u7528\u6237\u200b\u7684\u200b\u6587\u732e\u200b\u4e2d\u200b\u8fdb\u884c\u200b\u68c0\u7d22\u200b\u3002</p>"},{"location":"function_modules/paper/shared_papers/retrieve/#_3","title":"\u7b2c\u4e8c\u6b65\u200b\u76f8\u5173\u6027\u200b\u5206\u6790\u200b\uff1a","text":"<p>\u200b\u5728\u200b\u7b2c\u4e00\u6b65\u200b\u68c0\u7d22\u200b\u51fa\u200b\u7684\u200b\u76f8\u5173\u200b\u6587\u732e\u200b\u7684\u200b\u8303\u56f4\u200b\u5185\u200b\uff0c\u200b\u6211\u4eec\u200b\u5c06\u200b\u4f7f\u7528\u200b LLM \u200b\u5bf9\u200b\u8fd9\u4e9b\u200b\u6587\u732e\u200b\u7684\u200bAbstract &amp; Summary\u200b\u548c\u200b\u95ee\u9898\u200b\u6587\u672c\u200b\u7684\u200b\u76f8\u5173\u6027\u200b\u8fdb\u884c\u200b\u6253\u5206\u200b\uff0c \u200b\u83b7\u53d6\u200b\u76f8\u5173\u6027\u200b\u5206\u6570\u200b\u6700\u9ad8\u200b\u7684\u200b <code>docs_top_k</code> \u200b\u4efd\u200b\u6587\u732e\u200b\u3002</p>"},{"location":"function_modules/paper/shared_papers/retrieve/#_4","title":"\u6700\u540e\u200b\u7684\u200b\u76f8\u4f3c\u6027\u200b\u68c0\u7d22\u200b\uff1a","text":"<p>\u200b\u5728\u200b\u7b2c\u4e8c\u6b65\u200b\u7b5b\u9009\u200b\u51fa\u200b\u7684\u200b\u6587\u732e\u200b\u8303\u56f4\u200b\u5185\u200b\uff0c\u200b\u6211\u4eec\u200b\u5728\u200b\u8fd9\u4e9b\u200b\u6587\u732e\u200b\u7684\u200b\u6587\u672c\u200b\u4e2d\u200b\u68c0\u7d22\u200b\u4e0e\u200b\u95ee\u9898\u200b\u5411\u91cf\u200b\u6700\u200b\u76f8\u4f3c\u200b\u7684\u200b <code>re_retrieve_top_k</code> \u200b\u4e2a\u200b\u6587\u672c\u200b\u5757\u200b\u3002 \u200b\u7531\u4e8e\u200b\u672c\u6b21\u200b\u68c0\u7d22\u200b\u662f\u200b\u6700\u7ec8\u200b\u7684\u200b\u7ec6\u7c92\u5ea6\u200b\u7684\u200b\u68c0\u7d22\u200b\uff0c\u200b\u56e0\u6b64\u200b\u672c\u6b21\u200b\u68c0\u7d22\u200b\u8fc7\u7a0b\u200b\u4e2d\u200b\uff0c\u200b\u63d0\u4f9b\u200b\u7ed9\u200bEmbedding\u200b\u6a21\u578b\u200b\u7684\u200b\u6587\u672c\u200b\u53ea\u6709\u200b\u6587\u732e\u200b\u6587\u672c\u200b\u5757\u200b\u672c\u8eab\u200b\u7684\u200b\u6587\u672c\u200b\uff0c\u200b\u4e0d\u200b\u5305\u542b\u200b\u4efb\u4f55\u200b\u989d\u5916\u200b\u7684\u200bMetadata\u3002</p>"},{"location":"function_modules/paper/shared_papers/retrieve/#_5","title":"\u6dfb\u52a0\u200b\u4e0a\u4e0b\u6587\u200b\u4e0e\u200b\u76f8\u5173\u200b\u603b\u7ed3\u200b\uff1a","text":"<p>\u200b\u5728\u200b\u6700\u540e\u200b\uff0c\u200b\u6211\u4eec\u200b\u53ef\u4ee5\u200b\u9009\u62e9\u200b\u4e3a\u200b\u68c0\u7d22\u200b\u51fa\u200b\u7684\u200b\u6587\u672c\u200b\u5757\u200b\u52a0\u4e0a\u200b\u5b83\u4eec\u200b\u7684\u200b\u4e0a\u4e0b\u6587\u200b\uff0c\u200b\u4ee5\u53ca\u200b\u5b83\u4eec\u200b\u6240\u5c5e\u200b\u6587\u732e\u200b\u7684\u200b\u603b\u7ed3\u200b\u3002\u200b\u5c06\u200b\u8fd9\u4e9b\u200b\u5185\u5bb9\u200b\u4f5c\u4e3a\u200b\u6700\u7ec8\u200b\u7684\u200b\u68c0\u7d22\u200b\u7ed3\u679c\u200b\u63d0\u4f9b\u200b\u7ed9\u200b LLM \u3002</p>"},{"location":"function_modules/paper/shared_papers/store/","title":"\u5171\u4eab\u200b\u6587\u732e\u200b\u5e93\u200b\u6784\u5efa","text":"<p>\u200b\u5171\u4eab\u200b\u6587\u732e\u200b\u5e93\u200b\u7684\u200b\u539f\u59cb\u200b\u6587\u4ef6\u200b\u5b58\u653e\u200b\u5728\u200b <code>documents/papers</code>\u200b\u8def\u5f84\u200b\u4e0b\u200b\u3002\u200b\u8be5\u200b\u6587\u732e\u200b\u4ed3\u5e93\u200b\u7684\u200b\u4e00\u7ea7\u200b\u5b50\u76ee\u5f55\u200b\u4e3a\u200b\u5b9e\u9a8c\u5ba4\u200b\u6210\u5458\u200b\u7684\u200b<code>user_id</code></p> <p>Labridge\u200b\u57fa\u4e8e\u200bParse\u200b\u83b7\u5f97\u200b\u7684\u200b\u6587\u732e\u200b\u5185\u5bb9\u200b\u4e0e\u200b\u4fe1\u606f\u200b\u6784\u5efa\u200b\u5145\u5206\u200b\u7fd4\u5b9e\u200b\u7684\u200b\u5171\u4eab\u200b\u6587\u732e\u200b\u5e93\u200b\uff0c\u200b\u4ee5\u200b\u652f\u6301\u200b\u591a\u79cd\u200b\u65b9\u5f0f\u200b\u7684\u200b\u68c0\u7d22\u200b\u3002</p>"},{"location":"function_modules/paper/shared_papers/store/#_2","title":"\u5171\u4eab\u200b\u6587\u732e\u200b\u5411\u91cf\u200b\u6570\u636e\u5e93\u200b\uff1a","text":"<p>Labridge\u200b\u4e3a\u200b\u6240\u6709\u200b\u7684\u200b\u5171\u4eab\u200b\u6587\u732e\u200b\u6784\u5efa\u200b\u5411\u91cf\u200b\u6570\u636e\u5e93\u200b(VectorIndex)\uff0c\u200b\u5e76\u200b\u8bb0\u5f55\u200b\u6bcf\u7bc7\u200b\u6587\u732e\u200b\u7684\u200bMetadata\uff0c\u200b\u4ee5\u53ca\u200b\u8be5\u200b\u6587\u732e\u200b\u7684\u200b\u6240\u6709\u8005\u200b\u3002 \u200b\u5185\u5bb9\u200b\u5411\u91cf\u200b\u6570\u636e\u5e93\u200b\u7684\u200b\u6784\u5efa\u200b\u53c2\u89c1\u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Func_modules.paper.store.shared_paper_store</code></p> <p>\u200b\u5171\u4eab\u200b\u6587\u732e\u200b\u5411\u91cf\u200b\u6570\u636e\u5e93\u200b\u7684\u200b\u7ed3\u6784\u200b\u5982\u4e0b\u200b\u56fe\u200b\u6240\u793a\u200b\u3002\u200b\u8be5\u200b\u6570\u636e\u5e93\u200b\u4e3a\u200b\u6811\u5f62\u200b\u7ed3\u6784\u200b\uff0c\u200b\u7b2c\u4e00\u5c42\u200b\u5b50\u200b\u8282\u70b9\u200b\u4e3a\u200b\u4e0d\u540c\u200b\u7684\u200b\u7528\u6237\u200b\uff0c\u200b\u6bcf\u4e2a\u200b\u7528\u6237\u200b\u8282\u70b9\u200b\u4e0b\u4f1a\u200b\u4f9d\u7167\u200b\u539f\u59cb\u200b\u6587\u732e\u200b\u5e93\u4e2d\u200b\u7684\u200b\u76ee\u5f55\u200b\u6811\u200b\u6784\u5efa\u200b\u76f8\u5e94\u200b\u7684\u200b \u200b\u76ee\u5f55\u200b\u8282\u70b9\u200b\u3002\u200b\u6587\u732e\u200b\u8282\u70b9\u200b\u8bb0\u5f55\u200b\u8be5\u200b\u6587\u732e\u200b\u539f\u59cb\u200b\u6587\u4ef6\u200b\u7684\u200b\u76f8\u5bf9\u8def\u5f84\u200b\uff0c\u200b\u4ee5\u53ca\u200b\u989d\u5916\u200b\u7684\u200bMetadata\u200b\u5982\u200b<code>Abstract</code>, <code>Summary</code>, <code>Authors</code>, <code>Title</code> \u200b\u7b49\u7b49\u200b\u3002 \u200b\u6700\u540e\u200b\u7684\u200b\u53f6\u5b50\u200b\u8282\u70b9\u200b\u4e3a\u200b\u6bcf\u7bc7\u200b\u6587\u732e\u200b\u5185\u5bb9\u200b\u7684\u200b\u6587\u672c\u200b\u5757\u200b\uff0c\u200b\u524d\u540e\u200b\u6587\u672c\u200b\u5757\u200b\u4e4b\u95f4\u200b\u4f1a\u200b\u6709\u200b\u4e00\u5b9a\u200b\u4ea4\u53e0\u200b\u3002</p> <p></p>"},{"location":"function_modules/paper/shared_papers/store/#_3","title":"\u5185\u5bb9\u200b\u603b\u7ed3\u200b\uff1a","text":"<p>Labridge\u200b\u4f1a\u200b\u4f7f\u7528\u200b LLM \u200b\u5bf9\u200b\u52a0\u5165\u200b\u5171\u4eab\u200b\u6587\u732e\u200b\u5e93\u200b\u7684\u200b\u6bcf\u200b\u4e00\u7bc7\u200b\u6587\u732e\u200b\u7684\u200b<code>MainText</code>\u200b\u90e8\u5206\u200b\u4e0e\u200b<code>Methods</code>\u200b\u90e8\u5206\u200b\u8fdb\u884c\u200b\u603b\u7ed3\u200b\uff0c\u200b\u5e76\u200b\u6784\u5efa\u200b\u76f8\u5e94\u200b\u7684\u200bSummary\u200b\u5411\u91cf\u200b\u6570\u636e\u5e93\u200b(SummaryVectorIndex)\u3002 \u200b\u5bf9\u4e8e\u200b<code>MainText</code>\u200b\u4e0e\u200b<code>Methods</code>\u200b\u8fdb\u884c\u200b\u603b\u7ed3\u200b\u7684\u200b\u4fa7\u91cd\u70b9\u200b\u4e0d\u200b\u4e00\u6837\u200b\u3002\u200b\u5bf9\u4e8e\u200b<code>MainText</code>\u200b\u7684\u200b\u603b\u7ed3\u200b\u4fa7\u91cd\u4e8e\u200b\u6587\u7ae0\u200b\u7684\u200b\u6574\u4f53\u200b\u5185\u5bb9\u200b\uff0c\u200b\u4e3b\u8981\u200b\u521b\u65b0\u200b\u70b9\u200b\u7b49\u200b\uff1b \u200b\u5bf9\u4e8e\u200b<code>Methods</code>\u200b\u7684\u200b\u603b\u7ed3\u200b\u4fa7\u91cd\u4e8e\u200b\u6587\u7ae0\u200b\u4f7f\u7528\u200b\u7684\u200b\u6280\u672f\u200b\u8def\u5f84\u200b\u3002</p> <ul> <li>\u200b\u5185\u5bb9\u200b\u603b\u7ed3\u200b\u7684\u200b\u5177\u4f53\u200b\u7ec6\u8282\u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Func_modules.paper.synthesizer.summarize</code></li> <li>\u200b\u4e0e\u200bSummary\u200b\u5411\u91cf\u200b\u6570\u636e\u5e93\u200b\u76f8\u5173\u200b\u7684\u200b\u7ec6\u8282\u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Func_modules.paper.store.paper_store</code></li> <li><code>MainText</code>, <code>Methods</code>\u200b\u603b\u7ed3\u200b\u76f8\u5173\u200b\u63d0\u793a\u200b\u8bcd\u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b <code>func_modules.paper.prompt.synthesize.paper_summarize</code></li> </ul>"},{"location":"function_modules/paper/shared_papers/store/#_4","title":"\u6587\u732e\u200b\u76ee\u5f55\u200b\u603b\u7ed3\u200b\uff1a","text":"<p>Labridge\u200b\u4f7f\u7528\u200b LLM \u200b\u9012\u5f52\u200b\u5730\u4e3a\u200b\u6587\u732e\u200b\u4ed3\u5e93\u200b\u7684\u200b\u6bcf\u200b\u4e00\u7ea7\u200b\u76ee\u5f55\u200b\u751f\u6210\u200b\u8be5\u200b\u76ee\u5f55\u200b\u7684\u200b\u6587\u732e\u200b\u7b80\u4ecb\u200b\uff0c\u200b\u5982\u200b\u6bcf\u4e2a\u200b\u76ee\u5f55\u200b\u4e0b\u200b\u6587\u732e\u200b\u6d89\u53ca\u200b\u7684\u200b\u7814\u7a76\u200b\u9886\u57df\u200b\u7b49\u200b\u3002 \u200b\u8fd9\u4e9b\u200b\u4fe1\u606f\u200b\u4f1a\u200b\u4f5c\u4e3a\u200bLabridge\u200b\u4e3a\u200b\u5b9e\u9a8c\u5ba4\u200b\u6210\u5458\u200b\u63a8\u8350\u200b\u6587\u732e\u200b\u4ee5\u53ca\u200b\u5411\u200b\u5171\u4eab\u200b\u6587\u732e\u200b\u5e93\u200b\u63d2\u5165\u200b\u65b0\u200b\u6587\u732e\u200b\u7684\u200b\u91cd\u8981\u200b\u53c2\u8003\u200b\u3002 \u200b\u6587\u732e\u200b\u76ee\u5f55\u200b\u603b\u7ed3\u200b\u7684\u200b\u5177\u4f53\u200b\u7ec6\u8282\u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Func_modules.paper.store.paper_store</code></p>"},{"location":"function_modules/paper/shared_papers/store/#_5","title":"\u5171\u4eab\u200b\u6587\u732e\u200b\u7b14\u8bb0\u200b\u5411\u91cf\u200b\u6570\u636e\u5e93","text":"<p>\u200b\u5171\u4eab\u200b\u6587\u732e\u200b\u7b14\u8bb0\u200b\u5411\u91cf\u200b\u6570\u636e\u5e93\u200b\u7684\u200b\u7ed3\u6784\u200b\u5982\u4e0b\u200b\u56fe\u200b\u6240\u793a\u200b\u3002\u200b\u8be5\u200b\u6570\u636e\u5e93\u200b\u662f\u200b\u4e00\u4e2a\u200b\u8f83\u4e3a\u200b\u6241\u5e73\u5316\u200b\u7684\u200b\u6811\u5f62\u200b\u7ed3\u6784\u200b\uff0c\u200b\u7b2c\u4e00\u5c42\u200b\u8282\u70b9\u200b\u4e3a\u200b\u6587\u732e\u200b\u7684\u200bDOI\uff0c\u200b\u5bf9\u5e94\u200b\u4e00\u4efd\u200b\u72ec\u4e00\u65e0\u4e8c\u200b\u7684\u200b\u6587\u732e\u200b\uff0c\u200b\u5176\u5b50\u200b\u8282\u70b9\u200b\u4e3a\u200b \u200b\u4e0d\u200b\u4ea4\u53e0\u200b\u7684\u200b\u5185\u5bb9\u200b\u6587\u672c\u200b\u5757\u200b\uff0c\u200b\u4e14\u200b\u6587\u672c\u200b\u5757\u200b\u957f\u5ea6\u200b\u8f83\u200b\u77ed\u200b\uff0c\u200b\u4ee5\u200b\u63d0\u4f9b\u200b\u7cbe\u7ec6\u5316\u200b\u7684\u200b\u68c0\u7d22\u200b\u3002\u200b\u6bcf\u4e2a\u200b\u6587\u672c\u200b\u5757\u200b\u8282\u70b9\u200b\u7684\u200b\u5b50\u200b\u8282\u70b9\u200b\u4e3a\u200b\u7b14\u8bb0\u200b\u8282\u70b9\u200b\uff0c\u200b\u8bb0\u5f55\u200b\u8be5\u200b\u6587\u672c\u200b\u5757\u200b\u4e2d\u200b\u7528\u6237\u200b\u8bb0\u5f55\u200b\u7684\u200b\u7b14\u8bb0\u200b\u5185\u5bb9\u200b\u3002</p> <p></p>"},{"location":"function_modules/paper/temporary_papers/","title":"\u4e2a\u4eba\u200b\u8fd1\u671f\u200b\u6587\u732e\u200b\u5e93","text":"<p>Labridge\u200b\u4e3a\u200b\u5b9e\u9a8c\u5ba4\u200b\u6bcf\u4e2a\u200b\u6210\u5458\u200b\u63d0\u4f9b\u200b\u4e00\u4e2a\u200b\u72ec\u7acb\u200b\u7684\u200b\u4e34\u65f6\u200b\u6587\u732e\u200b\u5e93\u200b\uff0c\u200b\u8be5\u200b\u6587\u732e\u200b\u5e93\u4f1a\u200b\u5b58\u653e\u200bLabridge\u200b\u534f\u52a9\u200b\u6210\u5458\u200b\u4e0b\u8f7d\u200b\u7684\u200b\u6587\u732e\u200b\uff0c\u200b\u4e0e\u200b\u6210\u5458\u200b\u4e0a\u4f20\u200b\u7684\u200b\u6587\u732e\u200b\u3002 \u200b\u8be5\u200b\u4e34\u65f6\u200b\u6587\u732e\u200b\u5e93\u4f1a\u200b\u5b9a\u65f6\u200b\u6e05\u7406\u200b\uff0c\u200b\u5982\u679c\u200b\u8981\u200b\u6c38\u4e45\u200b\u4fdd\u5b58\u200b\uff0c\u200b\u6210\u5458\u200b\u53ef\u4ee5\u200b\u8981\u6c42\u200bLabridge\u200b\u5c06\u200b\u6709\u200b\u4ef7\u503c\u200b\u7684\u200b\u6587\u732e\u200b\u5b58\u653e\u200b\u8fdb\u200b\u5b9e\u9a8c\u5ba4\u200b\u5171\u4eab\u200b\u6587\u732e\u200b\u5e93\u200b\u3002</p>"},{"location":"function_modules/paper/temporary_papers/#_2","title":"\u6587\u732e\u200b\u5e93\u200b\u6784\u5efa","text":"<p>\u200b\u4e2a\u4eba\u200b\u8fd1\u671f\u200b\u6587\u732e\u200b\u5e93\u200b\u7ed3\u6784\u200b</p>"},{"location":"function_modules/paper/temporary_papers/#_3","title":"\u6587\u732e\u200b\u5e93\u200b\u68c0\u7d22","text":"<p>\u200b\u4e2a\u4eba\u200b\u8fd1\u671f\u200b\u6587\u732e\u200b\u5e93\u200b\u68c0\u7d22\u200b</p>"},{"location":"function_modules/paper/temporary_papers/retrieve/","title":"\u4e2a\u4eba\u200b\u4e34\u65f6\u200b\u6587\u732e\u200b\u5e93\u200b\u68c0\u7d22","text":"<p>\u200b\u5bf9\u4e8e\u200b\u4e2a\u4eba\u200b\u4e34\u65f6\u200b\u6587\u732e\u200b\u5e93\u200b\u7684\u200b\u68c0\u7d22\u200b\uff0c\u200b\u6211\u4eec\u200b\u540c\u6837\u200b\u91c7\u7528\u200b\u4e86\u200b\u591a\u7ea7\u200b\u6df7\u5408\u200b\u68c0\u7d22\u200b\u3002\u200b\u4e2a\u4eba\u200b\u4e34\u65f6\u200b\u6587\u732e\u200b\u5e93\u200b\u7684\u200b\u4f7f\u7528\u200b\u573a\u666f\u200b\u66f4\u200b\u591a\u200b\u5730\u200b\u662f\u200b\u9488\u5bf9\u200b\u67d0\u200b\u4e00\u7bc7\u200b\u7279\u5b9a\u200b\u6587\u732e\u200b\u8fdb\u884c\u200b\u8be2\u95ee\u200b\uff0c \u200b\u4e14\u200b\u5bf9\u4e8e\u200b\u65f6\u6548\u6027\u200b\u6709\u200b\u8f83\u200b\u9ad8\u200b\u8981\u6c42\u200b\u3002\u200b\u56e0\u6b64\u200b\u6211\u4eec\u200b\u91c7\u7528\u200b\u4e86\u200b \u200b\u6a21\u7cca\u200b\u68c0\u7d22\u200b\u5b9a\u4f4d\u200b\u6587\u732e\u200b\u8303\u56f4\u200b + \u200b\u8fdb\u4e00\u6b65\u200b\u76f8\u4f3c\u6027\u200b\u68c0\u7d22\u200b \u200b\u7684\u200b\u7b56\u7565\u200b\u3002</p> <p></p>"},{"location":"function_modules/paper/temporary_papers/retrieve/#_2","title":"\u6a21\u7cca\u200b\u68c0\u7d22\u200b\u786e\u5b9a\u200b\u6587\u732e\u200b\u8303\u56f4","text":"<p>\u200b\u9996\u5148\u200b\uff0cLabridge\u200b\u4f1a\u200b\u4ece\u200b\u5de5\u5177\u200b\u8c03\u7528\u200b\u65e5\u5fd7\u200b\u4ee5\u53ca\u200b\u804a\u5929\u8bb0\u5f55\u200b\u4e2d\u200b\u786e\u5b9a\u200b\u6240\u200b\u9700\u200b\u6587\u732e\u200b\u7684\u200b\u5927\u81f4\u200b\u4fe1\u606f\u200b(PaperInfo)\uff08\u200b\u5982\u200b\u6807\u9898\u200b\u3001\u200b\u6587\u4ef6\u200b\u8def\u5f84\u200b\u7b49\u200b\uff09\u3002 \u200b\u6839\u636e\u200b\u8be5\u200bPaperInfo\uff0cLabridge\u200b\u5728\u200b\u4e2a\u4eba\u200b\u4e34\u65f6\u200b\u6587\u732e\u200b\u5e93\u4e2d\u200b\u8fdb\u884c\u200b\u76f8\u4f3c\u6027\u200b\u68c0\u7d22\u200b\u83b7\u5f97\u200b\u76f8\u5173\u200bnodes\uff0c\u200b\u8fd9\u4e9b\u200bnodes\u200b\u6240\u5c5e\u200b\u7684\u200b\u6587\u732e\u200b\u5373\u200b\u4e3a\u200bLabridge\u200b\u5728\u200b \u200b\u4e0b\u200b\u4e00\u6b65\u200b\u68c0\u7d22\u200b\u4e2d\u200b\u7684\u200b\u68c0\u7d22\u200b\u8303\u56f4\u200b\u3002</p>"},{"location":"function_modules/paper/temporary_papers/retrieve/#_3","title":"\u65e5\u671f\u200b\u8fc7\u6ee4","text":"<p>Labridge\u200b\u53ef\u4ee5\u200b\u63d0\u4f9b\u200b\u8d77\u6b62\u200b\u65f6\u95f4\u200b\u6765\u200b\u8fdb\u4e00\u6b65\u200b\u7f29\u5c0f\u200b\u68c0\u7d22\u200b\u8303\u56f4\u200b\u3002</p>"},{"location":"function_modules/paper/temporary_papers/retrieve/#_4","title":"\u8fdb\u4e00\u6b65\u200b\u68c0\u7d22","text":"<p>\u200b\u5728\u200b\u8fd9\u200b\u4e00\u6b65\u200b\u68c0\u7d22\u200b\u4e2d\u200b\uff0cLabridge\u200b\u5728\u200b\u4e0a\u200b\u4e00\u6b65\u200b\u68c0\u7d22\u200b\u7684\u200b\u6587\u732e\u200b\u8303\u56f4\u200b\u4e2d\u200b\uff0c\u200b\u6839\u636e\u200b\u7528\u6237\u200b\u7684\u200b\u68c0\u7d22\u200b\u6587\u672c\u200b\u8fdb\u884c\u200b\u76f8\u4f3c\u6027\u200b\u68c0\u7d22\u200b\uff0c\u200b\u5e76\u200b\u83b7\u5f97\u200b\u6700\u200b\u76f8\u5173\u200b\u7684\u200b\u5185\u5bb9\u200b\u8282\u70b9\u200b(doc nodes)</p>"},{"location":"function_modules/paper/temporary_papers/retrieve/#_5","title":"\u6dfb\u52a0\u200b\u4e0a\u4e0b\u6587","text":"<p>\u200b\u53ef\u4ee5\u200b\u9009\u62e9\u200b\u4e3a\u200b\u68c0\u7d22\u200b\u5f97\u5230\u200b\u7684\u200b\u7ed3\u679c\u200b\u6dfb\u52a0\u200b\u4e0a\u4e0b\u6587\u200b\uff0c\u200b\u4f5c\u4e3a\u200b\u6700\u7ec8\u200b\u7ed3\u679c\u200b\u4f20\u7ed9\u200b LLM\uff0c\u200b\u4ee5\u200b\u907f\u514d\u200b\u6587\u672c\u200b\u5206\u5757\u200b\u5bfc\u81f4\u200b\u7684\u200b\u5185\u5bb9\u200b\u4e0d\u200b\u5b8c\u6574\u200b\u3002</p>"},{"location":"function_modules/paper/temporary_papers/store/","title":"\u4e2a\u4eba\u200b\u8fd1\u671f\u200b\u6587\u732e\u200b\u5e93\u200b\u7ed3\u6784","text":"<p>\u200b\u6bcf\u4e2a\u200b\u4e34\u65f6\u200b\u6587\u732e\u200b\u5e93\u200b\u90fd\u200b\u662f\u200b\u4e00\u4e2a\u200b\u5411\u91cf\u200b\u6570\u636e\u5e93\u200b\uff0c\u200b\u5b58\u50a8\u200b\u6bcf\u4e2a\u200b\u7528\u6237\u200b\u5404\u81ea\u200b\u8fd1\u671f\u200b\u7684\u200b\u6587\u732e\u200b\u3002\u200b\u5176\u200b\u7ed3\u6784\u200b\u5982\u4e0b\u200b\u56fe\u200b\u6240\u793a\u200b\uff1a</p> <p></p> <ul> <li>\u200b\u4e34\u65f6\u200b\u6587\u732e\u200b\u6587\u4ef6\u200b\u5b58\u653e\u200b\u5728\u200b\u9879\u76ee\u200b\u8def\u5f84\u200b <code>documents\\tmp_papers\\{user_id}</code>, \u200b\u4e34\u65f6\u200b\u6587\u732e\u200b\u5e93\u662f\u200b user-specific \u200b\u7684\u200b\u3002</li> <li>\u200b\u6bcf\u4e2a\u200b\u6587\u732e\u200b\u5e93\u5b58\u200b\u5728\u200b\u4e00\u4e2a\u200b\u6839\u200b\u8282\u70b9\u200b(root node), \u200b\u6240\u6709\u200b\u7684\u200b\u6587\u732e\u200b\u8282\u70b9\u200b(paper node)\u200b\u90fd\u200b\u662f\u200b\u6839\u200b\u8282\u70b9\u200b\u7684\u200b\u5b50\u200b\u8282\u70b9\u200b\u3002</li> <li>\u200b\u6587\u732e\u200b\u8282\u70b9\u200b\u7684\u200b<code>ID</code>\u200b\u4e3a\u200b\u8be5\u200b\u6587\u732e\u200b\u6587\u4ef6\u200b\u7684\u200b\u7edd\u5bf9\u8def\u5f84\u200b\u3002\u200b\u5176\u5b83\u200b\u989d\u5916\u200b\u4fe1\u606f\u200b\u5305\u62ec\u200b\u8be5\u200b\u6587\u4ef6\u200b\u5b58\u653e\u200b\u8fdb\u200b\u4e34\u65f6\u200b\u6587\u732e\u200b\u5e93\u200b\u7684\u200b\u65f6\u95f4\u200b(<code>date</code> <code>time</code>)\uff0c\u200b\u65f6\u95f4\u200b\u6233\u200b\u4fe1\u606f\u200b\u53ef\u4ee5\u200b\u7528\u4e8e\u200b\u5728\u200b\u68c0\u7d22\u200b\u8fc7\u7a0b\u200b\u4e2d\u200b\u8fdb\u884c\u200b\u65f6\u95f4\u200b\u8fc7\u6ee4\u200b\u3002</li> <li>\u200b\u6bcf\u7bc7\u200b\u6587\u732e\u200b\u7684\u200b\u6240\u6709\u200b\u5185\u5bb9\u200b\u8282\u70b9\u200b(doc node)\u200b\u4f5c\u4e3a\u200b\u5bf9\u5e94\u200b\u6587\u732e\u200b\u8282\u70b9\u200b\u7684\u200b\u5b50\u200b\u8282\u70b9\u200b\u3002</li> <li>\u200b\u5982\u679c\u200b\u8be5\u200b\u6210\u5458\u200b\u4f7f\u7528\u200b\u4e86\u200b\u6587\u732e\u200b\u603b\u7ed3\u200b\u529f\u80fd\u200b\uff0c\u200b\u76f8\u5e94\u200b\u7684\u200b\u6587\u732e\u200b\u603b\u7ed3\u200b\u6587\u672c\u200b\u4f1a\u200b\u4f5c\u4e3a\u200b\u5b50\u200b\u8282\u70b9\u200b\u52a0\u5165\u200b\u5bf9\u5e94\u200b\u7684\u200b\u6587\u732e\u200b\u8282\u70b9\u200b\u3002</li> </ul>"},{"location":"function_modules/paper/temporary_papers/download/arXiv/","title":"\u5728\u200barXiv\u200b\u4e0a\u200b\u68c0\u7d22\u200b\u4e0e\u200b\u4e0b\u8f7d\u200b\u6587\u732e","text":"<p>Labridge\u200b\u4f7f\u7528\u200barXiv\u200b\u63d0\u4f9b\u200b\u7684\u200bAPI, \u200b\u652f\u6301\u200b\u5f02\u6b65\u200b\u5730\u200b\u4ece\u200barXiv.org\u200b\u68c0\u7d22\u200b\u4e0e\u200b\u83b7\u53d6\u200b\u6587\u732e\u200b\u3002</p> <p>\u200b\u5177\u4f53\u200b\u7ec6\u8282\u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Fun_modules.paper.download.arxiv</code></p>"},{"location":"function_modules/reference/","title":"\u53c2\u8003\u200b\u6587\u4ef6","text":""},{"location":"function_modules/reference/#_2","title":"\u201c\u200b\u6388\u4eba\u200b\u4ee5\u9c7c\u200b\u4e0d\u5982\u200b\u6388\u4eba\u4ee5\u6e14\u200b\u201d","text":"<p>\u200b\u4e3a\u4e86\u200b\u4fdd\u8bc1\u200bLabridge\u200b\u56de\u7b54\u200b\u7684\u200b\u53ef\u4fe1\u5ea6\u200b\u4e0e\u200b\u51c6\u786e\u6027\u200b\uff0c\u200b\u5728\u200b\u8c03\u7528\u200b\u68c0\u7d22\u200b\u7c7b\u200b\u76f8\u5173\u200b\u5de5\u5177\u200b\u65f6\u200b\uff0c\u200b\u8be5\u200b\u5de5\u5177\u200b\u540c\u65f6\u200b\u4f1a\u200b\u8fd4\u56de\u200b\u53c2\u8003\u200b\u7684\u200b\u6587\u4ef6\u200b\u4fe1\u606f\u200b\u3002</p> <p>\u200b\u6b64\u5916\u200b\uff0cLabridge\u200b\u7684\u200b\u76ee\u6807\u200b\u4e0d\u4ec5\u4ec5\u200b\u662f\u200b\u7ed9\u51fa\u200b\u6b63\u786e\u200b\u7ed3\u679c\u200b\uff0cLabridge\u200b\u8fd8\u200b\u81f4\u529b\u4e8e\u200b\u4fc3\u8fdb\u200b\u77e5\u8bc6\u200b\u7684\u200b\u6d41\u52a8\u200b\uff0c\u200b\u6388\u4eba\u4ee5\u6e14\u200b\u3002\u200b\u56e0\u6b64\u200b\u53c2\u8003\u200b\u6587\u4ef6\u200b\u662f\u200b\u5341\u5206\u200b\u6709\u200b\u5fc5\u8981\u200b\u7684\u200b\u3002</p> <ul> <li>\u200b\u53c2\u8003\u6587\u732e\u200b</li> <li>\u200b\u53c2\u8003\u200b\u4eea\u5668\u200b\u6587\u6863\u200b</li> </ul>"},{"location":"function_modules/reference/instrument_reference/","title":"\u53c2\u8003\u200b\u4eea\u5668\u200b\u6587\u6863","text":"<p>\u200b\u53c2\u8003\u200b\u4eea\u5668\u200b\u6587\u6863\u200b\u4fe1\u606f\u200b\u5305\u542b\u200b\u5982\u4e0b\u200b\u5185\u5bb9\u200b\uff1a</p> <ul> <li>\u200b\u4eea\u5668\u200b\u540d\u79f0\u200b</li> <li>\u200b\u8be5\u200b\u4eea\u5668\u200b\u7684\u200b Super Users</li> </ul>"},{"location":"function_modules/reference/paper_reference/","title":"\u53c2\u8003\u6587\u732e","text":"<p>\u200b\u53c2\u8003\u6587\u732e\u200b\u4fe1\u606f\u200b\u5305\u542b\u200b\u5982\u4e0b\u200b\u5185\u5bb9\u200b\uff1a</p> <ul> <li>\u200b\u6587\u732e\u200b\u6807\u9898\u200b</li> <li>\u200b\u6587\u732e\u200b\u8def\u5f84\u200b</li> <li>\u200b\u62e5\u6709\u200b\u8be5\u200b\u6587\u732e\u200b\u7684\u200b\u6210\u5458\u200b\u3002</li> </ul>"},{"location":"interface/app/","title":"App\u200b\u4ea4\u4e92\u200b\u754c\u9762","text":"<p>\u200b\u6211\u4eec\u200b\u4e3a\u200b\u7528\u6237\u200b\u4e0e\u200bLabridge\u200b\u7684\u200b\u4ea4\u4e92\u200b\u63d0\u4f9b\u200bapp\u200b\u4ea4\u4e92\u200b\u754c\u9762\u200b\uff0c\u200b\u5982\u4e0b\u200b\u56fe\u200b\u6240\u793a\u200b\u3002</p> <p></p>"},{"location":"interface/app/#_1","title":"\u591a\u6837\u5316\u200b\u4ea4\u4e92\u65b9\u5f0f","text":"<p>Labridge\u200b\u652f\u6301\u200b\u591a\u6837\u5316\u200b\u7684\u200b\u4ea4\u4e92\u65b9\u5f0f\u200b\uff1a\u200b\u6587\u5b57\u200b\uff0c\u200b\u8bed\u97f3\u200b\uff0c\u200b\u6587\u4ef6\u200b\u7b49\u200b\uff1b</p> <p>Labridge\u200b\u8fd8\u200b\u652f\u6301\u200b\u4f7f\u200b\u7528\u6237\u200b\u4ecb\u5165\u200b\u667a\u80fd\u200b\u4f53\u200b\u7684\u200b\u601d\u8003\u200b\u4e0e\u200b\u51b3\u7b56\u200b\u7684\u200b\u5f00\u53d1\u8005\u200b\u6a21\u5f0f\u200b\u3002</p> <p> </p>"},{"location":"interface/app/#app_1","title":"App\u200b\u4ee3\u7801\u200b\u63cf\u8ff0\u200b\u4e0e\u200b\u7f16\u8bd1\u200b\u8bf4\u660e","text":""},{"location":"interface/server-client/","title":"Server\u200b\u4e0e\u200bClient\u200b\u4e4b\u95f4\u200b\u7684\u200b\u901a\u4fe1\u200b\u8bf4\u660e","text":""},{"location":"interface/server-client/#_1","title":"\u6570\u636e\u7ed3\u6784\u200b\uff1a","text":""},{"location":"interface/server-client/#client","title":"Client\u200b\u4e0a\u4f20\u200b\u7684\u200b\u6570\u636e\u200b\uff1a","text":""},{"location":"interface/server-client/#chat-with-text","title":"Chat with text:","text":"<p>ClientTextReq: - text (str): \u200b\u7528\u6237\u200b\u7684\u200b\u6d88\u606f\u200b\u5b57\u7b26\u4e32\u200b - reply_in_speech (bool): \u200b\u7528\u6237\u200b\u5e0c\u671b\u200b\u5f97\u5230\u200b\u8bed\u97f3\u200b\u56de\u590d\u200b\u8fd8\u662f\u200b\u6587\u672c\u200b\u56de\u590d\u200b\u3002 - enable_instruct (bool): \u200b\u5f53\u524d\u200b\u8f6e\u6b21\u200bQA, \u200b\u7528\u6237\u200b\u662f\u5426\u200b\u4ecb\u5165\u200bAgent\u200b\u7684\u200bReasoning - enable_comment (bool): \u200b\u5f53\u524d\u200b\u8f6e\u6b21\u200bQA, \u200b\u7528\u6237\u200b\u662f\u5426\u200b\u4ecb\u5165\u200bAgent\u200b\u7684\u200bActing</p> <p>Post URL: <code>/users/{user_id}/chat_text</code></p>"},{"location":"interface/server-client/#download-file","title":"Download File:","text":"<p>ClientDownloadReq: - filepath (str): \u200b\u7533\u8bf7\u200b\u4e0b\u8f7d\u200b\u7684\u200b\u6587\u4ef6\u200b\u8def\u5f84\u200b</p> <p>Post URL: <code>/users/{user_id}/files/bytes</code></p>"},{"location":"interface/server-client/#chat-with-file","title":"Chat with file:","text":"<ul> <li>file (bytes): \u200b\u4e0a\u4f20\u200b\u6587\u4ef6\u200b\u7684\u200b\u4e8c\u8fdb\u5236\u200b\u6570\u636e\u200b</li> <li>file_name (str): \u200b\u4e0a\u4f20\u200b\u6587\u4ef6\u200b\u7684\u200b\u6587\u4ef6\u540d\u200b\uff08\u200b\u5305\u542b\u200b\u540e\u7f00\u200b\uff09</li> <li>text (str): \u200b\u7528\u6237\u200b\u4e0e\u200b\u8be5\u200b\u6587\u4ef6\u200b\u76f8\u5173\u200b\u7684\u200b\u6d88\u606f\u200b</li> <li>reply_in_speech (bool): \u200b\u7528\u6237\u200b\u5e0c\u671b\u200b\u5f97\u5230\u200b\u8bed\u97f3\u200b\u56de\u590d\u200b\u8fd8\u662f\u200b\u6587\u672c\u200b\u56de\u590d\u200b\u3002</li> <li>enable_instruct (bool): \u200b\u5f53\u524d\u200b\u8f6e\u6b21\u200bQA, \u200b\u7528\u6237\u200b\u662f\u5426\u200b\u4ecb\u5165\u200bAgent\u200b\u7684\u200bReasoning</li> <li>enable_comment (bool): \u200b\u5f53\u524d\u200b\u8f6e\u6b21\u200bQA, \u200b\u7528\u6237\u200b\u662f\u5426\u200b\u4ecb\u5165\u200bAgent\u200b\u7684\u200bActing</li> </ul> <p>Post URL: <code>/users/{user_id}/chat_with_file</code></p>"},{"location":"interface/server-client/#chat-with-speech","title":"Chat with speech:","text":"<ul> <li>file (bytes): \u200b\u8bed\u97f3\u200b\u6587\u4ef6\u200b\u7684\u200b\u4e8c\u8fdb\u5236\u200b\u6570\u636e\u200b</li> <li>enable_instruct (bool): \u200b\u5f53\u524d\u200b\u8f6e\u6b21\u200bQA, \u200b\u7528\u6237\u200b\u662f\u5426\u200b\u4ecb\u5165\u200bAgent\u200b\u7684\u200bReasoning</li> <li>enable_comment (bool): \u200b\u5f53\u524d\u200b\u8f6e\u6b21\u200bQA, \u200b\u7528\u6237\u200b\u662f\u5426\u200b\u4ecb\u5165\u200bAgent\u200b\u7684\u200bActing</li> </ul> <p>Post URL: <code>/users/{user_id}/chat_speech</code></p>"},{"location":"interface/server-client/#server","title":"\u4ece\u200bServer\u200b\u83b7\u53d6\u200b\u56de\u590d\u200b:","text":"<p>Get URL: <code>/users/{user_id}/response</code></p>"},{"location":"interface/server-client/#_2","title":"\u8fd4\u56de\u200b\u7684\u200b\u6570\u636e\u7ed3\u6784","text":"<p>ServerReply: - reply_text (str): Agent\u200b\u7684\u200b\u56de\u590d\u200b\u5b57\u7b26\u4e32\u200b - valid (bool): \u200b\u672c\u200b\u56de\u590d\u200b\u662f\u5426\u662f\u200b\u6709\u6548\u200b\u56de\u590d\u200b\uff0c\u200b\u82e5\u200b\u6ca1\u6709\u200b\u5f97\u5230\u200b\u6709\u6548\u200b\u56de\u590d\u200b\uff0c\u200b\u5ba2\u6237\u7aef\u200b\u5e94\u200b\u8f6e\u8be2\u200b\u76f4\u81f3\u200b\u83b7\u5f97\u200b\u6709\u6548\u200b\u56de\u590d\u200b - references (Dict[str, int]): \u200b\u53c2\u8003\u200b\u6587\u4ef6\u200b\u5728\u200bserver\u200b\u7684\u200b\u5b58\u50a8\u200b\u8def\u5f84\u200b\u4e0e\u200b\u6587\u4ef6\u200b\u5b57\u8282\u6570\u200b\u3002 - error (str): \u200b\u9519\u8bef\u4fe1\u606f\u200b\uff0c\u200b\u5982\u679c\u200b\u6ca1\u6709\u200b\u9519\u8bef\u200b\uff0c\u200b\u5219\u200b\u4e3a\u200b<code>None</code>. - inner_chat (bool): \u200b\u672c\u200b\u56de\u590d\u200b\u662f\u5426\u662f\u200b\u4e00\u4e2a\u200bChat\u200b\u8c03\u7528\u200b\u5185\u90e8\u200b\u7684\u200b\u56de\u590d\u200b\u3002\u200b\u5982\u679c\u200b\u4e3a\u200b<code>True</code>, \u200b\u5ba2\u6237\u7aef\u200b\u5e94\u8be5\u200b\u628a\u200b\u7528\u6237\u200b\u63a5\u4e0b\u6765\u200b\u7684\u200b\u56de\u590d\u200b\u53d1\u9001\u5230\u200b\u76f8\u5e94\u200b\u7684\u200b <code>Inner</code> URL.</p> <p>ServerSpeechReply: - reply_speech (Dict[str, int]): Key: Agent\u200b\u56de\u590d\u200b\u7684\u200b\u8bed\u97f3\u200b\u6587\u4ef6\u200b\u5728\u200bServer\u200b\u7684\u200b\u5b58\u50a8\u200b\u8def\u5f84\u200b, Value: \u200b\u8bed\u97f3\u200b\u6587\u4ef6\u200b\u5b57\u8282\u6570\u200b\u3002 - valid (bool): \u200b\u672c\u200b\u56de\u590d\u200b\u662f\u5426\u662f\u200b\u6709\u6548\u200b\u56de\u590d\u200b\uff0c\u200b\u82e5\u200b\u6ca1\u6709\u200b\u5f97\u5230\u200b\u6709\u6548\u200b\u56de\u590d\u200b\uff0c\u200b\u5ba2\u6237\u7aef\u200b\u5e94\u200b\u8f6e\u8be2\u200b\u76f4\u81f3\u200b\u83b7\u5f97\u200b\u6709\u6548\u200b\u56de\u590d\u200b - references (Dict[str, int]): \u200b\u53c2\u8003\u200b\u6587\u4ef6\u200b\u5728\u200bserver\u200b\u7684\u200b\u5b58\u50a8\u200b\u8def\u5f84\u200b\u4e0e\u200b\u6587\u4ef6\u200b\u5b57\u8282\u6570\u200b\u3002 - inner_chat: Optional[bool] = False - error (str): \u200b\u9519\u8bef\u4fe1\u606f\u200b\uff0c\u200b\u5982\u679c\u200b\u6ca1\u6709\u200b\u9519\u8bef\u200b\uff0c\u200b\u5219\u200b\u4e3a\u200b<code>None</code>.</p>"},{"location":"interface/server-client/#inner-url","title":"\u76f8\u5e94\u200b\u7684\u200b Inner URL:","text":""},{"location":"interface/server-client/#chat-with-text_1","title":"Chat with text:","text":"<p>Inner URL: <code>/users/{user_id}/inner_chat_text</code></p>"},{"location":"interface/server-client/#chat-with-speech_1","title":"Chat with speech:","text":"<p>Inner URL: <code>/users/{user_id}/inner_chat_speech</code></p>"},{"location":"interface/server-client/#chat-with-file_1","title":"Chat with file:","text":"<p>Inner URL: <code>/users/{user_id}/inner_chat_with_file</code></p>"},{"location":"interface/web_ui/","title":"Web\u200b\u4ea4\u4e92\u200b\u754c\u9762","text":"<p>\u200b\u6211\u4eec\u200b\u4e3a\u200b\u7528\u6237\u200b\u4e0e\u200bLabridge\u200b\u7684\u200b\u4ea4\u4e92\u200b\u63d0\u4f9b\u200bweb\u200b\u4ea4\u4e92\u200b\u754c\u9762\u200b\uff0c\u200b\u5982\u4e0b\u200b\u56fe\u200b\u6240\u793a\u200b\u3002</p>"},{"location":"interface/web_ui/#web_1","title":"Web\u200b\u754c\u9762\u200b\u4ee3\u7801\u200b\u63cf\u8ff0\u200b\u4e0e\u200b\u7f16\u8bd1\u200b\u6d41\u7a0b","text":"<p>\u200b\u4f7f\u7528\u200b\u4e86\u200b\u4ec0\u4e48\u200b\u8bed\u8a00\u200b\uff0c\u200b\u57fa\u4e8e\u200b\u4ec0\u4e48\u200b\u6846\u67b6\u200b\u5f00\u53d1\u200b\uff0c\u200b\u5982\u4f55\u200b\u8fdb\u884c\u200b\u7f16\u8bd1\u200b\u3002</p>"},{"location":"overview/introduction/","title":"This is the inner introduction.","text":""},{"location":"en/#when-everybody-adds-fuel-the-flames-rise-high","title":"\u201dWhen everybody adds fuel, the flames rise high.\u201c","text":"<p>Labridge is committed to build a bridge for communication and collaboration among all scientific laboratories,  enhancing the efficiency of researchers and catalyzing the birth of new knowledge.</p> <p></p>"},{"location":"en/agent_tools/prompt_framework/","title":"Agent prompt framework","text":"<p>We have adopted the CoT (Chain of Thought) + ReAct (Reasoning &amp; Acting) prompt framework. Additionally, Labridge provides interfaces for user's intervention during the Reasoning phase and Acting phase,  allowing users to participate in the agent\u2019s thinking and decision-making process,  thereby offering fine-grained control over the agent\u2019s actions. We call it as <code>InstructReAct</code></p> <p>Example: Intervene agent's Reasoning &amp; Acting</p> <ul> <li>Instruct mode</li> <li>Instruct mode &amp; Comment mode</li> </ul>"},{"location":"en/agent_tools/prompt_framework/#react-prompt","title":"ReAct Prompt","text":"<pre><code>Your role is that of a research assistant in the laboratory. \nYou will assist the researchers in various aspects of their research, \nincluding helping with research paper reading, research paper retrieval, paper downloading and \nmanagement, integration of laboratory instrument information, recording and retrieval of experimental logs, \nas well as any other aspects that contribute to scientific research.\n\n## Tools\nYou have access to a wide variety of tools. You are responsible for using\nthe tools in any sequence you deem appropriate to complete the task at hand.\nThis may require breaking the task into subtasks and using different tools\nto complete each subtask.\n\nYou have access to the following tools:\n{tool_desc}\n\nyou must follow the instruction below:\n\nTo answer the question using extra tools, think step-by-step, and please use the following format.\n\n\nThought: Think step-by-step, In order to answer the overall question, given the executed actions and their observations, \n    What's my target in this step? Which tool should I use to help me accomplish this target?\nAction: tool name (one of {tool_names}) if using a tool.\nAction Input: the input to the tool, in a JSON format representing the kwargs (e.g. {{\"input\": \"hello world\", \"num_beams\": 5}})\n\n\nPlease ALWAYS start with a Thought.\n\nPlease use a valid JSON format for the Action Input. Do NOT do this {{'input': 'hello world', 'num_beams': 5}}.\n\nIf this format is used, the user will respond in the following format:\n\n\nObservation: tool response\n\n\n## Output Format\n\nWhen you decide to answer, you MUST respond in the one of the following two formats:\nYou MUST return valid and direct response that can answer the user's question, DO NOT output the Tool Call.\n\n\nThought: I have complete all the sub-tasks and I can answer without using any more tools. \nAnswer: [your answer here]\n\n\n\nThought: I cannot answer the question with the provided tools.\nAnswer: Sorry, I cannot answer your query.\n\n\n## Current Conversation\nBelow is the current conversation consisting of interleaving human and assistant messages.\n</code></pre>"},{"location":"en/agent_tools/prompt_framework/#instruct-prompt","title":"Instruct prompt","text":"<pre><code>Your role is that of a research assistant in the laboratory. \nYou will assist the researchers in various aspects of their research, \nincluding helping with research paper reading, research paper retrieval, paper downloading and \nmanagement, integration of laboratory instrument information, recording and retrieval of experimental logs, \nas well as any other aspects that contribute to scientific research.\n\n## Tools\nYou have access to a wide variety of tools. You are responsible for using\nthe tools in any sequence you deem appropriate to complete the task at hand.\nThis may require breaking the task into subtasks and using different tools\nto complete each subtask.\n\nYou have access to the following tools:\n{tool_desc}\n\nSeveral tools have been previously chose by another assistant:\nPrevious choice: {prev_response}\n\nThe User gives some suggestions to the previously selected action:\nUser suggestion: {suggestion}\n\nNow you should adopt the user's suggestions to optimize the tool choices to better answer the question.\nIf the user gives no valid suggestion, or agrees with the previous selected action,\nno modification is needed, just use the previous selected action.\n\nyou must follow the instruction below:\n\n## Output Format\nplease use the following format.\n\nThought: Given the previous action: {prev_response}, Following the user's suggestions: {suggestion}, \ndo I need to modify my action? If need, how should I adjust my action to meet the user's requirements better?\nAction: tool name (one of {tool_names}) if using a tool.\nAction Input: the input to the tool, in a JSON format representing the kwargs (e.g. {{\"input\": \"hello world\", \"num_beams\": 5}})\n\nPlease ALWAYS start with a Thought.\n\nPlease use a valid JSON format for the Action Input. Do NOT do this {{'input': 'hello world', 'num_beams': 5}}.\n\nIf this format is used, the user will respond in the following format:\n\n## Current Conversation\nBelow is the current conversation consisting of interleaving human and assistant messages.\n</code></pre>"},{"location":"en/agent_tools/tools/","title":"Tools callable by the agent.","text":"<p>Labridge can currently call the following tools:</p> <ul> <li>SharedPaperRetrieverTool</li> <li>RecentPaperRetrieveTool</li> <li>RecentPaperSummarizeTool</li> <li>ArXivSearchDownloadTool</li> <li>AddNewRecentPaperTool</li> <li>ExperimentLogRetrieveTool</li> <li>CreateNewExperimentLogTool</li> <li>SetCurrentExperimentTool</li> <li>RecordExperimentLogTool</li> <li>ChatMemoryRetrieverTool</li> </ul> <p>All operations requiring authorization from lab members are defined as CallbackOperation Such as creating experiment records, downloading papers, etc. Refer to Code docs <code>Callback.base.operation_base</code> for details of CallbackOperation</p> <p>The current CallbackOperation includes\uff1a</p> <ul> <li>ArxivDownloadOperation Refer to Code docs <code>Callback.paper.paper_download</code></li> <li>AddNewRecentPaperOperation Refer to Code docs <code>Callback.paper.add_recent_paper</code></li> <li>PaperSummarizeOperation Refer to Code docs <code>Callback.paper.paper_summarize</code></li> <li>CreateNewExperimentLogOperation Refer to Code docs <code>Callback.experiment_log.new_experiment</code></li> <li>SetCurrentExperimentOperation Refer to Code docs <code>Callback.experiment_log.set_current_experiment</code></li> </ul> <p>We provide the following tool template for developing tools that comply with the process of  \"collecting user information \u2192 defining execution operations \u2192 obtaining user authorization \u2192 executing Callback operations\"</p> <ul> <li>CollectAndAuthorizeTool</li> </ul>"},{"location":"en/agent_tools/tools/base/tool_base/","title":"Base classes of tools","text":""},{"location":"en/agent_tools/tools/base/tool_base/#checkbasetool","title":"CheckBaseTool","text":"<p>This tool template implements the functionality of checking and obtaining the required parameters from the input parameters.</p> <p>Refer to Code docs <code>Tools.base.tool_base</code></p>"},{"location":"en/agent_tools/tools/base/tool_base/#retrieverbasetool","title":"RetrieverBaseTool","text":"<p>This tool template implements the functionality of using the given Retriever for retrieval and recording tool logs  such as reference documents.</p> <p>Refer to Code docs <code>Tools.base.tool_base</code></p>"},{"location":"en/agent_tools/tools/base/tool_base/#queryenginebasetool","title":"QueryEngineBaseTool","text":"<p>This tool template implements the functionality of question answering based on a vector database.</p> <p>Refer to Code docs <code>Tools.base.tool_base</code></p>"},{"location":"en/agent_tools/tools/base/tool_base/#functionbasetool","title":"FunctionBaseTool","text":"<p>This tool template implements the functionality of invoking specified functions or class methods and recording tool logs.</p>"},{"location":"en/agent_tools/tools/base/tool_log/","title":"Tool logs","text":""},{"location":"en/agent_tools/tools/base/tool_log/#toollog","title":"ToolLog","text":"<p>This class records the logs of a tool invocation, including the following information:</p> <ul> <li>tool_name: The name of the invoked tool</li> <li>log_to_user: This part of the log will be added as additional information at the end of Labridge\u2019s response to the user.</li> <li>log_to_system: This part of the log will be stored in the user\u2019s interaction log database.</li> </ul> <p>Refer to Code docs <code>Tools.base.tool_log</code></p>"},{"location":"en/agent_tools/tools/chat_history/chat_memory_retrieve_tool/","title":"SharedPaperRetrieverTool","text":"<p>This tool is used to retrieve relevant information from the shared literature database of the laboratory.</p>"},{"location":"en/agent_tools/tools/chat_history/chat_memory_retrieve_tool/#parameters","title":"Parameters","text":"<ul> <li>item_to_be_retrieved (str): Information to be retrieved</li> <li>memory_id (str): Member name or member group name</li> <li>start_date (Optional[str]): Start date of time filter</li> <li>end_date (Optional[str]): End date of time filter</li> <li>kwargs (Any): Improve the fault tolerance of LLM when calling this tool</li> </ul>"},{"location":"en/agent_tools/tools/chat_history/chat_memory_retrieve_tool/#description","title":"Description","text":"<pre><code>This tool is used to retrieve relevant chat history in a certain chat history memory.\nThe memory_id of a chat history memory is the `user_id` of a specific user or the `chat_group_id` of a specific\nchat group.\n\nAdditionally, you can provide the `start_date` and `end_state` to limit the retrieving range of date,\nThe end date can be the same as the start date, but should not be earlier than the start date.\nIf the start date or end_date is not provided, retrieving will be performed among the whole memory.\n\nArgs:\n    item_to_be_retrieved (str): Things that you want to retrieve in the chat history memory.\n    memory_id (str): The memory_id of a chat history memory. It is either a `user_id` or a `chat_group_id`.\n    start_date (str): The START date of the retrieving date limit. Defaults to None.\n        If given, it should be given in the following FORMAT: Year-Month-Day.\n        For example, 2020-12-1 means the year 2020, the 12th month, the 1rst day.\n    end_date (str): The END date of the retrieving date limit. Defaults to None.\n        If given, It should be given in the following FORMAT: Year-Month-Day.\n        For example, 2024-6-2 means the year 2024, the 6th month, the 2nd day.\n\nReturns:\n    Retrieved chat history.\n</code></pre> <p>Refer to Code docs <code>Tools.memory.chat.retrieve</code></p>"},{"location":"en/agent_tools/tools/experiment_log/create_new_experiment_log/","title":"CreateNewExperimentLogTool","text":"<p>This tool is used to create a new experiment record in the experiment log database for a specific member.</p> <p>Note: This tool is a <code>CollectAndAuthorizeTool</code> template tool, which requires collecting user information  and obtaining user authorization.</p>"},{"location":"en/agent_tools/tools/experiment_log/create_new_experiment_log/#parameters","title":"Parameters","text":"<ul> <li>user_id (str): Member name</li> </ul>"},{"location":"en/agent_tools/tools/experiment_log/create_new_experiment_log/#description","title":"Description","text":"<pre><code>This tool is used to create a new experiment log record for the user.\nThis tool is only used when the user asks for creating a new experiment log record,\nor when other tools call this tool.\n\nArgs:\n    user_id (str): The user_id of a lab member.\n\nReturns:\n    The tool's output and log.\n</code></pre> <p>Refer to Code docs <code>Tools.memory.experiment.insert</code></p>"},{"location":"en/agent_tools/tools/experiment_log/experiment_log_retrieve_tool/","title":"ExperimentLogRetrieveTool","text":"<p>This tool is used to retrieve relevant information from a member\u2019s experiment log database.</p>"},{"location":"en/agent_tools/tools/experiment_log/experiment_log_retrieve_tool/#parameters","title":"Parameters","text":"<ul> <li>item_to_be_retrieved (str): Information to be retrieved</li> <li>memory_id (str): Member name</li> <li>start_date (Optional[str]): Start date of time filter</li> <li>end_date (Optional[str]): End date of time filter</li> <li>experiment_name (Optional[str]): Specify the experiment name, limit the retrieving scope</li> <li>kwargs (Any): Improve the fault tolerance of LLM when calling this tool</li> </ul>"},{"location":"en/agent_tools/tools/experiment_log/experiment_log_retrieve_tool/#description","title":"Description","text":"<pre><code>This tool is used to retrieve experiment logs of a user.\nUse this tool to help you to answer questions about experimental records.\n\nArgs:\n    item_to_be_retrieved (str): This argument is necessary.\n        It denotes things that you want to retrieve in the chat history memory.\n    memory_id (str): This argument is necessary.\n        It is the user_id of a lab member.\n    start_date (str): This argument is optional.\n        It denotes the start date in the format 'Year-Month-Day'.\n        If both start_date and end_date are specified, only logs which are recorded between the\n        start_date and end_date will be retrieved.\n    end_date (str): This argument is optional.\n        It denotes the end date in the format 'Year-Month-Day'.\n    experiment_name (str): This argument is optional.\n        It is the name of a specific experiment.\n        If it is specified and is valid, only logs of this experiment will be retrieved.\n    kwargs: Other arguments will be ignored.\n\nReturns:\n    Retrieved experiment logs.\n</code></pre> <p>Refer to Code docs <code>Tools.memory.experiment.retrieve</code></p>"},{"location":"en/agent_tools/tools/experiment_log/record_experiment_log_tool/","title":"RecordExperimentLogTool","text":"<p>This tool is used to record experiment logs for a specific member.</p>"},{"location":"en/agent_tools/tools/experiment_log/record_experiment_log_tool/#parameters","title":"Parameters","text":"<ul> <li>user_id (str): Member name</li> <li>log_str (str): Experimental log</li> </ul>"},{"location":"en/agent_tools/tools/experiment_log/record_experiment_log_tool/#description","title":"Description","text":"<pre><code>This tool is used to record the experiment log of the experiment in progress for a user.\n\nIf the no experiment record exists or experiment in progress is not valid, this tool will call\nthe corresponding tools to help the user.\n\nArgs:\n    user_id (str): The user_id of a lab member.\n    log_str (str): The experiment log to be recorded.\n\nReturns:\n    The tool output and log.\n</code></pre> <p>Refer to Code docs <code>Tools.memory.experiment.insert</code></p>"},{"location":"en/agent_tools/tools/experiment_log/set_current_experiment_tool/","title":"SetCurrentExperimentTool","text":"<p>This tool is used to set up the current experiment for a specific member, and the logs during the experiment will be  added to the corresponding record of that experiment.</p> <p>Note: This tool is a <code>CollectAndAuthorizeTool</code> template tool, which requires collecting user information  and obtaining user authorization.</p>"},{"location":"en/agent_tools/tools/experiment_log/set_current_experiment_tool/#parameters","title":"Parameters","text":"<ul> <li>user_id (str): Member name</li> </ul>"},{"location":"en/agent_tools/tools/experiment_log/set_current_experiment_tool/#description","title":"Description","text":"<pre><code>This tool is used to record the experiment log of the experiment in progress for a user.\n\nIf the no experiment record exists or experiment in progress is not valid, this tool will call\nthe corresponding tools to help the user.\n\nArgs:\n    user_id (str): The user_id of a lab member.\n    log_str (str): The experiment log to be recorded.\n\nReturns:\n    The tool output and log.\n</code></pre> <p>Refer to Code docs <code>Tools.memory.experiment.insert</code></p>"},{"location":"en/agent_tools/tools/interact/collect_and_authorize_tool/","title":"CollectAndAuthorizeTool","text":"<p>This is a tool template for tools based on the process of  \"collecting user information \u2192 defining execution actions \u2192 obtaining user authorization \u2192 executing callback operations\"</p> <p>Refer to Code docs <code>Tools.interact.collect_and_authorize</code></p> <p></p>"},{"location":"en/agent_tools/tools/shared_papers/shared_paper_retrieve_tool/","title":"SharedPaperRetrieverTool","text":"<p>This tool is used to retrieve relevant information from a laboratory\u2019s shared literature database.</p>"},{"location":"en/agent_tools/tools/shared_papers/shared_paper_retrieve_tool/#parameters","title":"Parameters","text":"<ul> <li>item_to_be_retrieved (str): information to be retrieved</li> </ul>"},{"location":"en/agent_tools/tools/shared_papers/shared_paper_retrieve_tool/#description","title":"Description","text":"<pre><code>This tool is used to retrieve academic information in the Laboratory's shared paper database.\nIt is useful to help answer the user's academic questions.\n\nArgs:\n    item_to_be_retrieved (str): The things that you want to retrieve in the shared paper database.\n</code></pre> <p>Refer to Code docs <code>Tools.paper.shared_papers.retriever</code></p>"},{"location":"en/agent_tools/tools/temporary_papers/add_new_recent_paper_tool/","title":"AddNewRecentPaperTool","text":"<p>This tool is used to add literature to a member\u2019s recent paper database.</p>"},{"location":"en/agent_tools/tools/temporary_papers/add_new_recent_paper_tool/#parameters","title":"Parameters","text":"<ul> <li>user_id (str): Member name</li> <li>paper_file_path (str): Path of a new paper</li> </ul>"},{"location":"en/agent_tools/tools/temporary_papers/add_new_recent_paper_tool/#description","title":"Description","text":"<pre><code>This tool is used to add a new paper to a specific user's recent papers storage.\n\nArgs:\n    user_id (str): The user_id of a lab member.\n    paper_file_path (str): The file path of the paper to be added. Browse the chat context or tool logs\n        to get the correct and valid file path.\n\nReturns:\n    FuncOutputWithLog: The output and log.\n</code></pre> <p>Refer to Code docs <code>Tools.paper.temporary_papers.insert</code></p>"},{"location":"en/agent_tools/tools/temporary_papers/arxiv_search_download_tool/","title":"ArXivSearchDownloadTool","text":"<p>This tool is used to retrieve and download literature from arXiv for a member.</p> <p>Note: This is a tool that requires the user's authorization.</p>"},{"location":"en/agent_tools/tools/temporary_papers/arxiv_search_download_tool/#parameters","title":"Parameters","text":"<ul> <li>user_id (str): Member name</li> <li>search_str (str): Information to be retrieved</li> <li>kwargs (Any): Improve the fault tolerance of LLM when calling this tool</li> </ul>"},{"location":"en/agent_tools/tools/temporary_papers/arxiv_search_download_tool/#description","title":"Description","text":"<pre><code>This tool is used to search relevant papers in arXiv and download the papers that the user is interested in.\nWhen using the tool, be sure that the search_str MUST be English.\nIf the user do not use English, translate the search string to English first.\n\nArgs:\n    user_id (str): The user_id of a lab member.\n    search_str (str): The string that is used to search in arXiv.\n\nReturns:\n    FuncOutputWithLog: the operation output and log.\n</code></pre> <p>Refer to Code docs <code>Tools.paper.download.arxiv_download</code></p>"},{"location":"en/agent_tools/tools/temporary_papers/recent_paper_retrieve_tool/","title":"RecentPaperRetrieveTool","text":"<p>This tool is used to retrieve relevant information from a member\u2019s recent paper database.</p>"},{"location":"en/agent_tools/tools/temporary_papers/recent_paper_retrieve_tool/#parameters","title":"Parameters","text":"<ul> <li>paper_info (str): Relevant information of the target paper, such as title, file path, etc.</li> <li>item_to_be_retrieved (str): Information to be retrieved</li> <li>user_id (str): Member name</li> <li>start_date (Optional[str]): Start date of time filter</li> <li>end_date (Optional[str]): End date of time filter</li> <li>kwargs (Any): Improve the fault tolerance of LLM when calling this tool</li> </ul>"},{"location":"en/agent_tools/tools/temporary_papers/recent_paper_retrieve_tool/#description","title":"Description","text":"<pre><code>This tool is used to retrieve in the recent papers storage of a specific user.\nThese information should be provided:\n1. The paper information, such as title or save path.\n2. The specific question that you want to obtain answer from the paper.\n3. The user id.\n\nArgs:\n    paper_info (str): This argument is necessary.\n        It is the relevant information of the paper.\n        For example, it can be the paper title, or its save path.\n    item_to_be_retrieved (str): This argument is necessary.\n        It denotes the specific question that you want to retrieve in a specific paper.\n    user_id (str): This argument is necessary.\n        The user_id of a lab member.\n    start_date (str): This argument is optional. It denotes the start date in the format 'Year-Month-Day'.\n        If both start_date and end_date are specified, only papers which are added to storage between the\n        start_date and end_date will be retrieved.\n    end_date: This argument is optional. It denotes the end date in the format 'Year-Month-Day'.\n    **kwargs: Other keyword arguments will be ignored.\n\nReturns:\n    The retrieved results.\n</code></pre> <p>Refer to Code docs <code>Tools.paper.temporary_papers.paper_retriever</code></p>"},{"location":"en/agent_tools/tools/temporary_papers/recent_paper_summarize_tool/","title":"RecentPaperSummarizeTool","text":"<p>This tool is used to summarize a paper in the member's recent paper database or to add a new paper  to the recent paper database and summarize it.</p>"},{"location":"en/agent_tools/tools/temporary_papers/recent_paper_summarize_tool/#parameters","title":"Parameters","text":"<ul> <li>user_id (str): Member name</li> <li>paper_file_path (str): The path of the paper to be summarized</li> </ul>"},{"location":"en/agent_tools/tools/temporary_papers/recent_paper_summarize_tool/#description","title":"Description","text":"<pre><code>This tool is used to summarize a paper that is stored in a specific user's recent papers storage.\nThis tool is used ONLY when the user explicitly ask for a summarization of the paper.\nDO NOT use this tool by yourself.\n\nArgs:\n    user_id (str): The user_id of a lab member.\n    paper_file_path (str): The file path of a specific paper. Browse the chat context to get the correct\n        and valid file path of the paper.\n\nReturns:\n    The summary of the paper.\n</code></pre> <p>Refer to Code docs <code>Tools.paper.temporary_papers.paper_summarize</code></p>"},{"location":"en/demonstration/","title":"Application Demonstration","text":"<p>We demonstrate how Labridge builds a bridge for communication and collaboration in the laboratory  through several application examples.</p> <ul> <li>example1</li> </ul>"},{"location":"en/demonstration/developer_mode/comment_mode/","title":"Comment in Acting phase","text":"<p>You can comment the Labridge's action in the acting phase if you open the <code>comment mode</code></p>"},{"location":"en/demonstration/developer_mode/comment_mode/#comment-settings","title":"Comment Settings","text":"<p>In this example, we open both <code>comment mode</code> and <code>instruct mode</code></p> <p></p>"},{"location":"en/demonstration/developer_mode/comment_mode/#example","title":"Example","text":""},{"location":"en/demonstration/developer_mode/instruct_mode/","title":"Instruct Labridge in reasoning phase","text":""},{"location":"en/demonstration/developer_mode/instruct_mode/#settings","title":"Settings:","text":""},{"location":"en/demonstration/developer_mode/instruct_mode/#example","title":"Example:","text":""},{"location":"en/demonstration/experiment_log/record_log/","title":"Record experiment logs","text":""},{"location":"en/demonstration/experiment_log/retrieve_log/","title":"Retrieve in experiment log","text":""},{"location":"en/demonstration/instrument/instrument_docs/","title":"Instrument QA","text":""},{"location":"en/demonstration/paper/paper_download/","title":"Paper download","text":""},{"location":"en/demonstration/paper/recent_papers_qa/","title":"Recent Paper QA.","text":"<p>Base on the downloaded paper in paper_download:</p> <p></p>"},{"location":"en/demonstration/paper/shared_papers/","title":"Shared papers.","text":""},{"location":"en/deployment/","title":"Deployment based on Ascend hardware and software","text":"<p>We deploy the Labridge project in a multi-level method based on Ascend hardware and software.</p> <p></p>"},{"location":"en/deployment/#accelerate-the-inference-of-labridge-by-ascend-ai-chip","title":"Accelerate the inference of Labridge by Ascend AI chip","text":"<p>We deploy the embedding model using OrangePi equipped with Ascend AI chips. </p> <p>The Ascend AI chip provides 20TOPS (FP16) AI computing power, </p> <p>significantly accelerating Labridge\u2019s information retrieval, </p> <p>leveraging the advantages of local data deployment, and ensuring data security.</p> <p>Meanwhile, the large language model (LLM) is deployed on a GPU server and communicates with the embedding model via HTTP.</p>"},{"location":"en/deployment/#endow-labridge-with-its-soul-through-mindspore","title":"endow Labridge with its soul through Mindspore","text":"<p>Both the embedding model and the LLM rely on the Mindspore deep learning framework and the MindNLP natural language processing suite, </p> <p>which endow Labridge with its soul and intelligent engine</p>"},{"location":"en/function_modules/chat_history/","title":"Interaction log storage","text":""},{"location":"en/function_modules/chat_history/#reviewing-the-old-and-learning-the-new","title":"\"Reviewing the old and learning the new.\"","text":"<p>In addition to serving the current conversation with short-term memory,  Labridge will keep interaction logs with each member of the lab.  The contents of the interaction logs include:</p>"},{"location":"en/function_modules/chat_history/#chat-logs","title":"Chat logs","text":"<p>Recording the chat logs between members and Labridge in units of single QA.</p>"},{"location":"en/function_modules/chat_history/#tool-invocation-logs","title":"Tool invocation logs","text":"<p>If any tools are invoked by Labridge during the QA process,  the relevant tool logs (ToolLog) will also be recorded in this QA record. Refer to Code docs <code>tools.base.tool_log</code> for the data structure of <code>ToolLog</code>.</p> <p>The above information will be recorded as a vector database, allowing Labridge to retrieve it at an appropriate time,  providing Labridge with long-term memory functionality.</p> <p>You can learn more about the structure  and retrieval of the interaction log vector database.</p>"},{"location":"en/function_modules/chat_history/short-term_history/","title":"Short-term memory","text":"<p>Labridge stores a recent interaction record for each member or member group.  This interaction record follows a queue structure with a fixed length.</p> <p>Each time an interaction occurs with a member,  the corresponding interaction record is input to the LLM as part of the prompt  along with the current message from that member.</p> <p>Users can manually clear the short-term memory to start a new topic, avoiding interference from previous conversations.</p>"},{"location":"en/function_modules/chat_history/long-term_history/retrieve/","title":"Interaction Log Retrieval","text":"<p>The characteristic of interaction log retrieval is its strong correlation with time.  Therefore, Labridge uses a retrieval method that combines similarity search and timestamp filtering for interaction log retrieval.</p> <p></p>"},{"location":"en/function_modules/chat_history/long-term_history/retrieve/#timestamp-filtering","title":"Timestamp filtering","text":"<p>Each QA log node records the corresponding timestamp.  Labridge filters the log nodes based on the input start and end times to narrow the search scope.</p>"},{"location":"en/function_modules/chat_history/long-term_history/retrieve/#similarity-retrieval","title":"Similarity retrieval","text":"<p>In the filtered and narrowed-down log nodes, retrieve the most similar relevant_top_k interaction logs  based on the similarity between the Query\u2019s embedding vector and the QA log vectors.</p>"},{"location":"en/function_modules/chat_history/long-term_history/retrieve/#add-context","title":"Add context","text":"<p>Since the interactions between Labridge and the members are often continuous multi-round QA,  context (i.e., the previous QA and the subsequent QA) is added to all retrieval results to  ensure the completeness of the interaction logs.</p>"},{"location":"en/function_modules/chat_history/long-term_history/retrieve/#reorder-by-time","title":"Reorder by time","text":"<p>The order of the interaction logs greatly affects the semantics of the conversation.  Therefore, after adding context, the obtained QA log nodes are deduplicated and sorted to ensure the coherence of the interaction logs.</p> <p>Refer to Code docs <code>Func_modules.memory.chat.retrieve</code></p>"},{"location":"en/function_modules/chat_history/long-term_history/store/","title":"Interaction log storage structure","text":"<p>Interaction logs use a single round of QA as the basic unit, containing chat records and tool logs during the period.  An independent vector database is stored for each member or member group</p> <p>The structure of each vector database is similar to that of a doubly linked list.</p> <p></p> <ul> <li>The initial node (first node) stores the object to which the database belongs and the description of the database.  Additional information includes the creation time of the database.</li> <li>The newly added QA log unit will be added as the last node in the linked list structure.  This node stores the QA logs, with additional information including the occurrence time (date time) of the QA.</li> </ul> <p>After each interaction with a member or in the group chat of the member group,  the interaction logs will be recorded in the corresponding vector database and persisted.</p> <p>Refer to Code docs <code>Func_modules.memory.chat.store</code></p>"},{"location":"en/function_modules/experiment_log/","title":"Experimental logs","text":""},{"location":"en/function_modules/experiment_log/#every-result-of-your-experiment-has-the-potential-to-change-the-world","title":"\u201cEvery result of your experiment has the potential to change the world.\u201d","text":"<p>Researchers explore the boundaries of human knowledge through experiments.  Although most explorations are 'failures,' changes in the researchers' understanding might  uncover new value from these 'failed' results.  Alternatively, researchers in other fields might discover its unique value from a different perspective.</p> <p>Therefore, every experimental result is worth detailed documentation.  Labridge provides lab members with the functionality to record experiment logs:</p>"},{"location":"en/function_modules/experiment_log/#personal-experimental-logs","title":"Personal experimental logs","text":"<p>Labridge independently records each member's personal experiment logs  and assists members in organizing and integrating their experimental results.</p>"},{"location":"en/function_modules/experiment_log/#shared-experimental-logs","title":"Shared experimental logs","text":"<p>Labridge also records shared experiment results for the entire lab.  Members can add their own experimental results to the shared records, which are available  for all members to search and review.</p>"},{"location":"en/function_modules/experiment_log/personal_experiment/","title":"Personal experimental logs","text":"<p>Labridge records the experiment logs for each member of the lab.</p>"},{"location":"en/function_modules/experiment_log/personal_experiment/#storage-structure-of-personal-experimental-logs","title":"Storage structure of personal experimental logs","text":"<p>The records corresponding to each member's experiment are stored in the  personal experiment log vector database</p>"},{"location":"en/function_modules/experiment_log/personal_experiment/#personal-experiment-log-retrieval","title":"Personal experiment log retrieval","text":"<p>Labridge retrieves information from the experiment logs to assist members in conducting experiments.</p>"},{"location":"en/function_modules/experiment_log/personal_experiment/#personal-experiment-log-management","title":"Personal experiment log management","text":"<p>Labridge manages members' experiment logs by invoking tools (Tools).  Refer to <code>Agent &amp; Available tools</code> for details.</p>"},{"location":"en/function_modules/experiment_log/personal_experiment/retrieve/","title":"Personal experiment log retrieval","text":"<p>The experiment log is related to time, therefore, Labridge adopts a multi-level retrieval + timestamp filtering method  based on the storage structure of the experiment log.</p> <p></p>"},{"location":"en/function_modules/experiment_log/personal_experiment/retrieve/#the-first-retrieval-step","title":"The first retrieval step","text":"<p>In the first retrieval step, Labridge retrieves the most likely <code>experiment_top_k</code> experiments  based on the similarity between the Query vector and the descriptions of all experiment nodes.  At the same time, Labridge searches within all nodes of log types to retrieve the most similar  <code>first_top_k</code> log nodes based on similarity, and obtains the corresponding experiment nodes for them.</p> <p>The retrieved experiment nodes will serve as the scope for the next retrieval step.</p>"},{"location":"en/function_modules/experiment_log/personal_experiment/retrieve/#the-second-retrieval-step","title":"The second retrieval step","text":"<p>Within the range of experiment nodes obtained from the first retrieval step, Labridge retrieves <code>second_top_k</code> log nodes  from the log nodes of these experiment nodes to serve as the retrieval results.</p>"},{"location":"en/function_modules/experiment_log/personal_experiment/retrieve/#timestamp-filtering","title":"Timestamp filtering","text":"<p>In the second retrieval step, Labridge will perform timestamp filtering based on the input start and end times (if provided).  The ultimately retrieved experiment log content will be provided to LLM as input.</p> <p>Refer to Code docs <code>Func_modules.memory.experiment.retrieve_log</code> for details of retrieval</p>"},{"location":"en/function_modules/experiment_log/personal_experiment/store/","title":"Storage structure of personal experimental logs","text":"<p>Experiment logs are stored in a vector database.</p> <p></p> <ul> <li>There is a root node in the database, and all experiment nodes are the children of this root node.</li> <li> <p>Each experiment node includes the following information:</p> </li> <li> <p>Experiment name</p> </li> <li>Experiment description</li> <li>Relevant instruments</li> <li>The creation time</li> <li>For each experiment, the experiment logs are recorded as child nodes of the experiment node,  with the log nodes forming a structure similar to a doubly linked list in chronological order.</li> <li> <p>the log nodes include the following information:</p> </li> <li> <p>Experimental log</p> </li> <li>Record time</li> </ul> <p>When laboratory members request Labridge to help record experimental results, Labridge will record the  experimental results in the corresponding experiment log entry within his/her experiment log database.</p> <p>For more details about the storage structure of personal experimental logs,  refer to Code docs <code>Func_modules.memory.experiment.experiment_log</code></p>"},{"location":"en/function_modules/experiment_log/shared_experiment/","title":"Shared experimental logs","text":""},{"location":"en/function_modules/instrument/","title":"Instrument information","text":""},{"location":"en/function_modules/instrument/#an-extraordinary-researcher-make-good-use-of-instruments","title":"\u201cAn extraordinary researcher make good use of instruments\u201d","text":"<p>Experimental instruments are the tools researchers use to explore and discover.  Researchers should be thoroughly familiar with the information about each instrument to overcome difficulties  in the experimental process and obtain credible results.</p> <p>Labridge integrates the usage regulations, manuals, and precautions for all scientific instruments and equipment in the lab.  It helps lab members understand how to use the experimental instruments, assists in instrument management,  and simplifies training for experimental operations.</p>"},{"location":"en/function_modules/instrument/#instrument-information-database","title":"Instrument information database","text":"<p>Labridge consolidates all relevant information about the lab's instruments into an instrument information database,  aiming to reduce the learning and operating costs for members related to instruments.</p>"},{"location":"en/function_modules/instrument/#instrument-information-retrieval","title":"Instrument information retrieval","text":"<p>Labridge performs retrieval within the instrument information database to answer lab members' questions about  instruments and provides the corresponding Super Users for each instrument.</p>"},{"location":"en/function_modules/instrument/#instrument-management","title":"Instrument management","text":"<p>Labridge manages members' experiment logs by utilizing tools, refer to <code>Agent &amp; Available tools</code> for details.</p>"},{"location":"en/function_modules/instrument/retrieve/","title":"Instrument info retrieval","text":"<p>Labridge uses a multi-level retrieval approach to retrieve relevant instrument information.</p> <p></p>"},{"location":"en/function_modules/instrument/retrieve/#the-first-retrieval-step","title":"The first retrieval step","text":"<p>In the first step of retrieval, Labridge uses LLM to score the relevance between the query text  and the experimental instruments (based on instrument descriptions), selecting the top <code>instrument_top_k</code>  most relevant instruments.</p>"},{"location":"en/function_modules/instrument/retrieve/#the-second-retrieval-step","title":"The second retrieval step","text":"<p>Limit the search scope to the instruments obtained from the first step of retrieval.  Perform a similarity retrieval within the information of these instruments to get the <code>top_k</code>  most relevant pieces of information to the query vector.  These pieces of information are provided to LLM as reference information for the retrieval results.</p> <p>For more details about instrument retrieval, please refer to Code docs <code>Func_modules.instrument.retrieve.instrument_retrieve</code></p>"},{"location":"en/function_modules/instrument/store/","title":"Storage structure of instrument information","text":"<p>Information about experimental instruments is stored in a vector database.</p> <p></p> <ul> <li>There is a root node in the database, and all instrument nodes are the children of this root node.</li> <li> <p>Each instrument node contains the following information:</p> </li> <li> <p>Instrument name</p> </li> <li>Instrument description</li> <li>Super Users (responsible for managing instrument information, laboratory members with full access to the instruments)</li> <li>For each instrument, the instrument information is recorded as child nodes of the instrument node,  such as usage specifications, operating manuals, instrument parameters, etc.</li> </ul> <p>Refer to Code docs <code>Func_modules.instrument.store.instrument_store</code> for more details.</p>"},{"location":"en/function_modules/paper/","title":"Paper management","text":""},{"location":"en/function_modules/paper/#to-catalyze-the-birth-of-new-knowledge-in-the-flow-of-existing-knowledge","title":"\u201cTo catalyze the birth of new knowledge in the flow of existing knowledge.\u201d","text":"<p>An excellent researcher should track the latest research results in their field while maintaining curiosity and openness to new areas,  as many great scientific achievements often come from the collision of ideas between different fields.  Therefore, literature management is one of the crucial parts of a scientific laboratory.  We hope that Labridge can help researchers manage these valuable knowledge assets and build a shared literature knowledge base  for the laboratory, providing a platform for scientific communication and collaboration among lab members.</p> <p>Labridge promotes the flow of literature knowledge and the integration of knowledge across fields in the following ways:</p>"},{"location":"en/function_modules/paper/#labs-shared-paper-database","title":"Lab's shared paper database","text":"<p>Labridge collects the literature of all lab members to form a Shared paper database.  Labridge answers relevant questions from lab members based on the content of the shared knowledge base  and provides the source of the reference content (e.g., this paper is from member XXX).  This allows the flow of knowledge to be unrestricted by time and space.</p>"},{"location":"en/function_modules/paper/#personal-recent-papers","title":"Personal recent papers","text":"<p>Labridge provides each lab member with a personal Recent paper database to record the paper  that the member has recently downloaded from journal websites or uploaded to Labridge.  Labridge assists each member in better understanding the research content they are recently interested in  based on the Recent paper database.  It also supports members in managing their personal literature library through natural language.</p>"},{"location":"en/function_modules/paper/#search-and-download-papers","title":"Search and download papers","text":"<p>Labridge provides a natural language interactive literature search and download tool,  allowing researchers to stay updated with the latest research developments in their field.</p> <p>Labridge currently supports searching and downloading from the following journal websites:</p> <ul> <li>arXiv</li> </ul>"},{"location":"en/function_modules/paper/shared_papers/","title":"Shared paper database","text":"<p>Labridge collects papers from laboratory members to form a shared paper knowledge base.</p>"},{"location":"en/function_modules/paper/shared_papers/#construction-of-shared-paper-database","title":"Construction of shared paper database","text":"<p>The construction of the shared paper knowledge base includes the following aspects:</p> <ul> <li>paper parsing and medata extraction: we conduct detailed parsing and content extraction of the collected papers to ensure precise retrieval.</li> <li>construction\uff1a Based on the extracted literature content and information,  Labridge constructs a Summary vector database and a content vector database for the shared papers.</li> </ul>"},{"location":"en/function_modules/paper/shared_papers/#retrieval-of-shared-paper-database","title":"Retrieval of shared paper database","text":"<p>Labridge will retrieve in the constructed paper database to help answer questions from laboratory members.</p> <ul> <li>retrieval:  Labridge employs a multi-level, hybrid retrieval method to ensure the accuracy of search results.</li> </ul>"},{"location":"en/function_modules/paper/shared_papers/parse/","title":"Parsing and medata extraction","text":"<p>we conduct detailed parsing and content extraction of the collected papers to ensure precise retrieval.</p> <p></p>"},{"location":"en/function_modules/paper/shared_papers/parse/#source-analysis","title":"Source analysis:","text":"<p>We analyze the source of a PDF document through various methods including structured PDF parsing, keyword frequency analysis, LLM-assisted analysis. such as from <code>Nature</code>, <code>IEEE</code>, etc. For details, refer to Code docs:<code>Fun_modules.paper.parse.extractors.source_analyze</code></p>"},{"location":"en/function_modules/paper/shared_papers/parse/#structured-parsing-for-papers","title":"Structured parsing for papers:","text":"<p>Based on the analyzed paper source, we use the corresponding parsing templates to parse the document,  extracting sections such as <code>Abstract</code>, <code>MainText</code>, <code>Methods</code>, <code>References</code>, etc.,  to enable more precise literature database retrieval.</p> <p>Labridge support the following parsing templates now\uff1a   - Nature Parser: refer to Code docs <code>Fun_modules.paper.parse.parsers.nature_parser</code>   - IEEE Parser: refer to Code docs <code>Fun_modules.paper.parse.parsers.ieee_parser</code></p>"},{"location":"en/function_modules/paper/shared_papers/parse/#metadata-extraction","title":"Metadata Extraction:","text":"<p>Labridge utilizes LLM (Large Language Models) to extract metadata from literature,  such as article title, article keywords, author information, author affiliation, publication date, etc.  Papers downloaded from journal websites by Labridge often already contains sufficient metadata.  For such documents, this step involves supplementing any metadata that is not already provided.</p> <p>Refer to Code docs <code>Fun_modules.paper.parse.extractors.metadata_extract</code> for details.</p> Metadata Extraction Example"},{"location":"en/function_modules/paper/shared_papers/retrieve/","title":"Shared paper database retrieval","text":"<p>Labridge will retrieve in the Constructed shared paper database for the relevant information.</p> <p>We have employed a multi-level, hybrid search approach to enhance the accuracy of the retrieval results. Refer to Code docs <code>Fun_modules.paper.retrieve.paper_retrieve</code> for details.</p> <p></p>"},{"location":"en/function_modules/paper/shared_papers/retrieve/#the-first-retrieval-step","title":"The first retrieval step","text":"<p>In the first step of the retrieval process, we retrieve the <code>vector_similarity_top_k</code> text blocks most similar to  the question vector in the content vector database of the shared literature library, and then get the paper nodes that they belongs to. If specific <code>user_id</code> is given, the retrieval range is confined to this user's papers.</p>"},{"location":"en/function_modules/paper/shared_papers/retrieve/#the-second-relevance-analysis-step","title":"The second relevance analysis step","text":"<p>Within the scope of the papers identified in the first step of retrieval,  We then use LLM to score the relevance of their summaries to the question text.  From this scoring, we obtain the <code>docs_top_k</code> documents with the highest relevance scores.</p>"},{"location":"en/function_modules/paper/shared_papers/retrieve/#final-retrieval-step","title":"Final retrieval step","text":"<p>Within the scope of the papers that has been filtered in the second step,  we search for the <code>re_retrieve_top_k</code> text blocks most similar to the question vector within the text of these documents. Since this retrieval is the final fine-grained search, the text provided to the Embedding model during this process  consists no additional metadata.</p>"},{"location":"en/function_modules/paper/shared_papers/retrieve/#add-context-and-summary-text","title":"Add context and summary text","text":"<p>Finally, we can choose to add context to the retrieved text blocks, as well as the summaries of the documents they belong to.  These contents are then provided as the final search results to the LLM.</p>"},{"location":"en/function_modules/paper/shared_papers/store/","title":"Construction of shared paper database","text":"<p>The original files of the shared paper database are stored in <code>documents/papers</code>.  The first-level subdirectories of this paper repository are the <code>user_id</code> of the lab members.</p> <p>Labridge utilizes the Parsed content and information to construct  a comprehensive and detailed shared literature database, supporting various retrieval methods.</p>"},{"location":"en/function_modules/paper/shared_papers/store/#paper-content-vector-database","title":"Paper content vector database","text":"<p>Labridge constructs a vector database (VectorIndex) for all shared papers and records the metadata of each paper,  as well as the owner of the paper.</p> <p>Refer to Code docs <code>Func_modules.paper.store.shared_paper_store</code> for details of the construction of the content vector database.</p> <p></p>"},{"location":"en/function_modules/paper/shared_papers/store/#summarize","title":"Summarize","text":"<p>Labridge uses LLM to summarize the <code>MainText</code> and <code>Methods</code> sections of each paper added to the  shared literature database and constructs a corresponding SummaryVectorIndex. The summary of the <code>MainText</code> focuses on the overall content of the article, main innovations, etc.,  while the summary of the <code>Methods</code> focuses on the technical approaches used in the article.</p> <ul> <li>Refer to Code docs <code>Func_modules.paper.synthesizer.summarize</code> for details about content summarizing.</li> <li>Refer to Code docs <code>Func_modules.paper.store.paper_store</code> for details about the constructed SummaryVectorIndex. </li> <li>The prompts for summarizing <code>MainText</code> and <code>Methods</code> is shown in  Code <code>func_modules.paper.prompt.synthesize.paper_summarize</code></li> </ul>"},{"location":"en/function_modules/paper/shared_papers/store/#summarize-the-paper-directories","title":"Summarize the paper directories","text":"<p>Labridge uses LLM to recursively generate summaries for each level of the paper repository\u2019s directory,  such as the research fields involved in the papers under each directory.  This information serves as an important reference for Labridge to recommend papers to lab members  and to insert new papers into the shared paper repository.</p> <p>For details about summarizing the paper directories, refer to Code docs <code>Func_modules.paper.store.paper_store</code></p>"},{"location":"en/function_modules/paper/shared_papers/store/#shared-paper-note-vector-database","title":"Shared paper note vector database","text":"<p>The shared paper note vector database is structured as follows. It is structured as a flatten tree, nodes in the first layer record the paper DOI. Each DOI node represents a unique paper. The child nodes of a DOI node record non-overlapped paper content chunks with short length, for the sake of a fine-grained retrieval. The bottom nodes record the notes of users.</p> <p></p>"},{"location":"en/function_modules/paper/temporary_papers/","title":"Personal recent paper database","text":"<p>Labridge provides each member of the laboratory with an independent recent paper database.  This database stores papers downloaded with the assistance of Labridge, as well as papers uploaded by the members.  The recent paper database is regularly cleaned. If permanent storage is needed, members can request Labridge to  store valuable papers in the laboratory\u2019s shared paper database.</p>"},{"location":"en/function_modules/paper/temporary_papers/#construction","title":"Construction","text":"<p>Structure of recent paper database</p>"},{"location":"en/function_modules/paper/temporary_papers/#retrieval","title":"Retrieval","text":"<p>Retrieval in recent paper database</p>"},{"location":"en/function_modules/paper/temporary_papers/retrieve/","title":"Retrieval of personal recent papers","text":"<p>For the retrieval of personal  recent paper database, we also use a multi-level hybrid search.  The usage scenario for personal recent paper database is more focused on inquiries about a specific paper,  with high requirements for timeliness. Therefore, we adopt a strategy of fuzzy search to locate the paper range,  followed by further similarity search.</p> <p></p>"},{"location":"en/function_modules/paper/temporary_papers/retrieve/#fuzzy-search-to-determine-the-document-range","title":"Fuzzy search to determine the document range","text":"<p>Firstly, Labridge will determine the general information (PaperInfo) of  the required paper (such as title, file path, etc.) from the tool invocation logs and chat records.  Based on this PaperInfo, Labridge performs a similarity search in the personal temporary document library to  obtain relevant nodes.  The documents to which these nodes belong will be the search range for the next step of Labridge\u2019s retrieval.</p>"},{"location":"en/function_modules/paper/temporary_papers/retrieve/#timestamp-filtering","title":"Timestamp filtering","text":"<p>Labridge can provide start and end times to further narrow the search range.</p>"},{"location":"en/function_modules/paper/temporary_papers/retrieve/#further-retrieval","title":"Further retrieval","text":"<p>In this retrieval step, Labridge conducts similarity searches within the scope of papers identified in the previous step,  based on the user\u2019s search text.  It then obtains the most relevant content nodes (doc nodes) from these papers.</p>"},{"location":"en/function_modules/paper/temporary_papers/retrieve/#add-context","title":"Add context","text":"<p>You can choose to add context to the retrieved results and pass them as the final result to the LLM  to avoid incomplete content caused by text chunking.</p>"},{"location":"en/function_modules/paper/temporary_papers/store/","title":"Structure of personal recent paper database","text":"<p>Each personal recent paper database is a vector database.</p> <p></p> <ul> <li>The original files of a user-specific recent paper database are stored in <code>documents\\tmp_papers\\{user_id}</code></li> <li>Each recent paper database has a root node, and all paper nodes are child nodes of the root node.</li> <li>The ID of a paper node is the absolute path of the document file.  Additional information includes the time (<code>date</code> <code>time</code>) when the file was stored in the recent paper repository.  Timestamp information can be used for time filtering during retrieval.</li> <li>All content nodes (doc nodes) of each paper are inserted as child nodes of the corresponding paper node.</li> <li>If the member calls the paper summary tool, the corresponding literature summary text will be added as a child node  to the corresponding paper node.</li> </ul>"},{"location":"en/function_modules/paper/temporary_papers/download/arXiv/","title":"Search &amp; Download from arXiv","text":"<p>Labridge use the API provided by arXiv to asynchronously search and get papers from arXiv.org.</p> <p>Refer to Code docs <code>Fun_modules.paper.download.arxiv</code></p>"},{"location":"en/function_modules/reference/","title":"Reference files","text":"<p>In order to ensure the credibility and accuracy of Labridge\u2019s responses, when invoking retrieval-related tools,  the tool will also return reference document information. </p> <p>Additionally, Labridge\u2019s goal is not only to provide correct results but also to promote the flow of knowledge,  making reference documents essential.</p> <ul> <li>Reference papers</li> <li>Reference document docs</li> </ul>"},{"location":"en/function_modules/reference/instrument_reference/","title":"Reference instrument document","text":"<p>The Reference info of an instrument document includes:</p> <ul> <li>instrument name</li> <li>Super Users of the instrument</li> </ul>"},{"location":"en/function_modules/reference/paper_reference/","title":"Reference paper","text":"<p>The Reference info of a paper includes\uff1a</p> <ul> <li>Title of the paper</li> <li>Path of the paper</li> <li>The owner of the paper</li> </ul>"},{"location":"en/interface/app/","title":"App user interface","text":"<p>We provide an App for the interaction between users and Labridge, as shown below.</p> <p></p>"},{"location":"en/interface/app/#multimedia-interaction","title":"Multimedia interaction","text":"<p>Labridge supports multimedia interaction with users, such as text, speech, and files.</p> <p>Labridge provides developer mode that makes users available to intervening the agent's thoughts and actions.</p> <p> </p>"},{"location":"en/interface/app/#description-of-app-codes-and-compilation","title":"Description of App codes and compilation","text":""},{"location":"en/interface/server-client/","title":"Description for the communication between the Server and Client","text":""},{"location":"en/interface/server-client/#data-structure","title":"Data Structure","text":""},{"location":"en/interface/server-client/#data-updated-by-clients","title":"Data updated by clients\uff1a","text":""},{"location":"en/interface/server-client/#chat-with-text","title":"Chat with text:","text":"<p>ClientTextReq: - text (str): The message string of the user</p> <p>Post URL: <code>/users/{user_id}/chat_text</code></p>"},{"location":"en/interface/server-client/#download-file","title":"Download File:","text":"<p>ClientDownloadReq: - filepath (str): The path of the requested file</p> <p>Post URL: <code>/users/{user_id}/files/bytes</code></p>"},{"location":"en/interface/server-client/#chat-with-file","title":"Chat with file:","text":"<ul> <li>file (bytes): The bytes of the uploaded file.</li> <li>file_name (str): The name of the uploaded file (including suffix)</li> <li>text (str): The user's attached text</li> <li>reply_in_speech (bool): Whether the user expect reply in speech or not</li> </ul> <p>Post URL: <code>/users/{user_id}/chat_with_file</code></p>"},{"location":"en/interface/server-client/#chat-with-speech","title":"Chat with speech:","text":"<ul> <li>file (bytes): The bytes of the speech file</li> </ul> <p>Post URL: <code>/users/{user_id}/chat_speech</code></p>"},{"location":"en/interface/server-client/#get-reply-from-the-server","title":"Get reply from the server:","text":"<p>Get URL: <code>/users/{user_id}/response</code></p>"},{"location":"en/interface/server-client/#returned-data-structure","title":"Returned data structure","text":"<p>ServerReply: - reply_text (str): The reply string of the agent - valid (bool): Whether this reply is valid. If it is invalid, the client should keep requesting until receiving a valid response. - references (Dict[str, int]): Key -- the path of the reference file, Value -- the file size of the ref file - error (str): The error message. If no error occurs, it is <code>None</code> - inner_chat (bool): Whether this reply is an <code>inner</code> reply. If <code>True</code>, the client should send the user's next message to the corresponding <code>Inner</code> URL.</p> <p>ServerSpeechReply: - reply_speech (str): The file path of the agent's speech reply - valid (bool):  Whether this reply is valid. If it is invalid, the client should keep requesting until receiving a valid response. - references (Dict[str, int]): Key -- the path of the reference file, Value -- the file size of the ref file - inner_chat: Optional[bool]: Whether this reply is an <code>inner</code> reply. If <code>True</code>, the client should send the user's next message to the corresponding <code>Inner</code> URL. - error (str): The error message. If no error occurs, it is <code>None</code></p>"},{"location":"en/interface/server-client/#corresponding-inner-url","title":"Corresponding Inner URL:","text":""},{"location":"","title":"Labridge","text":""},{"location":"#_1","title":"\u201d\u200b\u6c47\u200b\u6d93\u6ef4\u200b\u4ee5\u6210\u200b\u6c5f\u6d77\u200b\u201c","text":"<p>Labridge \u200b\u5e0c\u671b\u200b\u80fd\u4e3a\u200b\u6240\u6709\u200b\u7684\u200b\u79d1\u5b66\u200b\u5b9e\u9a8c\u5ba4\u200b\u642d\u5efa\u200b\u6c9f\u901a\u200b\u4e0e\u200b\u5408\u4f5c\u200b\u7684\u200b\u6865\u6881\u200b\uff0c\u200b\u63d0\u9ad8\u200b\u79d1\u7814\u200b\u5de5\u4f5c\u8005\u200b\u7684\u200b\u6548\u7387\u200b\uff0c\u200b\u50ac\u5316\u200b\u65b0\u200b\u77e5\u8bc6\u200b\u7684\u200b\u8bde\u751f\u200b\u3002</p> <p></p>"},{"location":"agent_tools/prompt_framework/","title":"Agent\u200b\u63d0\u793a\u200b\u8bcd\u200b\u6846\u67b6","text":"<p>\u200b\u6211\u4eec\u200b\u91c7\u7528\u200b\u4e86\u200b CoT(Chain of Thought) + ReAct(Reasoning &amp; Acting) \u200b\u63d0\u793a\u200b\u8bcd\u200b\u6846\u67b6\u200b\uff0c \u200b\u5e76\u4e14\u200bLabridge\u200b\u5728\u200b Reasoning phase \u200b\u548c\u200b Acting phase \u200b\u4e2d\u200b\uff0c\u200b\u4e3a\u200b\u63d0\u4f9b\u200b\u7528\u6237\u200b\u8fdb\u884c\u200b\u4ecb\u5165\u200b\u7684\u200b\u63a5\u53e3\u200b\uff0c\u200b\u4f7f\u5f97\u200b\u7528\u6237\u200b\u53ef\u4ee5\u200b\u53c2\u4e0e\u200b \u200b\u5230\u200bAgent\u200b\u7684\u200b\u601d\u8003\u200b\u4e0e\u200b\u51b3\u7b56\u200b\u7684\u200b\u8fc7\u7a0b\u200b\u4e2d\u200b\u53bb\u200b\uff0c\u200b\u5bf9\u200bAgent\u200b\u7684\u200b\u884c\u4e3a\u200b\u63d0\u4f9b\u200b\u7ec6\u7c92\u5ea6\u200b\u7684\u200b\u63a7\u5236\u200b\u3002 \u200b\u6211\u4eec\u200b\u79f0\u4e4b\u4e3a\u200b <code>InstructReAct</code></p> <p>\u200b\u793a\u4f8b\u200b\uff1a\u200b\u4ecb\u5165\u200bAgent\u200b\u7684\u200bReasoning &amp; Acting</p> <ul> <li>\u200b\u6307\u4ee4\u200b\u6a21\u5f0f\u200b</li> <li>\u200b\u6307\u4ee4\u200b\u6a21\u5f0f\u200b &amp; \u200b\u8bc4\u8bba\u200b\u6a21\u5f0f\u200b</li> </ul>"},{"location":"agent_tools/prompt_framework/#react","title":"ReAct\u200b\u63d0\u793a\u200b\u8bcd","text":"<pre><code>Your role is that of a research assistant in the laboratory. \nYou will assist the researchers in various aspects of their research, \nincluding helping with research paper reading, research paper retrieval, paper downloading and \nmanagement, integration of laboratory instrument information, recording and retrieval of experimental logs, \nas well as any other aspects that contribute to scientific research.\n\n## Tools\nYou have access to a wide variety of tools. You are responsible for using\nthe tools in any sequence you deem appropriate to complete the task at hand.\nThis may require breaking the task into subtasks and using different tools\nto complete each subtask.\n\nYou have access to the following tools:\n{tool_desc}\n\nyou must follow the instruction below:\n\nTo answer the question using extra tools, think step-by-step, and please use the following format.\n\nThought: Think step-by-step, In order to answer the overall question, given the executed actions and their observations, \n    What's my target in this step? Which tool should I use to help me accomplish this target?\nAction: tool name (one of {tool_names}) if using a tool.\nAction Input: the input to the tool, in a JSON format representing the kwargs (e.g. {{\"input\": \"hello world\", \"num_beams\": 5}})\n\nPlease ALWAYS start with a Thought.\n\nWhen you decide to call a tool, you should strictly follow the format above.\nAdditionally, you MUST NOT user the JSON formatted tool call as your final answer.\nPlease use a valid JSON format for the Action Input. Do NOT do this {{'input': 'hello world', 'num_beams': 5}}.\n\n\nIf this format is used, the user will respond in the following format:\n\nObservation: tool response\n\n## Output Format\n\nWhen you decide to answer, you MUST respond in the one of the following two formats:\nYou MUST return valid and direct response that can answer the user's question, DO NOT output the Tool Call.\n\nThought: I have complete all the sub-tasks and I can answer without using any more tools. \nAnswer: [your answer here]\n\nThought: I cannot answer the question with the provided tools.\nAnswer: Sorry, I cannot answer your query.\n\n## Current Conversation\nBelow is the current conversation consisting of interleaving human and assistant messages.\n</code></pre>"},{"location":"agent_tools/prompt_framework/#instruct","title":"Instruct\u200b\u63d0\u793a\u200b\u8bcd","text":"<pre><code>Your role is that of a research assistant in the laboratory. \nYou will assist the researchers in various aspects of their research, \nincluding helping with research paper reading, research paper retrieval, paper downloading and \nmanagement, integration of laboratory instrument information, recording and retrieval of experimental logs, \nas well as any other aspects that contribute to scientific research.\n\n## Tools\nYou have access to a wide variety of tools. You are responsible for using\nthe tools in any sequence you deem appropriate to complete the task at hand.\nThis may require breaking the task into subtasks and using different tools\nto complete each subtask.\n\nYou have access to the following tools:\n{tool_desc}\n\nSeveral tools have been previously chose by another assistant:\nPrevious choice: {prev_response}\n\nThe User gives some suggestions to the previously selected action:\nUser suggestion: {suggestion}\n\nNow you should adopt the user's suggestions to optimize the tool choices to better answer the question.\nIf the user gives no valid suggestion, or agrees with the previous selected action,\nno modification is needed, just use the previous selected action.\n\nyou must follow the instruction below:\n\n## Output Format\nplease use the following format.\n\nThought: Given the previous action: {prev_response}, Following the user's suggestions: {suggestion}, \ndo I need to modify my action? If need, how should I adjust my action to meet the user's requirements better?\nAction: tool name (one of {tool_names}) if using a tool.\nAction Input: the input to the tool, in a JSON format representing the kwargs (e.g. {{\"input\": \"hello world\", \"num_beams\": 5}})\n\nPlease ALWAYS start with a Thought.\n\nPlease use a valid JSON format for the Action Input. Do NOT do this {{'input': 'hello world', 'num_beams': 5}}.\n\nIf this format is used, the user will respond in the following format:\n\n## Current Conversation\nBelow is the current conversation consisting of interleaving human and assistant messages.\n</code></pre>"},{"location":"agent_tools/tools/","title":"Agent\u200b\u53ef\u200b\u8c03\u7528\u200b\u5de5\u5177","text":"<p>Labridge\u200b\u76ee\u524d\u200b\u53ef\u200b\u8c03\u7528\u200b\u5982\u4e0b\u200b\u5de5\u5177\u200b\uff1a</p> <ul> <li>SharedPaperRetrieverTool</li> <li>RecentPaperRetrieveTool</li> <li>RecentPaperSummarizeTool</li> <li>ArXivSearchDownloadTool</li> <li>AddNewRecentPaperTool</li> <li>ExperimentLogRetrieveTool</li> <li>CreateNewExperimentLogTool</li> <li>SetCurrentExperimentTool</li> <li>RecordExperimentLogTool</li> <li>ChatMemoryRetrieverTool</li> </ul> <p>\u200b\u6240\u6709\u200b\u9700\u8981\u200b\u5b9e\u9a8c\u5ba4\u200b\u6210\u5458\u200b\u6388\u6743\u200b\u7684\u200b\u64cd\u4f5c\u200b\u88ab\u200b\u5b9a\u4e49\u200b\u4e3a\u200b CallbackOperation,  \u200b\u5982\u200b\u521b\u5efa\u200b\u5b9e\u9a8c\u200b\u8bb0\u5f55\u200b\u3001\u200b\u4e0b\u8f7d\u200b\u6587\u732e\u200b\u7b49\u200b\u3002 CallbackOperation \u200b\u7684\u200b\u5177\u4f53\u200b\u5b9a\u4e49\u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Callback.base.operation_base</code></p> <p>\u200b\u76ee\u524d\u200b\u7684\u200b CallbackOperation \u200b\u5305\u62ec\u200b\uff1a</p> <ul> <li>ArxivDownloadOperation \u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Callback.paper.paper_download</code></li> <li>AddNewRecentPaperOperation \u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Callback.paper.add_recent_paper</code></li> <li>PaperSummarizeOperation \u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Callback.paper.paper_summarize</code></li> <li>CreateNewExperimentLogOperation \u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Callback.experiment_log.new_experiment</code></li> <li>SetCurrentExperimentOperation \u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Callback.experiment_log.set_current_experiment</code></li> </ul> <p>\u200b\u6211\u4eec\u200b\u63d0\u4f9b\u200b\u5982\u4e0b\u200b\u5de5\u5177\u200b\u6a21\u677f\u200b\uff0c\u200b\u7528\u4ee5\u200b\u5f00\u53d1\u200b\u7b26\u5408\u200b </p> <p>\u201c\u200b\u6536\u96c6\u200b\u7528\u6237\u200b\u4fe1\u606f\u200b \u2192 \u200b\u5b9a\u4e49\u200b\u6267\u884c\u200b\u64cd\u4f5c\u200b \u2192 \u200b\u5f81\u53d6\u200b\u7528\u6237\u200b\u6388\u6743\u200b \u2192 \u200b\u6267\u884c\u200bCallback\u200b\u64cd\u4f5c\u200b\u201d </p> <p>\u200b\u6d41\u7a0b\u200b\u7684\u200b\u5de5\u5177\u200b</p> <ul> <li>CollectAndAuthorizeTool</li> </ul>"},{"location":"agent_tools/tools/base/tool_base/","title":"\u5404\u79cd\u200bTools\u200b\u7684\u200b\u57fa\u7c7b","text":""},{"location":"agent_tools/tools/base/tool_base/#checkbasetool","title":"CheckBaseTool","text":"<p>\u200b\u8fd9\u4e2a\u200b\u5de5\u5177\u200b\u6a21\u677f\u200b\u5b9e\u73b0\u200b\u4e86\u200b\u4ece\u200b\u8f93\u5165\u200b\u53c2\u6570\u200b\u4e2d\u200b\u68c0\u67e5\u200b\u4e0e\u200b\u83b7\u53d6\u200b\u6240\u200b\u9700\u200b\u53c2\u6570\u200b\u7684\u200b\u529f\u80fd\u200b\u3002</p> <p>\u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Tools.base.tool_base</code></p>"},{"location":"agent_tools/tools/base/tool_base/#retrieverbasetool","title":"RetrieverBaseTool","text":"<p>\u200b\u8fd9\u4e2a\u200b\u5de5\u5177\u200b\u6a21\u677f\u200b\u5b9e\u73b0\u200b\u4e86\u200b\u4f7f\u7528\u200b\u6240\u200b\u7ed9\u200bRetriever\u200b\u8fdb\u884c\u200b\u68c0\u7d22\u200b\uff0c\u200b\u5e76\u200b\u8bb0\u5f55\u200b\u53c2\u8003\u200b\u6587\u6863\u200b\u7b49\u200b\u5de5\u5177\u200b\u65e5\u5fd7\u200b\u7684\u200b\u529f\u80fd\u200b\u3002</p> <p>\u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Tools.base.tool_base</code></p>"},{"location":"agent_tools/tools/base/tool_base/#queryenginebasetool","title":"QueryEngineBaseTool","text":"<p>\u200b\u8fd9\u4e2a\u200b\u5de5\u5177\u200b\u6a21\u677f\u200b\u5b9e\u73b0\u200b\u4e86\u200b\u57fa\u4e8e\u200b\u5411\u91cf\u200b\u6570\u636e\u5e93\u200b\u8fdb\u884c\u200b\u95ee\u7b54\u200b\u7684\u200b\u529f\u80fd\u200b</p> <p>\u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Tools.base.tool_base</code></p>"},{"location":"agent_tools/tools/base/tool_base/#functionbasetool","title":"FunctionBaseTool","text":"<p>\u200b\u8fd9\u4e2a\u200b\u5de5\u5177\u200b\u6a21\u677f\u200b\u5b9e\u73b0\u200b\u4e86\u200b\u8c03\u7528\u200b\u6307\u5b9a\u200b\u51fd\u6570\u200b\u6216\u7c7b\u200b\u65b9\u6cd5\u200b\uff0c\u200b\u5e76\u200b\u8bb0\u5f55\u200b\u5de5\u5177\u200b\u65e5\u5fd7\u200b\u7684\u200b\u529f\u80fd\u200b</p>"},{"location":"agent_tools/tools/base/tool_log/","title":"\u5de5\u5177\u200b\u8c03\u7528\u200b\u65e5\u5fd7","text":""},{"location":"agent_tools/tools/base/tool_log/#toollog","title":"ToolLog","text":"<p>\u200b\u8fd9\u4e2a\u200b\u7c7b\u200b\u8bb0\u5f55\u200b\u67d0\u4e2a\u200b\u5de5\u5177\u200b\u8c03\u7528\u200b\u7684\u200b\u65e5\u5fd7\u200b\uff0c\u200b\u5305\u542b\u200b\u5982\u4e0b\u200b\u4fe1\u606f\u200b\uff1a</p> <ul> <li>tool_name: \u200b\u8c03\u7528\u200b\u7684\u200b\u5de5\u5177\u200b\u540d\u79f0\u200b</li> <li>log_to_user: \u200b\u8fd9\u90e8\u5206\u200b\u65e5\u5fd7\u200b\u5c06\u4f1a\u200b\u4f5c\u4e3a\u200b\u989d\u5916\u200b\u4fe1\u606f\u200b\u52a0\u200b\u5728\u200bLabridge\u200b\u5bf9\u200b\u7528\u6237\u200b\u56de\u590d\u200b\u7684\u200b\u672b\u5c3e\u200b</li> <li>log_to_system: \u200b\u8fd9\u90e8\u5206\u200b\u65e5\u5fd7\u200b\u5c06\u200b\u5b58\u50a8\u200b\u4e8e\u200b\u7528\u6237\u200b\u7684\u200b\u4ea4\u4e92\u200b\u65e5\u5fd7\u200b\u6570\u636e\u5e93\u200b</li> </ul> <p>\u200b\u5177\u4f53\u200b\u7ec6\u8282\u200b\u8bf7\u200b\u53c2\u8003\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Tools.base.tool_log</code></p>"},{"location":"agent_tools/tools/chat_history/chat_memory_retrieve_tool/","title":"SharedPaperRetrieverTool","text":"<p>\u200b\u8fd9\u4e2a\u200b\u5de5\u5177\u200b\u7528\u4e8e\u200b\u4ece\u200b\u5b9e\u9a8c\u5ba4\u200b\u5171\u4eab\u200b\u6587\u732e\u200b\u5e93\u4e2d\u200b\u68c0\u7d22\u200b\u76f8\u5173\u200b\u4fe1\u606f\u200b\u3002</p>"},{"location":"agent_tools/tools/chat_history/chat_memory_retrieve_tool/#_1","title":"\u8c03\u7528\u200b\u53c2\u6570","text":"<ul> <li>item_to_be_retrieved (str): \u200b\u5f85\u200b\u68c0\u7d22\u200b\u4fe1\u606f\u200b</li> <li>memory_id (str): \u200b\u6210\u5458\u200b\u540d\u200b\u6216\u200b\u6210\u5458\u200b\u5c0f\u7ec4\u200b\u540d\u200b</li> <li>start_date (Optional[str]): \u200b\u65f6\u95f4\u200b\u8fc7\u6ee4\u200b\u7684\u200b\u5f00\u59cb\u200b\u65e5\u671f\u200b</li> <li>end_date (Optional[str]): \u200b\u65f6\u95f4\u200b\u8fc7\u6ee4\u200b\u7684\u200b\u7ed3\u675f\u200b\u65e5\u671f\u200b</li> <li>kwargs (Any): \u200b\u63d0\u9ad8\u200b LLM \u200b\u8c03\u7528\u200b\u672c\u200b\u5de5\u5177\u200b\u7684\u200b\u5bb9\u9519\u200b</li> </ul>"},{"location":"agent_tools/tools/chat_history/chat_memory_retrieve_tool/#_2","title":"\u5de5\u5177\u200b\u63cf\u8ff0","text":"<pre><code>This tool is used to retrieve relevant chat history in a certain chat history memory.\nThe memory_id of a chat history memory is the `user_id` of a specific user or the `chat_group_id` of a specific\nchat group.\n\nAdditionally, you can provide the `start_date` and `end_state` to limit the retrieving range of date,\nThe end date can be the same as the start date, but should not be earlier than the start date.\nIf the start date or end_date is not provided, retrieving will be performed among the whole memory.\n\nArgs:\n    item_to_be_retrieved (str): Things that you want to retrieve in the chat history memory.\n    memory_id (str): The memory_id of a chat history memory. It is either a `user_id` or a `chat_group_id`.\n    start_date (str): The START date of the retrieving date limit. Defaults to None.\n        If given, it should be given in the following FORMAT: Year-Month-Day.\n        For example, 2020-12-1 means the year 2020, the 12th month, the 1rst day.\n    end_date (str): The END date of the retrieving date limit. Defaults to None.\n        If given, It should be given in the following FORMAT: Year-Month-Day.\n        For example, 2024-6-2 means the year 2024, the 6th month, the 2nd day.\n\nReturns:\n    Retrieved chat history.\n</code></pre> <p>\u200b\u8be6\u7ec6\u200b\u5185\u5bb9\u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Tools.memory.chat.retrieve</code></p>"},{"location":"agent_tools/tools/experiment_log/create_new_experiment_log/","title":"CreateNewExperimentLogTool","text":"<p>\u200b\u8fd9\u4e2a\u200b\u5de5\u5177\u200b\u7528\u4e8e\u200b\u4e3a\u200b\u67d0\u4e2a\u200b\u6210\u5458\u200b\u5728\u200b\u5176\u200b\u5b9e\u9a8c\u200b\u65e5\u5fd7\u200b\u6570\u636e\u5e93\u200b\u4e2d\u200b\u65b0\u5efa\u200b\u5b9e\u9a8c\u200b\u8bb0\u5f55\u200b\u3002</p> <p>\u200b\u6ce8\u200b\uff1a\u200b\u8fd9\u4e2a\u200b\u5de5\u5177\u200b\u662f\u200b\u4e00\u4e2a\u200b <code>CollectAndAuthorizeTool</code> \u200b\u6a21\u677f\u200b\u5de5\u5177\u200b\uff0c\u200b\u9700\u8981\u200b\u6536\u96c6\u200b\u7528\u6237\u200b\u4fe1\u606f\u200b\u4ee5\u53ca\u200b\u83b7\u53d6\u200b\u7528\u6237\u200b\u6388\u6743\u200b\u3002</p>"},{"location":"agent_tools/tools/experiment_log/create_new_experiment_log/#_1","title":"\u8c03\u7528\u200b\u53c2\u6570","text":"<ul> <li>user_id (str): \u200b\u6210\u5458\u200b\u540d\u200b</li> </ul>"},{"location":"agent_tools/tools/experiment_log/create_new_experiment_log/#_2","title":"\u5de5\u5177\u200b\u63cf\u8ff0","text":"<pre><code>This tool is used to create a new experiment log record for the user.\nThis tool is only used when the user asks for creating a new experiment log record,\nor when other tools call this tool.\n\nArgs:\n    user_id (str): The user_id of a lab member.\n\nReturns:\n    The tool's output and log.\n</code></pre> <p>\u200b\u8be6\u7ec6\u200b\u5185\u5bb9\u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Tools.memory.experiment.insert</code></p>"},{"location":"agent_tools/tools/experiment_log/experiment_log_retrieve_tool/","title":"ExperimentLogRetrieveTool","text":"<p>\u200b\u8fd9\u4e2a\u200b\u5de5\u5177\u200b\u7528\u4e8e\u200b\u4ece\u200b\u67d0\u4e2a\u200b\u6210\u5458\u200b\u7684\u200b\u5b9e\u9a8c\u200b\u65e5\u5fd7\u200b\u6570\u636e\u5e93\u200b\u4e2d\u200b\u68c0\u7d22\u200b\u76f8\u5173\u200b\u4fe1\u606f\u200b\u3002</p>"},{"location":"agent_tools/tools/experiment_log/experiment_log_retrieve_tool/#_1","title":"\u8c03\u7528\u200b\u53c2\u6570","text":"<ul> <li>item_to_be_retrieved (str): \u200b\u5f85\u200b\u68c0\u7d22\u200b\u4fe1\u606f\u200b</li> <li>memory_id (str): \u200b\u6210\u5458\u200b\u540d\u200b</li> <li>start_date (Optional[str]): \u200b\u65f6\u95f4\u200b\u8fc7\u6ee4\u200b\u7684\u200b\u5f00\u59cb\u200b\u65e5\u671f\u200b</li> <li>end_date (Optional[str]): \u200b\u65f6\u95f4\u200b\u8fc7\u6ee4\u200b\u7684\u200b\u7ed3\u675f\u200b\u65e5\u671f\u200b</li> <li>experiment_name (Optional[str]): \u200b\u6307\u5b9a\u200b\u5b9e\u9a8c\u200b\u540d\u79f0\u200b\uff0c\u200b\u9650\u5236\u200b\u68c0\u7d22\u200b\u8303\u56f4\u200b</li> <li>kwargs (Any): \u200b\u63d0\u9ad8\u200b LLM \u200b\u8c03\u7528\u200b\u672c\u200b\u5de5\u5177\u200b\u7684\u200b\u5bb9\u9519\u200b</li> </ul>"},{"location":"agent_tools/tools/experiment_log/experiment_log_retrieve_tool/#_2","title":"\u5de5\u5177\u200b\u63cf\u8ff0","text":"<pre><code>This tool is used to retrieve experiment logs of a user.\nUse this tool to help you to answer questions about experimental records.\n\nArgs:\n    item_to_be_retrieved (str): This argument is necessary.\n        It denotes things that you want to retrieve in the chat history memory.\n    memory_id (str): This argument is necessary.\n        It is the user_id of a lab member.\n    start_date (str): This argument is optional.\n        It denotes the start date in the format 'Year-Month-Day'.\n        If both start_date and end_date are specified, only logs which are recorded between the\n        start_date and end_date will be retrieved.\n    end_date (str): This argument is optional.\n        It denotes the end date in the format 'Year-Month-Day'.\n    experiment_name (str): This argument is optional.\n        It is the name of a specific experiment.\n        If it is specified and is valid, only logs of this experiment will be retrieved.\n    kwargs: Other arguments will be ignored.\n\nReturns:\n    Retrieved experiment logs.\n</code></pre> <p>\u200b\u8be6\u7ec6\u200b\u5185\u5bb9\u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Tools.memory.experiment.retrieve</code></p>"},{"location":"agent_tools/tools/experiment_log/record_experiment_log_tool/","title":"RecordExperimentLogTool","text":"<p>\u200b\u8fd9\u4e2a\u200b\u5de5\u5177\u200b\u7528\u4e8e\u200b\u4e3a\u200b\u67d0\u4e2a\u200b\u6210\u5458\u200b\u8bb0\u5f55\u200b\u5b9e\u9a8c\u200b\u65e5\u5fd7\u200b\u3002</p>"},{"location":"agent_tools/tools/experiment_log/record_experiment_log_tool/#_1","title":"\u8c03\u7528\u200b\u53c2\u6570","text":"<ul> <li>user_id (str): \u200b\u6210\u5458\u200b\u540d\u200b</li> <li>log_str (str): \u200b\u5b9e\u9a8c\u200b\u65e5\u5fd7\u200b</li> </ul>"},{"location":"agent_tools/tools/experiment_log/record_experiment_log_tool/#_2","title":"\u5de5\u5177\u200b\u63cf\u8ff0","text":"<pre><code>This tool is used to record the experiment log of the experiment in progress for a user.\n\nIf the no experiment record exists or experiment in progress is not valid, this tool will call\nthe corresponding tools to help the user.\n\nArgs:\n    user_id (str): The user_id of a lab member.\n    log_str (str): The experiment log to be recorded.\n\nReturns:\n    The tool output and log.\n</code></pre> <p>\u200b\u8be6\u7ec6\u200b\u5185\u5bb9\u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Tools.memory.experiment.insert</code></p>"},{"location":"agent_tools/tools/experiment_log/set_current_experiment_tool/","title":"SetCurrentExperimentTool","text":"<p>\u200b\u8fd9\u4e2a\u200b\u5de5\u5177\u200b\u7528\u4e8e\u200b\u4e3a\u200b\u67d0\u4e2a\u200b\u6210\u5458\u200b\u8bbe\u7f6e\u200b\u5f53\u524d\u200b\u8fdb\u884c\u200b\u7684\u200b\u5b9e\u9a8c\u200b\uff0c\u200b\u5b9e\u9a8c\u200b\u8fdb\u884c\u200b\u671f\u95f4\u200b\u7684\u200b\u65e5\u5fd7\u200b\u5c06\u4f1a\u200b\u6dfb\u52a0\u200b\u5728\u200b\u8be5\u200b\u5b9e\u9a8c\u200b\u7684\u200b\u5bf9\u5e94\u200b\u8bb0\u5f55\u200b\u4e2d\u200b\u3002</p> <p>\u200b\u6ce8\u200b\uff1a\u200b\u8fd9\u4e2a\u200b\u5de5\u5177\u200b\u662f\u200b\u4e00\u4e2a\u200b <code>CollectAndAuthorizeTool</code> \u200b\u6a21\u677f\u200b\u5de5\u5177\u200b\uff0c\u200b\u9700\u8981\u200b\u6536\u96c6\u200b\u7528\u6237\u200b\u4fe1\u606f\u200b\u4ee5\u53ca\u200b\u83b7\u53d6\u200b\u7528\u6237\u200b\u6388\u6743\u200b\u3002</p>"},{"location":"agent_tools/tools/experiment_log/set_current_experiment_tool/#_1","title":"\u8c03\u7528\u200b\u53c2\u6570","text":"<ul> <li>user_id (str): \u200b\u6210\u5458\u200b\u540d\u200b</li> </ul>"},{"location":"agent_tools/tools/experiment_log/set_current_experiment_tool/#_2","title":"\u5de5\u5177\u200b\u63cf\u8ff0","text":"<pre><code>This tool is used to record the experiment log of the experiment in progress for a user.\n\nIf the no experiment record exists or experiment in progress is not valid, this tool will call\nthe corresponding tools to help the user.\n\nArgs:\n    user_id (str): The user_id of a lab member.\n    log_str (str): The experiment log to be recorded.\n\nReturns:\n    The tool output and log.\n</code></pre> <p>\u200b\u8be6\u7ec6\u200b\u5185\u5bb9\u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Tools.memory.experiment.insert</code></p>"},{"location":"agent_tools/tools/interact/collect_and_authorize_tool/","title":"CollectAndAuthorizeTool","text":"<p>\u200b\u8fd9\u662f\u200b\u4e00\u4e2a\u200b\u5de5\u5177\u200b\u6a21\u677f\u200b\uff0c\u200b\u5728\u200b\u6b64\u57fa\u7840\u200b\u4e0a\u200b\u5f00\u53d1\u200b\u7b26\u5408\u200b \u201c\u200b\u6536\u96c6\u200b\u7528\u6237\u200b\u4fe1\u606f\u200b \u2192 \u200b\u5b9a\u4e49\u200b\u6267\u884c\u200b\u64cd\u4f5c\u200b \u2192 \u200b\u5f81\u53d6\u200b\u7528\u6237\u200b\u6388\u6743\u200b \u2192 \u200b\u6267\u884c\u200bCallback\u200b\u64cd\u4f5c\u200b\u201d \u200b\u6d41\u7a0b\u200b\u7684\u200b\u5de5\u5177\u200b</p> <p>\u200b\u8be6\u7ec6\u200b\u5185\u5bb9\u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Tools.interact.collect_and_authorize</code></p> <p></p>"},{"location":"agent_tools/tools/shared_papers/shared_paper_retrieve_tool/","title":"SharedPaperRetrieverTool","text":"<p>\u200b\u8fd9\u4e2a\u200b\u5de5\u5177\u200b\u7528\u4e8e\u200b\u4ece\u200b\u5b9e\u9a8c\u5ba4\u200b\u5171\u4eab\u200b\u6587\u732e\u200b\u4fe1\u606f\u5e93\u200b\u4e2d\u200b\u68c0\u7d22\u200b\u76f8\u5173\u200b\u4fe1\u606f\u200b\u3002</p>"},{"location":"agent_tools/tools/shared_papers/shared_paper_retrieve_tool/#_1","title":"\u8c03\u7528\u200b\u53c2\u6570","text":"<ul> <li>item_to_be_retrieved (str): \u200b\u5f85\u200b\u68c0\u7d22\u200b\u4fe1\u606f\u200b</li> </ul>"},{"location":"agent_tools/tools/shared_papers/shared_paper_retrieve_tool/#_2","title":"\u5de5\u5177\u200b\u63cf\u8ff0","text":"<pre><code>This tool is used to retrieve academic information in the Laboratory's shared paper database.\nIt is useful to help answer the user's academic questions.\n\nArgs:\n    item_to_be_retrieved (str): The things that you want to retrieve in the shared paper database.\n</code></pre> <p>\u200b\u8be6\u7ec6\u200b\u5185\u5bb9\u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Tools.paper.shared_papers.retriever</code></p>"},{"location":"agent_tools/tools/temporary_papers/add_new_recent_paper_tool/","title":"AddNewRecentPaperTool","text":"<p>\u200b\u8fd9\u4e2a\u200b\u5de5\u5177\u200b\u7528\u4e8e\u200b\u5411\u200b\u67d0\u4e2a\u200b\u6210\u5458\u200b\u7684\u200b\u8fd1\u671f\u200b\u6587\u732e\u200b\u5e93\u4e2d\u200b\u6dfb\u52a0\u200b\u6587\u732e\u200b\u3002</p>"},{"location":"agent_tools/tools/temporary_papers/add_new_recent_paper_tool/#_1","title":"\u8c03\u7528\u200b\u53c2\u6570","text":"<ul> <li>user_id (str): \u200b\u6210\u5458\u200b\u4fe1\u606f\u200b</li> <li>paper_file_path (str): \u200b\u65b0\u200b\u6587\u732e\u200b\u7684\u200b\u8def\u5f84\u200b</li> </ul>"},{"location":"agent_tools/tools/temporary_papers/add_new_recent_paper_tool/#_2","title":"\u5de5\u5177\u200b\u63cf\u8ff0","text":"<pre><code>This tool is used to add a new paper to a specific user's recent papers storage.\n\nArgs:\n    user_id (str): The user_id of a lab member.\n    paper_file_path (str): The file path of the paper to be added. Browse the chat context or tool logs\n        to get the correct and valid file path.\n\nReturns:\n    FuncOutputWithLog: The output and log.\n</code></pre> <p>\u200b\u8be6\u7ec6\u200b\u5185\u5bb9\u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Tools.paper.temporary_papers.insert</code></p>"},{"location":"agent_tools/tools/temporary_papers/arxiv_search_download_tool/","title":"ArXivSearchDownloadTool","text":"<p>\u200b\u8fd9\u4e2a\u200b\u5de5\u5177\u200b\u7528\u4e8e\u200b\u4e3a\u200b\u67d0\u4e2a\u200b\u6210\u5458\u200b\u4ece\u200barXiv\u200b\u4e0a\u200b\u68c0\u7d22\u200b\u5e76\u200b\u4e0b\u8f7d\u200b\u6587\u732e\u200b\u3002</p> <p>\u200b\u6ce8\u200b\uff1a\u200b\u8fd9\u662f\u200b\u4e00\u4e2a\u200b\u9700\u8981\u200b\u7528\u6237\u200b\u6388\u6743\u200b\u7684\u200b\u5de5\u5177\u200b\u3002</p>"},{"location":"agent_tools/tools/temporary_papers/arxiv_search_download_tool/#_1","title":"\u8c03\u7528\u200b\u53c2\u6570","text":"<ul> <li>user_id (str): \u200b\u6210\u5458\u200b\u540d\u200b</li> <li>search_str (str): \u200b\u5f85\u200b\u68c0\u7d22\u200b\u4fe1\u606f\u200b</li> <li>kwargs (Any): \u200b\u7528\u4e8e\u200b\u63d0\u9ad8\u200b LLM \u200b\u8c03\u7528\u200b\u672c\u200b\u5de5\u5177\u200b\u7684\u200b\u5bb9\u9519\u200b</li> </ul>"},{"location":"agent_tools/tools/temporary_papers/arxiv_search_download_tool/#_2","title":"\u5de5\u5177\u200b\u63cf\u8ff0","text":"<pre><code>This tool is used to search relevant papers in arXiv and download the papers that the user is interested in.\nWhen using the tool, be sure that the search_str MUST be English.\nIf the user do not use English, translate the search string to English first.\n\nArgs:\n    user_id (str): The user_id of a lab member.\n    search_str (str): The string that is used to search in arXiv.\n\nReturns:\n    FuncOutputWithLog: the operation output and log.\n</code></pre> <p>\u200b\u8be6\u7ec6\u200b\u5185\u5bb9\u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Tools.paper.download.arxiv_download</code></p>"},{"location":"agent_tools/tools/temporary_papers/recent_paper_retrieve_tool/","title":"RecentPaperRetrieveTool","text":"<p>\u200b\u8fd9\u4e2a\u200b\u5de5\u5177\u200b\u7528\u4e8e\u200b\u4ece\u200b\u67d0\u4e2a\u200b\u6210\u5458\u200b\u7684\u200b\u8fd1\u671f\u200b\u6587\u732e\u200b\u5e93\u4e2d\u200b\u68c0\u7d22\u200b\u76f8\u5173\u200b\u4fe1\u606f\u200b\u3002</p>"},{"location":"agent_tools/tools/temporary_papers/recent_paper_retrieve_tool/#_1","title":"\u8c03\u7528\u200b\u53c2\u6570","text":"<ul> <li>paper_info (str): \u200b\u76ee\u6807\u200b\u6587\u732e\u200b\u7684\u200b\u76f8\u5173\u200b\u4fe1\u606f\u200b\uff0c\u200b\u5982\u200b\u6807\u9898\u200b\uff0c\u200b\u6587\u4ef6\u200b\u8def\u5f84\u200b\u7b49\u200b</li> <li>item_to_be_retrieved (str): \u200b\u5f85\u200b\u68c0\u7d22\u200b\u4fe1\u606f\u200b</li> <li>user_id (str): \u200b\u6210\u5458\u200b\u540d\u200b</li> <li>start_date (Optional[str]): \u200b\u65f6\u95f4\u200b\u8fc7\u6ee4\u200b\u7684\u200b\u5f00\u59cb\u200b\u65e5\u671f\u200b</li> <li>end_date (Optional[str]): \u200b\u65f6\u95f4\u200b\u8fc7\u6ee4\u200b\u7684\u200b\u7ed3\u675f\u200b\u65e5\u671f\u200b</li> <li>kwargs (Any): \u200b\u7528\u4e8e\u200b\u63d0\u9ad8\u200b LLM \u200b\u8c03\u7528\u200b\u672c\u200b\u5de5\u5177\u200b\u7684\u200b\u5bb9\u9519\u200b</li> </ul>"},{"location":"agent_tools/tools/temporary_papers/recent_paper_retrieve_tool/#_2","title":"\u5de5\u5177\u200b\u63cf\u8ff0","text":"<pre><code>This tool is used to retrieve in the recent papers storage of a specific user.\nThese information should be provided:\n1. The paper information, such as title or save path.\n2. The specific question that you want to obtain answer from the paper.\n3. The user id.\n\nArgs:\n    paper_info (str): This argument is necessary.\n        It is the relevant information of the paper.\n        For example, it can be the paper title, or its save path.\n    item_to_be_retrieved (str): This argument is necessary.\n        It denotes the specific question that you want to retrieve in a specific paper.\n    user_id (str): This argument is necessary.\n        The user_id of a lab member.\n    start_date (str): This argument is optional. It denotes the start date in the format 'Year-Month-Day'.\n        If both start_date and end_date are specified, only papers which are added to storage between the\n        start_date and end_date will be retrieved.\n    end_date: This argument is optional. It denotes the end date in the format 'Year-Month-Day'.\n    **kwargs: Other keyword arguments will be ignored.\n\nReturns:\n    The retrieved results.\n</code></pre> <p>\u200b\u8be6\u7ec6\u200b\u5185\u5bb9\u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Tools.paper.temporary_papers.paper_retriever</code></p>"},{"location":"agent_tools/tools/temporary_papers/recent_paper_summarize_tool/","title":"RecentPaperSummarizeTool","text":"<p>\u200b\u8fd9\u4e2a\u200b\u5de5\u5177\u200b\u7528\u4e8e\u200b\u4e3a\u200b\u67d0\u4e2a\u200b\u6210\u5458\u200b\u603b\u7ed3\u200b\u5176\u200b\u8fd1\u671f\u200b\u6587\u732e\u200b\u5e93\u200b\u7684\u200b\u6587\u732e\u200b\uff0c\u200b\u6216\u200b\u5c06\u200b\u65b0\u200b\u6587\u732e\u200b\u52a0\u5165\u200b\u8fd1\u671f\u200b\u6587\u732e\u200b\u5e93\u200b\u5e76\u200b\u603b\u7ed3\u200b\u3002</p>"},{"location":"agent_tools/tools/temporary_papers/recent_paper_summarize_tool/#_1","title":"\u8c03\u7528\u200b\u53c2\u6570","text":"<ul> <li>user_id (str): \u200b\u6210\u5458\u200b\u540d\u200b</li> <li>paper_file_path (str): \u200b\u5f85\u200b\u603b\u7ed3\u200b\u6587\u732e\u200b\u8def\u5f84\u200b</li> </ul>"},{"location":"agent_tools/tools/temporary_papers/recent_paper_summarize_tool/#_2","title":"\u5de5\u5177\u200b\u63cf\u8ff0","text":"<pre><code>This tool is used to summarize a paper that is stored in a specific user's recent papers storage.\nThis tool is used ONLY when the user explicitly ask for a summarization of the paper.\nDO NOT use this tool by yourself.\n\nArgs:\n    user_id (str): The user_id of a lab member.\n    paper_file_path (str): The file path of a specific paper. Browse the chat context to get the correct\n        and valid file path of the paper.\n\nReturns:\n    The summary of the paper.\n</code></pre> <p>\u200b\u8be6\u7ec6\u200b\u5185\u5bb9\u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Tools.paper.temporary_papers.paper_summarize</code></p>"},{"location":"code_docs/accounts/super_users/","title":"Super users","text":""},{"location":"code_docs/accounts/super_users/#labridge.accounts.super_users","title":"<code>labridge.accounts.super_users</code>","text":""},{"location":"code_docs/accounts/super_users/#labridge.accounts.super_users.InstrumentSuperUserManager","title":"<code>labridge.accounts.super_users.InstrumentSuperUserManager</code>","text":"<p>               Bases: <code>object</code></p> <p>This is the account manager of super-users.</p> <p>Each set of super-users are related to a specific scientific instrument. These super-users own full authority to their instruments, and are responsible for the instrument management such as updating instruction manual, adding a new super-user, etc.</p> <p>The accounts of super-users are stored as a dictionary as follows in a json format. <code>{instrument_id: [super_user_ids, ]}</code></p> Source code in <code>labridge\\accounts\\super_users.py</code> <pre><code>class InstrumentSuperUserManager(object):\n\tr\"\"\"\n\tThis is the account manager of super-users.\n\n\tEach set of super-users are related to a specific scientific instrument.\n\tThese super-users own full authority to their instruments, and are responsible for the instrument management such as\n\tupdating instruction manual, adding a new super-user, etc.\n\n\tThe accounts of super-users are stored as a dictionary as follows in a json format.\n\t`{instrument_id: [super_user_ids, ]}`\n\t\"\"\"\n\tdef __init__(self):\n\t\troot = Path(__file__)\n\t\tfor idx in range(3):\n\t\t\troot = root.parent\n\t\tself.root = root\n\t\tself.super_user_ids_path = str(root / SUPER_USER_IDS_PERSIS_PATH)\n\t\tself.fs = fsspec.filesystem(\"file\")\n\t\tdir_path = str(Path(self.super_user_ids_path).parent)\n\t\tif not self.fs.exists(dir_path):\n\t\t\tself.fs.makedirs(dir_path)\n\n\tdef _get_user_ids_dict(self) -&gt; Dict[str, List[str]]:\n\t\tr\"\"\" Get the super-user accounts dictionary. \"\"\"\n\t\tif not self.fs.exists(self.super_user_ids_path):\n\t\t\treturn {}\n\t\twith self.fs.open(self.super_user_ids_path, \"rb\") as f:\n\t\t\tsuper_user_ids = json.load(f)\n\t\treturn super_user_ids\n\n\tdef get_super_users(self, instrument_id: str) -&gt; List[str]:\n\t\tr\"\"\" Get the super-users of a specific instrument. \"\"\"\n\t\treturn list(self._get_user_ids_dict()[instrument_id])\n\n\tdef is_super_user(self, user_id: str, instrument_id: str) -&gt; bool:\n\t\tr\"\"\" Judge whether a user is the super-user of a instrument. \"\"\"\n\t\tsuper_user_list = self.get_super_users(instrument_id=instrument_id)\n\t\treturn user_id in super_user_list\n\n\t@staticmethod\n\tdef check_users(user_id: Union[str, List[str]]):\n\t\tr\"\"\" Check whether all given users have registered.\"\"\"\n\t\tuser_manager = AccountManager()\n\t\tif not isinstance(user_id, list):\n\t\t\tuser_id = [user_id]\n\n\t\tfor user in user_id:\n\t\t\tuser_manager.check_valid_user(user_id=user)\n\n\tdef add_super_user(self, user_id: str, instrument_id: str):\n\t\tr\"\"\" Add a new super-user for the instrument. \"\"\"\n\t\tsuper_user_ids = self._get_user_ids_dict()\n\t\tself.check_users(user_id=user_id)\n\n\t\tif instrument_id not in super_user_ids.keys():\n\t\t\traise ValueError(f\"The instrument {instrument_id} is not registered yet.\")\n\n\t\tsuper_user_ids[instrument_id].append(user_id)\n\t\twith self.fs.open(self.super_user_ids_path, \"w\") as f:\n\t\t\tf.write(json.dumps(super_user_ids))\n\n\tdef delete_super_user(self, user_id: str, instrument_id: str):\n\t\tr\"\"\" Delete a super-user of the instrument. \"\"\"\n\t\tsuper_user_ids = self._get_user_ids_dict()\n\t\tif instrument_id not in super_user_ids.keys():\n\t\t\traise ValueError(f\"The instrument {instrument_id} is not registered yet.\")\n\t\tsuper_user_ids[instrument_id].remove(user_id)\n\t\twith self.fs.open(self.super_user_ids_path, \"w\") as f:\n\t\t\tf.write(json.dumps(super_user_ids))\n\n\tdef add_instrument(self, instrument_id: str, super_users: List[str]):\n\t\tr\"\"\" Add a new instrument along with its super-users. \"\"\"\n\t\tsuper_user_ids = self._get_user_ids_dict()\n\t\tif instrument_id in super_user_ids.keys():\n\t\t\traise ValueError(f\"The instrument {instrument_id} already exists.\")\n\n\t\tself.check_users(user_id=super_users)\n\t\tsuper_user_ids[instrument_id] = super_users\n\t\twith self.fs.open(self.super_user_ids_path, \"w\") as f:\n\t\t\tf.write(json.dumps(super_user_ids))\n</code></pre>"},{"location":"code_docs/accounts/super_users/#labridge.accounts.super_users.InstrumentSuperUserManager.add_instrument","title":"<code>labridge.accounts.super_users.InstrumentSuperUserManager.add_instrument(instrument_id, super_users)</code>","text":"<p>Add a new instrument along with its super-users.</p> Source code in <code>labridge\\accounts\\super_users.py</code> <pre><code>def add_instrument(self, instrument_id: str, super_users: List[str]):\n\tr\"\"\" Add a new instrument along with its super-users. \"\"\"\n\tsuper_user_ids = self._get_user_ids_dict()\n\tif instrument_id in super_user_ids.keys():\n\t\traise ValueError(f\"The instrument {instrument_id} already exists.\")\n\n\tself.check_users(user_id=super_users)\n\tsuper_user_ids[instrument_id] = super_users\n\twith self.fs.open(self.super_user_ids_path, \"w\") as f:\n\t\tf.write(json.dumps(super_user_ids))\n</code></pre>"},{"location":"code_docs/accounts/super_users/#labridge.accounts.super_users.InstrumentSuperUserManager.add_super_user","title":"<code>labridge.accounts.super_users.InstrumentSuperUserManager.add_super_user(user_id, instrument_id)</code>","text":"<p>Add a new super-user for the instrument.</p> Source code in <code>labridge\\accounts\\super_users.py</code> <pre><code>def add_super_user(self, user_id: str, instrument_id: str):\n\tr\"\"\" Add a new super-user for the instrument. \"\"\"\n\tsuper_user_ids = self._get_user_ids_dict()\n\tself.check_users(user_id=user_id)\n\n\tif instrument_id not in super_user_ids.keys():\n\t\traise ValueError(f\"The instrument {instrument_id} is not registered yet.\")\n\n\tsuper_user_ids[instrument_id].append(user_id)\n\twith self.fs.open(self.super_user_ids_path, \"w\") as f:\n\t\tf.write(json.dumps(super_user_ids))\n</code></pre>"},{"location":"code_docs/accounts/super_users/#labridge.accounts.super_users.InstrumentSuperUserManager.check_users","title":"<code>labridge.accounts.super_users.InstrumentSuperUserManager.check_users(user_id)</code>  <code>staticmethod</code>","text":"<p>Check whether all given users have registered.</p> Source code in <code>labridge\\accounts\\super_users.py</code> <pre><code>@staticmethod\ndef check_users(user_id: Union[str, List[str]]):\n\tr\"\"\" Check whether all given users have registered.\"\"\"\n\tuser_manager = AccountManager()\n\tif not isinstance(user_id, list):\n\t\tuser_id = [user_id]\n\n\tfor user in user_id:\n\t\tuser_manager.check_valid_user(user_id=user)\n</code></pre>"},{"location":"code_docs/accounts/super_users/#labridge.accounts.super_users.InstrumentSuperUserManager.delete_super_user","title":"<code>labridge.accounts.super_users.InstrumentSuperUserManager.delete_super_user(user_id, instrument_id)</code>","text":"<p>Delete a super-user of the instrument.</p> Source code in <code>labridge\\accounts\\super_users.py</code> <pre><code>def delete_super_user(self, user_id: str, instrument_id: str):\n\tr\"\"\" Delete a super-user of the instrument. \"\"\"\n\tsuper_user_ids = self._get_user_ids_dict()\n\tif instrument_id not in super_user_ids.keys():\n\t\traise ValueError(f\"The instrument {instrument_id} is not registered yet.\")\n\tsuper_user_ids[instrument_id].remove(user_id)\n\twith self.fs.open(self.super_user_ids_path, \"w\") as f:\n\t\tf.write(json.dumps(super_user_ids))\n</code></pre>"},{"location":"code_docs/accounts/super_users/#labridge.accounts.super_users.InstrumentSuperUserManager.get_super_users","title":"<code>labridge.accounts.super_users.InstrumentSuperUserManager.get_super_users(instrument_id)</code>","text":"<p>Get the super-users of a specific instrument.</p> Source code in <code>labridge\\accounts\\super_users.py</code> <pre><code>def get_super_users(self, instrument_id: str) -&gt; List[str]:\n\tr\"\"\" Get the super-users of a specific instrument. \"\"\"\n\treturn list(self._get_user_ids_dict()[instrument_id])\n</code></pre>"},{"location":"code_docs/accounts/super_users/#labridge.accounts.super_users.InstrumentSuperUserManager.is_super_user","title":"<code>labridge.accounts.super_users.InstrumentSuperUserManager.is_super_user(user_id, instrument_id)</code>","text":"<p>Judge whether a user is the super-user of a instrument.</p> Source code in <code>labridge\\accounts\\super_users.py</code> <pre><code>def is_super_user(self, user_id: str, instrument_id: str) -&gt; bool:\n\tr\"\"\" Judge whether a user is the super-user of a instrument. \"\"\"\n\tsuper_user_list = self.get_super_users(instrument_id=instrument_id)\n\treturn user_id in super_user_list\n</code></pre>"},{"location":"code_docs/accounts/users/","title":"Users","text":""},{"location":"code_docs/accounts/users/#labridge.accounts.users","title":"<code>labridge.accounts.users</code>","text":""},{"location":"code_docs/accounts/users/#labridge.accounts.users.AccountManager","title":"<code>labridge.accounts.users.AccountManager</code>","text":"<p>               Bases: <code>object</code></p> <p>This is account manager of the Laboratory members and chat groups. Only registered users have access to the Lab assistant.</p> <p>The user account information is stored as a dictionary in JSON format: <code>{user_id: password}</code></p> <p>The chat groups information is stored as a dictionary in JSON format: <code>{chat_group_id: [user_id, ]}</code></p> Source code in <code>labridge\\accounts\\users.py</code> <pre><code>class AccountManager(object):\n\tr\"\"\"\n\tThis is account manager of the Laboratory members and chat groups.\n\tOnly registered users have access to the Lab assistant.\n\n\tThe user account information is stored as a dictionary in JSON format:\n\t`{user_id: password}`\n\n\tThe chat groups information is stored as a dictionary in JSON format:\n\t`{chat_group_id: [user_id, ]}`\n\t\"\"\"\n\tdef __init__(self):\n\t\troot = Path(__file__)\n\t\tfor idx in range(3):\n\t\t\troot = root.parent\n\t\tself.root = root\n\t\tself.user_ids_path = str(root / USER_IDS_PERSIS_PATH)\n\t\tself.chat_group_ids_path = str(root / CHAT_GROUP_IDS_PERSIST_PATH)\n\t\tself.fs = fsspec.filesystem(\"file\")\n\t\tdir_path = str(Path(self.user_ids_path).parent)\n\t\tif not self.fs.exists(dir_path):\n\t\t\tself.fs.makedirs(dir_path)\n\n\tdef _get_user_ids_dict(self) -&gt; Dict[str, str]:\n\t\tr\"\"\" Get the user account dict. \"\"\"\n\t\tif not self.fs.exists(self.user_ids_path):\n\t\t\treturn {}\n\t\twith self.fs.open(self.user_ids_path, \"rb\") as f:\n\t\t\tuser_ids = json.load(f)\n\t\treturn user_ids\n\n\tdef _get_chat_group_ids_dict(self) -&gt; Dict[str, List[str]]:\n\t\tr\"\"\" Get the chat group id dict. \"\"\"\n\t\tif not self.fs.exists(self.chat_group_ids_path):\n\t\t\treturn {}\n\t\twith self.fs.open(self.chat_group_ids_path, \"rb\") as f:\n\t\t\tchat_group_ids = json.load(f)\n\t\treturn chat_group_ids\n\n\tdef get_users(self) -&gt; List[str]:\n\t\tr\"\"\" Get the registered users. \"\"\"\n\t\treturn list(self._get_user_ids_dict().keys())\n\n\tdef get_chat_groups(self) -&gt; List[str]:\n\t\tr\"\"\" Get the registered chat groups \"\"\"\n\t\treturn list(self._get_chat_group_ids_dict().keys())\n\n\tdef user_log_in(self, user_id: str, password: str) -&gt; bool:\n\t\tr\"\"\" User log in \"\"\"\n\t\ttry:\n\t\t\tself.check_valid_user(user_id)\n\t\t\tuser_ids = self._get_user_ids_dict()\n\t\t\treturn password == user_ids[user_id]\n\t\texcept ValueError:\n\t\t\treturn False\n\n\tdef check_valid_user(self, user_id: str):\n\t\tr\"\"\" Check whether the given user is registered. \"\"\"\n\t\tuser_list = self.get_users()\n\t\tif user_id not in user_list:\n\t\t\traise ValueError(f\"Invalid user id, the user {user_id} is not registered.\")\n\n\tdef is_valid_chat_group(self, chat_group_id: str):\n\t\tr\"\"\" Check whether the given chat group is registered \"\"\"\n\t\tchat_group_list = self.get_chat_groups()\n\t\tif chat_group_id not in chat_group_list:\n\t\t\traise ValueError(f\"The chat group {chat_group_id} is not registered.\")\n\n\tdef add_user(self, user_id: str, password: str):\n\t\tr\"\"\" Register a new user. \"\"\"\n\t\tuser_ids = self._get_user_ids_dict()\n\n\t\tif user_id not in user_ids:\n\t\t\tuser_ids[user_id] = password\n\t\t\twith self.fs.open(self.user_ids_path, \"w\") as f:\n\t\t\t\tf.write(json.dumps(user_ids))\n\n\tdef add_chat_group(self, chat_group_id: str, user_list: List[str]) -&gt; Optional[str]:\n\t\tr\"\"\"\n\t\tRegister a new chat group along with its members.\n\t\tAll members in the chat group should have registered as a user.\n\t\t\"\"\"\n\t\tfor user_id in user_list:\n\t\t\ttry:\n\t\t\t\tself.check_valid_user(user_id)\n\t\t\texcept ValueError as e:\n\t\t\t\treturn f\"Error: {e!s}\"\n\n\t\tchat_group_ids = self._get_chat_group_ids_dict()\n\n\t\tif chat_group_id not in chat_group_ids:\n\t\t\tchat_group_ids[chat_group_id] = user_list\n\t\t\twith self.fs.open(self.chat_group_ids_path, \"w\") as f:\n\t\t\t\tf.write(json.dumps(chat_group_ids))\n\t\t\treturn None\n\n\tdef update_chat_group_members(self, chat_group_id: str, new_user_list: List[str]) -&gt; Optional[str]:\n\t\tr\"\"\" Update the members of a chat group. \"\"\"\n\t\tfor user_id in new_user_list:\n\t\t\ttry:\n\t\t\t\tself.check_valid_user(user_id)\n\t\t\texcept ValueError as e:\n\t\t\t\treturn f\"Error: {e!s}\"\n\n\t\tchat_group_ids = self._get_chat_group_ids_dict()\n\t\tchat_group_ids[chat_group_id] = new_user_list\n\t\twith self.fs.open(self.chat_group_ids_path, \"w\") as f:\n\t\t\tf.write(json.dumps(chat_group_ids))\n\t\treturn None\n</code></pre>"},{"location":"code_docs/accounts/users/#labridge.accounts.users.AccountManager.add_chat_group","title":"<code>labridge.accounts.users.AccountManager.add_chat_group(chat_group_id, user_list)</code>","text":"<p>Register a new chat group along with its members. All members in the chat group should have registered as a user.</p> Source code in <code>labridge\\accounts\\users.py</code> <pre><code>def add_chat_group(self, chat_group_id: str, user_list: List[str]) -&gt; Optional[str]:\n\tr\"\"\"\n\tRegister a new chat group along with its members.\n\tAll members in the chat group should have registered as a user.\n\t\"\"\"\n\tfor user_id in user_list:\n\t\ttry:\n\t\t\tself.check_valid_user(user_id)\n\t\texcept ValueError as e:\n\t\t\treturn f\"Error: {e!s}\"\n\n\tchat_group_ids = self._get_chat_group_ids_dict()\n\n\tif chat_group_id not in chat_group_ids:\n\t\tchat_group_ids[chat_group_id] = user_list\n\t\twith self.fs.open(self.chat_group_ids_path, \"w\") as f:\n\t\t\tf.write(json.dumps(chat_group_ids))\n\t\treturn None\n</code></pre>"},{"location":"code_docs/accounts/users/#labridge.accounts.users.AccountManager.add_user","title":"<code>labridge.accounts.users.AccountManager.add_user(user_id, password)</code>","text":"<p>Register a new user.</p> Source code in <code>labridge\\accounts\\users.py</code> <pre><code>def add_user(self, user_id: str, password: str):\n\tr\"\"\" Register a new user. \"\"\"\n\tuser_ids = self._get_user_ids_dict()\n\n\tif user_id not in user_ids:\n\t\tuser_ids[user_id] = password\n\t\twith self.fs.open(self.user_ids_path, \"w\") as f:\n\t\t\tf.write(json.dumps(user_ids))\n</code></pre>"},{"location":"code_docs/accounts/users/#labridge.accounts.users.AccountManager.check_valid_user","title":"<code>labridge.accounts.users.AccountManager.check_valid_user(user_id)</code>","text":"<p>Check whether the given user is registered.</p> Source code in <code>labridge\\accounts\\users.py</code> <pre><code>def check_valid_user(self, user_id: str):\n\tr\"\"\" Check whether the given user is registered. \"\"\"\n\tuser_list = self.get_users()\n\tif user_id not in user_list:\n\t\traise ValueError(f\"Invalid user id, the user {user_id} is not registered.\")\n</code></pre>"},{"location":"code_docs/accounts/users/#labridge.accounts.users.AccountManager.get_chat_groups","title":"<code>labridge.accounts.users.AccountManager.get_chat_groups()</code>","text":"<p>Get the registered chat groups</p> Source code in <code>labridge\\accounts\\users.py</code> <pre><code>def get_chat_groups(self) -&gt; List[str]:\n\tr\"\"\" Get the registered chat groups \"\"\"\n\treturn list(self._get_chat_group_ids_dict().keys())\n</code></pre>"},{"location":"code_docs/accounts/users/#labridge.accounts.users.AccountManager.get_users","title":"<code>labridge.accounts.users.AccountManager.get_users()</code>","text":"<p>Get the registered users.</p> Source code in <code>labridge\\accounts\\users.py</code> <pre><code>def get_users(self) -&gt; List[str]:\n\tr\"\"\" Get the registered users. \"\"\"\n\treturn list(self._get_user_ids_dict().keys())\n</code></pre>"},{"location":"code_docs/accounts/users/#labridge.accounts.users.AccountManager.is_valid_chat_group","title":"<code>labridge.accounts.users.AccountManager.is_valid_chat_group(chat_group_id)</code>","text":"<p>Check whether the given chat group is registered</p> Source code in <code>labridge\\accounts\\users.py</code> <pre><code>def is_valid_chat_group(self, chat_group_id: str):\n\tr\"\"\" Check whether the given chat group is registered \"\"\"\n\tchat_group_list = self.get_chat_groups()\n\tif chat_group_id not in chat_group_list:\n\t\traise ValueError(f\"The chat group {chat_group_id} is not registered.\")\n</code></pre>"},{"location":"code_docs/accounts/users/#labridge.accounts.users.AccountManager.update_chat_group_members","title":"<code>labridge.accounts.users.AccountManager.update_chat_group_members(chat_group_id, new_user_list)</code>","text":"<p>Update the members of a chat group.</p> Source code in <code>labridge\\accounts\\users.py</code> <pre><code>def update_chat_group_members(self, chat_group_id: str, new_user_list: List[str]) -&gt; Optional[str]:\n\tr\"\"\" Update the members of a chat group. \"\"\"\n\tfor user_id in new_user_list:\n\t\ttry:\n\t\t\tself.check_valid_user(user_id)\n\t\texcept ValueError as e:\n\t\t\treturn f\"Error: {e!s}\"\n\n\tchat_group_ids = self._get_chat_group_ids_dict()\n\tchat_group_ids[chat_group_id] = new_user_list\n\twith self.fs.open(self.chat_group_ids_path, \"w\") as f:\n\t\tf.write(json.dumps(chat_group_ids))\n\treturn None\n</code></pre>"},{"location":"code_docs/accounts/users/#labridge.accounts.users.AccountManager.user_log_in","title":"<code>labridge.accounts.users.AccountManager.user_log_in(user_id, password)</code>","text":"<p>User log in</p> Source code in <code>labridge\\accounts\\users.py</code> <pre><code>def user_log_in(self, user_id: str, password: str) -&gt; bool:\n\tr\"\"\" User log in \"\"\"\n\ttry:\n\t\tself.check_valid_user(user_id)\n\t\tuser_ids = self._get_user_ids_dict()\n\t\treturn password == user_ids[user_id]\n\texcept ValueError:\n\t\treturn False\n</code></pre>"},{"location":"code_docs/agent/chat_agent/","title":"Chat agent","text":""},{"location":"code_docs/agent/chat_agent/#labridge.agent.chat_agent","title":"<code>labridge.agent.chat_agent</code>","text":""},{"location":"code_docs/agent/chat_agent/#labridge.agent.chat_agent.LabChatAgent","title":"<code>labridge.agent.chat_agent.LabChatAgent</code>","text":"<p>This is the Chat agent following the ReAct framework, with access to multiple tools ranging papers, instruments and experiments.</p> Source code in <code>labridge\\agent\\chat_agent.py</code> <pre><code>class LabChatAgent:\n\tr\"\"\"\n\tThis is the Chat agent following the ReAct framework, with access to multiple tools\n\tranging papers, instruments and experiments.\n\t\"\"\"\n\n\tdef __init__(\n\t\tself,\n\t\tchat_engine: InstructReActAgent = None,\n\t):\n\t\tself._chat_engine = chat_engine\n\t\tself._short_memory_manager = ShortMemoryManager()\n\t\tself._account_manager = AccountManager()\n\t\tself._chatting_status = {}\n\t\tself.reset_chatting_status()\n\n\tdef reset_chatting_status(self):\n\t\tusers = self._account_manager.get_users()\n\t\tself._chatting_status = {user: False for user in users}\n\n\tdef update_users(self):\n\t\tself._account_manager = AccountManager()\n\n\t@property\n\tdef chat_engine(self) -&gt; InstructReActAgent:\n\t\tif self._chat_engine is None:\n\t\t\tself._chat_engine = self.get_chat_engine()\n\t\treturn self._chat_engine\n\n\tdef is_chatting(self, user_id: str) -&gt; bool:\n\t\treturn self._chatting_status[user_id]\n\n\tdef set_chatting(self, user_id: str, chatting: bool):\n\t\tself._chatting_status[user_id] = chatting\n\n\t@property\n\tdef short_memory_manager(self):\n\t\treturn self._short_memory_manager\n\n\tasync def chat(self, packed_msgs: PackedUserMessage) -&gt; AgentResponse:\n\t\tr\"\"\" Chat with agent. \"\"\"\n\t\tuser_id = packed_msgs.user_id\n\t\tself.set_chatting(user_id=user_id, chatting=True)\n\t\tpacked_json = packed_msgs.dumps()\n\t\tchat_history = self.short_memory_manager.load_memory(user_id=user_id)\n\n\t\tresponse = await self.chat_engine.achat(\n\t\t\tmessage=packed_json,\n\t\t\tchat_history=chat_history,\n\t\t)\n\t\tchat_history = self.chat_engine.memory.get()\n\t\tself.short_memory_manager.save_memory(user_id=user_id, chat_history=chat_history)\n\t\tself.chat_engine.reset()\n\n\t\tref_paths = response.metadata[\"references\"]\n\t\tif len(ref_paths) &lt; 1:\n\t\t\tref_paths = None\n\n\t\tagent_response = AgentResponse(\n\t\t\tresponse=response.response,\n\t\t\treferences=ref_paths,\n\t\t)\n\t\treturn agent_response\n\n\tdef test_chat(self, packed_msgs: PackedUserMessage) -&gt; AgentResponse:\n\t\tr\"\"\" Debug. \"\"\"\n\t\tuser_id = packed_msgs.user_id\n\t\tself.set_chatting(user_id=user_id, chatting=True)\n\t\tpacked_json = packed_msgs.dumps()\n\t\tchat_history = self.short_memory_manager.load_memory(user_id=user_id)\n\n\t\tresponse = self.chat_engine.chat(\n\t\t\tmessage=packed_json,\n\t\t\tchat_history=chat_history,\n\t\t)\n\t\tchat_history = self.chat_engine.memory.get()\n\t\tself.short_memory_manager.save_memory(user_id=user_id, chat_history=chat_history)\n\n\t\tref_paths = response.metadata[\"references\"]\n\t\tif len(ref_paths) &lt; 1:\n\t\t\tref_paths = None\n\n\t\tagent_response = AgentResponse(\n\t\t\tresponse=response.response,\n\t\t\treferences=ref_paths,\n\t\t)\n\t\treturn agent_response\n\n\n\tdef get_tools(self) -&gt; List[AsyncBaseTool]:\n\t\tr\"\"\" Available tools. \"\"\"\n\t\treturn [\n\t\t\tChatMemoryRetrieverTool(),\n\t\t\tExperimentLogRetrieveTool(),\n\t\t\tCreateNewExperimentLogTool(),\n\t\t\tSetCurrentExperimentTool(),\n\t\t\tRecordExperimentLogTool(),\n\t\t\tSharedPaperRetrieverTool(),\n\t\t\tArXivSearchDownloadTool(),\n\t\t\tAddNewRecentPaperTool(),\n\t\t\tRecentPaperRetrieveTool(),\n\t\t\tRecentPaperSummarizeTool(),\n\t\t\tInstrumentRetrieverTool(),\n\t\t]\n\n\tdef get_chat_engine(self) -&gt; InstructReActAgent:\n\t\tllm, embed_model = get_models()\n\t\tSettings.embed_model = embed_model\n\t\tSettings.llm = llm\n\t\ttools = self.get_tools()\n\n\t\treact_chat_formatter = ReActChatFormatter.from_defaults(system_header=LABRIDGE_CHAT_SYSTEM_HEADER)\n\n\t\tchat_engine = InstructReActAgent.from_tools(\n\t\t\ttools=tools,\n\t\t\treact_chat_formatter=react_chat_formatter,\n\t\t\tverbose=True,\n\t\t\tllm=llm,\n\t\t\tmemory=ChatMemoryBuffer.from_defaults(token_limit=3000),\n\t\t\tenable_instruct=False,\n\t\t\tenable_comment=False,\n\t\t\tmax_iterations=20,\n\t\t)\n\t\treturn chat_engine\n</code></pre>"},{"location":"code_docs/agent/chat_agent/#labridge.agent.chat_agent.LabChatAgent.chat","title":"<code>labridge.agent.chat_agent.LabChatAgent.chat(packed_msgs)</code>  <code>async</code>","text":"<p>Chat with agent.</p> Source code in <code>labridge\\agent\\chat_agent.py</code> <pre><code>async def chat(self, packed_msgs: PackedUserMessage) -&gt; AgentResponse:\n\tr\"\"\" Chat with agent. \"\"\"\n\tuser_id = packed_msgs.user_id\n\tself.set_chatting(user_id=user_id, chatting=True)\n\tpacked_json = packed_msgs.dumps()\n\tchat_history = self.short_memory_manager.load_memory(user_id=user_id)\n\n\tresponse = await self.chat_engine.achat(\n\t\tmessage=packed_json,\n\t\tchat_history=chat_history,\n\t)\n\tchat_history = self.chat_engine.memory.get()\n\tself.short_memory_manager.save_memory(user_id=user_id, chat_history=chat_history)\n\tself.chat_engine.reset()\n\n\tref_paths = response.metadata[\"references\"]\n\tif len(ref_paths) &lt; 1:\n\t\tref_paths = None\n\n\tagent_response = AgentResponse(\n\t\tresponse=response.response,\n\t\treferences=ref_paths,\n\t)\n\treturn agent_response\n</code></pre>"},{"location":"code_docs/agent/chat_agent/#labridge.agent.chat_agent.LabChatAgent.get_tools","title":"<code>labridge.agent.chat_agent.LabChatAgent.get_tools()</code>","text":"<p>Available tools.</p> Source code in <code>labridge\\agent\\chat_agent.py</code> <pre><code>def get_tools(self) -&gt; List[AsyncBaseTool]:\n\tr\"\"\" Available tools. \"\"\"\n\treturn [\n\t\tChatMemoryRetrieverTool(),\n\t\tExperimentLogRetrieveTool(),\n\t\tCreateNewExperimentLogTool(),\n\t\tSetCurrentExperimentTool(),\n\t\tRecordExperimentLogTool(),\n\t\tSharedPaperRetrieverTool(),\n\t\tArXivSearchDownloadTool(),\n\t\tAddNewRecentPaperTool(),\n\t\tRecentPaperRetrieveTool(),\n\t\tRecentPaperSummarizeTool(),\n\t\tInstrumentRetrieverTool(),\n\t]\n</code></pre>"},{"location":"code_docs/agent/chat_agent/#labridge.agent.chat_agent.LabChatAgent.test_chat","title":"<code>labridge.agent.chat_agent.LabChatAgent.test_chat(packed_msgs)</code>","text":"<p>Debug.</p> Source code in <code>labridge\\agent\\chat_agent.py</code> <pre><code>def test_chat(self, packed_msgs: PackedUserMessage) -&gt; AgentResponse:\n\tr\"\"\" Debug. \"\"\"\n\tuser_id = packed_msgs.user_id\n\tself.set_chatting(user_id=user_id, chatting=True)\n\tpacked_json = packed_msgs.dumps()\n\tchat_history = self.short_memory_manager.load_memory(user_id=user_id)\n\n\tresponse = self.chat_engine.chat(\n\t\tmessage=packed_json,\n\t\tchat_history=chat_history,\n\t)\n\tchat_history = self.chat_engine.memory.get()\n\tself.short_memory_manager.save_memory(user_id=user_id, chat_history=chat_history)\n\n\tref_paths = response.metadata[\"references\"]\n\tif len(ref_paths) &lt; 1:\n\t\tref_paths = None\n\n\tagent_response = AgentResponse(\n\t\tresponse=response.response,\n\t\treferences=ref_paths,\n\t)\n\treturn agent_response\n</code></pre>"},{"location":"code_docs/agent/chat_msg/msg_types/","title":"Msg types","text":""},{"location":"code_docs/agent/chat_msg/msg_types/#labridge.agent.chat_msg.msg_types","title":"<code>labridge.agent.chat_msg.msg_types</code>","text":""},{"location":"code_docs/agent/chat_msg/msg_types/#labridge.agent.chat_msg.msg_types.AgentResponse","title":"<code>labridge.agent.chat_msg.msg_types.AgentResponse</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>The response of chat agent.</p> <p>response (str): The response string. references (Optional[List[str]]): The paths of reference files.</p> Source code in <code>labridge\\agent\\chat_msg\\msg_types.py</code> <pre><code>class AgentResponse(BaseModel):\n\tr\"\"\"\n\tThe response of chat agent.\n\n\tresponse (str): The response string.\n\treferences (Optional[List[str]]): The paths of reference files.\n\t\"\"\"\n\tresponse: str\n\treferences: Optional[List[str]]\n</code></pre>"},{"location":"code_docs/agent/chat_msg/msg_types/#labridge.agent.chat_msg.msg_types.BaseClientMessage","title":"<code>labridge.agent.chat_msg.msg_types.BaseClientMessage</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>This is the base class for client's messages.</p> <p>user_id (str): The user id of a Lab member. reply_in_speech (bool): If True, the agent will reply in speech. enable_instruct (bool): If True, enable the user to intervene into the agent's reasoning phase. enable_comment (bool): If True: enable the user to intervene into the agent's acting phase.</p> Source code in <code>labridge\\agent\\chat_msg\\msg_types.py</code> <pre><code>class BaseClientMessage(BaseModel):\n\tr\"\"\"\n\tThis is the base class for client's messages.\n\n\tuser_id (str): The user id of a Lab member.\n\treply_in_speech (bool): If True, the agent will reply in speech.\n\tenable_instruct (bool): If True, enable the user to intervene into the agent's reasoning phase.\n\tenable_comment (bool): If True: enable the user to intervene into the agent's acting phase.\n\t\"\"\"\n\tuser_id: str\n\treply_in_speech: bool\n\tenable_instruct: bool\n\tenable_comment: bool\n</code></pre>"},{"location":"code_docs/agent/chat_msg/msg_types/#labridge.agent.chat_msg.msg_types.ChatMsgBuffer","title":"<code>labridge.agent.chat_msg.msg_types.ChatMsgBuffer</code>","text":"<p>               Bases: <code>object</code></p> <p>This class includes buffers that manager the messages from users and the agent's corresponding reply.</p> <p>Before a chat, the user's messages will put into the <code>user_msg_buffer</code>. When the agent get a user's messages, these messages will be packed and used as input to Call <code>Chat()</code>.</p> <p>Additionally, During the execution of <code>Chat()</code>, the agent is able to get new messages from the buffer, such as when collecting information from the user in some tools.</p> <p>The response of the agent will be put into the <code>agent_reply_buffer</code>, similarly, the user may receive an 'inner' response from the buffer.</p> <p>Depending on the user's choice <code>reply_in_speech</code>, the agent's response will be sent back to the user directly or transformed to speech before that.</p> Source code in <code>labridge\\agent\\chat_msg\\msg_types.py</code> <pre><code>class ChatMsgBuffer(object):\n\tr\"\"\"\n\tThis class includes buffers that manager the messages from users and the agent's corresponding reply.\n\n\tBefore a chat, the user's messages will put into the `user_msg_buffer`.\n\tWhen the agent get a user's messages, these messages will be packed and used as input to Call `Chat()`.\n\n\tAdditionally, During the execution of `Chat()`, the agent is able to get new messages from the buffer, such as\n\twhen collecting information from the user in some tools.\n\n\tThe response of the agent will be put into the `agent_reply_buffer`, similarly, the user may receive an 'inner'\n\tresponse from the buffer.\n\n\tDepending on the user's choice `reply_in_speech`, the agent's response will be sent back to the user directly or\n\ttransformed to speech before that.\n\t\"\"\"\n\tdef __init__(self):\n\t\troot = Path(__file__)\n\t\tfor i in range(4):\n\t\t\troot = root.parent\n\t\tself._root = root\n\t\tself.account_manager = AccountManager()\n\t\tself.user_msg_buffer: Dict[str, List[BaseClientMessage]] = {}\n\t\tself.agent_reply_buffer: Dict[str, Optional[Union[ServerReply, ServerSpeechReply]]] = {}\n\t\tself.config_buffer: Dict[str, ChatConfig] = {}\n\t\tself.user_msg_formatter = UserMsgFormatter()\n\t\tself.reset_buffer()\n\t\tself._fs = fsspec.filesystem(\"file\")\n\n\tdef reset_buffer(self):\n\t\tr\"\"\"\n\t\tReset the user_msg_buffer and agent_reply_buffer.\n\n\t\tReturns:\n\t\t\tNone\n\t\t\"\"\"\n\t\tusers = self.account_manager.get_users()\n\t\tself.user_msg_buffer = {user: [] for user in users}\n\t\tself.agent_reply_buffer = {user: None for user in users}\n\t\tself.config_buffer = {user: ChatConfig() for user in users}\n\n\tdef clear_user_msg(self, user_id: str):\n\t\tr\"\"\"\n\t\tClear a user's messages in the buffer.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user id of a Lab member.\n\t\t\"\"\"\n\t\tself.user_msg_buffer[user_id] = []\n\n\tdef put_user_msg(self, user_msg: BaseClientMessage):\n\t\tr\"\"\"\n\t\tPut a new user message into the buffer.\n\n\t\tArgs:\n\t\t\tuser_msg (BaseClientMessage): A new message from a user.\n\t\t\"\"\"\n\t\tif not isinstance(user_msg, (FileWithTextMessage, ChatTextMessage, ChatSpeechMessage)):\n\t\t\traise ValueError(f\"The Msg type {type(user_msg)} is not supported.\")\n\n\t\tuser_id = user_msg.user_id\n\t\tself.account_manager.check_valid_user(user_id=user_id)\n\t\tself.user_msg_buffer[user_id].append(user_msg)\n\t\tself.config_buffer[user_id].update(\n\t\t\tenable_instruct=user_msg.enable_instruct,\n\t\t\tenable_comment=user_msg.enable_comment,\n\t\t\treply_in_speech=user_msg.reply_in_speech,\n\t\t)\n\n\tasync def get_user_msg(self, user_id: str, timeout: int = 240) -&gt; Optional[PackedUserMessage]:\n\t\tr\"\"\"\n\t\tWait until a user's messages are put into the buffer, and get them.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user id of a Lab member.\n\t\t\ttimeout (int): If timeout, return None.\n\n\t\tReturns:\n\t\t\tOptional[PackedUserMessage]: The obtained packed user messages.\n\t\t\t\tIf no user messages if put in until time is out, return None.\n\t\t\"\"\"\n\t\tstart_time = time.time()\n\n\t\twhile True:\n\t\t\tmsgs = self.user_msg_buffer[user_id]\n\t\t\tend_time = time.time()\n\t\t\tif len(msgs) &gt; 0 or end_time &gt; start_time + timeout:\n\t\t\t\tself.clear_user_msg(user_id=user_id)\n\t\t\t\tbreak\n\t\t\tawait asyncio.sleep(1)\n\t\tif len(msgs) &gt; 0:\n\t\t\tpacked_msgs = self.user_msg_formatter.formatted_msgs(msgs=msgs)\n\t\t\treturn packed_msgs\n\n\t\tno_reply_msg = PackedUserMessage(\n\t\t\tuser_id=user_id,\n\t\t\tuser_msg=\"\",\n\t\t\tsystem_msg=f\"The user {user_id} does not reply, end this conversation.\",\n\t\t)\n\t\treturn no_reply_msg\n\n\tdef test_get_user_text(\n\t\tself,\n\t\tuser_id: str,\n\t\tenable_instruct: bool = False,\n\t\tenable_comment: bool = False,\n\t) -&gt; PackedUserMessage:\n\t\tr\"\"\" For debug. \"\"\"\n\t\tuser_msg = input(\"User: \")\n\n\t\ttext_msg = ChatTextMessage(\n\t\t\tuser_id=user_id,\n\t\t\ttext=user_msg,\n\t\t\treply_in_speech=False,\n\t\t\tenable_instruct=enable_instruct,\n\t\t\tenable_comment=enable_comment,\n\t\t)\n\t\tpacked_msgs = self.user_msg_formatter.formatted_msgs(msgs=[text_msg])\n\t\treturn packed_msgs\n\n\tdef default_user_speech_path(self, user_id: str) -&gt; str:\n\t\tr\"\"\" Default save path of a user's speech. \"\"\"\n\t\tuser_speech_path = self._root / f\"{USER_TMP_DIR}/{user_id}/{USER_SPEECH_NAME}\"\n\t\tdir_pth = str(user_speech_path.parent)\n\t\tif not self._fs.exists(dir_pth):\n\t\t\tself._fs.mkdirs(dir_pth)\n\t\treturn str(user_speech_path)\n\n\tdef default_agent_speech_path(self, user_id: str) -&gt; str:\n\t\tr\"\"\" Default save path of agent's speech. \"\"\"\n\t\tagent_speech_path = self._root / f\"{USER_TMP_DIR}/{user_id}/{AGENT_SPEECH_NAME}\"\n\t\tdir_pth = str(agent_speech_path.parent)\n\t\tif not self._fs.exists(dir_pth):\n\t\t\tself._fs.mkdirs(dir_pth)\n\t\treturn str(agent_speech_path)\n\n\tdef default_tmp_file_path(self, user_id: str, file_name: str) -&gt; str:\n\t\tr\"\"\" Default save path of the user's uploaded file. \"\"\"\n\t\tdate, _ = get_time()\n\t\ttmp_dir = self._root / f\"{USER_TMP_DIR}/{user_id}/{date}\"\n\t\ttmp_path = str(tmp_dir / file_name)\n\t\treturn tmp_path\n\n\tdef put_agent_reply(\n\t\tself,\n\t\tuser_id: str,\n\t\treply_str: str,\n\t\treferences: List[str] = None,\n\t\tinner_chat: bool = False,\n\t\textra_info: str = None,\n\t):\n\t\tr\"\"\"\n\t\tPut an agent's reply into the buffer.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user id of a Lab member.\n\t\t\treply_str (str): The agent's reply string.\n\t\t\treferences (List[str]): The paths of reference files. Defaults to None.\n\t\t\tinner_chat (bool): Whether the reply happens inside a chat.\n\t\t\textra_info (str): extra information generally with long texts.\n\t\t\"\"\"\n\t\tself.account_manager.check_valid_user(user_id=user_id)\n\n\t\tif references is not None:\n\t\t\tref_dict = {}\n\t\t\tfor ref_path in references:\n\t\t\t\tif not self._fs.exists(ref_path):\n\t\t\t\t\tcontinue\n\n\t\t\t\tref_size = os.path.getsize(ref_path)\n\t\t\t\tref_dict[ref_path] = ref_size\n\t\t\tif ref_dict:\n\t\t\t\treferences = ref_dict\n\t\t\telse:\n\t\t\t\treferences = None\n\n\t\tif not self.config_buffer[user_id].reply_in_speech:\n\t\t\treply = ServerReply(\n\t\t\t\treply_text=reply_str,\n\t\t\t\treferences=references,\n\t\t\t\tvalid=True,\n\t\t\t\tinner_chat=inner_chat,\n\t\t\t\textra_info=extra_info,\n\t\t\t)\n\t\t\tself.agent_reply_buffer[user_id] = reply\n\t\t\treturn\n\n\t\tspeech_name = self.default_agent_speech_path(user_id=user_id)\n\t\tspeech_path = TTSWorker.transform(text=reply_str, speech_name=speech_name)\n\n\t\tspeech_size = os.path.getsize(speech_path)\n\t\treply = ServerSpeechReply(\n\t\t\treply_speech={\n\t\t\t\tspeech_path: speech_size,\n\t\t\t},\n\t\t\tinner_chat=inner_chat,\n\t\t\treferences=references,\n\t\t\tvalid=True,\n\t\t\textra_info=extra_info,\n\t\t)\n\t\tself.agent_reply_buffer[user_id] = reply\n\n\tdef get_agent_reply(self, user_id: str) -&gt; Union[ServerReply, ServerSpeechReply]:\n\t\tr\"\"\"\n\t\tGet the agent reply to a user from the buffer.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user id of a Lab member.\n\n\t\tReturns:\n\t\t\tUnion[ServerReply, ServerSpeechReply]: If an agent's reply exists, return a valid reply,\n\t\t\t\totherwise, return an invalid reply.\n\t\t\"\"\"\n\t\tagent_reply = self.agent_reply_buffer[user_id]\n\t\tif agent_reply is None:\n\t\t\treturn ServerReply(\n\t\t\t\treply_text=\"Please wait.\",\n\t\t\t\tvalid=False,\n\t\t\t)\n\t\telse:\n\t\t\tself.agent_reply_buffer[user_id] = None\n\t\t\treturn agent_reply\n</code></pre>"},{"location":"code_docs/agent/chat_msg/msg_types/#labridge.agent.chat_msg.msg_types.ChatMsgBuffer.clear_user_msg","title":"<code>labridge.agent.chat_msg.msg_types.ChatMsgBuffer.clear_user_msg(user_id)</code>","text":"<p>Clear a user's messages in the buffer.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user id of a Lab member.</p> <p> TYPE: <code>str</code> </p> Source code in <code>labridge\\agent\\chat_msg\\msg_types.py</code> <pre><code>def clear_user_msg(self, user_id: str):\n\tr\"\"\"\n\tClear a user's messages in the buffer.\n\n\tArgs:\n\t\tuser_id (str): The user id of a Lab member.\n\t\"\"\"\n\tself.user_msg_buffer[user_id] = []\n</code></pre>"},{"location":"code_docs/agent/chat_msg/msg_types/#labridge.agent.chat_msg.msg_types.ChatMsgBuffer.default_agent_speech_path","title":"<code>labridge.agent.chat_msg.msg_types.ChatMsgBuffer.default_agent_speech_path(user_id)</code>","text":"<p>Default save path of agent's speech.</p> Source code in <code>labridge\\agent\\chat_msg\\msg_types.py</code> <pre><code>def default_agent_speech_path(self, user_id: str) -&gt; str:\n\tr\"\"\" Default save path of agent's speech. \"\"\"\n\tagent_speech_path = self._root / f\"{USER_TMP_DIR}/{user_id}/{AGENT_SPEECH_NAME}\"\n\tdir_pth = str(agent_speech_path.parent)\n\tif not self._fs.exists(dir_pth):\n\t\tself._fs.mkdirs(dir_pth)\n\treturn str(agent_speech_path)\n</code></pre>"},{"location":"code_docs/agent/chat_msg/msg_types/#labridge.agent.chat_msg.msg_types.ChatMsgBuffer.default_tmp_file_path","title":"<code>labridge.agent.chat_msg.msg_types.ChatMsgBuffer.default_tmp_file_path(user_id, file_name)</code>","text":"<p>Default save path of the user's uploaded file.</p> Source code in <code>labridge\\agent\\chat_msg\\msg_types.py</code> <pre><code>def default_tmp_file_path(self, user_id: str, file_name: str) -&gt; str:\n\tr\"\"\" Default save path of the user's uploaded file. \"\"\"\n\tdate, _ = get_time()\n\ttmp_dir = self._root / f\"{USER_TMP_DIR}/{user_id}/{date}\"\n\ttmp_path = str(tmp_dir / file_name)\n\treturn tmp_path\n</code></pre>"},{"location":"code_docs/agent/chat_msg/msg_types/#labridge.agent.chat_msg.msg_types.ChatMsgBuffer.default_user_speech_path","title":"<code>labridge.agent.chat_msg.msg_types.ChatMsgBuffer.default_user_speech_path(user_id)</code>","text":"<p>Default save path of a user's speech.</p> Source code in <code>labridge\\agent\\chat_msg\\msg_types.py</code> <pre><code>def default_user_speech_path(self, user_id: str) -&gt; str:\n\tr\"\"\" Default save path of a user's speech. \"\"\"\n\tuser_speech_path = self._root / f\"{USER_TMP_DIR}/{user_id}/{USER_SPEECH_NAME}\"\n\tdir_pth = str(user_speech_path.parent)\n\tif not self._fs.exists(dir_pth):\n\t\tself._fs.mkdirs(dir_pth)\n\treturn str(user_speech_path)\n</code></pre>"},{"location":"code_docs/agent/chat_msg/msg_types/#labridge.agent.chat_msg.msg_types.ChatMsgBuffer.get_agent_reply","title":"<code>labridge.agent.chat_msg.msg_types.ChatMsgBuffer.get_agent_reply(user_id)</code>","text":"<p>Get the agent reply to a user from the buffer.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user id of a Lab member.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Union[ServerReply, ServerSpeechReply]</code> <p>Union[ServerReply, ServerSpeechReply]: If an agent's reply exists, return a valid reply, otherwise, return an invalid reply.</p> Source code in <code>labridge\\agent\\chat_msg\\msg_types.py</code> <pre><code>def get_agent_reply(self, user_id: str) -&gt; Union[ServerReply, ServerSpeechReply]:\n\tr\"\"\"\n\tGet the agent reply to a user from the buffer.\n\n\tArgs:\n\t\tuser_id (str): The user id of a Lab member.\n\n\tReturns:\n\t\tUnion[ServerReply, ServerSpeechReply]: If an agent's reply exists, return a valid reply,\n\t\t\totherwise, return an invalid reply.\n\t\"\"\"\n\tagent_reply = self.agent_reply_buffer[user_id]\n\tif agent_reply is None:\n\t\treturn ServerReply(\n\t\t\treply_text=\"Please wait.\",\n\t\t\tvalid=False,\n\t\t)\n\telse:\n\t\tself.agent_reply_buffer[user_id] = None\n\t\treturn agent_reply\n</code></pre>"},{"location":"code_docs/agent/chat_msg/msg_types/#labridge.agent.chat_msg.msg_types.ChatMsgBuffer.get_user_msg","title":"<code>labridge.agent.chat_msg.msg_types.ChatMsgBuffer.get_user_msg(user_id, timeout=240)</code>  <code>async</code>","text":"<p>Wait until a user's messages are put into the buffer, and get them.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user id of a Lab member.</p> <p> TYPE: <code>str</code> </p> <code>timeout</code> <p>If timeout, return None.</p> <p> TYPE: <code>int</code> DEFAULT: <code>240</code> </p> RETURNS DESCRIPTION <code>Optional[PackedUserMessage]</code> <p>Optional[PackedUserMessage]: The obtained packed user messages. If no user messages if put in until time is out, return None.</p> Source code in <code>labridge\\agent\\chat_msg\\msg_types.py</code> <pre><code>async def get_user_msg(self, user_id: str, timeout: int = 240) -&gt; Optional[PackedUserMessage]:\n\tr\"\"\"\n\tWait until a user's messages are put into the buffer, and get them.\n\n\tArgs:\n\t\tuser_id (str): The user id of a Lab member.\n\t\ttimeout (int): If timeout, return None.\n\n\tReturns:\n\t\tOptional[PackedUserMessage]: The obtained packed user messages.\n\t\t\tIf no user messages if put in until time is out, return None.\n\t\"\"\"\n\tstart_time = time.time()\n\n\twhile True:\n\t\tmsgs = self.user_msg_buffer[user_id]\n\t\tend_time = time.time()\n\t\tif len(msgs) &gt; 0 or end_time &gt; start_time + timeout:\n\t\t\tself.clear_user_msg(user_id=user_id)\n\t\t\tbreak\n\t\tawait asyncio.sleep(1)\n\tif len(msgs) &gt; 0:\n\t\tpacked_msgs = self.user_msg_formatter.formatted_msgs(msgs=msgs)\n\t\treturn packed_msgs\n\n\tno_reply_msg = PackedUserMessage(\n\t\tuser_id=user_id,\n\t\tuser_msg=\"\",\n\t\tsystem_msg=f\"The user {user_id} does not reply, end this conversation.\",\n\t)\n\treturn no_reply_msg\n</code></pre>"},{"location":"code_docs/agent/chat_msg/msg_types/#labridge.agent.chat_msg.msg_types.ChatMsgBuffer.put_agent_reply","title":"<code>labridge.agent.chat_msg.msg_types.ChatMsgBuffer.put_agent_reply(user_id, reply_str, references=None, inner_chat=False, extra_info=None)</code>","text":"<p>Put an agent's reply into the buffer.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user id of a Lab member.</p> <p> TYPE: <code>str</code> </p> <code>reply_str</code> <p>The agent's reply string.</p> <p> TYPE: <code>str</code> </p> <code>references</code> <p>The paths of reference files. Defaults to None.</p> <p> TYPE: <code>List[str]</code> DEFAULT: <code>None</code> </p> <code>inner_chat</code> <p>Whether the reply happens inside a chat.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>extra_info</code> <p>extra information generally with long texts.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> Source code in <code>labridge\\agent\\chat_msg\\msg_types.py</code> <pre><code>def put_agent_reply(\n\tself,\n\tuser_id: str,\n\treply_str: str,\n\treferences: List[str] = None,\n\tinner_chat: bool = False,\n\textra_info: str = None,\n):\n\tr\"\"\"\n\tPut an agent's reply into the buffer.\n\n\tArgs:\n\t\tuser_id (str): The user id of a Lab member.\n\t\treply_str (str): The agent's reply string.\n\t\treferences (List[str]): The paths of reference files. Defaults to None.\n\t\tinner_chat (bool): Whether the reply happens inside a chat.\n\t\textra_info (str): extra information generally with long texts.\n\t\"\"\"\n\tself.account_manager.check_valid_user(user_id=user_id)\n\n\tif references is not None:\n\t\tref_dict = {}\n\t\tfor ref_path in references:\n\t\t\tif not self._fs.exists(ref_path):\n\t\t\t\tcontinue\n\n\t\t\tref_size = os.path.getsize(ref_path)\n\t\t\tref_dict[ref_path] = ref_size\n\t\tif ref_dict:\n\t\t\treferences = ref_dict\n\t\telse:\n\t\t\treferences = None\n\n\tif not self.config_buffer[user_id].reply_in_speech:\n\t\treply = ServerReply(\n\t\t\treply_text=reply_str,\n\t\t\treferences=references,\n\t\t\tvalid=True,\n\t\t\tinner_chat=inner_chat,\n\t\t\textra_info=extra_info,\n\t\t)\n\t\tself.agent_reply_buffer[user_id] = reply\n\t\treturn\n\n\tspeech_name = self.default_agent_speech_path(user_id=user_id)\n\tspeech_path = TTSWorker.transform(text=reply_str, speech_name=speech_name)\n\n\tspeech_size = os.path.getsize(speech_path)\n\treply = ServerSpeechReply(\n\t\treply_speech={\n\t\t\tspeech_path: speech_size,\n\t\t},\n\t\tinner_chat=inner_chat,\n\t\treferences=references,\n\t\tvalid=True,\n\t\textra_info=extra_info,\n\t)\n\tself.agent_reply_buffer[user_id] = reply\n</code></pre>"},{"location":"code_docs/agent/chat_msg/msg_types/#labridge.agent.chat_msg.msg_types.ChatMsgBuffer.put_user_msg","title":"<code>labridge.agent.chat_msg.msg_types.ChatMsgBuffer.put_user_msg(user_msg)</code>","text":"<p>Put a new user message into the buffer.</p> PARAMETER DESCRIPTION <code>user_msg</code> <p>A new message from a user.</p> <p> TYPE: <code>BaseClientMessage</code> </p> Source code in <code>labridge\\agent\\chat_msg\\msg_types.py</code> <pre><code>def put_user_msg(self, user_msg: BaseClientMessage):\n\tr\"\"\"\n\tPut a new user message into the buffer.\n\n\tArgs:\n\t\tuser_msg (BaseClientMessage): A new message from a user.\n\t\"\"\"\n\tif not isinstance(user_msg, (FileWithTextMessage, ChatTextMessage, ChatSpeechMessage)):\n\t\traise ValueError(f\"The Msg type {type(user_msg)} is not supported.\")\n\n\tuser_id = user_msg.user_id\n\tself.account_manager.check_valid_user(user_id=user_id)\n\tself.user_msg_buffer[user_id].append(user_msg)\n\tself.config_buffer[user_id].update(\n\t\tenable_instruct=user_msg.enable_instruct,\n\t\tenable_comment=user_msg.enable_comment,\n\t\treply_in_speech=user_msg.reply_in_speech,\n\t)\n</code></pre>"},{"location":"code_docs/agent/chat_msg/msg_types/#labridge.agent.chat_msg.msg_types.ChatMsgBuffer.reset_buffer","title":"<code>labridge.agent.chat_msg.msg_types.ChatMsgBuffer.reset_buffer()</code>","text":"<p>Reset the user_msg_buffer and agent_reply_buffer.</p> RETURNS DESCRIPTION <p>None</p> Source code in <code>labridge\\agent\\chat_msg\\msg_types.py</code> <pre><code>def reset_buffer(self):\n\tr\"\"\"\n\tReset the user_msg_buffer and agent_reply_buffer.\n\n\tReturns:\n\t\tNone\n\t\"\"\"\n\tusers = self.account_manager.get_users()\n\tself.user_msg_buffer = {user: [] for user in users}\n\tself.agent_reply_buffer = {user: None for user in users}\n\tself.config_buffer = {user: ChatConfig() for user in users}\n</code></pre>"},{"location":"code_docs/agent/chat_msg/msg_types/#labridge.agent.chat_msg.msg_types.ChatMsgBuffer.test_get_user_text","title":"<code>labridge.agent.chat_msg.msg_types.ChatMsgBuffer.test_get_user_text(user_id, enable_instruct=False, enable_comment=False)</code>","text":"<p>For debug.</p> Source code in <code>labridge\\agent\\chat_msg\\msg_types.py</code> <pre><code>def test_get_user_text(\n\tself,\n\tuser_id: str,\n\tenable_instruct: bool = False,\n\tenable_comment: bool = False,\n) -&gt; PackedUserMessage:\n\tr\"\"\" For debug. \"\"\"\n\tuser_msg = input(\"User: \")\n\n\ttext_msg = ChatTextMessage(\n\t\tuser_id=user_id,\n\t\ttext=user_msg,\n\t\treply_in_speech=False,\n\t\tenable_instruct=enable_instruct,\n\t\tenable_comment=enable_comment,\n\t)\n\tpacked_msgs = self.user_msg_formatter.formatted_msgs(msgs=[text_msg])\n\treturn packed_msgs\n</code></pre>"},{"location":"code_docs/agent/chat_msg/msg_types/#labridge.agent.chat_msg.msg_types.ChatSpeechMessage","title":"<code>labridge.agent.chat_msg.msg_types.ChatSpeechMessage</code>","text":"<p>               Bases: <code>BaseClientMessage</code></p> <p>This message includes:</p> <ol> <li>Basic: user_id.</li> <li>The save path of user's speech file data.</li> </ol> <p>This message is used in the <code>websocket_chat_speech</code>.</p> Source code in <code>labridge\\agent\\chat_msg\\msg_types.py</code> <pre><code>class ChatSpeechMessage(BaseClientMessage):\n\tr\"\"\"\n\tThis message includes:\n\n\t1. Basic: user_id.\n\t2. The save path of user's speech file data.\n\n\tThis message is used in the `websocket_chat_speech`.\n\t\"\"\"\n\tspeech_path: str\n\treply_in_speech: bool = True\n</code></pre>"},{"location":"code_docs/agent/chat_msg/msg_types/#labridge.agent.chat_msg.msg_types.ChatTextMessage","title":"<code>labridge.agent.chat_msg.msg_types.ChatTextMessage</code>","text":"<p>               Bases: <code>BaseClientMessage</code></p> <p>This message includes:</p> <ol> <li>Basic: user_id.</li> <li>The user's query.</li> </ol> <p>This message is used in the <code>websocket_chat_text</code>.</p> Source code in <code>labridge\\agent\\chat_msg\\msg_types.py</code> <pre><code>class ChatTextMessage(BaseClientMessage):\n\tr\"\"\"\n\tThis message includes:\n\n\t1. Basic: user_id.\n\t2. The user's query.\n\n\tThis message is used in the `websocket_chat_text`.\n\t\"\"\"\n\ttext: str\n\treply_in_speech: bool = False\n</code></pre>"},{"location":"code_docs/agent/chat_msg/msg_types/#labridge.agent.chat_msg.msg_types.FileWithTextMessage","title":"<code>labridge.agent.chat_msg.msg_types.FileWithTextMessage</code>","text":"<p>               Bases: <code>BaseClientMessage</code></p> <p>This message includes:</p> <ol> <li>Basic: user_id</li> <li>The info of the file to be uploaded.</li> <li>The attached user's query.</li> <li>Whether to reply in speech or not.</li> </ol> <p>This message is used in the <code>websocket_chat_with_file</code>.</p> Source code in <code>labridge\\agent\\chat_msg\\msg_types.py</code> <pre><code>class FileWithTextMessage(BaseClientMessage):\n\tr\"\"\"\n\tThis message includes:\n\n\t1. Basic: user_id\n\t2. The info of the file to be uploaded.\n\t3. The attached user's query.\n\t4. Whether to reply in speech or not.\n\n\tThis message is used in the `websocket_chat_with_file`.\n\t\"\"\"\n\tattached_text: str\n\treply_in_speech: bool = False\n\tfile_path: Optional[str] = None\n\n\tdef dumps(self) -&gt; str:\n\t\tr\"\"\"\n\t\tThe formatted string that the client sends to the server for uploading request,\n\t\tincluding the file info and the attached text.\n\t\t\"\"\"\n\t\tmsg_dict = {\n\t\t\t\"user_id\": self.user_id,\n\t\t\t\"file_name\": self.file_name,\n\t\t\t\"attached_text\": self.attached_text\n\t\t}\n\t\treturn json.dumps(msg_dict)\n\n\t@classmethod\n\tdef loads(cls, dumped_str):\n\t\tmsg_dict = json.loads(dumped_str)\n\t\tuser_id = msg_dict.get(\"user_id\")\n\t\tfile_name = msg_dict.get(\"file_name\")\n\t\tattached_text = msg_dict.get(\"attached_text\")\n\t\treturn cls(\n\t\t\tuser_id=user_id,\n\t\t\tfile_name=file_name,\n\t\t\tattached_text=attached_text,\n\t\t)\n</code></pre>"},{"location":"code_docs/agent/chat_msg/msg_types/#labridge.agent.chat_msg.msg_types.FileWithTextMessage.dumps","title":"<code>labridge.agent.chat_msg.msg_types.FileWithTextMessage.dumps()</code>","text":"<p>The formatted string that the client sends to the server for uploading request, including the file info and the attached text.</p> Source code in <code>labridge\\agent\\chat_msg\\msg_types.py</code> <pre><code>def dumps(self) -&gt; str:\n\tr\"\"\"\n\tThe formatted string that the client sends to the server for uploading request,\n\tincluding the file info and the attached text.\n\t\"\"\"\n\tmsg_dict = {\n\t\t\"user_id\": self.user_id,\n\t\t\"file_name\": self.file_name,\n\t\t\"attached_text\": self.attached_text\n\t}\n\treturn json.dumps(msg_dict)\n</code></pre>"},{"location":"code_docs/agent/chat_msg/msg_types/#labridge.agent.chat_msg.msg_types.PackedUserMessage","title":"<code>labridge.agent.chat_msg.msg_types.PackedUserMessage</code>","text":"<p>Pack the user messages.</p> <p>user_id (str): The user id of a Lab member. system_msg (str): The corresponding system message. user_msg (str): The packed user messages. reply_in_speech (bool): Whether the agent should reply in speech or not chat_group_id (Optional[str]): The ID of a chat group (If the messages are from a chat group). Defaults to None.</p> Source code in <code>labridge\\agent\\chat_msg\\msg_types.py</code> <pre><code>class PackedUserMessage:\n\tr\"\"\"\n\tPack the user messages.\n\n\tuser_id (str): The user id of a Lab member.\n\tsystem_msg (str): The corresponding system message.\n\tuser_msg (str): The packed user messages.\n\treply_in_speech (bool): Whether the agent should reply in speech or not\n\tchat_group_id (Optional[str]): The ID of a chat group (If the messages are from a chat group). Defaults to None.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tuser_id: str,\n\t\tsystem_msg: str,\n\t\tuser_msg: str,\n\t\tchat_group_id: Optional[str] = None,\n\t):\n\t\tself.user_id = user_id\n\t\tself.system_msg = system_msg\n\t\tself.user_msg = user_msg\n\t\tself.chat_group_id = chat_group_id\n\n\tdef dumps(self) -&gt; str:\n\t\tmsg_dict = {\n\t\t\t\"user_id\": self.user_id,\n\t\t\t\"system_msg\": self.system_msg,\n\t\t\t\"user_msg\": self.user_msg,\n\t\t\t\"chat_group_id\": self.chat_group_id,\n\t\t}\n\t\treturn json.dumps(msg_dict)\n\n\t@classmethod\n\tdef loads(cls, dumped_str: str):\n\t\tr\"\"\"\n\t\tLoad from a dumped JSON string.\n\n\t\tArgs:\n\t\t\tdumped_str (str): The dumped JSON string.\n\n\t\tReturns:\n\t\t\tPackedUserMessage\n\t\t\"\"\"\n\t\tmsg_dict = json.loads(dumped_str)\n\t\treturn cls(\n\t\t\tuser_id=msg_dict[\"user_id\"],\n\t\t\tsystem_msg=msg_dict[\"system_msg\"],\n\t\t\tuser_msg=msg_dict[\"user_msg\"],\n\t\t\tchat_group_id=msg_dict[\"chat_group_id\"],\n\t\t)\n</code></pre>"},{"location":"code_docs/agent/chat_msg/msg_types/#labridge.agent.chat_msg.msg_types.PackedUserMessage.loads","title":"<code>labridge.agent.chat_msg.msg_types.PackedUserMessage.loads(dumped_str)</code>  <code>classmethod</code>","text":"<p>Load from a dumped JSON string.</p> PARAMETER DESCRIPTION <code>dumped_str</code> <p>The dumped JSON string.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <p>PackedUserMessage</p> Source code in <code>labridge\\agent\\chat_msg\\msg_types.py</code> <pre><code>@classmethod\ndef loads(cls, dumped_str: str):\n\tr\"\"\"\n\tLoad from a dumped JSON string.\n\n\tArgs:\n\t\tdumped_str (str): The dumped JSON string.\n\n\tReturns:\n\t\tPackedUserMessage\n\t\"\"\"\n\tmsg_dict = json.loads(dumped_str)\n\treturn cls(\n\t\tuser_id=msg_dict[\"user_id\"],\n\t\tsystem_msg=msg_dict[\"system_msg\"],\n\t\tuser_msg=msg_dict[\"user_msg\"],\n\t\tchat_group_id=msg_dict[\"chat_group_id\"],\n\t)\n</code></pre>"},{"location":"code_docs/agent/chat_msg/msg_types/#labridge.agent.chat_msg.msg_types.ServerReply","title":"<code>labridge.agent.chat_msg.msg_types.ServerReply</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>The server's text reply.</p> <p>reply_text (str): The reply text. valid (bool): Whether this reply contains valid information. references (Optional[Dict[str, int]]): The paths of reference files and file size. error (Optional[str]): The error information. If no error, it is None. inner_chat (Optional[bool]): Whether the reply is produced inside the Chat Call.         - If this reply is the final response of the agent, it is False.         - If this reply is an internal response such as collecting information from the user or getting authorization,         it is True. When <code>inner_chat</code> is True, the client should post the user's answer to corresponding URL with flag <code>Inner</code>.</p> Source code in <code>labridge\\agent\\chat_msg\\msg_types.py</code> <pre><code>class ServerReply(BaseModel):\n\tr\"\"\"\n\tThe server's text reply.\n\n\treply_text (str): The reply text.\n\tvalid (bool): Whether this reply contains valid information.\n\treferences (Optional[Dict[str, int]]): The paths of reference files and file size.\n\terror (Optional[str]): The error information. If no error, it is None.\n\tinner_chat (Optional[bool]): Whether the reply is produced inside the Chat Call.\n\t\t- If this reply is the final response of the agent, it is False.\n\t\t- If this reply is an internal response such as collecting information from the user or getting authorization,\n\t\tit is True. When `inner_chat` is True, the client should post the user's answer to corresponding URL with flag `Inner`.\n\t\"\"\"\n\treply_text: str\n\tvalid: bool\n\treferences: Optional[Dict[str, int]] = None\n\textra_info: Optional[str] = None\n\terror: Optional[str] = None\n\tinner_chat: Optional[bool] = False\n</code></pre>"},{"location":"code_docs/agent/chat_msg/msg_types/#labridge.agent.chat_msg.msg_types.ServerSpeechReply","title":"<code>labridge.agent.chat_msg.msg_types.ServerSpeechReply</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>The server's speech reply.</p> <p>reply_speech (Dict[str, int]): The path of the agent's speech file. valid (bool): Whether the reply contains valid information. When receiving an invalid reply,         the client should continue to get the server's reply until get a valid reply. references (Optional[List[str]]): The paths of reference files. inner_chat (Optional[bool]): Whether the reply is produced inside the Chat Call.         - If this reply is the final response of the agent, it is False.         - If this reply is an internal response such as collecting information from the user or getting authorization,         it is True. When <code>inner_chat</code> is True, the client should post the user's answer to corresponding URL with flag <code>Inner</code>.</p> Source code in <code>labridge\\agent\\chat_msg\\msg_types.py</code> <pre><code>class ServerSpeechReply(BaseModel):\n\tr\"\"\"\n\tThe server's speech reply.\n\n\treply_speech (Dict[str, int]): The path of the agent's speech file.\n\tvalid (bool): Whether the reply contains valid information. When receiving an invalid reply,\n\t\tthe client should continue to get the server's reply until get a valid reply.\n\treferences (Optional[List[str]]): The paths of reference files.\n\tinner_chat (Optional[bool]): Whether the reply is produced inside the Chat Call.\n\t\t- If this reply is the final response of the agent, it is False.\n\t\t- If this reply is an internal response such as collecting information from the user or getting authorization,\n\t\tit is True. When `inner_chat` is True, the client should post the user's answer to corresponding URL with flag `Inner`.\n\t\"\"\"\n\treply_speech: Dict[str, int]\n\tvalid: bool\n\treferences: Optional[List[str]] = None\n\textra_info: Optional[str] = None\n\terror: Optional[str] = None\n\tinner_chat: Optional[bool] = False\n</code></pre>"},{"location":"code_docs/agent/chat_msg/msg_types/#labridge.agent.chat_msg.msg_types.UserMsgFormatter","title":"<code>labridge.agent.chat_msg.msg_types.UserMsgFormatter</code>","text":"<p>               Bases: <code>object</code></p> <p>This class transform the user's messages into specific formats and generate corresponding system messages.</p> Source code in <code>labridge\\agent\\chat_msg\\msg_types.py</code> <pre><code>class UserMsgFormatter(object):\n\tr\"\"\"\n\tThis class transform the user's messages into specific formats and generate corresponding system messages.\n\t\"\"\"\n\n\tdef _speech_to_text(self, msg: ChatSpeechMessage) -&gt; str:\n\t\tr\"\"\" Speech message to text. \"\"\"\n\t\ttext = ASRWorker.transform(speech_path=msg.speech_path)\n\t\treturn text\n\n\tdef _formatted_file_with_text(self, msg: FileWithTextMessage, file_idx: int) -&gt; Tuple[str, str]:\n\t\tr\"\"\" FileWithTextMessage to formatted text. \"\"\"\n\t\tsystem_str = f\"Path of File {file_idx}: {msg.file_path}\"\n\t\tuser_str = f\"The user query about the File {file_idx}:\\n{msg.attached_text}\"\n\t\treturn system_str, user_str\n\n\tdef formatted_msgs(self, msgs: List[BaseClientMessage]) -&gt; PackedUserMessage:\n\t\tr\"\"\"\n\t\tTurn into formatted text message.\n\n\t\tArgs:\n\t\t\tmsgs (List[BaseClientMessage]): The user's messages.\n\n\t\tReturns:\n\t\t\tPackedUserMessage: The packed user messages, and system message.\n\n\t\t\"\"\"\n\t\tfile_idx = 1\n\t\tuser_id = msgs[0].user_id\n\t\treply_in_speech = msgs[0].reply_in_speech\n\t\tenable_instruct = msgs[0].enable_instruct\n\t\tenable_comment = msgs[0].enable_comment\n\n\t\tdate_str, time_str = get_time()\n\t\tuser_queries = []\n\t\tsystem_strings = [\n\t\t\tf\"You are chatting with a user one-to-one\\n\"\n\t\t\tf\"User id: {user_id}\\n\"\n\t\t\tf\"Current date: {date_str}\\n\"\n\t\t\tf\"Current time: {time_str}\\n\",\n\t\t]\n\n\t\tfor msg in msgs:\n\t\t\tif isinstance(msg, ChatSpeechMessage):\n\t\t\t\tuser_str = self._speech_to_text(msg=msg)\n\t\t\t\tuser_queries.append(user_str)\n\t\t\telif isinstance(msg, FileWithTextMessage):\n\t\t\t\tsystem_str, user_str = self._formatted_file_with_text(msg=msg, file_idx=file_idx)\n\t\t\t\tfile_idx += 1\n\t\t\t\tuser_queries.append(user_str)\n\t\t\t\tsystem_strings.append(system_str)\n\t\t\telif isinstance(msg, ChatTextMessage):\n\t\t\t\tuser_queries.append(msg.text)\n\t\t\telse:\n\t\t\t\traise ValueError(f\"Invalid Msg type: {type(msg)}\")\n\n\t\tsystem_msg = \"\\n\".join(system_strings)\n\t\tuser_msg = \"\\n\".join(user_queries)\n\t\tpacked_msg = PackedUserMessage(\n\t\t\tsystem_msg=system_msg,\n\t\t\tuser_id=user_id,\n\t\t\tuser_msg=user_msg,\n\t\t)\n\t\treturn packed_msg\n</code></pre>"},{"location":"code_docs/agent/chat_msg/msg_types/#labridge.agent.chat_msg.msg_types.UserMsgFormatter.formatted_msgs","title":"<code>labridge.agent.chat_msg.msg_types.UserMsgFormatter.formatted_msgs(msgs)</code>","text":"<p>Turn into formatted text message.</p> PARAMETER DESCRIPTION <code>msgs</code> <p>The user's messages.</p> <p> TYPE: <code>List[BaseClientMessage]</code> </p> RETURNS DESCRIPTION <code>PackedUserMessage</code> <p>The packed user messages, and system message.</p> <p> TYPE: <code>PackedUserMessage</code> </p> Source code in <code>labridge\\agent\\chat_msg\\msg_types.py</code> <pre><code>def formatted_msgs(self, msgs: List[BaseClientMessage]) -&gt; PackedUserMessage:\n\tr\"\"\"\n\tTurn into formatted text message.\n\n\tArgs:\n\t\tmsgs (List[BaseClientMessage]): The user's messages.\n\n\tReturns:\n\t\tPackedUserMessage: The packed user messages, and system message.\n\n\t\"\"\"\n\tfile_idx = 1\n\tuser_id = msgs[0].user_id\n\treply_in_speech = msgs[0].reply_in_speech\n\tenable_instruct = msgs[0].enable_instruct\n\tenable_comment = msgs[0].enable_comment\n\n\tdate_str, time_str = get_time()\n\tuser_queries = []\n\tsystem_strings = [\n\t\tf\"You are chatting with a user one-to-one\\n\"\n\t\tf\"User id: {user_id}\\n\"\n\t\tf\"Current date: {date_str}\\n\"\n\t\tf\"Current time: {time_str}\\n\",\n\t]\n\n\tfor msg in msgs:\n\t\tif isinstance(msg, ChatSpeechMessage):\n\t\t\tuser_str = self._speech_to_text(msg=msg)\n\t\t\tuser_queries.append(user_str)\n\t\telif isinstance(msg, FileWithTextMessage):\n\t\t\tsystem_str, user_str = self._formatted_file_with_text(msg=msg, file_idx=file_idx)\n\t\t\tfile_idx += 1\n\t\t\tuser_queries.append(user_str)\n\t\t\tsystem_strings.append(system_str)\n\t\telif isinstance(msg, ChatTextMessage):\n\t\t\tuser_queries.append(msg.text)\n\t\telse:\n\t\t\traise ValueError(f\"Invalid Msg type: {type(msg)}\")\n\n\tsystem_msg = \"\\n\".join(system_strings)\n\tuser_msg = \"\\n\".join(user_queries)\n\tpacked_msg = PackedUserMessage(\n\t\tsystem_msg=system_msg,\n\t\tuser_id=user_id,\n\t\tuser_msg=user_msg,\n\t)\n\treturn packed_msg\n</code></pre>"},{"location":"code_docs/agent/react/prompt/","title":"Prompt","text":""},{"location":"code_docs/agent/react/prompt/#labridge.agent.react.prompt","title":"<code>labridge.agent.react.prompt</code>","text":""},{"location":"code_docs/agent/react/react/","title":"React","text":""},{"location":"code_docs/agent/react/react/#labridge.agent.react.react","title":"<code>labridge.agent.react.react</code>","text":""},{"location":"code_docs/agent/react/react/#labridge.agent.react.react.InstructReActAgent","title":"<code>labridge.agent.react.react.InstructReActAgent</code>","text":"<p>               Bases: <code>AgentRunner</code></p> <p>This Agent uses the Reasoning and acting prompt framework. Additionally, this class enables the user to intervene the reasoning phase and acting phase:</p> <ul> <li>If <code>enable_instruct</code> is set to True, in the reasoning phase, the user is able to instruct the agent's thought.</li> <li>If 'enable_comment' is set to True, in the reacting phase, the user is able to comment the agent's action, the user's comment will be treated as observation to instruct the agent's next thought.</li> </ul> PARAMETER DESCRIPTION <code>tools</code> <p>The available tools of the agent.</p> <p> TYPE: <code>Sequence[BaseTool]</code> </p> <code>llm</code> <p>The used LLM.</p> <p> TYPE: <code>LLM</code> </p> <code>memory</code> <p>The short-term memory.</p> <p> TYPE: <code>BaseMemory</code> </p> <code>max_iterations</code> <p>The maximum reasoning-acting steps.</p> <p> TYPE: <code>int</code> DEFAULT: <code>10</code> </p> <code>react_chat_formatter</code> <p>The ReAct prompt template.</p> <p> TYPE: <code>Optional[ReActChatFormatter]</code> DEFAULT: <code>None</code> </p> <code>output_parser</code> <p>Used to parse tool call from the agent's Acting output.</p> <p> TYPE: <code>Optional[ReActOutputParser]</code> DEFAULT: <code>None</code> </p> <code>callback_manager</code> <p> TYPE: <code>Optional[CallbackManager]</code> DEFAULT: <code>None</code> </p> <code>verbose</code> <p>Whether to show the inner Reasoning-Acting process.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>tool_retriever</code> <p>Used to retrieve proper tool among the given tools.</p> <p> TYPE: <code>Optional[ObjectRetriever[BaseTool]]</code> DEFAULT: <code>None</code> </p> <code>handle_reasoning_failure_fn</code> <p> TYPE: <code>Optional[Callable[[CallbackManager, Exception], ToolOutput]]</code> DEFAULT: <code>None</code> </p> <code>enable_instruct</code> <p>Whether to enable user's instructing in the reasoning phase.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>enable_comment</code> <p>Whether to enable user's commenting in the acting phase.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> Source code in <code>labridge\\agent\\react\\react.py</code> <pre><code>class InstructReActAgent(AgentRunner):\n\tr\"\"\"\n\tThis Agent uses the Reasoning and acting prompt framework.\n\tAdditionally, this class enables the user to intervene the reasoning phase and acting phase:\n\n\t- If `enable_instruct` is set to True, in the reasoning phase, the user is able to instruct the agent's thought.\n\t- If 'enable_comment' is set to True, in the reacting phase, the user is able to comment the agent's action, the\n\tuser's comment will be treated as observation to instruct the agent's next thought.\n\n\tArgs:\n\t\ttools (Sequence[BaseTool]): The available tools of the agent.\n\t\tllm (LLM): The used LLM.\n\t\tmemory (BaseMemory): The short-term memory.\n\t\tmax_iterations (int): The maximum reasoning-acting steps.\n\t\treact_chat_formatter (Optional[ReActChatFormatter]): The ReAct prompt template.\n\t\toutput_parser (Optional[ReActOutputParser]): Used to parse tool call from the agent's Acting output.\n\t\tcallback_manager (Optional[CallbackManager]):\n\t\tverbose (bool): Whether to show the inner Reasoning-Acting process.\n\t\ttool_retriever (Optional[ObjectRetriever[BaseTool]]): Used to retrieve proper tool among the given tools.\n\t\thandle_reasoning_failure_fn (Optional[Callable[[CallbackManager, Exception], ToolOutput]]):\n\t\tenable_instruct (bool): Whether to enable user's instructing in the reasoning phase.\n\t\tenable_comment (bool): Whether to enable user's commenting in the acting phase.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\ttools: Sequence[BaseTool],\n\t\tllm: LLM,\n\t\tmemory: BaseMemory,\n\t\tmax_iterations: int = 10,\n\t\treact_chat_formatter: Optional[ReActChatFormatter] = None,\n\t\toutput_parser: Optional[ReActOutputParser] = None,\n\t\tcallback_manager: Optional[CallbackManager] = None,\n\t\tverbose: bool = False,\n\t\ttool_retriever: Optional[ObjectRetriever[BaseTool]] = None,\n\t\thandle_reasoning_failure_fn: Optional[Callable[[CallbackManager, Exception],\n\t\tToolOutput]] = None,\n\t\tenable_instruct: bool = False,\n\t\tenable_comment: bool = False,\n\t):\n\t\tself.user_id_list = AccountManager().get_users()\n\t\tself.chat_group_list = AccountManager().get_chat_groups()\n\t\tstep_engine = InstructReActAgentWorker.from_tools(\n\t\t\ttools=tools,\n\t\t\ttool_retriever=tool_retriever,\n\t\t\tuser_id_list=self.user_id_list,\n\t\t\tchat_group_id_list=self.chat_group_list,\n\t\t\tllm=llm,\n\t\t\tmax_iterations=max_iterations,\n\t\t\treact_chat_formatter=react_chat_formatter,\n\t\t\toutput_parser=output_parser,\n\t\t\tcallback_manager=callback_manager,\n\t\t\tverbose=verbose,\n\t\t\thandle_reasoning_failure_fn=handle_reasoning_failure_fn,\n\t\t\tenable_instruct=enable_instruct,\n\t\t)\n\t\tself._enable_comment = enable_comment\n\t\tsuper().__init__(\n\t\t\tstep_engine,\n\t\t\tmemory=memory,\n\t\t\tllm=llm,\n\t\t\tcallback_manager=callback_manager,\n\t\t)\n\n\tdef update_user_id_list(self):\n\t\tr\"\"\" Update the registered user ids \"\"\"\n\t\tself.user_id_list = AccountManager().get_users()\n\t\tself.agent_worker.user_id_list = self.user_id_list\n\n\tdef set_enable_instruct(self, enable: bool):\n\t\tr\"\"\" Set enable_instruct. \"\"\"\n\t\tself.agent_worker.set_enable_instruct(enable)\n\n\tdef set_enable_comment(self, enable: bool):\n\t\tr\"\"\" Set enable_comment. \"\"\"\n\t\tself._enable_comment = enable\n\n\t@property\n\tdef enable_instruct(self):\n\t\tr\"\"\" Enable user's instruction in Reasoning Phase. \"\"\"\n\t\treturn self.agent_worker.enable_instruct\n\n\t@property\n\tdef enable_comment(self):\n\t\tr\"\"\" Enable user's instruction in Acting Phase. \"\"\"\n\t\treturn self._enable_comment\n\n\tdef final_process_tool_logs(self, task: Task) -&gt; Tuple[str, List[str]]:\n\t\tr\"\"\"\n\t\tProcess the tool logs of the agent's acting.\n\n\t\t1. Record the log_to_system: log_to_system will be recorded to the long-term memory.\n\t\t2. Extract the log_to_user: log_to_user will be attached to the agent's answer.\n\t\t3. Extract the references: references are the file paths of the relevant documents. This information will be\n\t\tsent to the frontend.\n\t\t\"\"\"\n\t\ttool_log_list = task.extra_state[\"tool_log\"]\n\t\ttool_logs_str = get_all_system_logs(tool_logs=tool_log_list)\n\n\t\t# task.extra_state[\"new_memory\"].put(\n\t\t# \tChatMessage(\n\t\t# \t\tcontent=tool_logs_str,\n\t\t# \t\trole=MessageRole.TOOL,\n\t\t# \t)\n\t\t# )\n\t\tto_user_logs = get_extra_str_to_user(tool_logs=tool_log_list)\n\t\tref_file_paths = get_ref_file_paths(tool_logs=tool_log_list)\n\t\treturn to_user_logs, ref_file_paths\n\n\t@dispatcher.span\n\tdef _chat(self, message: str, chat_history: Optional[List[ChatMessage]] = None,\n\t\ttool_choice: Union[str, dict] = \"auto\",\n\t\tmode: ChatResponseMode = ChatResponseMode.WAIT, ) -&gt; AGENT_CHAT_RESPONSE_TYPE:\n\t\t\"\"\"\n\t\tChat with step executor.\n\t\tUser is able to instruct or comment.\n\t\t\"\"\"\n\t\tif chat_history is not None:\n\t\t\tself.memory.set(chat_history)\n\n\t\tpacked_msgs = PackedUserMessage.loads(dumped_str=message)\n\t\tuser_id, chat_group_id = packed_msgs.user_id, packed_msgs.chat_group_id\n\t\tuser_msg, system_msg = packed_msgs.user_msg, packed_msgs.system_msg\n\n\t\ttask = self.create_task(\n\t\t\tinput=user_msg,\n\t\t\textra_state={\n\t\t\t\t\"system_msg\": system_msg,\n\t\t\t\t\"user_id\": user_id,\n\t\t\t\t\"enable_instruct\": ChatBuffer.config_buffer[user_id].enable_instruct,\n\t\t\t\t\"enable_comment\": ChatBuffer.config_buffer[user_id].enable_comment,\n\t\t\t}\n\t\t)\n\t\tif chat_group_id is not None:\n\t\t\ttask.extra_state[\"chat_group_id\"] = chat_group_id\n\n\t\tresult_output = None\n\t\tdispatcher.event(AgentChatWithStepStartEvent(user_msg=user_msg))\n\n\t\t# \u200b\u663e\u5f0f\u200b\u83b7\u53d6\u200b initial step\n\t\tstep = self.state.get_step_queue(task.task_id).popleft()\n\n\t\twhile True:\n\t\t\t# pass step queue in as argument, assume step executor is stateless\n\t\t\tcur_step_output = self._run_step(\n\t\t\t\ttask.task_id,\n\t\t\t\tstep=step,\n\t\t\t\tmode=mode,\n\t\t\t\ttool_choice=tool_choice,\n\t\t\t)\n\n\t\t\tif cur_step_output.is_last:\n\t\t\t\tresult_output = cur_step_output\n\t\t\t\tbreak\n\n\t\t\tstep_queue = self.state.get_step_queue(task.task_id)\n\t\t\tstep = step_queue.popleft()\n\n\t\t\t# Send the observation to the user.\n\t\t\tif task.extra_state[\"enable_comment\"]:\n\t\t\t\t# TODO: \u200b\u5c06\u200b cur_step_output.output.response \u200b\u8f93\u51fa\u200b\u7ed9\u200b User, \u200b\u83b7\u53d6\u200b User \u200b\u7684\u200b Instruction\u3002\n\t\t\t\tprint_text(text=cur_step_output.output.response, color=\"llama_turquoise\", end=\"\\n\")\n\t\t\t\t# TODO: \u200b\u83b7\u53d6\u200b\u4e0b\u200b\u4e00\u6b65\u200b step, \u200b\u5e76\u200b\u5c06\u200bInstruction\u200b\u4f5c\u4e3a\u200b step.input\u3002\n\t\t\t\tpacked_msgs = ChatBuffer.test_get_user_text(\n\t\t\t\t\tuser_id=user_id,\n\t\t\t\t\tenable_instruct=False,\n\t\t\t\t\tenable_comment=False,\n\t\t\t\t)\n\n\t\t\t\tuser_comment = packed_msgs.user_msg\n\t\t\t\tsystem_msg = packed_msgs.system_msg\n\t\t\t\tupdate_intervene_status(\n\t\t\t\t\ttask=task,\n\t\t\t\t\tenable_instruct=ChatBuffer.config_buffer[user_id].enable_instruct,\n\t\t\t\t\tenable_comment=ChatBuffer.config_buffer[user_id].enable_comment,\n\t\t\t\t\treply_in_speech=ChatBuffer.config_buffer[user_id].reply_in_speech,\n\t\t\t\t)\n\t\t\t\t# Add as the step's input\n\t\t\t\tstep.input = user_comment\n\t\t\t\tstep.step_state[\"system_msg\"] = system_msg\n\t\t\t\tprint_text(f\"&gt;&gt;&gt; User's comment: \\n {user_comment}\", color=\"blue\", end=\"\\n\")\n\n\t\t\t# ensure tool_choice does not cause endless loops\n\t\t\ttool_choice = \"auto\"\n\n\t\tto_user_logs, ref_file_paths = self.final_process_tool_logs(task=task)\n\t\tresult = self.finalize_response(task.task_id, result_output, )\n\t\t# add the tool log if necessary.\n\t\tresult.response += f\"\\n\\n{to_user_logs}\"\n\t\tdispatcher.event(AgentChatWithStepEndEvent(response=result))\n\n\t\tif result.metadata is None:\n\t\t\tresult.metadata = {\"references\": ref_file_paths}\n\t\telse:\n\t\t\tresult.metadata.update({\"references\": ref_file_paths})\n\t\treturn result\n\n\t@dispatcher.span\n\tasync def _achat(self, message: str, chat_history: Optional[List[ChatMessage]] = None,\n\t\ttool_choice: Union[str, dict] = \"auto\",\n\t\tmode: ChatResponseMode = ChatResponseMode.WAIT, ) -&gt; AGENT_CHAT_RESPONSE_TYPE:\n\t\t\"\"\"\n\t\tAsync version.\n\t\tChat with step executor.\n\t\tUser is able to instruct or comment.\n\t\t\"\"\"\n\t\tif chat_history is not None:\n\t\t\tself.memory.set(chat_history)\n\n\t\tpacked_msgs = PackedUserMessage.loads(dumped_str=message)\n\t\tuser_id, chat_group_id = packed_msgs.user_id, packed_msgs.chat_group_id\n\t\tuser_msg, system_msg = packed_msgs.user_msg, packed_msgs.system_msg\n\n\t\ttask = self.create_task(\n\t\t\tinput=user_msg,\n\t\t\textra_state={\n\t\t\t\t\"system_msg\": system_msg,\n\t\t\t\t\"user_id\": user_id,\n\t\t\t\t\"enable_instruct\": ChatBuffer.config_buffer[user_id].enable_instruct,\n\t\t\t\t\"enable_comment\": ChatBuffer.config_buffer[user_id].enable_comment,\n\t\t\t\t\"reply_in_speech\": ChatBuffer.config_buffer[user_id].reply_in_speech,\n\t\t\t}\n\t\t)\n\t\tif chat_group_id is not None:\n\t\t\ttask.extra_state[\"chat_group_id\"] = chat_group_id\n\n\t\tresult_output = None\n\t\tdispatcher.event(AgentChatWithStepStartEvent(user_msg=user_msg))\n\n\t\t# explicitly get initial step\n\t\tstep = self.state.get_step_queue(task.task_id).popleft()\n\t\twhile True:\n\t\t\t# pass step queue in as argument, assume step executor is stateless\n\t\t\tcur_step_output = await self._arun_step(\n\t\t\t\ttask.task_id,\n\t\t\t\tstep=step,\n\t\t\t\tmode=mode,\n\t\t\t\ttool_choice=tool_choice,\n\t\t\t)\n\n\t\t\tif cur_step_output.is_last:\n\t\t\t\tresult_output = cur_step_output\n\t\t\t\tbreak\n\n\t\t\tstep_queue = self.state.get_step_queue(task.task_id)\n\t\t\tstep = step_queue.popleft()\n\n\t\t\t# Send the observation to the user.\n\t\t\tif task.extra_state[\"enable_comment\"]:\n\t\t\t\t# TODO: \u200b\u5c06\u200b cur_step_output.output.response \u200b\u8f93\u51fa\u200b\u7ed9\u200b User, \u200b\u83b7\u53d6\u200b User \u200b\u7684\u200b Instruction\u3002\n\t\t\t\tChatBuffer.put_agent_reply(\n\t\t\t\t\tuser_id=user_id,\n\t\t\t\t\treply_str=cur_step_output.output.response,\n\t\t\t\t\tinner_chat=True,\n\t\t\t\t)\n\t\t\t\t# TODO: \u200b\u5c06\u200bInstruction\u200b\u4f5c\u4e3a\u200b step.input, \u200b\u4ee5\u53ca\u200b\u5c06\u200b system_msg \u200b\u8bb0\u5165\u200b step.extra_state\u3002\n\t\t\t\tpacked_msgs = await ChatBuffer.get_user_msg(user_id=user_id)\n\t\t\t\tuser_comment, system_msg = packed_msgs.user_msg, packed_msgs.system_msg\n\t\t\t\t# update\n\t\t\t\tupdate_intervene_status(\n\t\t\t\t\ttask=task,\n\t\t\t\t\tenable_instruct=ChatBuffer.config_buffer[user_id].enable_instruct,\n\t\t\t\t\tenable_comment=ChatBuffer.config_buffer[user_id].enable_comment,\n\t\t\t\t\treply_in_speech=ChatBuffer.config_buffer[user_id].reply_in_speech,\n\t\t\t\t)\n\t\t\t\t# add to the step's input\n\t\t\t\tstep.input = user_comment\n\t\t\t\tstep.step_state[\"system_msg\"] = system_msg\n\t\t\t\tprint_text(\n\t\t\t\t\tf\"System: {system_msg}\"\n\t\t\t\t\tf\"&gt;&gt;&gt; User's comment: \\n {user_comment}\",\n\t\t\t\t\tcolor=\"blue\",\n\t\t\t\t\tend=\"\\n\",\n\t\t\t\t)\n\n\t\t\t# ensure tool_choice does not cause endless loops\n\t\t\ttool_choice = \"auto\"\n\n\t\tto_user_logs, ref_file_paths = self.final_process_tool_logs(task=task)\n\t\tresult = self.finalize_response(task.task_id, result_output, )\n\t\tresult.response += f\"\\n\\n{to_user_logs}\"\n\t\tdispatcher.event(AgentChatWithStepEndEvent(response=result))\n\t\tif result.metadata is None:\n\t\t\tresult.metadata = {\"references\": ref_file_paths}\n\t\telse:\n\t\t\tresult.metadata.update({\"references\": ref_file_paths})\n\t\treturn result\n\n\t@classmethod\n\tdef from_tools(\n\t\tcls,\n\t\ttools: Optional[List[BaseTool]] = None,\n\t\ttool_retriever: Optional[ObjectRetriever[BaseTool]] = None,\n\t\tllm: Optional[LLM] = None,\n\t\tchat_history: Optional[List[ChatMessage]] = None,\n\t\tmemory: Optional[BaseMemory] = None,\n\t\tmemory_cls: Type[BaseMemory] = ChatMemoryBuffer,\n\t\tmax_iterations: int = 10,\n\t\treact_chat_formatter: Optional[ReActChatFormatter] = None,\n\t\toutput_parser: Optional[ReActOutputParser] = None,\n\t\tcallback_manager: Optional[CallbackManager] = None,\n\t\tverbose: bool = False,\n\t\thandle_reasoning_failure_fn: Optional[Callable[[CallbackManager, Exception], ToolOutput]] = None,\n\t\tenable_instruct: bool = False,\n\t\tenable_comment: bool = False,\n\t\t**kwargs: Any,\n\t) -&gt; \"InstructReActAgent\":\n\t\t\"\"\"\n\t\tConvenience constructor method from set of BaseTools (Optional).\n\n\t\tNOTE: kwargs should have been exhausted by this point. In other words\n\t\tthe various upstream components such as BaseSynthesizer (response synthesizer)\n\t\tor BaseRetriever should have picked up off their respective kwargs in their\n\t\tconstructions.\n\n\t\tIf `handle_reasoning_failure_fn` is provided, when LLM fails to follow the response templates specified in\n\t\tthe System Prompt, this function will be called. This function should provide to the Agent, so that the Agent\n\t\tcan have a second chance to fix its mistakes.\n\t\tTo handle the exception yourself, you can provide a function that raises the `Exception`.\n\n\t\tNote: If you modified any response template in the System Prompt, you should override the method\n\t\t`_extract_reasoning_step` in `ReActAgentWorker`.\n\n\t\tReturns:\n\t\t\tInstructReActAgent\n\t\t\"\"\"\n\t\tllm = llm or Settings.llm\n\t\tif callback_manager is not None:\n\t\t\tllm.callback_manager = callback_manager\n\t\tmemory = memory or memory_cls.from_defaults(chat_history=chat_history or [], llm=llm)\n\t\treturn cls(\n\t\t\ttools=tools or [],\n\t\t\ttool_retriever=tool_retriever,\n\t\t\tllm=llm,\n\t\t\tmemory=memory,\n\t\t\tmax_iterations=max_iterations,\n\t\t\treact_chat_formatter=react_chat_formatter,\n\t\t\toutput_parser=output_parser,\n\t\t\tcallback_manager=callback_manager,\n\t\t\tverbose=verbose,\n\t\t\thandle_reasoning_failure_fn=handle_reasoning_failure_fn,\n\t\t\tenable_instruct=enable_instruct,\n\t\t\tenable_comment=enable_comment,\n\t\t)\n</code></pre>"},{"location":"code_docs/agent/react/react/#labridge.agent.react.react.InstructReActAgent.enable_comment","title":"<code>labridge.agent.react.react.InstructReActAgent.enable_comment</code>  <code>property</code>","text":"<p>Enable user's instruction in Acting Phase.</p>"},{"location":"code_docs/agent/react/react/#labridge.agent.react.react.InstructReActAgent.enable_instruct","title":"<code>labridge.agent.react.react.InstructReActAgent.enable_instruct</code>  <code>property</code>","text":"<p>Enable user's instruction in Reasoning Phase.</p>"},{"location":"code_docs/agent/react/react/#labridge.agent.react.react.InstructReActAgent.final_process_tool_logs","title":"<code>labridge.agent.react.react.InstructReActAgent.final_process_tool_logs(task)</code>","text":"<p>Process the tool logs of the agent's acting.</p> <ol> <li>Record the log_to_system: log_to_system will be recorded to the long-term memory.</li> <li>Extract the log_to_user: log_to_user will be attached to the agent's answer.</li> <li>Extract the references: references are the file paths of the relevant documents. This information will be sent to the frontend.</li> </ol> Source code in <code>labridge\\agent\\react\\react.py</code> <pre><code>def final_process_tool_logs(self, task: Task) -&gt; Tuple[str, List[str]]:\n\tr\"\"\"\n\tProcess the tool logs of the agent's acting.\n\n\t1. Record the log_to_system: log_to_system will be recorded to the long-term memory.\n\t2. Extract the log_to_user: log_to_user will be attached to the agent's answer.\n\t3. Extract the references: references are the file paths of the relevant documents. This information will be\n\tsent to the frontend.\n\t\"\"\"\n\ttool_log_list = task.extra_state[\"tool_log\"]\n\ttool_logs_str = get_all_system_logs(tool_logs=tool_log_list)\n\n\t# task.extra_state[\"new_memory\"].put(\n\t# \tChatMessage(\n\t# \t\tcontent=tool_logs_str,\n\t# \t\trole=MessageRole.TOOL,\n\t# \t)\n\t# )\n\tto_user_logs = get_extra_str_to_user(tool_logs=tool_log_list)\n\tref_file_paths = get_ref_file_paths(tool_logs=tool_log_list)\n\treturn to_user_logs, ref_file_paths\n</code></pre>"},{"location":"code_docs/agent/react/react/#labridge.agent.react.react.InstructReActAgent.from_tools","title":"<code>labridge.agent.react.react.InstructReActAgent.from_tools(tools=None, tool_retriever=None, llm=None, chat_history=None, memory=None, memory_cls=ChatMemoryBuffer, max_iterations=10, react_chat_formatter=None, output_parser=None, callback_manager=None, verbose=False, handle_reasoning_failure_fn=None, enable_instruct=False, enable_comment=False, **kwargs)</code>  <code>classmethod</code>","text":"<p>Convenience constructor method from set of BaseTools (Optional).</p> <p>NOTE: kwargs should have been exhausted by this point. In other words the various upstream components such as BaseSynthesizer (response synthesizer) or BaseRetriever should have picked up off their respective kwargs in their constructions.</p> <p>If <code>handle_reasoning_failure_fn</code> is provided, when LLM fails to follow the response templates specified in the System Prompt, this function will be called. This function should provide to the Agent, so that the Agent can have a second chance to fix its mistakes. To handle the exception yourself, you can provide a function that raises the <code>Exception</code>.</p> <p>Note: If you modified any response template in the System Prompt, you should override the method <code>_extract_reasoning_step</code> in <code>ReActAgentWorker</code>.</p> RETURNS DESCRIPTION <code>InstructReActAgent</code> <p>InstructReActAgent</p> Source code in <code>labridge\\agent\\react\\react.py</code> <pre><code>@classmethod\ndef from_tools(\n\tcls,\n\ttools: Optional[List[BaseTool]] = None,\n\ttool_retriever: Optional[ObjectRetriever[BaseTool]] = None,\n\tllm: Optional[LLM] = None,\n\tchat_history: Optional[List[ChatMessage]] = None,\n\tmemory: Optional[BaseMemory] = None,\n\tmemory_cls: Type[BaseMemory] = ChatMemoryBuffer,\n\tmax_iterations: int = 10,\n\treact_chat_formatter: Optional[ReActChatFormatter] = None,\n\toutput_parser: Optional[ReActOutputParser] = None,\n\tcallback_manager: Optional[CallbackManager] = None,\n\tverbose: bool = False,\n\thandle_reasoning_failure_fn: Optional[Callable[[CallbackManager, Exception], ToolOutput]] = None,\n\tenable_instruct: bool = False,\n\tenable_comment: bool = False,\n\t**kwargs: Any,\n) -&gt; \"InstructReActAgent\":\n\t\"\"\"\n\tConvenience constructor method from set of BaseTools (Optional).\n\n\tNOTE: kwargs should have been exhausted by this point. In other words\n\tthe various upstream components such as BaseSynthesizer (response synthesizer)\n\tor BaseRetriever should have picked up off their respective kwargs in their\n\tconstructions.\n\n\tIf `handle_reasoning_failure_fn` is provided, when LLM fails to follow the response templates specified in\n\tthe System Prompt, this function will be called. This function should provide to the Agent, so that the Agent\n\tcan have a second chance to fix its mistakes.\n\tTo handle the exception yourself, you can provide a function that raises the `Exception`.\n\n\tNote: If you modified any response template in the System Prompt, you should override the method\n\t`_extract_reasoning_step` in `ReActAgentWorker`.\n\n\tReturns:\n\t\tInstructReActAgent\n\t\"\"\"\n\tllm = llm or Settings.llm\n\tif callback_manager is not None:\n\t\tllm.callback_manager = callback_manager\n\tmemory = memory or memory_cls.from_defaults(chat_history=chat_history or [], llm=llm)\n\treturn cls(\n\t\ttools=tools or [],\n\t\ttool_retriever=tool_retriever,\n\t\tllm=llm,\n\t\tmemory=memory,\n\t\tmax_iterations=max_iterations,\n\t\treact_chat_formatter=react_chat_formatter,\n\t\toutput_parser=output_parser,\n\t\tcallback_manager=callback_manager,\n\t\tverbose=verbose,\n\t\thandle_reasoning_failure_fn=handle_reasoning_failure_fn,\n\t\tenable_instruct=enable_instruct,\n\t\tenable_comment=enable_comment,\n\t)\n</code></pre>"},{"location":"code_docs/agent/react/react/#labridge.agent.react.react.InstructReActAgent.set_enable_comment","title":"<code>labridge.agent.react.react.InstructReActAgent.set_enable_comment(enable)</code>","text":"<p>Set enable_comment.</p> Source code in <code>labridge\\agent\\react\\react.py</code> <pre><code>def set_enable_comment(self, enable: bool):\n\tr\"\"\" Set enable_comment. \"\"\"\n\tself._enable_comment = enable\n</code></pre>"},{"location":"code_docs/agent/react/react/#labridge.agent.react.react.InstructReActAgent.set_enable_instruct","title":"<code>labridge.agent.react.react.InstructReActAgent.set_enable_instruct(enable)</code>","text":"<p>Set enable_instruct.</p> Source code in <code>labridge\\agent\\react\\react.py</code> <pre><code>def set_enable_instruct(self, enable: bool):\n\tr\"\"\" Set enable_instruct. \"\"\"\n\tself.agent_worker.set_enable_instruct(enable)\n</code></pre>"},{"location":"code_docs/agent/react/react/#labridge.agent.react.react.InstructReActAgent.update_user_id_list","title":"<code>labridge.agent.react.react.InstructReActAgent.update_user_id_list()</code>","text":"<p>Update the registered user ids</p> Source code in <code>labridge\\agent\\react\\react.py</code> <pre><code>def update_user_id_list(self):\n\tr\"\"\" Update the registered user ids \"\"\"\n\tself.user_id_list = AccountManager().get_users()\n\tself.agent_worker.user_id_list = self.user_id_list\n</code></pre>"},{"location":"code_docs/agent/react/react_chat_format/","title":"React chat format","text":""},{"location":"code_docs/agent/react/react_chat_format/#labridge.agent.react.react_chat_format","title":"<code>labridge.agent.react.react_chat_format</code>","text":""},{"location":"code_docs/agent/react/react_chat_format/#labridge.agent.react.react_chat_format.InstructChatFormatter","title":"<code>labridge.agent.react.react_chat_format.InstructChatFormatter</code>","text":"<p>               Bases: <code>object</code></p> <p>Instruct chat formatter.</p> Source code in <code>labridge\\agent\\react\\react_chat_format.py</code> <pre><code>class InstructChatFormatter(object):\n    \"\"\"Instruct chat formatter.\"\"\"\n\n    system_header: str = INSTRUCT_CHAT_SYSTEM_HEADER  # default\n    context: str = \"\"  # not needed w/ default\n\n    def format(\n        self,\n        tools: Sequence[BaseTool],\n        chat_history: List[ChatMessage],\n\t\tprev_response: str,\n\t\tsuggestion: str,\n        current_reasoning: Optional[List[BaseReasoningStep]] = None,\n    ) -&gt; List[ChatMessage]:\n        \"\"\"Format chat history into list of ChatMessage.\"\"\"\n        current_reasoning = current_reasoning or []\n\n        format_args = {\n            \"tool_desc\": \"\\n\".join(get_react_tool_descriptions(tools)),\n            \"tool_names\": \", \".join([tool.metadata.get_name() for tool in tools]),\n\t\t\t\"prev_response\": prev_response,\n\t\t\t\"suggestion\": suggestion,\n        }\n        if self.context:\n            format_args[\"context\"] = self.context\n\n        fmt_sys_header = self.system_header.format(**format_args)\n\n        # format reasoning history as alternating user and assistant messages\n        # where the assistant messages are thoughts and actions and the user\n        # messages are observations\n        reasoning_history = []\n        for reasoning_step in current_reasoning:\n            if isinstance(reasoning_step, ObservationReasoningStep):\n                message = ChatMessage(\n                    role=MessageRole.USER,\n                    content=reasoning_step.get_content(),\n                )\n            else:\n                message = ChatMessage(\n                    role=MessageRole.ASSISTANT,\n                    content=reasoning_step.get_content(),\n                )\n            reasoning_history.append(message)\n\n        return [\n            ChatMessage(role=MessageRole.SYSTEM, content=fmt_sys_header),\n            *chat_history,\n            *reasoning_history,\n        ]\n</code></pre>"},{"location":"code_docs/agent/react/react_chat_format/#labridge.agent.react.react_chat_format.InstructChatFormatter.format","title":"<code>labridge.agent.react.react_chat_format.InstructChatFormatter.format(tools, chat_history, prev_response, suggestion, current_reasoning=None)</code>","text":"<p>Format chat history into list of ChatMessage.</p> Source code in <code>labridge\\agent\\react\\react_chat_format.py</code> <pre><code>    def format(\n        self,\n        tools: Sequence[BaseTool],\n        chat_history: List[ChatMessage],\n\t\tprev_response: str,\n\t\tsuggestion: str,\n        current_reasoning: Optional[List[BaseReasoningStep]] = None,\n    ) -&gt; List[ChatMessage]:\n        \"\"\"Format chat history into list of ChatMessage.\"\"\"\n        current_reasoning = current_reasoning or []\n\n        format_args = {\n            \"tool_desc\": \"\\n\".join(get_react_tool_descriptions(tools)),\n            \"tool_names\": \", \".join([tool.metadata.get_name() for tool in tools]),\n\t\t\t\"prev_response\": prev_response,\n\t\t\t\"suggestion\": suggestion,\n        }\n        if self.context:\n            format_args[\"context\"] = self.context\n\n        fmt_sys_header = self.system_header.format(**format_args)\n\n        # format reasoning history as alternating user and assistant messages\n        # where the assistant messages are thoughts and actions and the user\n        # messages are observations\n        reasoning_history = []\n        for reasoning_step in current_reasoning:\n            if isinstance(reasoning_step, ObservationReasoningStep):\n                message = ChatMessage(\n                    role=MessageRole.USER,\n                    content=reasoning_step.get_content(),\n                )\n            else:\n                message = ChatMessage(\n                    role=MessageRole.ASSISTANT,\n                    content=reasoning_step.get_content(),\n                )\n            reasoning_history.append(message)\n\n        return [\n            ChatMessage(role=MessageRole.SYSTEM, content=fmt_sys_header),\n            *chat_history,\n            *reasoning_history,\n        ]\n</code></pre>"},{"location":"code_docs/agent/react/react_step/","title":"React step","text":""},{"location":"code_docs/agent/react/react_step/#labridge.agent.react.react_step","title":"<code>labridge.agent.react.react_step</code>","text":""},{"location":"code_docs/agent/react/react_step/#labridge.agent.react.react_step.InstructReActAgentWorker","title":"<code>labridge.agent.react.react_step.InstructReActAgentWorker</code>","text":"<p>               Bases: <code>ReActAgentWorker</code></p> Source code in <code>labridge\\agent\\react\\react_step.py</code> <pre><code>class InstructReActAgentWorker(ReActAgentWorker):\n\tdef __init__(\n\t\tself,\n\t\ttools: Sequence[BaseTool],\n\t\tllm: LLM,\n\t\tuser_id_list: List[str],\n\t\tchat_group_id_list: List[str],\n\t\tmax_iterations: int = 10,\n\t\treact_chat_formatter: Optional[ReActChatFormatter] = None,\n\t\toutput_parser: Optional[ReActOutputParser] = None,\n\t\tcallback_manager: Optional[CallbackManager] = None,\n\t\tverbose: bool = False,\n\t\ttool_retriever: Optional[ObjectRetriever[BaseTool]] = None,\n\t\thandle_reasoning_failure_fn: Optional[Callable[[CallbackManager, Exception], ToolOutput]] = None,\n\t\tenable_instruct: bool = False,\n\t):\n\t\tself._enable_instruct = enable_instruct\n\t\tself._instruct_chat_formatter = InstructChatFormatter()\n\t\tself.user_id_list = user_id_list\n\t\tself.chat_group_id_list = chat_group_id_list\n\t\tsuper().__init__(\n\t\t\ttools=tools,\n\t\t\tllm=llm,\n\t\t\tmax_iterations=max_iterations,\n\t\t\treact_chat_formatter=react_chat_formatter,\n\t\t\toutput_parser=output_parser,\n\t\t\tcallback_manager=callback_manager,\n\t\t\tverbose=verbose,\n\t\t\ttool_retriever=tool_retriever,\n\t\t\thandle_reasoning_failure_fn=handle_reasoning_failure_fn,\n\t\t)\n\n\tdef set_enable_instruct(self, enable: bool):\n\t\tself._enable_instruct = enable\n\n\t@property\n\tdef enable_instruct(self):\n\t\tr\"\"\" Enable user's instruction in reasoning phase. \"\"\"\n\t\treturn self._enable_instruct\n\n\t@classmethod\n\tdef from_tools(\n\t\tcls,\n\t\ttools: Optional[Sequence[BaseTool]] = None,\n\t\ttool_retriever: Optional[ObjectRetriever[BaseTool]] = None,\n\t\tllm: Optional[LLM] = None,\n\t\tuser_id_list: List[str] = None,\n\t\tchat_group_id_list: List[str] = None,\n\t\tmax_iterations: int = 10,\n\t\treact_chat_formatter: Optional[ReActChatFormatter] = None,\n\t\toutput_parser: Optional[ReActOutputParser] = None,\n\t\tcallback_manager: Optional[CallbackManager] = None,\n\t\tverbose: bool = False,\n\t\thandle_reasoning_failure_fn: Optional[Callable[[CallbackManager, Exception], ToolOutput]] = None,\n\t\tenable_instruct: bool = False,\n\t\t**kwargs: Any,\n\t) -&gt; \"InstructReActAgentWorker\":\n\t\t\"\"\"\n\t\tConvenience constructor method from set of BaseTools (Optional).\n\n\t\tNOTE: kwargs should have been exhausted by this point. In other words\n\t\tthe various upstream components such as BaseSynthesizer (response synthesizer)\n\t\tor BaseRetriever should have picked up off their respective kwargs in their\n\t\tconstructions.\n\n\t\tReturns:\n\t\t\tReActAgentWorker\n\t\t\"\"\"\n\t\tllm = llm or Settings.llm\n\t\tif callback_manager is not None:\n\t\t\tllm.callback_manager = callback_manager\n\t\treturn cls(\n\t\t\ttools=tools or [],\n\t\t\ttool_retriever=tool_retriever,\n\t\t\tuser_id_list=user_id_list or AccountManager().get_users(),\n\t\t\tchat_group_id_list=chat_group_id_list or AccountManager().get_chat_groups(),\n\t\t\tllm=llm,\n\t\t\tmax_iterations=max_iterations,\n\t\t\treact_chat_formatter=react_chat_formatter,\n\t\t\toutput_parser=output_parser,\n\t\t\tcallback_manager=callback_manager,\n\t\t\tverbose=verbose,\n\t\t\thandle_reasoning_failure_fn=handle_reasoning_failure_fn,\n\t\t\tenable_instruct=enable_instruct,\n\t\t)\n\n\tdef initialize_step(self, task: Task, **kwargs: Any) -&gt; TaskStep:\n\t\t\"\"\"Initialize step from task.\"\"\"\n\t\tsources: List[ToolOutput] = []\n\t\tcurrent_reasoning: List[BaseReasoningStep] = []\n\t\t# temporary memory for new messages\n\t\tnew_memory = ChatMemoryBuffer.from_defaults()\n\t\t# the tool log list with ToolLogs.\n\t\ttool_log = []\n\n\t\t# initialize task state\n\t\ttask_state = {\n\t\t\t\"sources\": sources,\n\t\t\t\"current_reasoning\": current_reasoning,\n\t\t\t\"new_memory\": new_memory,\n\t\t\t\"tool_log\": tool_log,\n\t\t}\n\t\ttask.extra_state.update(task_state)\n\n\t\treturn TaskStep(\n\t\t\ttask_id=task.task_id,\n\t\t\tstep_id=str(uuid.uuid4()),\n\t\t\tinput=task.input,\n\t\t\tstep_state={\"is_first\": True, \"system_msg\": task.extra_state[\"system_msg\"]},\n\t\t)\n\n\tdef _run_step(self, step: TaskStep, task: Task, ) -&gt; TaskStepOutput:\n\t\t\"\"\"Run step.\"\"\"\n\t\tuser_id = task.extra_state[\"user_id\"]\n\t\tif step.input is not None:\n\t\t\tstep.step_state[\"user_id\"] = user_id\n\t\t\tadd_user_step_to_reasoning(\n\t\t\t\tstep,\n\t\t\t\ttask.extra_state[\"new_memory\"],\n\t\t\t\ttask.extra_state[\"current_reasoning\"],\n\t\t\t\tverbose=self._verbose,\n\t\t\t)\n\t\ttools = self.get_tools(task.input)\n\t\tinput_chat = self._react_chat_formatter.format(\n\t\t\ttools,\n\t\t\tchat_history=task.memory.get(input=task.input) + task.extra_state[\"new_memory\"].get_all(),\n\t\t\tcurrent_reasoning=task.extra_state[\"current_reasoning\"],\n\t\t)\n\n\t\t# send prompt\n\t\tchat_response = self._llm.chat(input_chat)\n\n\t\tif task.extra_state[\"enable_instruct\"]:\n\t\t\t# TODO: interface: Send the action to the user\n\t\t\tprint_text(f\"&gt;&gt;&gt; Initial reasoning: \\n{chat_response.message.content}\", color=\"pink\", end=\"\\n\")\n\t\t\t# TODO: interface: Get the user's suggestion\n\t\t\tpacked_msgs = ChatBuffer.test_get_user_text(\n\t\t\t\tuser_id=user_id,\n\t\t\t\tenable_instruct=False,\n\t\t\t\tenable_comment=False,\n\t\t\t)\n\n\t\t\tuser_advice = packed_msgs.user_msg\n\t\t\t# update enable_instruct and enable_comment\n\t\t\tupdate_intervene_status(\n\t\t\t\ttask=task,\n\t\t\t\tenable_instruct=ChatBuffer.config_buffer[user_id].enable_instruct,\n\t\t\t\tenable_comment=ChatBuffer.config_buffer[user_id].enable_comment,\n\t\t\t\treply_in_speech=ChatBuffer.config_buffer[user_id].reply_in_speech,\n\t\t\t)\n\t\t\tprint_text(f\"&gt;&gt;&gt; User's suggestion: \\n{user_advice}\", color=\"blue\", end=\"\\n\")\n\t\t\treasoning_step = ObservationReasoningStep(observation=f\"User's suggestion: {user_advice}\")\n\t\t\ttask.extra_state[\"current_reasoning\"].append(reasoning_step)\n\n\t\t\tinstruct_chat = self._instruct_chat_formatter.format(\n\t\t\t\ttools,\n\t\t\t\tchat_history=task.memory.get(input=task.input) + task.extra_state[\"new_memory\"].get_all(),\n\t\t\t\tcurrent_reasoning=task.extra_state[\"current_reasoning\"],\n\t\t\t\tprev_response=chat_response.message.content,\n\t\t\t\tsuggestion=f\"User's suggestion: {user_advice}\",\n\t\t\t)\n\t\t\tchat_response = self._llm.chat(instruct_chat)\n\t\t\tprint_text(f\"&gt;&gt;&gt; Modified reasoning: \\n{chat_response.message.content}\", color=\"green\", end=\"\\n\")\n\n\t\t# given react prompt outputs, call tools or return response\n\t\treasoning_steps, is_done = self._process_actions(task, tools, output=chat_response)\n\t\ttask.extra_state[\"current_reasoning\"].extend(reasoning_steps)\n\t\tagent_response = self._get_response(task.extra_state[\"current_reasoning\"], task.extra_state[\"sources\"])\n\n\t\tif is_done:\n\t\t\tdate, h_m_s = get_time()\n\t\t\tadditional_kwargs = {\n\t\t\t\tLOG_DATE_NAME: date,\n\t\t\t\tLOG_TIME_NAME: h_m_s,\n\t\t\t}\n\t\t\ttask.extra_state[\"new_memory\"].put(\n\t\t\t\tChatMessage(\n\t\t\t\t\tcontent=agent_response.response,\n\t\t\t\t\trole=MessageRole.ASSISTANT,\n\t\t\t\t\tadditional_kwargs=additional_kwargs,\n\t\t\t\t)\n\t\t\t)\n\n\t\treturn self._get_task_step_response(agent_response, step, is_done)\n\n\tasync def _arun_step(self, step: TaskStep, task: Task, ) -&gt; TaskStepOutput:\n\t\t\"\"\"Run step.\"\"\"\n\t\tuser_id = task.extra_state[\"user_id\"]\n\t\tif step.input is not None:\n\t\t\tstep.step_state[\"user_id\"] = user_id\n\t\t\tadd_user_step_to_reasoning(\n\t\t\t\tstep,\n\t\t\t\ttask.extra_state[\"new_memory\"],\n\t\t\t\ttask.extra_state[\"current_reasoning\"],\n\t\t\t\tverbose=self._verbose,\n\t\t\t)\n\n\t\ttools = self.get_tools(task.input)\n\n\t\tinput_chat = self._react_chat_formatter.format(\n\t\t\ttools,\n\t\t\tchat_history=task.memory.get(input=task.input) + task.extra_state[\"new_memory\"].get_all(),\n\t\t\tcurrent_reasoning=task.extra_state[\"current_reasoning\"],\n\t\t)\n\n\t\t# send prompt\n\t\tchat_response = await self._llm.achat(input_chat)\n\n\t\tif task.extra_state[\"enable_instruct\"]:\n\t\t\t# TODO: interface: Send the action to the user\n\t\t\tinit_reasoning = (\n\t\t\t\tf\"**\u200b\u5f53\u524d\u200bThought**:\\n\"\n\t\t\t\tf\"{chat_response.message.content}\\n\"\n\t\t\t\tf\"\u200b\u8bf7\u200b\u60a8\u200b\u53c2\u4e0e\u200b\u5230\u200b\u6211\u200b\u7684\u200bReasoning\u200b\u8fc7\u7a0b\u200b\u4e2d\u200b\uff0c\u200b\u7ed9\u4e88\u200b\u6307\u5bfc\u200b\u3002\u200b\u6211\u200b\u5c06\u200b\u53c2\u8003\u200b\u60a8\u200b\u7684\u200b\u5efa\u8bae\u200b\u5bf9\u200b\u6211\u200b\u7684\u200b\u51b3\u7b56\u200b\u505a\u51fa\u200b\u8c03\u6574\u200b\uff1a\"\n\t\t\t)\n\n\t\t\tChatBuffer.put_agent_reply(\n\t\t\t\tuser_id=user_id,\n\t\t\t\treply_str=init_reasoning,\n\t\t\t\tinner_chat=True,\n\t\t\t)\n\t\t\t# TODO: interface: Get the user's suggestion\n\t\t\tpacked_msgs = await ChatBuffer.get_user_msg(\n\t\t\t\tuser_id=user_id,\n\t\t\t)\n\n\t\t\tuser_advice = packed_msgs.user_msg\n\t\t\tsystem_msg = packed_msgs.system_msg\n\t\t\t# Update the enable_instruct and enable_comment\n\t\t\tupdate_intervene_status(\n\t\t\t\ttask=task,\n\t\t\t\tenable_instruct=ChatBuffer.config_buffer[user_id].enable_instruct,\n\t\t\t\tenable_comment=ChatBuffer.config_buffer[user_id].enable_comment,\n\t\t\t\treply_in_speech=ChatBuffer.config_buffer[user_id].reply_in_speech,\n\t\t\t)\n\n\t\t\t# Put the user's instruction into reasoning.\n\t\t\tsystem_step = ObservationReasoningStep(observation=f\"&lt;system&gt;:{system_msg}\")\n\t\t\treasoning_step = ObservationReasoningStep(observation=f\"User's suggestion: {user_advice}\")\n\t\t\ttask.extra_state[\"current_reasoning\"].extend([system_step, reasoning_step])\n\n\t\t\tinstruct_chat = self._instruct_chat_formatter.format(\n\t\t\t\ttools,\n\t\t\t\tchat_history=task.memory.get(input=task.input) + task.extra_state[\"new_memory\"].get_all(),\n\t\t\t\tcurrent_reasoning=task.extra_state[\"current_reasoning\"],\n\t\t\t\tprev_response=chat_response.message.content,\n\t\t\t\tsuggestion=f\"User's suggestion: {user_advice}\",\n\t\t\t)\n\t\t\tchat_response = await self._llm.achat(instruct_chat)\n\n\t\t\t# modified_reasoning = (\n\t\t\t# \tf\"**\u200b\u53c2\u8003\u200b\u60a8\u200b\u5efa\u8bae\u200b\u540e\u200b\u7684\u200bThought**:\\n\"\n\t\t\t# \tf\"{chat_response.message.content}\\n\\n\"\n\t\t\t# \tf\"\u200b\u6211\u200b\u5c06\u200b\u6839\u636e\u200b\u8fd9\u4e2a\u200bThought\u200b\u884c\u52a8\u200b\u3002\"\n\t\t\t# )\n\t\t\t#\n\t\t\t# ChatBuffer.put_agent_reply(\n\t\t\t# \tuser_id=step.step_state[\"user_id\"],\n\t\t\t# \treply_str=modified_reasoning,\n\t\t\t# \tinner_chat=True,\n\t\t\t# )\n\n\t\t# given react prompt outputs, call tools or return response\n\t\treasoning_steps, is_done = await self._aprocess_actions(task, tools, output=chat_response)\n\t\ttask.extra_state[\"current_reasoning\"].extend(reasoning_steps)\n\t\tagent_response = self._get_response(task.extra_state[\"current_reasoning\"], task.extra_state[\"sources\"])\n\t\tif is_done:\n\t\t\tdate, h_m_s = get_time()\n\t\t\tadditional_kwargs = {\n\t\t\t\tLOG_DATE_NAME: date,\n\t\t\t\tLOG_TIME_NAME: h_m_s,\n\t\t\t}\n\t\t\ttask.extra_state[\"new_memory\"].put(\n\t\t\t\tChatMessage(\n\t\t\t\t\tcontent=agent_response.response,\n\t\t\t\t\trole=MessageRole.ASSISTANT,\n\t\t\t\t\tadditional_kwargs=additional_kwargs,\n\t\t\t\t)\n\t\t\t)\n\n\t\treturn self._get_task_step_response(agent_response, step, is_done)\n\n\tdef _process_actions(\n\t\tself,\n\t\ttask: Task,\n\t\ttools: Sequence[AsyncBaseTool],\n\t\toutput: ChatResponse,\n\t\tis_streaming: bool = False,\n\t) -&gt; Tuple[List[BaseReasoningStep], bool]:\n\t\ttools_dict: Dict[str, AsyncBaseTool] = {tool.metadata.get_name(): tool for tool in tools}\n\t\ttool = None\n\n\t\ttry:\n\t\t\t_, current_reasoning, is_done = self._extract_reasoning_step(output, is_streaming)\n\t\texcept ValueError as exp:\n\t\t\tcurrent_reasoning = []\n\t\t\ttool_output = self._handle_reasoning_failure_fn(self.callback_manager, exp)\n\t\telse:\n\t\t\tif is_done:\n\t\t\t\treturn current_reasoning, True\n\n\t\t\t# call tool with input\n\t\t\treasoning_step = cast(ActionReasoningStep, current_reasoning[-1])\n\t\t\tif reasoning_step.action in tools_dict:\n\t\t\t\ttool = tools_dict[reasoning_step.action]\n\t\t\t\twith self.callback_manager.event(\n\t\t\t\t\t\tCBEventType.FUNCTION_CALL,\n\t\t\t\t\t\tpayload={EventPayload.FUNCTION_CALL: reasoning_step.action_input,\n\t\t\t\t\t\t\tEventPayload.TOOL: tool.metadata,\n\t\t\t\t\t\t},\n\t\t\t\t) as event:\n\t\t\t\t\ttry:\n\t\t\t\t\t\ttool_output = tool.call(**reasoning_step.action_input)\n\t\t\t\t\texcept Exception as e:\n\t\t\t\t\t\ttool_output = ToolOutput(\n\t\t\t\t\t\t\tcontent=f\"Error: {e!s}\",\n\t\t\t\t\t\t\ttool_name=tool.metadata.name,\n\t\t\t\t\t\t\traw_input={\"kwargs\": reasoning_step.action_input},\n\t\t\t\t\t\t\traw_output=e,\n\t\t\t\t\t\t\tis_error=True,\n\t\t\t\t\t\t)\n\t\t\t\t\tevent.on_end(payload={EventPayload.FUNCTION_OUTPUT: str(tool_output)})\n\t\t\telse:\n\t\t\t\ttool_output = self._handle_nonexistent_tool_name(reasoning_step)\n\n\t\ttask.extra_state[\"sources\"].append(tool_output)\n\n\t\ttool_output_str, tool_log_str = unpack_tool_output(tool_out_json=tool_output.content)\n\t\tif tool is not None and tool.metadata.return_direct:\n\t\t\tobservation = tool_output_str\n\t\telse:\n\t\t\tobservation = f\"Tool output:\\n{tool_output_str}\\nTool logs:\\n{tool_log_str}\"\n\n\t\t# record the tool log.\n\t\tif tool_log_str:\n\t\t\ttool_log = ToolLog.loads(log_str=tool_log_str)\n\t\t\ttask.extra_state[\"tool_log\"].append(tool_log)\n\t\t\ttask.extra_state[\"new_memory\"].put(\n\t\t\t\tChatMessage(\n\t\t\t\t\tcontent=tool_log_str,\n\t\t\t\t\trole=MessageRole.TOOL,\n\t\t\t\t)\n\t\t\t)\n\n\t\tobservation_step = ObservationReasoningStep(\n\t\t\tobservation=observation,\n\t\t\treturn_direct=(tool.metadata.return_direct and not tool_output.is_error if tool else False),\n\t\t)\n\t\tcurrent_reasoning.append(observation_step)\n\t\tif self._verbose:\n\t\t\tprint_text(f\"{observation_step.get_content()}\\n\", color=\"blue\")\n\t\treturn (\n\t\t\tcurrent_reasoning,\n\t\t\ttool.metadata.return_direct and not tool_output.is_error if tool else False,\n\t\t)\n\n\tasync def _aprocess_actions(\n\t\tself,\n\t\ttask: Task,\n\t\ttools: Sequence[AsyncBaseTool],\n\t\toutput: ChatResponse,\n\t\tis_streaming: bool = False,\n\t) -&gt; Tuple[List[BaseReasoningStep], bool]:\n\t\ttools_dict = {tool.metadata.name: tool for tool in tools}\n\t\ttool = None\n\n\t\ttry:\n\t\t\t_, current_reasoning, is_done = self._extract_reasoning_step(output, is_streaming)\n\t\texcept ValueError as exp:\n\t\t\tcurrent_reasoning = []\n\t\t\ttool_output = self._handle_reasoning_failure_fn(self.callback_manager, exp)\n\t\telse:\n\t\t\tif is_done:\n\t\t\t\treturn current_reasoning, True\n\n\t\t\t# call tool with input\n\t\t\treasoning_step = cast(ActionReasoningStep, current_reasoning[-1])\n\t\t\tif reasoning_step.action in tools_dict:\n\t\t\t\ttool = tools_dict[reasoning_step.action]\n\t\t\t\twith self.callback_manager.event(CBEventType.FUNCTION_CALL,\n\t\t\t\t\t\tpayload={EventPayload.FUNCTION_CALL: reasoning_step.action_input,\n\t\t\t\t\t\t\tEventPayload.TOOL: tool.metadata, }, ) as event:\n\t\t\t\t\ttry:\n\t\t\t\t\t\ttool_output = await tool.acall(**reasoning_step.action_input)\n\t\t\t\t\texcept Exception as e:\n\t\t\t\t\t\ttool_output = ToolOutput(content=f\"Error: {e!s}\", tool_name=tool.metadata.name,\n\t\t\t\t\t\t\traw_input={\"kwargs\": reasoning_step.action_input}, raw_output=e, is_error=True, )\n\t\t\t\t\tevent.on_end(payload={EventPayload.FUNCTION_OUTPUT: str(tool_output)})\n\t\t\telse:\n\t\t\t\ttool_output = self._handle_nonexistent_tool_name(reasoning_step)\n\n\t\ttask.extra_state[\"sources\"].append(tool_output)\n\n\t\ttool_output_str, tool_log_str = unpack_tool_output(tool_out_json=tool_output.content)\n\t\tif tool is not None and tool.metadata.return_direct:\n\t\t\tobservation = tool_output_str\n\t\telse:\n\t\t\tobservation = f\"Tool output:\\n{tool_output_str}\\nTool logs:\\n{tool_log_str}\"\n\n\t\t# record the tool log.\n\t\tif tool_log_str:\n\t\t\ttool_log = ToolLog.loads(log_str=tool_log_str)\n\t\t\ttask.extra_state[\"tool_log\"].append(tool_log)\n\t\t\ttask.extra_state[\"new_memory\"].put(\n\t\t\t\tChatMessage(\n\t\t\t\t\tcontent=tool_log_str,\n\t\t\t\t\trole=MessageRole.TOOL,\n\t\t\t\t)\n\t\t\t)\n\n\t\tobservation_step = ObservationReasoningStep(observation=observation,\n\t\t\treturn_direct=(tool.metadata.return_direct and not tool_output.is_error if tool else False), )\n\n\t\tcurrent_reasoning.append(observation_step)\n\t\tif self._verbose:\n\t\t\tprint_text(f\"{observation_step.get_content()}\\n\", color=\"blue\")\n\t\treturn (\n\t\t\tcurrent_reasoning, tool.metadata.return_direct and not tool_output.is_error if tool else False,\n\t\t)\n\n\tdef finalize_task(self, task: Task, **kwargs: Any) -&gt; None:\n\t\t\"\"\"Finalize task, after all the steps are completed.\"\"\"\n\t\tuser_id = task.extra_state.get(\"user_id\", None)\n\t\tchat_group_id = task.extra_state.get(\"chat_group_id\", None)\n\n\t\tif chat_group_id is not None:\n\t\t\tif chat_group_id in self.chat_group_id_list:\n\t\t\t\tupdate_chat_memory(\n\t\t\t\t\tmemory_id=user_id,\n\t\t\t\t\tchat_messages=task.extra_state[\"new_memory\"].get_all(),\n\t\t\t\t)\n\t\t\telse:\n\t\t\t\tif self._verbose:\n\t\t\t\t\tprint_text(f\"The chat group {chat_group_id} is not registered.\", color=\"cyan\", end=\"\\n\")\n\t\telse:\n\t\t\tif user_id in self.user_id_list:\n\t\t\t\tupdate_chat_memory(\n\t\t\t\t\tmemory_id=user_id,\n\t\t\t\t\tchat_messages=task.extra_state[\"new_memory\"].get_all(),\n\t\t\t\t)\n\t\t\telse:\n\t\t\t\tif self._verbose and user_id is not None:\n\t\t\t\t\tprint_text(f\"{user_id} is not registered as a user.\", color=\"cyan\", end=\"\\n\")\n\n\t\t# add new messages to memory\n\t\ttask.memory.set(task.memory.get_all() + task.extra_state[\"new_memory\"].get_all())\n\t\t# reset new memory\n\t\ttask.extra_state[\"new_memory\"].reset()\n</code></pre>"},{"location":"code_docs/agent/react/react_step/#labridge.agent.react.react_step.InstructReActAgentWorker.enable_instruct","title":"<code>labridge.agent.react.react_step.InstructReActAgentWorker.enable_instruct</code>  <code>property</code>","text":"<p>Enable user's instruction in reasoning phase.</p>"},{"location":"code_docs/agent/react/react_step/#labridge.agent.react.react_step.InstructReActAgentWorker.finalize_task","title":"<code>labridge.agent.react.react_step.InstructReActAgentWorker.finalize_task(task, **kwargs)</code>","text":"<p>Finalize task, after all the steps are completed.</p> Source code in <code>labridge\\agent\\react\\react_step.py</code> <pre><code>def finalize_task(self, task: Task, **kwargs: Any) -&gt; None:\n\t\"\"\"Finalize task, after all the steps are completed.\"\"\"\n\tuser_id = task.extra_state.get(\"user_id\", None)\n\tchat_group_id = task.extra_state.get(\"chat_group_id\", None)\n\n\tif chat_group_id is not None:\n\t\tif chat_group_id in self.chat_group_id_list:\n\t\t\tupdate_chat_memory(\n\t\t\t\tmemory_id=user_id,\n\t\t\t\tchat_messages=task.extra_state[\"new_memory\"].get_all(),\n\t\t\t)\n\t\telse:\n\t\t\tif self._verbose:\n\t\t\t\tprint_text(f\"The chat group {chat_group_id} is not registered.\", color=\"cyan\", end=\"\\n\")\n\telse:\n\t\tif user_id in self.user_id_list:\n\t\t\tupdate_chat_memory(\n\t\t\t\tmemory_id=user_id,\n\t\t\t\tchat_messages=task.extra_state[\"new_memory\"].get_all(),\n\t\t\t)\n\t\telse:\n\t\t\tif self._verbose and user_id is not None:\n\t\t\t\tprint_text(f\"{user_id} is not registered as a user.\", color=\"cyan\", end=\"\\n\")\n\n\t# add new messages to memory\n\ttask.memory.set(task.memory.get_all() + task.extra_state[\"new_memory\"].get_all())\n\t# reset new memory\n\ttask.extra_state[\"new_memory\"].reset()\n</code></pre>"},{"location":"code_docs/agent/react/react_step/#labridge.agent.react.react_step.InstructReActAgentWorker.from_tools","title":"<code>labridge.agent.react.react_step.InstructReActAgentWorker.from_tools(tools=None, tool_retriever=None, llm=None, user_id_list=None, chat_group_id_list=None, max_iterations=10, react_chat_formatter=None, output_parser=None, callback_manager=None, verbose=False, handle_reasoning_failure_fn=None, enable_instruct=False, **kwargs)</code>  <code>classmethod</code>","text":"<p>Convenience constructor method from set of BaseTools (Optional).</p> <p>NOTE: kwargs should have been exhausted by this point. In other words the various upstream components such as BaseSynthesizer (response synthesizer) or BaseRetriever should have picked up off their respective kwargs in their constructions.</p> RETURNS DESCRIPTION <code>InstructReActAgentWorker</code> <p>ReActAgentWorker</p> Source code in <code>labridge\\agent\\react\\react_step.py</code> <pre><code>@classmethod\ndef from_tools(\n\tcls,\n\ttools: Optional[Sequence[BaseTool]] = None,\n\ttool_retriever: Optional[ObjectRetriever[BaseTool]] = None,\n\tllm: Optional[LLM] = None,\n\tuser_id_list: List[str] = None,\n\tchat_group_id_list: List[str] = None,\n\tmax_iterations: int = 10,\n\treact_chat_formatter: Optional[ReActChatFormatter] = None,\n\toutput_parser: Optional[ReActOutputParser] = None,\n\tcallback_manager: Optional[CallbackManager] = None,\n\tverbose: bool = False,\n\thandle_reasoning_failure_fn: Optional[Callable[[CallbackManager, Exception], ToolOutput]] = None,\n\tenable_instruct: bool = False,\n\t**kwargs: Any,\n) -&gt; \"InstructReActAgentWorker\":\n\t\"\"\"\n\tConvenience constructor method from set of BaseTools (Optional).\n\n\tNOTE: kwargs should have been exhausted by this point. In other words\n\tthe various upstream components such as BaseSynthesizer (response synthesizer)\n\tor BaseRetriever should have picked up off their respective kwargs in their\n\tconstructions.\n\n\tReturns:\n\t\tReActAgentWorker\n\t\"\"\"\n\tllm = llm or Settings.llm\n\tif callback_manager is not None:\n\t\tllm.callback_manager = callback_manager\n\treturn cls(\n\t\ttools=tools or [],\n\t\ttool_retriever=tool_retriever,\n\t\tuser_id_list=user_id_list or AccountManager().get_users(),\n\t\tchat_group_id_list=chat_group_id_list or AccountManager().get_chat_groups(),\n\t\tllm=llm,\n\t\tmax_iterations=max_iterations,\n\t\treact_chat_formatter=react_chat_formatter,\n\t\toutput_parser=output_parser,\n\t\tcallback_manager=callback_manager,\n\t\tverbose=verbose,\n\t\thandle_reasoning_failure_fn=handle_reasoning_failure_fn,\n\t\tenable_instruct=enable_instruct,\n\t)\n</code></pre>"},{"location":"code_docs/agent/react/react_step/#labridge.agent.react.react_step.InstructReActAgentWorker.initialize_step","title":"<code>labridge.agent.react.react_step.InstructReActAgentWorker.initialize_step(task, **kwargs)</code>","text":"<p>Initialize step from task.</p> Source code in <code>labridge\\agent\\react\\react_step.py</code> <pre><code>def initialize_step(self, task: Task, **kwargs: Any) -&gt; TaskStep:\n\t\"\"\"Initialize step from task.\"\"\"\n\tsources: List[ToolOutput] = []\n\tcurrent_reasoning: List[BaseReasoningStep] = []\n\t# temporary memory for new messages\n\tnew_memory = ChatMemoryBuffer.from_defaults()\n\t# the tool log list with ToolLogs.\n\ttool_log = []\n\n\t# initialize task state\n\ttask_state = {\n\t\t\"sources\": sources,\n\t\t\"current_reasoning\": current_reasoning,\n\t\t\"new_memory\": new_memory,\n\t\t\"tool_log\": tool_log,\n\t}\n\ttask.extra_state.update(task_state)\n\n\treturn TaskStep(\n\t\ttask_id=task.task_id,\n\t\tstep_id=str(uuid.uuid4()),\n\t\tinput=task.input,\n\t\tstep_state={\"is_first\": True, \"system_msg\": task.extra_state[\"system_msg\"]},\n\t)\n</code></pre>"},{"location":"code_docs/agent/react/react_step/#labridge.agent.react.react_step.add_user_step_to_reasoning","title":"<code>labridge.agent.react.react_step.add_user_step_to_reasoning(step, memory, current_reasoning, verbose=False)</code>","text":"<p>Add user step to memory.</p> Source code in <code>labridge\\agent\\react\\react_step.py</code> <pre><code>def add_user_step_to_reasoning(\n    step: TaskStep,\n    memory: BaseMemory,\n    current_reasoning: List[BaseReasoningStep],\n    verbose: bool = False,\n) -&gt; None:\n\t\"\"\"Add user step to memory.\"\"\"\n\tif \"is_first\" in step.step_state and step.step_state[\"is_first\"]:\n\t\t# add to new memory\n\t\trecord_str = step.input\n\t\tdate, h_m_s = get_time()\n\t\tadditional_kwargs = {\n\t\t\tLOG_DATE_NAME: date,\n\t\t\tLOG_TIME_NAME: h_m_s,\n\t\t}\n\t\tmemory.put(\n\t\t\tChatMessage(\n\t\t\t\tcontent=step.step_state[\"system_msg\"],\n\t\t\t\trole=MessageRole.SYSTEM,\n\t\t\t\tadditional_kwargs=additional_kwargs,\n\t\t\t)\n\t\t)\n\t\tmemory.put(\n\t\t\tChatMessage(\n\t\t\t\tcontent=record_str,\n\t\t\t\trole=MessageRole.USER,\n\t\t\t\tadditional_kwargs=additional_kwargs,\n\t\t\t)\n\t\t)\n\t\tstep.step_state[\"is_first\"] = False\n\telse:\n\t\treasoning_step = ObservationReasoningStep(observation=step.input)\n\t\tcurrent_reasoning.append(reasoning_step)\n\t\tif verbose:\n\t\t\tprint(f\"Added user message to memory: {step.input}\")\n</code></pre>"},{"location":"code_docs/agent/react/react_step/#labridge.agent.react.react_step.update_intervene_status","title":"<code>labridge.agent.react.react_step.update_intervene_status(task, enable_instruct, enable_comment, reply_in_speech)</code>","text":"<p>Update the <code>enable_instruct</code> and <code>enable_comment</code> in the Reasoning &amp; Acting.</p> PARAMETER DESCRIPTION <code>task</code> <p>The processing task.</p> <p> TYPE: <code>Task</code> </p> <code>enable_instruct</code> <p>If True, enable the user to instruct the agent's Reasoning.</p> <p> TYPE: <code>bool</code> </p> <code>enable_comment</code> <p>If True, enable the user to comment on the agent's Acting.</p> <p> TYPE: <code>bool</code> </p> <code>reply_in_speech</code> <p>If True, the agent will reply in speech.</p> <p> TYPE: <code>bool</code> </p> RETURNS DESCRIPTION <p>None</p> Source code in <code>labridge\\agent\\react\\react_step.py</code> <pre><code>def update_intervene_status(\n\ttask: Task,\n\tenable_instruct: bool,\n\tenable_comment: bool,\n\treply_in_speech: bool\n):\n\tr\"\"\"\n\tUpdate the `enable_instruct` and `enable_comment` in the Reasoning &amp; Acting.\n\n\tArgs:\n\t\ttask (Task): The processing task.\n\t\tenable_instruct (bool): If True, enable the user to instruct the agent's Reasoning.\n\t\tenable_comment (bool): If True, enable the user to comment on the agent's Acting.\n\t\treply_in_speech (bool): If True, the agent will reply in speech.\n\n\tReturns:\n\t\tNone\n\t\"\"\"\n\ttask.extra_state[\"enable_instruct\"] = enable_instruct\n\ttask.extra_state[\"enable_comment\"] = enable_comment\n\ttask.extra_state[\"reply_in_speech\"] = reply_in_speech\n</code></pre>"},{"location":"code_docs/callback/base/operation_base/","title":"Operation base","text":""},{"location":"code_docs/callback/base/operation_base/#labridge.callback.base.operation_base","title":"<code>labridge.callback.base.operation_base</code>","text":""},{"location":"code_docs/callback/base/operation_base/#labridge.callback.base.operation_base.CallBackOperationBase","title":"<code>labridge.callback.base.operation_base.CallBackOperationBase</code>","text":"<p>               Bases: <code>object</code></p> <p>This is base class for callback operation. Here, callback operations indicate those operations requiring the user's permission.</p> PARAMETER DESCRIPTION <code>llm</code> <p>The used LLM.</p> <p> TYPE: <code>LLM</code> </p> <code>embed_model</code> <p>The used embedding model.</p> <p> TYPE: <code>BaseEmbedding</code> </p> <code>verbose</code> <p>Whether to show the inner progress.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> Source code in <code>labridge\\callback\\base\\operation_base.py</code> <pre><code>class CallBackOperationBase(object):\n\tr\"\"\"\n\tThis is base class for callback operation.\n\tHere, callback operations indicate those operations requiring the user's permission.\n\n\tArgs:\n\t\tllm (LLM): The used LLM.\n\t\tembed_model (BaseEmbedding): The used embedding model.\n\t\tverbose (bool): Whether to show the inner progress.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tllm: LLM,\n\t\tembed_model: BaseEmbedding,\n\t\top_name: str,\n\t\tverbose: bool = False,\n\t):\n\t\tself.op_name = op_name\n\t\tself._llm = llm\n\t\tself._embed_model = embed_model\n\t\tself._verbose = verbose\n\n\n\t@abstractmethod\n\tdef operation_description(self, **kwargs) -&gt; str:\n\t\tr\"\"\" This method return the description of the operation, which is presented to the users. \"\"\"\n\n\t@abstractmethod\n\tdef do_operation(self, **kwargs) -&gt; OperationOutputLog:\n\t\tr\"\"\" This method will execute the operation when authorized. And return the operation log \"\"\"\n\n\t@abstractmethod\n\tasync def ado_operation(self, **kwargs) -&gt; OperationOutputLog:\n\t\tr\"\"\" This method will asynchronously execute the operation when authorized. And return the operation log \"\"\"\n</code></pre>"},{"location":"code_docs/callback/base/operation_base/#labridge.callback.base.operation_base.CallBackOperationBase.ado_operation","title":"<code>labridge.callback.base.operation_base.CallBackOperationBase.ado_operation(**kwargs)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>This method will asynchronously execute the operation when authorized. And return the operation log</p> Source code in <code>labridge\\callback\\base\\operation_base.py</code> <pre><code>@abstractmethod\nasync def ado_operation(self, **kwargs) -&gt; OperationOutputLog:\n\tr\"\"\" This method will asynchronously execute the operation when authorized. And return the operation log \"\"\"\n</code></pre>"},{"location":"code_docs/callback/base/operation_base/#labridge.callback.base.operation_base.CallBackOperationBase.do_operation","title":"<code>labridge.callback.base.operation_base.CallBackOperationBase.do_operation(**kwargs)</code>  <code>abstractmethod</code>","text":"<p>This method will execute the operation when authorized. And return the operation log</p> Source code in <code>labridge\\callback\\base\\operation_base.py</code> <pre><code>@abstractmethod\ndef do_operation(self, **kwargs) -&gt; OperationOutputLog:\n\tr\"\"\" This method will execute the operation when authorized. And return the operation log \"\"\"\n</code></pre>"},{"location":"code_docs/callback/base/operation_base/#labridge.callback.base.operation_base.CallBackOperationBase.operation_description","title":"<code>labridge.callback.base.operation_base.CallBackOperationBase.operation_description(**kwargs)</code>  <code>abstractmethod</code>","text":"<p>This method return the description of the operation, which is presented to the users.</p> Source code in <code>labridge\\callback\\base\\operation_base.py</code> <pre><code>@abstractmethod\ndef operation_description(self, **kwargs) -&gt; str:\n\tr\"\"\" This method return the description of the operation, which is presented to the users. \"\"\"\n</code></pre>"},{"location":"code_docs/callback/base/operation_log/","title":"Operation log","text":""},{"location":"code_docs/callback/base/operation_log/#labridge.callback.base.operation_log","title":"<code>labridge.callback.base.operation_log</code>","text":""},{"location":"code_docs/callback/base/operation_log/#labridge.callback.base.operation_log.OperationOutputLog","title":"<code>labridge.callback.base.operation_log.OperationOutputLog</code>","text":"<p>               Bases: <code>object</code></p> <p>This class record the log of a specific callback operation. The <code>operation_output</code> will be a part of the corresponding tool output. The <code>log_to_user</code> and <code>references</code> in <code>log_to_system</code> will be presented to the users.</p> PARAMETER DESCRIPTION <code>operation_name</code> <p>The operation name.</p> <p> TYPE: <code>str</code> </p> <code>operation_output</code> <p>The operation output.</p> <p> TYPE: <code>str</code> </p> <code>log_to_user</code> <p>This log might be presented to the users.</p> <p> TYPE: <code>str</code> </p> <code>log_to_system</code> <p>This log is more structured, specifically, it is a dictionary in JSON format. The keys 'operation_description' and 'references' are required. The values of <code>references</code> are either None or List[str], where the <code>str</code> is in JSON format, for example, the dumped string of a <code>PaperInfo</code>.</p> <p> TYPE: <code>dict</code> </p> Source code in <code>labridge\\callback\\base\\operation_log.py</code> <pre><code>class OperationOutputLog(object):\n\tr\"\"\"\n\tThis class record the log of a specific callback operation.\n\tThe `operation_output` will be a part of the corresponding tool output.\n\tThe `log_to_user` and `references` in `log_to_system` will be presented to the users.\n\n\tArgs:\n\t\toperation_name (str): The operation name.\n\t\toperation_output (str): The operation output.\n\t\tlog_to_user (str): This log might be presented to the users.\n\t\tlog_to_system (dict): This log is more structured, specifically, it is a dictionary in JSON format.\n\t\t\tThe keys 'operation_description' and 'references' are required. The values of `references` are either\n\t\t\tNone or List[str], where the `str` is in JSON format, for example, the dumped string of a `PaperInfo`.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\toperation_name: str,\n\t\toperation_output: Optional[str],\n\t\tlog_to_user: Optional[str],\n\t\tlog_to_system: Dict[str, Union[str, Optional[List[str]]]],\n\t\toperation_abort: Optional[bool] = False,\n\n\t):\n\t\tself.operation_name = operation_name\n\t\tself.operation_output = operation_output\n\t\tself.log_to_user = log_to_user\n\t\tself.operation_abort = operation_abort\n\n\t\tfor key in LOG_TO_SYSTEM_KEYS:\n\t\t\tif key not in log_to_system.keys():\n\t\t\t\traise ValueError(f\"The key {key} is required in the log_to_system.\")\n\n\t\tref = log_to_system[OP_REFERENCES]\n\t\tif ref and not isinstance(ref, list):\n\t\t\traise ValueError(f\"The value of '{OP_REFERENCES}' can only be list or None.\")\n\t\tself.log_to_system = log_to_system\n\n\t@classmethod\n\tdef construct(\n\t\tcls,\n\t\toperation_name: str,\n\t\toperation_output: str,\n\t\top_description: str,\n\t\top_references: Optional[List[str]] = None,\n\t\tlog_to_user: Optional[str] = None,\n\t\toperation_abort: Optional[bool] = False,\n\t):\n\t\treturn cls(\n\t\t\toperation_name=operation_name,\n\t\t\toperation_output=operation_output,\n\t\t\tlog_to_user=log_to_user,\n\t\t\tlog_to_system={\n\t\t\t\tOP_DESCRIPTION: op_description,\n\t\t\t\tOP_REFERENCES: op_references,\n\t\t\t},\n\t\t\toperation_abort = operation_abort,\n\t\t)\n\n\tdef dumps(self) -&gt; str:\n\t\tr\"\"\" Dump to JSON string. \"\"\"\n\t\toutput_logs = {\n\t\t\t\"operation_name\": self.operation_name,\n\t\t\t\"operation_output\": self.operation_output,\n\t\t\t\"log_to_user\": self.log_to_user,\n\t\t\t\"log_to_system\": self.log_to_system,\n\t\t\t\"operation_abort\": self.operation_abort\n\t\t}\n\t\treturn json.dumps(output_logs)\n\n\t@classmethod\n\tdef loads(\n\t\tcls,\n\t\tlog_str: str,\n\t):\n\t\tr\"\"\" Load from JSON string. \"\"\"\n\t\ttry:\n\t\t\toutput_logs = json.loads(log_str)\n\t\t\toperation_name = output_logs[\"operation_name\"]\n\t\t\toperation_output = output_logs[\"operation_output\"]\n\t\t\tlog_to_user = output_logs[\"log_to_user\"]\n\t\t\tlog_to_system = output_logs[\"log_to_system\"]\n\t\t\toperation_abort = output_logs[\"operation_abort\"]\n\t\t\treturn cls(\n\t\t\t\toperation_name=operation_name,\n\t\t\t\toperation_output=operation_output,\n\t\t\t\tlog_to_user=log_to_user,\n\t\t\t\tlog_to_system=log_to_system,\n\t\t\t\toperation_abort=operation_abort,\n\t\t\t)\n\t\texcept Exception:\n\t\t\traise ValueError(\"Invalid operation log string.\")\n</code></pre>"},{"location":"code_docs/callback/base/operation_log/#labridge.callback.base.operation_log.OperationOutputLog.dumps","title":"<code>labridge.callback.base.operation_log.OperationOutputLog.dumps()</code>","text":"<p>Dump to JSON string.</p> Source code in <code>labridge\\callback\\base\\operation_log.py</code> <pre><code>def dumps(self) -&gt; str:\n\tr\"\"\" Dump to JSON string. \"\"\"\n\toutput_logs = {\n\t\t\"operation_name\": self.operation_name,\n\t\t\"operation_output\": self.operation_output,\n\t\t\"log_to_user\": self.log_to_user,\n\t\t\"log_to_system\": self.log_to_system,\n\t\t\"operation_abort\": self.operation_abort\n\t}\n\treturn json.dumps(output_logs)\n</code></pre>"},{"location":"code_docs/callback/base/operation_log/#labridge.callback.base.operation_log.OperationOutputLog.loads","title":"<code>labridge.callback.base.operation_log.OperationOutputLog.loads(log_str)</code>  <code>classmethod</code>","text":"<p>Load from JSON string.</p> Source code in <code>labridge\\callback\\base\\operation_log.py</code> <pre><code>@classmethod\ndef loads(\n\tcls,\n\tlog_str: str,\n):\n\tr\"\"\" Load from JSON string. \"\"\"\n\ttry:\n\t\toutput_logs = json.loads(log_str)\n\t\toperation_name = output_logs[\"operation_name\"]\n\t\toperation_output = output_logs[\"operation_output\"]\n\t\tlog_to_user = output_logs[\"log_to_user\"]\n\t\tlog_to_system = output_logs[\"log_to_system\"]\n\t\toperation_abort = output_logs[\"operation_abort\"]\n\t\treturn cls(\n\t\t\toperation_name=operation_name,\n\t\t\toperation_output=operation_output,\n\t\t\tlog_to_user=log_to_user,\n\t\t\tlog_to_system=log_to_system,\n\t\t\toperation_abort=operation_abort,\n\t\t)\n\texcept Exception:\n\t\traise ValueError(\"Invalid operation log string.\")\n</code></pre>"},{"location":"code_docs/callback/experiment_log/new_experiment/","title":"New experiment","text":""},{"location":"code_docs/callback/experiment_log/new_experiment/#labridge.callback.experiment_log.new_experiment","title":"<code>labridge.callback.experiment_log.new_experiment</code>","text":""},{"location":"code_docs/callback/experiment_log/new_experiment/#labridge.callback.experiment_log.new_experiment.CreateNewExperimentLogOperation","title":"<code>labridge.callback.experiment_log.new_experiment.CreateNewExperimentLogOperation</code>","text":"<p>               Bases: <code>CallBackOperationBase</code></p> <p>This operation will create a new experiment record for a specific user.</p> PARAMETER DESCRIPTION <code>llm</code> <p>The used LLM.</p> <p> TYPE: <code>LLM</code> DEFAULT: <code>None</code> </p> <code>embed_model</code> <p>The used embedding model.</p> <p> TYPE: <code>BaseEmbedding</code> DEFAULT: <code>None</code> </p> <code>verbose</code> <p>Whether to show the inner progress.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> Source code in <code>labridge\\callback\\experiment_log\\new_experiment.py</code> <pre><code>class CreateNewExperimentLogOperation(CallBackOperationBase):\n\tr\"\"\"\n\tThis operation will create a new experiment record for a specific user.\n\n\tArgs:\n\t\tllm (LLM): The used LLM.\n\t\tembed_model (BaseEmbedding): The used embedding model.\n\t\tverbose (bool): Whether to show the inner progress.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tllm: LLM = None,\n\t\tembed_model: BaseEmbedding = None,\n\t\tverbose: bool = False,\n\t\top_name: str = None,\n\t):\n\t\tembed_model = embed_model or Settings.embed_model\n\t\tllm = llm or Settings.llm\n\t\tsuper().__init__(\n\t\t\tllm=llm,\n\t\t\tembed_model=embed_model,\n\t\t\tverbose=verbose,\n\t\t\top_name=op_name or CreateNewExperimentLogOperation.__name__,\n\t\t)\n\n\tdef operation_description(self, **kwargs) -&gt; str:\n\t\tr\"\"\"\n\t\tReturn the operation description, this description will be sent to the user for authorization.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user id of a lab member.\n\t\t\texperiment_name (str): The name of the new experiment.\n\t\t\texperiment_description (str): The description of the new experiment.\n\n\t\tReturns:\n\t\t\tstr: The operation description.\n\t\t\"\"\"\n\t\tuser_id = kwargs[\"user_id\"]\n\t\texpr_name = kwargs[NEW_EXPERIMENT_NAME_KEY]\n\t\texpr_description = kwargs[NEW_EXPERIMENT_DESCRIPTION_KEY]\n\n\t\top_description = CREATE_NEW_EXPERIMENT_DESCRIPTION.format(\n\t\t\tuser_id=user_id,\n\t\t\texperiment_name=expr_name,\n\t\t\texperiment_description=expr_description,\n\t\t)\n\t\treturn op_description\n\n\tdef do_operation(self, **kwargs) -&gt; OperationOutputLog:\n\t\tr\"\"\"\n\t\tExecute the operation to add a new experiment record.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user id of a lab member.\n\t\t\texperiment_name (str): The name of the new experiment.\n\t\t\texperiment_description (str): The description of the new experiment.\n\n\t\tReturns:\n\t\t\tOperationOutputLog: The output and log of the operation.\n\t\t\"\"\"\n\t\tuser_id = kwargs[\"user_id\"]\n\t\texpr_name = kwargs[NEW_EXPERIMENT_NAME_KEY]\n\t\texpr_description = kwargs[NEW_EXPERIMENT_DESCRIPTION_KEY]\n\t\texpr_log_store = ExperimentLog.from_user_id(\n\t\t\tuser_id=user_id,\n\t\t\tembed_model=self._embed_model,\n\t\t)\n\n\t\texpr_log_store.create_experiment(\n\t\t\texperiment_name=expr_name,\n\t\t\tdescription=expr_description,\n\t\t)\n\t\texpr_log_store.persist()\n\n\t\top_log_str = (\n\t\t\tf\"Have created a new experiment log record for the user {user_id}.\\n\"\n\t\t\tf\"Experiment name: {expr_name}\"\n\t\t)\n\t\treturn OperationOutputLog(\n\t\t\toperation_name=self.op_name,\n\t\t\toperation_output=None,\n\t\t\tlog_to_user=None,\n\t\t\tlog_to_system={\n\t\t\t\tOP_DESCRIPTION: op_log_str,\n\t\t\t\tOP_REFERENCES: None,\n\t\t\t}\n\t\t)\n\n\tasync def ado_operation(self, **kwargs) -&gt; OperationOutputLog:\n\t\treturn self.do_operation(**kwargs)\n</code></pre>"},{"location":"code_docs/callback/experiment_log/new_experiment/#labridge.callback.experiment_log.new_experiment.CreateNewExperimentLogOperation.do_operation","title":"<code>labridge.callback.experiment_log.new_experiment.CreateNewExperimentLogOperation.do_operation(**kwargs)</code>","text":"<p>Execute the operation to add a new experiment record.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user id of a lab member.</p> <p> TYPE: <code>str</code> </p> <code>experiment_name</code> <p>The name of the new experiment.</p> <p> TYPE: <code>str</code> </p> <code>experiment_description</code> <p>The description of the new experiment.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>OperationOutputLog</code> <p>The output and log of the operation.</p> <p> TYPE: <code>OperationOutputLog</code> </p> Source code in <code>labridge\\callback\\experiment_log\\new_experiment.py</code> <pre><code>def do_operation(self, **kwargs) -&gt; OperationOutputLog:\n\tr\"\"\"\n\tExecute the operation to add a new experiment record.\n\n\tArgs:\n\t\tuser_id (str): The user id of a lab member.\n\t\texperiment_name (str): The name of the new experiment.\n\t\texperiment_description (str): The description of the new experiment.\n\n\tReturns:\n\t\tOperationOutputLog: The output and log of the operation.\n\t\"\"\"\n\tuser_id = kwargs[\"user_id\"]\n\texpr_name = kwargs[NEW_EXPERIMENT_NAME_KEY]\n\texpr_description = kwargs[NEW_EXPERIMENT_DESCRIPTION_KEY]\n\texpr_log_store = ExperimentLog.from_user_id(\n\t\tuser_id=user_id,\n\t\tembed_model=self._embed_model,\n\t)\n\n\texpr_log_store.create_experiment(\n\t\texperiment_name=expr_name,\n\t\tdescription=expr_description,\n\t)\n\texpr_log_store.persist()\n\n\top_log_str = (\n\t\tf\"Have created a new experiment log record for the user {user_id}.\\n\"\n\t\tf\"Experiment name: {expr_name}\"\n\t)\n\treturn OperationOutputLog(\n\t\toperation_name=self.op_name,\n\t\toperation_output=None,\n\t\tlog_to_user=None,\n\t\tlog_to_system={\n\t\t\tOP_DESCRIPTION: op_log_str,\n\t\t\tOP_REFERENCES: None,\n\t\t}\n\t)\n</code></pre>"},{"location":"code_docs/callback/experiment_log/new_experiment/#labridge.callback.experiment_log.new_experiment.CreateNewExperimentLogOperation.operation_description","title":"<code>labridge.callback.experiment_log.new_experiment.CreateNewExperimentLogOperation.operation_description(**kwargs)</code>","text":"<p>Return the operation description, this description will be sent to the user for authorization.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user id of a lab member.</p> <p> TYPE: <code>str</code> </p> <code>experiment_name</code> <p>The name of the new experiment.</p> <p> TYPE: <code>str</code> </p> <code>experiment_description</code> <p>The description of the new experiment.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>str</code> <p>The operation description.</p> <p> TYPE: <code>str</code> </p> Source code in <code>labridge\\callback\\experiment_log\\new_experiment.py</code> <pre><code>def operation_description(self, **kwargs) -&gt; str:\n\tr\"\"\"\n\tReturn the operation description, this description will be sent to the user for authorization.\n\n\tArgs:\n\t\tuser_id (str): The user id of a lab member.\n\t\texperiment_name (str): The name of the new experiment.\n\t\texperiment_description (str): The description of the new experiment.\n\n\tReturns:\n\t\tstr: The operation description.\n\t\"\"\"\n\tuser_id = kwargs[\"user_id\"]\n\texpr_name = kwargs[NEW_EXPERIMENT_NAME_KEY]\n\texpr_description = kwargs[NEW_EXPERIMENT_DESCRIPTION_KEY]\n\n\top_description = CREATE_NEW_EXPERIMENT_DESCRIPTION.format(\n\t\tuser_id=user_id,\n\t\texperiment_name=expr_name,\n\t\texperiment_description=expr_description,\n\t)\n\treturn op_description\n</code></pre>"},{"location":"code_docs/callback/experiment_log/set_current_experiment/","title":"Set current experiment","text":""},{"location":"code_docs/callback/experiment_log/set_current_experiment/#labridge.callback.experiment_log.set_current_experiment","title":"<code>labridge.callback.experiment_log.set_current_experiment</code>","text":""},{"location":"code_docs/callback/experiment_log/set_current_experiment/#labridge.callback.experiment_log.set_current_experiment.SetCurrentExperimentOperation","title":"<code>labridge.callback.experiment_log.set_current_experiment.SetCurrentExperimentOperation</code>","text":"<p>               Bases: <code>CallBackOperationBase</code></p> <p>This operation will set a recorded experiment as the user's experiment in progress.</p> PARAMETER DESCRIPTION <code>llm</code> <p>The used LLM.</p> <p> TYPE: <code>LLM</code> DEFAULT: <code>None</code> </p> <code>embed_model</code> <p>The used embedding model.</p> <p> TYPE: <code>BaseEmbedding</code> DEFAULT: <code>None</code> </p> <code>verbose</code> <p>Whether to show the inner progress.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> Source code in <code>labridge\\callback\\experiment_log\\set_current_experiment.py</code> <pre><code>class SetCurrentExperimentOperation(CallBackOperationBase):\n\tr\"\"\"\n\tThis operation will set a recorded experiment as the user's experiment in progress.\n\n\tArgs:\n\t\tllm (LLM): The used LLM.\n\t\tembed_model (BaseEmbedding): The used embedding model.\n\t\tverbose (bool): Whether to show the inner progress.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tllm: LLM = None,\n\t\tembed_model: BaseEmbedding = None,\n\t\tverbose: bool = False,\n\t\top_name: str = None,\n\t):\n\n\t\tllm = llm or Settings.llm\n\t\tembed_model = embed_model or Settings.embed_model\n\t\tsuper().__init__(\n\t\t\tllm=llm,\n\t\t\tembed_model=embed_model,\n\t\t\tverbose=verbose,\n\t\t\top_name=op_name or SetCurrentExperimentOperation.__name__,\n\t\t)\n\n\tdef operation_description(self, **kwargs) -&gt; str:\n\t\tr\"\"\"\n\t\tReturn the operation description, this description will be sent to the user for authorization.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user id of a lab member.\n\t\t\texperiment_name (str): The name of a recorded experiment.\n\t\t\texperiment_duration (str): The duration of the experiment, in a format of \"%Hh%Mm%Ss\",\n\t\t\t\trefer to `common.utils.time`.\n\n\t\tReturns:\n\t\t\tstr: The operation description.\n\t\t\"\"\"\n\t\tuser_id = kwargs[\"user_id\"]\n\t\texperiment_name = kwargs[\"experiment_name\"]\n\t\texperiment_duration = kwargs[\"experiment_duration\"]\n\n\t\tstart_date, start_time = get_time()\n\t\tstart = str_to_datetime(date_str=start_date, time_str=start_time)\n\t\tdelta_time = str_to_delta_time(time_str=experiment_duration)\n\t\tend = start + delta_time\n\t\tend_date, end_time = datetime_to_str(date_time=end)\n\t\top_description = SET_CURRENT_EXPERIMENT_DESCRIPTION.format(\n\t\t\tuser_id=user_id,\n\t\t\texperiment_name=experiment_name,\n\t\t\tstart_date=start_date,\n\t\t\tstart_time=start_time,\n\t\t\tend_date=end_date,\n\t\t\tend_time=end_time,\n\t\t)\n\t\treturn op_description\n\n\tdef do_operation(self, **kwargs) -&gt; OperationOutputLog:\n\t\tr\"\"\"\n\t\tExecute the operation set the experiment in progress for a user.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user id of a lab member.\n\t\t\texperiment_name (str): The name of a recorded experiment.\n\t\t\texperiment_duration (str): The duration of the experiment, in a format of \"%Hh%Mm%Ss\",\n\t\t\t\trefer to `common.utils.time`.\n\n\t\tReturns:\n\t\t\tOperationOutputLog: The output and log of the operation.\n\t\t\"\"\"\n\t\tuser_id = kwargs[\"user_id\"]\n\t\texperiment_name = kwargs[\"experiment_name\"]\n\t\texperiment_duration = kwargs[\"experiment_duration\"]\n\n\t\tstart_date, start_time = get_time()\n\t\tstart = str_to_datetime(date_str=start_date, time_str=start_time)\n\t\tdelta_time = str_to_delta_time(time_str=experiment_duration)\n\t\tend = start + delta_time\n\t\tend_date, end_time = datetime_to_str(date_time=end)\n\n\t\texpr_log_store = ExperimentLog.from_user_id(\n\t\t\tuser_id=user_id,\n\t\t\tembed_model=self._embed_model\n\t\t)\n\t\texpr_log_store.set_recent_experiment(\n\t\t\texperiment_name=experiment_name,\n\t\t\tstart_date=start_date,\n\t\t\tstart_time=start_time,\n\t\t\tend_date=end_date,\n\t\t\tend_time=end_time,\n\t\t)\n\t\texpr_log_store.persist()\n\t\top_log_str = (\n\t\t\tf\"Set the experiment in progress for {user_id}.\\n\"\n\t\t\tf\"Experiment name: {experiment_name}.\\n\"\n\t\t\tf\"Start from {start_date}, {start_time} to {end_date}, {end_time}.\"\n\t\t)\n\t\treturn OperationOutputLog(\n\t\t\toperation_name=self.op_name,\n\t\t\toperation_output=None,\n\t\t\tlog_to_user=None,\n\t\t\tlog_to_system={\n\t\t\t\tOP_DESCRIPTION: op_log_str,\n\t\t\t\tOP_REFERENCES: None,\n\t\t\t}\n\t\t)\n\n\tasync def ado_operation(self, **kwargs) -&gt; OperationOutputLog:\n\t\treturn self.do_operation(**kwargs)\n</code></pre>"},{"location":"code_docs/callback/experiment_log/set_current_experiment/#labridge.callback.experiment_log.set_current_experiment.SetCurrentExperimentOperation.do_operation","title":"<code>labridge.callback.experiment_log.set_current_experiment.SetCurrentExperimentOperation.do_operation(**kwargs)</code>","text":"<p>Execute the operation set the experiment in progress for a user.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user id of a lab member.</p> <p> TYPE: <code>str</code> </p> <code>experiment_name</code> <p>The name of a recorded experiment.</p> <p> TYPE: <code>str</code> </p> <code>experiment_duration</code> <p>The duration of the experiment, in a format of \"%Hh%Mm%Ss\", refer to <code>common.utils.time</code>.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>OperationOutputLog</code> <p>The output and log of the operation.</p> <p> TYPE: <code>OperationOutputLog</code> </p> Source code in <code>labridge\\callback\\experiment_log\\set_current_experiment.py</code> <pre><code>def do_operation(self, **kwargs) -&gt; OperationOutputLog:\n\tr\"\"\"\n\tExecute the operation set the experiment in progress for a user.\n\n\tArgs:\n\t\tuser_id (str): The user id of a lab member.\n\t\texperiment_name (str): The name of a recorded experiment.\n\t\texperiment_duration (str): The duration of the experiment, in a format of \"%Hh%Mm%Ss\",\n\t\t\trefer to `common.utils.time`.\n\n\tReturns:\n\t\tOperationOutputLog: The output and log of the operation.\n\t\"\"\"\n\tuser_id = kwargs[\"user_id\"]\n\texperiment_name = kwargs[\"experiment_name\"]\n\texperiment_duration = kwargs[\"experiment_duration\"]\n\n\tstart_date, start_time = get_time()\n\tstart = str_to_datetime(date_str=start_date, time_str=start_time)\n\tdelta_time = str_to_delta_time(time_str=experiment_duration)\n\tend = start + delta_time\n\tend_date, end_time = datetime_to_str(date_time=end)\n\n\texpr_log_store = ExperimentLog.from_user_id(\n\t\tuser_id=user_id,\n\t\tembed_model=self._embed_model\n\t)\n\texpr_log_store.set_recent_experiment(\n\t\texperiment_name=experiment_name,\n\t\tstart_date=start_date,\n\t\tstart_time=start_time,\n\t\tend_date=end_date,\n\t\tend_time=end_time,\n\t)\n\texpr_log_store.persist()\n\top_log_str = (\n\t\tf\"Set the experiment in progress for {user_id}.\\n\"\n\t\tf\"Experiment name: {experiment_name}.\\n\"\n\t\tf\"Start from {start_date}, {start_time} to {end_date}, {end_time}.\"\n\t)\n\treturn OperationOutputLog(\n\t\toperation_name=self.op_name,\n\t\toperation_output=None,\n\t\tlog_to_user=None,\n\t\tlog_to_system={\n\t\t\tOP_DESCRIPTION: op_log_str,\n\t\t\tOP_REFERENCES: None,\n\t\t}\n\t)\n</code></pre>"},{"location":"code_docs/callback/experiment_log/set_current_experiment/#labridge.callback.experiment_log.set_current_experiment.SetCurrentExperimentOperation.operation_description","title":"<code>labridge.callback.experiment_log.set_current_experiment.SetCurrentExperimentOperation.operation_description(**kwargs)</code>","text":"<p>Return the operation description, this description will be sent to the user for authorization.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user id of a lab member.</p> <p> TYPE: <code>str</code> </p> <code>experiment_name</code> <p>The name of a recorded experiment.</p> <p> TYPE: <code>str</code> </p> <code>experiment_duration</code> <p>The duration of the experiment, in a format of \"%Hh%Mm%Ss\", refer to <code>common.utils.time</code>.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>str</code> <p>The operation description.</p> <p> TYPE: <code>str</code> </p> Source code in <code>labridge\\callback\\experiment_log\\set_current_experiment.py</code> <pre><code>def operation_description(self, **kwargs) -&gt; str:\n\tr\"\"\"\n\tReturn the operation description, this description will be sent to the user for authorization.\n\n\tArgs:\n\t\tuser_id (str): The user id of a lab member.\n\t\texperiment_name (str): The name of a recorded experiment.\n\t\texperiment_duration (str): The duration of the experiment, in a format of \"%Hh%Mm%Ss\",\n\t\t\trefer to `common.utils.time`.\n\n\tReturns:\n\t\tstr: The operation description.\n\t\"\"\"\n\tuser_id = kwargs[\"user_id\"]\n\texperiment_name = kwargs[\"experiment_name\"]\n\texperiment_duration = kwargs[\"experiment_duration\"]\n\n\tstart_date, start_time = get_time()\n\tstart = str_to_datetime(date_str=start_date, time_str=start_time)\n\tdelta_time = str_to_delta_time(time_str=experiment_duration)\n\tend = start + delta_time\n\tend_date, end_time = datetime_to_str(date_time=end)\n\top_description = SET_CURRENT_EXPERIMENT_DESCRIPTION.format(\n\t\tuser_id=user_id,\n\t\texperiment_name=experiment_name,\n\t\tstart_date=start_date,\n\t\tstart_time=start_time,\n\t\tend_date=end_date,\n\t\tend_time=end_time,\n\t)\n\treturn op_description\n</code></pre>"},{"location":"code_docs/callback/paper/add_recent_paper/","title":"Add recent paper","text":""},{"location":"code_docs/callback/paper/add_recent_paper/#labridge.callback.paper.add_paper","title":"<code>labridge.callback.paper.add_paper</code>","text":""},{"location":"code_docs/callback/paper/add_recent_paper/#labridge.callback.paper.add_paper.AddNewRecentPaperOperation","title":"<code>labridge.callback.paper.add_paper.AddNewRecentPaperOperation</code>","text":"<p>               Bases: <code>CallBackOperationBase</code></p> <p>This operation will add a new paper into a user's recent papers.</p> PARAMETER DESCRIPTION <code>llm</code> <p>The used LLM.</p> <p> TYPE: <code>LLM</code> DEFAULT: <code>None</code> </p> <code>embed_model</code> <p>The used embedding model.</p> <p> TYPE: <code>BaseEmbedding</code> DEFAULT: <code>None</code> </p> <code>verbose</code> <p>Whether to show the inner progress.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> Source code in <code>labridge\\callback\\paper\\add_paper.py</code> <pre><code>class AddNewRecentPaperOperation(CallBackOperationBase):\n\tr\"\"\"\n\tThis operation will add a new paper into a user's recent papers.\n\n\tArgs:\n\t\tllm (LLM): The used LLM.\n\t\tembed_model (BaseEmbedding): The used embedding model.\n\t\tverbose (bool): Whether to show the inner progress.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tllm: LLM = None,\n\t\tembed_model: BaseEmbedding = None,\n\t\tverbose: bool = False,\n\t\top_name: str = None,\n\t):\n\t\tembed_model = embed_model or Settings.embed_model\n\t\tllm = llm or Settings.llm\n\t\tsuper().__init__(\n\t\t\tembed_model=embed_model,\n\t\t\tllm=llm,\n\t\t\tverbose=verbose,\n\t\t\top_name=op_name or AddNewRecentPaperOperation.__name__,\n\t\t)\n\n\tdef operation_description(self, **kwargs) -&gt; str:\n\t\tr\"\"\"\n\t\tReturn the operation description, this description will be sent to the user for authorization.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user id of a lab member.\n\t\t\tpaper_file_path (str): The file path of the new paper.\n\n\t\tReturns:\n\t\t\tstr: The operation description.\n\t\t\"\"\"\n\t\tuser_id = kwargs.get(\"user_id\", None)\n\t\tpaper_file_path = kwargs.get(\"paper_file_path\", None)\n\n\t\tif None in [user_id, paper_file_path]:\n\t\t\traise ValueError(f\"Should provide these arguments: user_id, paper_file_path.\")\n\t\treturn ADD_NEW_RECENT_PAPER_TMPL.format(\n\t\t\tuser_id=user_id,\n\t\t\tpaper_file_path=paper_file_path,\n\t\t)\n\n\tdef do_operation(\n\t\tself,\n\t\t**kwargs\n\t) -&gt; OperationOutputLog:\n\t\tr\"\"\"\n\t\tExecute the operation after authorized to add a new paper to a user's recent papers.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user id of a lab member.\n\t\t\tpaper_file_path (str): The file path of the new paper.\n\n\t\tReturns:\n\t\t\tOperationOutputLog: The output and log of the operation.\n\t\t\"\"\"\n\t\tuser_id = kwargs.get(\"user_id\", None)\n\t\tpaper_file_path = kwargs.get(\"paper_file_path\", None)\n\n\t\tif None in [user_id, paper_file_path]:\n\t\t\traise ValueError(f\"Should provide these arguments: user_id, paper_file_path.\")\n\n\t\tpaper_store = RecentPaperStore.from_user_id(\n\t\t\tuser_id=user_id,\n\t\t\tembed_model=self._embed_model,\n\t\t)\n\t\ttry:\n\t\t\tpaper_store.put(paper_file_path=paper_file_path)\n\t\t\tpaper_store.persist()\n\t\t\top_log = (\n\t\t\t\tf\"Have put a new paper to the recent papers of the user {user_id}\\n\"\n\t\t\t\tf\"Paper file path: {paper_file_path}\"\n\t\t\t)\n\t\t\tpaper_info = PaperInfo(\n\t\t\t\tfile_path=paper_file_path,\n\t\t\t\tpossessor=user_id,\n\t\t\t\ttitle=paper_file_path,\n\t\t\t)\n\t\t\treturn OperationOutputLog(\n\t\t\t\toperation_name=self.op_name,\n\t\t\t\toperation_output=None,\n\t\t\t\tlog_to_user=None,\n\t\t\t\tlog_to_system={\n\t\t\t\t\tOP_DESCRIPTION: op_log,\n\t\t\t\t\tOP_REFERENCES: [paper_info.dumps()]\n\t\t\t\t}\n\t\t\t)\n\n\t\texcept Exception as e:\n\t\t\top_log = f\"Error: {e}\"\n\t\t\treturn OperationOutputLog(\n\t\t\t\toperation_name=self.op_name,\n\t\t\t\toperation_output=None,\n\t\t\t\tlog_to_user=None,\n\t\t\t\tlog_to_system={\n\t\t\t\t\tOP_DESCRIPTION: op_log,\n\t\t\t\t\tOP_REFERENCES: None\n\t\t\t\t}\n\t\t)\n\n\tasync def ado_operation(\n\t\tself,\n\t\t**kwargs\n\t) -&gt; OperationOutputLog:\n\t\treturn self.do_operation(**kwargs)\n</code></pre>"},{"location":"code_docs/callback/paper/add_recent_paper/#labridge.callback.paper.add_paper.AddNewRecentPaperOperation.do_operation","title":"<code>labridge.callback.paper.add_paper.AddNewRecentPaperOperation.do_operation(**kwargs)</code>","text":"<p>Execute the operation after authorized to add a new paper to a user's recent papers.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user id of a lab member.</p> <p> TYPE: <code>str</code> </p> <code>paper_file_path</code> <p>The file path of the new paper.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>OperationOutputLog</code> <p>The output and log of the operation.</p> <p> TYPE: <code>OperationOutputLog</code> </p> Source code in <code>labridge\\callback\\paper\\add_paper.py</code> <pre><code>def do_operation(\n\tself,\n\t**kwargs\n) -&gt; OperationOutputLog:\n\tr\"\"\"\n\tExecute the operation after authorized to add a new paper to a user's recent papers.\n\n\tArgs:\n\t\tuser_id (str): The user id of a lab member.\n\t\tpaper_file_path (str): The file path of the new paper.\n\n\tReturns:\n\t\tOperationOutputLog: The output and log of the operation.\n\t\"\"\"\n\tuser_id = kwargs.get(\"user_id\", None)\n\tpaper_file_path = kwargs.get(\"paper_file_path\", None)\n\n\tif None in [user_id, paper_file_path]:\n\t\traise ValueError(f\"Should provide these arguments: user_id, paper_file_path.\")\n\n\tpaper_store = RecentPaperStore.from_user_id(\n\t\tuser_id=user_id,\n\t\tembed_model=self._embed_model,\n\t)\n\ttry:\n\t\tpaper_store.put(paper_file_path=paper_file_path)\n\t\tpaper_store.persist()\n\t\top_log = (\n\t\t\tf\"Have put a new paper to the recent papers of the user {user_id}\\n\"\n\t\t\tf\"Paper file path: {paper_file_path}\"\n\t\t)\n\t\tpaper_info = PaperInfo(\n\t\t\tfile_path=paper_file_path,\n\t\t\tpossessor=user_id,\n\t\t\ttitle=paper_file_path,\n\t\t)\n\t\treturn OperationOutputLog(\n\t\t\toperation_name=self.op_name,\n\t\t\toperation_output=None,\n\t\t\tlog_to_user=None,\n\t\t\tlog_to_system={\n\t\t\t\tOP_DESCRIPTION: op_log,\n\t\t\t\tOP_REFERENCES: [paper_info.dumps()]\n\t\t\t}\n\t\t)\n\n\texcept Exception as e:\n\t\top_log = f\"Error: {e}\"\n\t\treturn OperationOutputLog(\n\t\t\toperation_name=self.op_name,\n\t\t\toperation_output=None,\n\t\t\tlog_to_user=None,\n\t\t\tlog_to_system={\n\t\t\t\tOP_DESCRIPTION: op_log,\n\t\t\t\tOP_REFERENCES: None\n\t\t\t}\n\t)\n</code></pre>"},{"location":"code_docs/callback/paper/add_recent_paper/#labridge.callback.paper.add_paper.AddNewRecentPaperOperation.operation_description","title":"<code>labridge.callback.paper.add_paper.AddNewRecentPaperOperation.operation_description(**kwargs)</code>","text":"<p>Return the operation description, this description will be sent to the user for authorization.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user id of a lab member.</p> <p> TYPE: <code>str</code> </p> <code>paper_file_path</code> <p>The file path of the new paper.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>str</code> <p>The operation description.</p> <p> TYPE: <code>str</code> </p> Source code in <code>labridge\\callback\\paper\\add_paper.py</code> <pre><code>def operation_description(self, **kwargs) -&gt; str:\n\tr\"\"\"\n\tReturn the operation description, this description will be sent to the user for authorization.\n\n\tArgs:\n\t\tuser_id (str): The user id of a lab member.\n\t\tpaper_file_path (str): The file path of the new paper.\n\n\tReturns:\n\t\tstr: The operation description.\n\t\"\"\"\n\tuser_id = kwargs.get(\"user_id\", None)\n\tpaper_file_path = kwargs.get(\"paper_file_path\", None)\n\n\tif None in [user_id, paper_file_path]:\n\t\traise ValueError(f\"Should provide these arguments: user_id, paper_file_path.\")\n\treturn ADD_NEW_RECENT_PAPER_TMPL.format(\n\t\tuser_id=user_id,\n\t\tpaper_file_path=paper_file_path,\n\t)\n</code></pre>"},{"location":"code_docs/callback/paper/paper_download/","title":"Paper download","text":""},{"location":"code_docs/callback/paper/paper_download/#labridge.callback.paper.paper_download","title":"<code>labridge.callback.paper.paper_download</code>","text":""},{"location":"code_docs/callback/paper/paper_download/#labridge.callback.paper.paper_download.ArxivDownloadOperation","title":"<code>labridge.callback.paper.paper_download.ArxivDownloadOperation</code>","text":"<p>               Bases: <code>CallBackOperationBase</code></p> <p>This operation will download papers from aXiv for the user.</p> PARAMETER DESCRIPTION <code>llm</code> <p>The used LLM.</p> <p> TYPE: <code>LLM</code> DEFAULT: <code>None</code> </p> <code>embed_model</code> <p>The used embedding model.</p> <p> TYPE: <code>BaseEmbedding</code> DEFAULT: <code>None</code> </p> <code>verbose</code> <p>Whether to show the inner progress.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> Source code in <code>labridge\\callback\\paper\\paper_download.py</code> <pre><code>class ArxivDownloadOperation(CallBackOperationBase):\n\tr\"\"\"\n\tThis operation will download papers from aXiv for the user.\n\n\tArgs:\n\t\tllm (LLM): The used LLM.\n\t\tembed_model (BaseEmbedding): The used embedding model.\n\t\tverbose (bool): Whether to show the inner progress.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tllm: LLM = None,\n\t\tembed_model: BaseEmbedding = None,\n\t\tverbose: bool = False,\n\t\top_name: str = None,\n\t):\n\t\troot = Path(__file__)\n\n\t\tfor idx in range(4):\n\t\t\troot = root.parent\n\n\t\tself.root = root\n\t\tself._fs = fsspec.filesystem(\"file\")\n\t\tembed_model = embed_model or Settings.embed_model\n\t\tllm = llm or Settings.llm\n\t\tsuper().__init__(\n\t\t\tllm=llm,\n\t\t\tembed_model=embed_model,\n\t\t\tverbose=verbose,\n\t\t\top_name=op_name or ArxivDownloadOperation.__name__,\n\t\t)\n\n\tdef _get_default_path(self, user_id: str, title: str) -&gt; Tuple[str, str]:\n\t\tr\"\"\"\n\t\tThe downloaded paper will be stored in the user's recent paper warehouse.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user id of a lab member.\n\t\t\ttitle (str): The title of the paper, will be used as the filename.\n\n\t\tReturns:\n\t\t\tTuple[str, str]:\n\t\t\t\tThe paper file path and file name.\n\t\t\"\"\"\n\t\tfile_name = f\"{title}.pdf\"\n\t\tfile_dir = self.root / TMP_PAPER_WAREHOUSE_DIR\n\t\tfile_dir = file_dir / user_id\n\n\t\tif not self._fs.exists(file_dir):\n\t\t\tself._fs.makedirs(file_dir)\n\t\treturn str(file_dir), file_name\n\n\tdef operation_description(self, **kwargs) -&gt; str:\n\t\tr\"\"\"\n\t\tDescribe the operation.\n\n\t\tArgs:\n\t\t\tuser_id (str): the user id.\n\t\t\tpaper_infos (List[Dict[str, str]]): the metadata of papers,\n\t\t\t\tfor each paper, the `title` must be provided.\n\n\t\tReturns:\n\t\t\tthe operation description.\n\t\t\"\"\"\n\t\tuser_id = kwargs.get(\"user_id\", None)\n\t\tpaper_infos = kwargs.get(\"paper_infos\", None)\n\n\t\tif None in [user_id, paper_infos]:\n\t\t\traise ValueError(\"should provide valid user_id, paper_infos.\")\n\n\t\tpapers = []\n\t\tfor paper in paper_infos:\n\t\t\ttitle = paper.get(\"title\", None)\n\t\t\tfile_dir, file_name = self._get_default_path(user_id=user_id, title=title)\n\t\t\tsave_path = str(Path(file_dir) / file_name)\n\t\t\tpaper_dsc = PAPER_DESCRIPTION_TMPL.format(title=title, save_path=save_path)\n\t\t\tpapers.append(paper_dsc)\n\t\tpapers = \"\\n\\n\".join(papers)\n\t\theader = ARXIV_DOWNLOAD_DESCRIPTION.format(user_id=user_id)\n\t\tdescription = f\"{header}\\n{papers}\"\n\t\treturn description\n\n\tdef download_paper(self, user_id: str, title: str, pdf_url: str) -&gt; Optional[str]:\n\t\tr\"\"\"\n\t\tDownload a paper from arxiv and save to the user's recent paper directory.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user id of a lab member.\n\t\t\ttitle (str): The paper title.\n\t\t\tpdf_url (str): The paper URL.\n\n\t\tReturns:\n\t\t\tOptional[str]:\n\n\t\t\t\t- If the paper is successfully downloaded, return the file_path.\n\t\t\t\t- If the downloading fails, return None.\n\t\t\"\"\"\n\t\tif None in [user_id, title, pdf_url]:\n\t\t\traise ValueError(\"should provide valid user_id, title, pdf_url to download paper.\")\n\t\tfile_dir, file_name = self._get_default_path(user_id=user_id, title=title)\n\t\tresult = Result(entry_id=\"\")\n\t\tresult.pdf_url = pdf_url\n\n\t\tif self._verbose:\n\t\t\tprint_text(text=f\"Downloading paper '{title}' ...\", color=\"pink\", end=\"\\n\")\n\n\t\ttry:\n\t\t\tresult.download_pdf(dirpath=file_dir, filename=file_name)\n\t\t\tfile_path = str(Path(file_dir) / file_name)\n\t\t\treturn file_path\n\t\texcept Exception as e:\n\t\t\tprint(f\"Download failed. Error: {e}\")\n\t\t\treturn None\n\n\tasync def adownload_paper(self, user_id: str, title: str, pdf_url: str) -&gt; Optional[str]:\n\t\tr\"\"\"\n\t\tAsynchronously download a paper from arxiv and save to the user's recent paper directory.\n\t\t\"\"\"\n\t\tif None in [user_id, title, pdf_url]:\n\t\t\traise ValueError(\"should provide valid user_id, title, pdf_url to download paper.\")\n\n\t\tfile_dir, file_name = self._get_default_path(user_id=user_id, title=title)\n\t\tfile_path = str(Path(file_dir) / file_name)\n\n\t\tif self._verbose:\n\t\t\tprint_text(text=f\"Downloading paper '{title}' ...\", color=\"pink\", end=\"\\n\")\n\t\ttry:\n\t\t\tawait adownload_file(url=pdf_url, save_path=file_path)\n\t\t\treturn file_path\n\t\texcept Exception as e:\n\t\t\tprint(f\"Download failed. Error: {e}\")\n\t\t\treturn None\n\n\tdef _get_log(\n\t\tself,\n\t\tuser_id: str,\n\t\tsucceed_papers: List[Tuple[str, str]],\n\t\tfail_papers: List[str]\n\t) -&gt; OperationOutputLog:\n\t\tr\"\"\" Get the operation log. \"\"\"\n\t\tlogs = []\n\t\tif succeed_papers:\n\t\t\tlogs.append(f\"Successfully download these papers, and restore them in the recent papers of user {user_id}:\")\n\n\t\tref_paper_infos = []\n\n\t\tfor title, file_path in succeed_papers:\n\t\t\tdownload_log = {\n\t\t\t\t\"Title\": title,\n\t\t\t\t\"Save path\": file_path,\n\t\t\t}\n\t\t\tdownload_log_str = json.dumps(download_log)\n\t\t\tlogs.append(download_log_str)\n\t\t\tpaper_info = PaperInfo(\n\t\t\t\ttitle=title,\n\t\t\t\tfile_path=file_path,\n\t\t\t\tpossessor=user_id,\n\t\t\t)\n\t\t\tref_paper_infos.append(paper_info.dumps())\n\n\t\tif fail_papers:\n\t\t\tfailed_log = \"These paper downloading failed:\\n\"\n\t\t\tfailed_log += \"\\n\".join(fail_papers)\n\t\t\tlogs.append(failed_log)\n\t\tlog_str = \"\\n\\n\".join(logs)\n\t\treturn OperationOutputLog(\n\t\t\toperation_name=self.op_name,\n\t\t\toperation_output=None,\n\t\t\tlog_to_user=None,\n\t\t\tlog_to_system={\n\t\t\t\tOP_DESCRIPTION: log_str,\n\t\t\t\tOP_REFERENCES: ref_paper_infos,\n\t\t\t}\n\t\t)\n\n\tdef do_operation(self, **kwargs) -&gt; OperationOutputLog:\n\t\tr\"\"\"\n\t\tExecute the downloading operation and return the log string.\n\n\t\tArgs:\n\t\t\tuser_id (str): the user id.\n\t\t\tpaper_infos (List[Dict[str, str]]): the metadata of papers,\n\t\t\t\tfor each paper, the `title` and `pdf_url` must be provided\n\n\t\tReturns:\n\t\t\tOperationLog:\n\t\t\t\tThe operation output and log.\n\t\t\"\"\"\n\t\tuser_id = kwargs.get(\"user_id\", None)\n\t\tpaper_infos = kwargs.get(\"paper_infos\", [])\n\n\t\tif None in [user_id, paper_infos]:\n\t\t\traise ValueError(\"These arguments must be provided: user_id, paper_infos.\")\n\n\t\tif not isinstance(paper_infos, list):\n\t\t\tpaper_infos = [paper_infos]\n\n\t\ttmp_paper_store = RecentPaperStore.from_user_id(\n\t\t\tuser_id=user_id,\n\t\t\tembed_model=self._embed_model,\n\t\t)\n\n\t\tsucceed, fail = [], []\n\n\t\tfor info in paper_infos:\n\t\t\tpdf_url = info.get(\"pdf_url\", None)\n\t\t\ttitle = info.get(\"title\", None)\n\t\t\tfile_path = self.download_paper(\n\t\t\t\tuser_id=user_id,\n\t\t\t\ttitle=title,\n\t\t\t\tpdf_url=pdf_url,\n\t\t\t)\n\t\t\tif file_path is None:\n\t\t\t\tfail.append(title)\n\t\t\telse:\n\t\t\t\tsucceed.append((title, file_path))\n\t\t\t\ttmp_paper_store.put(paper_file_path=file_path)\n\n\t\ttmp_paper_store.persist()\n\t\toutput_log = self._get_log(user_id=user_id, succeed_papers=succeed, fail_papers=fail)\n\t\treturn output_log\n\n\tasync def ado_operation(self, **kwargs) -&gt; OperationOutputLog:\n\t\tr\"\"\"\n\t\tAsynchronously do the downloading operation and return the log string.\n\n\t\tArgs:\n\t\t\tuser_id (str): the user id.\n\t\t\tpaper_infos (List[Dict[str, str]]): the metadata of papers,\n\t\t\t\tfor each paper, the `title` and `pdf_url` must be provided\n\n\t\tReturns:\n\t\t\tstr:\n\t\t\t\tThe operation output and log.\n\t\t\"\"\"\n\t\tuser_id = kwargs.get(\"user_id\", None)\n\t\tpaper_infos = kwargs.get(\"paper_infos\", [])\n\n\t\tif None in [user_id, paper_infos]:\n\t\t\traise ValueError(\"These arguments must be provided: user_id, paper_infos.\")\n\n\t\tif not isinstance(paper_infos, list):\n\t\t\tpaper_infos = [paper_infos]\n\n\t\ttmp_paper_store = RecentPaperStore.from_user_id(\n\t\t\tuser_id=user_id,\n\t\t\tembed_model=self._embed_model,\n\t\t)\n\n\t\tsucceed, fail = [], []\n\n\t\tasync def single_op(info):\n\t\t\tpdf_url = info.get(\"pdf_url\", None)\n\t\t\ttitle = info.get(\"title\", None)\n\t\t\tfile_path = await self.adownload_paper(\n\t\t\t\tuser_id=user_id,\n\t\t\t\ttitle=title,\n\t\t\t\tpdf_url=pdf_url,\n\t\t\t)\n\t\t\tif file_path is None:\n\t\t\t\tfail.append(title)\n\t\t\telse:\n\t\t\t\tsucceed.append((title, file_path))\n\t\t\t\ttmp_paper_store.put(paper_file_path=file_path)\n\n\t\ttask_list = tuple([asyncio.create_task(single_op(paper_info)) for paper_info in paper_infos])\n\t\tawait asyncio.gather(*task_list)\n\t\ttmp_paper_store.persist()\n\t\toutput_log = self._get_log(user_id=user_id, succeed_papers=succeed, fail_papers=fail)\n\t\treturn output_log\n</code></pre>"},{"location":"code_docs/callback/paper/paper_download/#labridge.callback.paper.paper_download.ArxivDownloadOperation.ado_operation","title":"<code>labridge.callback.paper.paper_download.ArxivDownloadOperation.ado_operation(**kwargs)</code>  <code>async</code>","text":"<p>Asynchronously do the downloading operation and return the log string.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>the user id.</p> <p> TYPE: <code>str</code> </p> <code>paper_infos</code> <p>the metadata of papers, for each paper, the <code>title</code> and <code>pdf_url</code> must be provided</p> <p> TYPE: <code>List[Dict[str, str]]</code> </p> RETURNS DESCRIPTION <code>str</code> <p>The operation output and log.</p> <p> TYPE: <code>OperationOutputLog</code> </p> Source code in <code>labridge\\callback\\paper\\paper_download.py</code> <pre><code>async def ado_operation(self, **kwargs) -&gt; OperationOutputLog:\n\tr\"\"\"\n\tAsynchronously do the downloading operation and return the log string.\n\n\tArgs:\n\t\tuser_id (str): the user id.\n\t\tpaper_infos (List[Dict[str, str]]): the metadata of papers,\n\t\t\tfor each paper, the `title` and `pdf_url` must be provided\n\n\tReturns:\n\t\tstr:\n\t\t\tThe operation output and log.\n\t\"\"\"\n\tuser_id = kwargs.get(\"user_id\", None)\n\tpaper_infos = kwargs.get(\"paper_infos\", [])\n\n\tif None in [user_id, paper_infos]:\n\t\traise ValueError(\"These arguments must be provided: user_id, paper_infos.\")\n\n\tif not isinstance(paper_infos, list):\n\t\tpaper_infos = [paper_infos]\n\n\ttmp_paper_store = RecentPaperStore.from_user_id(\n\t\tuser_id=user_id,\n\t\tembed_model=self._embed_model,\n\t)\n\n\tsucceed, fail = [], []\n\n\tasync def single_op(info):\n\t\tpdf_url = info.get(\"pdf_url\", None)\n\t\ttitle = info.get(\"title\", None)\n\t\tfile_path = await self.adownload_paper(\n\t\t\tuser_id=user_id,\n\t\t\ttitle=title,\n\t\t\tpdf_url=pdf_url,\n\t\t)\n\t\tif file_path is None:\n\t\t\tfail.append(title)\n\t\telse:\n\t\t\tsucceed.append((title, file_path))\n\t\t\ttmp_paper_store.put(paper_file_path=file_path)\n\n\ttask_list = tuple([asyncio.create_task(single_op(paper_info)) for paper_info in paper_infos])\n\tawait asyncio.gather(*task_list)\n\ttmp_paper_store.persist()\n\toutput_log = self._get_log(user_id=user_id, succeed_papers=succeed, fail_papers=fail)\n\treturn output_log\n</code></pre>"},{"location":"code_docs/callback/paper/paper_download/#labridge.callback.paper.paper_download.ArxivDownloadOperation.adownload_paper","title":"<code>labridge.callback.paper.paper_download.ArxivDownloadOperation.adownload_paper(user_id, title, pdf_url)</code>  <code>async</code>","text":"<p>Asynchronously download a paper from arxiv and save to the user's recent paper directory.</p> Source code in <code>labridge\\callback\\paper\\paper_download.py</code> <pre><code>async def adownload_paper(self, user_id: str, title: str, pdf_url: str) -&gt; Optional[str]:\n\tr\"\"\"\n\tAsynchronously download a paper from arxiv and save to the user's recent paper directory.\n\t\"\"\"\n\tif None in [user_id, title, pdf_url]:\n\t\traise ValueError(\"should provide valid user_id, title, pdf_url to download paper.\")\n\n\tfile_dir, file_name = self._get_default_path(user_id=user_id, title=title)\n\tfile_path = str(Path(file_dir) / file_name)\n\n\tif self._verbose:\n\t\tprint_text(text=f\"Downloading paper '{title}' ...\", color=\"pink\", end=\"\\n\")\n\ttry:\n\t\tawait adownload_file(url=pdf_url, save_path=file_path)\n\t\treturn file_path\n\texcept Exception as e:\n\t\tprint(f\"Download failed. Error: {e}\")\n\t\treturn None\n</code></pre>"},{"location":"code_docs/callback/paper/paper_download/#labridge.callback.paper.paper_download.ArxivDownloadOperation.do_operation","title":"<code>labridge.callback.paper.paper_download.ArxivDownloadOperation.do_operation(**kwargs)</code>","text":"<p>Execute the downloading operation and return the log string.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>the user id.</p> <p> TYPE: <code>str</code> </p> <code>paper_infos</code> <p>the metadata of papers, for each paper, the <code>title</code> and <code>pdf_url</code> must be provided</p> <p> TYPE: <code>List[Dict[str, str]]</code> </p> RETURNS DESCRIPTION <code>OperationLog</code> <p>The operation output and log.</p> <p> TYPE: <code>OperationOutputLog</code> </p> Source code in <code>labridge\\callback\\paper\\paper_download.py</code> <pre><code>def do_operation(self, **kwargs) -&gt; OperationOutputLog:\n\tr\"\"\"\n\tExecute the downloading operation and return the log string.\n\n\tArgs:\n\t\tuser_id (str): the user id.\n\t\tpaper_infos (List[Dict[str, str]]): the metadata of papers,\n\t\t\tfor each paper, the `title` and `pdf_url` must be provided\n\n\tReturns:\n\t\tOperationLog:\n\t\t\tThe operation output and log.\n\t\"\"\"\n\tuser_id = kwargs.get(\"user_id\", None)\n\tpaper_infos = kwargs.get(\"paper_infos\", [])\n\n\tif None in [user_id, paper_infos]:\n\t\traise ValueError(\"These arguments must be provided: user_id, paper_infos.\")\n\n\tif not isinstance(paper_infos, list):\n\t\tpaper_infos = [paper_infos]\n\n\ttmp_paper_store = RecentPaperStore.from_user_id(\n\t\tuser_id=user_id,\n\t\tembed_model=self._embed_model,\n\t)\n\n\tsucceed, fail = [], []\n\n\tfor info in paper_infos:\n\t\tpdf_url = info.get(\"pdf_url\", None)\n\t\ttitle = info.get(\"title\", None)\n\t\tfile_path = self.download_paper(\n\t\t\tuser_id=user_id,\n\t\t\ttitle=title,\n\t\t\tpdf_url=pdf_url,\n\t\t)\n\t\tif file_path is None:\n\t\t\tfail.append(title)\n\t\telse:\n\t\t\tsucceed.append((title, file_path))\n\t\t\ttmp_paper_store.put(paper_file_path=file_path)\n\n\ttmp_paper_store.persist()\n\toutput_log = self._get_log(user_id=user_id, succeed_papers=succeed, fail_papers=fail)\n\treturn output_log\n</code></pre>"},{"location":"code_docs/callback/paper/paper_download/#labridge.callback.paper.paper_download.ArxivDownloadOperation.download_paper","title":"<code>labridge.callback.paper.paper_download.ArxivDownloadOperation.download_paper(user_id, title, pdf_url)</code>","text":"<p>Download a paper from arxiv and save to the user's recent paper directory.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user id of a lab member.</p> <p> TYPE: <code>str</code> </p> <code>title</code> <p>The paper title.</p> <p> TYPE: <code>str</code> </p> <code>pdf_url</code> <p>The paper URL.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Optional[str]</code> <p>Optional[str]:</p> <ul> <li>If the paper is successfully downloaded, return the file_path.</li> <li>If the downloading fails, return None.</li> </ul> Source code in <code>labridge\\callback\\paper\\paper_download.py</code> <pre><code>def download_paper(self, user_id: str, title: str, pdf_url: str) -&gt; Optional[str]:\n\tr\"\"\"\n\tDownload a paper from arxiv and save to the user's recent paper directory.\n\n\tArgs:\n\t\tuser_id (str): The user id of a lab member.\n\t\ttitle (str): The paper title.\n\t\tpdf_url (str): The paper URL.\n\n\tReturns:\n\t\tOptional[str]:\n\n\t\t\t- If the paper is successfully downloaded, return the file_path.\n\t\t\t- If the downloading fails, return None.\n\t\"\"\"\n\tif None in [user_id, title, pdf_url]:\n\t\traise ValueError(\"should provide valid user_id, title, pdf_url to download paper.\")\n\tfile_dir, file_name = self._get_default_path(user_id=user_id, title=title)\n\tresult = Result(entry_id=\"\")\n\tresult.pdf_url = pdf_url\n\n\tif self._verbose:\n\t\tprint_text(text=f\"Downloading paper '{title}' ...\", color=\"pink\", end=\"\\n\")\n\n\ttry:\n\t\tresult.download_pdf(dirpath=file_dir, filename=file_name)\n\t\tfile_path = str(Path(file_dir) / file_name)\n\t\treturn file_path\n\texcept Exception as e:\n\t\tprint(f\"Download failed. Error: {e}\")\n\t\treturn None\n</code></pre>"},{"location":"code_docs/callback/paper/paper_download/#labridge.callback.paper.paper_download.ArxivDownloadOperation.operation_description","title":"<code>labridge.callback.paper.paper_download.ArxivDownloadOperation.operation_description(**kwargs)</code>","text":"<p>Describe the operation.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>the user id.</p> <p> TYPE: <code>str</code> </p> <code>paper_infos</code> <p>the metadata of papers, for each paper, the <code>title</code> must be provided.</p> <p> TYPE: <code>List[Dict[str, str]]</code> </p> RETURNS DESCRIPTION <code>str</code> <p>the operation description.</p> Source code in <code>labridge\\callback\\paper\\paper_download.py</code> <pre><code>def operation_description(self, **kwargs) -&gt; str:\n\tr\"\"\"\n\tDescribe the operation.\n\n\tArgs:\n\t\tuser_id (str): the user id.\n\t\tpaper_infos (List[Dict[str, str]]): the metadata of papers,\n\t\t\tfor each paper, the `title` must be provided.\n\n\tReturns:\n\t\tthe operation description.\n\t\"\"\"\n\tuser_id = kwargs.get(\"user_id\", None)\n\tpaper_infos = kwargs.get(\"paper_infos\", None)\n\n\tif None in [user_id, paper_infos]:\n\t\traise ValueError(\"should provide valid user_id, paper_infos.\")\n\n\tpapers = []\n\tfor paper in paper_infos:\n\t\ttitle = paper.get(\"title\", None)\n\t\tfile_dir, file_name = self._get_default_path(user_id=user_id, title=title)\n\t\tsave_path = str(Path(file_dir) / file_name)\n\t\tpaper_dsc = PAPER_DESCRIPTION_TMPL.format(title=title, save_path=save_path)\n\t\tpapers.append(paper_dsc)\n\tpapers = \"\\n\\n\".join(papers)\n\theader = ARXIV_DOWNLOAD_DESCRIPTION.format(user_id=user_id)\n\tdescription = f\"{header}\\n{papers}\"\n\treturn description\n</code></pre>"},{"location":"code_docs/callback/paper/paper_summarize/","title":"Paper summarize","text":""},{"location":"code_docs/callback/paper/paper_summarize/#labridge.callback.paper.paper_summarize","title":"<code>labridge.callback.paper.paper_summarize</code>","text":""},{"location":"code_docs/callback/paper/paper_summarize/#labridge.callback.paper.paper_summarize.PaperSummarizeOperation","title":"<code>labridge.callback.paper.paper_summarize.PaperSummarizeOperation</code>","text":"<p>               Bases: <code>CallBackOperationBase</code></p> <p>This operation will summarize a paper.</p> PARAMETER DESCRIPTION <code>llm</code> <p>The used LLM.</p> <p> TYPE: <code>LLM</code> DEFAULT: <code>None</code> </p> <code>embed_model</code> <p>The used embedding model.</p> <p> TYPE: <code>BaseEmbedding</code> DEFAULT: <code>None</code> </p> <code>verbose</code> <p>Whether to show the inner progress.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> Source code in <code>labridge\\callback\\paper\\paper_summarize.py</code> <pre><code>class PaperSummarizeOperation(CallBackOperationBase):\n\tr\"\"\"\n\tThis operation will summarize a paper.\n\n\tArgs:\n\t\tllm (LLM): The used LLM.\n\t\tembed_model (BaseEmbedding): The used embedding model.\n\t\tverbose (bool): Whether to show the inner progress.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tllm: LLM = None,\n\t\tembed_model: BaseEmbedding = None,\n\t\tverbose: bool = False,\n\t\top_name: str = None,\n\t):\n\t\troot = Path(__file__)\n\n\t\tfor idx in range(4):\n\t\t\troot = root.parent\n\n\t\tself.root = root\n\t\tself._fs = fsspec.filesystem(\"file\")\n\t\tembed_model = embed_model or Settings.embed_model\n\t\tllm = llm or Settings.llm\n\t\tself._summarizer = PaperBatchSummarize(llm=llm)\n\t\tsuper().__init__(\n\t\t\tllm=llm,\n\t\t\tembed_model=embed_model,\n\t\t\tverbose=verbose,\n\t\t\top_name=op_name or PaperSummarizeOperation.__name__,\n\t\t)\n\n\tdef operation_description(self, **kwargs) -&gt; str:\n\t\tr\"\"\"\n\t\tDescribe the operation.\n\n\t\tArgs:\n\t\t\tuser_id (str): the user id.\n\t\t\tpaper_file_path (str): The file path of the paper.\n\n\t\tReturns:\n\t\t\tstr: the operation description.\n\t\t\"\"\"\n\t\tuser_id = kwargs.get(\"user_id\", None)\n\t\tpaper_file_path = kwargs.get(\"paper_file_path\", None)\n\n\t\tif None in [user_id, paper_file_path]:\n\t\t\traise ValueError(\"should provide valid user_id, paper_infos.\")\n\n\t\tdescription = SUMMARIZE_DESCRIPTION_TMPL.format(user_id=user_id, paper_file_path=paper_file_path)\n\t\treturn description\n\n\tdef do_operation(\n\t\tself,\n\t\tuser_id: str,\n\t\tpaper_file_path: str,\n\t) -&gt; OperationOutputLog:\n\t\tr\"\"\"\n\t\tExecute the operation to summarize a paper in a user's recent papers.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user id of a lab member.\n\t\t\tpaper_file_path (str): The file path of the paper.\n\n\t\tReturns:\n\t\t\tOperationOutputLog:\n\t\t\t\tThe operation output and log.\n\t\t\"\"\"\n\t\trecent_paper_store = RecentPaperStore.from_user_id(\n\t\t\tuser_id=user_id,\n\t\t\tembed_model=self._embed_model,\n\t\t)\n\t\trecent_paper_store.check_valid_paper(paper_file_path=paper_file_path)\n\t\tsummary_node = recent_paper_store.get_summary_node(paper_file_path=paper_file_path)\n\t\tif summary_node is not None:\n\t\t\treturn summary_node.text\n\n\t\t# TODO: Send to the user\n\t\tprint(\"Assistant: \u200b\u6b63\u5728\u200b\u4e3a\u200b\u60a8\u200b\u603b\u7ed3\u200b\u4e2d\u200b\uff0c\u200b\u8bf7\u200b\u7a0d\u5019\u200b\u3002\")\n\t\tpaper_nodes = recent_paper_store.get_paper_nodes(paper_file_path=paper_file_path)\n\t\tnodes_with_scores = [NodeWithScore(node=n) for n in paper_nodes]\n\t\t# get the summary for each doc_id\n\t\tsummary_response = self._summarizer.synthesize(\n\t\t\tnodes=nodes_with_scores,\n\t\t\tquery=\"\"\n\t\t)\n\t\tsummary_response = cast(Response, summary_response)\n\t\tsummary_node = TextNode(text=summary_response.response)\n\t\trecent_paper_store.insert_summary_node(\n\t\t\tpaper_file_path=paper_file_path,\n\t\t\tsummary_node=summary_node,\n\t\t)\n\t\trecent_paper_store.persist()\n\t\tpaper_info = PaperInfo(\n\t\t\ttitle=paper_file_path,\n\t\t\tpossessor=user_id,\n\t\t\tfile_path=paper_file_path,\n\t\t)\n\t\top_log = f\"Have summarized the paper {paper_file_path} for the user {user_id}.\"\n\t\treturn OperationOutputLog(\n\t\t\toperation_name=self.op_name,\n\t\t\toperation_output=summary_node.text,\n\t\t\tlog_to_user=None,\n\t\t\tlog_to_system={\n\t\t\t\tOP_DESCRIPTION: op_log,\n\t\t\t\tOP_REFERENCES: [paper_info.dumps()]\n\t\t\t},\n\t\t)\n\n\tasync def ado_operation(\n\t\tself,\n\t\tuser_id: str,\n\t\tpaper_file_path: str,\n\t) -&gt; OperationOutputLog:\n\t\tr\"\"\"\n\t\tAsynchronously execute the operation to summarize a paper in a user's recent papers.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user id of a lab member.\n\t\t\tpaper_file_path (str): The file path of the paper.\n\n\t\tReturns:\n\t\t\tOperationOutputLog:\n\t\t\t\tThe output and log.\n\t\t\"\"\"\n\t\trecent_paper_store = RecentPaperStore.from_user_id(\n\t\t\tuser_id=user_id,\n\t\t\tembed_model=self._embed_model,\n\t\t)\n\t\trecent_paper_store.check_valid_paper(paper_file_path=paper_file_path)\n\t\tsummary_node = recent_paper_store.get_summary_node(paper_file_path=paper_file_path)\n\t\tif summary_node is not None:\n\t\t\treturn summary_node.text\n\n\t\t# TODO: Send to the user\n\t\tprint(\"Assistant: \u200b\u6b63\u5728\u200b\u4e3a\u200b\u60a8\u200b\u603b\u7ed3\u200b\u4e2d\u200b\uff0c\u200b\u8bf7\u200b\u7a0d\u5019\u200b\u3002\")\n\t\tpaper_nodes = recent_paper_store.get_paper_nodes(paper_file_path=paper_file_path)\n\t\tnodes_with_scores = [NodeWithScore(node=n) for n in paper_nodes]\n\t\t# get the summary for each doc_id\n\t\tsummary_response = await self._summarizer.asynthesize(\n\t\t\tnodes=nodes_with_scores,\n\t\t\tquery=\"\"\n\t\t)\n\t\tsummary_response = cast(Response, summary_response)\n\t\tsummary_node = TextNode(text=summary_response.response)\n\t\trecent_paper_store.insert_summary_node(\n\t\t\tpaper_file_path=paper_file_path,\n\t\t\tsummary_node=summary_node,\n\t\t)\n\t\trecent_paper_store.persist()\n\t\tpaper_info = PaperInfo(\n\t\t\ttitle=paper_file_path,\n\t\t\tpossessor=user_id,\n\t\t\tfile_path=paper_file_path,\n\t\t)\n\t\top_log = f\"Have summarized the paper {paper_file_path} for the user {user_id}.\"\n\t\treturn OperationOutputLog(\n\t\t\toperation_name=self.op_name,\n\t\t\toperation_output=summary_node.text,\n\t\t\tlog_to_user=None,\n\t\t\tlog_to_system={\n\t\t\t\tOP_DESCRIPTION: op_log,\n\t\t\t\tOP_REFERENCES: [paper_info.dumps()]\n\t\t\t},\n\t\t)\n</code></pre>"},{"location":"code_docs/callback/paper/paper_summarize/#labridge.callback.paper.paper_summarize.PaperSummarizeOperation.ado_operation","title":"<code>labridge.callback.paper.paper_summarize.PaperSummarizeOperation.ado_operation(user_id, paper_file_path)</code>  <code>async</code>","text":"<p>Asynchronously execute the operation to summarize a paper in a user's recent papers.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user id of a lab member.</p> <p> TYPE: <code>str</code> </p> <code>paper_file_path</code> <p>The file path of the paper.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>OperationOutputLog</code> <p>The output and log.</p> <p> TYPE: <code>OperationOutputLog</code> </p> Source code in <code>labridge\\callback\\paper\\paper_summarize.py</code> <pre><code>async def ado_operation(\n\tself,\n\tuser_id: str,\n\tpaper_file_path: str,\n) -&gt; OperationOutputLog:\n\tr\"\"\"\n\tAsynchronously execute the operation to summarize a paper in a user's recent papers.\n\n\tArgs:\n\t\tuser_id (str): The user id of a lab member.\n\t\tpaper_file_path (str): The file path of the paper.\n\n\tReturns:\n\t\tOperationOutputLog:\n\t\t\tThe output and log.\n\t\"\"\"\n\trecent_paper_store = RecentPaperStore.from_user_id(\n\t\tuser_id=user_id,\n\t\tembed_model=self._embed_model,\n\t)\n\trecent_paper_store.check_valid_paper(paper_file_path=paper_file_path)\n\tsummary_node = recent_paper_store.get_summary_node(paper_file_path=paper_file_path)\n\tif summary_node is not None:\n\t\treturn summary_node.text\n\n\t# TODO: Send to the user\n\tprint(\"Assistant: \u200b\u6b63\u5728\u200b\u4e3a\u200b\u60a8\u200b\u603b\u7ed3\u200b\u4e2d\u200b\uff0c\u200b\u8bf7\u200b\u7a0d\u5019\u200b\u3002\")\n\tpaper_nodes = recent_paper_store.get_paper_nodes(paper_file_path=paper_file_path)\n\tnodes_with_scores = [NodeWithScore(node=n) for n in paper_nodes]\n\t# get the summary for each doc_id\n\tsummary_response = await self._summarizer.asynthesize(\n\t\tnodes=nodes_with_scores,\n\t\tquery=\"\"\n\t)\n\tsummary_response = cast(Response, summary_response)\n\tsummary_node = TextNode(text=summary_response.response)\n\trecent_paper_store.insert_summary_node(\n\t\tpaper_file_path=paper_file_path,\n\t\tsummary_node=summary_node,\n\t)\n\trecent_paper_store.persist()\n\tpaper_info = PaperInfo(\n\t\ttitle=paper_file_path,\n\t\tpossessor=user_id,\n\t\tfile_path=paper_file_path,\n\t)\n\top_log = f\"Have summarized the paper {paper_file_path} for the user {user_id}.\"\n\treturn OperationOutputLog(\n\t\toperation_name=self.op_name,\n\t\toperation_output=summary_node.text,\n\t\tlog_to_user=None,\n\t\tlog_to_system={\n\t\t\tOP_DESCRIPTION: op_log,\n\t\t\tOP_REFERENCES: [paper_info.dumps()]\n\t\t},\n\t)\n</code></pre>"},{"location":"code_docs/callback/paper/paper_summarize/#labridge.callback.paper.paper_summarize.PaperSummarizeOperation.do_operation","title":"<code>labridge.callback.paper.paper_summarize.PaperSummarizeOperation.do_operation(user_id, paper_file_path)</code>","text":"<p>Execute the operation to summarize a paper in a user's recent papers.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user id of a lab member.</p> <p> TYPE: <code>str</code> </p> <code>paper_file_path</code> <p>The file path of the paper.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>OperationOutputLog</code> <p>The operation output and log.</p> <p> TYPE: <code>OperationOutputLog</code> </p> Source code in <code>labridge\\callback\\paper\\paper_summarize.py</code> <pre><code>def do_operation(\n\tself,\n\tuser_id: str,\n\tpaper_file_path: str,\n) -&gt; OperationOutputLog:\n\tr\"\"\"\n\tExecute the operation to summarize a paper in a user's recent papers.\n\n\tArgs:\n\t\tuser_id (str): The user id of a lab member.\n\t\tpaper_file_path (str): The file path of the paper.\n\n\tReturns:\n\t\tOperationOutputLog:\n\t\t\tThe operation output and log.\n\t\"\"\"\n\trecent_paper_store = RecentPaperStore.from_user_id(\n\t\tuser_id=user_id,\n\t\tembed_model=self._embed_model,\n\t)\n\trecent_paper_store.check_valid_paper(paper_file_path=paper_file_path)\n\tsummary_node = recent_paper_store.get_summary_node(paper_file_path=paper_file_path)\n\tif summary_node is not None:\n\t\treturn summary_node.text\n\n\t# TODO: Send to the user\n\tprint(\"Assistant: \u200b\u6b63\u5728\u200b\u4e3a\u200b\u60a8\u200b\u603b\u7ed3\u200b\u4e2d\u200b\uff0c\u200b\u8bf7\u200b\u7a0d\u5019\u200b\u3002\")\n\tpaper_nodes = recent_paper_store.get_paper_nodes(paper_file_path=paper_file_path)\n\tnodes_with_scores = [NodeWithScore(node=n) for n in paper_nodes]\n\t# get the summary for each doc_id\n\tsummary_response = self._summarizer.synthesize(\n\t\tnodes=nodes_with_scores,\n\t\tquery=\"\"\n\t)\n\tsummary_response = cast(Response, summary_response)\n\tsummary_node = TextNode(text=summary_response.response)\n\trecent_paper_store.insert_summary_node(\n\t\tpaper_file_path=paper_file_path,\n\t\tsummary_node=summary_node,\n\t)\n\trecent_paper_store.persist()\n\tpaper_info = PaperInfo(\n\t\ttitle=paper_file_path,\n\t\tpossessor=user_id,\n\t\tfile_path=paper_file_path,\n\t)\n\top_log = f\"Have summarized the paper {paper_file_path} for the user {user_id}.\"\n\treturn OperationOutputLog(\n\t\toperation_name=self.op_name,\n\t\toperation_output=summary_node.text,\n\t\tlog_to_user=None,\n\t\tlog_to_system={\n\t\t\tOP_DESCRIPTION: op_log,\n\t\t\tOP_REFERENCES: [paper_info.dumps()]\n\t\t},\n\t)\n</code></pre>"},{"location":"code_docs/callback/paper/paper_summarize/#labridge.callback.paper.paper_summarize.PaperSummarizeOperation.operation_description","title":"<code>labridge.callback.paper.paper_summarize.PaperSummarizeOperation.operation_description(**kwargs)</code>","text":"<p>Describe the operation.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>the user id.</p> <p> TYPE: <code>str</code> </p> <code>paper_file_path</code> <p>The file path of the paper.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>str</code> <p>the operation description.</p> <p> TYPE: <code>str</code> </p> Source code in <code>labridge\\callback\\paper\\paper_summarize.py</code> <pre><code>def operation_description(self, **kwargs) -&gt; str:\n\tr\"\"\"\n\tDescribe the operation.\n\n\tArgs:\n\t\tuser_id (str): the user id.\n\t\tpaper_file_path (str): The file path of the paper.\n\n\tReturns:\n\t\tstr: the operation description.\n\t\"\"\"\n\tuser_id = kwargs.get(\"user_id\", None)\n\tpaper_file_path = kwargs.get(\"paper_file_path\", None)\n\n\tif None in [user_id, paper_file_path]:\n\t\traise ValueError(\"should provide valid user_id, paper_infos.\")\n\n\tdescription = SUMMARIZE_DESCRIPTION_TMPL.format(user_id=user_id, paper_file_path=paper_file_path)\n\treturn description\n</code></pre>"},{"location":"code_docs/common/prompt/llm_doc_choice_select/","title":"Llm doc choice select","text":""},{"location":"code_docs/common/prompt/llm_doc_choice_select/#labridge.common.prompt.llm_doc_choice_select","title":"<code>labridge.common.prompt.llm_doc_choice_select</code>","text":""},{"location":"code_docs/common/query_engine/query_engines/","title":"Query engines","text":""},{"location":"code_docs/common/query_engine/query_engines/#labridge.common.query_engine.query_engines","title":"<code>labridge.common.query_engine.query_engines</code>","text":""},{"location":"code_docs/common/query_engine/query_engines/#labridge.common.query_engine.query_engines.SingleQueryEngine","title":"<code>labridge.common.query_engine.query_engines.SingleQueryEngine</code>","text":"<p>               Bases: <code>BaseQueryEngine</code></p> <p>A single query engine.</p> PARAMETER DESCRIPTION <code>llm</code> <p>The used LLM.</p> <p> TYPE: <code>LLM</code> </p> <code>prompt_tmpl</code> <p>The prompt template.</p> <p> TYPE: <code>str</code> </p> Source code in <code>labridge\\common\\query_engine\\query_engines.py</code> <pre><code>class SingleQueryEngine(BaseQueryEngine):\n\tr\"\"\"\n\tA single query engine.\n\n\tArgs:\n\t\tllm (LLM): The used LLM.\n\t\tprompt_tmpl (str): The prompt template.\n\t\"\"\"\n\tdef __init__(self, llm: LLM, prompt_tmpl: str):\n\t\tif llm is not None:\n\t\t\tself.llm = llm\n\t\telse:\n\t\t\tself.llm = Settings.llm\n\t\tself.prompt_tmpl = prompt_tmpl\n\t\tsuper().__init__(callback_manager=None)\n\n\tdef _query(self, query_bundle: QueryBundle) -&gt; RESPONSE_TYPE:\n\t\treturn self.single_query(query_bundle.query_str)\n\n\tasync def _aquery(self, query_bundle: QueryBundle) -&gt; RESPONSE_TYPE:\n\t\treturn self.single_query(query_bundle.query_str)\n\n\tdef _get_prompt_modules(self) -&gt; Dict[str, Any]:\n\t\t\"\"\"Get prompts.\"\"\"\n\t\treturn {}\n\n\tdef single_query(self, query_str: str) -&gt; Union[RESPONSE_TYPE, str]:\n\t\tquery = self.prompt_tmpl.format(query_str)\n\t\tmotivation_str = self.llm.complete(prompt=query)\n\t\tmotivation = Response(motivation_str.text)\n\t\treturn motivation\n</code></pre>"},{"location":"code_docs/common/utils/chat/","title":"Chat","text":""},{"location":"code_docs/common/utils/chat/#labridge.common.utils.chat","title":"<code>labridge.common.utils.chat</code>","text":""},{"location":"code_docs/common/utils/chat/#labridge.common.utils.chat.pack_user_message","title":"<code>labridge.common.utils.chat.pack_user_message(user_id, user_msg, system_msg, reply_in_speech)</code>","text":"Source code in <code>labridge\\common\\utils\\chat.py</code> <pre><code>def pack_user_message(user_id: str, user_msg: str, system_msg: str, reply_in_speech: bool):\n\tr\"\"\" TODO: change to system format \"\"\"\n\tmessage_dict = {\n\t\t\"user_id\": user_id,\n\t\t\"user_message\": user_msg,\n\t\t\"system_message\": system_msg,\n\t}\n\tmessage_str = json.dumps(message_dict)\n\treturn message_str\n</code></pre>"},{"location":"code_docs/common/utils/time/","title":"Time","text":""},{"location":"code_docs/common/utils/time/#labridge.common.utils.time","title":"<code>labridge.common.utils.time</code>","text":""},{"location":"code_docs/common/utils/time/#labridge.common.utils.time.datetime_to_str","title":"<code>labridge.common.utils.time.datetime_to_str(date_time)</code>","text":"<p>Transform datetime into formatted strings.</p> PARAMETER DESCRIPTION <code>date_time</code> <p>The datetime.</p> <p> TYPE: <code>datetime</code> </p> RETURNS DESCRIPTION <code>Tuple[str, str]</code> <p>Tuple[str, str]: The formatted date string and time string.</p> Source code in <code>labridge\\common\\utils\\time.py</code> <pre><code>def datetime_to_str(date_time: datetime.datetime) -&gt; Tuple[str, str]:\n\tr\"\"\"\n\tTransform datetime into formatted strings.\n\n\tArgs:\n\t\tdate_time (datetime.datetime): The datetime.\n\n\tReturns:\n\t\tTuple[str, str]: The formatted date string and time string.\n\t\"\"\"\n\tdate_str = date_time.date().strftime(f\"{DATE_FORMAT}\")\n\ttime_str = date_time.time().strftime(f\"{TIME_FORMAT}\")\n\treturn date_str, time_str\n</code></pre>"},{"location":"code_docs/common/utils/time/#labridge.common.utils.time.get_time","title":"<code>labridge.common.utils.time.get_time()</code>","text":"<p>Get current date time in <code>DATE_FORMAT</code> and <code>TIME_FORMAT</code></p> RETURNS DESCRIPTION <code>Tuple[str, str]</code> <p>Tuple[str, str]: The formatted date string and time string.</p> Source code in <code>labridge\\common\\utils\\time.py</code> <pre><code>def get_time() -&gt; Tuple[str, str]:\n\tr\"\"\"\n\tGet current date time in `DATE_FORMAT` and `TIME_FORMAT`\n\n\tReturns:\n\t\tTuple[str, str]: The formatted date string and time string.\n\t\"\"\"\n\tnow = time.strftime(f\"{DATE_FORMAT} {TIME_FORMAT}\")\n\tdate, h_m_s = now.split()\n\treturn date, h_m_s\n</code></pre>"},{"location":"code_docs/common/utils/time/#labridge.common.utils.time.parse_date_list","title":"<code>labridge.common.utils.time.parse_date_list(start_date_str, end_date_str)</code>","text":"<p>Return the formatted strings of all dates from start_date to end_date.</p> PARAMETER DESCRIPTION <code>start_date_str</code> <p>The formatted string of the start date.</p> <p> TYPE: <code>str</code> </p> <code>end_date_str</code> <p>The formatted string of the end date.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>List[str]</code> <p>List[str]: The formatted date string.</p> RAISES DESCRIPTION <code>-ValueError</code> <p>If the end_date is earlier than the start_date.</p> Source code in <code>labridge\\common\\utils\\time.py</code> <pre><code>def parse_date_list(start_date_str: str, end_date_str: str) -&gt; List[str]:\n\tr\"\"\"\n\tReturn the formatted strings of all dates from start_date to end_date.\n\n\tArgs:\n\t\tstart_date_str (str): The formatted string of the start date.\n\t\tend_date_str (str): The formatted string of the end date.\n\n\tReturns:\n\t\tList[str]: The formatted date string.\n\n\tRaises:\n\t\t- ValueError: If the end_date is earlier than the start_date.\n\t\t- Any other errors raises in internal process.\n\t\"\"\"\n\tstart_date = str_to_date(start_date_str)\n\tend_date = str_to_date(end_date_str)\n\tif end_date &lt; start_date:\n\t\traise ValueError(\"The end_date can not be earlier than the start_date!\")\n\n\tdate_list = []\n\tcurrent_date = start_date\n\twhile current_date &lt;= end_date:\n\t\tdate_list.append(current_date.strftime(DATE_FORMAT))\n\t\tcurrent_date = current_date + datetime.timedelta(days=1)\n\treturn date_list\n</code></pre>"},{"location":"code_docs/common/utils/time/#labridge.common.utils.time.parse_delta_time","title":"<code>labridge.common.utils.time.parse_delta_time(time_unit)</code>","text":"<p>Get the delta time from a unit of a formatted time_delta string.</p> PARAMETER DESCRIPTION <code>time_unit</code> <p>A unit of a formatted time_delta string.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>dict</code> <ul> <li>If the time_unit is valid, return the parsed delta time. For example: \"2h\" -&gt; {\"hours\": 2}</li> <li>If the time_unit is invalid, return an empty dict.</li> </ul> <p> TYPE: <code>Dict[str, int]</code> </p> Source code in <code>labridge\\common\\utils\\time.py</code> <pre><code>def parse_delta_time(time_unit: str) -&gt; Dict[str, int]:\n\tr\"\"\"\n\tGet the delta time from a unit of a formatted time_delta string.\n\n\tArgs:\n\t\ttime_unit (str): A unit of a formatted time_delta string.\n\n\tReturns:\n\t\tdict:\n\t\t\t- If the time_unit is valid, return the parsed delta time. For example: \"2h\" -&gt; {\"hours\": 2}\n\t\t\t- If the time_unit is invalid, return an empty dict.\n\t\"\"\"\n\tnumbers = [char for char in time_unit if char.isnumeric()]\n\tflag = [char for char in time_unit if char.isalpha()]\n\n\tnum = int(\"\".join(numbers))\n\tflag_str = \"\".join(flag).lower()\n\n\tif flag_str in DELTA_TIME_FLAG_MAPPING.keys():\n\t\tkey = DELTA_TIME_FLAG_MAPPING.get(flag_str)\n\t\treturn {key: num}\n\treturn {}\n</code></pre>"},{"location":"code_docs/common/utils/time/#labridge.common.utils.time.str_to_date","title":"<code>labridge.common.utils.time.str_to_date(date_str)</code>","text":"<p>Transform a formatted date string to <code>datetime.date</code>.</p> PARAMETER DESCRIPTION <code>date_str</code> <p>The date string in format <code>DATE_FORMAT</code>.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>date</code> <p>datetime.date: The date.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If the date_str does not match the DATE_FORMAT`.</p> Source code in <code>labridge\\common\\utils\\time.py</code> <pre><code>def str_to_date(date_str: str) -&gt; datetime.date:\n\tr\"\"\"\n\tTransform a formatted date string to `datetime.date`.\n\n\tArgs:\n\t\tdate_str (str): The date string in format `DATE_FORMAT`.\n\n\tReturns:\n\t\tdatetime.date: The date.\n\n\tRaises:\n\t\tValueError: If the date_str does not match the DATE_FORMAT`.\n\t\"\"\"\n\tyear_month_day = date_str.split(\"-\")\n\n\ttry:\n\t\tmy_date = datetime.date(\n\t\t\tyear=int(year_month_day[0]),\n\t\t\tmonth=int(year_month_day[1]),\n\t\t\tday=int(year_month_day[2]),\n\t\t)\n\t\treturn my_date\n\texcept Exception:\n\t\traise ValueError(f\"The input date string {date_str} is invalid.\")\n</code></pre>"},{"location":"code_docs/common/utils/time/#labridge.common.utils.time.str_to_datetime","title":"<code>labridge.common.utils.time.str_to_datetime(date_str, time_str)</code>","text":"<p>Transform formatted time strings to <code>datetime.datetime</code>.</p> PARAMETER DESCRIPTION <code>date_str</code> <p>The date string in format <code>DATE_FORMAT</code>.</p> <p> TYPE: <code>str</code> </p> <code>time_str</code> <p>The time string in format <code>TIME_FORMAT</code>.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>datetime</code> <p>datetime.datetime: The datetime</p> Source code in <code>labridge\\common\\utils\\time.py</code> <pre><code>def str_to_datetime(date_str: str, time_str: str) -&gt; datetime.datetime:\n\tr\"\"\"\n\tTransform formatted time strings to `datetime.datetime`.\n\n\tArgs:\n\t\tdate_str (str): The date string in format `DATE_FORMAT`.\n\t\ttime_str (str): The time string in format `TIME_FORMAT`.\n\n\tReturns:\n\t\tdatetime.datetime: The datetime\n\n\tRaises:\n\t\tAny Error raises in `str_to_date` or `str_to_time`.\n\t\"\"\"\n\tmy_date = str_to_date(date_str)\n\tmy_time = str_to_time(time_str)\n\tmy_datetime = datetime.datetime(\n\t\tyear=my_date.year,\n\t\tmonth=my_date.month,\n\t\tday=my_date.day,\n\t\thour=my_time.hour,\n\t\tminute=my_time.minute,\n\t\tsecond=my_time.second,\n\t)\n\treturn my_datetime\n</code></pre>"},{"location":"code_docs/common/utils/time/#labridge.common.utils.time.str_to_delta_time","title":"<code>labridge.common.utils.time.str_to_delta_time(time_str)</code>","text":"<p>Transform a formatted time_delta string to <code>datetime.timedelta</code>.</p> PARAMETER DESCRIPTION <code>time_str</code> <p>The time_delta str in format <code>DELTA_TIME_FORMAT</code>.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>timedelta</code> <p>datetime.timedelta: The time delta.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If the time_str does not match the <code>DELTA_TIME_FORMAT</code>.</p> Source code in <code>labridge\\common\\utils\\time.py</code> <pre><code>def str_to_delta_time(time_str: str) -&gt; datetime.timedelta:\n\tr\"\"\"\n\tTransform a formatted time_delta string to `datetime.timedelta`.\n\n\tArgs:\n\t\ttime_str (str): The time_delta str in format `DELTA_TIME_FORMAT`.\n\n\tReturns:\n\t\tdatetime.timedelta: The time delta.\n\n\tRaises:\n\t\tValueError: If the time_str does not match the `DELTA_TIME_FORMAT`.\n\t\"\"\"\n\thour_minute_second = time_str.split(\":\")\n\n\tdefault = {\n\t\t\"hours\": 0,\n\t\t\"minutes\": 0,\n\t\t\"seconds\": 0,\n\t}\n\n\tfor unit in hour_minute_second:\n\t\tparsed_dict = parse_delta_time(time_unit=unit)\n\t\tdefault.update(parsed_dict)\n\n\ttry:\n\t\tdelta_time = datetime.timedelta(**default)\n\t\treturn delta_time\n\texcept Exception:\n\t\traise ValueError(f\"The input time string {time_str} is invalid.\")\n</code></pre>"},{"location":"code_docs/common/utils/time/#labridge.common.utils.time.str_to_time","title":"<code>labridge.common.utils.time.str_to_time(time_str)</code>","text":"<p>Transform a formatted time string to <code>datetime.time</code>.</p> PARAMETER DESCRIPTION <code>time_str</code> <p>The time string in format <code>TIME_FORMAT</code>.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>time</code> <p>datetime.time: The time.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If the time_str does not match the TIME_FORMAT`.</p> Source code in <code>labridge\\common\\utils\\time.py</code> <pre><code>def str_to_time(time_str: str) -&gt; datetime.time:\n\tr\"\"\"\n\tTransform a formatted time string to `datetime.time`.\n\n\tArgs:\n\t\ttime_str (str): The time string in format `TIME_FORMAT`.\n\n\tReturns:\n\t\tdatetime.time: The time.\n\n\tRaises:\n\t\tValueError: If the time_str does not match the TIME_FORMAT`.\n\t\"\"\"\n\thour_minute_second = time_str.split(\":\")\n\n\ttry:\n\t\tmy_time = datetime.time(\n\t\t\thour=int(hour_minute_second[0]),\n\t\t\tminute=int(hour_minute_second[1]),\n\t\t\tsecond=int(hour_minute_second[2]),\n\t\t)\n\t\treturn my_time\n\texcept Exception:\n\t\traise ValueError(f\"The input time string {time_str} is invalid.\")\n</code></pre>"},{"location":"code_docs/func_modules/instrument/prompt/llm_instrument_choice_select/","title":"Llm instrument choice select","text":""},{"location":"code_docs/func_modules/instrument/prompt/llm_instrument_choice_select/#labridge.func_modules.instrument.prompt.llm_instrument_choice_select","title":"<code>labridge.func_modules.instrument.prompt.llm_instrument_choice_select</code>","text":""},{"location":"code_docs/func_modules/instrument/retrieve/instrument_retriever/","title":"Instrument retriever","text":""},{"location":"code_docs/func_modules/instrument/retrieve/instrument_retriever/#labridge.func_modules.instrument.retrieve.instrument_retriever","title":"<code>labridge.func_modules.instrument.retrieve.instrument_retriever</code>","text":""},{"location":"code_docs/func_modules/instrument/retrieve/instrument_retriever/#labridge.func_modules.instrument.retrieve.instrument_retriever.InstrumentRetriever","title":"<code>labridge.func_modules.instrument.retrieve.instrument_retriever.InstrumentRetriever</code>","text":"<p>This is a retriever retrieving in the instrument docs. Hybrid retrieving is used.</p> PARAMETER DESCRIPTION <code>llm</code> <p>The used large language model.</p> <p> TYPE: <code>LLM</code> DEFAULT: <code>None</code> </p> <code>embed_model</code> <p>The used embedding model.</p> <p> TYPE: <code>BaseEmbedding</code> DEFAULT: <code>None</code> </p> <code>similarity_top_k</code> <p>When retrieving in the vector store, the top-k relevant nodes will be selected.</p> <p> TYPE: <code>int</code> DEFAULT: <code>3</code> </p> <code>instrument_top_k</code> <p>When choosing among the instruments based on their descriptions, the top-k instruments will be used.</p> <p> TYPE: <code>int</code> DEFAULT: <code>2</code> </p> <code>final_top_k</code> <p>Finally, retrieving is conducted among the nodes belong to the corresponding instruments that are chose in the former content-based retrieving and instrument selection. The top-k nodes will be used as the finally retrieved nodes.</p> <p> TYPE: <code>int</code> DEFAULT: <code>3</code> </p> Source code in <code>labridge\\func_modules\\instrument\\retrieve\\instrument_retriever.py</code> <pre><code>class InstrumentRetriever:\n\tr\"\"\"\n\tThis is a retriever retrieving in the instrument docs.\n\tHybrid retrieving is used.\n\n\tArgs:\n\t\tllm (LLM): The used large language model.\n\t\tembed_model (BaseEmbedding): The used embedding model.\n\t\tsimilarity_top_k (int): When retrieving in the vector store, the top-k relevant nodes will be selected.\n\t\tinstrument_top_k (int): When choosing among the instruments based on their descriptions, the top-k instruments\n\t\t\twill be used.\n\t\tfinal_top_k (int): Finally, retrieving is conducted among the nodes belong to the corresponding instruments\n\t\t\tthat are chose in the former content-based retrieving and instrument selection. The top-k nodes will be\n\t\t\tused as the finally retrieved nodes.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tllm: LLM = None,\n\t\tembed_model: BaseEmbedding = None,\n\t\tsimilarity_top_k: int = 3,\n\t\tinstrument_top_k: int = 2,\n\t\tfinal_top_k: int = 3,\n\t\tchoice_batch_size: int = 8,\n\t):\n\t\tself.llm = llm or Settings.llm\n\t\tembed_model = embed_model or Settings.embed_model\n\t\tself.instrument_store = InstrumentStorage.from_default(embed_model=embed_model)\n\t\tself.vector_index_retriever = self.instrument_store.vector_index.as_retriever(\n\t\t\tsimilarity_top_k=similarity_top_k,\n\t\t)\n\t\tself._similarity_top_k = similarity_top_k\n\t\tself._instrument_top_k = instrument_top_k\n\t\tself._choice_batch_size = choice_batch_size\n\t\tself._final_top_k = final_top_k\n\t\tself._format_node_batch_fn = format_instrument_node_batch_fn\n\t\tself._choice_select_prompt = INSTRUMENT_CHOICE_SELECT_PROMPT\n\t\tself._parse_choice_select_answer_fn = default_parse_choice_select_answer_fn\n\n\tdef _retrieve_proper_instrument(self, retrieve_items: str) -&gt; List[str]:\n\t\tr\"\"\"\n\t\tUse LLM to select the proper instruments based on their description.\n\n\t\tArgs:\n\t\t\tretrieve_items (str): The things to be retrieved.\n\n\t\tReturns:\n\t\t\tList[str]:\n\t\t\t\tThe retrieved node_ids.\n\t\t\"\"\"\n\t\tinstrument_ids = self.instrument_store.get_all_instruments()\n\t\tdsc_nodes = self.instrument_store.get_nodes(node_ids=instrument_ids)\n\n\t\tall_nodes: List[BaseNode] = []\n\t\tall_relevances: List[float] = []\n\n\t\tfor idx in range(0, len(dsc_nodes), self._choice_batch_size):\n\t\t\tnodes = dsc_nodes[idx: idx + self._choice_batch_size]\n\t\t\tfmt_batch_str = self._format_node_batch_fn(nodes)\n\t\t\tllm_response = self.llm.predict(\n\t\t\t\tself._choice_select_prompt,\n\t\t\t\tcontext_str=fmt_batch_str,\n\t\t\t\tquery_str=retrieve_items,\n\t\t\t)\n\n\t\t\tanswer_lines = llm_response.split(\"\\n\")\n\t\t\tvalid_lines = []\n\t\t\tfor answer_line in answer_lines:\n\t\t\t\tif len(answer_line) &gt; 4:\n\t\t\t\t\tvalid_lines.append(answer_line.strip())\n\t\t\tvalid_response = \"\\n\".join(valid_lines)\n\n\t\t\tchoices, relevances = self._parse_choice_select_answer_fn(valid_response, len(nodes), raise_error=True)\n\t\t\tchoice_indices = [c - 1 for c in choices]\n\n\t\t\tchoice_instruments = [nodes[ci] for ci in choice_indices]\n\n\t\t\tall_nodes.extend(choice_instruments)\n\t\t\tall_relevances.extend(relevances)\n\n\t\tzipped_list = list(zip(all_nodes, all_relevances))\n\t\tsorted_list = sorted(zipped_list, key=lambda x: x[1], reverse=True)\n\t\ttop_k_list = sorted_list[: self._instrument_top_k]\n\n\t\tselect_instrument_ids = [node.node_id for node, relevance in top_k_list]\n\t\treturn select_instrument_ids\n\n\tasync def _aretrieve_proper_instrument(self, retrieve_items: str):\n\t\tr\"\"\"\n\t\tAsynchronously select the proper instruments based on their description.\n\n\t\tArgs:\n\t\t\tretrieve_items (str): The things to be retrieved.\n\n\t\tReturns:\n\t\t\tList[str]:\n\t\t\t\tThe retrieved node_ids.\n\t\t\"\"\"\n\t\tinstrument_ids = self.instrument_store.get_all_instruments()\n\t\tdsc_nodes = self.instrument_store.get_nodes(node_ids=instrument_ids)\n\n\t\tall_nodes: List[BaseNode] = []\n\t\tall_relevances: List[float] = []\n\n\t\tfor idx in range(0, len(dsc_nodes), self._choice_batch_size):\n\t\t\tnodes = dsc_nodes[idx: idx + self._choice_batch_size]\n\t\t\tfmt_batch_str = self._format_node_batch_fn(nodes)\n\t\t\tllm_response = await self.llm.apredict(\n\t\t\t\tself._choice_select_prompt,\n\t\t\t\tcontext_str=fmt_batch_str,\n\t\t\t\tquery_str=retrieve_items,\n\t\t\t)\n\t\t\tchoices, relevances = self._parse_choice_select_answer_fn(llm_response, len(nodes))\n\t\t\tchoice_indices = [c - 1 for c in choices]\n\n\t\t\tchoice_instruments = [nodes[ci] for ci in choice_indices]\n\n\t\t\tall_nodes.extend(choice_instruments)\n\t\t\tall_relevances.extend(relevances)\n\n\t\tzipped_list = list(zip(all_nodes, all_relevances))\n\t\tsorted_list = sorted(zipped_list, key=lambda x: x[1], reverse=True)\n\t\ttop_k_list = sorted_list[: self._instrument_top_k]\n\n\t\tselect_instrument_ids = [node.node_id for node, relevance in top_k_list]\n\t\treturn select_instrument_ids\n\n\tdef set_retriever_top_k(self, similarity_top_k: int):\n\t\tr\"\"\" Set the top-k of the first content-based retrieving. \"\"\"\n\t\tself.vector_index_retriever._similarity_top_k = similarity_top_k\n\n\tdef set_retriever_node_ids(self, node_ids: Optional[List[str]] = None):\n\t\tr\"\"\" Confine the range of node_ids in retrieving. \"\"\"\n\t\tself.vector_index_retriever._node_ids = node_ids\n\n\tdef _retrieve_instrument_content_based(self, retrieve_items: str) -&gt; List[str]:\n\t\tr\"\"\"\n\t\tContent-based retrieving.\n\n\t\tArgs:\n\t\t\tretrieve_items (str): Item to be retrieved.\n\n\t\tReturns:\n\t\t\tList[str]: The ids of the instruments that the retrieved docs belong to.\n\t\t\"\"\"\n\t\tself.set_retriever_top_k(self._similarity_top_k)\n\t\tself.set_retriever_node_ids()\n\t\tcontent_nodes = self.vector_index_retriever.retrieve(retrieve_items)\n\n\t\tinstrument_ids = set()\n\t\t# TODO: To be modified\n\t\tfor node in content_nodes:\n\t\t\tinstrument_node = node.node.parent_node\n\t\t\tif instrument_node is not None:\n\t\t\t\tinstrument_ids.add(instrument_node.node_id)\n\t\t\telse:\n\t\t\t\tinstrument_ids.add(node.node_id)\n\t\treturn list(instrument_ids)\n\n\tasync def _aretrieve_instrument_content_based(self, retrieve_items: str) -&gt; List[str]:\n\t\tr\"\"\"\n\t\tAsynchronously content-based retrieving.\n\n\t\tArgs:\n\t\t\tretrieve_items (str): Item to be retrieved.\n\n\t\tReturns:\n\t\t\tList[str]: The ids of the instruments that the retrieved docs belong to.\n\t\t\"\"\"\n\t\tself.set_retriever_top_k(self._similarity_top_k)\n\t\tself.set_retriever_node_ids()\n\t\tcontent_nodes = await self.vector_index_retriever.aretrieve(retrieve_items)\n\n\t\tinstrument_ids = set()\n\t\t# TODO: To be modified\n\t\tfor node in content_nodes:\n\t\t\tinstrument_node = node.node.parent_node\n\t\t\tif instrument_node is not None:\n\t\t\t\tinstrument_ids.add(instrument_node.node_id)\n\t\t\telse:\n\t\t\t\tinstrument_ids.add(node.node_id)\n\t\treturn list(instrument_ids)\n\n\t@dispatcher.span\n\tdef retrieve(\n\t\tself,\n\t\titem_to_be_retrieved: str,\n\t) -&gt; List[NodeWithScore]:\n\t\tr\"\"\"\n\t\tThis tool is used to help the laboratory member to solve their encountered difficulties in their experiment,\n\t\tby retrieving in the documents of the lab's scientific instruments.\n\n\t\tyou could use this tool to suggest proper instruments to help him/her to overcome the difficulties,\n\t\tand provide comprehensive information about these instruments from the instrument documents\n\t\tincluding instruction manuals, operation specifications of scientific instruments.\n\n\t\tArgs:\n\t\t\titem_to_be_retrieved (str): The string to be retrieved relevant to the scientific instruments\n\n\t\tReturns:\n\t\t\tList[NodeWithScore]: The retrieved nodes.\n\t\t\t\tThe contents of these retrieved nodes will be presented as the output.\n\t\t\"\"\"\n\t\t# This docstring will be used as the tool description.\n\t\tdsc_instruments = self._retrieve_proper_instrument(retrieve_items=item_to_be_retrieved)\n\n\t\t# content_instruments = self._retrieve_instrument_content_based(retrieve_items=item_to_be_retrieved)\n\t\t# instrument_ids = list(set(dsc_instruments + content_instruments))\n\n\t\tinstrument_ids = dsc_instruments\n\n\t\tinstruments = self.instrument_store.get_nodes(node_ids=instrument_ids)\n\t\tretrieve_range = []\n\n\t\tretrieve_range.extend(instrument_ids)\n\t\tfor ins in instruments:\n\t\t\tdoc_nodes = ins.child_nodes\n\t\t\tif doc_nodes is not None:\n\t\t\t\tretrieve_range.extend([node.node_id for node in doc_nodes])\n\n\t\tself.set_retriever_top_k(self._final_top_k)\n\t\tself.set_retriever_node_ids(node_ids=retrieve_range)\n\t\tfinal_nodes = self.vector_index_retriever.retrieve(item_to_be_retrieved)\n\t\treturn final_nodes\n\n\tasync def aretrieve(\n\t\tself,\n\t\titem_to_be_retrieved: str,\n\t) -&gt; List[NodeWithScore]:\n\t\tr\"\"\"\n\t\tThis tool is used to retrieve in the documents of the lab's scientific instruments.\n\t\tThese documents include the instruction manuals, operation specifications of scientific instruments.\n\n\t\tArgs:\n\t\t\titem_to_be_retrieved (str): The string to be retrieved relevant to the scientific instruments\n\n\t\tReturns:\n\t\t\tList[NodeWithScore]: The retrieved nodes.\n\t\t\t\tThe contents of these retrieved nodes will be presented as the output.\n\t\t\"\"\"\n\t\t# This docstring will be used as the tool description.\n\t\tdsc_instruments = await self._aretrieve_proper_instrument(retrieve_items=item_to_be_retrieved)\n\t\t# content_instruments = await self._aretrieve_instrument_content_based(retrieve_items=item_to_be_retrieved)\n\t\t# instrument_ids = list(set(dsc_instruments + content_instruments))\n\n\t\tinstrument_ids = dsc_instruments\n\n\t\tinstruments = self.instrument_store.get_nodes(node_ids=instrument_ids)\n\t\tretrieve_range = []\n\n\t\tretrieve_range.extend(instrument_ids)\n\t\tfor ins in instruments:\n\t\t\tdoc_nodes = ins.child_nodes\n\t\t\tif doc_nodes is not None:\n\t\t\t\tretrieve_range.extend([node.node_id for node in doc_nodes])\n\n\t\tself.set_retriever_top_k(self._final_top_k)\n\t\tself.set_retriever_node_ids(node_ids=retrieve_range)\n\t\tfinal_nodes = await self.vector_index_retriever.aretrieve(item_to_be_retrieved)\n\t\treturn final_nodes\n</code></pre>"},{"location":"code_docs/func_modules/instrument/retrieve/instrument_retriever/#labridge.func_modules.instrument.retrieve.instrument_retriever.InstrumentRetriever.aretrieve","title":"<code>labridge.func_modules.instrument.retrieve.instrument_retriever.InstrumentRetriever.aretrieve(item_to_be_retrieved)</code>  <code>async</code>","text":"<p>This tool is used to retrieve in the documents of the lab's scientific instruments. These documents include the instruction manuals, operation specifications of scientific instruments.</p> PARAMETER DESCRIPTION <code>item_to_be_retrieved</code> <p>The string to be retrieved relevant to the scientific instruments</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>List[NodeWithScore]</code> <p>List[NodeWithScore]: The retrieved nodes. The contents of these retrieved nodes will be presented as the output.</p> Source code in <code>labridge\\func_modules\\instrument\\retrieve\\instrument_retriever.py</code> <pre><code>async def aretrieve(\n\tself,\n\titem_to_be_retrieved: str,\n) -&gt; List[NodeWithScore]:\n\tr\"\"\"\n\tThis tool is used to retrieve in the documents of the lab's scientific instruments.\n\tThese documents include the instruction manuals, operation specifications of scientific instruments.\n\n\tArgs:\n\t\titem_to_be_retrieved (str): The string to be retrieved relevant to the scientific instruments\n\n\tReturns:\n\t\tList[NodeWithScore]: The retrieved nodes.\n\t\t\tThe contents of these retrieved nodes will be presented as the output.\n\t\"\"\"\n\t# This docstring will be used as the tool description.\n\tdsc_instruments = await self._aretrieve_proper_instrument(retrieve_items=item_to_be_retrieved)\n\t# content_instruments = await self._aretrieve_instrument_content_based(retrieve_items=item_to_be_retrieved)\n\t# instrument_ids = list(set(dsc_instruments + content_instruments))\n\n\tinstrument_ids = dsc_instruments\n\n\tinstruments = self.instrument_store.get_nodes(node_ids=instrument_ids)\n\tretrieve_range = []\n\n\tretrieve_range.extend(instrument_ids)\n\tfor ins in instruments:\n\t\tdoc_nodes = ins.child_nodes\n\t\tif doc_nodes is not None:\n\t\t\tretrieve_range.extend([node.node_id for node in doc_nodes])\n\n\tself.set_retriever_top_k(self._final_top_k)\n\tself.set_retriever_node_ids(node_ids=retrieve_range)\n\tfinal_nodes = await self.vector_index_retriever.aretrieve(item_to_be_retrieved)\n\treturn final_nodes\n</code></pre>"},{"location":"code_docs/func_modules/instrument/retrieve/instrument_retriever/#labridge.func_modules.instrument.retrieve.instrument_retriever.InstrumentRetriever.retrieve","title":"<code>labridge.func_modules.instrument.retrieve.instrument_retriever.InstrumentRetriever.retrieve(item_to_be_retrieved)</code>","text":"<p>This tool is used to help the laboratory member to solve their encountered difficulties in their experiment, by retrieving in the documents of the lab's scientific instruments.</p> <p>you could use this tool to suggest proper instruments to help him/her to overcome the difficulties, and provide comprehensive information about these instruments from the instrument documents including instruction manuals, operation specifications of scientific instruments.</p> PARAMETER DESCRIPTION <code>item_to_be_retrieved</code> <p>The string to be retrieved relevant to the scientific instruments</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>List[NodeWithScore]</code> <p>List[NodeWithScore]: The retrieved nodes. The contents of these retrieved nodes will be presented as the output.</p> Source code in <code>labridge\\func_modules\\instrument\\retrieve\\instrument_retriever.py</code> <pre><code>@dispatcher.span\ndef retrieve(\n\tself,\n\titem_to_be_retrieved: str,\n) -&gt; List[NodeWithScore]:\n\tr\"\"\"\n\tThis tool is used to help the laboratory member to solve their encountered difficulties in their experiment,\n\tby retrieving in the documents of the lab's scientific instruments.\n\n\tyou could use this tool to suggest proper instruments to help him/her to overcome the difficulties,\n\tand provide comprehensive information about these instruments from the instrument documents\n\tincluding instruction manuals, operation specifications of scientific instruments.\n\n\tArgs:\n\t\titem_to_be_retrieved (str): The string to be retrieved relevant to the scientific instruments\n\n\tReturns:\n\t\tList[NodeWithScore]: The retrieved nodes.\n\t\t\tThe contents of these retrieved nodes will be presented as the output.\n\t\"\"\"\n\t# This docstring will be used as the tool description.\n\tdsc_instruments = self._retrieve_proper_instrument(retrieve_items=item_to_be_retrieved)\n\n\t# content_instruments = self._retrieve_instrument_content_based(retrieve_items=item_to_be_retrieved)\n\t# instrument_ids = list(set(dsc_instruments + content_instruments))\n\n\tinstrument_ids = dsc_instruments\n\n\tinstruments = self.instrument_store.get_nodes(node_ids=instrument_ids)\n\tretrieve_range = []\n\n\tretrieve_range.extend(instrument_ids)\n\tfor ins in instruments:\n\t\tdoc_nodes = ins.child_nodes\n\t\tif doc_nodes is not None:\n\t\t\tretrieve_range.extend([node.node_id for node in doc_nodes])\n\n\tself.set_retriever_top_k(self._final_top_k)\n\tself.set_retriever_node_ids(node_ids=retrieve_range)\n\tfinal_nodes = self.vector_index_retriever.retrieve(item_to_be_retrieved)\n\treturn final_nodes\n</code></pre>"},{"location":"code_docs/func_modules/instrument/retrieve/instrument_retriever/#labridge.func_modules.instrument.retrieve.instrument_retriever.InstrumentRetriever.set_retriever_node_ids","title":"<code>labridge.func_modules.instrument.retrieve.instrument_retriever.InstrumentRetriever.set_retriever_node_ids(node_ids=None)</code>","text":"<p>Confine the range of node_ids in retrieving.</p> Source code in <code>labridge\\func_modules\\instrument\\retrieve\\instrument_retriever.py</code> <pre><code>def set_retriever_node_ids(self, node_ids: Optional[List[str]] = None):\n\tr\"\"\" Confine the range of node_ids in retrieving. \"\"\"\n\tself.vector_index_retriever._node_ids = node_ids\n</code></pre>"},{"location":"code_docs/func_modules/instrument/retrieve/instrument_retriever/#labridge.func_modules.instrument.retrieve.instrument_retriever.InstrumentRetriever.set_retriever_top_k","title":"<code>labridge.func_modules.instrument.retrieve.instrument_retriever.InstrumentRetriever.set_retriever_top_k(similarity_top_k)</code>","text":"<p>Set the top-k of the first content-based retrieving.</p> Source code in <code>labridge\\func_modules\\instrument\\retrieve\\instrument_retriever.py</code> <pre><code>def set_retriever_top_k(self, similarity_top_k: int):\n\tr\"\"\" Set the top-k of the first content-based retrieving. \"\"\"\n\tself.vector_index_retriever._similarity_top_k = similarity_top_k\n</code></pre>"},{"location":"code_docs/func_modules/instrument/retrieve/instrument_retriever/#labridge.func_modules.instrument.retrieve.instrument_retriever.format_instrument_node_batch_fn","title":"<code>labridge.func_modules.instrument.retrieve.instrument_retriever.format_instrument_node_batch_fn(instrument_nodes)</code>","text":"<p>This function returns a text containing the indices and descriptions of a batch of instruments. LLM will select from these instruments according to this text.</p> PARAMETER DESCRIPTION <code>instrument_nodes</code> <p>The nodes stored in the <code>InstrumentStorage</code>, containing the instrument name and description.</p> <p> TYPE: <code>List[BaseNode]</code> </p> RETURNS DESCRIPTION <code>str</code> <p>The generated text.</p> <p> TYPE: <code>str</code> </p> Source code in <code>labridge\\func_modules\\instrument\\retrieve\\instrument_retriever.py</code> <pre><code>def format_instrument_node_batch_fn(instrument_nodes: List[BaseNode]) -&gt; str:\n\tr\"\"\"\n\tThis function returns a text containing the indices and descriptions of a batch of instruments.\n\tLLM will select from these instruments according to this text.\n\n\tArgs:\n\t\tinstrument_nodes (List[BaseNode]): The nodes stored in the `InstrumentStorage`,\n\t\t\tcontaining the instrument name and description.\n\n\tReturns:\n\t\tstr: The generated text.\n\t\"\"\"\n\ttexts = []\n\tfor idx in range(len(instrument_nodes)):\n\t\tnumber = idx + 1\n\t\ttexts.append(\n\t\t\tf\"Instrument {number}:\\n\"\n\t\t\tf\"{instrument_nodes[idx].get_content(metadata_mode=MetadataMode.LLM)}\"\n\t\t)\n\treturn \"\\n\\n\".join(texts)\n</code></pre>"},{"location":"code_docs/func_modules/instrument/store/instrument_store/","title":"Instrument store","text":""},{"location":"code_docs/func_modules/instrument/store/instrument_store/#labridge.func_modules.instrument.store.instrument_store","title":"<code>labridge.func_modules.instrument.store.instrument_store</code>","text":""},{"location":"code_docs/func_modules/instrument/store/instrument_store/#labridge.func_modules.instrument.store.instrument_store.InstrumentStorage","title":"<code>labridge.func_modules.instrument.store.instrument_store.InstrumentStorage</code>","text":"<p>               Bases: <code>object</code></p> <p>This class is used for the storage of instrument documents.</p> PARAMETER DESCRIPTION <code>vector_index</code> <p>The vector database that stores the instrument documents.</p> <p> TYPE: <code>VectorStoreIndex</code> DEFAULT: <code>None</code> </p> <code>persist_dir</code> <p>The save path of the vector_index.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>embed_model</code> <p>The used embedding model.</p> <p> TYPE: <code>BaseEmbedding</code> DEFAULT: <code>None</code> </p> Source code in <code>labridge\\func_modules\\instrument\\store\\instrument_store.py</code> <pre><code>class InstrumentStorage(object):\n\tr\"\"\"\n\tThis class is used for the storage of instrument documents.\n\n\tArgs:\n\t\tvector_index (VectorStoreIndex): The vector database that stores the instrument documents.\n\t\tpersist_dir (str): The save path of the vector_index.\n\t\tembed_model (BaseEmbedding): The used embedding model.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tvector_index: VectorStoreIndex = None,\n\t\tpersist_dir: str = None,\n\t\tembed_model: BaseEmbedding = None\n\t):\n\t\troot = Path(__file__)\n\t\tfor i in range(5):\n\t\t\troot = root.parent\n\t\tself.root = root\n\t\tself.vector_index = vector_index\n\t\tself.vector_index.set_index_id(INSTRUMENT_VECTOR_INDEX_ID)\n\t\tself.embed_model = embed_model\n\t\tself.persist_dir = persist_dir or self._default_persist_dir()\n\t\tself.instrument_ware_house_dir = self._default_warehouse_dir()\n\n\tdef _default_persist_dir(self) -&gt; str:\n\t\tr\"\"\" Return the default save directory of the instrument vector index. \"\"\"\n\t\treturn str(self.root / DEFAULT_INSTRUMENT_VECTOR_PERSIST_DIR)\n\n\tdef _default_warehouse_dir(self) -&gt; str:\n\t\tr\"\"\" Returns the default save directory of the instrument documents. \"\"\"\n\t\treturn str(self.root / DEFAULT_INSTRUMENT_WAREHOUSE_DIR)\n\n\t@classmethod\n\tdef from_storage(\n\t\tcls,\n\t\tpersist_dir: str,\n\t\tembed_model: BaseEmbedding,\n\t):\n\t\tr\"\"\"\n\t\tConstruct from an existing storage.\n\n\t\tArgs:\n\t\t\tpersist_dir (str): The persis_dir of an existing InstrumentStorage.\n\t\t\tembed_model (BaseEmbedding): The used embedding model.\n\n\t\tReturns:\n\t\t\tInstrumentStorage: The loaded storage.\n\t\t\"\"\"\n\t\tvector_storage_context = StorageContext.from_defaults(persist_dir=persist_dir)\n\t\tvector_index = load_index_from_storage(\n\t\t\tstorage_context=vector_storage_context,\n\t\t\tindex_id=INSTRUMENT_VECTOR_INDEX_ID,\n\t\t\tembed_model=embed_model,\n\t\t)\n\t\treturn cls(\n\t\t\tvector_index=vector_index,\n\t\t\tpersist_dir=persist_dir,\n\t\t)\n\n\t@classmethod\n\tdef from_default(\n\t\tcls,\n\t\tembed_model: BaseEmbedding = None,\n\t):\n\t\tr\"\"\"\n\t\tLoad the default instrument storage.\n\n\t\tArgs:\n\t\t\tembed_model (BaseEmbedding): The used embedding model.\n\n\t\tReturns:\n\t\t\tInstrumentStorage: The loaded storage.\n\t\t\"\"\"\n\t\troot = Path(__file__)\n\t\tfor i in range(5):\n\t\t\troot = root.parent\n\t\tpersist_dir = str(root / DEFAULT_INSTRUMENT_VECTOR_PERSIST_DIR)\n\n\t\tembed_model = embed_model or Settings.embed_model\n\t\tfs = fsspec.filesystem(\"file\")\n\t\tif fs.exists(persist_dir):\n\t\t\treturn cls.from_storage(\n\t\t\t\tpersist_dir=persist_dir,\n\t\t\t\tembed_model=embed_model,\n\t\t\t)\n\t\troot_node = TextNode(\n\t\t\ttext=\"root node for the instruments.\",\n\t\t\tid_=INSTRUMENT_ROOT_NODE_NAME\n\t\t)\n\t\tnodes = [root_node]\n\t\tvector_index = VectorStoreIndex(\n\t\t\tnodes=nodes,\n\t\t\tembed_model=embed_model,\n\t\t)\n\n\t\treturn cls(\n\t\t\tvector_index=vector_index,\n\t\t\tpersist_dir=persist_dir,\n\t\t\tembed_model=embed_model,\n\t\t)\n\n\tdef _add_instrument_docs_to_warehouse(\n\t\tself,\n\t\tinstrument_id: str,\n\t\tinstrument_doc_paths: List[str],\n\t) -&gt; List[str]:\n\t\tr\"\"\"\n\t\tStore the instrument documents in the instrument warehouse.\n\n\t\tArgs:\n\t\t\tinstrument_id (str): The instrument name.\n\t\t\tinstrument_doc_paths (InstrumentStorage): The file paths of the instrument's documents.\n\n\t\tReturns:\n\t\t\tList[str]: The file paths of the stored instrument documents\n\t\t\"\"\"\n\t\tfs = fsspec.filesystem(\"file\")\n\t\twarehouse_dir = self.root / DEFAULT_INSTRUMENT_WAREHOUSE_DIR\n\t\tinstrument_dir = warehouse_dir / instrument_id\n\n\t\tif not fs.exists(str(instrument_dir)):\n\t\t\tfs.makedirs(str(instrument_dir))\n\n\t\tfor doc_path in instrument_doc_paths:\n\t\t\tif not fs.exists(doc_path):\n\t\t\t\traise ValueError(f\"Error: {doc_path} do not exist!\")\n\n\t\tstore_paths = []\n\t\tfor doc_path in instrument_doc_paths:\n\t\t\tfs.cp(doc_path, str(instrument_dir))\n\t\t\tdoc_name = Path(doc_path).name\n\t\t\tstore_paths.append(\n\t\t\t\tstr(instrument_dir / doc_name)\n\t\t\t)\n\t\treturn store_paths\n\n\tdef _default_vector_transformations(self) -&gt; List[TransformComponent]:\n\t\tr\"\"\" Default transformations of the vector index. \"\"\"\n\t\treturn [SentenceSplitter(chunk_size=1024, chunk_overlap=256, include_metadata=True), ]\n\n\tdef get_nodes(self, node_ids: List[str]) -&gt; List[BaseNode]:\n\t\tr\"\"\"\n\t\tGet the nodes according to node_ids.\n\n\t\tArgs:\n\t\t\tnode_ids (List[str]): The node ids.\n\n\t\tReturns:\n\t\t\tList[BaseNode]: The corresponding nodes in the vector index.\n\n\t\tRaises:\n\t\t\tValueError: If any node_id does not exist in the vector index.\n\t\t\"\"\"\n\t\treturn self.vector_index.docstore.get_nodes(node_ids=node_ids)\n\n\tdef _get_node(self, node_id: str) -&gt; BaseNode:\n\t\tr\"\"\" get node from the vector index \"\"\"\n\t\treturn self.vector_index.docstore.get_node(node_id)\n\n\tdef _update_node(\n\t\tself,\n\t\tnode_id: str,\n\t\tnode: BaseNode,\n\t):\n\t\tr\"\"\" update node in vector index \"\"\"\n\t\tself.vector_index.delete_nodes([node_id])\n\t\tself.vector_index.insert_nodes([node])\n\n\tdef get_all_instruments(self) -&gt; List[str]:\n\t\tr\"\"\"\n\t\tGet all instrument ids.\n\n\t\tReturns:\n\t\t\tList[str]: All instrument ids.\n\t\t\"\"\"\n\t\troot_node = self._get_node(node_id=INSTRUMENT_ROOT_NODE_NAME)\n\t\tinstrument_list = root_node.child_nodes or []\n\t\tinstrument_ids = [ins.node_id for ins in instrument_list]\n\t\treturn instrument_ids\n\n\tdef add_instrument(\n\t\tself,\n\t\tinstrument_id: str,\n\t\tinstrument_description: str,\n\t\tinstrument_doc_paths: List[str],\n\t\tsuper_user_ids: List[str],\n\t):\n\t\tr\"\"\"\n\t\tAdd a new instrument to storage.\n\n\t\t1. Add a text node containing the instrument id and description, and add it to the root_node's children.\n\t\t2. Add the instrument document nodes as the children of the instrument node.\n\n\t\tArgs:\n\t\t\tinstrument_id (str): The instrument name.\n\t\t\tinstrument_description (str): The instrument description.\n\t\t\tinstrument_doc_paths (List[str]): The file paths of the instrument's documents.\n\t\t\tsuper_user_ids (List[str]): The supe-users of the instrument.\n\t\t\"\"\"\n\t\t# Add to instrument manager\n\t\tmanager = InstrumentSuperUserManager()\n\t\tmanager.add_instrument(\n\t\t\tinstrument_id=instrument_id,\n\t\t\tsuper_users=super_user_ids,\n\t\t)\n\t\t# add instrument node to root node.\n\t\troot_node = self._get_node(node_id=INSTRUMENT_ROOT_NODE_NAME)\n\t\tprint(\"root_node childs: \", root_node.child_nodes)\n\t\tinstrument_list = root_node.child_nodes or []\n\n\t\tinstrument_node = TextNode(\n\t\t\ttext=instrument_description,\n\t\t\tid_=instrument_id,\n\t\t)\n\t\tinstrument_list.append(\n\t\t\tRelatedNodeInfo(node_id=instrument_node.node_id)\n\t\t)\n\t\troot_node.relationships[NodeRelationship.CHILD] = instrument_list\n\t\tself._update_node(node_id=INSTRUMENT_ROOT_NODE_NAME, node=root_node)\n\n\t\tself.vector_index.insert_nodes(nodes=[instrument_node])\n\n\t\tself.add_instrument_doc(\n\t\t\tinstrument_id=instrument_id,\n\t\t\tdoc_path=instrument_doc_paths,\n\t\t)\n\n\tdef add_instrument_doc(\n\t\tself,\n\t\tinstrument_id: str,\n\t\tdoc_path: Union[str, List[str]]\n\t):\n\t\tr\"\"\"\n\t\tAdd documents to an instrument's docs.\n\n\t\tArgs:\n\t\t\tinstrument_id (str): The instrument name.\n\t\t\tdoc_path (Union[str, List[str]]): New documents of the instrument.\n\t\t\"\"\"\n\t\tinstrument_node = self._get_node(node_id=instrument_id)\n\t\tif not isinstance(doc_path, list):\n\t\t\tdoc_path = [doc_path]\n\n\t\tif len(doc_path) &lt; 1:\n\t\t\treturn\n\n\t\tpath_list = self._add_instrument_docs_to_warehouse(\n\t\t\tinstrument_id=instrument_id,\n\t\t\tinstrument_doc_paths=doc_path,\n\t\t)\n\n\t\t# read the docs.\n\t\treader = SimpleDirectoryReader(\n\t\t\tinput_files=path_list,\n\t\t\tfile_metadata=instrument_get_file_metadata,\n\t\t\tfilename_as_id=True,\n\t\t\trecursive=True,\n\t\t)\n\t\tdocuments = reader.load_data()\n\n\t\tfor doc in documents:\n\t\t\tself.vector_index.docstore.set_document_hash(doc.get_doc_id(), doc.hash)\n\n\t\t# chunk to nodes.\n\t\tdoc_nodes = run_transformations(nodes=documents, transformations=self._default_vector_transformations(), )\n\n\t\tchild_nodes = instrument_node.child_nodes or []\n\t\tfor doc_node in doc_nodes:\n\t\t\tchild_nodes.append(RelatedNodeInfo(node_id=doc_node.node_id))\n\t\t\tdoc_node.relationships[NodeRelationship.PARENT] = RelatedNodeInfo(node_id=instrument_id)\n\n\t\tinstrument_node.relationships[NodeRelationship.CHILD] = child_nodes\n\n\t\tself._update_node(node_id=instrument_id, node=instrument_node)\n\t\tself.vector_index.insert_nodes(nodes=doc_nodes)\n\n\tdef delete_instrument_doc(\n\t\tself,\n\t\tinstrument_id: str,\n\t\tdoc_rel_path: Union[str, List[str]],\n\t):\n\t\tr\"\"\"\n\t\tDelete specific docs from the instrument storage and warehouse according to the relative path of the document.\n\n\t\tArgs:\n\t\t\tinstrument_id (str): The instrument name.\n\t\t\tdoc_rel_path (str): The document path relative to root.\n\t\t\"\"\"\n\t\tinstrument_node = self._get_node(node_id=instrument_id)\n\t\tchild_node_list = instrument_node.child_nodes\n\n\t\tif not isinstance(doc_rel_path, list):\n\t\t\tdoc_rel_path = [doc_rel_path]\n\n\t\tdelete_node_ids = []\n\t\tfor child_node in child_node_list:\n\t\t\tnode_id = child_node.node_id\n\t\t\tdoc_node = self._get_node(node_id=node_id)\n\t\t\tif doc_node.metadata[INSTRUMENT_FILE_PATH_KEY] in doc_rel_path:\n\t\t\t\tdelete_node_ids.append(node_id)\n\t\t\t\tchild_node_list.remove(child_node)\n\n\t\tinstrument_node.relationships[NodeRelationship.CHILD] = child_node_list\n\t\tself._update_node(node_id=instrument_id, node=instrument_node)\n\t\tself.vector_index.delete_nodes(node_ids=delete_node_ids)\n\n\t\tfs = fsspec.filesystem(\"file\")\n\t\tfor rel_path in doc_rel_path:\n\t\t\tabs_path = str(self.root / rel_path)\n\t\t\tfs.rm(abs_path)\n\n\tdef update_instrument_doc(\n\t\tself,\n\t\tinstrument_id: str,\n\t\tinstrument_doc_name: str,\n\t\tnew_doc_path: str,\n\t):\n\t\tr\"\"\"\n\t\tUpdate an instrument document with a new document.\n\n\t\tArgs:\n\t\t\tinstrument_id (str): The instrument name.\n\t\t\tinstrument_doc_name (str): The old instrument document name.\n\t\t\tnew_doc_path (str): The path of the new document.\n\t\t\"\"\"\n\t\told_doc_path = Path(DEFAULT_INSTRUMENT_WAREHOUSE_DIR) / instrument_doc_name\n\t\told_doc_path = str(old_doc_path)\n\n\t\tself.delete_instrument_doc(\n\t\t\tinstrument_id=instrument_id,\n\t\t\tdoc_rel_path=old_doc_path,\n\t\t)\n\t\tself.add_instrument_doc(\n\t\t\tinstrument_id=instrument_id,\n\t\t\tdoc_path=new_doc_path,\n\t\t)\n\n\tdef persist(self, persist_dir: str = None):\n\t\tr\"\"\" Save the storage. \"\"\"\n\t\tpersist_dir = persist_dir or self.persist_dir\n\t\tfs = fsspec.filesystem(\"file\")\n\t\tif not fs.exists(persist_dir):\n\t\t\tfs.makedirs(persist_dir)\n\t\tself.vector_index.storage_context.persist(persist_dir=persist_dir)\n</code></pre>"},{"location":"code_docs/func_modules/instrument/store/instrument_store/#labridge.func_modules.instrument.store.instrument_store.InstrumentStorage.add_instrument","title":"<code>labridge.func_modules.instrument.store.instrument_store.InstrumentStorage.add_instrument(instrument_id, instrument_description, instrument_doc_paths, super_user_ids)</code>","text":"<p>Add a new instrument to storage.</p> <ol> <li>Add a text node containing the instrument id and description, and add it to the root_node's children.</li> <li>Add the instrument document nodes as the children of the instrument node.</li> </ol> PARAMETER DESCRIPTION <code>instrument_id</code> <p>The instrument name.</p> <p> TYPE: <code>str</code> </p> <code>instrument_description</code> <p>The instrument description.</p> <p> TYPE: <code>str</code> </p> <code>instrument_doc_paths</code> <p>The file paths of the instrument's documents.</p> <p> TYPE: <code>List[str]</code> </p> <code>super_user_ids</code> <p>The supe-users of the instrument.</p> <p> TYPE: <code>List[str]</code> </p> Source code in <code>labridge\\func_modules\\instrument\\store\\instrument_store.py</code> <pre><code>def add_instrument(\n\tself,\n\tinstrument_id: str,\n\tinstrument_description: str,\n\tinstrument_doc_paths: List[str],\n\tsuper_user_ids: List[str],\n):\n\tr\"\"\"\n\tAdd a new instrument to storage.\n\n\t1. Add a text node containing the instrument id and description, and add it to the root_node's children.\n\t2. Add the instrument document nodes as the children of the instrument node.\n\n\tArgs:\n\t\tinstrument_id (str): The instrument name.\n\t\tinstrument_description (str): The instrument description.\n\t\tinstrument_doc_paths (List[str]): The file paths of the instrument's documents.\n\t\tsuper_user_ids (List[str]): The supe-users of the instrument.\n\t\"\"\"\n\t# Add to instrument manager\n\tmanager = InstrumentSuperUserManager()\n\tmanager.add_instrument(\n\t\tinstrument_id=instrument_id,\n\t\tsuper_users=super_user_ids,\n\t)\n\t# add instrument node to root node.\n\troot_node = self._get_node(node_id=INSTRUMENT_ROOT_NODE_NAME)\n\tprint(\"root_node childs: \", root_node.child_nodes)\n\tinstrument_list = root_node.child_nodes or []\n\n\tinstrument_node = TextNode(\n\t\ttext=instrument_description,\n\t\tid_=instrument_id,\n\t)\n\tinstrument_list.append(\n\t\tRelatedNodeInfo(node_id=instrument_node.node_id)\n\t)\n\troot_node.relationships[NodeRelationship.CHILD] = instrument_list\n\tself._update_node(node_id=INSTRUMENT_ROOT_NODE_NAME, node=root_node)\n\n\tself.vector_index.insert_nodes(nodes=[instrument_node])\n\n\tself.add_instrument_doc(\n\t\tinstrument_id=instrument_id,\n\t\tdoc_path=instrument_doc_paths,\n\t)\n</code></pre>"},{"location":"code_docs/func_modules/instrument/store/instrument_store/#labridge.func_modules.instrument.store.instrument_store.InstrumentStorage.add_instrument_doc","title":"<code>labridge.func_modules.instrument.store.instrument_store.InstrumentStorage.add_instrument_doc(instrument_id, doc_path)</code>","text":"<p>Add documents to an instrument's docs.</p> PARAMETER DESCRIPTION <code>instrument_id</code> <p>The instrument name.</p> <p> TYPE: <code>str</code> </p> <code>doc_path</code> <p>New documents of the instrument.</p> <p> TYPE: <code>Union[str, List[str]]</code> </p> Source code in <code>labridge\\func_modules\\instrument\\store\\instrument_store.py</code> <pre><code>def add_instrument_doc(\n\tself,\n\tinstrument_id: str,\n\tdoc_path: Union[str, List[str]]\n):\n\tr\"\"\"\n\tAdd documents to an instrument's docs.\n\n\tArgs:\n\t\tinstrument_id (str): The instrument name.\n\t\tdoc_path (Union[str, List[str]]): New documents of the instrument.\n\t\"\"\"\n\tinstrument_node = self._get_node(node_id=instrument_id)\n\tif not isinstance(doc_path, list):\n\t\tdoc_path = [doc_path]\n\n\tif len(doc_path) &lt; 1:\n\t\treturn\n\n\tpath_list = self._add_instrument_docs_to_warehouse(\n\t\tinstrument_id=instrument_id,\n\t\tinstrument_doc_paths=doc_path,\n\t)\n\n\t# read the docs.\n\treader = SimpleDirectoryReader(\n\t\tinput_files=path_list,\n\t\tfile_metadata=instrument_get_file_metadata,\n\t\tfilename_as_id=True,\n\t\trecursive=True,\n\t)\n\tdocuments = reader.load_data()\n\n\tfor doc in documents:\n\t\tself.vector_index.docstore.set_document_hash(doc.get_doc_id(), doc.hash)\n\n\t# chunk to nodes.\n\tdoc_nodes = run_transformations(nodes=documents, transformations=self._default_vector_transformations(), )\n\n\tchild_nodes = instrument_node.child_nodes or []\n\tfor doc_node in doc_nodes:\n\t\tchild_nodes.append(RelatedNodeInfo(node_id=doc_node.node_id))\n\t\tdoc_node.relationships[NodeRelationship.PARENT] = RelatedNodeInfo(node_id=instrument_id)\n\n\tinstrument_node.relationships[NodeRelationship.CHILD] = child_nodes\n\n\tself._update_node(node_id=instrument_id, node=instrument_node)\n\tself.vector_index.insert_nodes(nodes=doc_nodes)\n</code></pre>"},{"location":"code_docs/func_modules/instrument/store/instrument_store/#labridge.func_modules.instrument.store.instrument_store.InstrumentStorage.delete_instrument_doc","title":"<code>labridge.func_modules.instrument.store.instrument_store.InstrumentStorage.delete_instrument_doc(instrument_id, doc_rel_path)</code>","text":"<p>Delete specific docs from the instrument storage and warehouse according to the relative path of the document.</p> PARAMETER DESCRIPTION <code>instrument_id</code> <p>The instrument name.</p> <p> TYPE: <code>str</code> </p> <code>doc_rel_path</code> <p>The document path relative to root.</p> <p> TYPE: <code>str</code> </p> Source code in <code>labridge\\func_modules\\instrument\\store\\instrument_store.py</code> <pre><code>def delete_instrument_doc(\n\tself,\n\tinstrument_id: str,\n\tdoc_rel_path: Union[str, List[str]],\n):\n\tr\"\"\"\n\tDelete specific docs from the instrument storage and warehouse according to the relative path of the document.\n\n\tArgs:\n\t\tinstrument_id (str): The instrument name.\n\t\tdoc_rel_path (str): The document path relative to root.\n\t\"\"\"\n\tinstrument_node = self._get_node(node_id=instrument_id)\n\tchild_node_list = instrument_node.child_nodes\n\n\tif not isinstance(doc_rel_path, list):\n\t\tdoc_rel_path = [doc_rel_path]\n\n\tdelete_node_ids = []\n\tfor child_node in child_node_list:\n\t\tnode_id = child_node.node_id\n\t\tdoc_node = self._get_node(node_id=node_id)\n\t\tif doc_node.metadata[INSTRUMENT_FILE_PATH_KEY] in doc_rel_path:\n\t\t\tdelete_node_ids.append(node_id)\n\t\t\tchild_node_list.remove(child_node)\n\n\tinstrument_node.relationships[NodeRelationship.CHILD] = child_node_list\n\tself._update_node(node_id=instrument_id, node=instrument_node)\n\tself.vector_index.delete_nodes(node_ids=delete_node_ids)\n\n\tfs = fsspec.filesystem(\"file\")\n\tfor rel_path in doc_rel_path:\n\t\tabs_path = str(self.root / rel_path)\n\t\tfs.rm(abs_path)\n</code></pre>"},{"location":"code_docs/func_modules/instrument/store/instrument_store/#labridge.func_modules.instrument.store.instrument_store.InstrumentStorage.from_default","title":"<code>labridge.func_modules.instrument.store.instrument_store.InstrumentStorage.from_default(embed_model=None)</code>  <code>classmethod</code>","text":"<p>Load the default instrument storage.</p> PARAMETER DESCRIPTION <code>embed_model</code> <p>The used embedding model.</p> <p> TYPE: <code>BaseEmbedding</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>InstrumentStorage</code> <p>The loaded storage.</p> Source code in <code>labridge\\func_modules\\instrument\\store\\instrument_store.py</code> <pre><code>@classmethod\ndef from_default(\n\tcls,\n\tembed_model: BaseEmbedding = None,\n):\n\tr\"\"\"\n\tLoad the default instrument storage.\n\n\tArgs:\n\t\tembed_model (BaseEmbedding): The used embedding model.\n\n\tReturns:\n\t\tInstrumentStorage: The loaded storage.\n\t\"\"\"\n\troot = Path(__file__)\n\tfor i in range(5):\n\t\troot = root.parent\n\tpersist_dir = str(root / DEFAULT_INSTRUMENT_VECTOR_PERSIST_DIR)\n\n\tembed_model = embed_model or Settings.embed_model\n\tfs = fsspec.filesystem(\"file\")\n\tif fs.exists(persist_dir):\n\t\treturn cls.from_storage(\n\t\t\tpersist_dir=persist_dir,\n\t\t\tembed_model=embed_model,\n\t\t)\n\troot_node = TextNode(\n\t\ttext=\"root node for the instruments.\",\n\t\tid_=INSTRUMENT_ROOT_NODE_NAME\n\t)\n\tnodes = [root_node]\n\tvector_index = VectorStoreIndex(\n\t\tnodes=nodes,\n\t\tembed_model=embed_model,\n\t)\n\n\treturn cls(\n\t\tvector_index=vector_index,\n\t\tpersist_dir=persist_dir,\n\t\tembed_model=embed_model,\n\t)\n</code></pre>"},{"location":"code_docs/func_modules/instrument/store/instrument_store/#labridge.func_modules.instrument.store.instrument_store.InstrumentStorage.from_storage","title":"<code>labridge.func_modules.instrument.store.instrument_store.InstrumentStorage.from_storage(persist_dir, embed_model)</code>  <code>classmethod</code>","text":"<p>Construct from an existing storage.</p> PARAMETER DESCRIPTION <code>persist_dir</code> <p>The persis_dir of an existing InstrumentStorage.</p> <p> TYPE: <code>str</code> </p> <code>embed_model</code> <p>The used embedding model.</p> <p> TYPE: <code>BaseEmbedding</code> </p> RETURNS DESCRIPTION <code>InstrumentStorage</code> <p>The loaded storage.</p> Source code in <code>labridge\\func_modules\\instrument\\store\\instrument_store.py</code> <pre><code>@classmethod\ndef from_storage(\n\tcls,\n\tpersist_dir: str,\n\tembed_model: BaseEmbedding,\n):\n\tr\"\"\"\n\tConstruct from an existing storage.\n\n\tArgs:\n\t\tpersist_dir (str): The persis_dir of an existing InstrumentStorage.\n\t\tembed_model (BaseEmbedding): The used embedding model.\n\n\tReturns:\n\t\tInstrumentStorage: The loaded storage.\n\t\"\"\"\n\tvector_storage_context = StorageContext.from_defaults(persist_dir=persist_dir)\n\tvector_index = load_index_from_storage(\n\t\tstorage_context=vector_storage_context,\n\t\tindex_id=INSTRUMENT_VECTOR_INDEX_ID,\n\t\tembed_model=embed_model,\n\t)\n\treturn cls(\n\t\tvector_index=vector_index,\n\t\tpersist_dir=persist_dir,\n\t)\n</code></pre>"},{"location":"code_docs/func_modules/instrument/store/instrument_store/#labridge.func_modules.instrument.store.instrument_store.InstrumentStorage.get_all_instruments","title":"<code>labridge.func_modules.instrument.store.instrument_store.InstrumentStorage.get_all_instruments()</code>","text":"<p>Get all instrument ids.</p> RETURNS DESCRIPTION <code>List[str]</code> <p>List[str]: All instrument ids.</p> Source code in <code>labridge\\func_modules\\instrument\\store\\instrument_store.py</code> <pre><code>def get_all_instruments(self) -&gt; List[str]:\n\tr\"\"\"\n\tGet all instrument ids.\n\n\tReturns:\n\t\tList[str]: All instrument ids.\n\t\"\"\"\n\troot_node = self._get_node(node_id=INSTRUMENT_ROOT_NODE_NAME)\n\tinstrument_list = root_node.child_nodes or []\n\tinstrument_ids = [ins.node_id for ins in instrument_list]\n\treturn instrument_ids\n</code></pre>"},{"location":"code_docs/func_modules/instrument/store/instrument_store/#labridge.func_modules.instrument.store.instrument_store.InstrumentStorage.get_nodes","title":"<code>labridge.func_modules.instrument.store.instrument_store.InstrumentStorage.get_nodes(node_ids)</code>","text":"<p>Get the nodes according to node_ids.</p> PARAMETER DESCRIPTION <code>node_ids</code> <p>The node ids.</p> <p> TYPE: <code>List[str]</code> </p> RETURNS DESCRIPTION <code>List[BaseNode]</code> <p>List[BaseNode]: The corresponding nodes in the vector index.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If any node_id does not exist in the vector index.</p> Source code in <code>labridge\\func_modules\\instrument\\store\\instrument_store.py</code> <pre><code>def get_nodes(self, node_ids: List[str]) -&gt; List[BaseNode]:\n\tr\"\"\"\n\tGet the nodes according to node_ids.\n\n\tArgs:\n\t\tnode_ids (List[str]): The node ids.\n\n\tReturns:\n\t\tList[BaseNode]: The corresponding nodes in the vector index.\n\n\tRaises:\n\t\tValueError: If any node_id does not exist in the vector index.\n\t\"\"\"\n\treturn self.vector_index.docstore.get_nodes(node_ids=node_ids)\n</code></pre>"},{"location":"code_docs/func_modules/instrument/store/instrument_store/#labridge.func_modules.instrument.store.instrument_store.InstrumentStorage.persist","title":"<code>labridge.func_modules.instrument.store.instrument_store.InstrumentStorage.persist(persist_dir=None)</code>","text":"<p>Save the storage.</p> Source code in <code>labridge\\func_modules\\instrument\\store\\instrument_store.py</code> <pre><code>def persist(self, persist_dir: str = None):\n\tr\"\"\" Save the storage. \"\"\"\n\tpersist_dir = persist_dir or self.persist_dir\n\tfs = fsspec.filesystem(\"file\")\n\tif not fs.exists(persist_dir):\n\t\tfs.makedirs(persist_dir)\n\tself.vector_index.storage_context.persist(persist_dir=persist_dir)\n</code></pre>"},{"location":"code_docs/func_modules/instrument/store/instrument_store/#labridge.func_modules.instrument.store.instrument_store.InstrumentStorage.update_instrument_doc","title":"<code>labridge.func_modules.instrument.store.instrument_store.InstrumentStorage.update_instrument_doc(instrument_id, instrument_doc_name, new_doc_path)</code>","text":"<p>Update an instrument document with a new document.</p> PARAMETER DESCRIPTION <code>instrument_id</code> <p>The instrument name.</p> <p> TYPE: <code>str</code> </p> <code>instrument_doc_name</code> <p>The old instrument document name.</p> <p> TYPE: <code>str</code> </p> <code>new_doc_path</code> <p>The path of the new document.</p> <p> TYPE: <code>str</code> </p> Source code in <code>labridge\\func_modules\\instrument\\store\\instrument_store.py</code> <pre><code>def update_instrument_doc(\n\tself,\n\tinstrument_id: str,\n\tinstrument_doc_name: str,\n\tnew_doc_path: str,\n):\n\tr\"\"\"\n\tUpdate an instrument document with a new document.\n\n\tArgs:\n\t\tinstrument_id (str): The instrument name.\n\t\tinstrument_doc_name (str): The old instrument document name.\n\t\tnew_doc_path (str): The path of the new document.\n\t\"\"\"\n\told_doc_path = Path(DEFAULT_INSTRUMENT_WAREHOUSE_DIR) / instrument_doc_name\n\told_doc_path = str(old_doc_path)\n\n\tself.delete_instrument_doc(\n\t\tinstrument_id=instrument_id,\n\t\tdoc_rel_path=old_doc_path,\n\t)\n\tself.add_instrument_doc(\n\t\tinstrument_id=instrument_id,\n\t\tdoc_path=new_doc_path,\n\t)\n</code></pre>"},{"location":"code_docs/func_modules/instrument/store/instrument_store/#labridge.func_modules.instrument.store.instrument_store.instrument_get_file_metadata","title":"<code>labridge.func_modules.instrument.store.instrument_store.instrument_get_file_metadata(file_path)</code>","text":"<p>Get the metadata of instrument doc nodes. This function will be used in the <code>SimpleDirectoryReader</code>.</p> PARAMETER DESCRIPTION <code>file_path</code> <p>The file path of a instrument document.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Dict[str, Any]</code> <p>Dict[str, Any]: These metadata will be recorded in each doc node:</p> <ul> <li>the path relative to the project root.</li> <li>the instrument id.</li> </ul> Source code in <code>labridge\\func_modules\\instrument\\store\\instrument_store.py</code> <pre><code>def instrument_get_file_metadata(file_path: str) -&gt; Dict[str, Any]:\n\tr\"\"\"\n\tGet the metadata of instrument doc nodes.\n\tThis function will be used in the `SimpleDirectoryReader`.\n\n\tArgs:\n\t\tfile_path (str): The file path of a instrument document.\n\n\tReturns:\n\t\tDict[str, Any]:\n\t\t\tThese metadata will be recorded in each doc node:\n\n\t\t\t- the path relative to the project root.\n\t\t\t- the instrument id.\n\t\"\"\"\n\troot = Path(__file__)\n\tfor i in range(5):\n\t\troot = root.parent\n\n\trel_path = Path(file_path).relative_to(root)\n\tinstrument_name = Path(file_path).parts[-2]\n\tmetadata = {\n\t\tINSTRUMENT_FILE_PATH_KEY: str(rel_path),\n\t\tINSTRUMENT_NAME_KEY: instrument_name\n\t}\n\treturn metadata\n</code></pre>"},{"location":"code_docs/func_modules/memory/base/","title":"Base","text":""},{"location":"code_docs/func_modules/memory/base/#labridge.func_modules.memory.base","title":"<code>labridge.func_modules.memory.base</code>","text":""},{"location":"code_docs/func_modules/memory/base/#labridge.func_modules.memory.base.LogBaseRetriever","title":"<code>labridge.func_modules.memory.base.LogBaseRetriever</code>","text":"<p>               Bases: <code>object</code></p> <p>This is the base class for log-type information retriever, such as chat history and experiment log.</p> <p>The attributes <code>memory</code> and <code>memory_vector_retriever</code> should be specified in the subclass, and they will be updated in the method <code>retrieve</code>.</p> PARAMETER DESCRIPTION <code>embed_model</code> <p>The used embedding model.</p> <p> TYPE: <code>BaseEmbedding</code> </p> <code>final_use_context</code> <p>Whether to use the context nodes of the retrieved nodes as the final results.</p> <p> TYPE: <code>bool</code> </p> <code>relevant_top_k</code> <p>The top-k relevant retrieved nodes will be used.</p> <p> TYPE: <code>int</code> </p> Note <p>The docstring of the Method <code>retrieve</code> will be used as the tool description of the corresponding retriever tool.</p> Source code in <code>labridge\\func_modules\\memory\\base.py</code> <pre><code>class LogBaseRetriever(object):\n\tr\"\"\"\n\tThis is the base class for log-type information retriever, such as chat history and experiment log.\n\n\tThe attributes `memory` and `memory_vector_retriever` should be specified in the subclass,\n\tand they will be updated in the method `retrieve`.\n\n\tArgs:\n\t\tembed_model (BaseEmbedding): The used embedding model.\n\t\tfinal_use_context (bool): Whether to use the context nodes of the retrieved nodes as the final results.\n\t\trelevant_top_k (int): The top-k relevant retrieved nodes will be used.\n\n\tNote:\n\t\tThe docstring of the Method `retrieve` will be used as the tool description of the corresponding\n\t\tretriever tool.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tembed_model: BaseEmbedding,\n\t\tfinal_use_context: bool,\n\t\trelevant_top_k: int,\n\t):\n\t\tself.memory = None\n\t\tself.memory_vector_retriever = None\n\t\tself.embed_model = embed_model or Settings.embed_model\n\t\tself.final_use_context = final_use_context\n\t\tself.relevant_top_k = relevant_top_k\n\n\tdef _parse_date(self, start_date_str: str, end_date_str: str) -&gt; List[str]:\n\t\tr\"\"\"\n\t\tGet the strings of dates that between the start date and the end date (including them).\n\n\t\tArgs:\n\t\t\tstart_date_str (str): The string of the start date in a specific format, specified in `common.utils.time`.\n\t\t\tend_date_str (str): The string of the end date.\n\n\t\tReturns:\n\t\t\"\"\"\n\t\treturn parse_date_list(\n\t\t\tstart_date_str=start_date_str,\n\t\t\tend_date_str=end_date_str,\n\t\t)\n\n\t@abstractmethod\n\tdef get_memory_vector_retriever(self) -&gt; VectorIndexRetriever:\n\t\tr\"\"\" Get the vector index retriever from the memory \"\"\"\n\n\t@abstractmethod\n\tdef get_memory_vector_index(self) -&gt; VectorStoreIndex:\n\t\tr\"\"\" Get the vector index \"\"\"\n\n\tdef get_date_filter(self, date_list: List[str]) -&gt; MetadataFilter:\n\t\tr\"\"\"\n\t\tReturn the MetadataFilter that filters nodes with dates in the date_list.\n\n\t\tArgs:\n\t\t\tdate_list (List[str]): The candidate date strings.\n\n\t\tReturns:\n\t\t\tMetadataFilter: The date filter.\n\t\t\"\"\"\n\t\tdate_filter = MetadataFilter(\n\t\t\tkey=LOG_DATE_NAME,\n\t\t\tvalue=date_list,\n\t\t\toperator=FilterOperator.ANY,\n\t\t)\n\t\treturn date_filter\n\n\tdef _log_node_filter(self) -&gt; MetadataFilter:\n\t\tr\"\"\"\n\t\tReturn the filter that filters `LOG_NODE_TYPE` nodes.\n\n\t\tReturns:\n\t\t\tThe node_type filter.\n\t\t\"\"\"\n\t\tlog_type_filter = MetadataFilter(\n\t\t\tkey=MEMORY_NODE_TYPE_NAME,\n\t\t\tvalue=LOG_NODE_TYPE,\n\t\t\toperator=FilterOperator.EQ,\n\t\t)\n\t\treturn log_type_filter\n\n\tdef sort_retrieved_nodes(\n\t\tself,\n\t\tmemory_nodes: List[NodeWithScore],\n\t\tdescending: bool = False,\n\t) -&gt; List[NodeWithScore]:\n\t\tr\"\"\"\n\t\tSort the retrieved nodes according datetime.\n\n\t\tArgs:\n\t\t\tmemory_nodes (List[NodeWithScore]): The retrieved nodes.\n\t\t\tdescending (bool): Sort in descending order. Defaults to False.\n\n\t\tReturns:\n\t\t\tList[NodeWithScore]: The sorted nodes.\n\t\t\"\"\"\n\t\tif len(memory_nodes) &lt; 1:\n\t\t\treturn []\n\t\tnodes_datetime = []\n\t\tfor node in memory_nodes:\n\t\t\tnode_date_str = node.node.metadata[LOG_DATE_NAME][0]\n\t\t\tnode_time_str = node.node.metadata[LOG_TIME_NAME][0]\n\t\t\tnodes_datetime.append(str_to_datetime(date_str=node_date_str, time_str=node_time_str))\n\n\t\tsorted_items = sorted(zip(memory_nodes, nodes_datetime), key=lambda x: x[1], reverse=descending)\n\t\tsorted_nodes, sorted_datetime = zip(*sorted_items)\n\t\treturn sorted_nodes\n\n\tdef _add_context(self, content_nodes: List[NodeWithScore]) -&gt; List[NodeWithScore]:\n\t\tr\"\"\"\n\t\tAdd the 1-hop context nodes of each content node and keep the QA time order.\n\t\tOnly the context nodes whose date is the same as the retrieved node will be added.\n\n\t\tArgs:\n\t\t\tcontent_nodes (List[NodeWithScore]): The retrieved nodes.\n\n\t\tReturns:\n\t\t\tList[NodeWithScore]: The final nodes including the context nodes.\n\t\t\"\"\"\n\t\texisting_ids = [node.node.node_id for node in content_nodes]\n\t\tfinal_nodes = []\n\t\tvector_index = self.get_memory_vector_index()\n\t\tfor node in content_nodes:\n\t\t\t# print(node.get_content())\n\t\t\tnode_date = node.node.metadata[LOG_DATE_NAME]\n\t\t\tprev_node_info = node.node.prev_node\n\t\t\tnext_node_info = node.node.next_node\n\t\t\tif prev_node_info is not None:\n\t\t\t\tprev_id = prev_node_info.node_id\n\t\t\t\tprev_node = vector_index.docstore.get_node(prev_id)\n\t\t\t\tif prev_id not in existing_ids and prev_node.metadata[LOG_DATE_NAME] == node_date:\n\t\t\t\t\texisting_ids.append(prev_id)\n\t\t\t\t\tfinal_nodes.append(NodeWithScore(node=prev_node))\n\n\t\t\tfinal_nodes.append(node)\n\n\t\t\tif next_node_info is not None:\n\t\t\t\tnext_id = next_node_info.node_id\n\t\t\t\tnext_node = vector_index.docstore.get_node(next_id)\n\t\t\t\tif next_id not in existing_ids and next_node.metadata[LOG_DATE_NAME] == node_date:\n\t\t\t\t\texisting_ids.append(next_id)\n\t\t\t\t\tfinal_nodes.append(NodeWithScore(node=next_node))\n\t\tfinal_nodes = self.sort_retrieved_nodes(memory_nodes=final_nodes)\n\t\treturn final_nodes\n\n\t@dispatcher.span\n\t@abstractmethod\n\tdef retrieve(\n\t\tself,\n\t\titem_to_be_retrieved: str,\n\t\tmemory_id: str,\n\t\tstart_date: str = None,\n\t\tend_date: str = None,\n\t\t**kwargs: Any,\n\t) -&gt; List[NodeWithScore]:\n\t\tr\"\"\"\n\t\tThe docstring of this Method will be used as the tool description of the corresponding retriever tool.\n\t\t\"\"\"\n\n\t@dispatcher.span\n\t@abstractmethod\n\tasync def aretrieve(\n\t\tself,\n\t\titem_to_be_retrieved: str,\n\t\tmemory_id: str,\n\t\tstart_date: str = None,\n\t\tend_date: str = None,\n\t\t**kwargs: Any,\n\t) -&gt; List[NodeWithScore]:\n\t\tr\"\"\"\n\t\tThe docstring of this Method will be used as the tool description of the corresponding retriever tool.\n\t\t\"\"\"\n</code></pre>"},{"location":"code_docs/func_modules/memory/base/#labridge.func_modules.memory.base.LogBaseRetriever.aretrieve","title":"<code>labridge.func_modules.memory.base.LogBaseRetriever.aretrieve(item_to_be_retrieved, memory_id, start_date=None, end_date=None, **kwargs)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>The docstring of this Method will be used as the tool description of the corresponding retriever tool.</p> Source code in <code>labridge\\func_modules\\memory\\base.py</code> <pre><code>@dispatcher.span\n@abstractmethod\nasync def aretrieve(\n\tself,\n\titem_to_be_retrieved: str,\n\tmemory_id: str,\n\tstart_date: str = None,\n\tend_date: str = None,\n\t**kwargs: Any,\n) -&gt; List[NodeWithScore]:\n\tr\"\"\"\n\tThe docstring of this Method will be used as the tool description of the corresponding retriever tool.\n\t\"\"\"\n</code></pre>"},{"location":"code_docs/func_modules/memory/base/#labridge.func_modules.memory.base.LogBaseRetriever.get_date_filter","title":"<code>labridge.func_modules.memory.base.LogBaseRetriever.get_date_filter(date_list)</code>","text":"<p>Return the MetadataFilter that filters nodes with dates in the date_list.</p> PARAMETER DESCRIPTION <code>date_list</code> <p>The candidate date strings.</p> <p> TYPE: <code>List[str]</code> </p> RETURNS DESCRIPTION <code>MetadataFilter</code> <p>The date filter.</p> <p> TYPE: <code>MetadataFilter</code> </p> Source code in <code>labridge\\func_modules\\memory\\base.py</code> <pre><code>def get_date_filter(self, date_list: List[str]) -&gt; MetadataFilter:\n\tr\"\"\"\n\tReturn the MetadataFilter that filters nodes with dates in the date_list.\n\n\tArgs:\n\t\tdate_list (List[str]): The candidate date strings.\n\n\tReturns:\n\t\tMetadataFilter: The date filter.\n\t\"\"\"\n\tdate_filter = MetadataFilter(\n\t\tkey=LOG_DATE_NAME,\n\t\tvalue=date_list,\n\t\toperator=FilterOperator.ANY,\n\t)\n\treturn date_filter\n</code></pre>"},{"location":"code_docs/func_modules/memory/base/#labridge.func_modules.memory.base.LogBaseRetriever.get_memory_vector_index","title":"<code>labridge.func_modules.memory.base.LogBaseRetriever.get_memory_vector_index()</code>  <code>abstractmethod</code>","text":"<p>Get the vector index</p> Source code in <code>labridge\\func_modules\\memory\\base.py</code> <pre><code>@abstractmethod\ndef get_memory_vector_index(self) -&gt; VectorStoreIndex:\n\tr\"\"\" Get the vector index \"\"\"\n</code></pre>"},{"location":"code_docs/func_modules/memory/base/#labridge.func_modules.memory.base.LogBaseRetriever.get_memory_vector_retriever","title":"<code>labridge.func_modules.memory.base.LogBaseRetriever.get_memory_vector_retriever()</code>  <code>abstractmethod</code>","text":"<p>Get the vector index retriever from the memory</p> Source code in <code>labridge\\func_modules\\memory\\base.py</code> <pre><code>@abstractmethod\ndef get_memory_vector_retriever(self) -&gt; VectorIndexRetriever:\n\tr\"\"\" Get the vector index retriever from the memory \"\"\"\n</code></pre>"},{"location":"code_docs/func_modules/memory/base/#labridge.func_modules.memory.base.LogBaseRetriever.retrieve","title":"<code>labridge.func_modules.memory.base.LogBaseRetriever.retrieve(item_to_be_retrieved, memory_id, start_date=None, end_date=None, **kwargs)</code>  <code>abstractmethod</code>","text":"<p>The docstring of this Method will be used as the tool description of the corresponding retriever tool.</p> Source code in <code>labridge\\func_modules\\memory\\base.py</code> <pre><code>@dispatcher.span\n@abstractmethod\ndef retrieve(\n\tself,\n\titem_to_be_retrieved: str,\n\tmemory_id: str,\n\tstart_date: str = None,\n\tend_date: str = None,\n\t**kwargs: Any,\n) -&gt; List[NodeWithScore]:\n\tr\"\"\"\n\tThe docstring of this Method will be used as the tool description of the corresponding retriever tool.\n\t\"\"\"\n</code></pre>"},{"location":"code_docs/func_modules/memory/base/#labridge.func_modules.memory.base.LogBaseRetriever.sort_retrieved_nodes","title":"<code>labridge.func_modules.memory.base.LogBaseRetriever.sort_retrieved_nodes(memory_nodes, descending=False)</code>","text":"<p>Sort the retrieved nodes according datetime.</p> PARAMETER DESCRIPTION <code>memory_nodes</code> <p>The retrieved nodes.</p> <p> TYPE: <code>List[NodeWithScore]</code> </p> <code>descending</code> <p>Sort in descending order. Defaults to False.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>List[NodeWithScore]</code> <p>List[NodeWithScore]: The sorted nodes.</p> Source code in <code>labridge\\func_modules\\memory\\base.py</code> <pre><code>def sort_retrieved_nodes(\n\tself,\n\tmemory_nodes: List[NodeWithScore],\n\tdescending: bool = False,\n) -&gt; List[NodeWithScore]:\n\tr\"\"\"\n\tSort the retrieved nodes according datetime.\n\n\tArgs:\n\t\tmemory_nodes (List[NodeWithScore]): The retrieved nodes.\n\t\tdescending (bool): Sort in descending order. Defaults to False.\n\n\tReturns:\n\t\tList[NodeWithScore]: The sorted nodes.\n\t\"\"\"\n\tif len(memory_nodes) &lt; 1:\n\t\treturn []\n\tnodes_datetime = []\n\tfor node in memory_nodes:\n\t\tnode_date_str = node.node.metadata[LOG_DATE_NAME][0]\n\t\tnode_time_str = node.node.metadata[LOG_TIME_NAME][0]\n\t\tnodes_datetime.append(str_to_datetime(date_str=node_date_str, time_str=node_time_str))\n\n\tsorted_items = sorted(zip(memory_nodes, nodes_datetime), key=lambda x: x[1], reverse=descending)\n\tsorted_nodes, sorted_datetime = zip(*sorted_items)\n\treturn sorted_nodes\n</code></pre>"},{"location":"code_docs/func_modules/memory/chat/chat_memory/","title":"Chat memory","text":""},{"location":"code_docs/func_modules/memory/chat/chat_memory/#labridge.func_modules.memory.chat.chat_memory","title":"<code>labridge.func_modules.memory.chat.chat_memory</code>","text":""},{"location":"code_docs/func_modules/memory/chat/chat_memory/#labridge.func_modules.memory.chat.chat_memory.ChatVectorMemory","title":"<code>labridge.func_modules.memory.chat.chat_memory.ChatVectorMemory</code>","text":"<p>               Bases: <code>VectorMemory</code></p> <p>This class is used to store the chat history, involving the logs of called tools in chat.</p> PARAMETER DESCRIPTION <code>vector_index</code> <p>The vector database.</p> <p> TYPE: <code>VectorStoreIndex</code> </p> <code>retriever_kwargs</code> <p>Not used. Refer to <code>ChatMemoryRetriever</code>.</p> <p> TYPE: <code>dict</code> </p> <code>persist_dir</code> <p>The save directory.</p> <p> TYPE: <code>str</code> </p> Note <p>In the vector index, the metadata <code>LOG_DATE_NAME</code> and <code>LOG_TIME_NAME</code> are recorded for each chat log node, they are useful for filtering in retrieving. The metadata <code>date</code> and <code>time</code> is recorded in a list format for the convenience of metadata filtering. For example: ['2024-08-10'], ['09:05:03'].</p> Source code in <code>labridge\\func_modules\\memory\\chat\\chat_memory.py</code> <pre><code>class ChatVectorMemory(VectorMemory):\n\tr\"\"\"\n\tThis class is used to store the chat history, involving the logs of called tools in chat.\n\n\tArgs:\n\t\tvector_index (VectorStoreIndex): The vector database.\n\t\tretriever_kwargs (dict): Not used. Refer to `ChatMemoryRetriever`.\n\t\tpersist_dir (str): The save directory.\n\n\tNote:\n\t\tIn the vector index, the metadata `LOG_DATE_NAME` and `LOG_TIME_NAME` are recorded for each chat log node, they are\n\t\tuseful for filtering in retrieving.\n\t\tThe metadata `date` and `time` is recorded in a list format for the convenience of metadata filtering.\n\t\tFor example: ['2024-08-10'], ['09:05:03'].\n\t\"\"\"\n\tpersist_dir: str = Field(\n\t\tdefault=\"\",\n\t\tdescription=\"The persist dir of the memory index relative to the root.\",\n\t)\n\tdef __init__(\n\t\tself,\n\t\tvector_index: VectorStoreIndex,\n\t\tretriever_kwargs: dict,\n\t\tpersist_dir: str\n\t):\n\t\tsuper().__init__(vector_index=vector_index, retriever_kwargs=retriever_kwargs)\n\t\tself.vector_index.set_index_id(CHAT_MEMORY_VECTOR_INDEX_ID)\n\t\tself.persist_dir = persist_dir\n\n\t@classmethod\n\tdef from_storage(\n\t\tcls,\n\t\tpersist_dir: str,\n\t\tembed_model: BaseEmbedding,\n\t\tretriever_kwargs: dict,\n\t):\n\t\tr\"\"\"\n\t\tLoad from an existing storage.\n\n\t\tArgs:\n\t\t\tpersist_dir (str): The save path of the storage.\n\t\t\tembed_model (BaseEmbedding): The used embedding model.\n\t\t\tretriever_kwargs (dict): Not used.\n\n\t\tReturns:\n\t\t\tChatVectorMemory\n\t\t\"\"\"\n\t\tvector_storage_context = StorageContext.from_defaults(persist_dir=persist_dir)\n\t\tvector_index = load_index_from_storage(\n\t\t\tstorage_context=vector_storage_context,\n\t\t\tindex_id=CHAT_MEMORY_VECTOR_INDEX_ID,\n\t\t\tembed_model=embed_model,\n\t\t)\n\t\treturn cls(\n\t\t\tvector_index=vector_index,\n\t\t\tretriever_kwargs=retriever_kwargs,\n\t\t\tpersist_dir=persist_dir,\n\t\t)\n\n\t@property\n\tdef memory_id(self) -&gt; str:\n\t\tr\"\"\"\n\t\tThe memory_id is either a user_id or a chat_group_id.\n\n\t\tReturns:\n\t\t\tstr: The memory id of this ChatMemory.\n\t\t\"\"\"\n\t\troot = Path(__file__)\n\t\tfor idx in range(5):\n\t\t\troot = root.parent\n\n\t\tmem_id = Path(self.persist_dir).relative_to(root / CHAT_MEMORY_PERSIST_DIR)\n\t\treturn str(mem_id)\n\n\tdef is_chat_group_memory(self) -&gt; bool:\n\t\tr\"\"\"\n\t\tWhether this class records the history of a chat group or not.\n\t\t\"\"\"\n\t\ttry:\n\t\t\tself.vector_index.docstore.get_node(CHAT_GROUP_MEMBERS_NODE_NAME)\n\t\t\treturn True\n\t\texcept ValueError as e:\n\t\t\treturn False\n\n\t@classmethod\n\tdef from_memory_id(\n\t\tcls,\n\t\tmemory_id: str,\n\t\tembed_model: BaseEmbedding,\n\t\tretriever_kwargs: dict,\n\t\tdescription: str = None,\n\t\tgroup_members: Optional[List[str]] = None,\n\t):\n\t\tr\"\"\"\n\t\tConstruct from the memory_id.\n\t\tIf the corresponding persist_dir of the memory_id does not exist, a new ChatMemory will be created.\n\n\t\tArgs:\n\t\t\tmemory_id (str): a user_id of a lab member or a chat_group_id.\n\t\t\tembed_model (BaseEmbedding): The used embedding model.\n\t\t\tretriever_kwargs (dict): Not used.\n\t\t\tdescription (str): The description of this ChatMemory.\n\t\t\tgroup_members (Optional[List[str]]): If the memory_id is a chat_group_id, the group members must be given.\n\n\t\tReturns:\n\t\t\tChatVectorMemory\n\t\t\"\"\"\n\t\taccount_manager = AccountManager()\n\n\t\tif memory_id not in account_manager.get_users() + account_manager.get_chat_groups():\n\t\t\traise ValueError(f\"Invalid user id or chat group id: {memory_id}.\")\n\n\t\troot = Path(__file__)\n\t\tfor idx in range(5):\n\t\t\troot = root.parent\n\n\t\tpersist_dir = str(root / f\"{CHAT_MEMORY_PERSIST_DIR}/{memory_id}\")\n\t\tfs = fsspec.filesystem(\"file\")\n\t\tif fs.exists(persist_dir):\n\t\t\treturn cls.from_storage(\n\t\t\t\tpersist_dir=persist_dir,\n\t\t\t\tembed_model=embed_model,\n\t\t\t\tretriever_kwargs=retriever_kwargs,\n\t\t\t)\n\n\t\tdate, h_m_s = get_time()\n\t\tinit_msg = ChatMessage(\n\t\t\trole=MessageRole.SYSTEM,\n\t\t\tcontent=f\"This Memory Index is used for storing the chat history related to the USER/CHAT GROUP: {memory_id}\\n\"\n\t\t\t\t\tf\"Description: {description}.\",\n\t\t\tadditional_kwargs={\n\t\t\t\tLOG_DATE_NAME: date,\n\t\t\t\tLOG_TIME_NAME: h_m_s,\n\t\t\t},\n\t\t)\n\t\ttext_node = _get_starter_node_for_new_batch()\n\t\ttext_node.id_ = MEMORY_FIRST_NODE_NAME\n\t\ttext_node.text += init_msg.content\n\t\ttext_node.metadata[LOG_DATE_NAME] = [init_msg.additional_kwargs[LOG_DATE_NAME],]\n\t\ttext_node.metadata[LOG_TIME_NAME] = [init_msg.additional_kwargs[LOG_TIME_NAME],]\n\n\t\tlast_id_info_node = TextNode(text=text_node.node_id, id_=MEMORY_LAST_NODE_ID_NAME)\n\n\t\tnodes = [text_node, last_id_info_node]\n\t\tif group_members is not None:\n\t\t\tfor user_id in group_members:\n\t\t\t\ttry:\n\t\t\t\t\taccount_manager.check_valid_user(user_id=user_id)\n\t\t\t\texcept ValueError as e:\n\t\t\t\t\treturn f\"Error: {e!s}\"\n\t\t\tmembers_node = TextNode(text=\",\".join(group_members))\n\t\t\tmembers_node.id_ = CHAT_GROUP_MEMBERS_NODE_NAME\n\t\t\tnodes.append(members_node)\n\n\t\tvector_index = VectorStoreIndex(\n\t\t\tnodes=nodes,\n\t\t\tembed_model=embed_model,\n\t\t)\n\t\treturn cls(\n\t\t\tvector_index=vector_index,\n\t\t\tpersist_dir=persist_dir,\n\t\t\tretriever_kwargs=retriever_kwargs,\n\t\t)\n\n\tdef update_node(self, node_id: str, node: BaseNode):\n\t\tr\"\"\"\n\t\tUpdate a node in the vector index.\n\n\t\tArgs:\n\t\t\tnode_id (str): The node_id of the node to be updated.\n\t\t\tnode (BaseNode): The new node.\n\t\t\"\"\"\n\t\tself.vector_index.delete_nodes([node_id])\n\t\tself.vector_index.insert_nodes([node])\n\n\tdef put(self, message: ChatMessage) -&gt; None:\n\t\t\"\"\"\n\t\tPut chat history.\n\n\t\tMetadata: `LOG_DATE_NAME`: [date, ]; `LOG_TIME_NAME`: [time, ]\n\n\t\tThe node_id of the Last Text Node is stored in the node `MEMORY_LAST_NODE_ID_NAME`\n\t\tEvery time a New Text Node is put in, execute:\n\n\t\t- Last Text Node -&gt; next_node = New Text Node\n\t\t- New Text Node -&gt; prev_node = Last Text Node\n\t\t- let New Text Node be the Last Text Node\n\n\t\tArgs:\n\t\t\tmessage (ChatMessage): a chat message.\n\t\t\"\"\"\n\t\tif not self.batch_by_user_message or message.role in [MessageRole.USER, MessageRole.SYSTEM, ]:\n\t\t\t# if not batching by user message, commit to vector store immediately after adding\n\t\t\tself.cur_batch_textnode = _get_starter_node_for_new_batch()\n\t\t\t# add date and time\n\t\t\tself.cur_batch_textnode.metadata[LOG_DATE_NAME] = [message.additional_kwargs[LOG_DATE_NAME],]\n\t\t\tself.cur_batch_textnode.metadata[LOG_TIME_NAME] = [message.additional_kwargs[LOG_TIME_NAME],]\n\t\t\t# add previous and next relationships.\n\t\t\tlast_info_node = self.vector_index.docstore.get_node(MEMORY_LAST_NODE_ID_NAME)\n\t\t\tlast_node_id = last_info_node.text\n\t\t\tlast_node = self.vector_index.docstore.get_node(last_node_id)\n\t\t\tlast_node.relationships[NodeRelationship.NEXT] = RelatedNodeInfo(\n\t\t\t\tnode_id=self.cur_batch_textnode.node_id\n\t\t\t)\n\t\t\tself.cur_batch_textnode.relationships[NodeRelationship.PREVIOUS] = RelatedNodeInfo(\n\t\t\t\tnode_id=last_node.node_id\n\t\t\t)\n\t\t\t# update last node id\n\t\t\tlast_info_node.set_content(self.cur_batch_textnode.node_id)\n\t\t\tself.update_node(node_id=last_node_id, node=last_node)\n\t\t\tself.update_node(node_id=MEMORY_LAST_NODE_ID_NAME, node=last_info_node)\n\n\t\t# update current batch textnode\n\t\tsub_dict = _stringify_chat_message(message)\n\t\trole = sub_dict[\"role\"]\n\t\tcontent = sub_dict[\"content\"] or \"\"\n\t\tnew_msg = (\n\t\t\tf\"&gt;&gt;&gt; {role} message:\\n\"\n\t\t\tf\"{content.strip()}\\n\"\n\t\t)\n\t\tself.cur_batch_textnode.text += new_msg\n\t\t# self.cur_batch_textnode.metadata[\"sub_dicts\"].append(sub_dict)\n\t\tself._commit_node(override_last=True)\n\n\tdef persist(self, persist_dir: str = None):\n\t\tpersist_dir = persist_dir or self.persist_dir\n\t\tfs = fsspec.filesystem(\"file\")\n\t\tif not fs.exists(persist_dir):\n\t\t\tfs.makedirs(persist_dir)\n\t\tself.vector_index.storage_context.persist(persist_dir=persist_dir)\n</code></pre>"},{"location":"code_docs/func_modules/memory/chat/chat_memory/#labridge.func_modules.memory.chat.chat_memory.ChatVectorMemory.memory_id","title":"<code>labridge.func_modules.memory.chat.chat_memory.ChatVectorMemory.memory_id: str</code>  <code>property</code>","text":"<p>The memory_id is either a user_id or a chat_group_id.</p> RETURNS DESCRIPTION <code>str</code> <p>The memory id of this ChatMemory.</p> <p> TYPE: <code>str</code> </p>"},{"location":"code_docs/func_modules/memory/chat/chat_memory/#labridge.func_modules.memory.chat.chat_memory.ChatVectorMemory.from_memory_id","title":"<code>labridge.func_modules.memory.chat.chat_memory.ChatVectorMemory.from_memory_id(memory_id, embed_model, retriever_kwargs, description=None, group_members=None)</code>  <code>classmethod</code>","text":"<p>Construct from the memory_id. If the corresponding persist_dir of the memory_id does not exist, a new ChatMemory will be created.</p> PARAMETER DESCRIPTION <code>memory_id</code> <p>a user_id of a lab member or a chat_group_id.</p> <p> TYPE: <code>str</code> </p> <code>embed_model</code> <p>The used embedding model.</p> <p> TYPE: <code>BaseEmbedding</code> </p> <code>retriever_kwargs</code> <p>Not used.</p> <p> TYPE: <code>dict</code> </p> <code>description</code> <p>The description of this ChatMemory.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>group_members</code> <p>If the memory_id is a chat_group_id, the group members must be given.</p> <p> TYPE: <code>Optional[List[str]]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <p>ChatVectorMemory</p> Source code in <code>labridge\\func_modules\\memory\\chat\\chat_memory.py</code> <pre><code>@classmethod\ndef from_memory_id(\n\tcls,\n\tmemory_id: str,\n\tembed_model: BaseEmbedding,\n\tretriever_kwargs: dict,\n\tdescription: str = None,\n\tgroup_members: Optional[List[str]] = None,\n):\n\tr\"\"\"\n\tConstruct from the memory_id.\n\tIf the corresponding persist_dir of the memory_id does not exist, a new ChatMemory will be created.\n\n\tArgs:\n\t\tmemory_id (str): a user_id of a lab member or a chat_group_id.\n\t\tembed_model (BaseEmbedding): The used embedding model.\n\t\tretriever_kwargs (dict): Not used.\n\t\tdescription (str): The description of this ChatMemory.\n\t\tgroup_members (Optional[List[str]]): If the memory_id is a chat_group_id, the group members must be given.\n\n\tReturns:\n\t\tChatVectorMemory\n\t\"\"\"\n\taccount_manager = AccountManager()\n\n\tif memory_id not in account_manager.get_users() + account_manager.get_chat_groups():\n\t\traise ValueError(f\"Invalid user id or chat group id: {memory_id}.\")\n\n\troot = Path(__file__)\n\tfor idx in range(5):\n\t\troot = root.parent\n\n\tpersist_dir = str(root / f\"{CHAT_MEMORY_PERSIST_DIR}/{memory_id}\")\n\tfs = fsspec.filesystem(\"file\")\n\tif fs.exists(persist_dir):\n\t\treturn cls.from_storage(\n\t\t\tpersist_dir=persist_dir,\n\t\t\tembed_model=embed_model,\n\t\t\tretriever_kwargs=retriever_kwargs,\n\t\t)\n\n\tdate, h_m_s = get_time()\n\tinit_msg = ChatMessage(\n\t\trole=MessageRole.SYSTEM,\n\t\tcontent=f\"This Memory Index is used for storing the chat history related to the USER/CHAT GROUP: {memory_id}\\n\"\n\t\t\t\tf\"Description: {description}.\",\n\t\tadditional_kwargs={\n\t\t\tLOG_DATE_NAME: date,\n\t\t\tLOG_TIME_NAME: h_m_s,\n\t\t},\n\t)\n\ttext_node = _get_starter_node_for_new_batch()\n\ttext_node.id_ = MEMORY_FIRST_NODE_NAME\n\ttext_node.text += init_msg.content\n\ttext_node.metadata[LOG_DATE_NAME] = [init_msg.additional_kwargs[LOG_DATE_NAME],]\n\ttext_node.metadata[LOG_TIME_NAME] = [init_msg.additional_kwargs[LOG_TIME_NAME],]\n\n\tlast_id_info_node = TextNode(text=text_node.node_id, id_=MEMORY_LAST_NODE_ID_NAME)\n\n\tnodes = [text_node, last_id_info_node]\n\tif group_members is not None:\n\t\tfor user_id in group_members:\n\t\t\ttry:\n\t\t\t\taccount_manager.check_valid_user(user_id=user_id)\n\t\t\texcept ValueError as e:\n\t\t\t\treturn f\"Error: {e!s}\"\n\t\tmembers_node = TextNode(text=\",\".join(group_members))\n\t\tmembers_node.id_ = CHAT_GROUP_MEMBERS_NODE_NAME\n\t\tnodes.append(members_node)\n\n\tvector_index = VectorStoreIndex(\n\t\tnodes=nodes,\n\t\tembed_model=embed_model,\n\t)\n\treturn cls(\n\t\tvector_index=vector_index,\n\t\tpersist_dir=persist_dir,\n\t\tretriever_kwargs=retriever_kwargs,\n\t)\n</code></pre>"},{"location":"code_docs/func_modules/memory/chat/chat_memory/#labridge.func_modules.memory.chat.chat_memory.ChatVectorMemory.from_storage","title":"<code>labridge.func_modules.memory.chat.chat_memory.ChatVectorMemory.from_storage(persist_dir, embed_model, retriever_kwargs)</code>  <code>classmethod</code>","text":"<p>Load from an existing storage.</p> PARAMETER DESCRIPTION <code>persist_dir</code> <p>The save path of the storage.</p> <p> TYPE: <code>str</code> </p> <code>embed_model</code> <p>The used embedding model.</p> <p> TYPE: <code>BaseEmbedding</code> </p> <code>retriever_kwargs</code> <p>Not used.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <p>ChatVectorMemory</p> Source code in <code>labridge\\func_modules\\memory\\chat\\chat_memory.py</code> <pre><code>@classmethod\ndef from_storage(\n\tcls,\n\tpersist_dir: str,\n\tembed_model: BaseEmbedding,\n\tretriever_kwargs: dict,\n):\n\tr\"\"\"\n\tLoad from an existing storage.\n\n\tArgs:\n\t\tpersist_dir (str): The save path of the storage.\n\t\tembed_model (BaseEmbedding): The used embedding model.\n\t\tretriever_kwargs (dict): Not used.\n\n\tReturns:\n\t\tChatVectorMemory\n\t\"\"\"\n\tvector_storage_context = StorageContext.from_defaults(persist_dir=persist_dir)\n\tvector_index = load_index_from_storage(\n\t\tstorage_context=vector_storage_context,\n\t\tindex_id=CHAT_MEMORY_VECTOR_INDEX_ID,\n\t\tembed_model=embed_model,\n\t)\n\treturn cls(\n\t\tvector_index=vector_index,\n\t\tretriever_kwargs=retriever_kwargs,\n\t\tpersist_dir=persist_dir,\n\t)\n</code></pre>"},{"location":"code_docs/func_modules/memory/chat/chat_memory/#labridge.func_modules.memory.chat.chat_memory.ChatVectorMemory.is_chat_group_memory","title":"<code>labridge.func_modules.memory.chat.chat_memory.ChatVectorMemory.is_chat_group_memory()</code>","text":"<p>Whether this class records the history of a chat group or not.</p> Source code in <code>labridge\\func_modules\\memory\\chat\\chat_memory.py</code> <pre><code>def is_chat_group_memory(self) -&gt; bool:\n\tr\"\"\"\n\tWhether this class records the history of a chat group or not.\n\t\"\"\"\n\ttry:\n\t\tself.vector_index.docstore.get_node(CHAT_GROUP_MEMBERS_NODE_NAME)\n\t\treturn True\n\texcept ValueError as e:\n\t\treturn False\n</code></pre>"},{"location":"code_docs/func_modules/memory/chat/chat_memory/#labridge.func_modules.memory.chat.chat_memory.ChatVectorMemory.put","title":"<code>labridge.func_modules.memory.chat.chat_memory.ChatVectorMemory.put(message)</code>","text":"<p>Put chat history.</p> <p>Metadata: <code>LOG_DATE_NAME</code>: [date, ]; <code>LOG_TIME_NAME</code>: [time, ]</p> <p>The node_id of the Last Text Node is stored in the node <code>MEMORY_LAST_NODE_ID_NAME</code> Every time a New Text Node is put in, execute:</p> <ul> <li>Last Text Node -&gt; next_node = New Text Node</li> <li>New Text Node -&gt; prev_node = Last Text Node</li> <li>let New Text Node be the Last Text Node</li> </ul> PARAMETER DESCRIPTION <code>message</code> <p>a chat message.</p> <p> TYPE: <code>ChatMessage</code> </p> Source code in <code>labridge\\func_modules\\memory\\chat\\chat_memory.py</code> <pre><code>def put(self, message: ChatMessage) -&gt; None:\n\t\"\"\"\n\tPut chat history.\n\n\tMetadata: `LOG_DATE_NAME`: [date, ]; `LOG_TIME_NAME`: [time, ]\n\n\tThe node_id of the Last Text Node is stored in the node `MEMORY_LAST_NODE_ID_NAME`\n\tEvery time a New Text Node is put in, execute:\n\n\t- Last Text Node -&gt; next_node = New Text Node\n\t- New Text Node -&gt; prev_node = Last Text Node\n\t- let New Text Node be the Last Text Node\n\n\tArgs:\n\t\tmessage (ChatMessage): a chat message.\n\t\"\"\"\n\tif not self.batch_by_user_message or message.role in [MessageRole.USER, MessageRole.SYSTEM, ]:\n\t\t# if not batching by user message, commit to vector store immediately after adding\n\t\tself.cur_batch_textnode = _get_starter_node_for_new_batch()\n\t\t# add date and time\n\t\tself.cur_batch_textnode.metadata[LOG_DATE_NAME] = [message.additional_kwargs[LOG_DATE_NAME],]\n\t\tself.cur_batch_textnode.metadata[LOG_TIME_NAME] = [message.additional_kwargs[LOG_TIME_NAME],]\n\t\t# add previous and next relationships.\n\t\tlast_info_node = self.vector_index.docstore.get_node(MEMORY_LAST_NODE_ID_NAME)\n\t\tlast_node_id = last_info_node.text\n\t\tlast_node = self.vector_index.docstore.get_node(last_node_id)\n\t\tlast_node.relationships[NodeRelationship.NEXT] = RelatedNodeInfo(\n\t\t\tnode_id=self.cur_batch_textnode.node_id\n\t\t)\n\t\tself.cur_batch_textnode.relationships[NodeRelationship.PREVIOUS] = RelatedNodeInfo(\n\t\t\tnode_id=last_node.node_id\n\t\t)\n\t\t# update last node id\n\t\tlast_info_node.set_content(self.cur_batch_textnode.node_id)\n\t\tself.update_node(node_id=last_node_id, node=last_node)\n\t\tself.update_node(node_id=MEMORY_LAST_NODE_ID_NAME, node=last_info_node)\n\n\t# update current batch textnode\n\tsub_dict = _stringify_chat_message(message)\n\trole = sub_dict[\"role\"]\n\tcontent = sub_dict[\"content\"] or \"\"\n\tnew_msg = (\n\t\tf\"&gt;&gt;&gt; {role} message:\\n\"\n\t\tf\"{content.strip()}\\n\"\n\t)\n\tself.cur_batch_textnode.text += new_msg\n\t# self.cur_batch_textnode.metadata[\"sub_dicts\"].append(sub_dict)\n\tself._commit_node(override_last=True)\n</code></pre>"},{"location":"code_docs/func_modules/memory/chat/chat_memory/#labridge.func_modules.memory.chat.chat_memory.ChatVectorMemory.update_node","title":"<code>labridge.func_modules.memory.chat.chat_memory.ChatVectorMemory.update_node(node_id, node)</code>","text":"<p>Update a node in the vector index.</p> PARAMETER DESCRIPTION <code>node_id</code> <p>The node_id of the node to be updated.</p> <p> TYPE: <code>str</code> </p> <code>node</code> <p>The new node.</p> <p> TYPE: <code>BaseNode</code> </p> Source code in <code>labridge\\func_modules\\memory\\chat\\chat_memory.py</code> <pre><code>def update_node(self, node_id: str, node: BaseNode):\n\tr\"\"\"\n\tUpdate a node in the vector index.\n\n\tArgs:\n\t\tnode_id (str): The node_id of the node to be updated.\n\t\tnode (BaseNode): The new node.\n\t\"\"\"\n\tself.vector_index.delete_nodes([node_id])\n\tself.vector_index.insert_nodes([node])\n</code></pre>"},{"location":"code_docs/func_modules/memory/chat/chat_memory/#labridge.func_modules.memory.chat.chat_memory.update_chat_memory","title":"<code>labridge.func_modules.memory.chat.chat_memory.update_chat_memory(memory_id, chat_messages, embed_model=None)</code>","text":"<p>Update the user/chat_group specific chat memory.</p> PARAMETER DESCRIPTION <code>memory_id</code> <p>user_id or chat_group_id</p> <p> TYPE: <code>str</code> </p> <code>chat_messages</code> <p>New chat messages.</p> <p> TYPE: <code>List[ChatMessage]</code> </p> <code>embed_model</code> <p>The used embedding model.</p> <p> TYPE: <code>BaseEmbedding</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <p>None or an Error string.</p> Source code in <code>labridge\\func_modules\\memory\\chat\\chat_memory.py</code> <pre><code>def update_chat_memory(\n\tmemory_id: str,\n\tchat_messages: List[ChatMessage],\n\tembed_model: BaseEmbedding = None\n):\n\tr\"\"\"\n\tUpdate the user/chat_group specific chat memory.\n\n\tArgs:\n\t\tmemory_id (str): user_id or chat_group_id\n\t\tchat_messages (List[ChatMessage]): New chat messages.\n\t\tembed_model (BaseEmbedding): The used embedding model.\n\n\tReturns:\n\t\tNone or an Error string.\n\t\"\"\"\n\tchat_memory = ChatVectorMemory.from_memory_id(\n\t\tmemory_id=memory_id,\n\t\tembed_model=embed_model or Settings.embed_model,\n\t\tretriever_kwargs={},\n\t)\n\n\tif not isinstance(chat_memory, ChatVectorMemory):\n\t\treturn chat_memory\n\n\tfor msg in chat_messages:\n\t\tchat_memory.put(msg)\n\n\tchat_memory.persist()\n</code></pre>"},{"location":"code_docs/func_modules/memory/chat/retrieve/","title":"Retrieve","text":""},{"location":"code_docs/func_modules/memory/chat/retrieve/#labridge.func_modules.memory.chat.retrieve","title":"<code>labridge.func_modules.memory.chat.retrieve</code>","text":""},{"location":"code_docs/func_modules/memory/chat/retrieve/#labridge.func_modules.memory.chat.retrieve.ChatMemoryRetriever","title":"<code>labridge.func_modules.memory.chat.retrieve.ChatMemoryRetriever</code>","text":"<p>               Bases: <code>LogBaseRetriever</code></p> <p>This is a retriever that retrieve in the permanent chat history of a user or a chat group. You can use this tool when you want to obtain the historical interaction between you and the user.</p> PARAMETER DESCRIPTION <code>embed_model</code> <p>The used embedding model, if not specified, will use the <code>Settings.embed_model</code></p> <p> TYPE: <code>BaseEmbedding</code> DEFAULT: <code>None</code> </p> <code>final_use_context</code> <p>Whether to add the context nodes of the retrieved log nodes to the final results. Defaults to True.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>relevant_top_k</code> <p>The top-k relevant nodes in retrieving will be used as the retrieved results. Defaults to <code>CHAT_MEMORY_RELEVANT_TOP_K</code>.</p> <p> TYPE: <code>int</code> DEFAULT: <code>CHAT_MEMORY_RELEVANT_TOP_K</code> </p> Source code in <code>labridge\\func_modules\\memory\\chat\\retrieve.py</code> <pre><code>class ChatMemoryRetriever(LogBaseRetriever):\n\tr\"\"\"\n\tThis is a retriever that retrieve in the permanent chat history of a user or a chat group.\n\tYou can use this tool when you want to obtain the historical interaction between you and the user.\n\n\tArgs:\n\t\tembed_model (BaseEmbedding): The used embedding model, if not specified, will use the `Settings.embed_model`\n\t\tfinal_use_context (bool): Whether to add the context nodes of the retrieved log nodes to the final results.\n\t\t\tDefaults to True.\n\t\trelevant_top_k (int): The top-k relevant nodes in retrieving will be used as the retrieved results.\n\t\t\tDefaults to `CHAT_MEMORY_RELEVANT_TOP_K`.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tembed_model: BaseEmbedding = None,\n\t\tfinal_use_context: bool = True,\n\t\trelevant_top_k: int = CHAT_MEMORY_RELEVANT_TOP_K\n\t):\n\t\tsuper().__init__(\n\t\t\tembed_model=embed_model,\n\t\t\tfinal_use_context=final_use_context,\n\t\t\trelevant_top_k=relevant_top_k,\n\t\t)\n\n\tdef get_memory_vector_retriever(self) -&gt; VectorIndexRetriever:\n\t\tmemory_retriever = self.memory.vector_index.as_retriever(\n\t\t\tsimilarity_top_k=self.relevant_top_k,\n\t\t\tfilters=None,\n\t\t)\n\t\treturn memory_retriever\n\n\tdef reset_vector_retriever(self):\n\t\tself.memory_vector_retriever._filters = None\n\t\tself.memory_vector_retriever._node_ids = None\n\n\tdef get_memory_vector_index(self) -&gt; VectorStoreIndex:\n\t\treturn self.memory.vector_index\n\n\t@dispatcher.span\n\tdef retrieve(\n\t\tself,\n\t\titem_to_be_retrieved: str,\n\t\tmemory_id: str,\n\t\tstart_date: str = None,\n\t\tend_date: str = None,\n\t\t**kwargs: Any,\n\t) -&gt; List[NodeWithScore]:\n\t\tr\"\"\"\n\t\tThis tool is used to retrieve relevant chat history in a certain chat history memory.\n\t\tThe memory_id of a chat history memory is the `user_id` of a specific user or the `chat_group_id` of a specific\n\t\tchat group.\n\n\t\tAdditionally, you can provide the `start_date` and `end_state` to limit the retrieving range of date,\n\t\tThe end date can be the same as the start date, but should not be earlier than the start date.\n\t\tIf the start date or end_date is not provided, retrieving will be performed among the whole memory.\n\n\t\tArgs:\n\t\t\titem_to_be_retrieved (str): Things that you want to retrieve in the chat history memory.\n\t\t\tmemory_id (str): The memory_id of a chat history memory. It is either a `user_id` or a `chat_group_id`.\n\t\t\tstart_date (str): The START date of the retrieving date limit. Defaults to None.\n\t\t\t\tIf given, it should be given in the following FORMAT: Year-Month-Day.\n\t\t\t\tFor example, 2020-12-1 means the year 2020, the 12th month, the 1rst day.\n\t\t\tend_date (str): The END date of the retrieving date limit. Defaults to None.\n\t\t\t\tIf given, It should be given in the following FORMAT: Year-Month-Day.\n\t\t\t\tFor example, 2024-6-2 means the year 2024, the 6th month, the 2nd day.\n\n\t\tReturns:\n\t\t\tRetrieved chat history.\n\t\t\"\"\"\n\t\t# This docstring is used as the tool description.\n\t\t# set self.memory_index according to the user_id.\n\t\tif self.memory is None or self.memory.memory_id != memory_id:\n\t\t\tself.memory = ChatVectorMemory.from_memory_id(memory_id=memory_id, embed_model=self.embed_model,\n\t\t\t\tretriever_kwargs={}, )\n\t\t\tself.memory_vector_retriever = self.get_memory_vector_retriever()\n\n\t\t# get the candidate date list.\n\t\tdate_list = self._parse_date(start_date_str=start_date, end_date_str=end_date)\n\t\tmetadata_filters =  MetadataFilters(\n\t\t\tfilters=[\n\t\t\t\tself.get_date_filter(date_list=date_list),\n\t\t\t]\n\t\t)\n\t\tself.memory_vector_retriever._filters = metadata_filters\n\t\tchat_nodes = self.memory_vector_retriever.retrieve(item_to_be_retrieved)\n\t\tself.reset_vector_retriever()\n\t\t# get the results, add prev node and next node to it (if in a same date.).\n\t\tif self.final_use_context:\n\t\t\tchat_nodes = self._add_context(content_nodes=chat_nodes)\n\t\treturn chat_nodes\n\n\t@dispatcher.span\n\tasync def aretrieve(\n\t\tself,\n\t\titem_to_be_retrieved: str,\n\t\tmemory_id: str,\n\t\tstart_date: str = None,\n\t\tend_date: str = None,\n\t\t**kwargs: Any,\n\t) -&gt; List[NodeWithScore]:\n\t\tr\"\"\"\n\t\tThis method is used to asynchronously retrieve relevant chat history in a certain chat history memory.\n\t\tThe memory_id of a chat history memory is the `user_id` of a specific user or the `chat_group_id` of a specific\n\t\tchat group.\n\n\t\tAdditionally, you can provide the `start_date` and `end_state` to limit the retrieving range of date,\n\t\tThe end date should not be earlier than the start date.\n\t\tIf the start date or end_date is not provided, retrieving will be performed among the whole memory.\n\n\t\tArgs:\n\t\t\titem_to_be_retrieved (str): Things that you want to retrieve in the chat history memory.\n\t\t\tmemory_id (str): The memory_id of a chat history memory. It is either a `user_id` or a `chat_group_id`.\n\t\t\tstart_date (str): The START date of the retrieving date limit. Defaults to None.\n\t\t\t\tIf given, it should be given in the following FORMAT: Year-Month-Day.\n\t\t\t\tFor example, 2020-12-1 means the year 2020, the 12th month, the 1rst day.\n\t\t\tend_date (str): The END date of the retrieving date limit. Defaults to None.\n\t\t\t\tIf given, it should be given in the following FORMAT: Year-Month-Day.\n\t\t\t\tFor example, 2024-6-2 means the year 2024, the 6th month, the 2nd day.\n\n\t\tReturns:\n\t\t\tRetrieved chat history.\n\t\t\"\"\"\n\t\t# set self.memory_index according to the user_id.\n\t\tif self.memory is None or self.memory.memory_id != memory_id:\n\t\t\tself.memory = ChatVectorMemory.from_memory_id(\n\t\t\t\tmemory_id=memory_id,\n\t\t\t\tembed_model=self.embed_model,\n\t\t\t\tretriever_kwargs={},\n\t\t\t)\n\t\t\tself.memory_vector_retriever = self.get_memory_vector_retriever()\n\n\t\t# get the candidate date list.\n\t\tdate_list = self._parse_date(start_date_str=start_date, end_date_str=end_date)\n\t\tmetadata_filters = MetadataFilters(\n\t\t\tfilters=[\n\t\t\t\tself.get_date_filter(date_list=date_list),\n\t\t\t]\n\t\t)\n\t\tself.memory_vector_retriever._filters = metadata_filters\n\t\tchat_nodes = await self.memory_vector_retriever.aretrieve(item_to_be_retrieved)\n\t\t# get the results, add prev node and next node to it (if in a same date.).\n\t\tif self.final_use_context:\n\t\t\tchat_nodes = self._add_context(content_nodes=chat_nodes)\n\t\treturn chat_nodes\n</code></pre>"},{"location":"code_docs/func_modules/memory/chat/retrieve/#labridge.func_modules.memory.chat.retrieve.ChatMemoryRetriever.aretrieve","title":"<code>labridge.func_modules.memory.chat.retrieve.ChatMemoryRetriever.aretrieve(item_to_be_retrieved, memory_id, start_date=None, end_date=None, **kwargs)</code>  <code>async</code>","text":"<p>This method is used to asynchronously retrieve relevant chat history in a certain chat history memory. The memory_id of a chat history memory is the <code>user_id</code> of a specific user or the <code>chat_group_id</code> of a specific chat group.</p> <p>Additionally, you can provide the <code>start_date</code> and <code>end_state</code> to limit the retrieving range of date, The end date should not be earlier than the start date. If the start date or end_date is not provided, retrieving will be performed among the whole memory.</p> PARAMETER DESCRIPTION <code>item_to_be_retrieved</code> <p>Things that you want to retrieve in the chat history memory.</p> <p> TYPE: <code>str</code> </p> <code>memory_id</code> <p>The memory_id of a chat history memory. It is either a <code>user_id</code> or a <code>chat_group_id</code>.</p> <p> TYPE: <code>str</code> </p> <code>start_date</code> <p>The START date of the retrieving date limit. Defaults to None. If given, it should be given in the following FORMAT: Year-Month-Day. For example, 2020-12-1 means the year 2020, the 12<sup>th</sup> month, the 1rst day.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>end_date</code> <p>The END date of the retrieving date limit. Defaults to None. If given, it should be given in the following FORMAT: Year-Month-Day. For example, 2024-6-2 means the year 2024, the 6<sup>th</sup> month, the 2<sup>nd</sup> day.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>List[NodeWithScore]</code> <p>Retrieved chat history.</p> Source code in <code>labridge\\func_modules\\memory\\chat\\retrieve.py</code> <pre><code>@dispatcher.span\nasync def aretrieve(\n\tself,\n\titem_to_be_retrieved: str,\n\tmemory_id: str,\n\tstart_date: str = None,\n\tend_date: str = None,\n\t**kwargs: Any,\n) -&gt; List[NodeWithScore]:\n\tr\"\"\"\n\tThis method is used to asynchronously retrieve relevant chat history in a certain chat history memory.\n\tThe memory_id of a chat history memory is the `user_id` of a specific user or the `chat_group_id` of a specific\n\tchat group.\n\n\tAdditionally, you can provide the `start_date` and `end_state` to limit the retrieving range of date,\n\tThe end date should not be earlier than the start date.\n\tIf the start date or end_date is not provided, retrieving will be performed among the whole memory.\n\n\tArgs:\n\t\titem_to_be_retrieved (str): Things that you want to retrieve in the chat history memory.\n\t\tmemory_id (str): The memory_id of a chat history memory. It is either a `user_id` or a `chat_group_id`.\n\t\tstart_date (str): The START date of the retrieving date limit. Defaults to None.\n\t\t\tIf given, it should be given in the following FORMAT: Year-Month-Day.\n\t\t\tFor example, 2020-12-1 means the year 2020, the 12th month, the 1rst day.\n\t\tend_date (str): The END date of the retrieving date limit. Defaults to None.\n\t\t\tIf given, it should be given in the following FORMAT: Year-Month-Day.\n\t\t\tFor example, 2024-6-2 means the year 2024, the 6th month, the 2nd day.\n\n\tReturns:\n\t\tRetrieved chat history.\n\t\"\"\"\n\t# set self.memory_index according to the user_id.\n\tif self.memory is None or self.memory.memory_id != memory_id:\n\t\tself.memory = ChatVectorMemory.from_memory_id(\n\t\t\tmemory_id=memory_id,\n\t\t\tembed_model=self.embed_model,\n\t\t\tretriever_kwargs={},\n\t\t)\n\t\tself.memory_vector_retriever = self.get_memory_vector_retriever()\n\n\t# get the candidate date list.\n\tdate_list = self._parse_date(start_date_str=start_date, end_date_str=end_date)\n\tmetadata_filters = MetadataFilters(\n\t\tfilters=[\n\t\t\tself.get_date_filter(date_list=date_list),\n\t\t]\n\t)\n\tself.memory_vector_retriever._filters = metadata_filters\n\tchat_nodes = await self.memory_vector_retriever.aretrieve(item_to_be_retrieved)\n\t# get the results, add prev node and next node to it (if in a same date.).\n\tif self.final_use_context:\n\t\tchat_nodes = self._add_context(content_nodes=chat_nodes)\n\treturn chat_nodes\n</code></pre>"},{"location":"code_docs/func_modules/memory/chat/retrieve/#labridge.func_modules.memory.chat.retrieve.ChatMemoryRetriever.retrieve","title":"<code>labridge.func_modules.memory.chat.retrieve.ChatMemoryRetriever.retrieve(item_to_be_retrieved, memory_id, start_date=None, end_date=None, **kwargs)</code>","text":"<p>This tool is used to retrieve relevant chat history in a certain chat history memory. The memory_id of a chat history memory is the <code>user_id</code> of a specific user or the <code>chat_group_id</code> of a specific chat group.</p> <p>Additionally, you can provide the <code>start_date</code> and <code>end_state</code> to limit the retrieving range of date, The end date can be the same as the start date, but should not be earlier than the start date. If the start date or end_date is not provided, retrieving will be performed among the whole memory.</p> PARAMETER DESCRIPTION <code>item_to_be_retrieved</code> <p>Things that you want to retrieve in the chat history memory.</p> <p> TYPE: <code>str</code> </p> <code>memory_id</code> <p>The memory_id of a chat history memory. It is either a <code>user_id</code> or a <code>chat_group_id</code>.</p> <p> TYPE: <code>str</code> </p> <code>start_date</code> <p>The START date of the retrieving date limit. Defaults to None. If given, it should be given in the following FORMAT: Year-Month-Day. For example, 2020-12-1 means the year 2020, the 12<sup>th</sup> month, the 1rst day.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>end_date</code> <p>The END date of the retrieving date limit. Defaults to None. If given, It should be given in the following FORMAT: Year-Month-Day. For example, 2024-6-2 means the year 2024, the 6<sup>th</sup> month, the 2<sup>nd</sup> day.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>List[NodeWithScore]</code> <p>Retrieved chat history.</p> Source code in <code>labridge\\func_modules\\memory\\chat\\retrieve.py</code> <pre><code>@dispatcher.span\ndef retrieve(\n\tself,\n\titem_to_be_retrieved: str,\n\tmemory_id: str,\n\tstart_date: str = None,\n\tend_date: str = None,\n\t**kwargs: Any,\n) -&gt; List[NodeWithScore]:\n\tr\"\"\"\n\tThis tool is used to retrieve relevant chat history in a certain chat history memory.\n\tThe memory_id of a chat history memory is the `user_id` of a specific user or the `chat_group_id` of a specific\n\tchat group.\n\n\tAdditionally, you can provide the `start_date` and `end_state` to limit the retrieving range of date,\n\tThe end date can be the same as the start date, but should not be earlier than the start date.\n\tIf the start date or end_date is not provided, retrieving will be performed among the whole memory.\n\n\tArgs:\n\t\titem_to_be_retrieved (str): Things that you want to retrieve in the chat history memory.\n\t\tmemory_id (str): The memory_id of a chat history memory. It is either a `user_id` or a `chat_group_id`.\n\t\tstart_date (str): The START date of the retrieving date limit. Defaults to None.\n\t\t\tIf given, it should be given in the following FORMAT: Year-Month-Day.\n\t\t\tFor example, 2020-12-1 means the year 2020, the 12th month, the 1rst day.\n\t\tend_date (str): The END date of the retrieving date limit. Defaults to None.\n\t\t\tIf given, It should be given in the following FORMAT: Year-Month-Day.\n\t\t\tFor example, 2024-6-2 means the year 2024, the 6th month, the 2nd day.\n\n\tReturns:\n\t\tRetrieved chat history.\n\t\"\"\"\n\t# This docstring is used as the tool description.\n\t# set self.memory_index according to the user_id.\n\tif self.memory is None or self.memory.memory_id != memory_id:\n\t\tself.memory = ChatVectorMemory.from_memory_id(memory_id=memory_id, embed_model=self.embed_model,\n\t\t\tretriever_kwargs={}, )\n\t\tself.memory_vector_retriever = self.get_memory_vector_retriever()\n\n\t# get the candidate date list.\n\tdate_list = self._parse_date(start_date_str=start_date, end_date_str=end_date)\n\tmetadata_filters =  MetadataFilters(\n\t\tfilters=[\n\t\t\tself.get_date_filter(date_list=date_list),\n\t\t]\n\t)\n\tself.memory_vector_retriever._filters = metadata_filters\n\tchat_nodes = self.memory_vector_retriever.retrieve(item_to_be_retrieved)\n\tself.reset_vector_retriever()\n\t# get the results, add prev node and next node to it (if in a same date.).\n\tif self.final_use_context:\n\t\tchat_nodes = self._add_context(content_nodes=chat_nodes)\n\treturn chat_nodes\n</code></pre>"},{"location":"code_docs/func_modules/memory/chat/short_memory/","title":"Short memory","text":""},{"location":"code_docs/func_modules/memory/chat/short_memory/#labridge.func_modules.memory.chat.short_memory","title":"<code>labridge.func_modules.memory.chat.short_memory</code>","text":""},{"location":"code_docs/func_modules/memory/chat/short_memory/#labridge.func_modules.memory.chat.short_memory.ShortMemoryManager","title":"<code>labridge.func_modules.memory.chat.short_memory.ShortMemoryManager</code>","text":"<p>               Bases: <code>object</code></p> <p>This class manage the short-term chat memories between the agent and users.</p> ATTRIBUTE DESCRIPTION <code>_root</code> <p>The project root.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>_valid_delta_days</code> <p>Only valid chat histories will be loaded.</p> <p> TYPE: <code>Optional[int]</code> </p> <code>_valid_delta_hours</code> <p>Same as above.</p> <p> TYPE: <code>Optional[int]</code> </p> <code>_valid_delta_minutes</code> <p>Same as above.</p> <p> TYPE: <code>Optional[int]</code> </p> Source code in <code>labridge\\func_modules\\memory\\chat\\short_memory.py</code> <pre><code>class ShortMemoryManager(object):\n\tr\"\"\"\n\tThis class manage the short-term chat memories between the agent and users.\n\n\tAttributes:\n\t\t_root (Optional[str]): The project root.\n\t\t_valid_delta_days (Optional[int]): Only valid chat histories will be loaded.\n\t\t_valid_delta_hours (Optional[int]): Same as above.\n\t\t_valid_delta_minutes (Optional[int]): Same as above.\n\t\"\"\"\n\t_root: Optional[str] = None\n\t_valid_delta_days: Optional[int] = 0\n\t_valid_delta_hours: Optional[int] = 2\n\t_valid_delta_minutes: Optional[int] = 30\n\n\t@property\n\tdef root(self) -&gt; str:\n\t\tr\"\"\" Return the project root \"\"\"\n\t\tif self._root is None:\n\t\t\troot_dir = Path(__file__)\n\t\t\tfor idx in range(5):\n\t\t\t\troot_dir = root_dir.parent\n\t\t\tself._root = str(root_dir)\n\t\treturn self._root\n\n\t@property\n\tdef valid_delta_time(self) -&gt; datetime.timedelta:\n\t\tr\"\"\" Return the valid time delta. \"\"\"\n\t\treturn datetime.timedelta(\n\t\t\tdays=self._valid_delta_days,\n\t\t\thours=self._valid_delta_hours,\n\t\t\tminutes=self._valid_delta_minutes,\n\t\t)\n\n\t@staticmethod\n\tdef _pack_time_key(date_str: str, time_str: str) -&gt; str:\n\t\treturn f\"{date_str} {time_str}\"\n\n\t@staticmethod\n\tdef _unpack_time_key(time_key: str) -&gt; datetime.datetime:\n\t\tdate_str, time_str = time_key.split()\n\t\tlast_datetime = str_to_datetime(date_str=date_str, time_str=time_str)\n\t\treturn last_datetime\n\n\tdef clear_memory(self, user_id: str):\n\t\tpersist_path = Path(self.root) / f\"{SHORT_MEMORY_PERSIST_DIR}/{user_id}.json\"\n\t\tfs = fsspec.filesystem(\"file\")\n\t\tif fs.exists(persist_path):\n\t\t\tfs.rm(persist_path)\n\n\tdef load_memory(self, user_id: str) -&gt; Optional[List[ChatMessage]]:\n\t\tr\"\"\"\n\t\tOnly chat messages within the valid time delta will be loaded.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user_id of a lab member.\n\n\t\tReturns:\n\t\t\tThe loaded short memory:\n\t\t\t\tIf the short memory storage does not exist or the datetime of the short memory is invalid, return None.\n\t\t\"\"\"\n\t\tpersist_path = Path(self.root) / f\"{SHORT_MEMORY_PERSIST_DIR}/{user_id}.json\"\n\t\tfs = fsspec.filesystem(\"file\")\n\t\tif not fs.exists(persist_path):\n\t\t\treturn None\n\n\t\tchat_store = SimpleChatStore.from_persist_path(persist_path=str(persist_path))\n\t\tkeys = chat_store.get_keys()\n\t\tif len(keys) &lt; 1:\n\t\t\tfs.rm(persist_path)\n\t\t\treturn None\n\t\ttime_key = chat_store.get_keys()[0]\n\t\tlast_datetime = self._unpack_time_key(time_key=time_key)\n\t\tnow = datetime.datetime.now()\n\t\tif last_datetime + self.valid_delta_time &lt; now:\n\t\t\treturn None\n\t\treturn chat_store.store[time_key]\n\n\tdef save_memory(self, user_id: str, chat_history: List[ChatMessage]):\n\t\tr\"\"\"\n\t\tPersist the short-term memory for the user's next chat request.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user id of a Lab member.\n\t\t\tchat_history (List[ChatMessage]): Current chat history between the user and agent.\n\t\t\"\"\"\n\t\tdate, h_m_s = get_time()\n\t\ttime_key = self._pack_time_key(date_str=date, time_str=h_m_s)\n\t\tstore_dict = {\n\t\t\ttime_key: chat_history,\n\t\t}\n\t\tchat_store = SimpleChatStore(store=store_dict)\n\t\tpersist_path = Path(self.root) / f\"{SHORT_MEMORY_PERSIST_DIR}/{user_id}.json\"\n\t\tpersist_path = str(persist_path)\n\t\tchat_store.persist(persist_path=persist_path)\n</code></pre>"},{"location":"code_docs/func_modules/memory/chat/short_memory/#labridge.func_modules.memory.chat.short_memory.ShortMemoryManager.root","title":"<code>labridge.func_modules.memory.chat.short_memory.ShortMemoryManager.root: str</code>  <code>property</code>","text":"<p>Return the project root</p>"},{"location":"code_docs/func_modules/memory/chat/short_memory/#labridge.func_modules.memory.chat.short_memory.ShortMemoryManager.valid_delta_time","title":"<code>labridge.func_modules.memory.chat.short_memory.ShortMemoryManager.valid_delta_time: datetime.timedelta</code>  <code>property</code>","text":"<p>Return the valid time delta.</p>"},{"location":"code_docs/func_modules/memory/chat/short_memory/#labridge.func_modules.memory.chat.short_memory.ShortMemoryManager.load_memory","title":"<code>labridge.func_modules.memory.chat.short_memory.ShortMemoryManager.load_memory(user_id)</code>","text":"<p>Only chat messages within the valid time delta will be loaded.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user_id of a lab member.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Optional[List[ChatMessage]]</code> <p>The loaded short memory: If the short memory storage does not exist or the datetime of the short memory is invalid, return None.</p> Source code in <code>labridge\\func_modules\\memory\\chat\\short_memory.py</code> <pre><code>def load_memory(self, user_id: str) -&gt; Optional[List[ChatMessage]]:\n\tr\"\"\"\n\tOnly chat messages within the valid time delta will be loaded.\n\n\tArgs:\n\t\tuser_id (str): The user_id of a lab member.\n\n\tReturns:\n\t\tThe loaded short memory:\n\t\t\tIf the short memory storage does not exist or the datetime of the short memory is invalid, return None.\n\t\"\"\"\n\tpersist_path = Path(self.root) / f\"{SHORT_MEMORY_PERSIST_DIR}/{user_id}.json\"\n\tfs = fsspec.filesystem(\"file\")\n\tif not fs.exists(persist_path):\n\t\treturn None\n\n\tchat_store = SimpleChatStore.from_persist_path(persist_path=str(persist_path))\n\tkeys = chat_store.get_keys()\n\tif len(keys) &lt; 1:\n\t\tfs.rm(persist_path)\n\t\treturn None\n\ttime_key = chat_store.get_keys()[0]\n\tlast_datetime = self._unpack_time_key(time_key=time_key)\n\tnow = datetime.datetime.now()\n\tif last_datetime + self.valid_delta_time &lt; now:\n\t\treturn None\n\treturn chat_store.store[time_key]\n</code></pre>"},{"location":"code_docs/func_modules/memory/chat/short_memory/#labridge.func_modules.memory.chat.short_memory.ShortMemoryManager.save_memory","title":"<code>labridge.func_modules.memory.chat.short_memory.ShortMemoryManager.save_memory(user_id, chat_history)</code>","text":"<p>Persist the short-term memory for the user's next chat request.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user id of a Lab member.</p> <p> TYPE: <code>str</code> </p> <code>chat_history</code> <p>Current chat history between the user and agent.</p> <p> TYPE: <code>List[ChatMessage]</code> </p> Source code in <code>labridge\\func_modules\\memory\\chat\\short_memory.py</code> <pre><code>def save_memory(self, user_id: str, chat_history: List[ChatMessage]):\n\tr\"\"\"\n\tPersist the short-term memory for the user's next chat request.\n\n\tArgs:\n\t\tuser_id (str): The user id of a Lab member.\n\t\tchat_history (List[ChatMessage]): Current chat history between the user and agent.\n\t\"\"\"\n\tdate, h_m_s = get_time()\n\ttime_key = self._pack_time_key(date_str=date, time_str=h_m_s)\n\tstore_dict = {\n\t\ttime_key: chat_history,\n\t}\n\tchat_store = SimpleChatStore(store=store_dict)\n\tpersist_path = Path(self.root) / f\"{SHORT_MEMORY_PERSIST_DIR}/{user_id}.json\"\n\tpersist_path = str(persist_path)\n\tchat_store.persist(persist_path=persist_path)\n</code></pre>"},{"location":"code_docs/func_modules/memory/experiment/experiment_log/","title":"Experiment log","text":""},{"location":"code_docs/func_modules/memory/experiment/experiment_log/#labridge.func_modules.memory.experiment.experiment_log","title":"<code>labridge.func_modules.memory.experiment.experiment_log</code>","text":""},{"location":"code_docs/func_modules/memory/experiment/experiment_log/#labridge.func_modules.memory.experiment.experiment_log.ExperimentLog","title":"<code>labridge.func_modules.memory.experiment.experiment_log.ExperimentLog</code>","text":"<p>               Bases: <code>object</code></p> <p>This class stores the experiment logs for a specific user. It is constructed as a tree, with a root node. Different experiments are inserted as child nodes of the tree node. For each experiment node, TextNodes recording experiment logs are stored as its child nodes in chronological order. Like:</p> <pre><code>                                                                                root_node\n                                                                        /                               \\\n                                                                   /                             \\\n                                                        Experiment1                     Experiment2\n                                        /               ...                             \\\n                                log1 --next-&gt; ... --next-&gt; log n\n</code></pre> <p>Additionally, a recent_experiment node records the most recent experiment of the user, with the start time and the end time of the experiment.</p> PARAMETER DESCRIPTION <code>vector_index</code> <p>The vector database storing the experiment logs.</p> <p> TYPE: <code>VectorStoreIndex</code> </p> <code>persist_dir</code> <p>The persist directory.</p> <p> TYPE: <code>str</code> </p> Note <p>The metadata <code>date</code> and <code>time</code> is recorded in a list format for the convenience of metadata filtering. For example: ['2024-08-10'], ['09:05:03'].</p> Source code in <code>labridge\\func_modules\\memory\\experiment\\experiment_log.py</code> <pre><code>class ExperimentLog(object):\n\tr\"\"\"\n\tThis class stores the experiment logs for a specific user.\n\tIt is constructed as a tree, with a root node. Different experiments are inserted as child nodes of the tree node.\n\tFor each experiment node, TextNodes recording experiment logs are stored as its child nodes in chronological order.\n\tLike:\n\n\t```\n\t\t\t\t\t\t\t\t\t\t\troot_node\n\t\t\t\t\t\t\t\t\t\t/\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t   /\t\t\t\t \\\n\t\t\t\t\t\t\t\tExperiment1\t\t\tExperiment2\n\t\t\t\t\t\t/\t\t...\t\t\t\t\\\n\t\t\t\t\tlog1 --next-&gt; ... --next-&gt; log n\n\t```\n\n\tAdditionally, a recent_experiment node records the most recent experiment of the user, with the start time and the\n\tend time of the experiment.\n\n\tArgs:\n\t\tvector_index (VectorStoreIndex): The vector database storing the experiment logs.\n\t\tpersist_dir (str): The persist directory.\n\n\tNote:\n\t\tThe metadata `date` and `time` is recorded in a list format for the convenience of metadata filtering.\n\t\tFor example: ['2024-08-10'], ['09:05:03'].\n\t\"\"\"\n\tdef __init__(self, vector_index: VectorStoreIndex, persist_dir: str):\n\t\tself.vector_index = vector_index\n\t\tself.vector_index.set_index_id(EXPERIMENT_LOG_VECTOR_INDEX_ID)\n\t\tself.persist_dir = persist_dir\n\t\tself._fs = fsspec.filesystem(\"file\")\n\t\troot = Path(__file__)\n\t\tfor idx in range(5):\n\t\t\troot = root.parent\n\t\tself._root = root\n\n\t@classmethod\n\tdef from_storage(\n\t\tcls,\n\t\tpersist_dir: str,\n\t\tembed_model: BaseEmbedding,\n\t):\n\t\tr\"\"\"\n\t\tLoad from an existing storage.\n\n\t\tArgs:\n\t\t\tpersist_dir (str): The persist directory of an existing storage.\n\t\t\tembed_model (BaseEmbedding): The used embedding model.\n\n\t\tReturns:\n\t\t\tExperimentLog\n\t\t\"\"\"\n\t\tvector_storage_context = StorageContext.from_defaults(persist_dir=persist_dir)\n\t\tvector_index = load_index_from_storage(\n\t\t\tstorage_context=vector_storage_context,\n\t\t\tindex_id=EXPERIMENT_LOG_VECTOR_INDEX_ID,\n\t\t\tembed_model=embed_model,\n\t\t)\n\t\treturn cls(\n\t\t\tvector_index=vector_index,\n\t\t\tpersist_dir=persist_dir,\n\t\t)\n\n\t@property\n\tdef user_id(self)-&gt;str:\n\t\tr\"\"\" Get the corresponding user_id of this storage \"\"\"\n\t\troot = Path(__file__)\n\t\tfor idx in range(5):\n\t\t\troot = root.parent\n\n\t\tuser_id = Path(self.persist_dir).relative_to(root / EXPERIMENT_LOG_PERSIST_DIR)\n\t\treturn str(user_id)\n\n\tdef update(self):\n\t\tr\"\"\" Reload from the disk. \"\"\"\n\t\treturn self.from_user_id(\n\t\t\tuser_id=self.user_id,\n\t\t\tembed_model=self.vector_index._embed_model,\n\t\t)\n\n\t@classmethod\n\tdef from_user_id(\n\t\tcls,\n\t\tuser_id: str,\n\t\tembed_model: BaseEmbedding,\n\t):\n\t\tr\"\"\"\n\t\tConstruct from a user_id.\n\t\tIf the persist directory of the user_id does not exist, a new ExperimentLog will be created for the user.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user_id of a Lab member.\n\t\t\tembed_model (BaseEmbedding): The used embedding model.\n\n\t\tReturns:\n\t\t\tExperimentLog\n\t\t\"\"\"\n\t\taccount_manager = AccountManager()\n\t\taccount_manager.check_valid_user(user_id=user_id)\n\n\t\troot = Path(__file__)\n\t\tfor idx in range(5):\n\t\t\troot = root.parent\n\n\t\tpersist_dir = str(root / f\"{EXPERIMENT_LOG_PERSIST_DIR}/{user_id}\")\n\t\tfs = fsspec.filesystem(\"file\")\n\t\tif fs.exists(persist_dir):\n\t\t\treturn cls.from_storage(\n\t\t\t\tpersist_dir=persist_dir,\n\t\t\t\tembed_model=embed_model,\n\t\t\t)\n\n\t\t# root node.\n\t\tdate, h_m_s = get_time()\n\t\troot_node = TextNode(\n\t\t\ttext=f\"Root node for the experiment logs of {user_id}\",\n\t\t\tid_=INIT_NODE_NAME,\n\t\t\tmetadata={\n\t\t\t\tLOG_DATE_NAME: [date,],\n\t\t\t\tLOG_TIME_NAME: [h_m_s,],\n\t\t\t\tMEMORY_NODE_TYPE_NAME: NOT_LOG_NODE_TYPE,\n\t\t\t}\n\t\t)\n\t\t# record the most recent experiment.\n\t\trecent_expr_node = TextNode(\n\t\t\ttext=f\"The most recent experiment of the user {user_id}\",\n\t\t\tid_=RECENT_EXPERIMENT_NODE_NAME,\n\t\t\tmetadata={\n\t\t\t\tRECENT_EXPERIMENT_NAME_KEY: None,\n\t\t\t\tRECENT_EXPERIMENT_START_TIME_KEY: None,\n\t\t\t\tRECENT_EXPERIMENT_END_TIME_KEY: None,\n\t\t\t\tLOG_DATE_NAME: [date,],\n\t\t\t\tLOG_TIME_NAME: [h_m_s,],\n\t\t\t\tMEMORY_NODE_TYPE_NAME: NOT_LOG_NODE_TYPE,\n\t\t\t}\n\t\t)\n\t\tnodes = [root_node, recent_expr_node]\n\t\tvector_index = VectorStoreIndex(\n\t\t\tnodes=nodes,\n\t\t\tembed_model=embed_model,\n\t\t)\n\t\treturn cls(\n\t\t\tvector_index=vector_index,\n\t\t\tpersist_dir=persist_dir,\n\t\t)\n\n\tdef get_recent_experiment(self) -&gt; Optional[str]:\n\t\tr\"\"\" Get the most recent experiment name. \"\"\"\n\t\trecent_node = self._get_node(node_id=RECENT_EXPERIMENT_NODE_NAME)\n\t\tmetadata = recent_node.metadata\n\n\t\texpr_name = metadata[RECENT_EXPERIMENT_NAME_KEY]\n\t\tif expr_name is None:\n\t\t\treturn None\n\n\t\tstart_date_str, start_time_str = metadata[RECENT_EXPERIMENT_START_TIME_KEY]\n\t\tend_date_str, end_time_str = metadata[RECENT_EXPERIMENT_END_TIME_KEY]\n\n\t\ttry:\n\t\t\tstart = str_to_datetime(date_str=start_date_str, time_str=start_time_str)\n\t\t\tend = str_to_datetime(date_str=end_date_str, time_str=end_time_str)\n\t\t\tdate, h_m_s = get_time()\n\t\t\tcurrent = str_to_datetime(date_str=date, time_str=h_m_s)\n\t\t\tif start &lt;= current &lt;= end:\n\t\t\t\treturn expr_name\n\t\t\treturn None\n\t\texcept Exception as e:\n\t\t\tprint(f\"Error in get_recent_experiment: {e}\")\n\t\t\treturn None\n\n\tdef get_all_experiments(self) -&gt; Optional[List[str]]:\n\t\tr\"\"\" Get all experiment names. \"\"\"\n\t\troot_node = self._get_node(node_id=INIT_NODE_NAME)\n\t\texpr_list = root_node.child_nodes\n\t\tif expr_list:\n\t\t\treturn [expr.node_id for expr in expr_list]\n\t\treturn None\n\n\tdef get_all_experiments_with_description(self) -&gt; Optional[Dict[str, str]]:\n\t\tr\"\"\" Get all experiment names and their descriptions. \"\"\"\n\t\troot_node = self._get_node(node_id=INIT_NODE_NAME)\n\t\texpr_list = root_node.child_nodes\n\n\t\texperiments = {}\n\t\tif expr_list:\n\t\t\tfor child in expr_list:\n\t\t\t\texpr_id = child.node_id\n\t\t\t\texpr_node = self._get_node(node_id=expr_id)\n\t\t\t\texperiments[expr_id] = expr_node.text\n\t\t\treturn experiments\n\t\treturn None\n\n\tdef set_recent_experiment(\n\t\tself,\n\t\texperiment_name: str,\n\t\tstart_date: str,\n\t\tstart_time: str,\n\t\tend_date: str,\n\t\tend_time: str,\n\t):\n\t\tr\"\"\"\n\t\tSet the most recent (or actually, in progress) experiment and its duration.\n\n\t\tArgs:\n\t\t\texperiment_name (str): The experiment name to be set in progress.\n\t\t\tstart_date (str): The formatted string of the start date of the experiment.\n\t\t\tstart_time (str): The formatted string of the start time of the experiment.\n\t\t\tend_date (str): The formatted string of the end date of the experiment.\n\t\t\tend_time (str): The formatted string of the end time of the experiment.\n\t\t\"\"\"\n\t\texpr_list = self.get_all_experiments()\n\t\tif experiment_name not in expr_list:\n\t\t\traise ValueError(\n\t\t\t\tf\"The experiment {experiment_name} \" \n\t\t\t\tf\"does not exist in the experiment log memory of the user {self.user_id}\"\n\t\t\t)\n\n\t\trecent_node = self._get_node(node_id=RECENT_EXPERIMENT_NODE_NAME)\n\t\trecent_node.metadata[RECENT_EXPERIMENT_START_TIME_KEY] = (\n\t\t\tstart_date, start_time\n\t\t)\n\t\trecent_node.metadata[RECENT_EXPERIMENT_END_TIME_KEY] = (\n\t\t\tend_date, end_time\n\t\t)\n\t\trecent_node.metadata[RECENT_EXPERIMENT_NAME_KEY] = experiment_name\n\t\tself._update_node(\n\t\t\tnode_id=RECENT_EXPERIMENT_NODE_NAME,\n\t\t\tnode=recent_node,\n\t\t)\n\n\tdef _get_node(self, node_id: str) -&gt; BaseNode:\n\t\tr\"\"\" Get node. \"\"\"\n\t\treturn self.vector_index.docstore.get_node(node_id)\n\n\tdef _update_node(\n\t\tself,\n\t\tnode_id: str,\n\t\tnode: BaseNode,\n\t):\n\t\t\"\"\" Update an existing node. \"\"\"\n\t\tself.vector_index.delete_nodes([node_id])\n\t\tself.vector_index.insert_nodes([node])\n\n\tdef is_expr_exist(self, experiment_name: str) -&gt; bool:\n\t\tr\"\"\"\n\t\tWhether an experiment exists in the storage.\n\n\t\tArgs:\n\t\t\texperiment_name (str): The experiment name.\n\n\t\tReturns:\n\t\t\tbool: Whether the experiment exists.\n\t\t\"\"\"\n\t\troot_node = self._get_node(node_id=INIT_NODE_NAME)\n\t\texpr_list = root_node.relationships[NodeRelationship.CHILD]\n\t\treturn experiment_name in [expr.node_id for expr in expr_list]\n\n\tdef get_expr_log_node_ids(self, experiment_name: str) -&gt; List[str]:\n\t\tr\"\"\"\n\t\tGet the log node ids of a specific experiment.\n\n\t\tArgs:\n\t\t\texperiment_name (str): The experiment name.\n\n\t\tReturns:\n\t\t\tList[str]: The log node ids of the experiment node.\n\t\t\"\"\"\n\t\texpr_node = self._get_node(node_id=experiment_name)\n\t\treturn [log_node.node_id for log_node in expr_node.child_nodes]\n\n\tdef create_experiment(self, experiment_name: str, description: str):\n\t\tr\"\"\"\n\t\tAdd a new experiment.\n\n\t\tArgs:\n\t\t\texperiment_name (str): The experiment name.\n\t\t\tdescription (str): The experiment description.\n\t\t\"\"\"\n\t\troot_node = self._get_node(node_id=INIT_NODE_NAME)\n\t\texpr_list = root_node.child_nodes or []\n\t\tif experiment_name in [expr.node_id for expr in expr_list]:\n\t\t\traise ValueError(f\"The experiment name {experiment_name} already exists.\")\n\n\t\tnew_expr_node = self._new_node(\n\t\t\ttext=description,\n\t\t\tnode_id=experiment_name,\n\t\t\tnode_type=NOT_LOG_NODE_TYPE,\n\t\t)\n\n\t\texpr_header_node = self._new_node(\n\t\t\ttext=f\"The log beginning of the experiment {experiment_name}\",\n\t\t\tnode_id=f\"{experiment_name}_header\",\n\t\t\tnode_type=LOG_NODE_TYPE\n\t\t)\n\t\tnew_expr_node.relationships[NodeRelationship.CHILD] = [RelatedNodeInfo(node_id=expr_header_node.node_id)]\n\t\texpr_header_node.relationships[NodeRelationship.PARENT] = RelatedNodeInfo(node_id=new_expr_node.node_id)\n\n\t\tlast_info_node = self._new_node(\n\t\t\ttext=expr_header_node.node_id,\n\t\t\tnode_id=f\"{experiment_name}_{EXPERIMENT_LAST_NODE_ID_PREFIX}\",\n\t\t\tnode_type=NOT_LOG_NODE_TYPE,\n\t\t)\n\n\t\texpr_list.append(\n\t\t\tRelatedNodeInfo(node_id=new_expr_node.node_id)\n\t\t)\n\t\troot_node.relationships[NodeRelationship.CHILD] = expr_list\n\t\tself._update_node(node_id=INIT_NODE_NAME, node=root_node)\n\n\t\tself.vector_index.insert_nodes(\n\t\t\t[\n\t\t\t\tnew_expr_node,\n\t\t\t\texpr_header_node,\n\t\t\t\tlast_info_node,\n\t\t\t]\n\t\t)\n\n\tdef _new_node(\n\t\tself,\n\t\ttext: str,\n\t\tnode_type: str,\n\t\tnode_id: str = None,\n\t\textra_metadata: dict = None,\n\t) -&gt; TextNode:\n\t\tr\"\"\" A new node with `node_type` \"\"\"\n\t\tdate, h_m_s = get_time()\n\t\tmetadata = extra_metadata or dict()\n\t\tmetadata.update(\n\t\t\t{\n\t\t\t\tLOG_DATE_NAME: [date, ],\n\t\t\t\tLOG_TIME_NAME: [h_m_s, ],\n\t\t\t\tMEMORY_NODE_TYPE_NAME: node_type,\n\t\t\t}\n\t\t)\n\n\t\tnode = TextNode(\n\t\t\tid_=node_id or str(uuid.uuid4()),\n\t\t\ttext=text,\n\t\t\tmetadata=metadata,\n\t\t)\n\t\tnode.excluded_embed_metadata_keys = [MEMORY_NODE_TYPE_NAME, ]\n\t\tnode.excluded_llm_metadata_keys = [MEMORY_NODE_TYPE_NAME, ]\n\t\treturn node\n\n\tdef record_attachment(self, file_path: str) -&gt; str:\n\t\tif not self._fs.exists(file_path):\n\t\t\traise ValueError(f\"The path of the attachment file is not valid: {file_path}\")\n\n\t\tdate, h_m_s = get_time()\n\t\trecord_dir = str(self._root / f\"{EXPERIMENT_LOG_ATTACHMENT_DIR}/{self.user_id}/{date}\")\n\t\tif not self._fs.exists(record_dir):\n\t\t\tself._fs.mkdirs(record_dir)\n\n\t\tself._fs.cp(file_path, record_dir)\n\n\t\tfile_name = Path(file_path).name\n\t\trecord_path = f\"{record_dir}/{file_name}\"\n\t\treturn record_path\n\n\tdef put(\n\t\tself,\n\t\texperiment_name: str,\n\t\tlog_str: str,\n\t\tattached_file_path: str = None,\n\t):\n\t\tr\"\"\"\n\t\tPut in an experiment log into a specific experiment store.\n\n\t\tThese operations are done:\n\n\t\t- last_log_node -&gt; set_next(new_log_node)\n\t\t- new_log_node -&gt; set_previous(last_log_node)\n\t\t- last_store_node -&gt; set_content(new_log_node.node_id)\n\t\t- experiment_node -&gt; add_child(new_log_node)\n\n\t\tArgs:\n\t\t\texperiment_name (str): An existing experiment name.\n\t\t\tlog_str (str): The experiment log string to be put in.\n\t\t\tattached_file_path (str): The path of the attached file. Defaults to None.\n\t\t\"\"\"\n\t\t# TODO: Support files.\n\t\troot_node = self._get_node(node_id=INIT_NODE_NAME)\n\t\texperiments = root_node.child_nodes\n\t\tif experiments is None or experiment_name not in [expr.node_id for expr in experiments]:\n\t\t\traise ValueError(f\"The experiment {experiment_name} of user {self.user_id} does not exist.\")\n\n\t\textra_metadata = None\n\t\tif attached_file_path is not None:\n\t\t\trecord_path = self.record_attachment(file_path=attached_file_path)\n\t\t\textra_metadata = {\n\t\t\t\tEXPERIMENT_LOG_ATTACHMENT_KEY: record_path,\n\t\t\t}\n\n\t\tnew_log_node = self._new_node(\n\t\t\ttext=log_str,\n\t\t\tnode_type=LOG_NODE_TYPE,\n\t\t\textra_metadata=extra_metadata,\n\t\t)\n\t\texpr_node = self._get_node(node_id=experiment_name)\n\t\tlast_store_name = f\"{experiment_name}_{EXPERIMENT_LAST_NODE_ID_PREFIX}\"\n\t\tlast_store_node = self._get_node(node_id=last_store_name)\n\t\tlast_log_id = last_store_node.text\n\t\tlast_log_node = self._get_node(last_log_id)\n\t\tlast_log_node.relationships[NodeRelationship.NEXT] = RelatedNodeInfo(\n\t\t\tnode_id=new_log_node.node_id\n\t\t)\n\t\tnew_log_node.relationships[NodeRelationship.PREVIOUS] = RelatedNodeInfo(\n\t\t\tnode_id=last_log_node.node_id\n\t\t)\n\t\tnew_log_node.relationships[NodeRelationship.PARENT] = RelatedNodeInfo(\n\t\t\tnode_id=expr_node.node_id\n\t\t)\n\t\tlast_store_node.set_content(new_log_node.node_id)\n\t\tself._update_node(node_id=last_log_id, node=last_log_node)\n\t\tself._update_node(node_id=last_store_name, node=last_store_node)\n\n\t\tlog_node_list = expr_node.child_nodes or []\n\t\tlog_node_list.append(\n\t\t\tRelatedNodeInfo(node_id=new_log_node.node_id)\n\t\t)\n\t\texpr_node.relationships[NodeRelationship.CHILD] = log_node_list\n\t\tself._update_node(node_id=experiment_name, node=expr_node)\n\t\tprint(\"Parent: \", new_log_node.parent_node.node_id)\n\t\tself.vector_index.insert_nodes([new_log_node])\n\n\tdef persist(self, persist_dir: str = None):\n\t\tr\"\"\"\n\t\tPersist to disk.\n\n\t\tArgs:\n\t\t\tpersist_dir (str): The persist directory. If not given, use `self.directory`.\n\t\t\"\"\"\n\t\tpersist_dir = persist_dir or self.persist_dir\n\t\tfs = fsspec.filesystem(\"file\")\n\t\tif not fs.exists(persist_dir):\n\t\t\tfs.makedirs(persist_dir)\n\t\tself.vector_index.storage_context.persist(persist_dir=persist_dir)\n</code></pre>"},{"location":"code_docs/func_modules/memory/experiment/experiment_log/#labridge.func_modules.memory.experiment.experiment_log.ExperimentLog.user_id","title":"<code>labridge.func_modules.memory.experiment.experiment_log.ExperimentLog.user_id: str</code>  <code>property</code>","text":"<p>Get the corresponding user_id of this storage</p>"},{"location":"code_docs/func_modules/memory/experiment/experiment_log/#labridge.func_modules.memory.experiment.experiment_log.ExperimentLog.create_experiment","title":"<code>labridge.func_modules.memory.experiment.experiment_log.ExperimentLog.create_experiment(experiment_name, description)</code>","text":"<p>Add a new experiment.</p> PARAMETER DESCRIPTION <code>experiment_name</code> <p>The experiment name.</p> <p> TYPE: <code>str</code> </p> <code>description</code> <p>The experiment description.</p> <p> TYPE: <code>str</code> </p> Source code in <code>labridge\\func_modules\\memory\\experiment\\experiment_log.py</code> <pre><code>def create_experiment(self, experiment_name: str, description: str):\n\tr\"\"\"\n\tAdd a new experiment.\n\n\tArgs:\n\t\texperiment_name (str): The experiment name.\n\t\tdescription (str): The experiment description.\n\t\"\"\"\n\troot_node = self._get_node(node_id=INIT_NODE_NAME)\n\texpr_list = root_node.child_nodes or []\n\tif experiment_name in [expr.node_id for expr in expr_list]:\n\t\traise ValueError(f\"The experiment name {experiment_name} already exists.\")\n\n\tnew_expr_node = self._new_node(\n\t\ttext=description,\n\t\tnode_id=experiment_name,\n\t\tnode_type=NOT_LOG_NODE_TYPE,\n\t)\n\n\texpr_header_node = self._new_node(\n\t\ttext=f\"The log beginning of the experiment {experiment_name}\",\n\t\tnode_id=f\"{experiment_name}_header\",\n\t\tnode_type=LOG_NODE_TYPE\n\t)\n\tnew_expr_node.relationships[NodeRelationship.CHILD] = [RelatedNodeInfo(node_id=expr_header_node.node_id)]\n\texpr_header_node.relationships[NodeRelationship.PARENT] = RelatedNodeInfo(node_id=new_expr_node.node_id)\n\n\tlast_info_node = self._new_node(\n\t\ttext=expr_header_node.node_id,\n\t\tnode_id=f\"{experiment_name}_{EXPERIMENT_LAST_NODE_ID_PREFIX}\",\n\t\tnode_type=NOT_LOG_NODE_TYPE,\n\t)\n\n\texpr_list.append(\n\t\tRelatedNodeInfo(node_id=new_expr_node.node_id)\n\t)\n\troot_node.relationships[NodeRelationship.CHILD] = expr_list\n\tself._update_node(node_id=INIT_NODE_NAME, node=root_node)\n\n\tself.vector_index.insert_nodes(\n\t\t[\n\t\t\tnew_expr_node,\n\t\t\texpr_header_node,\n\t\t\tlast_info_node,\n\t\t]\n\t)\n</code></pre>"},{"location":"code_docs/func_modules/memory/experiment/experiment_log/#labridge.func_modules.memory.experiment.experiment_log.ExperimentLog.from_storage","title":"<code>labridge.func_modules.memory.experiment.experiment_log.ExperimentLog.from_storage(persist_dir, embed_model)</code>  <code>classmethod</code>","text":"<p>Load from an existing storage.</p> PARAMETER DESCRIPTION <code>persist_dir</code> <p>The persist directory of an existing storage.</p> <p> TYPE: <code>str</code> </p> <code>embed_model</code> <p>The used embedding model.</p> <p> TYPE: <code>BaseEmbedding</code> </p> RETURNS DESCRIPTION <p>ExperimentLog</p> Source code in <code>labridge\\func_modules\\memory\\experiment\\experiment_log.py</code> <pre><code>@classmethod\ndef from_storage(\n\tcls,\n\tpersist_dir: str,\n\tembed_model: BaseEmbedding,\n):\n\tr\"\"\"\n\tLoad from an existing storage.\n\n\tArgs:\n\t\tpersist_dir (str): The persist directory of an existing storage.\n\t\tembed_model (BaseEmbedding): The used embedding model.\n\n\tReturns:\n\t\tExperimentLog\n\t\"\"\"\n\tvector_storage_context = StorageContext.from_defaults(persist_dir=persist_dir)\n\tvector_index = load_index_from_storage(\n\t\tstorage_context=vector_storage_context,\n\t\tindex_id=EXPERIMENT_LOG_VECTOR_INDEX_ID,\n\t\tembed_model=embed_model,\n\t)\n\treturn cls(\n\t\tvector_index=vector_index,\n\t\tpersist_dir=persist_dir,\n\t)\n</code></pre>"},{"location":"code_docs/func_modules/memory/experiment/experiment_log/#labridge.func_modules.memory.experiment.experiment_log.ExperimentLog.from_user_id","title":"<code>labridge.func_modules.memory.experiment.experiment_log.ExperimentLog.from_user_id(user_id, embed_model)</code>  <code>classmethod</code>","text":"<p>Construct from a user_id. If the persist directory of the user_id does not exist, a new ExperimentLog will be created for the user.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user_id of a Lab member.</p> <p> TYPE: <code>str</code> </p> <code>embed_model</code> <p>The used embedding model.</p> <p> TYPE: <code>BaseEmbedding</code> </p> RETURNS DESCRIPTION <p>ExperimentLog</p> Source code in <code>labridge\\func_modules\\memory\\experiment\\experiment_log.py</code> <pre><code>@classmethod\ndef from_user_id(\n\tcls,\n\tuser_id: str,\n\tembed_model: BaseEmbedding,\n):\n\tr\"\"\"\n\tConstruct from a user_id.\n\tIf the persist directory of the user_id does not exist, a new ExperimentLog will be created for the user.\n\n\tArgs:\n\t\tuser_id (str): The user_id of a Lab member.\n\t\tembed_model (BaseEmbedding): The used embedding model.\n\n\tReturns:\n\t\tExperimentLog\n\t\"\"\"\n\taccount_manager = AccountManager()\n\taccount_manager.check_valid_user(user_id=user_id)\n\n\troot = Path(__file__)\n\tfor idx in range(5):\n\t\troot = root.parent\n\n\tpersist_dir = str(root / f\"{EXPERIMENT_LOG_PERSIST_DIR}/{user_id}\")\n\tfs = fsspec.filesystem(\"file\")\n\tif fs.exists(persist_dir):\n\t\treturn cls.from_storage(\n\t\t\tpersist_dir=persist_dir,\n\t\t\tembed_model=embed_model,\n\t\t)\n\n\t# root node.\n\tdate, h_m_s = get_time()\n\troot_node = TextNode(\n\t\ttext=f\"Root node for the experiment logs of {user_id}\",\n\t\tid_=INIT_NODE_NAME,\n\t\tmetadata={\n\t\t\tLOG_DATE_NAME: [date,],\n\t\t\tLOG_TIME_NAME: [h_m_s,],\n\t\t\tMEMORY_NODE_TYPE_NAME: NOT_LOG_NODE_TYPE,\n\t\t}\n\t)\n\t# record the most recent experiment.\n\trecent_expr_node = TextNode(\n\t\ttext=f\"The most recent experiment of the user {user_id}\",\n\t\tid_=RECENT_EXPERIMENT_NODE_NAME,\n\t\tmetadata={\n\t\t\tRECENT_EXPERIMENT_NAME_KEY: None,\n\t\t\tRECENT_EXPERIMENT_START_TIME_KEY: None,\n\t\t\tRECENT_EXPERIMENT_END_TIME_KEY: None,\n\t\t\tLOG_DATE_NAME: [date,],\n\t\t\tLOG_TIME_NAME: [h_m_s,],\n\t\t\tMEMORY_NODE_TYPE_NAME: NOT_LOG_NODE_TYPE,\n\t\t}\n\t)\n\tnodes = [root_node, recent_expr_node]\n\tvector_index = VectorStoreIndex(\n\t\tnodes=nodes,\n\t\tembed_model=embed_model,\n\t)\n\treturn cls(\n\t\tvector_index=vector_index,\n\t\tpersist_dir=persist_dir,\n\t)\n</code></pre>"},{"location":"code_docs/func_modules/memory/experiment/experiment_log/#labridge.func_modules.memory.experiment.experiment_log.ExperimentLog.get_all_experiments","title":"<code>labridge.func_modules.memory.experiment.experiment_log.ExperimentLog.get_all_experiments()</code>","text":"<p>Get all experiment names.</p> Source code in <code>labridge\\func_modules\\memory\\experiment\\experiment_log.py</code> <pre><code>def get_all_experiments(self) -&gt; Optional[List[str]]:\n\tr\"\"\" Get all experiment names. \"\"\"\n\troot_node = self._get_node(node_id=INIT_NODE_NAME)\n\texpr_list = root_node.child_nodes\n\tif expr_list:\n\t\treturn [expr.node_id for expr in expr_list]\n\treturn None\n</code></pre>"},{"location":"code_docs/func_modules/memory/experiment/experiment_log/#labridge.func_modules.memory.experiment.experiment_log.ExperimentLog.get_all_experiments_with_description","title":"<code>labridge.func_modules.memory.experiment.experiment_log.ExperimentLog.get_all_experiments_with_description()</code>","text":"<p>Get all experiment names and their descriptions.</p> Source code in <code>labridge\\func_modules\\memory\\experiment\\experiment_log.py</code> <pre><code>def get_all_experiments_with_description(self) -&gt; Optional[Dict[str, str]]:\n\tr\"\"\" Get all experiment names and their descriptions. \"\"\"\n\troot_node = self._get_node(node_id=INIT_NODE_NAME)\n\texpr_list = root_node.child_nodes\n\n\texperiments = {}\n\tif expr_list:\n\t\tfor child in expr_list:\n\t\t\texpr_id = child.node_id\n\t\t\texpr_node = self._get_node(node_id=expr_id)\n\t\t\texperiments[expr_id] = expr_node.text\n\t\treturn experiments\n\treturn None\n</code></pre>"},{"location":"code_docs/func_modules/memory/experiment/experiment_log/#labridge.func_modules.memory.experiment.experiment_log.ExperimentLog.get_expr_log_node_ids","title":"<code>labridge.func_modules.memory.experiment.experiment_log.ExperimentLog.get_expr_log_node_ids(experiment_name)</code>","text":"<p>Get the log node ids of a specific experiment.</p> PARAMETER DESCRIPTION <code>experiment_name</code> <p>The experiment name.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>List[str]</code> <p>List[str]: The log node ids of the experiment node.</p> Source code in <code>labridge\\func_modules\\memory\\experiment\\experiment_log.py</code> <pre><code>def get_expr_log_node_ids(self, experiment_name: str) -&gt; List[str]:\n\tr\"\"\"\n\tGet the log node ids of a specific experiment.\n\n\tArgs:\n\t\texperiment_name (str): The experiment name.\n\n\tReturns:\n\t\tList[str]: The log node ids of the experiment node.\n\t\"\"\"\n\texpr_node = self._get_node(node_id=experiment_name)\n\treturn [log_node.node_id for log_node in expr_node.child_nodes]\n</code></pre>"},{"location":"code_docs/func_modules/memory/experiment/experiment_log/#labridge.func_modules.memory.experiment.experiment_log.ExperimentLog.get_recent_experiment","title":"<code>labridge.func_modules.memory.experiment.experiment_log.ExperimentLog.get_recent_experiment()</code>","text":"<p>Get the most recent experiment name.</p> Source code in <code>labridge\\func_modules\\memory\\experiment\\experiment_log.py</code> <pre><code>def get_recent_experiment(self) -&gt; Optional[str]:\n\tr\"\"\" Get the most recent experiment name. \"\"\"\n\trecent_node = self._get_node(node_id=RECENT_EXPERIMENT_NODE_NAME)\n\tmetadata = recent_node.metadata\n\n\texpr_name = metadata[RECENT_EXPERIMENT_NAME_KEY]\n\tif expr_name is None:\n\t\treturn None\n\n\tstart_date_str, start_time_str = metadata[RECENT_EXPERIMENT_START_TIME_KEY]\n\tend_date_str, end_time_str = metadata[RECENT_EXPERIMENT_END_TIME_KEY]\n\n\ttry:\n\t\tstart = str_to_datetime(date_str=start_date_str, time_str=start_time_str)\n\t\tend = str_to_datetime(date_str=end_date_str, time_str=end_time_str)\n\t\tdate, h_m_s = get_time()\n\t\tcurrent = str_to_datetime(date_str=date, time_str=h_m_s)\n\t\tif start &lt;= current &lt;= end:\n\t\t\treturn expr_name\n\t\treturn None\n\texcept Exception as e:\n\t\tprint(f\"Error in get_recent_experiment: {e}\")\n\t\treturn None\n</code></pre>"},{"location":"code_docs/func_modules/memory/experiment/experiment_log/#labridge.func_modules.memory.experiment.experiment_log.ExperimentLog.is_expr_exist","title":"<code>labridge.func_modules.memory.experiment.experiment_log.ExperimentLog.is_expr_exist(experiment_name)</code>","text":"<p>Whether an experiment exists in the storage.</p> PARAMETER DESCRIPTION <code>experiment_name</code> <p>The experiment name.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>Whether the experiment exists.</p> <p> TYPE: <code>bool</code> </p> Source code in <code>labridge\\func_modules\\memory\\experiment\\experiment_log.py</code> <pre><code>def is_expr_exist(self, experiment_name: str) -&gt; bool:\n\tr\"\"\"\n\tWhether an experiment exists in the storage.\n\n\tArgs:\n\t\texperiment_name (str): The experiment name.\n\n\tReturns:\n\t\tbool: Whether the experiment exists.\n\t\"\"\"\n\troot_node = self._get_node(node_id=INIT_NODE_NAME)\n\texpr_list = root_node.relationships[NodeRelationship.CHILD]\n\treturn experiment_name in [expr.node_id for expr in expr_list]\n</code></pre>"},{"location":"code_docs/func_modules/memory/experiment/experiment_log/#labridge.func_modules.memory.experiment.experiment_log.ExperimentLog.persist","title":"<code>labridge.func_modules.memory.experiment.experiment_log.ExperimentLog.persist(persist_dir=None)</code>","text":"<p>Persist to disk.</p> PARAMETER DESCRIPTION <code>persist_dir</code> <p>The persist directory. If not given, use <code>self.directory</code>.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> Source code in <code>labridge\\func_modules\\memory\\experiment\\experiment_log.py</code> <pre><code>def persist(self, persist_dir: str = None):\n\tr\"\"\"\n\tPersist to disk.\n\n\tArgs:\n\t\tpersist_dir (str): The persist directory. If not given, use `self.directory`.\n\t\"\"\"\n\tpersist_dir = persist_dir or self.persist_dir\n\tfs = fsspec.filesystem(\"file\")\n\tif not fs.exists(persist_dir):\n\t\tfs.makedirs(persist_dir)\n\tself.vector_index.storage_context.persist(persist_dir=persist_dir)\n</code></pre>"},{"location":"code_docs/func_modules/memory/experiment/experiment_log/#labridge.func_modules.memory.experiment.experiment_log.ExperimentLog.put","title":"<code>labridge.func_modules.memory.experiment.experiment_log.ExperimentLog.put(experiment_name, log_str, attached_file_path=None)</code>","text":"<p>Put in an experiment log into a specific experiment store.</p> <p>These operations are done:</p> <ul> <li>last_log_node -&gt; set_next(new_log_node)</li> <li>new_log_node -&gt; set_previous(last_log_node)</li> <li>last_store_node -&gt; set_content(new_log_node.node_id)</li> <li>experiment_node -&gt; add_child(new_log_node)</li> </ul> PARAMETER DESCRIPTION <code>experiment_name</code> <p>An existing experiment name.</p> <p> TYPE: <code>str</code> </p> <code>log_str</code> <p>The experiment log string to be put in.</p> <p> TYPE: <code>str</code> </p> <code>attached_file_path</code> <p>The path of the attached file. Defaults to None.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> Source code in <code>labridge\\func_modules\\memory\\experiment\\experiment_log.py</code> <pre><code>def put(\n\tself,\n\texperiment_name: str,\n\tlog_str: str,\n\tattached_file_path: str = None,\n):\n\tr\"\"\"\n\tPut in an experiment log into a specific experiment store.\n\n\tThese operations are done:\n\n\t- last_log_node -&gt; set_next(new_log_node)\n\t- new_log_node -&gt; set_previous(last_log_node)\n\t- last_store_node -&gt; set_content(new_log_node.node_id)\n\t- experiment_node -&gt; add_child(new_log_node)\n\n\tArgs:\n\t\texperiment_name (str): An existing experiment name.\n\t\tlog_str (str): The experiment log string to be put in.\n\t\tattached_file_path (str): The path of the attached file. Defaults to None.\n\t\"\"\"\n\t# TODO: Support files.\n\troot_node = self._get_node(node_id=INIT_NODE_NAME)\n\texperiments = root_node.child_nodes\n\tif experiments is None or experiment_name not in [expr.node_id for expr in experiments]:\n\t\traise ValueError(f\"The experiment {experiment_name} of user {self.user_id} does not exist.\")\n\n\textra_metadata = None\n\tif attached_file_path is not None:\n\t\trecord_path = self.record_attachment(file_path=attached_file_path)\n\t\textra_metadata = {\n\t\t\tEXPERIMENT_LOG_ATTACHMENT_KEY: record_path,\n\t\t}\n\n\tnew_log_node = self._new_node(\n\t\ttext=log_str,\n\t\tnode_type=LOG_NODE_TYPE,\n\t\textra_metadata=extra_metadata,\n\t)\n\texpr_node = self._get_node(node_id=experiment_name)\n\tlast_store_name = f\"{experiment_name}_{EXPERIMENT_LAST_NODE_ID_PREFIX}\"\n\tlast_store_node = self._get_node(node_id=last_store_name)\n\tlast_log_id = last_store_node.text\n\tlast_log_node = self._get_node(last_log_id)\n\tlast_log_node.relationships[NodeRelationship.NEXT] = RelatedNodeInfo(\n\t\tnode_id=new_log_node.node_id\n\t)\n\tnew_log_node.relationships[NodeRelationship.PREVIOUS] = RelatedNodeInfo(\n\t\tnode_id=last_log_node.node_id\n\t)\n\tnew_log_node.relationships[NodeRelationship.PARENT] = RelatedNodeInfo(\n\t\tnode_id=expr_node.node_id\n\t)\n\tlast_store_node.set_content(new_log_node.node_id)\n\tself._update_node(node_id=last_log_id, node=last_log_node)\n\tself._update_node(node_id=last_store_name, node=last_store_node)\n\n\tlog_node_list = expr_node.child_nodes or []\n\tlog_node_list.append(\n\t\tRelatedNodeInfo(node_id=new_log_node.node_id)\n\t)\n\texpr_node.relationships[NodeRelationship.CHILD] = log_node_list\n\tself._update_node(node_id=experiment_name, node=expr_node)\n\tprint(\"Parent: \", new_log_node.parent_node.node_id)\n\tself.vector_index.insert_nodes([new_log_node])\n</code></pre>"},{"location":"code_docs/func_modules/memory/experiment/experiment_log/#labridge.func_modules.memory.experiment.experiment_log.ExperimentLog.set_recent_experiment","title":"<code>labridge.func_modules.memory.experiment.experiment_log.ExperimentLog.set_recent_experiment(experiment_name, start_date, start_time, end_date, end_time)</code>","text":"<p>Set the most recent (or actually, in progress) experiment and its duration.</p> PARAMETER DESCRIPTION <code>experiment_name</code> <p>The experiment name to be set in progress.</p> <p> TYPE: <code>str</code> </p> <code>start_date</code> <p>The formatted string of the start date of the experiment.</p> <p> TYPE: <code>str</code> </p> <code>start_time</code> <p>The formatted string of the start time of the experiment.</p> <p> TYPE: <code>str</code> </p> <code>end_date</code> <p>The formatted string of the end date of the experiment.</p> <p> TYPE: <code>str</code> </p> <code>end_time</code> <p>The formatted string of the end time of the experiment.</p> <p> TYPE: <code>str</code> </p> Source code in <code>labridge\\func_modules\\memory\\experiment\\experiment_log.py</code> <pre><code>def set_recent_experiment(\n\tself,\n\texperiment_name: str,\n\tstart_date: str,\n\tstart_time: str,\n\tend_date: str,\n\tend_time: str,\n):\n\tr\"\"\"\n\tSet the most recent (or actually, in progress) experiment and its duration.\n\n\tArgs:\n\t\texperiment_name (str): The experiment name to be set in progress.\n\t\tstart_date (str): The formatted string of the start date of the experiment.\n\t\tstart_time (str): The formatted string of the start time of the experiment.\n\t\tend_date (str): The formatted string of the end date of the experiment.\n\t\tend_time (str): The formatted string of the end time of the experiment.\n\t\"\"\"\n\texpr_list = self.get_all_experiments()\n\tif experiment_name not in expr_list:\n\t\traise ValueError(\n\t\t\tf\"The experiment {experiment_name} \" \n\t\t\tf\"does not exist in the experiment log memory of the user {self.user_id}\"\n\t\t)\n\n\trecent_node = self._get_node(node_id=RECENT_EXPERIMENT_NODE_NAME)\n\trecent_node.metadata[RECENT_EXPERIMENT_START_TIME_KEY] = (\n\t\tstart_date, start_time\n\t)\n\trecent_node.metadata[RECENT_EXPERIMENT_END_TIME_KEY] = (\n\t\tend_date, end_time\n\t)\n\trecent_node.metadata[RECENT_EXPERIMENT_NAME_KEY] = experiment_name\n\tself._update_node(\n\t\tnode_id=RECENT_EXPERIMENT_NODE_NAME,\n\t\tnode=recent_node,\n\t)\n</code></pre>"},{"location":"code_docs/func_modules/memory/experiment/experiment_log/#labridge.func_modules.memory.experiment.experiment_log.ExperimentLog.update","title":"<code>labridge.func_modules.memory.experiment.experiment_log.ExperimentLog.update()</code>","text":"<p>Reload from the disk.</p> Source code in <code>labridge\\func_modules\\memory\\experiment\\experiment_log.py</code> <pre><code>def update(self):\n\tr\"\"\" Reload from the disk. \"\"\"\n\treturn self.from_user_id(\n\t\tuser_id=self.user_id,\n\t\tembed_model=self.vector_index._embed_model,\n\t)\n</code></pre>"},{"location":"code_docs/func_modules/memory/experiment/retrieve_log/","title":"Retrieve log","text":""},{"location":"code_docs/func_modules/memory/experiment/retrieve_log/#labridge.func_modules.memory.experiment.retrieve_log","title":"<code>labridge.func_modules.memory.experiment.retrieve_log</code>","text":""},{"location":"code_docs/func_modules/memory/experiment/retrieve_log/#labridge.func_modules.memory.experiment.retrieve_log.ExperimentLogRetriever","title":"<code>labridge.func_modules.memory.experiment.retrieve_log.ExperimentLogRetriever</code>","text":"<p>               Bases: <code>LogBaseRetriever</code></p> <p>This class retrieve in a specific user's experiment logs.</p> <p>The docstring of the method <code>retrieve</code> or <code>aretrieve</code> are used as tool description of the corresponding retriever tool.</p> PARAMETER DESCRIPTION <code>embed_model</code> <p>The embed model. Defaults to None. If set to None, the Settings.embed_model will be used.</p> <p> TYPE: <code>BaseEmbedding</code> DEFAULT: <code>None</code> </p> <code>final_use_context</code> <p>Whether to add the context nodes of the retrieved nodes to the final results. Defaults to True.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>relevant_top_k</code> <p>The <code>relevant_top_k</code> log nodes will be selected as the retrieved nodes. Defaults to <code>EXPERIMENT_LOG_RELEVANT_TOP_K</code>.</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> Source code in <code>labridge\\func_modules\\memory\\experiment\\retrieve_log.py</code> <pre><code>class ExperimentLogRetriever(LogBaseRetriever):\n\tr\"\"\"\n\tThis class retrieve in a specific user's experiment logs.\n\n\tThe docstring of the method `retrieve` or `aretrieve` are used as tool description of the\n\tcorresponding retriever tool.\n\n\tArgs:\n\t\tembed_model (BaseEmbedding): The embed model. Defaults to None.\n\t\t\tIf set to None, the Settings.embed_model will be used.\n\t\tfinal_use_context (bool): Whether to add the context nodes of the retrieved nodes to the final results.\n\t\t\tDefaults to True.\n\t\trelevant_top_k (int): The `relevant_top_k` log nodes will be selected as the retrieved nodes.\n\t\t\tDefaults to `EXPERIMENT_LOG_RELEVANT_TOP_K`.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tembed_model: BaseEmbedding = None,\n\t\tfinal_use_context: bool = True,\n\t\trelevant_top_k: int = None,\n\t):\n\t\trelevant_top_k = relevant_top_k or EXPERIMENT_LOG_RELEVANT_TOP_K\n\t\tsuper().__init__(\n\t\t\tembed_model=embed_model,\n\t\t\tfinal_use_context=final_use_context,\n\t\t\trelevant_top_k=relevant_top_k,\n\t\t)\n\n\tdef get_memory_vector_index(self) -&gt; VectorStoreIndex:\n\t\tr\"\"\" Get the vector index. \"\"\"\n\t\treturn self.memory.vector_index\n\n\tdef get_memory_vector_retriever(self) -&gt; VectorIndexRetriever:\n\t\tr\"\"\" Get the default vector index retriever, with default similarity_top_k and no date filters. \"\"\"\n\t\tmemory_retriever = self.memory.vector_index.as_retriever(\n\t\t\tsimilarity_top_k=self.relevant_top_k,\n\t\t\tfilters=None,\n\t\t)\n\t\treturn memory_retriever\n\n\tdef reset_vector_retriever(self):\n\t\tr\"\"\"\n\t\tReset the vector index retriever to defaults.\n\t\tSpecifically, with no date filters and confined node ids.\n\t\t\"\"\"\n\t\tself.memory_vector_retriever._filters = [self._log_node_filter(),]\n\t\tself.memory_vector_retriever._node_ids = None\n\n\t@dispatcher.span\n\tdef retrieve(\n\t\tself,\n\t\titem_to_be_retrieved: str,\n\t\tmemory_id: str,\n\t\tstart_date: str = None,\n\t\tend_date: str = None,\n\t\texperiment_name: str = None,\n\t\t**kwargs: Any,\n\t) -&gt; List[NodeWithScore]:\n\t\tr\"\"\"\n\t\tThis tool is used to retrieve experiment logs of a user.\n\t\tUse this tool to help you to answer questions about experimental records.\n\n\t\tArgs:\n\t\t\titem_to_be_retrieved (str): This argument is necessary.\n\t\t\t\tIt denotes things that you want to retrieve in the chat history memory.\n\t\t\tmemory_id (str): This argument is necessary.\n\t\t\t\tIt is the user_id of a lab member.\n\t\t\tstart_date (str): This argument is optional.\n\t\t\t\tIt denotes the start date in the format 'Year-Month-Day'.\n\t\t\t\tIf both start_date and end_date are specified, only logs which are recorded between the\n\t\t\t\tstart_date and end_date will be retrieved.\n\t\t\tend_date (str): This argument is optional.\n\t\t\t\tIt denotes the end date in the format 'Year-Month-Day'.\n\t\t\texperiment_name (str): This argument is optional.\n\t\t\t\tIt is the name of a specific experiment.\n\t\t\t\tIf it is specified and is valid, only logs of this experiment will be retrieved.\n\t\t\tkwargs: Other arguments will be ignored.\n\n\t\tReturns:\n\t\t\tRetrieved experiment logs.\n\t\t\"\"\"\n\t\tif self.memory is None or self.memory.user_id != memory_id:\n\t\t\tself.memory = ExperimentLog.from_user_id(\n\t\t\t\tuser_id=memory_id,\n\t\t\t\tembed_model=self.embed_model,\n\t\t\t)\n\t\t\tself.memory_vector_retriever = self.get_memory_vector_retriever()\n\n\t\tself.reset_vector_retriever()\n\n\t\tif experiment_name is None or not self.memory.is_expr_exist(experiment_name):\n\t\t\tretrieve_node_ids = None\n\t\telse:\n\t\t\tretrieve_node_ids = self.memory.get_expr_log_node_ids(experiment_name)\n\n\t\tfilters = [self._log_node_filter(), ]\n\t\tif None not in [start_date, end_date]:\n\t\t\t# get the candidate date list.\n\t\t\tdate_list = self._parse_date(start_date_str=start_date, end_date_str=end_date)\n\t\t\tfilters.append(\n\t\t\t\tself.get_date_filter(date_list=date_list),\n\t\t\t)\n\n\t\tmetadata_filters = MetadataFilters(filters=filters)\n\n\t\tself.memory_vector_retriever._filters = metadata_filters\n\t\tself.memory_vector_retriever._node_ids = retrieve_node_ids\n\n\t\t# TODO: hybrid retrieve: add retrieve experiment.\n\t\tlog_nodes = self.memory_vector_retriever.retrieve(item_to_be_retrieved)\n\n\t\tif self.final_use_context:\n\t\t\tlog_nodes = self._add_context(content_nodes=log_nodes)\n\t\treturn log_nodes\n\n\t@dispatcher.span\n\tasync def aretrieve(\n\t\tself,\n\t\titem_to_be_retrieved: str,\n\t\tmemory_id: str,\n\t\tstart_date: str = None,\n\t\tend_date: str = None,\n\t\texperiment_name: str = None,\n\t\t**kwargs: Any,\n\t) -&gt; List[NodeWithScore]:\n\t\tr\"\"\"\n\t\tThis tool is used to retrieve relevant experiment logs in a certain experiment log memory.\n\n\t\tArgs:\n\t\t\titem_to_be_retrieved (str): This argument is necessary.\n\t\t\t\tIt denotes things that you want to retrieve in the chat history memory.\n\t\t\tmemory_id (str): This argument is necessary.\n\t\t\t\tIt is the user_id of a lab member.\n\t\t\tstart_date (str): This argument is optional.\n\t\t\t\tIt denotes the start date in the format 'Year-Month-Day'.\n\t\t\t\tIf both start_date and end_date are specified, only logs which are recorded between the\n\t\t\t\tstart_date and end_date will be retrieved.\n\t\t\tend_date (str): This argument is optional.\n\t\t\t\tIt denotes the end date in the format 'Year-Month-Day'.\n\t\t\texperiment_name (str): This argument is optional.\n\t\t\t\tIt is the name of a specific experiment.\n\t\t\t\tIf it is specified and is valid, only logs of this experiment will be retrieved.\n\t\t\tkwargs: Other arguments will be ignored.\n\n\t\tReturns:\n\t\t\tRetrieved experiment logs.\n\t\t\"\"\"\n\t\tif self.memory is None or self.memory.user_id != memory_id:\n\t\t\tself.memory = ExperimentLog.from_user_id(\n\t\t\t\tuser_id=memory_id,\n\t\t\t\tembed_model=self.embed_model,\n\t\t\t)\n\t\t\tself.memory_vector_retriever = self.get_memory_vector_retriever()\n\t\tself.reset_vector_retriever()\n\n\t\tif experiment_name is None or not self.memory.is_expr_exist(experiment_name):\n\t\t\tretrieve_node_ids = None\n\t\telse:\n\t\t\tretrieve_node_ids = self.memory.get_expr_log_node_ids(experiment_name)\n\n\t\tfilters = [self._log_node_filter(), ]\n\t\tif None not in [start_date, end_date]:\n\t\t\t# get the candidate date list.\n\t\t\tdate_list = self._parse_date(start_date_str=start_date, end_date_str=end_date)\n\t\t\tfilters.append(\n\t\t\t\tself.get_date_filter(date_list=date_list)\n\t\t\t)\n\n\t\tmetadata_filters = MetadataFilters(filters=filters)\n\n\t\tself.memory_vector_retriever._filters = metadata_filters\n\t\tself.memory_vector_retriever._node_ids = retrieve_node_ids\n\t\tlog_nodes = await self.memory_vector_retriever.aretrieve(item_to_be_retrieved)\n\n\t\tif self.final_use_context:\n\t\t\tlog_nodes = self._add_context(content_nodes=log_nodes)\n\t\treturn log_nodes\n</code></pre>"},{"location":"code_docs/func_modules/memory/experiment/retrieve_log/#labridge.func_modules.memory.experiment.retrieve_log.ExperimentLogRetriever.aretrieve","title":"<code>labridge.func_modules.memory.experiment.retrieve_log.ExperimentLogRetriever.aretrieve(item_to_be_retrieved, memory_id, start_date=None, end_date=None, experiment_name=None, **kwargs)</code>  <code>async</code>","text":"<p>This tool is used to retrieve relevant experiment logs in a certain experiment log memory.</p> PARAMETER DESCRIPTION <code>item_to_be_retrieved</code> <p>This argument is necessary. It denotes things that you want to retrieve in the chat history memory.</p> <p> TYPE: <code>str</code> </p> <code>memory_id</code> <p>This argument is necessary. It is the user_id of a lab member.</p> <p> TYPE: <code>str</code> </p> <code>start_date</code> <p>This argument is optional. It denotes the start date in the format 'Year-Month-Day'. If both start_date and end_date are specified, only logs which are recorded between the start_date and end_date will be retrieved.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>end_date</code> <p>This argument is optional. It denotes the end date in the format 'Year-Month-Day'.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>experiment_name</code> <p>This argument is optional. It is the name of a specific experiment. If it is specified and is valid, only logs of this experiment will be retrieved.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Other arguments will be ignored.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>List[NodeWithScore]</code> <p>Retrieved experiment logs.</p> Source code in <code>labridge\\func_modules\\memory\\experiment\\retrieve_log.py</code> <pre><code>@dispatcher.span\nasync def aretrieve(\n\tself,\n\titem_to_be_retrieved: str,\n\tmemory_id: str,\n\tstart_date: str = None,\n\tend_date: str = None,\n\texperiment_name: str = None,\n\t**kwargs: Any,\n) -&gt; List[NodeWithScore]:\n\tr\"\"\"\n\tThis tool is used to retrieve relevant experiment logs in a certain experiment log memory.\n\n\tArgs:\n\t\titem_to_be_retrieved (str): This argument is necessary.\n\t\t\tIt denotes things that you want to retrieve in the chat history memory.\n\t\tmemory_id (str): This argument is necessary.\n\t\t\tIt is the user_id of a lab member.\n\t\tstart_date (str): This argument is optional.\n\t\t\tIt denotes the start date in the format 'Year-Month-Day'.\n\t\t\tIf both start_date and end_date are specified, only logs which are recorded between the\n\t\t\tstart_date and end_date will be retrieved.\n\t\tend_date (str): This argument is optional.\n\t\t\tIt denotes the end date in the format 'Year-Month-Day'.\n\t\texperiment_name (str): This argument is optional.\n\t\t\tIt is the name of a specific experiment.\n\t\t\tIf it is specified and is valid, only logs of this experiment will be retrieved.\n\t\tkwargs: Other arguments will be ignored.\n\n\tReturns:\n\t\tRetrieved experiment logs.\n\t\"\"\"\n\tif self.memory is None or self.memory.user_id != memory_id:\n\t\tself.memory = ExperimentLog.from_user_id(\n\t\t\tuser_id=memory_id,\n\t\t\tembed_model=self.embed_model,\n\t\t)\n\t\tself.memory_vector_retriever = self.get_memory_vector_retriever()\n\tself.reset_vector_retriever()\n\n\tif experiment_name is None or not self.memory.is_expr_exist(experiment_name):\n\t\tretrieve_node_ids = None\n\telse:\n\t\tretrieve_node_ids = self.memory.get_expr_log_node_ids(experiment_name)\n\n\tfilters = [self._log_node_filter(), ]\n\tif None not in [start_date, end_date]:\n\t\t# get the candidate date list.\n\t\tdate_list = self._parse_date(start_date_str=start_date, end_date_str=end_date)\n\t\tfilters.append(\n\t\t\tself.get_date_filter(date_list=date_list)\n\t\t)\n\n\tmetadata_filters = MetadataFilters(filters=filters)\n\n\tself.memory_vector_retriever._filters = metadata_filters\n\tself.memory_vector_retriever._node_ids = retrieve_node_ids\n\tlog_nodes = await self.memory_vector_retriever.aretrieve(item_to_be_retrieved)\n\n\tif self.final_use_context:\n\t\tlog_nodes = self._add_context(content_nodes=log_nodes)\n\treturn log_nodes\n</code></pre>"},{"location":"code_docs/func_modules/memory/experiment/retrieve_log/#labridge.func_modules.memory.experiment.retrieve_log.ExperimentLogRetriever.get_memory_vector_index","title":"<code>labridge.func_modules.memory.experiment.retrieve_log.ExperimentLogRetriever.get_memory_vector_index()</code>","text":"<p>Get the vector index.</p> Source code in <code>labridge\\func_modules\\memory\\experiment\\retrieve_log.py</code> <pre><code>def get_memory_vector_index(self) -&gt; VectorStoreIndex:\n\tr\"\"\" Get the vector index. \"\"\"\n\treturn self.memory.vector_index\n</code></pre>"},{"location":"code_docs/func_modules/memory/experiment/retrieve_log/#labridge.func_modules.memory.experiment.retrieve_log.ExperimentLogRetriever.get_memory_vector_retriever","title":"<code>labridge.func_modules.memory.experiment.retrieve_log.ExperimentLogRetriever.get_memory_vector_retriever()</code>","text":"<p>Get the default vector index retriever, with default similarity_top_k and no date filters.</p> Source code in <code>labridge\\func_modules\\memory\\experiment\\retrieve_log.py</code> <pre><code>def get_memory_vector_retriever(self) -&gt; VectorIndexRetriever:\n\tr\"\"\" Get the default vector index retriever, with default similarity_top_k and no date filters. \"\"\"\n\tmemory_retriever = self.memory.vector_index.as_retriever(\n\t\tsimilarity_top_k=self.relevant_top_k,\n\t\tfilters=None,\n\t)\n\treturn memory_retriever\n</code></pre>"},{"location":"code_docs/func_modules/memory/experiment/retrieve_log/#labridge.func_modules.memory.experiment.retrieve_log.ExperimentLogRetriever.reset_vector_retriever","title":"<code>labridge.func_modules.memory.experiment.retrieve_log.ExperimentLogRetriever.reset_vector_retriever()</code>","text":"<p>Reset the vector index retriever to defaults. Specifically, with no date filters and confined node ids.</p> Source code in <code>labridge\\func_modules\\memory\\experiment\\retrieve_log.py</code> <pre><code>def reset_vector_retriever(self):\n\tr\"\"\"\n\tReset the vector index retriever to defaults.\n\tSpecifically, with no date filters and confined node ids.\n\t\"\"\"\n\tself.memory_vector_retriever._filters = [self._log_node_filter(),]\n\tself.memory_vector_retriever._node_ids = None\n</code></pre>"},{"location":"code_docs/func_modules/memory/experiment/retrieve_log/#labridge.func_modules.memory.experiment.retrieve_log.ExperimentLogRetriever.retrieve","title":"<code>labridge.func_modules.memory.experiment.retrieve_log.ExperimentLogRetriever.retrieve(item_to_be_retrieved, memory_id, start_date=None, end_date=None, experiment_name=None, **kwargs)</code>","text":"<p>This tool is used to retrieve experiment logs of a user. Use this tool to help you to answer questions about experimental records.</p> PARAMETER DESCRIPTION <code>item_to_be_retrieved</code> <p>This argument is necessary. It denotes things that you want to retrieve in the chat history memory.</p> <p> TYPE: <code>str</code> </p> <code>memory_id</code> <p>This argument is necessary. It is the user_id of a lab member.</p> <p> TYPE: <code>str</code> </p> <code>start_date</code> <p>This argument is optional. It denotes the start date in the format 'Year-Month-Day'. If both start_date and end_date are specified, only logs which are recorded between the start_date and end_date will be retrieved.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>end_date</code> <p>This argument is optional. It denotes the end date in the format 'Year-Month-Day'.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>experiment_name</code> <p>This argument is optional. It is the name of a specific experiment. If it is specified and is valid, only logs of this experiment will be retrieved.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Other arguments will be ignored.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>List[NodeWithScore]</code> <p>Retrieved experiment logs.</p> Source code in <code>labridge\\func_modules\\memory\\experiment\\retrieve_log.py</code> <pre><code>@dispatcher.span\ndef retrieve(\n\tself,\n\titem_to_be_retrieved: str,\n\tmemory_id: str,\n\tstart_date: str = None,\n\tend_date: str = None,\n\texperiment_name: str = None,\n\t**kwargs: Any,\n) -&gt; List[NodeWithScore]:\n\tr\"\"\"\n\tThis tool is used to retrieve experiment logs of a user.\n\tUse this tool to help you to answer questions about experimental records.\n\n\tArgs:\n\t\titem_to_be_retrieved (str): This argument is necessary.\n\t\t\tIt denotes things that you want to retrieve in the chat history memory.\n\t\tmemory_id (str): This argument is necessary.\n\t\t\tIt is the user_id of a lab member.\n\t\tstart_date (str): This argument is optional.\n\t\t\tIt denotes the start date in the format 'Year-Month-Day'.\n\t\t\tIf both start_date and end_date are specified, only logs which are recorded between the\n\t\t\tstart_date and end_date will be retrieved.\n\t\tend_date (str): This argument is optional.\n\t\t\tIt denotes the end date in the format 'Year-Month-Day'.\n\t\texperiment_name (str): This argument is optional.\n\t\t\tIt is the name of a specific experiment.\n\t\t\tIf it is specified and is valid, only logs of this experiment will be retrieved.\n\t\tkwargs: Other arguments will be ignored.\n\n\tReturns:\n\t\tRetrieved experiment logs.\n\t\"\"\"\n\tif self.memory is None or self.memory.user_id != memory_id:\n\t\tself.memory = ExperimentLog.from_user_id(\n\t\t\tuser_id=memory_id,\n\t\t\tembed_model=self.embed_model,\n\t\t)\n\t\tself.memory_vector_retriever = self.get_memory_vector_retriever()\n\n\tself.reset_vector_retriever()\n\n\tif experiment_name is None or not self.memory.is_expr_exist(experiment_name):\n\t\tretrieve_node_ids = None\n\telse:\n\t\tretrieve_node_ids = self.memory.get_expr_log_node_ids(experiment_name)\n\n\tfilters = [self._log_node_filter(), ]\n\tif None not in [start_date, end_date]:\n\t\t# get the candidate date list.\n\t\tdate_list = self._parse_date(start_date_str=start_date, end_date_str=end_date)\n\t\tfilters.append(\n\t\t\tself.get_date_filter(date_list=date_list),\n\t\t)\n\n\tmetadata_filters = MetadataFilters(filters=filters)\n\n\tself.memory_vector_retriever._filters = metadata_filters\n\tself.memory_vector_retriever._node_ids = retrieve_node_ids\n\n\t# TODO: hybrid retrieve: add retrieve experiment.\n\tlog_nodes = self.memory_vector_retriever.retrieve(item_to_be_retrieved)\n\n\tif self.final_use_context:\n\t\tlog_nodes = self._add_context(content_nodes=log_nodes)\n\treturn log_nodes\n</code></pre>"},{"location":"code_docs/func_modules/paper/download/arxiv/","title":"Arxiv","text":""},{"location":"code_docs/func_modules/paper/download/arxiv/#labridge.func_modules.paper.download.arxiv","title":"<code>labridge.func_modules.paper.download.arxiv</code>","text":""},{"location":"code_docs/func_modules/paper/download/arxiv/#labridge.func_modules.paper.download.arxiv.ArxivCategory","title":"<code>labridge.func_modules.paper.download.arxiv.ArxivCategory</code>","text":"<p>               Bases: <code>object</code></p> <p>The research fields category from arXiv.</p> ATTRIBUTE DESCRIPTION <code>category</code> <p>a dict containing sub dicts. - key: the research fields group name. - value: a sub dict containing the research fields categories. Each sub dict contains:</p> <pre><code>    - key: the research fields category name.\n    - value: the description of this category.\n</code></pre> <p> TYPE: <code>dict</code> </p> <code>persist_path</code> <p>the storing path of the category dict.</p> <p> TYPE: <code>str</code> </p> <code>arxiv_category_url</code> <p>the url of the arxiv category.</p> <p> TYPE: <code>str</code> </p> PARAMETER DESCRIPTION <code>persist_path</code> <p>the storing path of the category dict.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> Source code in <code>labridge\\func_modules\\paper\\download\\arxiv.py</code> <pre><code>class ArxivCategory(object):\n\tr\"\"\"\n\tThe research fields category from arXiv.\n\n\tAttributes:\n\t\tcategory (dict): a dict containing sub dicts.\n\t\t\t- key: the research fields group name.\n\t\t\t- value: a sub dict containing the research fields categories.\n\t\t\tEach sub dict contains:\n\n\t\t\t\t- key: the research fields category name.\n\t\t\t\t- value: the description of this category.\n\t\tpersist_path (str): the storing path of the category dict.\n\t\tarxiv_category_url (str): the url of the arxiv category.\n\n\tArgs:\n\t\tpersist_path (str): the storing path of the category dict.\n\t\"\"\"\n\tcategory: dict\n\tpersist_path: str\n\tarxiv_category_url: str = \"https://arxiv.org/category_taxonomy\"\n\n\tdef __init__(self, persist_path: Optional[str] = None):\n\t\tself.persist_path = persist_path or self._default_persist_path()\n\t\tif Path(self.persist_path).exists():\n\t\t\tself.category = self.load_category()\n\t\telse:\n\t\t\tself.category = self.category_from_arxiv()\n\t\t\tself.save_category()\n\n\tdef _default_persist_path(self) -&gt; str:\n\t\tr\"\"\" Default persist path. \"\"\"\n\t\troot = Path(__file__)\n\t\tfor i in range(5):\n\t\t\troot = root.parent\n\t\treturn str(root / ARXIV_CATEGORY_PATH)\n\n\tdef category_from_arxiv(self, arxiv_category_url: Optional[str] = None) -&gt; dict:\n\t\tr\"\"\"\n\t\tParse categories from arxiv.\n\n\t\tArgs:\n\t\t\tarxiv_category_url (Optional[str]): Generally, the url is \"https://arxiv.org/category_taxonomy\".\n\n\t\tReturns:\n\t\t\tdict: The category dict in the following format:\n\t\t\t\t`{Group: {Category: description (str)}}`\n\t\t\"\"\"\n\t\tarxiv_category_url = arxiv_category_url or self.arxiv_category_url\n\t\tweb_reader = SimpleWebPageReader(html_to_text=True)\n\t\tweb_text = web_reader.load_data([arxiv_category_url])\n\t\ttext = web_text[0].text\n\t\tfields_str = text.split(\"Category description if available\")[1]\n\t\tfields_dict= dict()\n\t\tline_list = fields_str.split('\\n')\n\n\t\tdescription = []\n\t\tgroup = None\n\t\tcategory = None\n\t\tfor line in line_list:\n\t\t\tline_items = line.split()\n\t\t\tif line_items and line_items[0] == \"##\":\n\t\t\t\tgroup = \" \".join(line_items[1:])\n\t\t\t\tfields_dict[group] = {}\n\t\t\t\tcategory = None\n\t\t\telif line_items and line_items[0] == \"####\":\n\t\t\t\tif category is not None:\n\t\t\t\t\tfields_dict[group][category] = \" \".join(description)\n\t\t\t\tcategory = line_items[1]\n\t\t\t\tdescription = [f\"{' '.join(line_items[2:])}:\"]\n\t\t\telse:\n\t\t\t\tdescription.append(line)\n\n\t\tfields_dict[group][category] = \" \".join(description)\n\n\t\t# Extra information.\n\t\tfor group in Extra_Descriptions.keys():\n\t\t\tfor category in Extra_Descriptions[group].keys():\n\t\t\t\tfields_dict[group][category] += Extra_Descriptions[group][category]\n\n\t\treturn fields_dict\n\n\tdef load_category(self, persist_path: Optional[str] = None, fs: Optional[fsspec.AbstractFileSystem] = None):\n\t\t\"\"\"Load the research categories from a persist path.\"\"\"\n\t\tfs = fs or fsspec.filesystem(\"file\")\n\t\tpersist_path = persist_path or self.persist_path\n\t\twith fs.open(persist_path, \"rb\") as f:\n\t\t\tcategory = json.load(f)\n\t\treturn category\n\n\tdef save_category(self, persist_path: Optional[str] = None, fs: Optional[fsspec.AbstractFileSystem] = None):\n\t\t\"\"\"Save the research categories from a persist path.\"\"\"\n\t\tpersist_path = persist_path or self.persist_path\n\t\tfs = fs or fsspec.filesystem(\"file\")\n\t\tdirpath = str(Path(persist_path).parent)\n\t\tif not fs.exists(dirpath):\n\t\t\tfs.makedirs(dirpath)\n\n\t\twith fs.open(persist_path, \"w\") as f:\n\t\t\tf.write(json.dumps(self.category))\n</code></pre>"},{"location":"code_docs/func_modules/paper/download/arxiv/#labridge.func_modules.paper.download.arxiv.ArxivCategory.category_from_arxiv","title":"<code>labridge.func_modules.paper.download.arxiv.ArxivCategory.category_from_arxiv(arxiv_category_url=None)</code>","text":"<p>Parse categories from arxiv.</p> PARAMETER DESCRIPTION <code>arxiv_category_url</code> <p>Generally, the url is \"https://arxiv.org/category_taxonomy\".</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>dict</code> <p>The category dict in the following format: <code>{Group: {Category: description (str)}}</code></p> <p> TYPE: <code>dict</code> </p> Source code in <code>labridge\\func_modules\\paper\\download\\arxiv.py</code> <pre><code>def category_from_arxiv(self, arxiv_category_url: Optional[str] = None) -&gt; dict:\n\tr\"\"\"\n\tParse categories from arxiv.\n\n\tArgs:\n\t\tarxiv_category_url (Optional[str]): Generally, the url is \"https://arxiv.org/category_taxonomy\".\n\n\tReturns:\n\t\tdict: The category dict in the following format:\n\t\t\t`{Group: {Category: description (str)}}`\n\t\"\"\"\n\tarxiv_category_url = arxiv_category_url or self.arxiv_category_url\n\tweb_reader = SimpleWebPageReader(html_to_text=True)\n\tweb_text = web_reader.load_data([arxiv_category_url])\n\ttext = web_text[0].text\n\tfields_str = text.split(\"Category description if available\")[1]\n\tfields_dict= dict()\n\tline_list = fields_str.split('\\n')\n\n\tdescription = []\n\tgroup = None\n\tcategory = None\n\tfor line in line_list:\n\t\tline_items = line.split()\n\t\tif line_items and line_items[0] == \"##\":\n\t\t\tgroup = \" \".join(line_items[1:])\n\t\t\tfields_dict[group] = {}\n\t\t\tcategory = None\n\t\telif line_items and line_items[0] == \"####\":\n\t\t\tif category is not None:\n\t\t\t\tfields_dict[group][category] = \" \".join(description)\n\t\t\tcategory = line_items[1]\n\t\t\tdescription = [f\"{' '.join(line_items[2:])}:\"]\n\t\telse:\n\t\t\tdescription.append(line)\n\n\tfields_dict[group][category] = \" \".join(description)\n\n\t# Extra information.\n\tfor group in Extra_Descriptions.keys():\n\t\tfor category in Extra_Descriptions[group].keys():\n\t\t\tfields_dict[group][category] += Extra_Descriptions[group][category]\n\n\treturn fields_dict\n</code></pre>"},{"location":"code_docs/func_modules/paper/download/arxiv/#labridge.func_modules.paper.download.arxiv.ArxivCategory.load_category","title":"<code>labridge.func_modules.paper.download.arxiv.ArxivCategory.load_category(persist_path=None, fs=None)</code>","text":"<p>Load the research categories from a persist path.</p> Source code in <code>labridge\\func_modules\\paper\\download\\arxiv.py</code> <pre><code>def load_category(self, persist_path: Optional[str] = None, fs: Optional[fsspec.AbstractFileSystem] = None):\n\t\"\"\"Load the research categories from a persist path.\"\"\"\n\tfs = fs or fsspec.filesystem(\"file\")\n\tpersist_path = persist_path or self.persist_path\n\twith fs.open(persist_path, \"rb\") as f:\n\t\tcategory = json.load(f)\n\treturn category\n</code></pre>"},{"location":"code_docs/func_modules/paper/download/arxiv/#labridge.func_modules.paper.download.arxiv.ArxivCategory.save_category","title":"<code>labridge.func_modules.paper.download.arxiv.ArxivCategory.save_category(persist_path=None, fs=None)</code>","text":"<p>Save the research categories from a persist path.</p> Source code in <code>labridge\\func_modules\\paper\\download\\arxiv.py</code> <pre><code>def save_category(self, persist_path: Optional[str] = None, fs: Optional[fsspec.AbstractFileSystem] = None):\n\t\"\"\"Save the research categories from a persist path.\"\"\"\n\tpersist_path = persist_path or self.persist_path\n\tfs = fs or fsspec.filesystem(\"file\")\n\tdirpath = str(Path(persist_path).parent)\n\tif not fs.exists(dirpath):\n\t\tfs.makedirs(dirpath)\n\n\twith fs.open(persist_path, \"w\") as f:\n\t\tf.write(json.dumps(self.category))\n</code></pre>"},{"location":"code_docs/func_modules/paper/download/arxiv/#labridge.func_modules.paper.download.arxiv.ArxivClient","title":"<code>labridge.func_modules.paper.download.arxiv.ArxivClient</code>","text":"<p>               Bases: <code>Client</code></p> <p>Similar to the class <code>Client</code> in the package <code>arxiv</code>. The method <code>_format_url</code> is corrected here to enable advanced search.</p> <p>For details about advanced search in arXiv, refer to Details of Query Construction</p> <p>Advanced search fields: |      prefix  |       explanation             | |:--------:|:-----------------:| |ti            |Title                          | |au            |Author                         | |abs           |Abstract                       | |co            |Comment                        | |jr            |Journal Reference      | |cat           |Subject Category       | |rn            |Report Number          | |id_list       |Id list                        | |all           |All of the above       |</p> Source code in <code>labridge\\func_modules\\paper\\download\\arxiv.py</code> <pre><code>class ArxivClient(Client):\n\tr\"\"\"\n\t Similar to the class `Client` in the package `arxiv`.\n\t The method `_format_url` is corrected here to enable advanced search.\n\n\t For details about advanced search in arXiv, refer to\n\t [Details of Query Construction](https://info.arxiv.org/help/api/user-manual.html#query_details)\n\n\t Advanced search fields:\n\t |\tprefix\t|\texplanation\t\t|\n\t |:--------:|:-----------------:|\n\t |ti\t\t|Title\t\t\t\t|\n\t |au\t\t|Author\t\t\t\t|\n\t |abs\t\t|Abstract\t\t\t|\n\t |co\t\t|Comment\t\t\t|\n\t |jr\t\t|Journal Reference\t|\n\t |cat\t\t|Subject Category\t|\n\t |rn\t\t|Report Number\t\t|\n\t |id_list\t|Id list\t\t\t|\n\t |all\t\t|All of the above\t|\n\t \"\"\"\n\n\tpage_size: int\n\t\"\"\"\n\tMaximum number of results fetched in a single API request. Smaller pages can\n\tbe retrieved faster, but may require more round-trips.\n\n\tThe API's limit is 2000 results per page.\n\t\"\"\"\n\tdelay_seconds: float\n\t\"\"\"\n\tNumber of seconds to wait between API requests.\n\n\t[arXiv's Terms of Use](https://arxiv.org/help/api/tou) ask that you \"make no\n\tmore than one request every three seconds.\"\n\t\"\"\"\n\tnum_retries: int\n\t\"\"\"\n\tNumber of times to retry a failing API request before raising an Exception.\n\t\"\"\"\n\tdef __init_(self, page_size: int = 100, delay_seconds: float = 3.0, num_retries: int = 3):\n\t\tsuper().__init__(\n\t\t\tpage_size=page_size,\n\t\t\tdelay_seconds=delay_seconds,\n\t\t\tnum_retries=num_retries\n\t\t)\n\n\tdef query_format(self, url_args: dict) -&gt; str:\n\t\tr\"\"\" Formatted url for searching in arXiv. \"\"\"\n\t\tquery = url_args[\"search_query\"]\n\t\tsuffix = f\"search_query={query}\"\n\t\tfor key in url_args.keys():\n\t\t\tif key != \"search_query\":\n\t\t\t\tsuffix += f\"&amp;{key}={url_args[key]}\"\n\t\treturn self.query_url_format.format(suffix)\n\n\tdef _format_url(self, search: Search, start: int, page_size: int) -&gt; str:\n\t\tr\"\"\" Formatted url for searching in arXiv. \"\"\"\n\t\turl_args = search._url_args()\n\t\turl_args.update(\n\t\t\t{\n\t\t\t\t\"start\": start,\n\t\t\t\t\"max_results\": page_size,\n\t\t\t}\n\t\t)\n\t\treturn self.query_format(url_args)\n</code></pre>"},{"location":"code_docs/func_modules/paper/download/arxiv/#labridge.func_modules.paper.download.arxiv.ArxivClient.delay_seconds","title":"<code>labridge.func_modules.paper.download.arxiv.ArxivClient.delay_seconds: float</code>  <code>instance-attribute</code>","text":"<p>Number of seconds to wait between API requests.</p> <p>arXiv's Terms of Use ask that you \"make no more than one request every three seconds.\"</p>"},{"location":"code_docs/func_modules/paper/download/arxiv/#labridge.func_modules.paper.download.arxiv.ArxivClient.num_retries","title":"<code>labridge.func_modules.paper.download.arxiv.ArxivClient.num_retries: int</code>  <code>instance-attribute</code>","text":"<p>Number of times to retry a failing API request before raising an Exception.</p>"},{"location":"code_docs/func_modules/paper/download/arxiv/#labridge.func_modules.paper.download.arxiv.ArxivClient.page_size","title":"<code>labridge.func_modules.paper.download.arxiv.ArxivClient.page_size: int</code>  <code>instance-attribute</code>","text":"<p>Maximum number of results fetched in a single API request. Smaller pages can be retrieved faster, but may require more round-trips.</p> <p>The API's limit is 2000 results per page.</p>"},{"location":"code_docs/func_modules/paper/download/arxiv/#labridge.func_modules.paper.download.arxiv.ArxivClient.query_format","title":"<code>labridge.func_modules.paper.download.arxiv.ArxivClient.query_format(url_args)</code>","text":"<p>Formatted url for searching in arXiv.</p> Source code in <code>labridge\\func_modules\\paper\\download\\arxiv.py</code> <pre><code>def query_format(self, url_args: dict) -&gt; str:\n\tr\"\"\" Formatted url for searching in arXiv. \"\"\"\n\tquery = url_args[\"search_query\"]\n\tsuffix = f\"search_query={query}\"\n\tfor key in url_args.keys():\n\t\tif key != \"search_query\":\n\t\t\tsuffix += f\"&amp;{key}={url_args[key]}\"\n\treturn self.query_url_format.format(suffix)\n</code></pre>"},{"location":"code_docs/func_modules/paper/download/arxiv/#labridge.func_modules.paper.download.arxiv.ArxivDailyDownloader","title":"<code>labridge.func_modules.paper.download.arxiv.ArxivDailyDownloader</code>","text":"<p>               Bases: <code>object</code></p> <p>Get the recent relevant papers on arXiv.</p> ATTRIBUTE DESCRIPTION <code>category</code> <p>Storing the research fields categories.</p> <p> TYPE: <code>ArxivCategory</code> </p> <code>client</code> <p>For Fetching papers.</p> <p> TYPE: <code>ArxivClient</code> </p> <code>recent_days</code> <p>papers dating back to <code>recent_days</code> ago from today will be obtained.</p> <p> TYPE: <code>int</code> </p> Source code in <code>labridge\\func_modules\\paper\\download\\arxiv.py</code> <pre><code>class ArxivDailyDownloader(object):\n\tr\"\"\"\n\tGet the recent relevant papers on arXiv.\n\n\tAttributes:\n\t\tcategory (ArxivCategory): Storing the research fields categories.\n\t\tclient (ArxivClient): For Fetching papers.\n\t\trecent_days (int): papers dating back to `recent_days` ago from today will be obtained.\n\t\"\"\"\n\n\tcategory: ArxivCategory\n\tclient: ArxivClient\n\trecent_days: int\n\n\tdef __init__(self, recent_days: int = 1):\n\t\tself.today = datetime.date.today()\n\t\tself.category = ArxivCategory()\n\t\tself.client = ArxivClient()\n\t\tself.recent_days = recent_days\n\t\tself.search = Search(\n\t\t\tquery=\"cat:cs.AI\",\n\t\t\tsort_by=SortCriterion.SubmittedDate,\n\t\t\tsort_order=SortOrder.Descending,\n\t\t)\n\n\tdef _is_valid_category(self, cat: str) -&gt; bool:\n\t\tr\"\"\"\n\t\tCheck if the category is valid\n\n\t\tArgs:\n\t\t\tcat (str): a research category.\n\n\t\tReturns:\n\t\t\tbool: Whether the given category is a valid category in arXiv.\n\t\t\"\"\"\n\t\tcat_dict = self.category.category\n\t\tfor group in cat_dict.keys():\n\t\t\tif cat in cat_dict[group].keys():\n\t\t\t\treturn True\n\t\treturn False\n\n\tdef _valid_date(self, date: datetime.date, start_date: datetime.date, end_date: datetime.date) -&gt; bool:\n\t\tr\"\"\" Check if the date is 'recent' \"\"\"\n\t\treturn start_date &lt;= date &lt;= end_date\n\n\tdef get_daily_papers_info(self, relevant_categories: List[str]) -&gt; List[Result]:\n\t\tr\"\"\"\n\t\tGet the recent papers relevant to the input categories.\n\n\t\tThe information (e.g. Abstract, Title, Authors) of these daily papers will be sent to\n\t\tthe corresponding Lab Members. The papers selected by the members will be parsed and stored\n\t\tinto a proper directory.\n\n\t\tArgs:\n\t\t\trelevant_categories (List[str]): The recent papers in these categories will be counted.\n\n\t\tReturn:\n\t\t\tList[Result]: Recent papers information.\n\t\t\"\"\"\n\t\tquery = \"\"\n\t\tfor cat in relevant_categories:\n\t\t\tif self._is_valid_category(cat):\n\t\t\t\tif len(query) &gt; 0:\n\t\t\t\t\tquery += \"+OR+\"\n\t\t\t\tquery += f\"cat:{cat}\"\n\n\t\tdaily_papers = []\n\t\tif len(query) == 0:\n\t\t\treturn daily_papers\n\n\t\tself.search.query = query\n\t\tstart_date = self.today - datetime.timedelta(days=self.recent_days)\n\t\tfor result in self.client.results(search=self.search):\n\t\t\tsubmit_date = result.published\n\t\t\tif not self._valid_date(date=submit_date, start_date=start_date, end_date=self.today):\n\t\t\t\tbreak\n\t\t\tdaily_papers.append(result)\n\t\treturn daily_papers\n\n\tdef download_papers(self, paper_dict: Dict[Result, str]):\n\t\tr\"\"\"\n\t\tDownload the selected papers.\n\n\t\tArgs:\n\t\t\tpaper_dict (Dict[Result, str]):\n\t\t\t\t- key: paper (Result)\n\t\t\t\t- value: save_dir (str)\n\t\t\"\"\"\n\t\tfor paper in paper_dict.keys():\n\t\t\tpaper.download_pdf(dirpath=paper_dict[paper], filename=f\"{paper.title}.pdf\")\n</code></pre>"},{"location":"code_docs/func_modules/paper/download/arxiv/#labridge.func_modules.paper.download.arxiv.ArxivDailyDownloader.download_papers","title":"<code>labridge.func_modules.paper.download.arxiv.ArxivDailyDownloader.download_papers(paper_dict)</code>","text":"<p>Download the selected papers.</p> PARAMETER DESCRIPTION <code>paper_dict</code> <ul> <li>key: paper (Result)</li> <li>value: save_dir (str)</li> </ul> <p> TYPE: <code>Dict[Result, str]</code> </p> Source code in <code>labridge\\func_modules\\paper\\download\\arxiv.py</code> <pre><code>def download_papers(self, paper_dict: Dict[Result, str]):\n\tr\"\"\"\n\tDownload the selected papers.\n\n\tArgs:\n\t\tpaper_dict (Dict[Result, str]):\n\t\t\t- key: paper (Result)\n\t\t\t- value: save_dir (str)\n\t\"\"\"\n\tfor paper in paper_dict.keys():\n\t\tpaper.download_pdf(dirpath=paper_dict[paper], filename=f\"{paper.title}.pdf\")\n</code></pre>"},{"location":"code_docs/func_modules/paper/download/arxiv/#labridge.func_modules.paper.download.arxiv.ArxivDailyDownloader.get_daily_papers_info","title":"<code>labridge.func_modules.paper.download.arxiv.ArxivDailyDownloader.get_daily_papers_info(relevant_categories)</code>","text":"<p>Get the recent papers relevant to the input categories.</p> <p>The information (e.g. Abstract, Title, Authors) of these daily papers will be sent to the corresponding Lab Members. The papers selected by the members will be parsed and stored into a proper directory.</p> PARAMETER DESCRIPTION <code>relevant_categories</code> <p>The recent papers in these categories will be counted.</p> <p> TYPE: <code>List[str]</code> </p> Return <p>List[Result]: Recent papers information.</p> Source code in <code>labridge\\func_modules\\paper\\download\\arxiv.py</code> <pre><code>def get_daily_papers_info(self, relevant_categories: List[str]) -&gt; List[Result]:\n\tr\"\"\"\n\tGet the recent papers relevant to the input categories.\n\n\tThe information (e.g. Abstract, Title, Authors) of these daily papers will be sent to\n\tthe corresponding Lab Members. The papers selected by the members will be parsed and stored\n\tinto a proper directory.\n\n\tArgs:\n\t\trelevant_categories (List[str]): The recent papers in these categories will be counted.\n\n\tReturn:\n\t\tList[Result]: Recent papers information.\n\t\"\"\"\n\tquery = \"\"\n\tfor cat in relevant_categories:\n\t\tif self._is_valid_category(cat):\n\t\t\tif len(query) &gt; 0:\n\t\t\t\tquery += \"+OR+\"\n\t\t\tquery += f\"cat:{cat}\"\n\n\tdaily_papers = []\n\tif len(query) == 0:\n\t\treturn daily_papers\n\n\tself.search.query = query\n\tstart_date = self.today - datetime.timedelta(days=self.recent_days)\n\tfor result in self.client.results(search=self.search):\n\t\tsubmit_date = result.published\n\t\tif not self._valid_date(date=submit_date, start_date=start_date, end_date=self.today):\n\t\t\tbreak\n\t\tdaily_papers.append(result)\n\treturn daily_papers\n</code></pre>"},{"location":"code_docs/func_modules/paper/download/arxiv/#labridge.func_modules.paper.download.arxiv.ArxivSearcher","title":"<code>labridge.func_modules.paper.download.arxiv.ArxivSearcher</code>","text":"<p>               Bases: <code>object</code></p> <p>This class searches for papers in the arxiv.</p> ATTRIBUTE DESCRIPTION <code>max_results_num</code> <p>Maximum number of results in a search.</p> <p> TYPE: <code>int</code> </p> <code>category</code> <p>The arXiv research category.</p> <p> TYPE: <code>ArxivCategory</code> </p> <code>client</code> <p>Client responsible for searching.</p> <p> TYPE: <code>ArxivClient</code> </p> <code>searcher</code> <p>The parameters of searching.</p> <p> TYPE: <code>Search</code> </p> Source code in <code>labridge\\func_modules\\paper\\download\\arxiv.py</code> <pre><code>class ArxivSearcher(object):\n\tr\"\"\"\n\tThis class searches for papers in the arxiv.\n\n\tAttributes:\n\t\tmax_results_num (int): Maximum number of results in a search.\n\t\tcategory (ArxivCategory): The arXiv research category.\n\t\tclient (ArxivClient): Client responsible for searching.\n\t\tsearcher (Search): The parameters of searching.\n\t\"\"\"\n\tdef __init__(self, max_results_num: int = 5):\n\t\tself.max_results_num = max_results_num\n\t\tself.category = ArxivCategory()\n\t\tself.client = ArxivClient()\n\t\tself.searcher = Search(\n\t\t\tquery=\"\",\n\t\t\tsort_by=SortCriterion.Relevance,\n\t\t\tsort_order=SortOrder.Descending,\n\t\t)\n\n\tdef search(self, search_str: str) -&gt; List[Result]:\n\t\tr\"\"\"\n\t\tSearch according to the title or abstract.\n\n\t\tArgs:\n\t\t\tsearch_str (str): The search string, typically the title or abstract.\n\n\t\tReturns:\n\t\t\tList[Result]: The search results.\n\t\t\"\"\"\n\t\tquery = f\"ti:{search_str}+OR+abs:{search_str}\"\n\t\tself.searcher.query = query\n\t\tcount = 0\n\t\tresults = []\n\t\tfor result in self.client.results(search=self.searcher):\n\t\t\tcount += 1\n\t\t\tresults.append(result)\n\t\t\tif count &gt;= self.max_results_num:\n\t\t\t\tbreak\n\t\treturn results\n</code></pre>"},{"location":"code_docs/func_modules/paper/download/arxiv/#labridge.func_modules.paper.download.arxiv.ArxivSearcher.search","title":"<code>labridge.func_modules.paper.download.arxiv.ArxivSearcher.search(search_str)</code>","text":"<p>Search according to the title or abstract.</p> PARAMETER DESCRIPTION <code>search_str</code> <p>The search string, typically the title or abstract.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>List[Result]</code> <p>List[Result]: The search results.</p> Source code in <code>labridge\\func_modules\\paper\\download\\arxiv.py</code> <pre><code>def search(self, search_str: str) -&gt; List[Result]:\n\tr\"\"\"\n\tSearch according to the title or abstract.\n\n\tArgs:\n\t\tsearch_str (str): The search string, typically the title or abstract.\n\n\tReturns:\n\t\tList[Result]: The search results.\n\t\"\"\"\n\tquery = f\"ti:{search_str}+OR+abs:{search_str}\"\n\tself.searcher.query = query\n\tcount = 0\n\tresults = []\n\tfor result in self.client.results(search=self.searcher):\n\t\tcount += 1\n\t\tresults.append(result)\n\t\tif count &gt;= self.max_results_num:\n\t\t\tbreak\n\treturn results\n</code></pre>"},{"location":"code_docs/func_modules/paper/download/async_utils/","title":"Async utils","text":""},{"location":"code_docs/func_modules/paper/download/async_utils/#labridge.func_modules.paper.download.async_utils","title":"<code>labridge.func_modules.paper.download.async_utils</code>","text":""},{"location":"code_docs/func_modules/paper/download/async_utils/#labridge.func_modules.paper.download.async_utils.adownload_file","title":"<code>labridge.func_modules.paper.download.async_utils.adownload_file(url, save_path)</code>  <code>async</code>","text":"<p>Asynchronously download file.</p> PARAMETER DESCRIPTION <code>url</code> <p>The url of the file.</p> <p> TYPE: <code>str</code> </p> <code>save_path</code> <p>The save path of the file.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>save_path</code> <p>The save path.</p> <p> TYPE: <code>str</code> </p> Source code in <code>labridge\\func_modules\\paper\\download\\async_utils.py</code> <pre><code>async def adownload_file(url: str, save_path: str) -&gt; str:\n\tr\"\"\"\n\tAsynchronously download file.\n\n\tArgs:\n\t\turl (str): The url of the file.\n\t\tsave_path (str): The save path of the file.\n\n\tReturns:\n\t\tsave_path (str): The save path.\n\t\"\"\"\n\tasync with aiohttp.ClientSession() as session:\n\t\tasync with session.get(url) as response:\n\t\t\twith open(save_path, 'wb') as f:\n\t\t\t\twhile True:\n\t\t\t\t\tchunk = await response.content.read(1024)\n\t\t\t\t\tif not chunk:\n\t\t\t\t\t\tbreak\n\t\t\t\t\tf.write(chunk)\n\treturn save_path\n</code></pre>"},{"location":"code_docs/func_modules/paper/parse/paper_reader/","title":"Paper reader","text":""},{"location":"code_docs/func_modules/paper/parse/paper_reader/#labridge.func_modules.paper.parse.paper_reader","title":"<code>labridge.func_modules.paper.parse.paper_reader</code>","text":""},{"location":"code_docs/func_modules/paper/parse/paper_reader/#labridge.func_modules.paper.parse.paper_reader.PaperReader","title":"<code>labridge.func_modules.paper.parse.paper_reader.PaperReader</code>","text":"<p>Read a PDF paper, and extract valid meta_data from it.</p> PARAMETER DESCRIPTION <code>llm</code> <p>the used llm, if not provided, use the llm from <code>service_context</code>. Defaults to None.</p> <p> TYPE: <code>LLM</code> DEFAULT: <code>None</code> </p> <code>source_keyword_threshold</code> <p>used in PaperSourceAnalyzer. refer to PaperSourceAnalyzer for details. Defaults to 10</p> <p> TYPE: <code>int</code> DEFAULT: <code>10</code> </p> <code>use_llm_for_source</code> <p>whether to use LLM in the source analyzer. Defaults to True.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>extract_metadata</code> <p>whether to use LLM to extract metadata for papers. Defaults to True.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>necessary_metadata</code> <p>Paper level metadata. The necessary metadata that must be extracted. It is a dictionary with k-v pairs like: {metadata_name: description}. The description is used to instruct the llm to extract the corresponding metadata. For example:</p> <ul> <li>key: \"Title\"</li> <li>value: \"The title often appears as a single concise sentence at the head of a paper.\"</li> </ul> <p> TYPE: <code>Dict[str, str]</code> DEFAULT: <code>None</code> </p> <code>optional_metadata</code> <p>Paper level metadata. The optional metadata that is not forced to extract from the paper. It is a dictionary with k-v pairs like: {metadata_name: description}.</p> <p> TYPE: <code>Dict[str, str]</code> DEFAULT: <code>None</code> </p> <code>extract_retry_times</code> <p>max retry times if not all necessary metadata is extracted.</p> <p> TYPE: <code>int</code> DEFAULT: <code>2</code> </p> <code>service_context</code> <p>the service context.</p> <p> TYPE: <code>ServiceContext</code> DEFAULT: <code>None</code> </p> <code>recursive</code> <p>Whether to recursively search in subdirectories.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <pre><code>False by default.\n    exclude (List): glob of python file paths to exclude (Optional)\n</code></pre> <p>exclude_hidden (bool): Whether to exclude hidden files (dotfiles). required_exts (Optional[List[str]]): List of required extensions.     Default is None. num_files_limit (Optional[int]): Maximum number of files to read.     Default is None.         filename_as_id (bool): whether to use the filename as the document id. True by default.                 If set to True, the doc node will be named as <code>{file_path}_{content_type}</code>.                 The file_path is relative to root directory.</p> Source code in <code>labridge\\func_modules\\paper\\parse\\paper_reader.py</code> <pre><code>class PaperReader:\n\tr\"\"\"\n\tRead a PDF paper, and extract valid meta_data from it.\n\n\tArgs:\n\t\tllm (LLM: the used llm, if not provided, use the llm from `service_context`.\n\t\t\tDefaults to None.\n\t\tsource_keyword_threshold (int): used in PaperSourceAnalyzer. refer to PaperSourceAnalyzer for details.\n\t\t\tDefaults to 10\n\t\tuse_llm_for_source (bool): whether to use LLM in the source analyzer. Defaults to True.\n\t\textract_metadata (bool): whether to use LLM to extract metadata for papers. Defaults to True.\n\t\tnecessary_metadata (Dict[str, str]): Paper level metadata.\n\t\t\tThe necessary metadata that must be extracted.\n\t\t \tIt is a dictionary with k-v pairs like: {metadata_name: description}. The description\n\t\t \tis used to instruct the llm to extract the corresponding metadata.\n\t\t \tFor example:\n\n\t\t \t- key: \"Title\"\n\t\t \t- value: \"The title often appears as a single concise sentence at the head of a paper.\"\n\t\toptional_metadata (Dict[str, str]): Paper level metadata.\n\t\t\tThe optional metadata that is not forced to extract from the paper.\n\t\t\tIt is a dictionary with k-v pairs like: {metadata_name: description}.\n\t\textract_retry_times: max retry times if not all necessary metadata is extracted.\n\t\tservice_context (ServiceContext): the service context.\n\t\trecursive (bool): Whether to recursively search in subdirectories.\n            False by default.\n\t\texclude (List): glob of python file paths to exclude (Optional)\n        exclude_hidden (bool): Whether to exclude hidden files (dotfiles).\n        required_exts (Optional[List[str]]): List of required extensions.\n            Default is None.\n        num_files_limit (Optional[int]): Maximum number of files to read.\n            Default is None.\n\t\tfilename_as_id (bool): whether to use the filename as the document id. True by default.\n\t\t\tIf set to True, the doc node will be named as `{file_path}_{content_type}`.\n\t\t\tThe file_path is relative to root directory.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tllm: LLM = None,\n\t\tsource_keyword_threshold: int = 10,\n\t\tuse_llm_for_source: bool = True,\n\t\textract_metadata: bool = True,\n\t\tnecessary_metadata: Dict[str, str] = None,\n\t\toptional_metadata: Dict[str, str] = None,\n\t\textract_retry_times: int = 2,\n\t\tfilename_as_id: bool = True,\n\t\tservice_context: ServiceContext = None,\n\t\trecursive: bool = False,\n\t\texclude: Optional[List] = None,\n\t\texclude_hidden: bool = True,\n\t\trequired_exts: Optional[List[str]] = None,\n\t\tnum_files_limit: Optional[int] = None,\n\t\tfs: Optional[fsspec.AbstractFileSystem] = None,\n\t):\n\t\tself.metadata_extractor = None\n\t\tself.extract_metadata = extract_metadata\n\t\tif extract_metadata:\n\t\t\tself.metadata_extractor = PaperMetadataExtractor(\n\t\t\t\tllm=llm,\n\t\t\t\tnecessary_metadata=necessary_metadata,\n\t\t\t\toptional_metadata=optional_metadata,\n\t\t\t\tmax_retry_times=extract_retry_times,\n\t\t\t\tservice_context=service_context,\n\t\t\t)\n\t\tif llm is None:\n\t\t\tself.llm = llm_from_settings_or_context(Settings, service_context)\n\t\telse:\n\t\t\tself.llm = llm\n\n\t\tself.source_analyzer = PaperSourceAnalyzer(llm=self.llm, keyword_count_threshold=source_keyword_threshold)\n\t\tself.use_llm_for_source = use_llm_for_source\n\t\tself.filename_as_id = filename_as_id\n\t\tself.recursive = recursive\n\t\tself.exclude = exclude\n\t\tself.exclude_hidden = exclude_hidden\n\t\tself.required_exts = required_exts\n\t\tself.num_files_limit = num_files_limit\n\t\tself.fs = fs or LocalFileSystem()\n\t\troot = Path(__file__)\n\t\tfor i in range(5):\n\t\t\troot = root.parent\n\t\tself.root = root\n\n\tdef get_paper_possessor(self, paper_path: Union[Path, str]) -&gt; str:\n\t\tr\"\"\"\n\t\tGet the possessor of this paper.\n\t\tAssume the possessor is the first level directory under the paper warehouse.\n\n\t\tArgs:\n\t\t\tpaper_path (Union[Path, str]): The file path of paper.\n\n\t\tReturns:\n\t\t\tstr: The paper possessor.\n\t\t\"\"\"\n\t\tif isinstance(paper_path, str):\n\t\t\tpaper_path = Path(paper_path)\n\t\ttry:\n\t\t\tpaper_warehouse = self.root / SHARED_PAPER_WAREHOUSE_DIR\n\t\t\trel = paper_path.relative_to(paper_warehouse)\n\t\t\tpossessor = rel.parts[0]\n\t\t\treturn possessor\n\t\texcept ValueError:\n\t\t\traise ValueError(\"The path of the paper is not valid, a valid path should be under the PaperWarehouse directory.\")\n\n\tdef read_single_paper(\n\t\tself,\n\t\tfile_path: Union[Path, str],\n\t\tshow_progress: bool = True,\n\t\textra_metadata: dict = None,\n\t) -&gt; Optional[Tuple[List[Document], List[Document]]]:\n\t\tr\"\"\"\n\t\tRead a single pdf paper.\n\n\t\tArgs:\n\t\t\tfile_path (Union[Path, str]): the path of pdf paper.\n\t\t\tshow_progress (bool): show parsing progress.\n\t\t\textra_metadata (dict): Existing metadata obtained by approaches such as arXiv API.\n\n\t\tReturns:\n\t\t\tTuple[List[Document], List[Document]]:\n\t\t\t\tThe ingested content docs and extra docs.\n\n\t\t\t\t- chunk_docs: the docs for retrieving, include information such as main text, methods.\n\t\t\t\tMight be None if nothing is parsed (auto_parse_paper fails.)\n\t\t\t\t- extra_docs: docs that involve supplementary information such as references.\n\t\t\t\tMight be None.\n\t\t\"\"\"\n\t\tif isinstance(file_path, str):\n\t\t\tfile_path = Path(file_path)\n\t\tif str(file_path)[-4:] != '.pdf':\n\t\t\traise ValueError(\"Expect a PDF file.\")\n\t\tif show_progress:\n\t\t\tprint_text(f\"&gt;&gt;&gt; Loading {file_path}\", color=\"blue\", end=\"\\n\")\n\t\tparsed_docs = auto_parse_paper(\n\t\t\tfile_path=file_path,\n\t\t\tsource_analyzer=self.source_analyzer,\n\t\t\tuse_llm_for_source=self.use_llm_for_source\n\t\t)\n\n\t\tchunk_docs, extra_docs, metadata_docs = [], [], []\n\t\tfor doc in parsed_docs:\n\t\t\tif doc.metadata[CONTENT_TYPE_NAME] in MetadataContents:\n\t\t\t\tmetadata_docs.append(doc)\n\t\t\telif doc.metadata[CONTENT_TYPE_NAME] in ChunkContents:\n\t\t\t\tchunk_docs.append(doc)\n\t\t\telse:\n\t\t\t\textra_docs.append(doc)\n\n\t\t# metadata\n\t\tpaper_metadata = dict()\n\n\t\tif self.extract_metadata:\n\t\t\tpaper_metadata = self.metadata_extractor.extract_paper_metadata(\n\t\t\t\tpdf_path=file_path,\n\t\t\t\textra_metadata=extra_metadata,\n\t\t\t)\n\t\t\tif paper_metadata is None:\n\t\t\t\treturn None\n\n\t\t\tfor meta_doc in metadata_docs:\n\t\t\t\tmetadata_name = meta_doc.metadata[CONTENT_TYPE_NAME]\n\t\t\t\tif metadata_name not in paper_metadata.keys():\n\t\t\t\t\tpaper_metadata[metadata_name] = meta_doc.text\n\n\t\tpossessor = self.get_paper_possessor(file_path)\n\t\tpaper_metadata[PAPER_POSSESSOR] = possessor\n\t\tpaper_metadata[PAPER_REL_FILE_PATH] = str(file_path.relative_to(self.root))\n\n\t\tfor idx, doc in enumerate(parsed_docs):\n\t\t\tdoc.metadata.update(paper_metadata)\n\t\t\tif self.filename_as_id:\n\t\t\t\trel_path = str(file_path.relative_to(self.root))\n\t\t\t\tdoc.id_ = f\"{rel_path!s}_{doc.metadata[CONTENT_TYPE_NAME]}\"\n\t\treturn chunk_docs, extra_docs\n\n\tdef read_papers(\n\t\tself,\n\t\tinput_dir: Optional[str] = None,\n\t\tinput_files: Optional[List] = None,\n\t\tshow_progress: bool = True,\n\t) -&gt; Tuple[List[Document], List[Document]]:\n\t\tr\"\"\"\n\t\tRead papers.\n\n\t\tArgs:\n\t\t\tinput_dir (Optional[str]): the paper directory.\n\t\t\tinput_files (Optional[List]): the paths of papers. If it is specified, the `input_dir` is ignored.\n\t\t\tshow_progress (bool): show parsing progress.\n\n\t\tReturns:\n\t\t\tTuple[List[Document], List[Document]]:\n\t\t\t\tthe content docs and the extra docs.\n\n\t\t\t\t- contents: for retrieving, each sequence in the list contains the content docs of a paper.\n\t\t\t\t- extra_info: extra info, each sequence in the list contains the extra docs of a paper.\n\t\t\"\"\"\n\t\t_Path = Path if is_default_fs(self.fs) else PurePosixPath\n\t\tpaper_files = None\n\t\tif input_files:\n\t\t\tpaper_files = []\n\t\t\tfor path in input_files:\n\t\t\t\tif not self.fs.isfile(path):\n\t\t\t\t\traise ValueError(f\"File {path} does not exist.\")\n\t\t\t\tinput_file = _Path(path)\n\t\t\t\tpaper_files.append(input_file)\n\t\telif input_dir:\n\t\t\tif not self.fs.isdir(input_dir):\n\t\t\t\traise ValueError(f\"Directory {input_dir} does not exist.\")\n\t\t\tinput_dir = _Path(input_dir)\n\t\t\tpaper_files = self._add_files(input_dir)\n\n\t\tcontents, extra_info = [], []\n\t\tif paper_files is not None:\n\t\t\tfor idx, paper in enumerate(paper_files):\n\t\t\t\tif str(paper)[-4:] != '.pdf':\n\t\t\t\t\tcontinue\n\t\t\t\tcontent_docs, extra_docs = self.read_single_paper(file_path=paper, show_progress=show_progress)\n\t\t\t\tcontents += content_docs\n\t\t\t\textra_info += extra_docs\n\t\treturn contents, extra_info\n\n\tdef is_hidden(self, path: Path) -&gt; bool:\n\t\treturn any(part.startswith(\".\") and part not in [\".\", \"..\"] for part in path.parts)\n\n\tdef _add_files(self, input_dir: Path) -&gt; List[Path]:\n\t\t\"\"\"Add files.\"\"\"\n\t\tall_files = set()\n\t\trejected_files = set()\n\t\trejected_dirs = set()\n\t\t# Default to POSIX paths for non-default file systems (e.g. S3)\n\t\t_Path = Path if is_default_fs(self.fs) else PurePosixPath\n\n\t\tif self.exclude is not None:\n\t\t\tfor excluded_pattern in self.exclude:\n\t\t\t\tif self.recursive:\n\t\t\t\t\t# Recursive glob\n\t\t\t\t\texcluded_glob = _Path(input_dir) / _Path(\"**\") / excluded_pattern\n\t\t\t\telse:\n\t\t\t\t\t# Non-recursive glob\n\t\t\t\t\texcluded_glob = _Path(input_dir) / excluded_pattern\n\t\t\t\tfor file in self.fs.glob(str(excluded_glob)):\n\t\t\t\t\tif self.fs.isdir(file):\n\t\t\t\t\t\trejected_dirs.add(_Path(file))\n\t\t\t\t\telse:\n\t\t\t\t\t\trejected_files.add(_Path(file))\n\n\t\tfile_refs: List[str] = []\n\t\tif self.recursive:\n\t\t\tfile_refs = self.fs.glob(str(input_dir) + \"/**/*\")\n\t\telse:\n\t\t\tfile_refs = self.fs.glob(str(input_dir) + \"/*\")\n\n\t\tfor ref in file_refs:\n\t\t\t# Manually check if file is hidden or directory instead of\n\t\t\t# in glob for backwards compatibility.\n\t\t\tref = _Path(ref)\n\t\t\tis_dir = self.fs.isdir(ref)\n\t\t\tskip_because_hidden = self.exclude_hidden and self.is_hidden(ref)\n\t\t\tskip_because_bad_ext = (self.required_exts is not None and ref.suffix not in self.required_exts)\n\t\t\tskip_because_excluded = ref in rejected_files\n\t\t\tif not skip_because_excluded:\n\t\t\t\tif is_dir:\n\t\t\t\t\tref_parent_dir = ref\n\t\t\t\telse:\n\t\t\t\t\tref_parent_dir = self.fs._parent(ref)\n\t\t\t\tfor rejected_dir in rejected_dirs:\n\t\t\t\t\tif str(ref_parent_dir).startswith(str(rejected_dir)):\n\t\t\t\t\t\tskip_because_excluded = True\n\t\t\t\t\t\tlogger.debug(\"Skipping %s because it in parent dir %s which is in %s\", ref, ref_parent_dir,\n\t\t\t\t\t\t\trejected_dir, )\n\t\t\t\t\t\tbreak\n\n\t\t\tif (is_dir or skip_because_hidden or skip_because_bad_ext or skip_because_excluded):\n\t\t\t\tcontinue\n\t\t\telse:\n\t\t\t\tall_files.add(ref)\n\n\t\tnew_input_files = sorted(all_files)\n\n\t\tif len(new_input_files) == 0:\n\t\t\traise ValueError(f\"No files found in {input_dir}.\")\n\n\t\tif self.num_files_limit is not None and self.num_files_limit &gt; 0:\n\t\t\tnew_input_files = new_input_files[0: self.num_files_limit]\n\n\t\t# print total number of files added\n\t\tlogger.debug(f\"&gt; [PaperReader] Total files added: {len(new_input_files)}\")\n\n\t\treturn new_input_files\n</code></pre>"},{"location":"code_docs/func_modules/paper/parse/paper_reader/#labridge.func_modules.paper.parse.paper_reader.PaperReader.get_paper_possessor","title":"<code>labridge.func_modules.paper.parse.paper_reader.PaperReader.get_paper_possessor(paper_path)</code>","text":"<p>Get the possessor of this paper. Assume the possessor is the first level directory under the paper warehouse.</p> PARAMETER DESCRIPTION <code>paper_path</code> <p>The file path of paper.</p> <p> TYPE: <code>Union[Path, str]</code> </p> RETURNS DESCRIPTION <code>str</code> <p>The paper possessor.</p> <p> TYPE: <code>str</code> </p> Source code in <code>labridge\\func_modules\\paper\\parse\\paper_reader.py</code> <pre><code>def get_paper_possessor(self, paper_path: Union[Path, str]) -&gt; str:\n\tr\"\"\"\n\tGet the possessor of this paper.\n\tAssume the possessor is the first level directory under the paper warehouse.\n\n\tArgs:\n\t\tpaper_path (Union[Path, str]): The file path of paper.\n\n\tReturns:\n\t\tstr: The paper possessor.\n\t\"\"\"\n\tif isinstance(paper_path, str):\n\t\tpaper_path = Path(paper_path)\n\ttry:\n\t\tpaper_warehouse = self.root / SHARED_PAPER_WAREHOUSE_DIR\n\t\trel = paper_path.relative_to(paper_warehouse)\n\t\tpossessor = rel.parts[0]\n\t\treturn possessor\n\texcept ValueError:\n\t\traise ValueError(\"The path of the paper is not valid, a valid path should be under the PaperWarehouse directory.\")\n</code></pre>"},{"location":"code_docs/func_modules/paper/parse/paper_reader/#labridge.func_modules.paper.parse.paper_reader.PaperReader.read_papers","title":"<code>labridge.func_modules.paper.parse.paper_reader.PaperReader.read_papers(input_dir=None, input_files=None, show_progress=True)</code>","text":"<p>Read papers.</p> PARAMETER DESCRIPTION <code>input_dir</code> <p>the paper directory.</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>input_files</code> <p>the paths of papers. If it is specified, the <code>input_dir</code> is ignored.</p> <p> TYPE: <code>Optional[List]</code> DEFAULT: <code>None</code> </p> <code>show_progress</code> <p>show parsing progress.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>Tuple[List[Document], List[Document]]</code> <p>Tuple[List[Document], List[Document]]: the content docs and the extra docs.</p> <ul> <li>contents: for retrieving, each sequence in the list contains the content docs of a paper.</li> <li>extra_info: extra info, each sequence in the list contains the extra docs of a paper.</li> </ul> Source code in <code>labridge\\func_modules\\paper\\parse\\paper_reader.py</code> <pre><code>def read_papers(\n\tself,\n\tinput_dir: Optional[str] = None,\n\tinput_files: Optional[List] = None,\n\tshow_progress: bool = True,\n) -&gt; Tuple[List[Document], List[Document]]:\n\tr\"\"\"\n\tRead papers.\n\n\tArgs:\n\t\tinput_dir (Optional[str]): the paper directory.\n\t\tinput_files (Optional[List]): the paths of papers. If it is specified, the `input_dir` is ignored.\n\t\tshow_progress (bool): show parsing progress.\n\n\tReturns:\n\t\tTuple[List[Document], List[Document]]:\n\t\t\tthe content docs and the extra docs.\n\n\t\t\t- contents: for retrieving, each sequence in the list contains the content docs of a paper.\n\t\t\t- extra_info: extra info, each sequence in the list contains the extra docs of a paper.\n\t\"\"\"\n\t_Path = Path if is_default_fs(self.fs) else PurePosixPath\n\tpaper_files = None\n\tif input_files:\n\t\tpaper_files = []\n\t\tfor path in input_files:\n\t\t\tif not self.fs.isfile(path):\n\t\t\t\traise ValueError(f\"File {path} does not exist.\")\n\t\t\tinput_file = _Path(path)\n\t\t\tpaper_files.append(input_file)\n\telif input_dir:\n\t\tif not self.fs.isdir(input_dir):\n\t\t\traise ValueError(f\"Directory {input_dir} does not exist.\")\n\t\tinput_dir = _Path(input_dir)\n\t\tpaper_files = self._add_files(input_dir)\n\n\tcontents, extra_info = [], []\n\tif paper_files is not None:\n\t\tfor idx, paper in enumerate(paper_files):\n\t\t\tif str(paper)[-4:] != '.pdf':\n\t\t\t\tcontinue\n\t\t\tcontent_docs, extra_docs = self.read_single_paper(file_path=paper, show_progress=show_progress)\n\t\t\tcontents += content_docs\n\t\t\textra_info += extra_docs\n\treturn contents, extra_info\n</code></pre>"},{"location":"code_docs/func_modules/paper/parse/paper_reader/#labridge.func_modules.paper.parse.paper_reader.PaperReader.read_single_paper","title":"<code>labridge.func_modules.paper.parse.paper_reader.PaperReader.read_single_paper(file_path, show_progress=True, extra_metadata=None)</code>","text":"<p>Read a single pdf paper.</p> PARAMETER DESCRIPTION <code>file_path</code> <p>the path of pdf paper.</p> <p> TYPE: <code>Union[Path, str]</code> </p> <code>show_progress</code> <p>show parsing progress.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>extra_metadata</code> <p>Existing metadata obtained by approaches such as arXiv API.</p> <p> TYPE: <code>dict</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Optional[Tuple[List[Document], List[Document]]]</code> <p>Tuple[List[Document], List[Document]]: The ingested content docs and extra docs.</p> <ul> <li>chunk_docs: the docs for retrieving, include information such as main text, methods. Might be None if nothing is parsed (auto_parse_paper fails.)</li> <li>extra_docs: docs that involve supplementary information such as references. Might be None.</li> </ul> Source code in <code>labridge\\func_modules\\paper\\parse\\paper_reader.py</code> <pre><code>def read_single_paper(\n\tself,\n\tfile_path: Union[Path, str],\n\tshow_progress: bool = True,\n\textra_metadata: dict = None,\n) -&gt; Optional[Tuple[List[Document], List[Document]]]:\n\tr\"\"\"\n\tRead a single pdf paper.\n\n\tArgs:\n\t\tfile_path (Union[Path, str]): the path of pdf paper.\n\t\tshow_progress (bool): show parsing progress.\n\t\textra_metadata (dict): Existing metadata obtained by approaches such as arXiv API.\n\n\tReturns:\n\t\tTuple[List[Document], List[Document]]:\n\t\t\tThe ingested content docs and extra docs.\n\n\t\t\t- chunk_docs: the docs for retrieving, include information such as main text, methods.\n\t\t\tMight be None if nothing is parsed (auto_parse_paper fails.)\n\t\t\t- extra_docs: docs that involve supplementary information such as references.\n\t\t\tMight be None.\n\t\"\"\"\n\tif isinstance(file_path, str):\n\t\tfile_path = Path(file_path)\n\tif str(file_path)[-4:] != '.pdf':\n\t\traise ValueError(\"Expect a PDF file.\")\n\tif show_progress:\n\t\tprint_text(f\"&gt;&gt;&gt; Loading {file_path}\", color=\"blue\", end=\"\\n\")\n\tparsed_docs = auto_parse_paper(\n\t\tfile_path=file_path,\n\t\tsource_analyzer=self.source_analyzer,\n\t\tuse_llm_for_source=self.use_llm_for_source\n\t)\n\n\tchunk_docs, extra_docs, metadata_docs = [], [], []\n\tfor doc in parsed_docs:\n\t\tif doc.metadata[CONTENT_TYPE_NAME] in MetadataContents:\n\t\t\tmetadata_docs.append(doc)\n\t\telif doc.metadata[CONTENT_TYPE_NAME] in ChunkContents:\n\t\t\tchunk_docs.append(doc)\n\t\telse:\n\t\t\textra_docs.append(doc)\n\n\t# metadata\n\tpaper_metadata = dict()\n\n\tif self.extract_metadata:\n\t\tpaper_metadata = self.metadata_extractor.extract_paper_metadata(\n\t\t\tpdf_path=file_path,\n\t\t\textra_metadata=extra_metadata,\n\t\t)\n\t\tif paper_metadata is None:\n\t\t\treturn None\n\n\t\tfor meta_doc in metadata_docs:\n\t\t\tmetadata_name = meta_doc.metadata[CONTENT_TYPE_NAME]\n\t\t\tif metadata_name not in paper_metadata.keys():\n\t\t\t\tpaper_metadata[metadata_name] = meta_doc.text\n\n\tpossessor = self.get_paper_possessor(file_path)\n\tpaper_metadata[PAPER_POSSESSOR] = possessor\n\tpaper_metadata[PAPER_REL_FILE_PATH] = str(file_path.relative_to(self.root))\n\n\tfor idx, doc in enumerate(parsed_docs):\n\t\tdoc.metadata.update(paper_metadata)\n\t\tif self.filename_as_id:\n\t\t\trel_path = str(file_path.relative_to(self.root))\n\t\t\tdoc.id_ = f\"{rel_path!s}_{doc.metadata[CONTENT_TYPE_NAME]}\"\n\treturn chunk_docs, extra_docs\n</code></pre>"},{"location":"code_docs/func_modules/paper/parse/extractors/metadata_extract/","title":"Metadata extract","text":""},{"location":"code_docs/func_modules/paper/parse/extractors/metadata_extract/#labridge.func_modules.paper.parse.extractors.metadata_extract","title":"<code>labridge.func_modules.paper.parse.extractors.metadata_extract</code>","text":""},{"location":"code_docs/func_modules/paper/parse/extractors/metadata_extract/#labridge.func_modules.paper.parse.extractors.metadata_extract.PaperMetadataExtractor","title":"<code>labridge.func_modules.paper.parse.extractors.metadata_extract.PaperMetadataExtractor</code>","text":"<p>This class uses LLM to extracts metadata from a paper.</p> <p>The LLM is instructed to extract all <code>DEFAULT_NECESSARY_METADATA</code>. The LLM is encourages to extract <code>DEFAULT_OPTIONAL_METADATA</code>.</p> PARAMETER DESCRIPTION <code>llm</code> <p>The used LLM.</p> <p> TYPE: <code>LLM</code> DEFAULT: <code>None</code> </p> <code>necessary_metadata</code> <p>The LLM is instructed to extract all necessary_metadata. Defaults to <code>DEFAULT_NECESSARY_METADATA</code>.</p> <p> TYPE: <code>Dict[str, str]</code> DEFAULT: <code>None</code> </p> <code>optional_metadata</code> <p>The LLM is encourages to extract optional_metadata. Defaults to <code>DEFAULT_OPTIONAL_METADATA</code>.</p> <p> TYPE: <code>Dict[str, str]</code> DEFAULT: <code>None</code> </p> <code>max_retry_times</code> <p>The maximum retry times for extracting necessary_metadata.</p> <p> TYPE: <code>int</code> DEFAULT: <code>2</code> </p> <code>service_context</code> <p>The context including llm, embed_model, etc.</p> <p> TYPE: <code>ServiceContext</code> DEFAULT: <code>None</code> </p> Source code in <code>labridge\\func_modules\\paper\\parse\\extractors\\metadata_extract.py</code> <pre><code>class PaperMetadataExtractor:\n\tr\"\"\"\n\tThis class uses LLM to extracts metadata from a paper.\n\n\tThe LLM is instructed to extract all `DEFAULT_NECESSARY_METADATA`.\n\tThe LLM is encourages to extract `DEFAULT_OPTIONAL_METADATA`.\n\n\tArgs:\n\t\tllm (LLM): The used LLM.\n\t\tnecessary_metadata (Dict[str, str]): The LLM is instructed to extract all necessary_metadata.\n\t\t\tDefaults to `DEFAULT_NECESSARY_METADATA`.\n\t\toptional_metadata (Dict[str, str]): The LLM is encourages to extract optional_metadata.\n\t\t\tDefaults to `DEFAULT_OPTIONAL_METADATA`.\n\t\tmax_retry_times (int): The maximum retry times for extracting necessary_metadata.\n\t\tservice_context (ServiceContext): The context including llm, embed_model, etc.\n\t\"\"\"\n\n\tdef __init__(\n\t\tself,\n\t\tllm: LLM = None,\n\t\tnecessary_metadata: Dict[str, str] = None,\n\t\toptional_metadata: Dict[str, str] = None,\n\t\tmax_retry_times: int = 2,\n\t\tservice_context: ServiceContext = None,\n\t):\n\t\tself.necessary_metadata = necessary_metadata or DEFAULT_NECESSARY_METADATA\n\t\tself.optional_metadata = optional_metadata or DEFAULT_OPTIONAL_METADATA\n\t\tif llm is None:\n\t\t\tself.llm = llm_from_settings_or_context(Settings, service_context)\n\t\telse:\n\t\t\tself.llm = llm\n\n\t\tself.prompt_tmpl = self.get_prompt_tmpl()\n\t\tself.crossref_worker = CrossRefWorker()\n\t\tself.query_engine = SingleQueryEngine(llm=llm, prompt_tmpl=self.prompt_tmpl)\n\t\tself.max_retry_times = max_retry_times\n\n\tdef _default_transformations(self) -&gt; List[TransformComponent]:\n\t\treturn [\n\t\t\t\tSentenceSplitter(chunk_size=1024, chunk_overlap=256, include_metadata=True),\n\t\t\t\tKeywordExtractor(keywords=5, llm=self.llm),\n\t\t\t]\n\n\tdef get_prompt_tmpl(\n\t\tself,\n\t\tnecessary_metadata: Dict[str, str] = None,\n\t\toptional_metadata: Dict[str, str] = None,\n\t) -&gt; str:\n\t\tr\"\"\"\n\t\tThis function is used to get the prompt template used for extracting metadata, according to the\n\t\t`necessary_metadata` and `optional_metadata`.\n\n\t\tArgs:\n\t\t\tnecessary_metadata (Dict[str, str]): necessary metadata, Defaults to `self.necessary_metadata`.\n\t\t\toptional_metadata (Dict[str, str]): optional metadata, Defaults to `self.optional_metadata`.\n\t\t\"\"\"\n\t\tnecessary_metadata = necessary_metadata or self.necessary_metadata\n\t\toptional_metadata = optional_metadata or self.optional_metadata\n\n\t\ttmpl = (\"Here is the first page of a research paper. \"\n\t\t\t\t\"You need try to extract some information from it.\\n\\n\"\n\t\t\t\t\"The NECESSARY metadata that you MUST extract contain:\\n\")\n\t\tnecessary_metadata_names = ', '.join(list(necessary_metadata.keys()))\n\t\ttmpl += necessary_metadata_names\n\t\ttmpl += (\"\\n\\nIt is better to extract the following metadata,\"\n\t\t\t\t \"But if a optional metadata does not appear in the paper, you do not need to output it.\\n\")\n\t\toptional_metadata_names = ', '.join(list(optional_metadata.keys()))\n\t\ttmpl += optional_metadata_names\n\t\ttmpl += (\"\\n\\n\"\n\t\t\t\t \"Here are some suggestions for you to extract these metadata:\")\n\t\ttmpl += \"\\n\\nSuggestions for extracting NECESSARY metadata:\\n\"\n\n\t\tfor key in necessary_metadata.keys():\n\t\t\ttmpl += f\"**{key}**: {necessary_metadata[key]}\\n\"\n\n\t\ttmpl += (\"\\n\\n\"\n\t\t\t\t \"Suggestions for extracting optional metadata:\\n\")\n\t\tfor key in optional_metadata.keys():\n\t\t\ttmpl += f\"**{key}**: {optional_metadata[key]}\\n\"\n\t\ttmpl += (\"\\n\\n\"\n\t\t\t\t \"The first page of the paper is as follows:\\n\"\n\t\t\t\t \"{}\")\n\t\ttmpl += (\"\\n\\nOutput your extracted metadata as the following FORMAT:\\n\"\n\t\t\t\t \"**metadata_name**: &lt;extracted corresponding metadata&gt;\\n\\n\"\n\t\t\t\t \"List your extracted metadata as follows:\\n\\n\")\n\n\t\tfor key in necessary_metadata.keys():\n\t\t\ttmpl += f\"**{key}**: \\n\\n\"\n\t\tfor key in optional_metadata.keys():\n\t\t\ttmpl += f\"**{key}**: \\n\\n\"\n\t\treturn tmpl\n\n\tdef _set_query_prompt(\n\t\tself,\n\t\tnecessary_metadata: Dict[str, str] = None,\n\t\toptional_metadata: Dict[str, str] = None,\n\t):\n\t\tr\"\"\" If both `necessary_metadata` and `optional_metadata` are None, set the default prompt. \"\"\"\n\t\tself.query_engine.prompt_tmpl = self.get_prompt_tmpl(necessary_metadata, optional_metadata)\n\n\tdef metadata_output_format(self, llm_answer: str) -&gt; Dict[str, str]:\n\t\tr\"\"\"\n\t\tThe LLM is supposed to answer like this:\n\n\t\t- **metadata_name 1**: extracted metadata 1.\n\t\t- **metadata_name 2**: extracted metadata 2.\n\n\t\tExtract a metadata dictionary from the answer of llm.\n\n\t\tArgs:\n\t\t\tllm_answer (str): The LLM Output.\n\t\t\"\"\"\n\t\tstr_list = llm_answer.split(\"**\")\n\t\tmetadata = dict()\n\n\t\tidx = 0\n\t\t# key: 1 v: 2\n\t\twhile 2 * idx + 2 &lt; len(str_list):\n\t\t\tkey = str_list[2 * idx + 1]\n\t\t\tval = str_list[2 * idx + 2]\n\t\t\tkey = key.replace(\"\\n\", \"\")\n\t\t\tval = val.replace(\"\\n\", \"\")\n\t\t\tif key in self.necessary_metadata.keys() or key in self.optional_metadata.keys():\n\t\t\t\tmetadata[key] = val.replace(\": \", \"\", 1)\n\t\t\tidx += 1\n\t\treturn metadata\n\n\tdef _extract_metadata(\n\t\tself,\n\t\tpdf_path: Union[Path, str] = None,\n\t\tpdf_docs: List[Document] = None,\n\t\tnecessary_metadata: Dict[str, str] = None,\n\t\toptional_metadata: Dict[str, str] = None,\n\t) -&gt; Dict[str, str]:\n\t\tr\"\"\"\n\t\tUse the LLM to extract metadata of a paper.\n\n\t\tArgs:\n\t\t\tpdf_path: (Union[Path, str]): the path of a pdf paper.\n\t\t\tpdf_docs (List[Document]): the documents of a pdf paper.\n\t\t\tnecessary_metadata (Dict[str, str]):\n\t\t\toptional_metadata (optional_metadata):\n\n\t\tReturns:\n\t\t\tmetadata (Dict[str, str]): The extracted meta data.\n\t\t\"\"\"\n\n\t\tif pdf_path is not None:\n\t\t\tpdf_docs = PyMuPDFReader().load_data(file_path=pdf_path)\n\t\telif pdf_docs is None:\n\t\t\traise ValueError(\"pdf_path and pdf_docs can not both be None.\")\n\n\t\tfirst_page = pdf_docs[0].text\n\t\tself._set_query_prompt(necessary_metadata, optional_metadata)\n\t\tresponse = self.query_engine.query(first_page)\n\t\t# reset prompt\n\t\tself._set_query_prompt()\n\t\textract_text = response.response\n\t\tmetadata = self.metadata_output_format(extract_text)\n\t\treturn metadata\n\n\tdef _lacked_metadata(self, paper_metadata: Dict[str, str]) -&gt; Tuple[Dict, Dict]:\n\t\tr\"\"\"\n\t\tReturn current lacked metadata.\n\n\t\tArgs:\n\t\t\tpaper_metadata (Dict[str, str]): Extracted metadata.\n\n\t\tReturns:\n\t\t\tTuple[Dict, Dict]: The lacked necessary metadata and lacked optional metadata\n\t\t\"\"\"\n\t\tlack_necessary_keys = set(self.necessary_metadata.keys()) - set(paper_metadata.keys())\n\t\tlack_optional_keys = set(self.optional_metadata.keys()) - set(paper_metadata.keys())\n\n\t\tlack_necessary_metadata = dict()\n\t\tlack_optional_metadata = dict()\n\t\tfor key in lack_necessary_keys:\n\t\t\tlack_necessary_metadata.update({key: self.necessary_metadata[key]})\n\n\t\tfor key in lack_optional_keys:\n\t\t\tlack_optional_metadata.update({key: self.optional_metadata[key]})\n\n\t\treturn lack_necessary_metadata, lack_optional_metadata\n\n\tdef extract_paper_metadata(\n\t\tself,\n\t\tpdf_path: Union[Path, str] = None,\n\t\tpdf_docs: List[Document] = None,\n\t\tshow_progress: bool = True,\n\t\textra_metadata: dict = None,\n\t) -&gt; Optional[Dict[str, str]]:\n\t\tr\"\"\"\n\t\tExtract required metadata from a paper.\n\t\tTitle and DOI is necessary, we will use the CrossRef API to get the DOI of a paper according to its title.\n\t\tIf any of them misses, this method will return None.\n\n\t\tArgs:\n\t\t\tpdf_path (Union[Path, str]): The file path of the paper.\n\t\t\tpdf_docs (List[Document]): If the pdf_path is not provided, the provided pdf_docs will be used.\n\t\t\t\tpdf_docs and pdf_path can not all be None.\n\t\t\tshow_progress (bool): Whether to show the inner progress.\n\t\t\textra_metadata (dict): Existing metadata obtained by approaches such as arXiv API.\n\n\t\tReturns:\n\t\t\tDict[str, str]: The extracted metadata.\n\t\t\"\"\"\n\t\tif pdf_path:\n\t\t\tpdf_docs = PyMuPDFReader().load_data(file_path=pdf_path)\n\t\telif pdf_docs is None:\n\t\t\traise ValueError(\"pdf_path and pdf_docs can not both be None.\")\n\n\t\tpaper_metadata = extra_metadata or dict()\n\t\tlack_necessary_metadata, _ = self._lacked_metadata(paper_metadata)\n\t\tretry_count = 0\n\t\twhile len(lack_necessary_metadata.keys()) &gt; 0 and retry_count &lt;= self.max_retry_times:\n\t\t\tnew_metadata = self._extract_metadata(\n\t\t\t\tpdf_docs=pdf_docs,\n\t\t\t\tnecessary_metadata=lack_necessary_metadata,\n\t\t\t\toptional_metadata=self.optional_metadata,\n\t\t\t)\n\t\t\tretry_count += 1\n\t\t\tif show_progress:\n\t\t\t\tprint_text(f\"&gt;&gt;&gt;\\tExtract try idx {retry_count}: {list(new_metadata.keys())}\", color=\"cyan\", end=\"\\n\")\n\t\t\tpaper_metadata.update(new_metadata)\n\t\t\tlack_necessary_metadata, _ = self._lacked_metadata(paper_metadata)\n\n\t\ttitle = paper_metadata.get(PAPER_TITLE, None)\n\t\tif title is None:\n\t\t\treturn None\n\n\t\t# find doi according to title\n\t\tdoi = paper_metadata.get(PAPER_DOI, None)\n\t\tif doi is None:\n\t\t\tdoi = self.crossref_worker.find_doi_by_title(title=title)\n\t\tif doi is None:\n\t\t\tprint(\"DOI find fails.\")\n\t\t\treturn None\n\n\t\tpaper_metadata[PAPER_DOI] = doi\n\t\treturn paper_metadata\n</code></pre>"},{"location":"code_docs/func_modules/paper/parse/extractors/metadata_extract/#labridge.func_modules.paper.parse.extractors.metadata_extract.PaperMetadataExtractor.extract_paper_metadata","title":"<code>labridge.func_modules.paper.parse.extractors.metadata_extract.PaperMetadataExtractor.extract_paper_metadata(pdf_path=None, pdf_docs=None, show_progress=True, extra_metadata=None)</code>","text":"<p>Extract required metadata from a paper. Title and DOI is necessary, we will use the CrossRef API to get the DOI of a paper according to its title. If any of them misses, this method will return None.</p> PARAMETER DESCRIPTION <code>pdf_path</code> <p>The file path of the paper.</p> <p> TYPE: <code>Union[Path, str]</code> DEFAULT: <code>None</code> </p> <code>pdf_docs</code> <p>If the pdf_path is not provided, the provided pdf_docs will be used. pdf_docs and pdf_path can not all be None.</p> <p> TYPE: <code>List[Document]</code> DEFAULT: <code>None</code> </p> <code>show_progress</code> <p>Whether to show the inner progress.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>extra_metadata</code> <p>Existing metadata obtained by approaches such as arXiv API.</p> <p> TYPE: <code>dict</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Optional[Dict[str, str]]</code> <p>Dict[str, str]: The extracted metadata.</p> Source code in <code>labridge\\func_modules\\paper\\parse\\extractors\\metadata_extract.py</code> <pre><code>def extract_paper_metadata(\n\tself,\n\tpdf_path: Union[Path, str] = None,\n\tpdf_docs: List[Document] = None,\n\tshow_progress: bool = True,\n\textra_metadata: dict = None,\n) -&gt; Optional[Dict[str, str]]:\n\tr\"\"\"\n\tExtract required metadata from a paper.\n\tTitle and DOI is necessary, we will use the CrossRef API to get the DOI of a paper according to its title.\n\tIf any of them misses, this method will return None.\n\n\tArgs:\n\t\tpdf_path (Union[Path, str]): The file path of the paper.\n\t\tpdf_docs (List[Document]): If the pdf_path is not provided, the provided pdf_docs will be used.\n\t\t\tpdf_docs and pdf_path can not all be None.\n\t\tshow_progress (bool): Whether to show the inner progress.\n\t\textra_metadata (dict): Existing metadata obtained by approaches such as arXiv API.\n\n\tReturns:\n\t\tDict[str, str]: The extracted metadata.\n\t\"\"\"\n\tif pdf_path:\n\t\tpdf_docs = PyMuPDFReader().load_data(file_path=pdf_path)\n\telif pdf_docs is None:\n\t\traise ValueError(\"pdf_path and pdf_docs can not both be None.\")\n\n\tpaper_metadata = extra_metadata or dict()\n\tlack_necessary_metadata, _ = self._lacked_metadata(paper_metadata)\n\tretry_count = 0\n\twhile len(lack_necessary_metadata.keys()) &gt; 0 and retry_count &lt;= self.max_retry_times:\n\t\tnew_metadata = self._extract_metadata(\n\t\t\tpdf_docs=pdf_docs,\n\t\t\tnecessary_metadata=lack_necessary_metadata,\n\t\t\toptional_metadata=self.optional_metadata,\n\t\t)\n\t\tretry_count += 1\n\t\tif show_progress:\n\t\t\tprint_text(f\"&gt;&gt;&gt;\\tExtract try idx {retry_count}: {list(new_metadata.keys())}\", color=\"cyan\", end=\"\\n\")\n\t\tpaper_metadata.update(new_metadata)\n\t\tlack_necessary_metadata, _ = self._lacked_metadata(paper_metadata)\n\n\ttitle = paper_metadata.get(PAPER_TITLE, None)\n\tif title is None:\n\t\treturn None\n\n\t# find doi according to title\n\tdoi = paper_metadata.get(PAPER_DOI, None)\n\tif doi is None:\n\t\tdoi = self.crossref_worker.find_doi_by_title(title=title)\n\tif doi is None:\n\t\tprint(\"DOI find fails.\")\n\t\treturn None\n\n\tpaper_metadata[PAPER_DOI] = doi\n\treturn paper_metadata\n</code></pre>"},{"location":"code_docs/func_modules/paper/parse/extractors/metadata_extract/#labridge.func_modules.paper.parse.extractors.metadata_extract.PaperMetadataExtractor.get_prompt_tmpl","title":"<code>labridge.func_modules.paper.parse.extractors.metadata_extract.PaperMetadataExtractor.get_prompt_tmpl(necessary_metadata=None, optional_metadata=None)</code>","text":"<p>This function is used to get the prompt template used for extracting metadata, according to the <code>necessary_metadata</code> and <code>optional_metadata</code>.</p> PARAMETER DESCRIPTION <code>necessary_metadata</code> <p>necessary metadata, Defaults to <code>self.necessary_metadata</code>.</p> <p> TYPE: <code>Dict[str, str]</code> DEFAULT: <code>None</code> </p> <code>optional_metadata</code> <p>optional metadata, Defaults to <code>self.optional_metadata</code>.</p> <p> TYPE: <code>Dict[str, str]</code> DEFAULT: <code>None</code> </p> Source code in <code>labridge\\func_modules\\paper\\parse\\extractors\\metadata_extract.py</code> <pre><code>def get_prompt_tmpl(\n\tself,\n\tnecessary_metadata: Dict[str, str] = None,\n\toptional_metadata: Dict[str, str] = None,\n) -&gt; str:\n\tr\"\"\"\n\tThis function is used to get the prompt template used for extracting metadata, according to the\n\t`necessary_metadata` and `optional_metadata`.\n\n\tArgs:\n\t\tnecessary_metadata (Dict[str, str]): necessary metadata, Defaults to `self.necessary_metadata`.\n\t\toptional_metadata (Dict[str, str]): optional metadata, Defaults to `self.optional_metadata`.\n\t\"\"\"\n\tnecessary_metadata = necessary_metadata or self.necessary_metadata\n\toptional_metadata = optional_metadata or self.optional_metadata\n\n\ttmpl = (\"Here is the first page of a research paper. \"\n\t\t\t\"You need try to extract some information from it.\\n\\n\"\n\t\t\t\"The NECESSARY metadata that you MUST extract contain:\\n\")\n\tnecessary_metadata_names = ', '.join(list(necessary_metadata.keys()))\n\ttmpl += necessary_metadata_names\n\ttmpl += (\"\\n\\nIt is better to extract the following metadata,\"\n\t\t\t \"But if a optional metadata does not appear in the paper, you do not need to output it.\\n\")\n\toptional_metadata_names = ', '.join(list(optional_metadata.keys()))\n\ttmpl += optional_metadata_names\n\ttmpl += (\"\\n\\n\"\n\t\t\t \"Here are some suggestions for you to extract these metadata:\")\n\ttmpl += \"\\n\\nSuggestions for extracting NECESSARY metadata:\\n\"\n\n\tfor key in necessary_metadata.keys():\n\t\ttmpl += f\"**{key}**: {necessary_metadata[key]}\\n\"\n\n\ttmpl += (\"\\n\\n\"\n\t\t\t \"Suggestions for extracting optional metadata:\\n\")\n\tfor key in optional_metadata.keys():\n\t\ttmpl += f\"**{key}**: {optional_metadata[key]}\\n\"\n\ttmpl += (\"\\n\\n\"\n\t\t\t \"The first page of the paper is as follows:\\n\"\n\t\t\t \"{}\")\n\ttmpl += (\"\\n\\nOutput your extracted metadata as the following FORMAT:\\n\"\n\t\t\t \"**metadata_name**: &lt;extracted corresponding metadata&gt;\\n\\n\"\n\t\t\t \"List your extracted metadata as follows:\\n\\n\")\n\n\tfor key in necessary_metadata.keys():\n\t\ttmpl += f\"**{key}**: \\n\\n\"\n\tfor key in optional_metadata.keys():\n\t\ttmpl += f\"**{key}**: \\n\\n\"\n\treturn tmpl\n</code></pre>"},{"location":"code_docs/func_modules/paper/parse/extractors/metadata_extract/#labridge.func_modules.paper.parse.extractors.metadata_extract.PaperMetadataExtractor.metadata_output_format","title":"<code>labridge.func_modules.paper.parse.extractors.metadata_extract.PaperMetadataExtractor.metadata_output_format(llm_answer)</code>","text":"<p>The LLM is supposed to answer like this:</p> <ul> <li>metadata_name 1: extracted metadata 1.</li> <li>metadata_name 2: extracted metadata 2.</li> </ul> <p>Extract a metadata dictionary from the answer of llm.</p> PARAMETER DESCRIPTION <code>llm_answer</code> <p>The LLM Output.</p> <p> TYPE: <code>str</code> </p> Source code in <code>labridge\\func_modules\\paper\\parse\\extractors\\metadata_extract.py</code> <pre><code>def metadata_output_format(self, llm_answer: str) -&gt; Dict[str, str]:\n\tr\"\"\"\n\tThe LLM is supposed to answer like this:\n\n\t- **metadata_name 1**: extracted metadata 1.\n\t- **metadata_name 2**: extracted metadata 2.\n\n\tExtract a metadata dictionary from the answer of llm.\n\n\tArgs:\n\t\tllm_answer (str): The LLM Output.\n\t\"\"\"\n\tstr_list = llm_answer.split(\"**\")\n\tmetadata = dict()\n\n\tidx = 0\n\t# key: 1 v: 2\n\twhile 2 * idx + 2 &lt; len(str_list):\n\t\tkey = str_list[2 * idx + 1]\n\t\tval = str_list[2 * idx + 2]\n\t\tkey = key.replace(\"\\n\", \"\")\n\t\tval = val.replace(\"\\n\", \"\")\n\t\tif key in self.necessary_metadata.keys() or key in self.optional_metadata.keys():\n\t\t\tmetadata[key] = val.replace(\": \", \"\", 1)\n\t\tidx += 1\n\treturn metadata\n</code></pre>"},{"location":"code_docs/func_modules/paper/parse/extractors/source_analyze/","title":"Source analyze","text":""},{"location":"code_docs/func_modules/paper/parse/extractors/source_analyze/#labridge.func_modules.paper.parse.extractors.source_analyze","title":"<code>labridge.func_modules.paper.parse.extractors.source_analyze</code>","text":""},{"location":"code_docs/func_modules/paper/parse/extractors/source_analyze/#labridge.func_modules.paper.parse.extractors.source_analyze.PaperSourceAnalyzer","title":"<code>labridge.func_modules.paper.parse.extractors.source_analyze.PaperSourceAnalyzer</code>","text":"<p>This class analyze the source of the paper, such as 'Nature', 'IEEE'.</p> <p>In default, the source analysis bases on keyword occurrence count. Also, LLM can be used to help analyzing the source.</p> PARAMETER DESCRIPTION <code>llm</code> <p>The used LLM.</p> <p> TYPE: <code>LLM</code> DEFAULT: <code>None</code> </p> <code>service_context</code> <p>The service context.</p> <p> TYPE: <code>ServiceContext</code> DEFAULT: <code>None</code> </p> <code>keyword_count_threshold</code> <p>A PaperSource is selected as a candidate only if its corresponding keyword occurrence count exceed this threshold.</p> <p> TYPE: <code>int</code> DEFAULT: <code>10</code> </p> Source code in <code>labridge\\func_modules\\paper\\parse\\extractors\\source_analyze.py</code> <pre><code>class PaperSourceAnalyzer:\n\tr\"\"\"\n\tThis class analyze the source of the paper, such as 'Nature', 'IEEE'.\n\n\tIn default, the source analysis bases on keyword occurrence count.\n\tAlso, LLM can be used to help analyzing the source.\n\n\tArgs:\n\t\tllm (LLM): The used LLM.\n\t\tservice_context (ServiceContext): The service context.\n\t\tkeyword_count_threshold (int): A PaperSource is selected as a candidate\n\t\t\tonly if its corresponding keyword occurrence count exceed this threshold.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tllm: LLM = None,\n\t\tservice_context: ServiceContext = None,\n\t\tkeyword_count_threshold: int = 10,\n\t):\n\t\tself.llm = llm or llm_from_settings_or_context(Settings, service_context)\n\t\tself.keyword_count_threshold = keyword_count_threshold\n\n\tdef reader_analyze(self, paper_path: Union[Path, str]) -&gt; PaperSource:\n\t\t\"\"\"\n\t\tAnalyze the paper source using a structured pdf reader.\n\n\t\tArgs:\n\t\t\tpaper_path (Union[Path, str]): The paper path.\n\n\t\tReturns:\n\t\t\tPaperSource: The paper source.\n\t\t\"\"\"\n\t\timport PyPDF2\n\n\t\twith open(paper_path, 'rb') as file:\n\t\t\tfileReader = PyPDF2.PdfReader(file)\n\t\t\tfile_info = fileReader.trailer['/Info']\n\n\t\tsource = None\n\t\tif '/Subject' in file_info.keys():\n\t\t\tsrc_string = file_info['/Subject']\n\t\t\tif len(src_string) &gt;= len(PaperSource.NATURE):\n\t\t\t\tsource = PaperSource.IEEE\n\t\t\t\tfor start in range(len(src_string) - len(PaperSource.NATURE) + 1):\n\t\t\t\t\tif src_string[start: start + len(PaperSource.NATURE)].upper() == PaperSource.NATURE.upper():\n\t\t\t\t\t\tsource = PaperSource.NATURE\n\t\treturn source\n\n\tdef llm_analyze(self, paper_path: Union[Path, str]) -&gt; PaperSource:\n\t\t\"\"\" TODO: using llm. \"\"\"\n\t\treturn PaperSource.DEFAULT\n\n\tdef keyword_analyze(self, paper_path: Union[Path, str]) -&gt; PaperSource:\n\t\tr\"\"\"\n\t\tAnalyze the paper source based on keyword occurrence count.\n\n\t\tArgs:\n\t\t\tpaper_path (Union[Path, str]): The paper path.\n\n\t\tReturns:\n\t\t\tPaperSource: The analyzed paper source.\n\t\t\"\"\"\n\t\timport pymupdf\n\t\timport re\n\n\t\tdoc = pymupdf.open(paper_path)\n\t\tpages = [page.get_text() for page in doc]\n\n\t\t\"\"\" Searching in the text.\"\"\"\n\t\tsource = None\n\t\tcount = 0\n\t\tfor page_text in pages:\n\t\t\tfor t in re.findall(r\"\\w+\", page_text):\n\t\t\t\tif t.strip().upper() == PaperSource.NATURE.upper():\n\t\t\t\t\tcount += 1\n\t\tif count &gt; self.keyword_count_threshold:\n\t\t\tsource = PaperSource.NATURE\n\t\telse:\n\t\t\tsource = PaperSource.IEEE\n\t\treturn source\n\n\tdef analyze_source(self, paper_path: Union[Path, str], use_llm = False) -&gt; PaperSource:\n\t\tr\"\"\"\n\t\tSequentially use `reader_analyze`, `keyword_analyze`, and `llm_analyze` to analyze the paper source\n\n\t\tArgs:\n\t\t\tpaper_path (Union[Path, str]): The paper path.\n\t\t\tuse_llm (bool): Whether to use `llm_analyze`.\n\n\t\tReturns:\n\t\t\tPaperSource\n\t\t\"\"\"\n\t\tsource = self.reader_analyze(paper_path)\n\t\tif source is None:\n\t\t\tsource = self.keyword_analyze(paper_path)\n\t\tif source is None and use_llm:\n\t\t\tsource = self.llm_analyze(paper_path)\n\t\tif source is None:\n\t\t\tsource = PaperSource.DEFAULT\n\t\treturn source\n</code></pre>"},{"location":"code_docs/func_modules/paper/parse/extractors/source_analyze/#labridge.func_modules.paper.parse.extractors.source_analyze.PaperSourceAnalyzer.analyze_source","title":"<code>labridge.func_modules.paper.parse.extractors.source_analyze.PaperSourceAnalyzer.analyze_source(paper_path, use_llm=False)</code>","text":"<p>Sequentially use <code>reader_analyze</code>, <code>keyword_analyze</code>, and <code>llm_analyze</code> to analyze the paper source</p> PARAMETER DESCRIPTION <code>paper_path</code> <p>The paper path.</p> <p> TYPE: <code>Union[Path, str]</code> </p> <code>use_llm</code> <p>Whether to use <code>llm_analyze</code>.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>PaperSource</code> <p>PaperSource</p> Source code in <code>labridge\\func_modules\\paper\\parse\\extractors\\source_analyze.py</code> <pre><code>def analyze_source(self, paper_path: Union[Path, str], use_llm = False) -&gt; PaperSource:\n\tr\"\"\"\n\tSequentially use `reader_analyze`, `keyword_analyze`, and `llm_analyze` to analyze the paper source\n\n\tArgs:\n\t\tpaper_path (Union[Path, str]): The paper path.\n\t\tuse_llm (bool): Whether to use `llm_analyze`.\n\n\tReturns:\n\t\tPaperSource\n\t\"\"\"\n\tsource = self.reader_analyze(paper_path)\n\tif source is None:\n\t\tsource = self.keyword_analyze(paper_path)\n\tif source is None and use_llm:\n\t\tsource = self.llm_analyze(paper_path)\n\tif source is None:\n\t\tsource = PaperSource.DEFAULT\n\treturn source\n</code></pre>"},{"location":"code_docs/func_modules/paper/parse/extractors/source_analyze/#labridge.func_modules.paper.parse.extractors.source_analyze.PaperSourceAnalyzer.keyword_analyze","title":"<code>labridge.func_modules.paper.parse.extractors.source_analyze.PaperSourceAnalyzer.keyword_analyze(paper_path)</code>","text":"<p>Analyze the paper source based on keyword occurrence count.</p> PARAMETER DESCRIPTION <code>paper_path</code> <p>The paper path.</p> <p> TYPE: <code>Union[Path, str]</code> </p> RETURNS DESCRIPTION <code>PaperSource</code> <p>The analyzed paper source.</p> <p> TYPE: <code>PaperSource</code> </p> Source code in <code>labridge\\func_modules\\paper\\parse\\extractors\\source_analyze.py</code> <pre><code>def keyword_analyze(self, paper_path: Union[Path, str]) -&gt; PaperSource:\n\tr\"\"\"\n\tAnalyze the paper source based on keyword occurrence count.\n\n\tArgs:\n\t\tpaper_path (Union[Path, str]): The paper path.\n\n\tReturns:\n\t\tPaperSource: The analyzed paper source.\n\t\"\"\"\n\timport pymupdf\n\timport re\n\n\tdoc = pymupdf.open(paper_path)\n\tpages = [page.get_text() for page in doc]\n\n\t\"\"\" Searching in the text.\"\"\"\n\tsource = None\n\tcount = 0\n\tfor page_text in pages:\n\t\tfor t in re.findall(r\"\\w+\", page_text):\n\t\t\tif t.strip().upper() == PaperSource.NATURE.upper():\n\t\t\t\tcount += 1\n\tif count &gt; self.keyword_count_threshold:\n\t\tsource = PaperSource.NATURE\n\telse:\n\t\tsource = PaperSource.IEEE\n\treturn source\n</code></pre>"},{"location":"code_docs/func_modules/paper/parse/extractors/source_analyze/#labridge.func_modules.paper.parse.extractors.source_analyze.PaperSourceAnalyzer.llm_analyze","title":"<code>labridge.func_modules.paper.parse.extractors.source_analyze.PaperSourceAnalyzer.llm_analyze(paper_path)</code>","text":"Source code in <code>labridge\\func_modules\\paper\\parse\\extractors\\source_analyze.py</code> <pre><code>def llm_analyze(self, paper_path: Union[Path, str]) -&gt; PaperSource:\n\t\"\"\" TODO: using llm. \"\"\"\n\treturn PaperSource.DEFAULT\n</code></pre>"},{"location":"code_docs/func_modules/paper/parse/extractors/source_analyze/#labridge.func_modules.paper.parse.extractors.source_analyze.PaperSourceAnalyzer.reader_analyze","title":"<code>labridge.func_modules.paper.parse.extractors.source_analyze.PaperSourceAnalyzer.reader_analyze(paper_path)</code>","text":"<p>Analyze the paper source using a structured pdf reader.</p> PARAMETER DESCRIPTION <code>paper_path</code> <p>The paper path.</p> <p> TYPE: <code>Union[Path, str]</code> </p> RETURNS DESCRIPTION <code>PaperSource</code> <p>The paper source.</p> <p> TYPE: <code>PaperSource</code> </p> Source code in <code>labridge\\func_modules\\paper\\parse\\extractors\\source_analyze.py</code> <pre><code>def reader_analyze(self, paper_path: Union[Path, str]) -&gt; PaperSource:\n\t\"\"\"\n\tAnalyze the paper source using a structured pdf reader.\n\n\tArgs:\n\t\tpaper_path (Union[Path, str]): The paper path.\n\n\tReturns:\n\t\tPaperSource: The paper source.\n\t\"\"\"\n\timport PyPDF2\n\n\twith open(paper_path, 'rb') as file:\n\t\tfileReader = PyPDF2.PdfReader(file)\n\t\tfile_info = fileReader.trailer['/Info']\n\n\tsource = None\n\tif '/Subject' in file_info.keys():\n\t\tsrc_string = file_info['/Subject']\n\t\tif len(src_string) &gt;= len(PaperSource.NATURE):\n\t\t\tsource = PaperSource.IEEE\n\t\t\tfor start in range(len(src_string) - len(PaperSource.NATURE) + 1):\n\t\t\t\tif src_string[start: start + len(PaperSource.NATURE)].upper() == PaperSource.NATURE.upper():\n\t\t\t\t\tsource = PaperSource.NATURE\n\treturn source\n</code></pre>"},{"location":"code_docs/func_modules/paper/parse/parsers/auto/","title":"Auto","text":""},{"location":"code_docs/func_modules/paper/parse/parsers/auto/#labridge.func_modules.paper.parse.parsers.auto","title":"<code>labridge.func_modules.paper.parse.parsers.auto</code>","text":""},{"location":"code_docs/func_modules/paper/parse/parsers/auto/#labridge.func_modules.paper.parse.parsers.auto.auto_parse_paper","title":"<code>labridge.func_modules.paper.parse.parsers.auto.auto_parse_paper(file_path, source_analyzer, use_llm_for_source)</code>","text":"<p>Automatically parse a paper according to the analyzed paper source.</p> PARAMETER DESCRIPTION <code>file_path</code> <p>The paper path.</p> <p> TYPE: <code>Union[str, Path]</code> </p> <code>source_analyzer</code> <p>The analyzer that analyze the paper source.</p> <p> TYPE: <code>PaperSourceAnalyzer</code> </p> <code>use_llm_for_source</code> <p>Whether to use LLM in the source_analyzer.</p> <p> TYPE: <code>bool</code> </p> RETURNS DESCRIPTION <code>List[Document]</code> <p>List[Document]: The parsed paper documents. For example: A paper from Nature will be seperated into these components: <code>ABSTRACT</code>, <code>MAINTEXT</code>, <code>REFERENCES</code>, <code>METHODS</code>.</p> Source code in <code>labridge\\func_modules\\paper\\parse\\parsers\\auto.py</code> <pre><code>def auto_parse_paper(\n\tfile_path: Union[str, Path],\n\tsource_analyzer: PaperSourceAnalyzer,\n\tuse_llm_for_source: bool,\n) -&gt; List[Document]:\n\tr\"\"\"\n\tAutomatically parse a paper according to the analyzed paper source.\n\n\tArgs:\n\t\tfile_path (Union[str, Path]): The paper path.\n\t\tsource_analyzer (PaperSourceAnalyzer): The analyzer that analyze the paper source.\n\t\tuse_llm_for_source (bool): Whether to use LLM in the source_analyzer.\n\n\tReturns:\n\t\tList[Document]: The parsed paper documents.\n\t\t\tFor example: A paper from Nature will be seperated into these components:\n\t\t\t`ABSTRACT`, `MAINTEXT`, `REFERENCES`, `METHODS`.\n\t\"\"\"\n\tpaper_source = source_analyzer.analyze_source(file_path, use_llm_for_source)\n\n\tif paper_source == PaperSource.NATURE:\n\t\tparser = NaturePaperParser()\n\telif paper_source == PaperSource.IEEE:\n\t\tparser = IEEEPaperParser()\n\telif paper_source == PaperSource.DEFAULT:\n\t\tparser = DefaultPaperParser()\n\telse:\n\t\traise ValueError(\"Invalid paper source.\")\n\n\tdocs = parser.parse_paper(file_path=file_path)\n\treturn docs\n</code></pre>"},{"location":"code_docs/func_modules/paper/parse/parsers/base/","title":"Base","text":""},{"location":"code_docs/func_modules/paper/parse/parsers/base/#labridge.func_modules.paper.parse.parsers.base","title":"<code>labridge.func_modules.paper.parse.parsers.base</code>","text":""},{"location":"code_docs/func_modules/paper/parse/parsers/base/#labridge.func_modules.paper.parse.parsers.base.BasePaperParser","title":"<code>labridge.func_modules.paper.parse.parsers.base.BasePaperParser</code>","text":"<p>This is the base paper parser. The Parser separates a paper into subcomponents according to several separators.</p> PARAMETER DESCRIPTION <code>separators</code> <p>Each tuple includes the separators that separate two components.</p> <p> TYPE: <code>List[Tuple[str]]</code> </p> <code>content_names</code> <p> TYPE: <code>Dict[int, Tuple[str]</code> </p> <code>separator_tolerance</code> <p>The tolerance of mismatch chars.</p> <p> TYPE: <code>int</code> DEFAULT: <code>3</code> </p> Source code in <code>labridge\\func_modules\\paper\\parse\\parsers\\base.py</code> <pre><code>class BasePaperParser:\n\tr\"\"\"\n\tThis is the base paper parser.\n\tThe Parser separates a paper into subcomponents according to several separators.\n\n\tArgs:\n\t\tseparators (List[Tuple[str]]): Each tuple includes the separators that separate two components.\n\t\tcontent_names (Dict[int, Tuple[str]): Key: component index; Value: component name candidates.\n\t\tseparator_tolerance (int): The tolerance of mismatch chars.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tseparators: List[Tuple[str]],\n\t\tcontent_names: Dict[int, Tuple[str]],\n\t\tseparator_tolerance: int = 3\n\t):\n\t\tself.separators = separators\n\t\tself.content_names = content_names\n\t\tself.separator_tolerance = separator_tolerance\n\n\t@abstractmethod\n\tdef parse_title(self, file_path: Union[str, Path]) -&gt; str:\n\t\t...\n\n\tdef to_documents(\n\t\tself,\n\t\tparsed_components: List[str],\n\t\textra_info: Dict[str, str],\n\t) -&gt; List[Document]:\n\t\tr\"\"\"\n\t\tTransform the parsed components to Documents.\n\n\t\tArgs:\n\t\t\tparsed_components (List[str]): The separated component strings.\n\t\t\textra_info (Dict[str, str]): The extra information will be recorded in the Document's metadata.\n\n\t\tReturns:\n\t\t\tList[Document]: The parsed Documents.\n\t\t\"\"\"\n\t\tcomponent_names = self.content_names[len(parsed_components)]\n\t\tdocuments = []\n\n\t\t# merge texts with the same name.\n\t\tmerged_component_names = []\n\t\tmerged_components = []\n\t\tfor idx, name in enumerate(component_names):\n\t\t\tif name not in merged_component_names:\n\t\t\t\tmerged_component_names.append(name)\n\t\t\t\tmerged_components.append(parsed_components[idx])\n\t\t\telse:\n\t\t\t\tname_idx = merged_component_names.index(name)\n\t\t\t\tmerged_components[name_idx] += parsed_components[idx]\n\n\t\tfor idx, component in enumerate(merged_components):\n\t\t\tdoc_info = {CONTENT_TYPE_NAME: merged_component_names[idx]}\n\t\t\tdoc_info.update(extra_info)\n\t\t\tdoc = Document(text=merged_components[idx], extra_info=doc_info)\n\t\t\tdocuments.append(doc)\n\t\treturn documents\n\n\tdef parse_paper(self, file_path: Union[str, Path]) -&gt; List[Document]:\n\t\tr\"\"\"\n\t\tSplit the article into main text, methods, extra info (references, extended data.) according to specific separators.\n\t\tFor example, separators for Nature are:\n\n\t\tExample:\n\t\t\t```python\n\t\t\t&gt;&gt;&gt; [\n\t\t\t... \t(\"Online content\", ),\n\t\t\t... \t(\"Methods\", ),\n\t\t\t... \t(\"Data availability\", \"Code availability\", \"References\")\n\t\t\t... ]\n\t\t\t```\n\n\t\tArgs:\n\t\t\tfile_path (Union[str, Path]): The paper path.\n\n\t\tReturns:\n\t\t\tTuple[List, Optional[str]]:\n\n\t\t\t\t- The separated paper text (List[str]): For example: [Main text, References 1, Methods, References 2]\n\t\t\t\t- The title (Optional[str]): Might be None if PyMuPDF failed to extract the doc toc. In that case you may\n\t\t\t\tneed to search for LLM's help to extract it.\n\t\t\"\"\"\n\t\tif not isinstance(file_path, str) and not isinstance(file_path, Path):\n\t\t\traise TypeError(\"file_path must be a string or Path.\")\n\n\t\tseparators = self.separators\n\t\tdoc = pymupdf.open(file_path)\n\t\tpages = [page.get_textpage() for page in doc]\n\n\t\ttext_blocks = []\n\t\tsep_p = 0\n\t\tcomponents = []\n\t\ttext_in_block = 4\n\t\tfor idx, text_page in enumerate(pages):\n\t\t\tpage_blocks = text_page.extractBLOCKS()\n\t\t\tif idx == 0:\n\t\t\t\tpage_blocks.pop(0)\n\t\t\tfor each_block in page_blocks:\n\t\t\t\tsep_idx = get_sep_idx(each_block[text_in_block], separators, self.separator_tolerance)\n\t\t\t\tif sep_p &lt; len(separators) and sep_idx &gt;= sep_p:\n\t\t\t\t\ttext_list = [block[text_in_block] for block in text_blocks]\n\t\t\t\t\ttext = ''.join(text_list)\n\t\t\t\t\tcomponents.append(text)\n\t\t\t\t\tsep_p = sep_idx + 1\n\t\t\t\t\ttext_blocks = []\n\t\t\t\ttext_blocks.append(each_block)\n\t\telse:\n\t\t\ttext_list = [block[text_in_block] for block in text_blocks]\n\t\t\ttext = ''.join(text_list)\n\t\t\tcomponents.append(text)\n\n\t\textra_info = {\n\t\t\t\"total_pages\": len(doc),\n\t\t\t\"file_path\": str(file_path)\n\t\t}\n\n\t\tdocuments = self.to_documents(parsed_components=components, extra_info=extra_info)\n\t\treturn documents\n</code></pre>"},{"location":"code_docs/func_modules/paper/parse/parsers/base/#labridge.func_modules.paper.parse.parsers.base.BasePaperParser.parse_paper","title":"<code>labridge.func_modules.paper.parse.parsers.base.BasePaperParser.parse_paper(file_path)</code>","text":"<p>Split the article into main text, methods, extra info (references, extended data.) according to specific separators. For example, separators for Nature are:</p> Example <pre><code>&gt;&gt;&gt; [\n...     (\"Online content\", ),\n...     (\"Methods\", ),\n...     (\"Data availability\", \"Code availability\", \"References\")\n... ]\n</code></pre> PARAMETER DESCRIPTION <code>file_path</code> <p>The paper path.</p> <p> TYPE: <code>Union[str, Path]</code> </p> RETURNS DESCRIPTION <code>List[Document]</code> <p>Tuple[List, Optional[str]]:</p> <ul> <li>The separated paper text (List[str]): For example: [Main text, References 1, Methods, References 2]</li> <li>The title (Optional[str]): Might be None if PyMuPDF failed to extract the doc toc. In that case you may need to search for LLM's help to extract it.</li> </ul> Source code in <code>labridge\\func_modules\\paper\\parse\\parsers\\base.py</code> <pre><code>def parse_paper(self, file_path: Union[str, Path]) -&gt; List[Document]:\n\tr\"\"\"\n\tSplit the article into main text, methods, extra info (references, extended data.) according to specific separators.\n\tFor example, separators for Nature are:\n\n\tExample:\n\t\t```python\n\t\t&gt;&gt;&gt; [\n\t\t... \t(\"Online content\", ),\n\t\t... \t(\"Methods\", ),\n\t\t... \t(\"Data availability\", \"Code availability\", \"References\")\n\t\t... ]\n\t\t```\n\n\tArgs:\n\t\tfile_path (Union[str, Path]): The paper path.\n\n\tReturns:\n\t\tTuple[List, Optional[str]]:\n\n\t\t\t- The separated paper text (List[str]): For example: [Main text, References 1, Methods, References 2]\n\t\t\t- The title (Optional[str]): Might be None if PyMuPDF failed to extract the doc toc. In that case you may\n\t\t\tneed to search for LLM's help to extract it.\n\t\"\"\"\n\tif not isinstance(file_path, str) and not isinstance(file_path, Path):\n\t\traise TypeError(\"file_path must be a string or Path.\")\n\n\tseparators = self.separators\n\tdoc = pymupdf.open(file_path)\n\tpages = [page.get_textpage() for page in doc]\n\n\ttext_blocks = []\n\tsep_p = 0\n\tcomponents = []\n\ttext_in_block = 4\n\tfor idx, text_page in enumerate(pages):\n\t\tpage_blocks = text_page.extractBLOCKS()\n\t\tif idx == 0:\n\t\t\tpage_blocks.pop(0)\n\t\tfor each_block in page_blocks:\n\t\t\tsep_idx = get_sep_idx(each_block[text_in_block], separators, self.separator_tolerance)\n\t\t\tif sep_p &lt; len(separators) and sep_idx &gt;= sep_p:\n\t\t\t\ttext_list = [block[text_in_block] for block in text_blocks]\n\t\t\t\ttext = ''.join(text_list)\n\t\t\t\tcomponents.append(text)\n\t\t\t\tsep_p = sep_idx + 1\n\t\t\t\ttext_blocks = []\n\t\t\ttext_blocks.append(each_block)\n\telse:\n\t\ttext_list = [block[text_in_block] for block in text_blocks]\n\t\ttext = ''.join(text_list)\n\t\tcomponents.append(text)\n\n\textra_info = {\n\t\t\"total_pages\": len(doc),\n\t\t\"file_path\": str(file_path)\n\t}\n\n\tdocuments = self.to_documents(parsed_components=components, extra_info=extra_info)\n\treturn documents\n</code></pre>"},{"location":"code_docs/func_modules/paper/parse/parsers/base/#labridge.func_modules.paper.parse.parsers.base.BasePaperParser.to_documents","title":"<code>labridge.func_modules.paper.parse.parsers.base.BasePaperParser.to_documents(parsed_components, extra_info)</code>","text":"<p>Transform the parsed components to Documents.</p> PARAMETER DESCRIPTION <code>parsed_components</code> <p>The separated component strings.</p> <p> TYPE: <code>List[str]</code> </p> <code>extra_info</code> <p>The extra information will be recorded in the Document's metadata.</p> <p> TYPE: <code>Dict[str, str]</code> </p> RETURNS DESCRIPTION <code>List[Document]</code> <p>List[Document]: The parsed Documents.</p> Source code in <code>labridge\\func_modules\\paper\\parse\\parsers\\base.py</code> <pre><code>def to_documents(\n\tself,\n\tparsed_components: List[str],\n\textra_info: Dict[str, str],\n) -&gt; List[Document]:\n\tr\"\"\"\n\tTransform the parsed components to Documents.\n\n\tArgs:\n\t\tparsed_components (List[str]): The separated component strings.\n\t\textra_info (Dict[str, str]): The extra information will be recorded in the Document's metadata.\n\n\tReturns:\n\t\tList[Document]: The parsed Documents.\n\t\"\"\"\n\tcomponent_names = self.content_names[len(parsed_components)]\n\tdocuments = []\n\n\t# merge texts with the same name.\n\tmerged_component_names = []\n\tmerged_components = []\n\tfor idx, name in enumerate(component_names):\n\t\tif name not in merged_component_names:\n\t\t\tmerged_component_names.append(name)\n\t\t\tmerged_components.append(parsed_components[idx])\n\t\telse:\n\t\t\tname_idx = merged_component_names.index(name)\n\t\t\tmerged_components[name_idx] += parsed_components[idx]\n\n\tfor idx, component in enumerate(merged_components):\n\t\tdoc_info = {CONTENT_TYPE_NAME: merged_component_names[idx]}\n\t\tdoc_info.update(extra_info)\n\t\tdoc = Document(text=merged_components[idx], extra_info=doc_info)\n\t\tdocuments.append(doc)\n\treturn documents\n</code></pre>"},{"location":"code_docs/func_modules/paper/parse/parsers/default_parser/","title":"Default parser","text":""},{"location":"code_docs/func_modules/paper/parse/parsers/default_parser/#labridge.func_modules.paper.parse.parsers.default_parser","title":"<code>labridge.func_modules.paper.parse.parsers.default_parser</code>","text":""},{"location":"code_docs/func_modules/paper/parse/parsers/default_parser/#labridge.func_modules.paper.parse.parsers.default_parser.DefaultPaperParser","title":"<code>labridge.func_modules.paper.parse.parsers.default_parser.DefaultPaperParser</code>","text":"<p>The default paper parser will mark the whole paper content as 'MAINTEXT'</p> Source code in <code>labridge\\func_modules\\paper\\parse\\parsers\\default_parser.py</code> <pre><code>class DefaultPaperParser:\n\tr\"\"\"\n\tThe default paper parser will mark the whole paper content as 'MAINTEXT'\n\t\"\"\"\n\tdef parse_paper(self, file_path: Union[str, Path]) -&gt; List[Document]:\n\t\tr\"\"\"\n\t\tParse the paper.\n\n\t\tArgs:\n\t\t\tfile_path (Union[str, Path]):\n\n\t\tReturns:\n\t\t\tList[Document]: The parsed documents.\n\t\t\"\"\"\n\t\tdoc = pymupdf.open(file_path)\n\t\tpages = [page.get_text().encode(\"utf-8\") for page in doc]\n\t\tpaper_text = ''.join([text for text in pages])\n\n\t\textra_info = {\n\t\t\t\"total_pages\": len(doc),\n\t\t\tCONTENT_TYPE_NAME: \"MainText\"\n\t\t}\n\t\tdoc = Document(text=paper_text, extra_info=extra_info)\n\t\treturn [doc,]\n</code></pre>"},{"location":"code_docs/func_modules/paper/parse/parsers/default_parser/#labridge.func_modules.paper.parse.parsers.default_parser.DefaultPaperParser.parse_paper","title":"<code>labridge.func_modules.paper.parse.parsers.default_parser.DefaultPaperParser.parse_paper(file_path)</code>","text":"<p>Parse the paper.</p> PARAMETER DESCRIPTION <code>file_path</code> <p> TYPE: <code>Union[str, Path]</code> </p> RETURNS DESCRIPTION <code>List[Document]</code> <p>List[Document]: The parsed documents.</p> Source code in <code>labridge\\func_modules\\paper\\parse\\parsers\\default_parser.py</code> <pre><code>def parse_paper(self, file_path: Union[str, Path]) -&gt; List[Document]:\n\tr\"\"\"\n\tParse the paper.\n\n\tArgs:\n\t\tfile_path (Union[str, Path]):\n\n\tReturns:\n\t\tList[Document]: The parsed documents.\n\t\"\"\"\n\tdoc = pymupdf.open(file_path)\n\tpages = [page.get_text().encode(\"utf-8\") for page in doc]\n\tpaper_text = ''.join([text for text in pages])\n\n\textra_info = {\n\t\t\"total_pages\": len(doc),\n\t\tCONTENT_TYPE_NAME: \"MainText\"\n\t}\n\tdoc = Document(text=paper_text, extra_info=extra_info)\n\treturn [doc,]\n</code></pre>"},{"location":"code_docs/func_modules/paper/parse/parsers/ieee_parser/","title":"Ieee parser","text":""},{"location":"code_docs/func_modules/paper/parse/parsers/ieee_parser/#labridge.func_modules.paper.parse.parsers.ieee_parser","title":"<code>labridge.func_modules.paper.parse.parsers.ieee_parser</code>","text":""},{"location":"code_docs/func_modules/paper/parse/parsers/ieee_parser/#labridge.func_modules.paper.parse.parsers.ieee_parser.IEEEPaperParser","title":"<code>labridge.func_modules.paper.parse.parsers.ieee_parser.IEEEPaperParser</code>","text":"<p>               Bases: <code>BasePaperParser</code></p> <p>Parse the paper according to the IEEE template.</p> PARAMETER DESCRIPTION <code>separators</code> <p>Each tuple includes the separators that separate two components. Defaults to <code>IEEE_SEPARATORS</code>.</p> <p> TYPE: <code>List[Tuple[str]]</code> DEFAULT: <code>None</code> </p> <code>content_names</code> <p>Defaults to <code>IEEE_CONTENT_NAMES</code>.</p> <p> TYPE: <code>Dict[int, Tuple[str]</code> DEFAULT: <code>None</code> </p> <code>separator_tolerance</code> <p>The tolerance of mismatch chars.</p> <p> TYPE: <code>int</code> DEFAULT: <code>3</code> </p> Source code in <code>labridge\\func_modules\\paper\\parse\\parsers\\ieee_parser.py</code> <pre><code>class IEEEPaperParser(BasePaperParser):\n\tr\"\"\"\n\tParse the paper according to the IEEE template.\n\n\tArgs:\n\t\tseparators (List[Tuple[str]]): Each tuple includes the separators that separate two components.\n\t\t\tDefaults to `IEEE_SEPARATORS`.\n\t\tcontent_names (Dict[int, Tuple[str]): Key: component index; Value: component name candidates.\n\t\t\tDefaults to `IEEE_CONTENT_NAMES`.\n\t\tseparator_tolerance (int): The tolerance of mismatch chars.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tseparators: List[Tuple[str]] = None,\n\t\tcontent_names: Dict[int, Tuple[str]] = None,\n\t\tseparator_tolerance: int = 3\n\t):\n\t\tseparators = separators or IEEE_SEPARATORS\n\t\tcontent_names = content_names or IEEE_CONTENT_NAMES\n\t\tsuper().__init__(separators, content_names, separator_tolerance)\n\n\tdef parse_title(self, file_path: Union[str, Path]) -&gt; str:\n\t\tr\"\"\" Suggest to use LLM to extract title and other information. \"\"\"\n\t\tdoc = pymupdf.open(file_path)\n\t\tpage = doc[0].get_textpage()\n\n\t\tpage_blocks = page.extractBLOCKS()\n\t\ttitle = page_blocks[0][4].replace(\"\\n\", \"\")\n\t\treturn title\n</code></pre>"},{"location":"code_docs/func_modules/paper/parse/parsers/ieee_parser/#labridge.func_modules.paper.parse.parsers.ieee_parser.IEEEPaperParser.parse_title","title":"<code>labridge.func_modules.paper.parse.parsers.ieee_parser.IEEEPaperParser.parse_title(file_path)</code>","text":"<p>Suggest to use LLM to extract title and other information.</p> Source code in <code>labridge\\func_modules\\paper\\parse\\parsers\\ieee_parser.py</code> <pre><code>def parse_title(self, file_path: Union[str, Path]) -&gt; str:\n\tr\"\"\" Suggest to use LLM to extract title and other information. \"\"\"\n\tdoc = pymupdf.open(file_path)\n\tpage = doc[0].get_textpage()\n\n\tpage_blocks = page.extractBLOCKS()\n\ttitle = page_blocks[0][4].replace(\"\\n\", \"\")\n\treturn title\n</code></pre>"},{"location":"code_docs/func_modules/paper/parse/parsers/nature_parser/","title":"Nature parser","text":""},{"location":"code_docs/func_modules/paper/parse/parsers/nature_parser/#labridge.func_modules.paper.parse.parsers.nature_parser","title":"<code>labridge.func_modules.paper.parse.parsers.nature_parser</code>","text":""},{"location":"code_docs/func_modules/paper/parse/parsers/nature_parser/#labridge.func_modules.paper.parse.parsers.nature_parser.NaturePaperParser","title":"<code>labridge.func_modules.paper.parse.parsers.nature_parser.NaturePaperParser</code>","text":"<p>               Bases: <code>BasePaperParser</code></p> <p>Parse the paper according to the Nature template.</p> PARAMETER DESCRIPTION <code>separators</code> <p>Each tuple includes the separators that separate two components. Defaults to <code>NATURE_SEPARATORS</code>.</p> <p> TYPE: <code>List[Tuple[str]]</code> DEFAULT: <code>None</code> </p> <code>content_names</code> <p>Defaults to <code>NATURE_CONTENT_NAMES</code>.</p> <p> TYPE: <code>Dict[int, Tuple[str]</code> DEFAULT: <code>None</code> </p> <code>separator_tolerance</code> <p>The tolerance of mismatch chars.</p> <p> TYPE: <code>int</code> DEFAULT: <code>3</code> </p> Source code in <code>labridge\\func_modules\\paper\\parse\\parsers\\nature_parser.py</code> <pre><code>class NaturePaperParser(BasePaperParser):\n\tr\"\"\"\n\tParse the paper according to the Nature template.\n\n\tArgs:\n\t\tseparators (List[Tuple[str]]): Each tuple includes the separators that separate two components.\n\t\t\tDefaults to `NATURE_SEPARATORS`.\n\t\tcontent_names (Dict[int, Tuple[str]): Key: component index; Value: component name candidates.\n\t\t\tDefaults to `NATURE_CONTENT_NAMES`.\n\t\tseparator_tolerance (int): The tolerance of mismatch chars.\n\t\"\"\"\n\tdef __init__(self,\n\t\t\t\t separators: List[Tuple[str]] = None,\n\t\t\t\t content_names: Dict[int, Tuple[str]] = None,\n\t\t\t\t separator_tolerance: int = 3):\n\t\tseparators = separators or NATURE_SEPARATORS\n\t\tcontent_names = content_names or NATURE_CONTENT_NAMES\n\t\tsuper().__init__(separators, content_names, separator_tolerance)\n\n\tdef parse_title(self, file_path: Union[str, Path]) -&gt; str:\n\t\tr\"\"\" Suggest to use LLM to extract title and other information. \"\"\"\n\t\tdoc = pymupdf.open(file_path)\n\t\ttoc = doc.get_toc()\n\t\ttitle = None\n\t\ttry:\n\t\t\twhile isinstance(toc[0], list):\n\t\t\t\ttoc = toc[0]\n\t\t\t\ttitle = toc[1]\n\t\texcept IndexError:\n\t\t\tprint(f\"&gt;&gt;&gt; PyMupdf failed to get toc from {file_path}\")\n\t\treturn title\n</code></pre>"},{"location":"code_docs/func_modules/paper/parse/parsers/nature_parser/#labridge.func_modules.paper.parse.parsers.nature_parser.NaturePaperParser.parse_title","title":"<code>labridge.func_modules.paper.parse.parsers.nature_parser.NaturePaperParser.parse_title(file_path)</code>","text":"<p>Suggest to use LLM to extract title and other information.</p> Source code in <code>labridge\\func_modules\\paper\\parse\\parsers\\nature_parser.py</code> <pre><code>def parse_title(self, file_path: Union[str, Path]) -&gt; str:\n\tr\"\"\" Suggest to use LLM to extract title and other information. \"\"\"\n\tdoc = pymupdf.open(file_path)\n\ttoc = doc.get_toc()\n\ttitle = None\n\ttry:\n\t\twhile isinstance(toc[0], list):\n\t\t\ttoc = toc[0]\n\t\t\ttitle = toc[1]\n\texcept IndexError:\n\t\tprint(f\"&gt;&gt;&gt; PyMupdf failed to get toc from {file_path}\")\n\treturn title\n</code></pre>"},{"location":"code_docs/func_modules/paper/prompt/store/dir_summary/","title":"Dir summary","text":""},{"location":"code_docs/func_modules/paper/prompt/store/dir_summary/#labridge.func_modules.paper.prompt.store.dir_summary","title":"<code>labridge.func_modules.paper.prompt.store.dir_summary</code>","text":""},{"location":"code_docs/func_modules/paper/prompt/synthesize/paper_summarize/","title":"Paper summarize","text":""},{"location":"code_docs/func_modules/paper/prompt/synthesize/paper_summarize/#labridge.func_modules.paper.prompt.synthesize.paper_summarize","title":"<code>labridge.func_modules.paper.prompt.synthesize.paper_summarize</code>","text":""},{"location":"code_docs/func_modules/paper/prompt/synthesize/synthesize/","title":"Synthesize","text":""},{"location":"code_docs/func_modules/paper/prompt/synthesize/synthesize/#labridge.func_modules.paper.prompt.synthesize.synthesize","title":"<code>labridge.func_modules.paper.prompt.synthesize.synthesize</code>","text":""},{"location":"code_docs/func_modules/paper/retrieve/paper_retriever/","title":"Paper retriever","text":""},{"location":"code_docs/func_modules/paper/retrieve/paper_retriever/#labridge.func_modules.paper.retrieve.paper_retriever","title":"<code>labridge.func_modules.paper.retrieve.paper_retriever</code>","text":""},{"location":"code_docs/func_modules/paper/retrieve/paper_retriever/#labridge.func_modules.paper.retrieve.paper_retriever.PaperRetriever","title":"<code>labridge.func_modules.paper.retrieve.paper_retriever.PaperRetriever</code>","text":"<p>We use hybrid, multi-level retrieving methods.</p> <p>In the first step, the retriever retrieve the vector index and the summary index to get candidate papers. These two index storages are constructed in the class <code>PaperStorage</code>, refer to its docstring for details.</p> <ul> <li>In the vector index, the paper contents except for references are chunked and embedded. The retriever get <code>vector_similarity_top_k</code> most relevant text chunk from the vector index, then we collect their <code>ref_doc_id</code>.</li> <li>In the summary index, each paper is summarized. Both the summary text and the paper chunks are stored. The retriever search in the summary texts to get <code>summary_similarity_top_k</code> most relevant summaries of docs. Similarly, we collect their <code>doc_id</code>.</li> </ul> <p>We have collected several relevant papers in the first step. Subsequently, we use the <code>PaperSummaryLLMPostSelector</code> to rank these papers according to the relevance between their summaries and the query, the relevance scores are given by the LLM. Among these papers, the LLM selects <code>docs_top_k</code> most relevant papers.</p> <p>Finally, we conduct secondary_retrieve among the text chunks of these luckily selected papers. Note that, in this period, we hide all metadata of these nodes from the LLM and the embed model for the sake of grained retrieving. At last, we will get <code>re_retrieve_top_k</code> text chunks.</p> <p>If the <code>final_use_context</code> is set to True, the prev_node and next_node of each node will be added. If the <code>final_use_summary</code> is set to True, the summary_node corresponding to each_node's doc will be added.</p> PARAMETER DESCRIPTION <code>llm</code> <p>the employed LLM.</p> <p> TYPE: <code>LLM</code> </p> <code>paper_vector_retriever</code> <p>the retriever based on the VectorIndex in paper storage.</p> <p> TYPE: <code>VectorIndexRetriever</code> </p> <code>paper_summary_retriever</code> <p>the retriever based on the DocumentSummaryIndex in the paper storage.</p> <p> TYPE: <code>DocumentSummaryIndexEmbeddingRetriever</code> </p> <code>docs_top_k</code> <p>the number of most relevant docs in the second retrieving step.</p> <p> TYPE: <code>int</code> DEFAULT: <code>2</code> </p> <code>re_retrieve_top_k</code> <p>the number of the finally retrieved nodes.</p> <p> TYPE: <code>int</code> DEFAULT: <code>5</code> </p> <code>final_use_context</code> <p>Whether to add the context nodes of each final node.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>final_use_summary</code> <p>Whether to add the summary node of each final node's doc.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> Source code in <code>labridge\\func_modules\\paper\\retrieve\\paper_retriever.py</code> <pre><code>class PaperRetriever:\n\tr\"\"\"\n\tWe use hybrid, multi-level retrieving methods.\n\n\tIn the first step, the retriever retrieve the vector index and the summary index to get candidate papers.\n\tThese two index storages are constructed in the class `PaperStorage`, refer to its docstring for details.\n\n\t- In the vector index, the paper contents except for references are chunked and embedded. The retriever get\n\t`vector_similarity_top_k` most relevant text chunk from the vector index, then we collect their `ref_doc_id`.\n\t- In the summary index, each paper is summarized. Both the summary text and the paper chunks are stored.\n\tThe retriever search in the summary texts to get `summary_similarity_top_k` most relevant summaries of docs.\n\tSimilarly, we collect their `doc_id`.\n\n\tWe have collected several relevant papers in the first step. Subsequently, we use the `PaperSummaryLLMPostSelector`\n\tto rank these papers according to the relevance between their summaries and the query, the relevance scores are\n\tgiven by the LLM. Among these papers, the LLM selects `docs_top_k` most relevant papers.\n\n\tFinally, we conduct secondary_retrieve among the text chunks of these luckily selected papers.\n\tNote that, in this period, we hide all metadata of these nodes from the LLM and the embed model for the sake of\n\tgrained retrieving. At last, we will get `re_retrieve_top_k` text chunks.\n\n\tIf the `final_use_context` is set to True, the prev_node and next_node of each node will be added.\n\tIf the `final_use_summary` is set to True, the summary_node corresponding to each_node's doc will be added.\n\n\tArgs:\n\t\tllm (LLM): the employed LLM.\n\t\tpaper_vector_retriever (VectorIndexRetriever): the retriever based on the VectorIndex in paper storage.\n\t\tpaper_summary_retriever (DocumentSummaryIndexEmbeddingRetriever):\n\t\t\tthe retriever based on the DocumentSummaryIndex in the paper storage.\n\t\tdocs_top_k (int): the number of most relevant docs in the second retrieving step.\n\t\tre_retrieve_top_k (int): the number of the finally retrieved nodes.\n\t\tfinal_use_context (bool): Whether to add the context nodes of each final node.\n\t\tfinal_use_summary (bool): Whether to add the summary node of each final node's doc.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tllm: LLM,\n\t\tpaper_vector_retriever: VectorIndexRetriever,\n\t\tpaper_summary_retriever: DocumentSummaryIndexEmbeddingRetriever,\n\t\tdocs_top_k: int = 2,\n\t\tre_retrieve_top_k: int = 5,\n\t\tfinal_use_context: bool = True,\n\t\tfinal_use_summary: bool = True\n\t):\n\t\tself.paper_vector_retriever = paper_vector_retriever\n\t\tself.paper_summary_retriever = paper_summary_retriever\n\t\tself.paper_summary_post_selector = PaperSummaryLLMPostSelector(\n\t\t\tsummary_nodes=[],\n\t\t\tllm=llm,\n\t\t\tchoice_top_k=docs_top_k,\n\t\t)\n\t\tself.re_retrieve_top_k = re_retrieve_top_k\n\t\tself.final_use_context = final_use_context\n\t\tself.final_use_summary = final_use_summary\n\t\tself.doc_id_to_summary_id = self.paper_summary_retriever._index._index_struct.doc_id_to_summary_id\n\t\tself.summary_id_to_node_ids = self.paper_summary_retriever._index._index_struct.summary_id_to_node_ids\n\t\tself.retrieved_nodes = []\n\t\troot = Path(__file__)\n\t\tfor i in range(5):\n\t\t\troot = root.parent\n\t\tself.root = root\n\n\tdef _exclude_all_llm_metadata(self, node: BaseNode):\n\t\tr\"\"\" Hidden all metadata of a node to LLM. \"\"\"\n\t\tnode.excluded_llm_metadata_keys.extend(list(node.metadata.keys()))\n\n\tdef _exclude_all_embedding_metadata(self, node: BaseNode):\n\t\tr\"\"\" Hidden all metadata of a node to the embed model. \"\"\"\n\t\tnode.excluded_embed_metadata_keys.extend(list(node.metadata.keys()))\n\n\tdef get_ref_info(self) -&gt; List[PaperInfo]:\n\t\tr\"\"\"\n\t\tGet the reference paper infos\n\n\t\tReturns:\n\t\t\tList[PaperInfo]: The reference paper infos in answering.\n\t\t\"\"\"\n\t\tdoc_ids, doc_titles, doc_possessors = [], [], []\n\t\tref_infos = []\n\t\tfor node_score in self.retrieved_nodes:\n\t\t\tref_doc_id = node_score.node.ref_doc_id\n\t\t\tif ref_doc_id not in doc_ids:\n\t\t\t\tdoc_ids.append(ref_doc_id)\n\t\t\t\ttitle = node_score.node.metadata.get(PAPER_TITLE) or ref_doc_id\n\t\t\t\tpossessor = node_score.node.metadata.get(PAPER_POSSESSOR)\n\t\t\t\trel_path = node_score.node.metadata.get(PAPER_REL_FILE_PATH)\n\t\t\t\tif rel_path is None:\n\t\t\t\t\traise ValueError(\"Invalid database.\")\n\t\t\t\tpaper_info = PaperInfo(\n\t\t\t\t\ttitle=title,\n\t\t\t\t\tpossessor=possessor,\n\t\t\t\t\tfile_path=str(self.root / rel_path),\n\t\t\t\t)\n\t\t\t\tref_infos.append(paper_info)\n\n\t\t\t\tdoc_titles.append(title)\n\t\t\t\tdoc_possessors.append(possessor)\n\t\treturn ref_infos\n\n\tdef _secondary_retrieve(\n\t\tself,\n\t\tfinal_doc_ids: List[str],\n\t\titem_to_be_retrieved: str\n\t) -&gt; Tuple[List[NodeWithScore], List[NodeWithScore]]:\n\t\tr\"\"\"\n\t\tSecondary retrieve among the nodes of the selected papers.\n\n\t\tArgs:\n\t\t\tfinal_doc_ids (List[str]): the doc_ids of the selected papers.\n\t\t\titem_to_be_retrieved (str): the retrieving items.\n\n\t\tReturns:\n\t\t\tthe summary_nodes and the content_nodes:\n\n\t\t\t\t- summary_nodes (List[NodeWithScore]): the summary nodes of these docs.\n\t\t\t\t- content_nodes (List[NodeWithScore]): the retrieved nodes among the chunked nodes of these docs.\n\t\t\"\"\"\n\t\t# get all nodes of these docs.\n\t\tsummary_nodes = []\n\t\tall_doc_nodes = []\n\t\tfor doc_id in final_doc_ids:\n\t\t\tsummary_id = self.doc_id_to_summary_id[doc_id]\n\t\t\tsummary_node = self.paper_summary_retriever._index.docstore.get_node(summary_id)\n\t\t\t# exclude metadata of summary nodes for llm using.\n\t\t\tself._exclude_all_llm_metadata(summary_node)\n\t\t\tsummary_nodes.append(NodeWithScore(node=summary_node))\n\n\t\t\t# all doc nodes.\n\t\t\tdoc_node_ids = self.summary_id_to_node_ids[summary_id]\n\t\t\tdoc_nodes = self.paper_summary_retriever._index.docstore.get_nodes(doc_node_ids)\n\t\t\t# exclude metadata of content nodes\n\t\t\tfor doc_node in doc_nodes:\n\t\t\t\tself._exclude_all_llm_metadata(doc_node)\n\t\t\t\tself._exclude_all_embedding_metadata(doc_node)\n\t\t\tall_doc_nodes.extend(doc_nodes)\n\n\t\tcontent_index = VectorStoreIndex(nodes=all_doc_nodes, embed_model=self.paper_vector_retriever._embed_model)\n\t\tcontent_retriever = content_index.as_retriever(similarity_top_k=self.re_retrieve_top_k)\n\t\tcontent_nodes = content_retriever.retrieve(item_to_be_retrieved)\n\t\treturn summary_nodes, content_nodes\n\n\tasync def _asecondary_retrieve(\n\t\tself,\n\t\tfinal_doc_ids: List[str],\n\t\titem_to_be_retrieved: str\n\t) -&gt; Tuple[List[NodeWithScore], List[NodeWithScore]]:\n\t\tr\"\"\"\n\t\tAsynchronous secondary retrieve among the nodes of the selected papers.\n\n\t\tArgs:\n\t\t\tfinal_doc_ids (List[str]): the doc_ids of the selected papers.\n\t\t\titem_to_be_retrieved (str): the retrieving items.\n\n\t\tReturns:\n\t\t\tthe summary_nodes and the content_nodes:\n\n\t\t\t\t- summary_nodes (List[NodeWithScore]): the summary nodes of these docs.\n\t\t\t\t- content_nodes (List[NodeWithScore]): the retrieved nodes among the chunked nodes of these docs.\n\t\t\"\"\"\n\t\tsummary_nodes = []\n\t\tall_doc_nodes = []\n\t\tfor doc_id in final_doc_ids:\n\t\t\tsummary_id = self.doc_id_to_summary_id[doc_id]\n\t\t\tsummary_node = self.paper_summary_retriever._index.docstore.get_node(summary_id)\n\t\t\t# exclude metadata of summary nodes for llm using.\n\t\t\tself._exclude_all_llm_metadata(summary_node)\n\t\t\tsummary_nodes.append(NodeWithScore(node=summary_node))\n\n\t\t\t# all doc nodes.\n\t\t\tdoc_node_ids = self.summary_id_to_node_ids[summary_id]\n\t\t\tdoc_nodes = self.paper_summary_retriever._index.docstore.get_nodes(doc_node_ids)\n\t\t\t# exclude metadata of content nodes\n\t\t\tfor doc_node in doc_nodes:\n\t\t\t\tself._exclude_all_llm_metadata(doc_node)\n\t\t\t\tself._exclude_all_embedding_metadata(doc_node)\n\t\t\tall_doc_nodes.extend(doc_nodes)\n\n\t\tcontent_index = VectorStoreIndex(nodes=all_doc_nodes, embed_model=self.paper_vector_retriever._embed_model)\n\t\tcontent_retriever = content_index.as_retriever(similarity_top_k=self.re_retrieve_top_k)\n\t\tcontent_nodes = await content_retriever.aretrieve(item_to_be_retrieved)\n\t\treturn summary_nodes, content_nodes\n\n\tdef _get_context(self, content_nodes: List[NodeWithScore]) -&gt; List[NodeWithScore]:\n\t\tr\"\"\"\n\t\tGet the 1-hop context nodes of each content node retrieved in the secondary retrieving.\n\t\t\"\"\"\n\t\tcontent_ids = [node.node.node_id for node in content_nodes]\n\t\textra_ids = []\n\t\tfor node in content_nodes:\n\t\t\tprev_node = node.node.prev_node\n\t\t\tnext_node = node.node.next_node\n\t\t\tif prev_node is not None:\n\t\t\t\tprev_id = node.node.prev_node.node_id\n\t\t\t\tif prev_id not in content_ids:\n\t\t\t\t\textra_ids.append(prev_id)\n\t\t\t\t\tcontent_ids.append(prev_id)\n\n\t\t\tif next_node is not None:\n\t\t\t\tnext_id = node.node.next_node.node_id\n\t\t\t\tif next_id not in content_ids:\n\t\t\t\t\textra_ids.append(next_id)\n\t\t\t\t\tcontent_ids.append(next_id)\n\n\t\tcontext_nodes = self.paper_summary_retriever._index.docstore.get_nodes(extra_ids)\n\t\tcontext_nodes = [NodeWithScore(node=node) for node in context_nodes]\n\t\t# exclude metadata in LLM using.\n\t\tfor node in context_nodes:\n\t\t\tself._exclude_all_llm_metadata(node.node)\n\t\treturn context_nodes\n\n\t@dispatcher.span\n\tdef retrieve(\n\t\tself,\n\t\titem_to_be_retrieved: str,\n\t) -&gt; List[NodeWithScore]:\n\t\tr\"\"\"\n\t\tThis tool is used to retrieve academic information in the Laboratory's shared paper database.\n\t\tIt is useful to help answer the user's academic questions.\n\n\t\tArgs:\n\t\t\titem_to_be_retrieved (str): The things that you want to retrieve in the shared paper database.\n\t\t\"\"\"\n\t\t# This docstring is used as the tool description.\n\t\tvector_nodes = self.paper_vector_retriever.retrieve(item_to_be_retrieved)\n\t\tsummary_chunk_nodes = self.paper_summary_retriever.retrieve(item_to_be_retrieved)\n\n\t\thybrid_doc_ids = set()\n\t\tfor node in summary_chunk_nodes + vector_nodes:\n\t\t\thybrid_doc_ids.add(node.node.ref_doc_id)\n\n\t\tdoc_id_to_summary_id = self.paper_summary_retriever._index._index_struct.doc_id_to_summary_id\n\t\thybrid_summary_ids = [doc_id_to_summary_id[doc_id] for doc_id in hybrid_doc_ids]\n\t\tdoc_summary_nodes = self.paper_summary_retriever._index.docstore.get_nodes(hybrid_summary_ids)\n\n\t\tself.paper_summary_post_selector._summary_nodes = doc_summary_nodes\n\t\tfinal_doc_ids = self.paper_summary_post_selector.select(item_to_be_retrieved)\n\n\t\tsummary_nodes, content_nodes = self._secondary_retrieve(\n\t\t\tfinal_doc_ids=final_doc_ids,\n\t\t\titem_to_be_retrieved=item_to_be_retrieved,\n\t\t)\n\n\t\tfinal_nodes = content_nodes\n\t\tif self.final_use_summary:\n\t\t\tfinal_nodes.extend(summary_nodes)\n\n\t\tif self.final_use_context:\n\t\t\tcontext_nodes = self._get_context(content_nodes)\n\t\t\tfinal_nodes.extend(context_nodes)\n\t\tself.retrieved_nodes = final_nodes\n\t\treturn final_nodes\n\n\t@dispatcher.span\n\tasync def aretrieve(\n\t\tself,\n\t\titem_to_be_retrieved: str,\n\t) -&gt; List[NodeWithScore]:\n\t\tr\"\"\"\n\t\tThis tool is used to retrieve academic information in the Laboratory's shared paper database, which contains\n\t\tabundant research papers. It is useful to help you to answer the user's academic questions.\n\n\t\tArgs:\n\t\t\titem_to_be_retrieved (str): The things that you want to retrieve in the shared paper database.\n\t\t\"\"\"\n\t\tvector_nodes = await self.paper_vector_retriever.aretrieve(item_to_be_retrieved)\n\t\tsummary_chunk_nodes = await self.paper_summary_retriever.aretrieve(item_to_be_retrieved)\n\n\t\thybrid_doc_ids = set()\n\t\tfor node in summary_chunk_nodes + vector_nodes:\n\t\t\thybrid_doc_ids.add(node.node.ref_doc_id)\n\n\t\tdoc_id_to_summary_id = self.paper_summary_retriever._index._index_struct.doc_id_to_summary_id\n\t\thybrid_summary_ids = [doc_id_to_summary_id[doc_id] for doc_id in hybrid_doc_ids]\n\t\tdoc_summary_nodes = self.paper_summary_retriever._index.docstore.get_nodes(hybrid_summary_ids)\n\n\t\tself.paper_summary_post_selector._summary_nodes = doc_summary_nodes\n\t\tfinal_doc_ids = await self.paper_summary_post_selector.aselect(item_to_be_retrieved)\n\n\t\tsummary_nodes, content_nodes = self._secondary_retrieve(\n\t\t\tfinal_doc_ids=final_doc_ids,\n\t\t\titem_to_be_retrieved=item_to_be_retrieved,\n\t\t)\n\n\t\tfinal_nodes = content_nodes\n\t\tif self.final_use_summary:\n\t\t\tfinal_nodes.extend(summary_nodes)\n\n\t\tif self.final_use_context:\n\t\t\tcontext_nodes = self._get_context(content_nodes)\n\t\t\tfinal_nodes.extend(context_nodes)\n\t\tself.retrieved_nodes = final_nodes\n\t\treturn final_nodes\n\n\n\t@classmethod\n\tdef from_storage(\n\t\tcls,\n\t\tllm: Optional[LLM] = None,\n\t\tembed_model: Optional[BaseEmbedding] = None,\n\t\tvector_persist_dir: Optional[Union[Path, str]] = None,\n\t\tpaper_summary_persist_dir: Optional[Union[Path, str]] = None,\n\t\tvector_similarity_top_k: Optional[int] = PAPER_VECTOR_TOP_K,\n\t\tsummary_similarity_top_k: Optional[int] = PAPER_SUMMARY_TOP_K,\n\t\tservice_context: Optional[ServiceContext] = None,\n\t\tdocs_top_k: int = PAPER_TOP_K,\n\t\tre_retrieve_top_k: int = PAPER_RETRIEVE_TOP_K,\n\t\tfinal_use_context: bool = True,\n\t\tfinal_use_summary: bool = True,\n\t):\n\t\tr\"\"\"\n\t\tLoad from an existing storage.\n\t\t\"\"\"\n\t\troot = Path(__file__)\n\t\tfor i in range(5):\n\t\t\troot = root.parent\n\n\t\tllm = llm or llm_from_settings_or_context(Settings, service_context)\n\t\tembed_model = embed_model or embed_model_from_settings_or_context(Settings, service_context)\n\n\t\tvector_persist_dir = vector_persist_dir or root / DEFAULT_PAPER_VECTOR_PERSIST_DIR\n\t\tvector_storage_context = StorageContext.from_defaults(persist_dir=vector_persist_dir)\n\t\tvector_index = load_index_from_storage(\n\t\t\tstorage_context=vector_storage_context,\n\t\t\tindex_id=PAPER_VECTOR_INDEX_ID,\n\t\t\tembed_model=embed_model\n\t\t)\n\t\tvector_retriever = vector_index.as_retriever(similarity_top_k=vector_similarity_top_k)\n\n\t\tpaper_summary_persist_dir = paper_summary_persist_dir or root / DEFAULT_PAPER_SUMMARY_PERSIST_DIR\n\t\tpaper_summary_storage_context = StorageContext.from_defaults(persist_dir=paper_summary_persist_dir)\n\t\tpaper_summary_index = load_index_from_storage(\n\t\t\tstorage_context=paper_summary_storage_context,\n\t\t\tindex_id=PAPER_SUMMARY_INDEX_ID,\n\t\t\tllm=llm,\n\t\t\tembed_model=embed_model\n\t\t)\n\t\tsummary_retriever = paper_summary_index.as_retriever(\n\t\t\tretriever_mode=DocumentSummaryRetrieverMode.EMBEDDING,\n\t\t\tsimilarity_top_k=summary_similarity_top_k)\n\t\treturn cls(\n\t\t\tllm = llm,\n\t\t\tpaper_vector_retriever=vector_retriever,\n\t\t\tpaper_summary_retriever=summary_retriever,\n\t\t\tdocs_top_k=docs_top_k,\n\t\t\tre_retrieve_top_k=re_retrieve_top_k,\n\t\t\tfinal_use_context=final_use_context,\n\t\t\tfinal_use_summary=final_use_summary,\n\t\t)\n</code></pre>"},{"location":"code_docs/func_modules/paper/retrieve/paper_retriever/#labridge.func_modules.paper.retrieve.paper_retriever.PaperRetriever.aretrieve","title":"<code>labridge.func_modules.paper.retrieve.paper_retriever.PaperRetriever.aretrieve(item_to_be_retrieved)</code>  <code>async</code>","text":"<p>This tool is used to retrieve academic information in the Laboratory's shared paper database, which contains abundant research papers. It is useful to help you to answer the user's academic questions.</p> PARAMETER DESCRIPTION <code>item_to_be_retrieved</code> <p>The things that you want to retrieve in the shared paper database.</p> <p> TYPE: <code>str</code> </p> Source code in <code>labridge\\func_modules\\paper\\retrieve\\paper_retriever.py</code> <pre><code>@dispatcher.span\nasync def aretrieve(\n\tself,\n\titem_to_be_retrieved: str,\n) -&gt; List[NodeWithScore]:\n\tr\"\"\"\n\tThis tool is used to retrieve academic information in the Laboratory's shared paper database, which contains\n\tabundant research papers. It is useful to help you to answer the user's academic questions.\n\n\tArgs:\n\t\titem_to_be_retrieved (str): The things that you want to retrieve in the shared paper database.\n\t\"\"\"\n\tvector_nodes = await self.paper_vector_retriever.aretrieve(item_to_be_retrieved)\n\tsummary_chunk_nodes = await self.paper_summary_retriever.aretrieve(item_to_be_retrieved)\n\n\thybrid_doc_ids = set()\n\tfor node in summary_chunk_nodes + vector_nodes:\n\t\thybrid_doc_ids.add(node.node.ref_doc_id)\n\n\tdoc_id_to_summary_id = self.paper_summary_retriever._index._index_struct.doc_id_to_summary_id\n\thybrid_summary_ids = [doc_id_to_summary_id[doc_id] for doc_id in hybrid_doc_ids]\n\tdoc_summary_nodes = self.paper_summary_retriever._index.docstore.get_nodes(hybrid_summary_ids)\n\n\tself.paper_summary_post_selector._summary_nodes = doc_summary_nodes\n\tfinal_doc_ids = await self.paper_summary_post_selector.aselect(item_to_be_retrieved)\n\n\tsummary_nodes, content_nodes = self._secondary_retrieve(\n\t\tfinal_doc_ids=final_doc_ids,\n\t\titem_to_be_retrieved=item_to_be_retrieved,\n\t)\n\n\tfinal_nodes = content_nodes\n\tif self.final_use_summary:\n\t\tfinal_nodes.extend(summary_nodes)\n\n\tif self.final_use_context:\n\t\tcontext_nodes = self._get_context(content_nodes)\n\t\tfinal_nodes.extend(context_nodes)\n\tself.retrieved_nodes = final_nodes\n\treturn final_nodes\n</code></pre>"},{"location":"code_docs/func_modules/paper/retrieve/paper_retriever/#labridge.func_modules.paper.retrieve.paper_retriever.PaperRetriever.from_storage","title":"<code>labridge.func_modules.paper.retrieve.paper_retriever.PaperRetriever.from_storage(llm=None, embed_model=None, vector_persist_dir=None, paper_summary_persist_dir=None, vector_similarity_top_k=PAPER_VECTOR_TOP_K, summary_similarity_top_k=PAPER_SUMMARY_TOP_K, service_context=None, docs_top_k=PAPER_TOP_K, re_retrieve_top_k=PAPER_RETRIEVE_TOP_K, final_use_context=True, final_use_summary=True)</code>  <code>classmethod</code>","text":"<p>Load from an existing storage.</p> Source code in <code>labridge\\func_modules\\paper\\retrieve\\paper_retriever.py</code> <pre><code>@classmethod\ndef from_storage(\n\tcls,\n\tllm: Optional[LLM] = None,\n\tembed_model: Optional[BaseEmbedding] = None,\n\tvector_persist_dir: Optional[Union[Path, str]] = None,\n\tpaper_summary_persist_dir: Optional[Union[Path, str]] = None,\n\tvector_similarity_top_k: Optional[int] = PAPER_VECTOR_TOP_K,\n\tsummary_similarity_top_k: Optional[int] = PAPER_SUMMARY_TOP_K,\n\tservice_context: Optional[ServiceContext] = None,\n\tdocs_top_k: int = PAPER_TOP_K,\n\tre_retrieve_top_k: int = PAPER_RETRIEVE_TOP_K,\n\tfinal_use_context: bool = True,\n\tfinal_use_summary: bool = True,\n):\n\tr\"\"\"\n\tLoad from an existing storage.\n\t\"\"\"\n\troot = Path(__file__)\n\tfor i in range(5):\n\t\troot = root.parent\n\n\tllm = llm or llm_from_settings_or_context(Settings, service_context)\n\tembed_model = embed_model or embed_model_from_settings_or_context(Settings, service_context)\n\n\tvector_persist_dir = vector_persist_dir or root / DEFAULT_PAPER_VECTOR_PERSIST_DIR\n\tvector_storage_context = StorageContext.from_defaults(persist_dir=vector_persist_dir)\n\tvector_index = load_index_from_storage(\n\t\tstorage_context=vector_storage_context,\n\t\tindex_id=PAPER_VECTOR_INDEX_ID,\n\t\tembed_model=embed_model\n\t)\n\tvector_retriever = vector_index.as_retriever(similarity_top_k=vector_similarity_top_k)\n\n\tpaper_summary_persist_dir = paper_summary_persist_dir or root / DEFAULT_PAPER_SUMMARY_PERSIST_DIR\n\tpaper_summary_storage_context = StorageContext.from_defaults(persist_dir=paper_summary_persist_dir)\n\tpaper_summary_index = load_index_from_storage(\n\t\tstorage_context=paper_summary_storage_context,\n\t\tindex_id=PAPER_SUMMARY_INDEX_ID,\n\t\tllm=llm,\n\t\tembed_model=embed_model\n\t)\n\tsummary_retriever = paper_summary_index.as_retriever(\n\t\tretriever_mode=DocumentSummaryRetrieverMode.EMBEDDING,\n\t\tsimilarity_top_k=summary_similarity_top_k)\n\treturn cls(\n\t\tllm = llm,\n\t\tpaper_vector_retriever=vector_retriever,\n\t\tpaper_summary_retriever=summary_retriever,\n\t\tdocs_top_k=docs_top_k,\n\t\tre_retrieve_top_k=re_retrieve_top_k,\n\t\tfinal_use_context=final_use_context,\n\t\tfinal_use_summary=final_use_summary,\n\t)\n</code></pre>"},{"location":"code_docs/func_modules/paper/retrieve/paper_retriever/#labridge.func_modules.paper.retrieve.paper_retriever.PaperRetriever.get_ref_info","title":"<code>labridge.func_modules.paper.retrieve.paper_retriever.PaperRetriever.get_ref_info()</code>","text":"<p>Get the reference paper infos</p> RETURNS DESCRIPTION <code>List[PaperInfo]</code> <p>List[PaperInfo]: The reference paper infos in answering.</p> Source code in <code>labridge\\func_modules\\paper\\retrieve\\paper_retriever.py</code> <pre><code>def get_ref_info(self) -&gt; List[PaperInfo]:\n\tr\"\"\"\n\tGet the reference paper infos\n\n\tReturns:\n\t\tList[PaperInfo]: The reference paper infos in answering.\n\t\"\"\"\n\tdoc_ids, doc_titles, doc_possessors = [], [], []\n\tref_infos = []\n\tfor node_score in self.retrieved_nodes:\n\t\tref_doc_id = node_score.node.ref_doc_id\n\t\tif ref_doc_id not in doc_ids:\n\t\t\tdoc_ids.append(ref_doc_id)\n\t\t\ttitle = node_score.node.metadata.get(PAPER_TITLE) or ref_doc_id\n\t\t\tpossessor = node_score.node.metadata.get(PAPER_POSSESSOR)\n\t\t\trel_path = node_score.node.metadata.get(PAPER_REL_FILE_PATH)\n\t\t\tif rel_path is None:\n\t\t\t\traise ValueError(\"Invalid database.\")\n\t\t\tpaper_info = PaperInfo(\n\t\t\t\ttitle=title,\n\t\t\t\tpossessor=possessor,\n\t\t\t\tfile_path=str(self.root / rel_path),\n\t\t\t)\n\t\t\tref_infos.append(paper_info)\n\n\t\t\tdoc_titles.append(title)\n\t\t\tdoc_possessors.append(possessor)\n\treturn ref_infos\n</code></pre>"},{"location":"code_docs/func_modules/paper/retrieve/paper_retriever/#labridge.func_modules.paper.retrieve.paper_retriever.PaperRetriever.retrieve","title":"<code>labridge.func_modules.paper.retrieve.paper_retriever.PaperRetriever.retrieve(item_to_be_retrieved)</code>","text":"<p>This tool is used to retrieve academic information in the Laboratory's shared paper database. It is useful to help answer the user's academic questions.</p> PARAMETER DESCRIPTION <code>item_to_be_retrieved</code> <p>The things that you want to retrieve in the shared paper database.</p> <p> TYPE: <code>str</code> </p> Source code in <code>labridge\\func_modules\\paper\\retrieve\\paper_retriever.py</code> <pre><code>@dispatcher.span\ndef retrieve(\n\tself,\n\titem_to_be_retrieved: str,\n) -&gt; List[NodeWithScore]:\n\tr\"\"\"\n\tThis tool is used to retrieve academic information in the Laboratory's shared paper database.\n\tIt is useful to help answer the user's academic questions.\n\n\tArgs:\n\t\titem_to_be_retrieved (str): The things that you want to retrieve in the shared paper database.\n\t\"\"\"\n\t# This docstring is used as the tool description.\n\tvector_nodes = self.paper_vector_retriever.retrieve(item_to_be_retrieved)\n\tsummary_chunk_nodes = self.paper_summary_retriever.retrieve(item_to_be_retrieved)\n\n\thybrid_doc_ids = set()\n\tfor node in summary_chunk_nodes + vector_nodes:\n\t\thybrid_doc_ids.add(node.node.ref_doc_id)\n\n\tdoc_id_to_summary_id = self.paper_summary_retriever._index._index_struct.doc_id_to_summary_id\n\thybrid_summary_ids = [doc_id_to_summary_id[doc_id] for doc_id in hybrid_doc_ids]\n\tdoc_summary_nodes = self.paper_summary_retriever._index.docstore.get_nodes(hybrid_summary_ids)\n\n\tself.paper_summary_post_selector._summary_nodes = doc_summary_nodes\n\tfinal_doc_ids = self.paper_summary_post_selector.select(item_to_be_retrieved)\n\n\tsummary_nodes, content_nodes = self._secondary_retrieve(\n\t\tfinal_doc_ids=final_doc_ids,\n\t\titem_to_be_retrieved=item_to_be_retrieved,\n\t)\n\n\tfinal_nodes = content_nodes\n\tif self.final_use_summary:\n\t\tfinal_nodes.extend(summary_nodes)\n\n\tif self.final_use_context:\n\t\tcontext_nodes = self._get_context(content_nodes)\n\t\tfinal_nodes.extend(context_nodes)\n\tself.retrieved_nodes = final_nodes\n\treturn final_nodes\n</code></pre>"},{"location":"code_docs/func_modules/paper/retrieve/paper_retriever/#labridge.func_modules.paper.retrieve.paper_retriever.PaperSummaryLLMPostSelector","title":"<code>labridge.func_modules.paper.retrieve.paper_retriever.PaperSummaryLLMPostSelector</code>","text":"<p>Use LLM to re-rank the retrieved papers obtained by vector_retriever and summary_retriever, according to their summaries.</p> Source code in <code>labridge\\func_modules\\paper\\retrieve\\paper_retriever.py</code> <pre><code>class PaperSummaryLLMPostSelector:\n\tr\"\"\"\n\tUse LLM to re-rank the retrieved papers obtained by vector_retriever and summary_retriever,\n\taccording to their summaries.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tsummary_nodes: List[BaseNode],\n\t\tllm: Optional[LLM] = None,\n\t\tchoice_select_prompt: Optional[BasePromptTemplate] = None,\n\t\tchoice_batch_size: int = 10,\n\t\tchoice_top_k: int = 2,\n\t\tformat_node_batch_fn: Optional[Callable] = None,\n\t\tparse_choice_select_answer_fn: Optional[Callable] = None,\n\t):\n\t\tself._summary_nodes = summary_nodes\n\t\tself._choice_select_prompt = (choice_select_prompt or DOC_CHOICE_SELECT_PROMPT)\n\t\tself._choice_batch_size = choice_batch_size\n\t\tself._choice_top_k = choice_top_k\n\t\tself._format_node_batch_fn = (format_node_batch_fn or default_format_node_batch_fn)\n\t\tself._parse_choice_select_answer_fn = (parse_choice_select_answer_fn or default_parse_choice_select_answer_fn)\n\t\tself._llm = llm or Settings.llm\n\n\tdef select(\n\t\tself,\n\t\titem_to_be_retrieved: str,\n\t) -&gt; List[str]:\n\t\tr\"\"\"\n\t\tSelect from the paper summaries according to the relevance to the retrieving string.\n\n\t\tArgs:\n\t\t\titem_to_be_retrieved (str): The retrieving string.\n\n\t\tReturn the ref_doc_ids, titles, possessors of the selected docs.\n\t\t\"\"\"\n\t\tall_nodes: List[BaseNode] = []\n\t\tall_relevances: List[float] = []\n\t\tfor idx in range(0, len(self._summary_nodes), self._choice_batch_size):\n\t\t\tsummary_nodes = self._summary_nodes[idx: idx + self._choice_batch_size]\n\t\t\tfmt_batch_str = self._format_node_batch_fn(summary_nodes)\n\t\t\t# call each batch independently\n\t\t\traw_response = self._llm.predict(\n\t\t\t\tself._choice_select_prompt,\n\t\t\t\tcontext_str=fmt_batch_str,\n\t\t\t\tquery_str=item_to_be_retrieved,\n\t\t\t)\n\n\t\t\traw_choices, relevances = self._parse_choice_select_answer_fn(raw_response, len(summary_nodes))\n\t\t\tchoice_idxs = [choice - 1 for choice in raw_choices]\n\n\t\t\tchoice_summary_nodes = [summary_nodes[ci] for ci in choice_idxs]\n\n\t\t\tall_nodes.extend(choice_summary_nodes)\n\t\t\tall_relevances.extend(relevances)\n\n\t\tzipped_list = list(zip(all_nodes, all_relevances))\n\t\tsorted_list = sorted(zipped_list, key=lambda x: x[1], reverse=True)\n\t\ttop_k_list = sorted_list[: self._choice_top_k]\n\n\t\tdoc_ids = [node.ref_doc_id for node, relevance in top_k_list]\n\t\treturn doc_ids\n\n\tasync def aselect(\n\t\tself,\n\t\titem_to_be_retrieved: str,\n\t) -&gt; List[str]:\n\t\tr\"\"\"\n\t\tAsynchronously select from the paper summaries according to the relevance to the retrieving string.\n\n\t\tArgs:\n\t\t\titem_to_be_retrieved (str): The retrieving string.\n\n\t\tReturn the ref_doc_ids, titles, possessors of the selected docs.\n\t\t\"\"\"\n\t\tall_nodes: List[BaseNode] = []\n\t\tall_relevances: List[float] = []\n\t\tfor idx in range(0, len(self._summary_nodes), self._choice_batch_size):\n\t\t\tsummary_nodes = self._summary_nodes[idx: idx + self._choice_batch_size]\n\t\t\tfmt_batch_str = self._format_node_batch_fn(summary_nodes)\n\t\t\t# call each batch independently\n\t\t\traw_response = await self._llm.apredict(\n\t\t\t\tself._choice_select_prompt,\n\t\t\t\tcontext_str=fmt_batch_str,\n\t\t\t\tquery_str=item_to_be_retrieved,\n\t\t\t)\n\t\t\traw_choices, relevances = self._parse_choice_select_answer_fn(raw_response, len(summary_nodes))\n\t\t\tchoice_idxs = [choice - 1 for choice in raw_choices]\n\n\t\t\tchoice_summary_nodes = [summary_nodes[ci] for ci in choice_idxs]\n\n\t\t\tall_nodes.extend(choice_summary_nodes)\n\t\t\tall_relevances.extend(relevances)\n\n\t\tzipped_list = list(zip(all_nodes, all_relevances))\n\t\tsorted_list = sorted(zipped_list, key=lambda x: x[1], reverse=True)\n\t\ttop_k_list = sorted_list[: self._choice_top_k]\n\n\t\tdoc_ids = [node.ref_doc_id for node, relevance in top_k_list]\n\t\treturn doc_ids\n</code></pre>"},{"location":"code_docs/func_modules/paper/retrieve/paper_retriever/#labridge.func_modules.paper.retrieve.paper_retriever.PaperSummaryLLMPostSelector.aselect","title":"<code>labridge.func_modules.paper.retrieve.paper_retriever.PaperSummaryLLMPostSelector.aselect(item_to_be_retrieved)</code>  <code>async</code>","text":"<p>Asynchronously select from the paper summaries according to the relevance to the retrieving string.</p> PARAMETER DESCRIPTION <code>item_to_be_retrieved</code> <p>The retrieving string.</p> <p> TYPE: <code>str</code> </p> <p>Return the ref_doc_ids, titles, possessors of the selected docs.</p> Source code in <code>labridge\\func_modules\\paper\\retrieve\\paper_retriever.py</code> <pre><code>async def aselect(\n\tself,\n\titem_to_be_retrieved: str,\n) -&gt; List[str]:\n\tr\"\"\"\n\tAsynchronously select from the paper summaries according to the relevance to the retrieving string.\n\n\tArgs:\n\t\titem_to_be_retrieved (str): The retrieving string.\n\n\tReturn the ref_doc_ids, titles, possessors of the selected docs.\n\t\"\"\"\n\tall_nodes: List[BaseNode] = []\n\tall_relevances: List[float] = []\n\tfor idx in range(0, len(self._summary_nodes), self._choice_batch_size):\n\t\tsummary_nodes = self._summary_nodes[idx: idx + self._choice_batch_size]\n\t\tfmt_batch_str = self._format_node_batch_fn(summary_nodes)\n\t\t# call each batch independently\n\t\traw_response = await self._llm.apredict(\n\t\t\tself._choice_select_prompt,\n\t\t\tcontext_str=fmt_batch_str,\n\t\t\tquery_str=item_to_be_retrieved,\n\t\t)\n\t\traw_choices, relevances = self._parse_choice_select_answer_fn(raw_response, len(summary_nodes))\n\t\tchoice_idxs = [choice - 1 for choice in raw_choices]\n\n\t\tchoice_summary_nodes = [summary_nodes[ci] for ci in choice_idxs]\n\n\t\tall_nodes.extend(choice_summary_nodes)\n\t\tall_relevances.extend(relevances)\n\n\tzipped_list = list(zip(all_nodes, all_relevances))\n\tsorted_list = sorted(zipped_list, key=lambda x: x[1], reverse=True)\n\ttop_k_list = sorted_list[: self._choice_top_k]\n\n\tdoc_ids = [node.ref_doc_id for node, relevance in top_k_list]\n\treturn doc_ids\n</code></pre>"},{"location":"code_docs/func_modules/paper/retrieve/paper_retriever/#labridge.func_modules.paper.retrieve.paper_retriever.PaperSummaryLLMPostSelector.select","title":"<code>labridge.func_modules.paper.retrieve.paper_retriever.PaperSummaryLLMPostSelector.select(item_to_be_retrieved)</code>","text":"<p>Select from the paper summaries according to the relevance to the retrieving string.</p> PARAMETER DESCRIPTION <code>item_to_be_retrieved</code> <p>The retrieving string.</p> <p> TYPE: <code>str</code> </p> <p>Return the ref_doc_ids, titles, possessors of the selected docs.</p> Source code in <code>labridge\\func_modules\\paper\\retrieve\\paper_retriever.py</code> <pre><code>def select(\n\tself,\n\titem_to_be_retrieved: str,\n) -&gt; List[str]:\n\tr\"\"\"\n\tSelect from the paper summaries according to the relevance to the retrieving string.\n\n\tArgs:\n\t\titem_to_be_retrieved (str): The retrieving string.\n\n\tReturn the ref_doc_ids, titles, possessors of the selected docs.\n\t\"\"\"\n\tall_nodes: List[BaseNode] = []\n\tall_relevances: List[float] = []\n\tfor idx in range(0, len(self._summary_nodes), self._choice_batch_size):\n\t\tsummary_nodes = self._summary_nodes[idx: idx + self._choice_batch_size]\n\t\tfmt_batch_str = self._format_node_batch_fn(summary_nodes)\n\t\t# call each batch independently\n\t\traw_response = self._llm.predict(\n\t\t\tself._choice_select_prompt,\n\t\t\tcontext_str=fmt_batch_str,\n\t\t\tquery_str=item_to_be_retrieved,\n\t\t)\n\n\t\traw_choices, relevances = self._parse_choice_select_answer_fn(raw_response, len(summary_nodes))\n\t\tchoice_idxs = [choice - 1 for choice in raw_choices]\n\n\t\tchoice_summary_nodes = [summary_nodes[ci] for ci in choice_idxs]\n\n\t\tall_nodes.extend(choice_summary_nodes)\n\t\tall_relevances.extend(relevances)\n\n\tzipped_list = list(zip(all_nodes, all_relevances))\n\tsorted_list = sorted(zipped_list, key=lambda x: x[1], reverse=True)\n\ttop_k_list = sorted_list[: self._choice_top_k]\n\n\tdoc_ids = [node.ref_doc_id for node, relevance in top_k_list]\n\treturn doc_ids\n</code></pre>"},{"location":"code_docs/func_modules/paper/retrieve/shared_paper_retrieve/","title":"Shared paper retrieve","text":""},{"location":"code_docs/func_modules/paper/retrieve/shared_paper_retrieve/#labridge.func_modules.paper.retrieve.shared_paper_retrieve","title":"<code>labridge.func_modules.paper.retrieve.shared_paper_retrieve</code>","text":""},{"location":"code_docs/func_modules/paper/retrieve/shared_paper_retrieve/#labridge.func_modules.paper.retrieve.shared_paper_retrieve.PaperSummaryLLMPostSelector","title":"<code>labridge.func_modules.paper.retrieve.shared_paper_retrieve.PaperSummaryLLMPostSelector</code>","text":"<p>Use LLM to re-rank the retrieved papers obtained by vector_retriever and summary_retriever, according to their summaries.</p> Source code in <code>labridge\\func_modules\\paper\\retrieve\\shared_paper_retrieve.py</code> <pre><code>class PaperSummaryLLMPostSelector:\n\tr\"\"\"\n\tUse LLM to re-rank the retrieved papers obtained by vector_retriever and summary_retriever,\n\taccording to their summaries.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tsummary_nodes: List[BaseNode],\n\t\tllm: Optional[LLM] = None,\n\t\tchoice_select_prompt: Optional[BasePromptTemplate] = None,\n\t\tchoice_batch_size: int = 10,\n\t\tchoice_top_k: int = PAPER_TOP_K,\n\t\tformat_node_batch_fn: Optional[Callable] = None,\n\t\tparse_choice_select_answer_fn: Optional[Callable] = None,\n\t):\n\t\tself._summary_nodes = summary_nodes\n\t\tself._choice_select_prompt = (choice_select_prompt or DOC_CHOICE_SELECT_PROMPT)\n\t\tself._choice_batch_size = choice_batch_size\n\t\tself._choice_top_k = choice_top_k\n\t\tself._format_node_batch_fn = (format_node_batch_fn or default_format_node_batch_fn)\n\t\tself._parse_choice_select_answer_fn = (parse_choice_select_answer_fn or default_parse_choice_select_answer_fn)\n\t\tself._llm = llm or Settings.llm\n\n\tdef format_batch_summaries(self, batch_summaries: List[str], ) -&gt; str:\n\t\t\"\"\"\n\t\tFormatted batch summaries.\n\t\t\"\"\"\n\t\tfmt_node_txts = []\n\t\tfor idx in range(len(batch_summaries)):\n\t\t\tnumber = idx + 1\n\t\t\tfmt_node_txts.append(\n\t\t\t\tf\"Document {number}:\\n\"\n\t\t\t\tf\"{batch_summaries[idx]}\"\n\t\t\t)\n\t\treturn \"\\n\\n\".join(fmt_node_txts)\n\n\tdef select(\n\t\tself,\n\t\titem_to_be_retrieved: str,\n\t\tpaper_summaries: Dict[str, str]\n\t) -&gt; List[str]:\n\t\tr\"\"\"\n\t\tSelect from the paper summaries according to the relevance to the retrieving string.\n\n\t\tArgs:\n\t\t\titem_to_be_retrieved (str): The retrieving string.\n\t\t\tpaper_summaries (Dict[str, str]): Key: paper_node_id, value: paper summary.\n\n\t\tReturn the ref_doc_ids, titles, possessors of the selected docs.\n\t\t\"\"\"\n\t\tall_paper_ids: List[str] = []\n\t\tall_relevances: List[float] = []\n\n\t\tpaper_ids = list(paper_summaries.keys())\n\t\tsummaries = [paper_summaries[key] for key in paper_ids]\n\n\t\tfor idx in range(0, len(summaries), self._choice_batch_size):\n\t\t\tbatch_summaries = summaries[idx: idx + self._choice_batch_size]\n\t\t\tbatch_paper_ids = paper_ids[idx: idx + self._choice_batch_size]\n\t\t\tfmt_batch_str = self.format_batch_summaries(batch_summaries=batch_summaries)\n\t\t\t# call each batch independently\n\t\t\traw_response = self._llm.predict(\n\t\t\t\tself._choice_select_prompt,\n\t\t\t\tcontext_str=fmt_batch_str,\n\t\t\t\tquery_str=item_to_be_retrieved,\n\t\t\t)\n\t\t\traw_choices, relevances = self._parse_choice_select_answer_fn(raw_response, len(summaries))\n\t\t\tchoice_idxs = [choice - 1 for choice in raw_choices]\n\t\t\tchoice_ids = [batch_paper_ids[ci] for ci in choice_idxs]\n\n\t\t\tall_paper_ids.extend(choice_ids)\n\t\t\tall_relevances.extend(relevances)\n\n\t\tzipped_list = list(zip(all_paper_ids, all_relevances))\n\t\tsorted_list = sorted(zipped_list, key=lambda x: x[1], reverse=True)\n\t\ttop_k_list = sorted_list[: self._choice_top_k]\n\n\t\tselected_paper_ids = [paper_id for paper_id, relevance in top_k_list]\n\t\treturn selected_paper_ids\n\n\tasync def aselect(\n\t\tself,\n\t\titem_to_be_retrieved: str,\n\t\tpaper_summaries: Dict[str, str],\n\t) -&gt; List[str]:\n\t\tr\"\"\"\n\t\tAsynchronously select from the paper summaries according to the relevance to the retrieving string.\n\n\t\tArgs:\n\t\t\titem_to_be_retrieved (str): The retrieving string.\n\t\t\tpaper_summaries (Dict[str, str]): Key: paper_node_id, value: paper summary.\n\n\t\tReturn the ref_doc_ids, titles, possessors of the selected docs.\n\t\t\"\"\"\n\t\tall_paper_ids: List[str] = []\n\t\tall_relevances: List[float] = []\n\n\t\tpaper_ids = list(paper_summaries.keys())\n\t\tsummaries = [paper_summaries[key] for key in paper_ids]\n\n\t\tfor idx in range(0, len(summaries), self._choice_batch_size):\n\t\t\tbatch_summaries = summaries[idx: idx + self._choice_batch_size]\n\t\t\tbatch_paper_ids = paper_ids[idx: idx + self._choice_batch_size]\n\t\t\tfmt_batch_str = self.format_batch_summaries(batch_summaries=batch_summaries)\n\t\t\t# call each batch independently\n\t\t\traw_response = await self._llm.apredict(\n\t\t\t\tself._choice_select_prompt,\n\t\t\t\tcontext_str=fmt_batch_str,\n\t\t\t\tquery_str=item_to_be_retrieved,\n\t\t\t)\n\n\t\t\traw_choices, relevances = self._parse_choice_select_answer_fn(raw_response, len(summaries))\n\t\t\tchoice_idxs = [choice - 1 for choice in raw_choices]\n\t\t\tchoice_ids = [batch_paper_ids[ci] for ci in choice_idxs]\n\n\t\t\tall_paper_ids.extend(choice_ids)\n\t\t\tall_relevances.extend(relevances)\n\n\t\tzipped_list = list(zip(all_paper_ids, all_relevances))\n\t\tsorted_list = sorted(zipped_list, key=lambda x: x[1], reverse=True)\n\t\ttop_k_list = sorted_list[: self._choice_top_k]\n\n\t\tselected_paper_ids = [paper_id for paper_id, relevance in top_k_list]\n\t\treturn selected_paper_ids\n</code></pre>"},{"location":"code_docs/func_modules/paper/retrieve/shared_paper_retrieve/#labridge.func_modules.paper.retrieve.shared_paper_retrieve.PaperSummaryLLMPostSelector.aselect","title":"<code>labridge.func_modules.paper.retrieve.shared_paper_retrieve.PaperSummaryLLMPostSelector.aselect(item_to_be_retrieved, paper_summaries)</code>  <code>async</code>","text":"<p>Asynchronously select from the paper summaries according to the relevance to the retrieving string.</p> PARAMETER DESCRIPTION <code>item_to_be_retrieved</code> <p>The retrieving string.</p> <p> TYPE: <code>str</code> </p> <code>paper_summaries</code> <p> TYPE: <code>Dict[str, str]</code> </p> <p>Return the ref_doc_ids, titles, possessors of the selected docs.</p> Source code in <code>labridge\\func_modules\\paper\\retrieve\\shared_paper_retrieve.py</code> <pre><code>async def aselect(\n\tself,\n\titem_to_be_retrieved: str,\n\tpaper_summaries: Dict[str, str],\n) -&gt; List[str]:\n\tr\"\"\"\n\tAsynchronously select from the paper summaries according to the relevance to the retrieving string.\n\n\tArgs:\n\t\titem_to_be_retrieved (str): The retrieving string.\n\t\tpaper_summaries (Dict[str, str]): Key: paper_node_id, value: paper summary.\n\n\tReturn the ref_doc_ids, titles, possessors of the selected docs.\n\t\"\"\"\n\tall_paper_ids: List[str] = []\n\tall_relevances: List[float] = []\n\n\tpaper_ids = list(paper_summaries.keys())\n\tsummaries = [paper_summaries[key] for key in paper_ids]\n\n\tfor idx in range(0, len(summaries), self._choice_batch_size):\n\t\tbatch_summaries = summaries[idx: idx + self._choice_batch_size]\n\t\tbatch_paper_ids = paper_ids[idx: idx + self._choice_batch_size]\n\t\tfmt_batch_str = self.format_batch_summaries(batch_summaries=batch_summaries)\n\t\t# call each batch independently\n\t\traw_response = await self._llm.apredict(\n\t\t\tself._choice_select_prompt,\n\t\t\tcontext_str=fmt_batch_str,\n\t\t\tquery_str=item_to_be_retrieved,\n\t\t)\n\n\t\traw_choices, relevances = self._parse_choice_select_answer_fn(raw_response, len(summaries))\n\t\tchoice_idxs = [choice - 1 for choice in raw_choices]\n\t\tchoice_ids = [batch_paper_ids[ci] for ci in choice_idxs]\n\n\t\tall_paper_ids.extend(choice_ids)\n\t\tall_relevances.extend(relevances)\n\n\tzipped_list = list(zip(all_paper_ids, all_relevances))\n\tsorted_list = sorted(zipped_list, key=lambda x: x[1], reverse=True)\n\ttop_k_list = sorted_list[: self._choice_top_k]\n\n\tselected_paper_ids = [paper_id for paper_id, relevance in top_k_list]\n\treturn selected_paper_ids\n</code></pre>"},{"location":"code_docs/func_modules/paper/retrieve/shared_paper_retrieve/#labridge.func_modules.paper.retrieve.shared_paper_retrieve.PaperSummaryLLMPostSelector.format_batch_summaries","title":"<code>labridge.func_modules.paper.retrieve.shared_paper_retrieve.PaperSummaryLLMPostSelector.format_batch_summaries(batch_summaries)</code>","text":"<p>Formatted batch summaries.</p> Source code in <code>labridge\\func_modules\\paper\\retrieve\\shared_paper_retrieve.py</code> <pre><code>def format_batch_summaries(self, batch_summaries: List[str], ) -&gt; str:\n\t\"\"\"\n\tFormatted batch summaries.\n\t\"\"\"\n\tfmt_node_txts = []\n\tfor idx in range(len(batch_summaries)):\n\t\tnumber = idx + 1\n\t\tfmt_node_txts.append(\n\t\t\tf\"Document {number}:\\n\"\n\t\t\tf\"{batch_summaries[idx]}\"\n\t\t)\n\treturn \"\\n\\n\".join(fmt_node_txts)\n</code></pre>"},{"location":"code_docs/func_modules/paper/retrieve/shared_paper_retrieve/#labridge.func_modules.paper.retrieve.shared_paper_retrieve.PaperSummaryLLMPostSelector.select","title":"<code>labridge.func_modules.paper.retrieve.shared_paper_retrieve.PaperSummaryLLMPostSelector.select(item_to_be_retrieved, paper_summaries)</code>","text":"<p>Select from the paper summaries according to the relevance to the retrieving string.</p> PARAMETER DESCRIPTION <code>item_to_be_retrieved</code> <p>The retrieving string.</p> <p> TYPE: <code>str</code> </p> <code>paper_summaries</code> <p> TYPE: <code>Dict[str, str]</code> </p> <p>Return the ref_doc_ids, titles, possessors of the selected docs.</p> Source code in <code>labridge\\func_modules\\paper\\retrieve\\shared_paper_retrieve.py</code> <pre><code>def select(\n\tself,\n\titem_to_be_retrieved: str,\n\tpaper_summaries: Dict[str, str]\n) -&gt; List[str]:\n\tr\"\"\"\n\tSelect from the paper summaries according to the relevance to the retrieving string.\n\n\tArgs:\n\t\titem_to_be_retrieved (str): The retrieving string.\n\t\tpaper_summaries (Dict[str, str]): Key: paper_node_id, value: paper summary.\n\n\tReturn the ref_doc_ids, titles, possessors of the selected docs.\n\t\"\"\"\n\tall_paper_ids: List[str] = []\n\tall_relevances: List[float] = []\n\n\tpaper_ids = list(paper_summaries.keys())\n\tsummaries = [paper_summaries[key] for key in paper_ids]\n\n\tfor idx in range(0, len(summaries), self._choice_batch_size):\n\t\tbatch_summaries = summaries[idx: idx + self._choice_batch_size]\n\t\tbatch_paper_ids = paper_ids[idx: idx + self._choice_batch_size]\n\t\tfmt_batch_str = self.format_batch_summaries(batch_summaries=batch_summaries)\n\t\t# call each batch independently\n\t\traw_response = self._llm.predict(\n\t\t\tself._choice_select_prompt,\n\t\t\tcontext_str=fmt_batch_str,\n\t\t\tquery_str=item_to_be_retrieved,\n\t\t)\n\t\traw_choices, relevances = self._parse_choice_select_answer_fn(raw_response, len(summaries))\n\t\tchoice_idxs = [choice - 1 for choice in raw_choices]\n\t\tchoice_ids = [batch_paper_ids[ci] for ci in choice_idxs]\n\n\t\tall_paper_ids.extend(choice_ids)\n\t\tall_relevances.extend(relevances)\n\n\tzipped_list = list(zip(all_paper_ids, all_relevances))\n\tsorted_list = sorted(zipped_list, key=lambda x: x[1], reverse=True)\n\ttop_k_list = sorted_list[: self._choice_top_k]\n\n\tselected_paper_ids = [paper_id for paper_id, relevance in top_k_list]\n\treturn selected_paper_ids\n</code></pre>"},{"location":"code_docs/func_modules/paper/retrieve/shared_paper_retrieve/#labridge.func_modules.paper.retrieve.shared_paper_retrieve.SharedPaperRetriever","title":"<code>labridge.func_modules.paper.retrieve.shared_paper_retrieve.SharedPaperRetriever</code>","text":"Source code in <code>labridge\\func_modules\\paper\\retrieve\\shared_paper_retrieve.py</code> <pre><code>class SharedPaperRetriever:\n\n\tdef __init__(\n\t\tself,\n\t\tllm: LLM,\n\t\tembed_model: BaseEmbedding,\n\t\tshared_vector_index: VectorStoreIndex,\n\t\tvector_similarity_top_k: int = PAPER_VECTOR_TOP_K,\n\t\tpapers_top_k: int = PAPER_TOP_K,\n\t\tre_retrieve_top_k: int = PAPER_RETRIEVE_TOP_K,\n\t\tfinal_use_context: bool = True,\n\t\tfinal_use_summary: bool = True,\n\t):\n\t\tself.paper_summary_post_selector = PaperSummaryLLMPostSelector(\n\t\t\tsummary_nodes=[],\n\t\t\tllm=llm,\n\t\t\tchoice_top_k=papers_top_k,\n\t\t)\n\t\tself.shared_vector_index = shared_vector_index\n\t\tself.shared_paper_retriever = shared_vector_index.as_retriever(similarity_top_k=vector_similarity_top_k)\n\t\tself.vector_similarity_top_k = vector_similarity_top_k\n\t\tself.re_retrieve_top_k = re_retrieve_top_k\n\t\tself.final_use_context = final_use_context\n\t\tself.final_use_summary = final_use_summary\n\t\tself._account_manager = AccountManager()\n\t\troot = Path(__file__)\n\t\tfor i in range(5):\n\t\t\troot = root.parent\n\t\tself.root = root\n\n\t@classmethod\n\tdef from_storage(\n\t\tcls,\n\t\tllm: Optional[LLM] = None,\n\t\tembed_model: Optional[BaseEmbedding] = None,\n\t\tvector_persist_dir: Optional[str] = None,\n\t\tvector_similarity_top_k: Optional[int] = PAPER_VECTOR_TOP_K,\n\t\tpapers_top_k: int = PAPER_TOP_K,\n\t\tre_retrieve_top_k: int = PAPER_RETRIEVE_TOP_K,\n\t\tservice_context: Optional[ServiceContext] = None,\n\t\tfinal_use_context: bool = True,\n\t\tfinal_use_summary: bool = True,\n\t):\n\t\tr\"\"\"\n\t\tLoad from an existing storage.\n\t\t\"\"\"\n\t\troot = Path(__file__)\n\t\tfor i in range(5):\n\t\t\troot = root.parent\n\n\t\tllm = llm or llm_from_settings_or_context(Settings, service_context)\n\t\tembed_model = embed_model or embed_model_from_settings_or_context(Settings, service_context)\n\n\t\tvector_persist_dir = vector_persist_dir or root / SHARED_PAPER_VECTOR_INDEX_PERSIST_DIR\n\t\tvector_storage_context = StorageContext.from_defaults(persist_dir=vector_persist_dir)\n\t\tshared_vector_index = load_index_from_storage(\n\t\t\tstorage_context=vector_storage_context,\n\t\t\tindex_id=SHARED_PAPER_VECTOR_INDEX_ID,\n\t\t\tembed_model=embed_model,\n\t\t)\n\t\treturn cls(\n\t\t\tllm=llm,\n\t\t\tembed_model=embed_model,\n\t\t\tshared_vector_index = shared_vector_index,\n\t\t\tvector_similarity_top_k=vector_similarity_top_k,\n\t\t\tpapers_top_k=papers_top_k,\n\t\t\tre_retrieve_top_k=re_retrieve_top_k,\n\t\t\tfinal_use_context=final_use_context,\n\t\t\tfinal_use_summary=final_use_summary,\n\t\t)\n\n\t@property\n\tdef _chunk_node_filter(self) -&gt; MetadataFilter:\n\t\tchunk_type_filter = MetadataFilter(\n\t\t\tkey=SHARED_PAPER_NODE_TYPE,\n\t\t\tvalue=SharedPaperNodeType.PAPER_CHUNK,\n\t\t\toperator=FilterOperator.EQ,\n\t\t)\n\t\treturn chunk_type_filter\n\n\tdef _user_filter(self, user_id: str) -&gt; MetadataFilter:\n\t\tself._account_manager.check_valid_user(user_id=user_id)\n\t\tuser_id_filter = MetadataFilter(\n\t\t\tkey=PAPER_POSSESSOR,\n\t\t\tvalue=user_id,\n\t\t\toperator=FilterOperator.EQ,\n\t\t)\n\t\treturn user_id_filter\n\n\tdef get_parent_summaries(self, chunk_nodes: List[NodeWithScore]) -&gt; Optional[Dict[str, str]]:\n\t\tpaper_ids = set()\n\t\tfor node_score in chunk_nodes:\n\t\t\tpaper_id = node_score.node.parent_node.node_id\n\t\t\tpaper_ids.add(paper_id)\n\n\t\tpaper_nodes = self.shared_vector_index.docstore.get_nodes(node_ids=list(paper_ids))\n\t\tpaper_themes = {}\n\t\tfor node in paper_nodes:\n\t\t\ttheme = \"\"\n\t\t\tsummary = node.metadata.get(SHARED_PAPER_SUMMARY_KEY, None)\n\t\t\tabstract = node.metadata.get(PAPER_ABSTRACT, None)\n\t\t\tif summary is None and abstract is None:\n\t\t\t\tcontinue\n\n\t\t\tif abstract:\n\t\t\t\ttheme += f\"Abstract:\\n{abstract}\\n\"\n\t\t\tif summary:\n\t\t\t\ttheme += f\"Summary:\\n{summary}\\n\"\n\t\t\tpaper_themes[node.node_id] = theme\n\n\t\tif len(paper_themes.keys()) &lt; 1:\n\t\t\treturn None\n\t\treturn paper_themes\n\n\tdef _reset_retriever(self, target_user_id: str = None):\n\t\tfilters = [self._chunk_node_filter, ]\n\n\t\tif target_user_id is not None:\n\t\t\tfilters.append(self._user_filter(user_id=target_user_id))\n\n\t\tself.shared_paper_retriever._filters = MetadataFilters(filters=filters)\n\t\tself.shared_paper_retriever._similarity_top_k = self.vector_similarity_top_k\n\n\tdef _add_summary_nodes(self, retrieved_nodes: List[NodeWithScore]) -&gt; List[NodeWithScore]:\n\t\tpaper_summaries = self.get_parent_summaries(chunk_nodes=retrieved_nodes)\n\n\t\tsummary_nodes = []\n\t\tfor paper_id in paper_summaries.keys():\n\t\t\tpaper_node = self.shared_vector_index.docstore.get_node(node_id=paper_id)\n\t\t\ttitle = paper_node.metadata[PAPER_TITLE]\n\t\t\tsummary = paper_summaries[paper_id]\n\t\t\tsummary_node = TextNode(\n\t\t\t\ttext=f\"Title: {title}\\n\\nSummary:\\n{summary}\",\n\t\t\t\tmetadata={\n\t\t\t\t\tPAPER_REL_FILE_PATH: paper_node.metadata[PAPER_REL_FILE_PATH],\n\t\t\t\t}\n\t\t\t)\n\t\t\tsummary_nodes.append(NodeWithScore(node=summary_node))\n\n\t\tretrieved_nodes.extend(summary_nodes)\n\t\treturn retrieved_nodes\n\n\tdef _add_context(self, content_nodes: List[NodeWithScore]) -&gt; List[NodeWithScore]:\n\t\tr\"\"\"\n\t\tGet the 1-hop context nodes of each content node retrieved in the secondary retrieving.\n\t\t\"\"\"\n\t\tcontent_ids = [node.node.node_id for node in content_nodes]\n\t\tnew_ids = []\n\t\tfor node in content_nodes:\n\t\t\tprev_node = node.node.prev_node\n\t\t\tnext_node = node.node.next_node\n\t\t\tif prev_node is not None:\n\t\t\t\tprev_id = node.node.prev_node.node_id\n\t\t\t\tif prev_id not in content_ids:\n\t\t\t\t\tcontent_ids.append(prev_id)\n\t\t\t\t\tnew_ids.append(prev_id)\n\n\t\t\tnew_ids.append(node.node_id)\n\n\t\t\tif next_node is not None:\n\t\t\t\tnext_id = node.node.next_node.node_id\n\t\t\t\tif next_id not in content_ids:\n\t\t\t\t\tcontent_ids.append(next_id)\n\t\t\t\t\tnew_ids.append(next_id)\n\n\t\tcontext_nodes = self.shared_vector_index.docstore.get_nodes(new_ids)\n\t\t# exclude metadata in LLM using.\n\t\tself._exclude_all_llm_metadata(nodes=context_nodes)\n\t\tcontext_nodes = [NodeWithScore(node=node) for node in context_nodes]\n\t\treturn context_nodes\n\n\tdef _exclude_all_llm_metadata(self, nodes: List[BaseNode]):\n\t\tr\"\"\" Hidden all metadata of a node to LLM. \"\"\"\n\t\tfor node in nodes:\n\t\t\tnode.excluded_llm_metadata_keys.extend(list(node.metadata.keys()))\n\n\tdef _exclude_all_embedding_metadata(self, nodes: List[BaseNode]):\n\t\tr\"\"\" Hidden all metadata of a node to the embed model. \"\"\"\n\t\tfor node in nodes:\n\t\t\tnode.excluded_embed_metadata_keys.extend(list(node.metadata.keys()))\n\n\tdef secondary_retrieve(\n\t\tself,\n\t\titem_to_be_retrieved: str,\n\t\tpaper_ids: List[str],\n\t) -&gt; List[NodeWithScore]:\n\t\tnode_ids = []\n\t\tfor paper_id in paper_ids:\n\t\t\tpaper_node = self.shared_vector_index.docstore.get_node(node_id=paper_id)\n\t\t\tchunk_ids = [node.node_id for node in paper_node.child_nodes]\n\t\t\tnode_ids.extend(chunk_ids)\n\n\t\tchunk_nodes = self.shared_vector_index.docstore.get_nodes(node_ids=node_ids)\n\t\tself._exclude_all_llm_metadata(nodes=chunk_nodes)\n\t\tself._exclude_all_embedding_metadata(nodes=chunk_nodes)\n\n\t\tcontent_index = VectorStoreIndex(nodes=chunk_nodes, embed_model=self.shared_vector_index._embed_model)\n\t\tcontent_retriever = content_index.as_retriever(similarity_top_k=self.re_retrieve_top_k)\n\t\tretrieved_nodes = content_retriever.retrieve(item_to_be_retrieved)\n\n\t\tif self.final_use_context:\n\t\t\tretrieved_nodes = self._add_context(content_nodes=retrieved_nodes)\n\t\tif self.final_use_summary:\n\t\t\tretrieved_nodes = self._add_summary_nodes(retrieved_nodes=retrieved_nodes)\n\t\treturn retrieved_nodes\n\n\tasync def asecondary_retrieve(\n\t\tself,\n\t\titem_to_be_retrieved: str,\n\t\tpaper_ids: List[str],\n\t) -&gt; List[NodeWithScore]:\n\t\tnode_ids = []\n\t\tfor paper_id in paper_ids:\n\t\t\tpaper_node = self.shared_vector_index.docstore.get_node(node_id=paper_id)\n\t\t\tchunk_ids = [node.node_id for node in paper_node.child_nodes]\n\t\t\tnode_ids.extend(chunk_ids)\n\n\t\tchunk_nodes = self.shared_vector_index.docstore.get_nodes(node_ids=node_ids)\n\t\tself._exclude_all_llm_metadata(nodes=chunk_nodes)\n\t\tself._exclude_all_embedding_metadata(nodes=chunk_nodes)\n\n\t\tcontent_index = VectorStoreIndex(nodes=chunk_nodes, embed_model=self.shared_vector_index._embed_model)\n\t\tcontent_retriever = content_index.as_retriever(similarity_top_k=self.re_retrieve_top_k)\n\t\tretrieved_nodes = await content_retriever.aretrieve(item_to_be_retrieved)\n\n\t\tif self.final_use_context:\n\t\t\tretrieved_nodes = self._add_context(content_nodes=retrieved_nodes)\n\t\tif self.final_use_summary:\n\t\t\tretrieved_nodes = self._add_summary_nodes(retrieved_nodes=retrieved_nodes)\n\t\treturn retrieved_nodes\n\n\tdef retrieve(\n\t\tself,\n\t\titem_to_be_retrieved: str,\n\t\ttarget_user_id: str = None,\n\t) -&gt; List[NodeWithScore]:\n\t\tr\"\"\"\n\t\tThis tool is used to retrieve academic information in the Laboratory's shared paper database.\n\t\tIt is useful to help answer the user's academic questions.\n\n\t\tArgs:\n\t\t\titem_to_be_retrieved (str): The things that you want to retrieve in the shared paper database.\n\t\t\ttarget_user_id (str): If given, the retrieval range will be confined to the papers belonging to the given user.\n\t\t\t\tDefaults to None.\n\t\t\"\"\"\n\t\t# This docstring is used as the tool description.\n\t\tself._reset_retriever(target_user_id=target_user_id)\n\t\tchunk_nodes = self.shared_paper_retriever.retrieve(item_to_be_retrieved)\n\t\tpaper_summaries = self.get_parent_summaries(chunk_nodes=chunk_nodes)\n\t\tif paper_summaries is None:\n\t\t\treturn []\n\n\t\tfinal_paper_ids = self.paper_summary_post_selector.select(\n\t\t\titem_to_be_retrieved=item_to_be_retrieved,\n\t\t\tpaper_summaries=paper_summaries,\n\t\t)\n\n\t\tretrieved_nodes = self.secondary_retrieve(\n\t\t\titem_to_be_retrieved=item_to_be_retrieved,\n\t\t\tpaper_ids=final_paper_ids,\n\t\t)\n\t\treturn retrieved_nodes\n\n\tasync def aretrieve(\n\t\tself,\n\t\titem_to_be_retrieved: str,\n\t\ttarget_user_id: str = None,\n\t) -&gt; List[NodeWithScore]:\n\t\tr\"\"\"\n\t\tThis tool is used to retrieve academic information in the Laboratory's shared paper database.\n\t\tIt is useful to help answer the user's academic questions.\n\n\t\tArgs:\n\t\t\titem_to_be_retrieved (str): The things that you want to retrieve in the shared paper database.\n\t\t\ttarget_user_id (str): If given, the retrieval range will be confined to the papers belonging to the given user.\n\t\t\t\tDefaults to None.\n\t\t\"\"\"\n\t\t# This docstring is used as the tool description.\n\t\t# Retrieve in chunk nodes\n\t\tself._reset_retriever(target_user_id=target_user_id)\n\t\tchunk_nodes = await self.shared_paper_retriever.aretrieve(item_to_be_retrieved)\n\t\tpaper_summaries = self.get_parent_summaries(chunk_nodes=chunk_nodes)\n\t\tif paper_summaries is None:\n\t\t\treturn []\n\n\t\tfinal_paper_ids = await self.paper_summary_post_selector.aselect(\n\t\t\titem_to_be_retrieved=item_to_be_retrieved,\n\t\t\tpaper_summaries=paper_summaries,\n\t\t)\n\t\tretrieved_nodes = await self.asecondary_retrieve(\n\t\t\titem_to_be_retrieved=item_to_be_retrieved,\n\t\t\tpaper_ids=final_paper_ids,\n\t\t)\n\t\treturn retrieved_nodes\n</code></pre>"},{"location":"code_docs/func_modules/paper/retrieve/shared_paper_retrieve/#labridge.func_modules.paper.retrieve.shared_paper_retrieve.SharedPaperRetriever.aretrieve","title":"<code>labridge.func_modules.paper.retrieve.shared_paper_retrieve.SharedPaperRetriever.aretrieve(item_to_be_retrieved, target_user_id=None)</code>  <code>async</code>","text":"<p>This tool is used to retrieve academic information in the Laboratory's shared paper database. It is useful to help answer the user's academic questions.</p> PARAMETER DESCRIPTION <code>item_to_be_retrieved</code> <p>The things that you want to retrieve in the shared paper database.</p> <p> TYPE: <code>str</code> </p> <code>target_user_id</code> <p>If given, the retrieval range will be confined to the papers belonging to the given user. Defaults to None.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> Source code in <code>labridge\\func_modules\\paper\\retrieve\\shared_paper_retrieve.py</code> <pre><code>async def aretrieve(\n\tself,\n\titem_to_be_retrieved: str,\n\ttarget_user_id: str = None,\n) -&gt; List[NodeWithScore]:\n\tr\"\"\"\n\tThis tool is used to retrieve academic information in the Laboratory's shared paper database.\n\tIt is useful to help answer the user's academic questions.\n\n\tArgs:\n\t\titem_to_be_retrieved (str): The things that you want to retrieve in the shared paper database.\n\t\ttarget_user_id (str): If given, the retrieval range will be confined to the papers belonging to the given user.\n\t\t\tDefaults to None.\n\t\"\"\"\n\t# This docstring is used as the tool description.\n\t# Retrieve in chunk nodes\n\tself._reset_retriever(target_user_id=target_user_id)\n\tchunk_nodes = await self.shared_paper_retriever.aretrieve(item_to_be_retrieved)\n\tpaper_summaries = self.get_parent_summaries(chunk_nodes=chunk_nodes)\n\tif paper_summaries is None:\n\t\treturn []\n\n\tfinal_paper_ids = await self.paper_summary_post_selector.aselect(\n\t\titem_to_be_retrieved=item_to_be_retrieved,\n\t\tpaper_summaries=paper_summaries,\n\t)\n\tretrieved_nodes = await self.asecondary_retrieve(\n\t\titem_to_be_retrieved=item_to_be_retrieved,\n\t\tpaper_ids=final_paper_ids,\n\t)\n\treturn retrieved_nodes\n</code></pre>"},{"location":"code_docs/func_modules/paper/retrieve/shared_paper_retrieve/#labridge.func_modules.paper.retrieve.shared_paper_retrieve.SharedPaperRetriever.from_storage","title":"<code>labridge.func_modules.paper.retrieve.shared_paper_retrieve.SharedPaperRetriever.from_storage(llm=None, embed_model=None, vector_persist_dir=None, vector_similarity_top_k=PAPER_VECTOR_TOP_K, papers_top_k=PAPER_TOP_K, re_retrieve_top_k=PAPER_RETRIEVE_TOP_K, service_context=None, final_use_context=True, final_use_summary=True)</code>  <code>classmethod</code>","text":"<p>Load from an existing storage.</p> Source code in <code>labridge\\func_modules\\paper\\retrieve\\shared_paper_retrieve.py</code> <pre><code>@classmethod\ndef from_storage(\n\tcls,\n\tllm: Optional[LLM] = None,\n\tembed_model: Optional[BaseEmbedding] = None,\n\tvector_persist_dir: Optional[str] = None,\n\tvector_similarity_top_k: Optional[int] = PAPER_VECTOR_TOP_K,\n\tpapers_top_k: int = PAPER_TOP_K,\n\tre_retrieve_top_k: int = PAPER_RETRIEVE_TOP_K,\n\tservice_context: Optional[ServiceContext] = None,\n\tfinal_use_context: bool = True,\n\tfinal_use_summary: bool = True,\n):\n\tr\"\"\"\n\tLoad from an existing storage.\n\t\"\"\"\n\troot = Path(__file__)\n\tfor i in range(5):\n\t\troot = root.parent\n\n\tllm = llm or llm_from_settings_or_context(Settings, service_context)\n\tembed_model = embed_model or embed_model_from_settings_or_context(Settings, service_context)\n\n\tvector_persist_dir = vector_persist_dir or root / SHARED_PAPER_VECTOR_INDEX_PERSIST_DIR\n\tvector_storage_context = StorageContext.from_defaults(persist_dir=vector_persist_dir)\n\tshared_vector_index = load_index_from_storage(\n\t\tstorage_context=vector_storage_context,\n\t\tindex_id=SHARED_PAPER_VECTOR_INDEX_ID,\n\t\tembed_model=embed_model,\n\t)\n\treturn cls(\n\t\tllm=llm,\n\t\tembed_model=embed_model,\n\t\tshared_vector_index = shared_vector_index,\n\t\tvector_similarity_top_k=vector_similarity_top_k,\n\t\tpapers_top_k=papers_top_k,\n\t\tre_retrieve_top_k=re_retrieve_top_k,\n\t\tfinal_use_context=final_use_context,\n\t\tfinal_use_summary=final_use_summary,\n\t)\n</code></pre>"},{"location":"code_docs/func_modules/paper/retrieve/shared_paper_retrieve/#labridge.func_modules.paper.retrieve.shared_paper_retrieve.SharedPaperRetriever.retrieve","title":"<code>labridge.func_modules.paper.retrieve.shared_paper_retrieve.SharedPaperRetriever.retrieve(item_to_be_retrieved, target_user_id=None)</code>","text":"<p>This tool is used to retrieve academic information in the Laboratory's shared paper database. It is useful to help answer the user's academic questions.</p> PARAMETER DESCRIPTION <code>item_to_be_retrieved</code> <p>The things that you want to retrieve in the shared paper database.</p> <p> TYPE: <code>str</code> </p> <code>target_user_id</code> <p>If given, the retrieval range will be confined to the papers belonging to the given user. Defaults to None.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> Source code in <code>labridge\\func_modules\\paper\\retrieve\\shared_paper_retrieve.py</code> <pre><code>def retrieve(\n\tself,\n\titem_to_be_retrieved: str,\n\ttarget_user_id: str = None,\n) -&gt; List[NodeWithScore]:\n\tr\"\"\"\n\tThis tool is used to retrieve academic information in the Laboratory's shared paper database.\n\tIt is useful to help answer the user's academic questions.\n\n\tArgs:\n\t\titem_to_be_retrieved (str): The things that you want to retrieve in the shared paper database.\n\t\ttarget_user_id (str): If given, the retrieval range will be confined to the papers belonging to the given user.\n\t\t\tDefaults to None.\n\t\"\"\"\n\t# This docstring is used as the tool description.\n\tself._reset_retriever(target_user_id=target_user_id)\n\tchunk_nodes = self.shared_paper_retriever.retrieve(item_to_be_retrieved)\n\tpaper_summaries = self.get_parent_summaries(chunk_nodes=chunk_nodes)\n\tif paper_summaries is None:\n\t\treturn []\n\n\tfinal_paper_ids = self.paper_summary_post_selector.select(\n\t\titem_to_be_retrieved=item_to_be_retrieved,\n\t\tpaper_summaries=paper_summaries,\n\t)\n\n\tretrieved_nodes = self.secondary_retrieve(\n\t\titem_to_be_retrieved=item_to_be_retrieved,\n\t\tpaper_ids=final_paper_ids,\n\t)\n\treturn retrieved_nodes\n</code></pre>"},{"location":"code_docs/func_modules/paper/retrieve/temporary_paper_retriever/","title":"Temporary paper retriever","text":""},{"location":"code_docs/func_modules/paper/retrieve/temporary_paper_retriever/#labridge.func_modules.paper.retrieve.temporary_paper_retriever","title":"<code>labridge.func_modules.paper.retrieve.temporary_paper_retriever</code>","text":""},{"location":"code_docs/func_modules/paper/retrieve/temporary_paper_retriever/#labridge.func_modules.paper.retrieve.temporary_paper_retriever.RecentPaperRetriever","title":"<code>labridge.func_modules.paper.retrieve.temporary_paper_retriever.RecentPaperRetriever</code>","text":"<p>This class is the retriever that retrieving in the recent papers store of a specific user.</p> PARAMETER DESCRIPTION <code>embed_model</code> <p>The used embedding model. If not specified, the <code>Settings.embed_model</code> will be used.</p> <p> TYPE: <code>BaseEmbedding</code> </p> <code>final_use_context</code> <p>Whether to use the context nodes as parts of the retrieved results.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>first_top_k</code> <p>The <code>similarity_top_k</code> in the first retrieving. Refer to the method <code>retrieve</code> for details.</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> <code>secondary_top_k</code> <p>The <code>similarity_top_k</code> in the secondary retrieving. Refer to the method <code>retrieve</code> for details.</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> Source code in <code>labridge\\func_modules\\paper\\retrieve\\temporary_paper_retriever.py</code> <pre><code>class RecentPaperRetriever:\n\tr\"\"\"\n\tThis class is the retriever that retrieving in the recent papers store of a specific user.\n\n\tArgs:\n\t\tembed_model (BaseEmbedding): The used embedding model. If not specified, the `Settings.embed_model` will be used.\n\t\tfinal_use_context (bool): Whether to use the context nodes as parts of the retrieved results.\n\t\tfirst_top_k (int): The `similarity_top_k` in the first retrieving.\n\t\t\tRefer to the method `retrieve` for details.\n\t\tsecondary_top_k (int): The `similarity_top_k` in the secondary retrieving.\n\t\t\tRefer to the method `retrieve` for details.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tembed_model: BaseEmbedding,\n\t\tfinal_use_context: bool = True,\n\t\tfirst_top_k: int = None,\n\t\tsecondary_top_k: int = None,\n\t):\n\t\tself.paper_store = None\n\t\tself.paper_retriever = None\n\t\tself._embed_model = embed_model or Settings.embed_model\n\t\tself._final_use_context = final_use_context\n\t\tself._first_top_k = first_top_k or RECENT_PAPER_INFO_SIMILARITY_TOP_K\n\t\tself._relevant_top_k = secondary_top_k or RECENT_PAPER_SIMILARITY_TOP_K\n\t\tself.fs = fsspec.filesystem(\"file\")\n\n\tdef _add_context(\n\t\tself,\n\t\tcontent_nodes: List[NodeWithScore]\n\t) -&gt; List[NodeWithScore]:\n\t\tr\"\"\"\n\t\tAdd context nodes for the retrieved nodes.\n\n\t\tArgs:\n\t\t\tcontent_nodes (List[NodeWithScore]): The retrieved nodes.\n\n\t\tReturns:\n\t\t\tList[NodeWithScore]: Concatenated nodes including context nodes.\n\t\t\"\"\"\n\t\tvector_index = self.paper_store.vector_index\n\t\texisting_ids = [node.node_id for node in content_nodes]\n\t\tfinal_nodes = []\n\n\t\tfor node in content_nodes:\n\t\t\tprev_node_info = node.node.prev_node\n\t\t\tnext_node_info = node.node.next_node\n\t\t\tif prev_node_info is not None:\n\t\t\t\tprev_id = prev_node_info.node_id\n\t\t\t\tif prev_id not in existing_ids:\n\t\t\t\t\texisting_ids.append(prev_id)\n\t\t\t\t\tprev_node = vector_index.docstore.get_node(node_id=prev_id)\n\t\t\t\t\tfinal_nodes.append(NodeWithScore(node=prev_node))\n\t\t\tfinal_nodes.append(node)\n\t\t\tif next_node_info is not None:\n\t\t\t\tnext_id = next_node_info.node_id\n\t\t\t\tif next_id not in existing_ids:\n\t\t\t\t\texisting_ids.append(next_id)\n\t\t\t\t\tnext_node = vector_index.docstore.get_node(node_id=next_id)\n\t\t\t\t\tfinal_nodes.append(NodeWithScore(node=next_node))\n\t\treturn final_nodes\n\n\tdef get_paper_retriever(self) -&gt; VectorIndexRetriever:\n\t\tr\"\"\"\n\t\tGet the default paper retriever, with a node_type_filter.\n\n\t\tReturns:\n\t\t\tVectorIndexRetriever: The paper retriever.\n\t\t\"\"\"\n\t\tpaper_retriever = self.paper_store.vector_index.as_retriever(\n\t\t\tsimilarity_top_k=self._relevant_top_k,\n\t\t\tfilters=MetadataFilters(\n\t\t\t\tfilters=[self.node_type_filter]\n\t\t\t),\n\t\t)\n\t\treturn paper_retriever\n\n\t@property\n\tdef node_type_filter(self) -&gt; MetadataFilter:\n\t\tr\"\"\"\n\t\tThe node type filter that filters nodes with type `TMP_PAPER_DOC_NODE_TYPE`.\n\n\t\tReturns:\n\t\t\tMetadataFilter: The node type metadata filter.\n\t\t\"\"\"\n\t\tdoc_node_filter = MetadataFilter(\n\t\t\tkey=TMP_PAPER_NODE_TYPE_KEY,\n\t\t\tvalue=TMP_PAPER_DOC_NODE_TYPE,\n\t\t\toperator=FilterOperator.EQ,\n\t\t)\n\t\treturn doc_node_filter\n\n\tdef get_date_filter(self, date_list: List[str]) -&gt; MetadataFilter:\n\t\tr\"\"\"\n\t\tGet the date filter that filters according to the creation date of nodes.\n\n\t\tArgs:\n\t\t\tdate_list (List[str]): The date candidates. Only nodes created in one of these dates will be retrieved.\n\n\t\tReturns:\n\t\t\tMetadataFilter: The date filter.\n\t\t\"\"\"\n\t\tdate_filter = MetadataFilter(\n\t\t\tkey=TMP_PAPER_DATE,\n\t\t\tvalue=date_list,\n\t\t\toperator=FilterOperator.ANY,\n\t\t)\n\t\treturn date_filter\n\n\tdef reset_retriever(self):\n\t\tr\"\"\"\n\t\tReset the paper retriever:\n\n\t\t- reset the node_ids that confine the retrieving range.\n\t\t- reset the similarity_top_k.\n\t\t- reset the MetadataFilters.\n\n\t\tReturns:\n\t\t\tNone.\n\t\t\"\"\"\n\t\tif self.paper_retriever:\n\t\t\tself.paper_retriever._node_ids = None\n\t\t\tself.paper_retriever._similarity_top_k = self._first_top_k\n\t\t\tself.paper_retriever._filters = MetadataFilters(\n\t\t\t\tfilters=[self.node_type_filter,]\n\t\t\t)\n\n\tdef first_retrieve(self, paper_info: str) -&gt; List[str]:\n\t\tr\"\"\"\n\t\tFirst retrieve: retrieve according to the paper_info.\n\n\t\tArgs:\n\t\t\tpaper_info (str): The information about the paper.\n\n\t\tReturns:\n\t\t\tList[str]: all the node ids of relevant papers.\n\t\t\"\"\"\n\t\tself.paper_retriever._similarity_top_k = self._first_top_k\n\t\tinfo_relevant_nodes = self.paper_retriever.retrieve(paper_info)\n\t\tconfine_node_ids = self.paper_store.get_all_relevant_node_ids(\n\t\t\tnode_ids=[node.node_id for node in info_relevant_nodes]\n\t\t)\n\t\treturn confine_node_ids\n\n\tasync def afirst_retrieve(self, paper_info: str) -&gt; List[str]:\n\t\tr\"\"\"\n\t\tFirst retrieve: retrieve according to the paper_info.\n\n\t\tArgs:\n\t\t\tpaper_info (str): The information about the paper.\n\n\t\tReturns:\n\t\t\tList[str]: all the node ids of relevant papers.\n\t\t\"\"\"\n\t\tself.paper_retriever._similarity_top_k = self._first_top_k\n\t\tinfo_relevant_nodes = await self.paper_retriever.aretrieve(paper_info)\n\t\tconfine_node_ids = self.paper_store.get_all_relevant_node_ids(\n\t\t\tnode_ids=[node.node_id for node in info_relevant_nodes]\n\t\t)\n\t\treturn confine_node_ids\n\n\tdef secondary_retrieve(\n\t\tself,\n\t\titem_to_be_retrieved: str,\n\t\tconfine_node_ids: List[str],\n\t) -&gt; List[NodeWithScore]:\n\t\tr\"\"\"\n\t\tSecondary retrieve in the confined nodes range.\n\n\t\tArgs:\n\t\t\titem_to_be_retrieved (str): The aspects to be retrieved in a paper.\n\t\t\tconfine_node_ids (List[str]): The confined node ids.\n\n\t\tReturns:\n\t\t\tList[NodeWithScore]: The retrieved relevant nodes.\n\t\t\"\"\"\n\t\tself.paper_retriever._node_ids = confine_node_ids\n\t\tnodes = self.paper_retriever.retrieve(item_to_be_retrieved)\n\t\treturn nodes\n\n\tasync def asecondary_retrieve(\n\t\tself,\n\t\titem_to_be_retrieved: str,\n\t\tconfine_node_ids: List[str],\n\t) -&gt; List[NodeWithScore]:\n\t\tr\"\"\"\n\t\tAsynchronous secondary retrieve in the confined nodes range.\n\n\t\tArgs:\n\t\t\titem_to_be_retrieved (str): The aspects to be retrieved in a paper.\n\t\t\tconfine_node_ids (List[str]): The confined node ids.\n\n\t\tReturns:\n\t\t\tList[NodeWithScore]: The retrieved relevant nodes.\n\t\t\"\"\"\n\t\tself.paper_retriever._node_ids = confine_node_ids\n\t\tnodes = await self.paper_retriever.aretrieve(item_to_be_retrieved)\n\t\treturn nodes\n\n\t@dispatcher.span\n\tdef retrieve(\n\t\tself,\n\t\tpaper_info: str,\n\t\titem_to_be_retrieved: str,\n\t\tuser_id: str,\n\t\tstart_date: str = None,\n\t\tend_date: str = None,\n\t\t**kwargs: Any,\n\t) -&gt; List[NodeWithScore]:\n\t\tr\"\"\"\n\t\tThis tool is used to retrieve in the recent papers storage of a specific user.\n\t\tThese information should be provided:\n\t\t1. The paper information, such as title or save path.\n\t\t2. The specific question that you want to obtain answer from the paper.\n\t\t3. The user id.\n\n\t\tArgs:\n\t\t\tpaper_info (str): This argument is necessary.\n\t\t\t\tIt is the relevant information of the paper.\n\t\t\t\tFor example, it can be the paper title, or its save path.\n\t\t\titem_to_be_retrieved (str): This argument is necessary.\n\t\t\t\tIt denotes the specific question that you want to retrieve in a specific paper.\n\t\t\tuser_id (str): This argument is necessary.\n\t\t\t\tThe user_id of a lab member.\n\t\t\tstart_date (str): This argument is optional. It denotes the start date in the format 'Year-Month-Day'.\n\t\t\t\tIf both start_date and end_date are specified, only papers which are added to storage between the\n\t\t\t\tstart_date and end_date will be retrieved.\n\t\t\tend_date: This argument is optional. It denotes the end date in the format 'Year-Month-Day'.\n\t\t\t**kwargs: Other keyword arguments will be ignored.\n\n\t\tReturns:\n\t\t\tThe retrieved results.\n\t\t\"\"\"\n\t\t# This docstring is used as the corresponding tool description.\n\t\tif self.paper_store is None or self.paper_store.user_id != user_id:\n\t\t\tself.paper_store = RecentPaperStore.from_user_id(\n\t\t\t\tuser_id=user_id,\n\t\t\t\tembed_model=self._embed_model,\n\t\t\t)\n\t\t\tif self.fs.exists(paper_info):\n\t\t\t\tprint(f\"Putting {paper_info} into storage.\")\n\t\t\t\tself.paper_store.put(paper_file_path=paper_info)\n\t\t\tself.paper_retriever = self.get_paper_retriever()\n\n\t\tself.reset_retriever()\n\n\t\t# if new file\n\t\tif self.fs.exists(paper_info) and not self.paper_store.file_exists(file_path=paper_info):\n\t\t\tself.paper_store.put(paper_file_path=paper_info)\n\n\t\tif None not in [start_date, end_date]:\n\t\t\t# get the candidate date list.\n\t\t\tdate_list = parse_date_list(start_date_str=start_date, end_date_str=end_date)\n\t\t\tmetadata_filters = MetadataFilters(\n\t\t\t\tfilters=[\n\t\t\t\t\tself.node_type_filter,\n\t\t\t\t\tself.get_date_filter(date_list=date_list),\n\t\t\t\t]\n\t\t\t)\n\t\t\tself.paper_retriever._filters = metadata_filters\n\n\t\tnode_ids_range = self.first_retrieve(paper_info=paper_info)\n\t\trelevant_nodes = self.secondary_retrieve(\n\t\t\titem_to_be_retrieved=item_to_be_retrieved,\n\t\t\tconfine_node_ids=node_ids_range,\n\t\t)\n\t\tif self._final_use_context:\n\t\t\trelevant_nodes = self._add_context(content_nodes=relevant_nodes)\n\n\t\treturn relevant_nodes\n\n\t@dispatcher.span\n\tasync def aretrieve(\n\t\tself,\n\t\tpaper_info: str,\n\t\titem_to_be_retrieved: str,\n\t\tuser_id: str,\n\t\tstart_date: str = None,\n\t\tend_date: str = None,\n\t\t**kwargs: Any,\n\t) -&gt; List[NodeWithScore]:\n\t\tr\"\"\"\n\t\tThis tool is used to retrieve in the recent papers storage of a specific user.\n\t\tThese information should be provided:\n\t\t1. The paper information, such as title or save path.\n\t\t2. The specific question that you want to obtain answer from the paper.\n\t\t3. The user id.\n\n\t\tArgs:\n\t\t\tpaper_info (str): This argument is necessary.\n\t\t\t\tIt is the relevant information of the paper.\n\t\t\t\tFor example, it can be the paper title, or its save path.\n\t\t\titem_to_be_retrieved (str): This argument is necessary.\n\t\t\t\tIt denotes the specific question that you want to retrieve in a specific paper.\n\t\t\tuser_id (str): This argument is necessary.\n\t\t\t\tThe user_id of a lab member.\n\t\t\tstart_date (str): This argument is optional. It denotes the start date in the format 'Year-Month-Day'.\n\t\t\t\tIf both start_date and end_date are specified, only papers which are added to storage between the\n\t\t\t\tstart_date and end_date will be retrieved.\n\t\t\tend_date: This argument is optional. It denotes the end date in the format 'Year-Month-Day'.\n\t\t\t**kwargs: Other keyword arguments will be ignored.\n\n\t\tReturns:\n\t\t\tThe retrieved results.\n\t\t\"\"\"\n\t\t# This docstring is used as the corresponding tool description.\n\t\tif self.paper_store is None or self.paper_store.user_id != user_id:\n\t\t\tself.paper_store = RecentPaperStore.from_user_id(\n\t\t\t\tuser_id=user_id,\n\t\t\t\tembed_model=self._embed_model,\n\t\t\t)\n\t\t\tif self.fs.exists(paper_info):\n\t\t\t\tself.paper_store.put(paper_file_path=paper_info)\n\t\t\tself.paper_retriever = self.get_paper_retriever()\n\n\t\tself.reset_retriever()\n\n\t\tif self.fs.exists(paper_info) and not self.paper_store.file_exists(file_path=paper_info):\n\t\t\tself.paper_store.put(paper_file_path=paper_info)\n\n\t\tif None not in [start_date, end_date]:\n\t\t\t# get the candidate date list.\n\t\t\tdate_list = parse_date_list(start_date_str=start_date, end_date_str=end_date)\n\t\t\tmetadata_filters = MetadataFilters(\n\t\t\t\tfilters=[\n\t\t\t\t\tself.node_type_filter,\n\t\t\t\t\tself.get_date_filter(date_list=date_list),\n\t\t\t\t]\n\t\t\t)\n\t\t\tself.paper_retriever._filters = metadata_filters\n\n\t\tnode_ids_range = await self.afirst_retrieve(paper_info=paper_info)\n\t\trelevant_nodes = await self.asecondary_retrieve(\n\t\t\titem_to_be_retrieved=item_to_be_retrieved,\n\t\t\tconfine_node_ids=node_ids_range,\n\t\t)\n\t\tif self._final_use_context:\n\t\t\trelevant_nodes = self._add_context(content_nodes=relevant_nodes)\n\t\treturn relevant_nodes\n</code></pre>"},{"location":"code_docs/func_modules/paper/retrieve/temporary_paper_retriever/#labridge.func_modules.paper.retrieve.temporary_paper_retriever.RecentPaperRetriever.node_type_filter","title":"<code>labridge.func_modules.paper.retrieve.temporary_paper_retriever.RecentPaperRetriever.node_type_filter: MetadataFilter</code>  <code>property</code>","text":"<p>The node type filter that filters nodes with type <code>TMP_PAPER_DOC_NODE_TYPE</code>.</p> RETURNS DESCRIPTION <code>MetadataFilter</code> <p>The node type metadata filter.</p> <p> TYPE: <code>MetadataFilter</code> </p>"},{"location":"code_docs/func_modules/paper/retrieve/temporary_paper_retriever/#labridge.func_modules.paper.retrieve.temporary_paper_retriever.RecentPaperRetriever.afirst_retrieve","title":"<code>labridge.func_modules.paper.retrieve.temporary_paper_retriever.RecentPaperRetriever.afirst_retrieve(paper_info)</code>  <code>async</code>","text":"<p>First retrieve: retrieve according to the paper_info.</p> PARAMETER DESCRIPTION <code>paper_info</code> <p>The information about the paper.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>List[str]</code> <p>List[str]: all the node ids of relevant papers.</p> Source code in <code>labridge\\func_modules\\paper\\retrieve\\temporary_paper_retriever.py</code> <pre><code>async def afirst_retrieve(self, paper_info: str) -&gt; List[str]:\n\tr\"\"\"\n\tFirst retrieve: retrieve according to the paper_info.\n\n\tArgs:\n\t\tpaper_info (str): The information about the paper.\n\n\tReturns:\n\t\tList[str]: all the node ids of relevant papers.\n\t\"\"\"\n\tself.paper_retriever._similarity_top_k = self._first_top_k\n\tinfo_relevant_nodes = await self.paper_retriever.aretrieve(paper_info)\n\tconfine_node_ids = self.paper_store.get_all_relevant_node_ids(\n\t\tnode_ids=[node.node_id for node in info_relevant_nodes]\n\t)\n\treturn confine_node_ids\n</code></pre>"},{"location":"code_docs/func_modules/paper/retrieve/temporary_paper_retriever/#labridge.func_modules.paper.retrieve.temporary_paper_retriever.RecentPaperRetriever.aretrieve","title":"<code>labridge.func_modules.paper.retrieve.temporary_paper_retriever.RecentPaperRetriever.aretrieve(paper_info, item_to_be_retrieved, user_id, start_date=None, end_date=None, **kwargs)</code>  <code>async</code>","text":"<p>This tool is used to retrieve in the recent papers storage of a specific user. These information should be provided: 1. The paper information, such as title or save path. 2. The specific question that you want to obtain answer from the paper. 3. The user id.</p> PARAMETER DESCRIPTION <code>paper_info</code> <p>This argument is necessary. It is the relevant information of the paper. For example, it can be the paper title, or its save path.</p> <p> TYPE: <code>str</code> </p> <code>item_to_be_retrieved</code> <p>This argument is necessary. It denotes the specific question that you want to retrieve in a specific paper.</p> <p> TYPE: <code>str</code> </p> <code>user_id</code> <p>This argument is necessary. The user_id of a lab member.</p> <p> TYPE: <code>str</code> </p> <code>start_date</code> <p>This argument is optional. It denotes the start date in the format 'Year-Month-Day'. If both start_date and end_date are specified, only papers which are added to storage between the start_date and end_date will be retrieved.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>end_date</code> <p>This argument is optional. It denotes the end date in the format 'Year-Month-Day'.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>**kwargs</code> <p>Other keyword arguments will be ignored.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>List[NodeWithScore]</code> <p>The retrieved results.</p> Source code in <code>labridge\\func_modules\\paper\\retrieve\\temporary_paper_retriever.py</code> <pre><code>@dispatcher.span\nasync def aretrieve(\n\tself,\n\tpaper_info: str,\n\titem_to_be_retrieved: str,\n\tuser_id: str,\n\tstart_date: str = None,\n\tend_date: str = None,\n\t**kwargs: Any,\n) -&gt; List[NodeWithScore]:\n\tr\"\"\"\n\tThis tool is used to retrieve in the recent papers storage of a specific user.\n\tThese information should be provided:\n\t1. The paper information, such as title or save path.\n\t2. The specific question that you want to obtain answer from the paper.\n\t3. The user id.\n\n\tArgs:\n\t\tpaper_info (str): This argument is necessary.\n\t\t\tIt is the relevant information of the paper.\n\t\t\tFor example, it can be the paper title, or its save path.\n\t\titem_to_be_retrieved (str): This argument is necessary.\n\t\t\tIt denotes the specific question that you want to retrieve in a specific paper.\n\t\tuser_id (str): This argument is necessary.\n\t\t\tThe user_id of a lab member.\n\t\tstart_date (str): This argument is optional. It denotes the start date in the format 'Year-Month-Day'.\n\t\t\tIf both start_date and end_date are specified, only papers which are added to storage between the\n\t\t\tstart_date and end_date will be retrieved.\n\t\tend_date: This argument is optional. It denotes the end date in the format 'Year-Month-Day'.\n\t\t**kwargs: Other keyword arguments will be ignored.\n\n\tReturns:\n\t\tThe retrieved results.\n\t\"\"\"\n\t# This docstring is used as the corresponding tool description.\n\tif self.paper_store is None or self.paper_store.user_id != user_id:\n\t\tself.paper_store = RecentPaperStore.from_user_id(\n\t\t\tuser_id=user_id,\n\t\t\tembed_model=self._embed_model,\n\t\t)\n\t\tif self.fs.exists(paper_info):\n\t\t\tself.paper_store.put(paper_file_path=paper_info)\n\t\tself.paper_retriever = self.get_paper_retriever()\n\n\tself.reset_retriever()\n\n\tif self.fs.exists(paper_info) and not self.paper_store.file_exists(file_path=paper_info):\n\t\tself.paper_store.put(paper_file_path=paper_info)\n\n\tif None not in [start_date, end_date]:\n\t\t# get the candidate date list.\n\t\tdate_list = parse_date_list(start_date_str=start_date, end_date_str=end_date)\n\t\tmetadata_filters = MetadataFilters(\n\t\t\tfilters=[\n\t\t\t\tself.node_type_filter,\n\t\t\t\tself.get_date_filter(date_list=date_list),\n\t\t\t]\n\t\t)\n\t\tself.paper_retriever._filters = metadata_filters\n\n\tnode_ids_range = await self.afirst_retrieve(paper_info=paper_info)\n\trelevant_nodes = await self.asecondary_retrieve(\n\t\titem_to_be_retrieved=item_to_be_retrieved,\n\t\tconfine_node_ids=node_ids_range,\n\t)\n\tif self._final_use_context:\n\t\trelevant_nodes = self._add_context(content_nodes=relevant_nodes)\n\treturn relevant_nodes\n</code></pre>"},{"location":"code_docs/func_modules/paper/retrieve/temporary_paper_retriever/#labridge.func_modules.paper.retrieve.temporary_paper_retriever.RecentPaperRetriever.asecondary_retrieve","title":"<code>labridge.func_modules.paper.retrieve.temporary_paper_retriever.RecentPaperRetriever.asecondary_retrieve(item_to_be_retrieved, confine_node_ids)</code>  <code>async</code>","text":"<p>Asynchronous secondary retrieve in the confined nodes range.</p> PARAMETER DESCRIPTION <code>item_to_be_retrieved</code> <p>The aspects to be retrieved in a paper.</p> <p> TYPE: <code>str</code> </p> <code>confine_node_ids</code> <p>The confined node ids.</p> <p> TYPE: <code>List[str]</code> </p> RETURNS DESCRIPTION <code>List[NodeWithScore]</code> <p>List[NodeWithScore]: The retrieved relevant nodes.</p> Source code in <code>labridge\\func_modules\\paper\\retrieve\\temporary_paper_retriever.py</code> <pre><code>async def asecondary_retrieve(\n\tself,\n\titem_to_be_retrieved: str,\n\tconfine_node_ids: List[str],\n) -&gt; List[NodeWithScore]:\n\tr\"\"\"\n\tAsynchronous secondary retrieve in the confined nodes range.\n\n\tArgs:\n\t\titem_to_be_retrieved (str): The aspects to be retrieved in a paper.\n\t\tconfine_node_ids (List[str]): The confined node ids.\n\n\tReturns:\n\t\tList[NodeWithScore]: The retrieved relevant nodes.\n\t\"\"\"\n\tself.paper_retriever._node_ids = confine_node_ids\n\tnodes = await self.paper_retriever.aretrieve(item_to_be_retrieved)\n\treturn nodes\n</code></pre>"},{"location":"code_docs/func_modules/paper/retrieve/temporary_paper_retriever/#labridge.func_modules.paper.retrieve.temporary_paper_retriever.RecentPaperRetriever.first_retrieve","title":"<code>labridge.func_modules.paper.retrieve.temporary_paper_retriever.RecentPaperRetriever.first_retrieve(paper_info)</code>","text":"<p>First retrieve: retrieve according to the paper_info.</p> PARAMETER DESCRIPTION <code>paper_info</code> <p>The information about the paper.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>List[str]</code> <p>List[str]: all the node ids of relevant papers.</p> Source code in <code>labridge\\func_modules\\paper\\retrieve\\temporary_paper_retriever.py</code> <pre><code>def first_retrieve(self, paper_info: str) -&gt; List[str]:\n\tr\"\"\"\n\tFirst retrieve: retrieve according to the paper_info.\n\n\tArgs:\n\t\tpaper_info (str): The information about the paper.\n\n\tReturns:\n\t\tList[str]: all the node ids of relevant papers.\n\t\"\"\"\n\tself.paper_retriever._similarity_top_k = self._first_top_k\n\tinfo_relevant_nodes = self.paper_retriever.retrieve(paper_info)\n\tconfine_node_ids = self.paper_store.get_all_relevant_node_ids(\n\t\tnode_ids=[node.node_id for node in info_relevant_nodes]\n\t)\n\treturn confine_node_ids\n</code></pre>"},{"location":"code_docs/func_modules/paper/retrieve/temporary_paper_retriever/#labridge.func_modules.paper.retrieve.temporary_paper_retriever.RecentPaperRetriever.get_date_filter","title":"<code>labridge.func_modules.paper.retrieve.temporary_paper_retriever.RecentPaperRetriever.get_date_filter(date_list)</code>","text":"<p>Get the date filter that filters according to the creation date of nodes.</p> PARAMETER DESCRIPTION <code>date_list</code> <p>The date candidates. Only nodes created in one of these dates will be retrieved.</p> <p> TYPE: <code>List[str]</code> </p> RETURNS DESCRIPTION <code>MetadataFilter</code> <p>The date filter.</p> <p> TYPE: <code>MetadataFilter</code> </p> Source code in <code>labridge\\func_modules\\paper\\retrieve\\temporary_paper_retriever.py</code> <pre><code>def get_date_filter(self, date_list: List[str]) -&gt; MetadataFilter:\n\tr\"\"\"\n\tGet the date filter that filters according to the creation date of nodes.\n\n\tArgs:\n\t\tdate_list (List[str]): The date candidates. Only nodes created in one of these dates will be retrieved.\n\n\tReturns:\n\t\tMetadataFilter: The date filter.\n\t\"\"\"\n\tdate_filter = MetadataFilter(\n\t\tkey=TMP_PAPER_DATE,\n\t\tvalue=date_list,\n\t\toperator=FilterOperator.ANY,\n\t)\n\treturn date_filter\n</code></pre>"},{"location":"code_docs/func_modules/paper/retrieve/temporary_paper_retriever/#labridge.func_modules.paper.retrieve.temporary_paper_retriever.RecentPaperRetriever.get_paper_retriever","title":"<code>labridge.func_modules.paper.retrieve.temporary_paper_retriever.RecentPaperRetriever.get_paper_retriever()</code>","text":"<p>Get the default paper retriever, with a node_type_filter.</p> RETURNS DESCRIPTION <code>VectorIndexRetriever</code> <p>The paper retriever.</p> <p> TYPE: <code>VectorIndexRetriever</code> </p> Source code in <code>labridge\\func_modules\\paper\\retrieve\\temporary_paper_retriever.py</code> <pre><code>def get_paper_retriever(self) -&gt; VectorIndexRetriever:\n\tr\"\"\"\n\tGet the default paper retriever, with a node_type_filter.\n\n\tReturns:\n\t\tVectorIndexRetriever: The paper retriever.\n\t\"\"\"\n\tpaper_retriever = self.paper_store.vector_index.as_retriever(\n\t\tsimilarity_top_k=self._relevant_top_k,\n\t\tfilters=MetadataFilters(\n\t\t\tfilters=[self.node_type_filter]\n\t\t),\n\t)\n\treturn paper_retriever\n</code></pre>"},{"location":"code_docs/func_modules/paper/retrieve/temporary_paper_retriever/#labridge.func_modules.paper.retrieve.temporary_paper_retriever.RecentPaperRetriever.reset_retriever","title":"<code>labridge.func_modules.paper.retrieve.temporary_paper_retriever.RecentPaperRetriever.reset_retriever()</code>","text":"<p>Reset the paper retriever:</p> <ul> <li>reset the node_ids that confine the retrieving range.</li> <li>reset the similarity_top_k.</li> <li>reset the MetadataFilters.</li> </ul> RETURNS DESCRIPTION <p>None.</p> Source code in <code>labridge\\func_modules\\paper\\retrieve\\temporary_paper_retriever.py</code> <pre><code>def reset_retriever(self):\n\tr\"\"\"\n\tReset the paper retriever:\n\n\t- reset the node_ids that confine the retrieving range.\n\t- reset the similarity_top_k.\n\t- reset the MetadataFilters.\n\n\tReturns:\n\t\tNone.\n\t\"\"\"\n\tif self.paper_retriever:\n\t\tself.paper_retriever._node_ids = None\n\t\tself.paper_retriever._similarity_top_k = self._first_top_k\n\t\tself.paper_retriever._filters = MetadataFilters(\n\t\t\tfilters=[self.node_type_filter,]\n\t\t)\n</code></pre>"},{"location":"code_docs/func_modules/paper/retrieve/temporary_paper_retriever/#labridge.func_modules.paper.retrieve.temporary_paper_retriever.RecentPaperRetriever.retrieve","title":"<code>labridge.func_modules.paper.retrieve.temporary_paper_retriever.RecentPaperRetriever.retrieve(paper_info, item_to_be_retrieved, user_id, start_date=None, end_date=None, **kwargs)</code>","text":"<p>This tool is used to retrieve in the recent papers storage of a specific user. These information should be provided: 1. The paper information, such as title or save path. 2. The specific question that you want to obtain answer from the paper. 3. The user id.</p> PARAMETER DESCRIPTION <code>paper_info</code> <p>This argument is necessary. It is the relevant information of the paper. For example, it can be the paper title, or its save path.</p> <p> TYPE: <code>str</code> </p> <code>item_to_be_retrieved</code> <p>This argument is necessary. It denotes the specific question that you want to retrieve in a specific paper.</p> <p> TYPE: <code>str</code> </p> <code>user_id</code> <p>This argument is necessary. The user_id of a lab member.</p> <p> TYPE: <code>str</code> </p> <code>start_date</code> <p>This argument is optional. It denotes the start date in the format 'Year-Month-Day'. If both start_date and end_date are specified, only papers which are added to storage between the start_date and end_date will be retrieved.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>end_date</code> <p>This argument is optional. It denotes the end date in the format 'Year-Month-Day'.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>**kwargs</code> <p>Other keyword arguments will be ignored.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>List[NodeWithScore]</code> <p>The retrieved results.</p> Source code in <code>labridge\\func_modules\\paper\\retrieve\\temporary_paper_retriever.py</code> <pre><code>@dispatcher.span\ndef retrieve(\n\tself,\n\tpaper_info: str,\n\titem_to_be_retrieved: str,\n\tuser_id: str,\n\tstart_date: str = None,\n\tend_date: str = None,\n\t**kwargs: Any,\n) -&gt; List[NodeWithScore]:\n\tr\"\"\"\n\tThis tool is used to retrieve in the recent papers storage of a specific user.\n\tThese information should be provided:\n\t1. The paper information, such as title or save path.\n\t2. The specific question that you want to obtain answer from the paper.\n\t3. The user id.\n\n\tArgs:\n\t\tpaper_info (str): This argument is necessary.\n\t\t\tIt is the relevant information of the paper.\n\t\t\tFor example, it can be the paper title, or its save path.\n\t\titem_to_be_retrieved (str): This argument is necessary.\n\t\t\tIt denotes the specific question that you want to retrieve in a specific paper.\n\t\tuser_id (str): This argument is necessary.\n\t\t\tThe user_id of a lab member.\n\t\tstart_date (str): This argument is optional. It denotes the start date in the format 'Year-Month-Day'.\n\t\t\tIf both start_date and end_date are specified, only papers which are added to storage between the\n\t\t\tstart_date and end_date will be retrieved.\n\t\tend_date: This argument is optional. It denotes the end date in the format 'Year-Month-Day'.\n\t\t**kwargs: Other keyword arguments will be ignored.\n\n\tReturns:\n\t\tThe retrieved results.\n\t\"\"\"\n\t# This docstring is used as the corresponding tool description.\n\tif self.paper_store is None or self.paper_store.user_id != user_id:\n\t\tself.paper_store = RecentPaperStore.from_user_id(\n\t\t\tuser_id=user_id,\n\t\t\tembed_model=self._embed_model,\n\t\t)\n\t\tif self.fs.exists(paper_info):\n\t\t\tprint(f\"Putting {paper_info} into storage.\")\n\t\t\tself.paper_store.put(paper_file_path=paper_info)\n\t\tself.paper_retriever = self.get_paper_retriever()\n\n\tself.reset_retriever()\n\n\t# if new file\n\tif self.fs.exists(paper_info) and not self.paper_store.file_exists(file_path=paper_info):\n\t\tself.paper_store.put(paper_file_path=paper_info)\n\n\tif None not in [start_date, end_date]:\n\t\t# get the candidate date list.\n\t\tdate_list = parse_date_list(start_date_str=start_date, end_date_str=end_date)\n\t\tmetadata_filters = MetadataFilters(\n\t\t\tfilters=[\n\t\t\t\tself.node_type_filter,\n\t\t\t\tself.get_date_filter(date_list=date_list),\n\t\t\t]\n\t\t)\n\t\tself.paper_retriever._filters = metadata_filters\n\n\tnode_ids_range = self.first_retrieve(paper_info=paper_info)\n\trelevant_nodes = self.secondary_retrieve(\n\t\titem_to_be_retrieved=item_to_be_retrieved,\n\t\tconfine_node_ids=node_ids_range,\n\t)\n\tif self._final_use_context:\n\t\trelevant_nodes = self._add_context(content_nodes=relevant_nodes)\n\n\treturn relevant_nodes\n</code></pre>"},{"location":"code_docs/func_modules/paper/retrieve/temporary_paper_retriever/#labridge.func_modules.paper.retrieve.temporary_paper_retriever.RecentPaperRetriever.secondary_retrieve","title":"<code>labridge.func_modules.paper.retrieve.temporary_paper_retriever.RecentPaperRetriever.secondary_retrieve(item_to_be_retrieved, confine_node_ids)</code>","text":"<p>Secondary retrieve in the confined nodes range.</p> PARAMETER DESCRIPTION <code>item_to_be_retrieved</code> <p>The aspects to be retrieved in a paper.</p> <p> TYPE: <code>str</code> </p> <code>confine_node_ids</code> <p>The confined node ids.</p> <p> TYPE: <code>List[str]</code> </p> RETURNS DESCRIPTION <code>List[NodeWithScore]</code> <p>List[NodeWithScore]: The retrieved relevant nodes.</p> Source code in <code>labridge\\func_modules\\paper\\retrieve\\temporary_paper_retriever.py</code> <pre><code>def secondary_retrieve(\n\tself,\n\titem_to_be_retrieved: str,\n\tconfine_node_ids: List[str],\n) -&gt; List[NodeWithScore]:\n\tr\"\"\"\n\tSecondary retrieve in the confined nodes range.\n\n\tArgs:\n\t\titem_to_be_retrieved (str): The aspects to be retrieved in a paper.\n\t\tconfine_node_ids (List[str]): The confined node ids.\n\n\tReturns:\n\t\tList[NodeWithScore]: The retrieved relevant nodes.\n\t\"\"\"\n\tself.paper_retriever._node_ids = confine_node_ids\n\tnodes = self.paper_retriever.retrieve(item_to_be_retrieved)\n\treturn nodes\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/paper_store/","title":"Paper store","text":""},{"location":"code_docs/func_modules/paper/store/paper_store/#labridge.func_modules.paper.store.paper_store","title":"<code>labridge.func_modules.paper.store.paper_store</code>","text":""},{"location":"code_docs/func_modules/paper/store/paper_store/#labridge.func_modules.paper.store.paper_store.PaperDirectorySummaryStore","title":"<code>labridge.func_modules.paper.store.paper_store.PaperDirectorySummaryStore</code>","text":"<p>This class is used to store the summary of each paper directory. It is useful for storing new papers in proper directories, recommending papers to lab members, etc.</p> <p>Initially, the directory summary store is automatically constructed using LLM to summarize each directory. However, it is not accurate enough, it should be updated according to the relevant research fields information provided by Lab members.</p> <p>Before storing directory summaries, make sure that all target papers have been added to the paper warehouse and stored in the <code>PaperStorage</code>.</p> <p>Each directory summary node is stored in the docstore, two items are recorded:</p> <ol> <li>the possessor of this directory.</li> <li>the summary (relevant research fields) of this directory.</li> </ol> <p>These two items are stored as metadata of th summary node.</p> PARAMETER DESCRIPTION <code>llm</code> <p>the used llm.</p> <p> TYPE: <code>LLM</code> DEFAULT: <code>None</code> </p> <code>embed_model</code> <p>the used embed model.</p> <p> TYPE: <code>BaseEmbedding</code> DEFAULT: <code>None</code> </p> <code>paper_root</code> <p>the directory root of the paper warehouse.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>paper_summary_persist_dir</code> <p>the directory storing the paper summary index.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>directory_summary_persist_dir</code> <p>the directory storing the directory summary index.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>service_context</code> <p>service_context</p> <p> TYPE: <code>ServiceContext</code> DEFAULT: <code>None</code> </p> <code>dir_choice_batch_size</code> <p> TYPE: <code>int</code> DEFAULT: <code>5</code> </p> Source code in <code>labridge\\func_modules\\paper\\store\\paper_store.py</code> <pre><code>class PaperDirectorySummaryStore:\n\tr\"\"\"\n\tThis class is used to store the summary of each paper directory.\n\tIt is useful for storing new papers in proper directories, recommending papers to lab members, etc.\n\n\tInitially, the directory summary store is automatically constructed using LLM to summarize each directory.\n\tHowever, it is not accurate enough, it should be updated according to the relevant research fields information\n\tprovided by Lab members.\n\n\tBefore storing directory summaries, make sure that all target papers have been added to the paper warehouse and\n\tstored in the `PaperStorage`.\n\n\tEach directory summary node is stored in the docstore, two items are recorded:\n\n\t1. the possessor of this directory.\n\t2. the summary (relevant research fields) of this directory.\n\n\tThese two items are stored as metadata of th summary node.\n\n\tArgs:\n\t\tllm (LLM): the used llm.\n\t\tembed_model (BaseEmbedding): the used embed model.\n\t\tpaper_root (str): the directory root of the paper warehouse.\n\t\tpaper_summary_persist_dir (str): the directory storing the paper summary index.\n\t\tdirectory_summary_persist_dir (str): the directory storing the directory summary index.\n\t\tservice_context (ServiceContext): service_context\n\t\tdir_choice_batch_size (int):\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tllm: Optional[LLM] = None,\n\t\tembed_model: Optional[BaseEmbedding] = None,\n\t\tpaper_root: Union[os.PathLike, str] = None,\n\t\tpaper_summary_persist_dir: Union[str, os.PathLike] = None,\n\t\tdirectory_summary_persist_dir: Union[str, os.PathLike] = None,\n\t\tservice_context: Optional[ServiceContext] = None,\n\t\tdir_choice_batch_size: int = 5,\n\t):\n\t\troot = Path(__file__)\n\t\tfor i in range(5):\n\t\t\troot = root.parent\n\t\tself.root = root\n\n\t\tself.llm = llm or llm_from_settings_or_context(Settings, service_context)\n\t\tself.embed_model = embed_model or embed_model_from_settings_or_context(Settings, service_context)\n\t\tself.service_context = service_context\n\t\tself.paper_root = self._path_format(\n\t\t\tpath=paper_root,\n\t\t\tdefault=root / DEFAULT_PAPER_WAREHOUSE_DIR,\n\t\t)\n\t\tself.paper_summary_persist_dir = self._path_format(\n\t\t\tpath=paper_summary_persist_dir,\n\t\t\tdefault=root / DEFAULT_PAPER_SUMMARY_PERSIST_DIR,\n\t\t)\n\t\tself.directory_summary_persist_dir = self._path_format(\n\t\t\tpath=directory_summary_persist_dir,\n\t\t\tdefault=root / DEFAULT_DIRECTORY_SUMMARY_PERSIST_DIR,\n\t\t)\n\t\tif not Path(self.directory_summary_persist_dir).exists():\n\t\t\tself._auto_construct()\n\t\tdirectory_storage_context = StorageContext.from_defaults(persist_dir=self.directory_summary_persist_dir)\n\t\tself.directory_summary_index = load_index_from_storage(\n\t\t\tstorage_context=directory_storage_context,\n\t\t\tindex_id=DIR_SUMMARY_INDEX_ID,\n\t\t\tservice_context=self.service_context,\n\t\t)\n\t\tself.dir_choice_batch_size = dir_choice_batch_size\n\n\n\tdef _path_format(self, path: Union[os.PathLike, str], default: Path) -&gt; str:\n\t\tif path is None:\n\t\t\treturn str(default)\n\t\treturn path\n\n\tdef _auto_summarize_dir(self, directory: str, verbose: bool = False):\n\t\tr\"\"\"\n\t\tAutomatically summarize each directory under the given directory.\n\t\tThe given directory must be under the paper root.\n\t\t\"\"\"\n\t\tif directory != self.paper_root and Path(self.paper_root) not in Path(directory).parents:\n\t\t\traise ValueError(\"Invalid directory. The input directory should be under the paper warehouse.\")\n\n\t\tpaper_summary_storage_context = StorageContext.from_defaults(persist_dir=self.paper_summary_persist_dir)\n\t\tpaper_summary_index = load_index_from_storage(\n\t\t\tstorage_context=paper_summary_storage_context,\n\t\t\tindex_id=PAPER_SUMMARY_INDEX_ID,\n\t\t\tservice_context=self.service_context,\n\t\t)\n\t\tdoc_id_to_summary_id = paper_summary_index.index_struct.doc_id_to_summary_id\n\n\t\tif not Path(self.directory_summary_persist_dir).exists():\n\t\t\trel_paper_root = Path(self.paper_root).relative_to(self.root)\n\t\t\troot_node = TextNode(text=\"\", id_=str(rel_paper_root), )\n\t\t\troot_node.relationships[NodeRelationship.SOURCE] = RelatedNodeInfo(node_id=\"Paper warehouse\", )\n\t\t\tdir_summary_index = DocumentSummaryIndex(\n\t\t\t\tnodes=[root_node, ],\n\t\t\t\tllm=self.llm,\n\t\t\t\tembed_model=self.embed_model,\n\t\t\t\tservice_context=self.service_context,\n\t\t\t\tresponse_synthesizer=get_response_synthesizer(\n\t\t\t\t\tllm=self.llm,\n\t\t\t\t\tresponse_mode=ResponseMode.COMPACT_ACCUMULATE\n\t\t\t\t),\n\t\t\t)\n\t\telse:\n\t\t\tdirectory_storage_context = StorageContext.from_defaults(persist_dir=self.directory_summary_persist_dir)\n\t\t\tdir_summary_index = load_index_from_storage(\n\t\t\t\tstorage_context=directory_storage_context,\n\t\t\t\tindex_id=DIR_SUMMARY_INDEX_ID,\n\t\t\t\tservice_context=self.service_context,\n\t\t\t)\n\t\tdir_id_to_summary_id = dir_summary_index.index_struct.doc_id_to_summary_id\n\n\t\tdef dfs(current_dir: Path):\n\t\t\tif not current_dir.is_dir():\n\t\t\t\treturn\n\n\t\t\tfor child in current_dir.iterdir():\n\t\t\t\tdfs(child)\n\n\t\t\tnodes = []\n\t\t\tcurrent_dir_id = str(current_dir.relative_to(self.root))\n\t\t\tif current_dir_id == DEFAULT_PAPER_WAREHOUSE_DIR:\n\t\t\t\treturn\n\n\t\t\tpossessor = current_dir_id.split('/')[2]\n\t\t\tprint_text(f\"&gt;&gt;&gt; Processing: {current_dir}\", color=\"blue\", end=\"\\n\")\n\t\t\tfor child in current_dir.iterdir():\n\t\t\t\tif not child.is_dir() and child.suffix == \".pdf\":\n\t\t\t\t\trel_paper = str(child.relative_to(self.root))\n\t\t\t\t\tchild_main_text = rel_paper + f\"_{MAINTEXT}\"\n\t\t\t\t\tchild_methods = rel_paper + f\"_{METHODS}\"\n\t\t\t\t\tfor doc_id in (child_main_text, child_methods):\n\t\t\t\t\t\tif doc_id not in doc_id_to_summary_id.keys() and verbose:\n\t\t\t\t\t\t\tprint(f\"{doc_id} not stored into the PaperStorage yet, \"\n\t\t\t\t\t\t\t\t  f\"please insert it into the PaperStorage first.\")\n\t\t\t\t\t\tif doc_id in doc_id_to_summary_id.keys():\n\t\t\t\t\t\t\tsummary_id = doc_id_to_summary_id[doc_id]\n\t\t\t\t\t\t\tpaper_summary_node = paper_summary_index.docstore.get_node(summary_id)\n\t\t\t\t\t\t\t# Get the paper keywords\n\t\t\t\t\t\t\tif PAPER_LEVEL_KEYWORDS in paper_summary_node.metadata.keys():\n\t\t\t\t\t\t\t\tpaper_keywords = paper_summary_node.metadata[PAPER_LEVEL_KEYWORDS]\n\t\t\t\t\t\t\telse:\n\t\t\t\t\t\t\t\t# extract keywords.\n\t\t\t\t\t\t\t\tpaper_keywords = dir_summary_index._response_synthesizer.synthesize(\n\t\t\t\t\t\t\t\t\tquery=PAPER_KEYWORDS_EXTRACT_QUERY,\n\t\t\t\t\t\t\t\t\tnodes=[NodeWithScore(node=paper_summary_node)]\n\t\t\t\t\t\t\t\t)\n\n\t\t\t\t\t\t\t# filter metadata (possessor &amp; paper keywords)\n\t\t\t\t\t\t\tpaper_summary_node.metadata = {\n\t\t\t\t\t\t\t\tPAPER_POSSESSOR: possessor,\n\t\t\t\t\t\t\t\tPAPER_LEVEL_KEYWORDS: paper_keywords,\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tpaper_summary_node.set_content(\"\")\n\t\t\t\t\t\t\tpaper_summary_node.relationships[NodeRelationship.SOURCE] = RelatedNodeInfo(\n\t\t\t\t\t\t\t\tnode_id=current_dir_id,\n\t\t\t\t\t\t\t)\n\t\t\t\t\t\t\tnodes.append(paper_summary_node)\n\t\t\t\telif child.is_dir():\n\t\t\t\t\tchild_dir_id = str(child.relative_to(self.root))\n\t\t\t\t\tif child_dir_id in dir_id_to_summary_id.keys():\n\t\t\t\t\t\tchild_summary_id = dir_id_to_summary_id[child_dir_id]\n\t\t\t\t\t\tdir_summary_node = dir_summary_index.docstore.get_node(child_summary_id)\n\t\t\t\t\t\tdir_summary_node.relationships[NodeRelationship.SOURCE] = RelatedNodeInfo(\n\t\t\t\t\t\t\tnode_id=current_dir_id,\n\t\t\t\t\t\t)\n\t\t\t\t\t\tnodes.append(dir_summary_node)\n\n\t\t\t# Summarize current directory based on its children\n\t\t\tnodes_with_scores = [NodeWithScore(node=n) for n in nodes]\n\n\t\t\tif len(nodes_with_scores) &gt; 0:\n\t\t\t\tsummary_response = dir_summary_index._response_synthesizer.synthesize(\n\t\t\t\t\tquery=DIR_SUMMARIZE_QUERY,\n\t\t\t\t\tnodes=nodes_with_scores,\n\t\t\t\t)\n\n\t\t\t\tsummary_response = cast(Response, summary_response)\n\t\t\t\tdir_summary_node = TextNode(\n\t\t\t\t\ttext=\"\",\n\t\t\t\t\trelationships={NodeRelationship.SOURCE: RelatedNodeInfo(node_id=current_dir_id)},\n\t\t\t\t\tmetadata={\n\t\t\t\t\t\tPAPER_POSSESSOR: possessor,\n\t\t\t\t\t\tPAPER_LEVEL_KEYWORDS: summary_response.response,\n\t\t\t\t\t},\n\t\t\t\t)\n\n\t\t\t\tdir_summary_index.docstore.add_documents([dir_summary_node])\n\t\t\t\tdir_summary_index._index_struct.doc_id_to_summary_id[current_dir_id] = dir_summary_node.node_id\n\n\t\t\t\tid_to_embed_map = embed_nodes([dir_summary_node,], self.embed_model)\n\t\t\t\tnode_with_embedding = dir_summary_node.copy()\n\t\t\t\tnode_with_embedding.embedding = id_to_embed_map[dir_summary_node.node_id]\n\t\t\t\tdir_summary_index._vector_store.add([node_with_embedding, ])\n\t\t\t\tdir_summary_index._storage_context.index_store.add_index_struct(dir_summary_index._index_struct)\n\n\t\tdfs(Path(directory))\n\t\tif dir_summary_index.index_id != DIR_SUMMARY_INDEX_ID:\n\t\t\tdir_summary_index.set_index_id(DIR_SUMMARY_INDEX_ID)\n\t\tdir_summary_index.storage_context.persist(persist_dir=str(self.directory_summary_persist_dir))\n\n\tdef _auto_construct(self):\n\t\tr\"\"\"\n\t\tAutomatically construct the directory summary index based on the paper warehouse.\n\n\t\tDFS the directory tree, directory root: `self.paper_root`.\n\t\tThe summary (relevant research fields) of each directory is synthesized from its child directories.\n\n\t\tEach summary node of a directory: ref_doc_id: the directory path relative to the root.\n\t\t\"\"\"\n\t\tself._auto_summarize_dir(self.paper_root)\n\n\tdef get_dir_nodes(self):\n\t\tr\"\"\" get the valid directory summary nodes \"\"\"\n\t\tdir_id_to_summary_id = self.directory_summary_index._index_struct.doc_id_to_summary_id\n\t\tdir_summary_nodes = []\n\t\tfor dir_id in dir_id_to_summary_id.keys():\n\t\t\tdir_path = self.root / dir_id\n\t\t\tif dir_path.exists():\n\t\t\t\tsummary_id = dir_id_to_summary_id[dir_id]\n\t\t\t\tsummary_node = self.directory_summary_index.docstore.get_node(summary_id)\n\t\t\t\tdir_summary_nodes.append(summary_node)\n\t\treturn dir_summary_nodes\n\n\tdef match_directory_for_new_paper(\n\t\tself,\n\t\tpdf_path: str,\n\t\tpossessor: str,\n\t\tpaper_summary: str = None,\n\t\tverbose: bool=False,\n\t) -&gt; Union[str, None]:\n\t\tr\"\"\"\n\t\tselect the most relevant (and deepest) directory for the new paper.\n\n\t\tArgs:\n\t\t\tpdf_path (str): the path of the new paper.\n\t\t\tpossessor (str): the possessor of this new paper.\n\t\t\tpaper_summary (str): the summary of the new paper.\n\t\t\tverbose (bool): whether to show progress.\n\n\t\tReturns:\n\t\t\tUnion[str, None]:\n\t\t\t\tThe matched directory for the new paper. If no proper directory found, return None.\n\t\t\"\"\"\n\t\tpdf_path = Path(pdf_path)\n\t\tif pdf_path.suffix != \".pdf\":\n\t\t\traise ValueError(\"Only papers with PDF format are supported now.\")\n\t\tpossessor_dir = Path(self.paper_root) / possessor\n\t\tif not possessor_dir.exists():\n\t\t\traise ValueError(f\"The member {possessor} do not exist. Please sign up as a member first.\")\n\n\t\tif paper_summary is None:\n\t\t\tpdf_docs = PyMuPDFReader().load_data(file_path=pdf_path)\n\t\t\t# typically, the first page includes conclusive information of a paper.\n\t\t\tpaper_summary = pdf_docs[0].text\n\n\t\tdir_summary_nodes = self.get_dir_nodes()\n\n\t\tselected_nodes = []\n\t\tselected_relevances = []\n\n\t\tfor idx in range(0, len(dir_summary_nodes), self.dir_choice_batch_size):\n\t\t\tsummary_nodes = dir_summary_nodes[idx: idx + self.dir_choice_batch_size]\n\t\t\tdir_context_str = default_format_node_batch_fn(summary_nodes=summary_nodes)\n\n\t\t\traw_response = self.llm.predict(\n\t\t\t\tDIR_CHOICE_SELECT_PROMPT,\n\t\t\t\tdir_context_str=dir_context_str,\n\t\t\t\tpaper_str=paper_summary,\n\t\t\t)\n\t\t\traw_choices, relevances = default_parse_choice_select_answer_fn(raw_response, len(summary_nodes))\n\t\t\tchoice_idxs = [choice - 1 for choice in raw_choices]\n\t\t\tchoice_summary_nodes = [summary_nodes[ci] for ci in choice_idxs]\n\t\t\tselected_nodes.extend(choice_summary_nodes)\n\t\t\tselected_relevances.extend(relevances)\n\n\t\tif len(selected_nodes) == 0:\n\t\t\treturn None\n\n\t\tzipped_list = list(zip(selected_nodes, selected_relevances))\n\t\tsorted_list = sorted(zipped_list, key=lambda x: x[1], reverse=True)\n\t\t# choose the most relevant and the deepest directory.\n\t\tbest_dir = sorted_list[0][0].ref_doc_id\n\n\t\tif verbose:\n\t\t\tfor node, relevance in sorted_list:\n\t\t\t\tprint_text(f\"&gt;&gt;&gt; dir: {node.ref_doc_id}, relevance: {relevance}\", color=\"blue\", end=\"\\n\")\n\t\tdef sub_dir_nodes(paper_dir: str):\n\t\t\tsub_nodes_with_score = []\n\t\t\tfor node, score in sorted_list:\n\t\t\t\tif Path(paper_dir) in Path(node.ref_doc_id).parents:\n\t\t\t\t\tsub_nodes_with_score.append((node, score))\n\t\t\treturn sub_nodes_with_score\n\n\t\tsub_list = sub_dir_nodes(best_dir)\n\t\twhile len(sub_list) &gt; 0:\n\t\t\tsub_list = sorted(sub_list, key=lambda x: x[1], reverse=True)\n\t\t\tbest_dir = sub_list[0][0].ref_doc_id\n\t\t\tsub_list = sub_dir_nodes(best_dir)\n\t\treturn best_dir\n\n\tdef update(self, dir_description_dict: Dict[str, str]):\n\t\tr\"\"\"\n\t\tUpdate the relevant research fields of each directory.\n\t\tTypically used for manually set each directory's relevant research fields.\n\n\t\tArgs:\n\t\t\tdir_description_dict (Dict[str, str]): the descriptions of the paper directories\n\t\t\t\t- key: the directory path relative to root;\n\t\t\t\t- value: the relevant research fields of the directory.\n\t\t\"\"\"\n\t\tfor dir_id in dir_description_dict.keys():\n\t\t\tself._set_dir_metadata(\n\t\t\t\tdir_id=dir_id,\n\t\t\t\tkey=PAPER_LEVEL_KEYWORDS,\n\t\t\t\tval=dir_description_dict[dir_id],\n\t\t\t)\n\n\tdef _set_dir_metadata(self, dir_id: str, key: str, val: Any):\n\t\tdir_id_to_summary_id = self.directory_summary_index._index_struct.doc_id_to_summary_id\n\t\tnode_collection = self.directory_summary_index.docstore._node_collection\n\n\t\tif dir_id in dir_id_to_summary_id.keys():\n\t\t\tsummary_id = dir_id_to_summary_id[dir_id]\n\t\t\tsummary_store = self.directory_summary_index.docstore._kvstore._data[node_collection][summary_id]\n\t\t\tsummary_store[\"__data__\"][\"metadata\"][key] = val\n\n\t\tself.directory_summary_index.storage_context.persist(persist_dir=self.directory_summary_persist_dir)\n\n\tdef set_possessor_research_categories(self, possessor_category_dict: Dict[str, List[str]]):\n\t\tr\"\"\"\n\t\tSet the research categories of the possessors, this research categories is used to recommend proper new papers\n\t\tto the possessors.\n\n\t\tArgs:\n\t\t\tpossessor_category_dict (Dict[str, List[str]]): the research categories to be set.\n\t\t\t\tIt is a dictionary with:\n\n\t\t\t\t- key: possessor\n\t\t\t\t- value: the list of research categories. For details about research categories,\n\t\t\t\trefer to the class `ArxivCategory`.\n\t\t\"\"\"\n\t\tfor possessor in possessor_category_dict.keys():\n\t\t\tdir_id = str((Path(self.paper_root) / possessor).relative_to(self.root))\n\t\t\tself._set_dir_metadata(\n\t\t\t\tdir_id=dir_id,\n\t\t\t\tkey=DIR_CATEGORY_NAME,\n\t\t\t\tval=possessor_category_dict[possessor],\n\t\t\t)\n\n\tdef add_dir(self, directory: str, verbose: bool = False):\n\t\tr\"\"\"\n\t\tAdd a directory to the paper storage.\n\t\t\"\"\"\n\t\tif Path(self.paper_root) not in Path(directory).parents:\n\t\t\traise ValueError(\"Invalid directory path, please add your documents to the paper warehouse, \"\n\t\t\t\t\t\t\t \"and store them in the PaperStorage first.\")\n\t\tself._auto_summarize_dir(directory=directory, verbose=verbose)\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/paper_store/#labridge.func_modules.paper.store.paper_store.PaperDirectorySummaryStore.add_dir","title":"<code>labridge.func_modules.paper.store.paper_store.PaperDirectorySummaryStore.add_dir(directory, verbose=False)</code>","text":"<p>Add a directory to the paper storage.</p> Source code in <code>labridge\\func_modules\\paper\\store\\paper_store.py</code> <pre><code>def add_dir(self, directory: str, verbose: bool = False):\n\tr\"\"\"\n\tAdd a directory to the paper storage.\n\t\"\"\"\n\tif Path(self.paper_root) not in Path(directory).parents:\n\t\traise ValueError(\"Invalid directory path, please add your documents to the paper warehouse, \"\n\t\t\t\t\t\t \"and store them in the PaperStorage first.\")\n\tself._auto_summarize_dir(directory=directory, verbose=verbose)\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/paper_store/#labridge.func_modules.paper.store.paper_store.PaperDirectorySummaryStore.get_dir_nodes","title":"<code>labridge.func_modules.paper.store.paper_store.PaperDirectorySummaryStore.get_dir_nodes()</code>","text":"<p>get the valid directory summary nodes</p> Source code in <code>labridge\\func_modules\\paper\\store\\paper_store.py</code> <pre><code>def get_dir_nodes(self):\n\tr\"\"\" get the valid directory summary nodes \"\"\"\n\tdir_id_to_summary_id = self.directory_summary_index._index_struct.doc_id_to_summary_id\n\tdir_summary_nodes = []\n\tfor dir_id in dir_id_to_summary_id.keys():\n\t\tdir_path = self.root / dir_id\n\t\tif dir_path.exists():\n\t\t\tsummary_id = dir_id_to_summary_id[dir_id]\n\t\t\tsummary_node = self.directory_summary_index.docstore.get_node(summary_id)\n\t\t\tdir_summary_nodes.append(summary_node)\n\treturn dir_summary_nodes\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/paper_store/#labridge.func_modules.paper.store.paper_store.PaperDirectorySummaryStore.match_directory_for_new_paper","title":"<code>labridge.func_modules.paper.store.paper_store.PaperDirectorySummaryStore.match_directory_for_new_paper(pdf_path, possessor, paper_summary=None, verbose=False)</code>","text":"<p>select the most relevant (and deepest) directory for the new paper.</p> PARAMETER DESCRIPTION <code>pdf_path</code> <p>the path of the new paper.</p> <p> TYPE: <code>str</code> </p> <code>possessor</code> <p>the possessor of this new paper.</p> <p> TYPE: <code>str</code> </p> <code>paper_summary</code> <p>the summary of the new paper.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>verbose</code> <p>whether to show progress.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>Union[str, None]</code> <p>Union[str, None]: The matched directory for the new paper. If no proper directory found, return None.</p> Source code in <code>labridge\\func_modules\\paper\\store\\paper_store.py</code> <pre><code>def match_directory_for_new_paper(\n\tself,\n\tpdf_path: str,\n\tpossessor: str,\n\tpaper_summary: str = None,\n\tverbose: bool=False,\n) -&gt; Union[str, None]:\n\tr\"\"\"\n\tselect the most relevant (and deepest) directory for the new paper.\n\n\tArgs:\n\t\tpdf_path (str): the path of the new paper.\n\t\tpossessor (str): the possessor of this new paper.\n\t\tpaper_summary (str): the summary of the new paper.\n\t\tverbose (bool): whether to show progress.\n\n\tReturns:\n\t\tUnion[str, None]:\n\t\t\tThe matched directory for the new paper. If no proper directory found, return None.\n\t\"\"\"\n\tpdf_path = Path(pdf_path)\n\tif pdf_path.suffix != \".pdf\":\n\t\traise ValueError(\"Only papers with PDF format are supported now.\")\n\tpossessor_dir = Path(self.paper_root) / possessor\n\tif not possessor_dir.exists():\n\t\traise ValueError(f\"The member {possessor} do not exist. Please sign up as a member first.\")\n\n\tif paper_summary is None:\n\t\tpdf_docs = PyMuPDFReader().load_data(file_path=pdf_path)\n\t\t# typically, the first page includes conclusive information of a paper.\n\t\tpaper_summary = pdf_docs[0].text\n\n\tdir_summary_nodes = self.get_dir_nodes()\n\n\tselected_nodes = []\n\tselected_relevances = []\n\n\tfor idx in range(0, len(dir_summary_nodes), self.dir_choice_batch_size):\n\t\tsummary_nodes = dir_summary_nodes[idx: idx + self.dir_choice_batch_size]\n\t\tdir_context_str = default_format_node_batch_fn(summary_nodes=summary_nodes)\n\n\t\traw_response = self.llm.predict(\n\t\t\tDIR_CHOICE_SELECT_PROMPT,\n\t\t\tdir_context_str=dir_context_str,\n\t\t\tpaper_str=paper_summary,\n\t\t)\n\t\traw_choices, relevances = default_parse_choice_select_answer_fn(raw_response, len(summary_nodes))\n\t\tchoice_idxs = [choice - 1 for choice in raw_choices]\n\t\tchoice_summary_nodes = [summary_nodes[ci] for ci in choice_idxs]\n\t\tselected_nodes.extend(choice_summary_nodes)\n\t\tselected_relevances.extend(relevances)\n\n\tif len(selected_nodes) == 0:\n\t\treturn None\n\n\tzipped_list = list(zip(selected_nodes, selected_relevances))\n\tsorted_list = sorted(zipped_list, key=lambda x: x[1], reverse=True)\n\t# choose the most relevant and the deepest directory.\n\tbest_dir = sorted_list[0][0].ref_doc_id\n\n\tif verbose:\n\t\tfor node, relevance in sorted_list:\n\t\t\tprint_text(f\"&gt;&gt;&gt; dir: {node.ref_doc_id}, relevance: {relevance}\", color=\"blue\", end=\"\\n\")\n\tdef sub_dir_nodes(paper_dir: str):\n\t\tsub_nodes_with_score = []\n\t\tfor node, score in sorted_list:\n\t\t\tif Path(paper_dir) in Path(node.ref_doc_id).parents:\n\t\t\t\tsub_nodes_with_score.append((node, score))\n\t\treturn sub_nodes_with_score\n\n\tsub_list = sub_dir_nodes(best_dir)\n\twhile len(sub_list) &gt; 0:\n\t\tsub_list = sorted(sub_list, key=lambda x: x[1], reverse=True)\n\t\tbest_dir = sub_list[0][0].ref_doc_id\n\t\tsub_list = sub_dir_nodes(best_dir)\n\treturn best_dir\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/paper_store/#labridge.func_modules.paper.store.paper_store.PaperDirectorySummaryStore.set_possessor_research_categories","title":"<code>labridge.func_modules.paper.store.paper_store.PaperDirectorySummaryStore.set_possessor_research_categories(possessor_category_dict)</code>","text":"<p>Set the research categories of the possessors, this research categories is used to recommend proper new papers to the possessors.</p> PARAMETER DESCRIPTION <code>possessor_category_dict</code> <p>the research categories to be set. It is a dictionary with:</p> <ul> <li>key: possessor</li> <li>value: the list of research categories. For details about research categories, refer to the class <code>ArxivCategory</code>.</li> </ul> <p> TYPE: <code>Dict[str, List[str]]</code> </p> Source code in <code>labridge\\func_modules\\paper\\store\\paper_store.py</code> <pre><code>def set_possessor_research_categories(self, possessor_category_dict: Dict[str, List[str]]):\n\tr\"\"\"\n\tSet the research categories of the possessors, this research categories is used to recommend proper new papers\n\tto the possessors.\n\n\tArgs:\n\t\tpossessor_category_dict (Dict[str, List[str]]): the research categories to be set.\n\t\t\tIt is a dictionary with:\n\n\t\t\t- key: possessor\n\t\t\t- value: the list of research categories. For details about research categories,\n\t\t\trefer to the class `ArxivCategory`.\n\t\"\"\"\n\tfor possessor in possessor_category_dict.keys():\n\t\tdir_id = str((Path(self.paper_root) / possessor).relative_to(self.root))\n\t\tself._set_dir_metadata(\n\t\t\tdir_id=dir_id,\n\t\t\tkey=DIR_CATEGORY_NAME,\n\t\t\tval=possessor_category_dict[possessor],\n\t\t)\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/paper_store/#labridge.func_modules.paper.store.paper_store.PaperDirectorySummaryStore.update","title":"<code>labridge.func_modules.paper.store.paper_store.PaperDirectorySummaryStore.update(dir_description_dict)</code>","text":"<p>Update the relevant research fields of each directory. Typically used for manually set each directory's relevant research fields.</p> PARAMETER DESCRIPTION <code>dir_description_dict</code> <p>the descriptions of the paper directories - key: the directory path relative to root; - value: the relevant research fields of the directory.</p> <p> TYPE: <code>Dict[str, str]</code> </p> Source code in <code>labridge\\func_modules\\paper\\store\\paper_store.py</code> <pre><code>def update(self, dir_description_dict: Dict[str, str]):\n\tr\"\"\"\n\tUpdate the relevant research fields of each directory.\n\tTypically used for manually set each directory's relevant research fields.\n\n\tArgs:\n\t\tdir_description_dict (Dict[str, str]): the descriptions of the paper directories\n\t\t\t- key: the directory path relative to root;\n\t\t\t- value: the relevant research fields of the directory.\n\t\"\"\"\n\tfor dir_id in dir_description_dict.keys():\n\t\tself._set_dir_metadata(\n\t\t\tdir_id=dir_id,\n\t\t\tkey=PAPER_LEVEL_KEYWORDS,\n\t\t\tval=dir_description_dict[dir_id],\n\t\t)\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/paper_store/#labridge.func_modules.paper.store.paper_store.PaperStorage","title":"<code>labridge.func_modules.paper.store.paper_store.PaperStorage</code>","text":"<p>               Bases: <code>object</code></p> <p>Store the papers in vector index and summary index. The vector index stores the text chunks of the main text (and methods) and their embeddings. The summary index stores the summaries of the papers. Note that they can not share the storage context.</p> PARAMETER DESCRIPTION <code>docs</code> <p>the Documents to be stored.</p> <p> TYPE: <code>List[Document]</code> DEFAULT: <code>None</code> </p> <code>extra_docs</code> <p>extra Documents (like References), they are stored in the docstore of the index.</p> <p> TYPE: <code>List[Document]</code> DEFAULT: <code>None</code> </p> <code>vector_index</code> <p>existing vector index.</p> <p> TYPE: <code>VectorStoreIndex</code> DEFAULT: <code>None</code> </p> <code>vector_persist_dir</code> <p>the store directory of the vector index.</p> <p> TYPE: <code>Union[str, PathLike]</code> DEFAULT: <code>None</code> </p> <code>vector_transformations</code> <p>the transformations used in the construction of the vector index.</p> <p> TYPE: <code>List[TransformComponent]</code> DEFAULT: <code>None</code> </p> <code>paper_summary_index</code> <p>existing summary index.</p> <p> TYPE: <code>DocumentSummaryIndex</code> DEFAULT: <code>None</code> </p> <code>paper_summary_persist_dir</code> <p>the store directory of the summary index.</p> <p> TYPE: <code>Union[str, PathLike]</code> DEFAULT: <code>None</code> </p> <code>paper_summary_query</code> <p>the query used in summarizing the papers.</p> <p> TYPE: <code>str</code> DEFAULT: <code>PAPER_SUMMARIZE_QUERY</code> </p> <code>summary_transformations</code> <p>the transformations used in the construction of the summary index.</p> <p> TYPE: <code>List[TransformComponent]</code> DEFAULT: <code>None</code> </p> <code>summary_synthesizer</code> <p>the synthesizer used in summarizing the papers.</p> <p> TYPE: <code>PaperBatchSummarize</code> DEFAULT: <code>None</code> </p> <code>vector_storage_context</code> <p>the storage context of the vector index.</p> <p> TYPE: <code>StorageContext</code> DEFAULT: <code>None</code> </p> <code>paper_summary_storage_context</code> <p>the storage context of the summary index.</p> <p> TYPE: <code>StorageContext</code> DEFAULT: <code>None</code> </p> <code>service_context</code> <p>the service context.</p> <p> TYPE: <code>ServiceContext</code> DEFAULT: <code>None</code> </p> Source code in <code>labridge\\func_modules\\paper\\store\\paper_store.py</code> <pre><code>class PaperStorage(object):\n\tr\"\"\"\n\tStore the papers in vector index and summary index.\n\tThe vector index stores the text chunks of the main text (and methods) and their embeddings.\n\tThe summary index stores the summaries of the papers.\n\tNote that they can not share the storage context.\n\n\tArgs:\n\t\tdocs (List[Document]): the Documents to be stored.\n\t\textra_docs (List[Document]): extra Documents (like References),\n\t\t\tthey are stored in the docstore of the index.\n\t\tvector_index (VectorStoreIndex): existing vector index.\n\t\tvector_persist_dir (Union[str, os.PathLike]): the store directory of the vector index.\n\t\tvector_transformations (List[TransformComponent]): the transformations used in the construction of the vector index.\n\t\tpaper_summary_index (DocumentSummaryIndex): existing summary index.\n\t\tpaper_summary_persist_dir (Union[str, os.PathLike]): the store directory of the summary index.\n\t\tpaper_summary_query (str): the query used in summarizing the papers.\n\t\tsummary_transformations (List[TransformComponent]): the transformations used in the construction of the summary index.\n\t\tsummary_synthesizer (PaperBatchSummarize): the synthesizer used in summarizing the papers.\n\t\tvector_storage_context (StorageContext): the storage context of the vector index.\n\t\tpaper_summary_storage_context (StorageContext): the storage context of the summary index.\n\t\tservice_context (ServiceContext): the service context.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tdocs: Optional[List[Document]] = None,\n\t\textra_docs: Optional[List[Document]] = None,\n\t\tvector_index: Optional[VectorStoreIndex] = None,\n\t\tvector_persist_dir: Union[str, os.PathLike] = None,\n\t\tvector_transformations: List[TransformComponent] = None,\n\t\tpaper_summary_index: Optional[DocumentSummaryIndex] = None,\n\t\tpaper_summary_persist_dir: Union[str, os.PathLike] = None,\n\t\tpaper_summary_query: str = PAPER_SUMMARIZE_QUERY,\n\t\tsummary_transformations: List[TransformComponent] = None,\n\t\tsummary_synthesizer: Optional[PaperBatchSummarize] = None,\n\t\tvector_storage_context: Optional[StorageContext] = None,\n\t\tpaper_summary_storage_context: Optional[StorageContext] = None,\n\t\tservice_context: Optional[ServiceContext] = None,\n\t):\n\t\troot = Path(__file__)\n\t\tfor i in range(5):\n\t\t\troot = root.parent\n\t\tself.root = root\n\t\tself.llm = llm_from_settings_or_context(Settings, service_context)\n\t\tself.embed_model = embed_model_from_settings_or_context(Settings, service_context)\n\t\tself.service_context = service_context\n\t\tself.vector_persist_dir = vector_persist_dir or self._default_vector_persist_dir()\n\t\tself.paper_summary_persist_dir = paper_summary_persist_dir or self._default_paper_summary_persist_dir()\n\t\tself.vector_transformations = vector_transformations or self._default_vector_transformations()\n\t\tself.summary_transformations = summary_transformations or self._default_summary_transformations()\n\t\tself.summary_synthesizer = summary_synthesizer\n\t\tself.paper_summary_query = paper_summary_query\n\t\tif summary_synthesizer is None:\n\t\t\tself.summary_synthesizer = PaperBatchSummarize(llm=self.llm, max_tokens=8000, overlap_chunk_num=1)\n\n\t\tif (vector_index is None or paper_summary_index is None) and (docs is None or extra_docs is None):\n\t\t\traise ValueError(\"Please provide (docs, extra_docs) or existed (vector_index, summary_index).\")\n\t\tif None not in (vector_index, paper_summary_index):\n\t\t\tassert vector_index.storage_context != paper_summary_index.storage_context\n\t\t\tself.vector_index, self.paper_summary_index = vector_index, paper_summary_index\n\t\t\tself.paper_summary_index._response_synthesizer = self.summary_synthesizer\n\t\t\tself.vector_storage_context = vector_index.storage_context\n\t\t\tself.paper_summary_storage_context = paper_summary_index.storage_context\n\t\telse:\n\t\t\tself.vector_storage_context = vector_storage_context or StorageContext.from_defaults()\n\t\t\tself.paper_summary_storage_context = paper_summary_storage_context or StorageContext.from_defaults()\n\t\t\tself.build_index_from_docs(docs=docs, extra_docs=extra_docs)\n\n\tdef _default_vector_persist_dir(self) -&gt; str:\n\t\treturn str(self.root / DEFAULT_PAPER_VECTOR_PERSIST_DIR)\n\n\tdef _default_paper_summary_persist_dir(self) -&gt; str:\n\t\treturn str(self.root / DEFAULT_PAPER_SUMMARY_PERSIST_DIR)\n\n\tdef _default_vector_transformations(self) -&gt; List[TransformComponent]:\n\t\treturn [SentenceSplitter(chunk_size=1024, chunk_overlap=256, include_metadata=True), ]\n\n\tdef _default_summary_transformations(self) -&gt; List[TransformComponent]:\n\t\treturn [SentenceSplitter(chunk_size=1024, chunk_overlap=256, include_metadata=True), ]\n\n\tdef build_vector_index_from_docs(self, docs: List[Document]) -&gt; VectorStoreIndex:\n\t\tr\"\"\"\n\t\tBuild a vector database from the paper docs.\n\n\t\tArgs:\n\t\t\tdocs (List[Document]): The paper Documents.\n\n\t\tReturns:\n\t\t\tVectorStoreIndex\n\t\t\"\"\"\n\t\tif not self._are_valid_docs(docs):\n\t\t\traise ValueError(f\"Doc not in paper warehouse.\")\n\t\tvector_index = VectorStoreIndex.from_documents(documents=docs,\n\t\t\t\t\t\t\t\t\t\t\t\t\t   storage_context=self.vector_storage_context,\n\t\t\t\t\t\t\t\t\t\t\t\t\t   show_progress=True,\n\t\t\t\t\t\t\t\t\t\t\t\t\t   transformations=self.vector_transformations,\n\t\t\t\t\t\t\t\t\t\t\t\t\t   service_context=self.service_context)\n\t\tvector_index.set_index_id(PAPER_VECTOR_INDEX_ID)\n\t\treturn vector_index\n\n\tdef build_paper_summary_index_from_docs(self, docs: List[Document]) -&gt; DocumentSummaryIndex:\n\t\tr\"\"\"\n\t\tBuild a summary vector database from the paper docs.\n\n\t\tArgs:\n\t\t\tdocs (List[Document]): The paper Documents.\n\n\t\tReturns:\n\t\t\tDocumentSummaryIndex\n\t\t\"\"\"\n\t\tif not self._are_valid_docs(docs):\n\t\t\traise ValueError(f\"Doc not in paper warehouse.\")\n\t\tpaper_summary_index = DocumentSummaryIndex.from_documents(\n\t\t\tdocuments=docs,\n\t\t\tstorage_context=self.paper_summary_storage_context,\n\t\t\tshow_progress=True,\n\t\t\ttransformations=self.summary_transformations,\n\t\t\tsummary_query = self.paper_summary_query,\n\t\t\tservice_context=self.service_context,\n\t\t\tresponse_synthesizer = self.summary_synthesizer,\n\t\t)\n\t\tpaper_summary_index.set_index_id(PAPER_SUMMARY_INDEX_ID)\n\t\treturn paper_summary_index\n\n\tdef build_index_from_docs(\n\t\tself,\n\t\tdocs: List[Document],\n\t\textra_docs: List[Document],\n\t):\n\t\tif not self._are_valid_docs(docs + extra_docs):\n\t\t\traise ValueError(f\"Doc not in paper warehouse.\")\n\n\t\tself.vector_index = self.build_vector_index_from_docs(docs=docs[:1])\n\t\tself.paper_summary_index = self.build_paper_summary_index_from_docs(docs=docs[:1])\n\t\tself.persist()\n\t\tself.insert(paper_docs=docs[1:], extra_docs=extra_docs)\n\t\t# vector_index = self.build_vector_index_from_docs(docs)\n\t\t# paper_summary_index = self.build_paper_summary_index_from_docs(docs)\n\t\t# vector_index.docstore.add_documents(extra_docs)\n\t\t# paper_summary_index.docstore.add_documents(extra_docs)\n\t\t# return vector_index, paper_summary_index\n\n\t@classmethod\n\tdef from_storage(\n\t\tcls,\n\t\tvector_persist_dir: str,\n\t\tpaper_summary_persist_dir: str,\n\t\tvector_transformations: List[TransformComponent] = None,\n\t\tpaper_summary_query: str = PAPER_SUMMARIZE_QUERY,\n\t\tsummary_transformations: List[TransformComponent] = None,\n\t\tsummary_synthesizer: Optional[BaseSynthesizer] = None,\n\t\tservice_context: Optional[ServiceContext] = None,\n\t):\n\t\tr\"\"\" Load from an existing storage. \"\"\"\n\t\troot = Path(__file__)\n\t\tfor i in range(5):\n\t\t\troot = root.parent\n\n\t\tvector_persist_dir = vector_persist_dir or str(root / DEFAULT_PAPER_VECTOR_PERSIST_DIR)\n\t\tpaper_summary_persist_dir = paper_summary_persist_dir or str(root / DEFAULT_PAPER_SUMMARY_PERSIST_DIR)\n\t\tvector_storage_context = StorageContext.from_defaults(persist_dir=vector_persist_dir)\n\t\tpaper_summary_storage_context = StorageContext.from_defaults(persist_dir=paper_summary_persist_dir)\n\n\t\tvector_index = load_index_from_storage(\n\t\t\tstorage_context=vector_storage_context,\n\t\t\tindex_id=PAPER_VECTOR_INDEX_ID,\n\t\t\tservice_context=service_context,\n\t\t)\n\t\tpaper_summary_index = load_index_from_storage(\n\t\t\tstorage_context=paper_summary_storage_context,\n\t\t\tindex_id=PAPER_SUMMARY_INDEX_ID,\n\t\t\tservice_context=service_context,\n\t\t)\n\n\t\treturn cls(\n\t\t\tvector_index=vector_index,\n\t\t\tpaper_summary_index=paper_summary_index,\n\t\t\tvector_transformations=vector_transformations,\n\t\t\tvector_persist_dir=vector_persist_dir,\n\t\t\tpaper_summary_persist_dir=paper_summary_persist_dir,\n\t\t\tpaper_summary_query=paper_summary_query,\n\t\t\tsummary_transformations=summary_transformations,\n\t\t\tsummary_synthesizer=summary_synthesizer,\n\t\t\tservice_context=service_context,\n\t\t)\n\n\tdef _is_valid_doc(self, doc: Document) -&gt; bool:\n\t\tr\"\"\" Judge whether the paper doc is from the paper warehouse. \"\"\"\n\t\tdoc_id = doc.doc_id\n\t\tif CONTENT_TYPE_NAME not in doc.metadata.keys():\n\t\t\treturn False\n\t\tdoc_type = doc.metadata[CONTENT_TYPE_NAME]\n\t\trel_path = doc_id.split(f'_{doc_type}')[0]\n\t\tdoc_path = self.root / rel_path\n\t\treturn doc_path.exists()\n\n\tdef _are_valid_docs(self, docs: List[Document]) -&gt; bool:\n\t\tfor doc in docs:\n\t\t\tif not self._is_valid_doc(doc):\n\t\t\t\tprint(f\"Invalid doc. Doc {doc.doc_id} is not in paper warehouse.\")\n\t\t\t\treturn False\n\t\treturn True\n\n\tdef insert(self, paper_docs: List[Document], extra_docs: List[Document]):\n\t\tr\"\"\"\n\t\tAdd new papers to index.\n\t\tAssert all new papers are already categorized (that is: they are from the organized paper warehouse.)\n\n\t\tEncourage you to build a storage with one paper first, then use `insert` methods to add other papers,\n\t\tbecause we can control the summarize query depending on each doc's type.\n\n\t\tArgs:\n\t\t\tpaper_docs (List[Document]): these docs will be summarized; chunked and vectorized.\n\t\t\textra_docs (List[Document]): these docs are stored in docstore.\n\t\t\"\"\"\n\t\tif not self._are_valid_docs(paper_docs + extra_docs):\n\t\t\traise ValueError(f\"Doc not in paper warehouse.\")\n\n\t\tfor doc in paper_docs:\n\t\t\tdoc_type = doc.metadata[CONTENT_TYPE_NAME]\n\t\t\tif doc_type not in SummarizeQueries.keys():\n\t\t\t\traise ValueError(f'Invalid paper doc type: {doc_type}. Acceptable: {list(SummarizeQueries.keys())}.')\n\t\t\tsum_query = SummarizeQueries[doc_type]\n\t\t\tself.paper_summary_index._response_synthesizer._summary_query = sum_query\n\n\t\t\tif doc.doc_id not in self.paper_summary_index.docstore.get_all_ref_doc_info().keys():\n\t\t\t\tself.paper_summary_index.insert(document=doc)\n\t\t\tif doc.doc_id not in self.vector_index.docstore.get_all_ref_doc_info().keys():\n\t\t\t\tself.vector_index.insert(document=doc)\n\n\t\tself.vector_index.docstore.add_documents(extra_docs)\n\t\tself.paper_summary_index.docstore.add_documents(extra_docs)\n\t\tself.persist()\n\n\tdef persist(self,\n\t\t\t\tvector_persist_dir: Union[str, os.PathLike] = None,\n\t\t\t\tpaper_summary_persist_dir: Union[str, os.PathLike] = None):\n\t\tr\"\"\" Persist to the disk. \"\"\"\n\t\tif vector_persist_dir is None:\n\t\t\tvector_persist_dir = self.vector_persist_dir\n\t\tif paper_summary_persist_dir is None:\n\t\t\tpaper_summary_persist_dir = self.paper_summary_persist_dir\n\t\tself.vector_storage_context.persist(vector_persist_dir)\n\t\tself.paper_summary_storage_context.persist(paper_summary_persist_dir)\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/paper_store/#labridge.func_modules.paper.store.paper_store.PaperStorage.build_paper_summary_index_from_docs","title":"<code>labridge.func_modules.paper.store.paper_store.PaperStorage.build_paper_summary_index_from_docs(docs)</code>","text":"<p>Build a summary vector database from the paper docs.</p> PARAMETER DESCRIPTION <code>docs</code> <p>The paper Documents.</p> <p> TYPE: <code>List[Document]</code> </p> RETURNS DESCRIPTION <code>DocumentSummaryIndex</code> <p>DocumentSummaryIndex</p> Source code in <code>labridge\\func_modules\\paper\\store\\paper_store.py</code> <pre><code>def build_paper_summary_index_from_docs(self, docs: List[Document]) -&gt; DocumentSummaryIndex:\n\tr\"\"\"\n\tBuild a summary vector database from the paper docs.\n\n\tArgs:\n\t\tdocs (List[Document]): The paper Documents.\n\n\tReturns:\n\t\tDocumentSummaryIndex\n\t\"\"\"\n\tif not self._are_valid_docs(docs):\n\t\traise ValueError(f\"Doc not in paper warehouse.\")\n\tpaper_summary_index = DocumentSummaryIndex.from_documents(\n\t\tdocuments=docs,\n\t\tstorage_context=self.paper_summary_storage_context,\n\t\tshow_progress=True,\n\t\ttransformations=self.summary_transformations,\n\t\tsummary_query = self.paper_summary_query,\n\t\tservice_context=self.service_context,\n\t\tresponse_synthesizer = self.summary_synthesizer,\n\t)\n\tpaper_summary_index.set_index_id(PAPER_SUMMARY_INDEX_ID)\n\treturn paper_summary_index\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/paper_store/#labridge.func_modules.paper.store.paper_store.PaperStorage.build_vector_index_from_docs","title":"<code>labridge.func_modules.paper.store.paper_store.PaperStorage.build_vector_index_from_docs(docs)</code>","text":"<p>Build a vector database from the paper docs.</p> PARAMETER DESCRIPTION <code>docs</code> <p>The paper Documents.</p> <p> TYPE: <code>List[Document]</code> </p> RETURNS DESCRIPTION <code>VectorStoreIndex</code> <p>VectorStoreIndex</p> Source code in <code>labridge\\func_modules\\paper\\store\\paper_store.py</code> <pre><code>def build_vector_index_from_docs(self, docs: List[Document]) -&gt; VectorStoreIndex:\n\tr\"\"\"\n\tBuild a vector database from the paper docs.\n\n\tArgs:\n\t\tdocs (List[Document]): The paper Documents.\n\n\tReturns:\n\t\tVectorStoreIndex\n\t\"\"\"\n\tif not self._are_valid_docs(docs):\n\t\traise ValueError(f\"Doc not in paper warehouse.\")\n\tvector_index = VectorStoreIndex.from_documents(documents=docs,\n\t\t\t\t\t\t\t\t\t\t\t\t   storage_context=self.vector_storage_context,\n\t\t\t\t\t\t\t\t\t\t\t\t   show_progress=True,\n\t\t\t\t\t\t\t\t\t\t\t\t   transformations=self.vector_transformations,\n\t\t\t\t\t\t\t\t\t\t\t\t   service_context=self.service_context)\n\tvector_index.set_index_id(PAPER_VECTOR_INDEX_ID)\n\treturn vector_index\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/paper_store/#labridge.func_modules.paper.store.paper_store.PaperStorage.from_storage","title":"<code>labridge.func_modules.paper.store.paper_store.PaperStorage.from_storage(vector_persist_dir, paper_summary_persist_dir, vector_transformations=None, paper_summary_query=PAPER_SUMMARIZE_QUERY, summary_transformations=None, summary_synthesizer=None, service_context=None)</code>  <code>classmethod</code>","text":"<p>Load from an existing storage.</p> Source code in <code>labridge\\func_modules\\paper\\store\\paper_store.py</code> <pre><code>@classmethod\ndef from_storage(\n\tcls,\n\tvector_persist_dir: str,\n\tpaper_summary_persist_dir: str,\n\tvector_transformations: List[TransformComponent] = None,\n\tpaper_summary_query: str = PAPER_SUMMARIZE_QUERY,\n\tsummary_transformations: List[TransformComponent] = None,\n\tsummary_synthesizer: Optional[BaseSynthesizer] = None,\n\tservice_context: Optional[ServiceContext] = None,\n):\n\tr\"\"\" Load from an existing storage. \"\"\"\n\troot = Path(__file__)\n\tfor i in range(5):\n\t\troot = root.parent\n\n\tvector_persist_dir = vector_persist_dir or str(root / DEFAULT_PAPER_VECTOR_PERSIST_DIR)\n\tpaper_summary_persist_dir = paper_summary_persist_dir or str(root / DEFAULT_PAPER_SUMMARY_PERSIST_DIR)\n\tvector_storage_context = StorageContext.from_defaults(persist_dir=vector_persist_dir)\n\tpaper_summary_storage_context = StorageContext.from_defaults(persist_dir=paper_summary_persist_dir)\n\n\tvector_index = load_index_from_storage(\n\t\tstorage_context=vector_storage_context,\n\t\tindex_id=PAPER_VECTOR_INDEX_ID,\n\t\tservice_context=service_context,\n\t)\n\tpaper_summary_index = load_index_from_storage(\n\t\tstorage_context=paper_summary_storage_context,\n\t\tindex_id=PAPER_SUMMARY_INDEX_ID,\n\t\tservice_context=service_context,\n\t)\n\n\treturn cls(\n\t\tvector_index=vector_index,\n\t\tpaper_summary_index=paper_summary_index,\n\t\tvector_transformations=vector_transformations,\n\t\tvector_persist_dir=vector_persist_dir,\n\t\tpaper_summary_persist_dir=paper_summary_persist_dir,\n\t\tpaper_summary_query=paper_summary_query,\n\t\tsummary_transformations=summary_transformations,\n\t\tsummary_synthesizer=summary_synthesizer,\n\t\tservice_context=service_context,\n\t)\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/paper_store/#labridge.func_modules.paper.store.paper_store.PaperStorage.insert","title":"<code>labridge.func_modules.paper.store.paper_store.PaperStorage.insert(paper_docs, extra_docs)</code>","text":"<p>Add new papers to index. Assert all new papers are already categorized (that is: they are from the organized paper warehouse.)</p> <p>Encourage you to build a storage with one paper first, then use <code>insert</code> methods to add other papers, because we can control the summarize query depending on each doc's type.</p> PARAMETER DESCRIPTION <code>paper_docs</code> <p>these docs will be summarized; chunked and vectorized.</p> <p> TYPE: <code>List[Document]</code> </p> <code>extra_docs</code> <p>these docs are stored in docstore.</p> <p> TYPE: <code>List[Document]</code> </p> Source code in <code>labridge\\func_modules\\paper\\store\\paper_store.py</code> <pre><code>def insert(self, paper_docs: List[Document], extra_docs: List[Document]):\n\tr\"\"\"\n\tAdd new papers to index.\n\tAssert all new papers are already categorized (that is: they are from the organized paper warehouse.)\n\n\tEncourage you to build a storage with one paper first, then use `insert` methods to add other papers,\n\tbecause we can control the summarize query depending on each doc's type.\n\n\tArgs:\n\t\tpaper_docs (List[Document]): these docs will be summarized; chunked and vectorized.\n\t\textra_docs (List[Document]): these docs are stored in docstore.\n\t\"\"\"\n\tif not self._are_valid_docs(paper_docs + extra_docs):\n\t\traise ValueError(f\"Doc not in paper warehouse.\")\n\n\tfor doc in paper_docs:\n\t\tdoc_type = doc.metadata[CONTENT_TYPE_NAME]\n\t\tif doc_type not in SummarizeQueries.keys():\n\t\t\traise ValueError(f'Invalid paper doc type: {doc_type}. Acceptable: {list(SummarizeQueries.keys())}.')\n\t\tsum_query = SummarizeQueries[doc_type]\n\t\tself.paper_summary_index._response_synthesizer._summary_query = sum_query\n\n\t\tif doc.doc_id not in self.paper_summary_index.docstore.get_all_ref_doc_info().keys():\n\t\t\tself.paper_summary_index.insert(document=doc)\n\t\tif doc.doc_id not in self.vector_index.docstore.get_all_ref_doc_info().keys():\n\t\t\tself.vector_index.insert(document=doc)\n\n\tself.vector_index.docstore.add_documents(extra_docs)\n\tself.paper_summary_index.docstore.add_documents(extra_docs)\n\tself.persist()\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/paper_store/#labridge.func_modules.paper.store.paper_store.PaperStorage.persist","title":"<code>labridge.func_modules.paper.store.paper_store.PaperStorage.persist(vector_persist_dir=None, paper_summary_persist_dir=None)</code>","text":"<p>Persist to the disk.</p> Source code in <code>labridge\\func_modules\\paper\\store\\paper_store.py</code> <pre><code>def persist(self,\n\t\t\tvector_persist_dir: Union[str, os.PathLike] = None,\n\t\t\tpaper_summary_persist_dir: Union[str, os.PathLike] = None):\n\tr\"\"\" Persist to the disk. \"\"\"\n\tif vector_persist_dir is None:\n\t\tvector_persist_dir = self.vector_persist_dir\n\tif paper_summary_persist_dir is None:\n\t\tpaper_summary_persist_dir = self.paper_summary_persist_dir\n\tself.vector_storage_context.persist(vector_persist_dir)\n\tself.paper_summary_storage_context.persist(paper_summary_persist_dir)\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/shared_paper_store/","title":"Shared paper store","text":""},{"location":"code_docs/func_modules/paper/store/shared_paper_store/#labridge.func_modules.paper.store.shared_paper_store","title":"<code>labridge.func_modules.paper.store.shared_paper_store</code>","text":"<p>Shared paper storage.</p> <p>A Tree-type storage.</p> <p>With members as the first child nodes. (Member Node type)</p> <p>Then recursive DIR nodes, corresponding to the warehouse's dir. (DIR node type)</p> <p>The leaf nodes: paper node. (include summary, abstraction, metadata, Title, ref_filepath) (Paper node type)</p> <p>The child nodes of paper node: doc nodes. () (with overlap) (Doc node type)</p> <p>Another child nodes of paper node: doc nodes for note. (without overlap, more detailed.) (Note Doc node type).</p> <p>Notes: The note of the corresponding context. (Note node type.)</p>"},{"location":"code_docs/func_modules/paper/store/shared_paper_store/#labridge.func_modules.paper.store.shared_paper_store.MarkAsChunk","title":"<code>labridge.func_modules.paper.store.shared_paper_store.MarkAsChunk</code>","text":"<p>               Bases: <code>TransformComponent</code></p> <p>A TransformComponent to mark the node type of each node of the vector index as <code>chunk_node</code>.</p> Source code in <code>labridge\\func_modules\\paper\\store\\shared_paper_store.py</code> <pre><code>class MarkAsChunk(TransformComponent):\n\tr\"\"\"\n\tA TransformComponent to mark the node type of each node of the vector index as `chunk_node`.\n\t\"\"\"\n\n\tdef __call__(self, nodes: List[\"BaseNode\"], **kwargs: Any) -&gt; List[\"BaseNode\"]:\n\t\tfor node in nodes:\n\t\t\tnode.metadata[SHARED_PAPER_NODE_TYPE] = SharedPaperNodeType.PAPER_CHUNK\n\t\treturn nodes\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/shared_paper_store/#labridge.func_modules.paper.store.shared_paper_store.MarkAsChunkForNote","title":"<code>labridge.func_modules.paper.store.shared_paper_store.MarkAsChunkForNote</code>","text":"<p>               Bases: <code>TransformComponent</code></p> <p>A TransformComponent to mark the node type of each node of the notes vector index as <code>chunk_node</code>.</p> Source code in <code>labridge\\func_modules\\paper\\store\\shared_paper_store.py</code> <pre><code>class MarkAsChunkForNote(TransformComponent):\n\tr\"\"\"\n\tA TransformComponent to mark the node type of each node of the notes vector index as `chunk_node`.\n\t\"\"\"\n\n\tdef __call__(self, nodes: List[\"BaseNode\"], **kwargs: Any) -&gt; List[\"BaseNode\"]:\n\t\tfor node in nodes:\n\t\t\tnode.metadata[SHARED_PAPER_NODE_TYPE] = SharedPaperNoteNodeType.PAPER_CHUNK\n\t\treturn nodes\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/shared_paper_store/#labridge.func_modules.paper.store.shared_paper_store.SharedPaperStorage","title":"<code>labridge.func_modules.paper.store.shared_paper_store.SharedPaperStorage</code>","text":"<p>               Bases: <code>object</code></p> <p>This class is for storing shared papers and notes. Two vector databases are used for storage:</p> <ul> <li>Paper vector index: This vector database records the overlapped paper content chunks along with detailed metadata. This database is structured the same as the directory structure of the shared paper warehouse. For example:</li> </ul> <p><pre><code>                                                                                        root_node\n                                                /                               /                               \\                       \\\n                                        user_1                  user_2          ...             user_m          user_n\n                                /                       \\\n                        dir_1_1         ...     dir_1_k\n                        /                               /\n                dir_2_1         ...     Paper_1\n                /       \\                       /       \\\n        Paper_1 Paper_p Chunk_1 Chunk_l\n        /       \\\nChunk_1 Chunk_l\n</code></pre> - Notes vector index: This vector database non-overlapped content chunks of smaller size and corresponding user notes. Each paper uses its DOI as the sign. This database is structured as follows:</p> <pre><code>                                                                                        root_node\n                                        /                                       /                               \\                                       \\\n                                DOI_1                           DOI_2                           DOI_m                           DOI_n\n                        /                       \\                                                                                               /                       \\\n                Chunk_1                 Chunk_k                                                                         Chunk_1                 Chunk_k\n        /                       \\                                                                                                                               /                       \\\nNote_1                  Note_l                                                                                                          Note_1                  Note_l\n</code></pre> <p>The <code>PaperReader</code> is used to parse content and metadata from the paper pdf.</p> Note <p>the metadata <code>Title</code> and <code>DOI</code> is essential. The <code>Title</code> is extracted by LLM, and the <code>DOI</code> is obtained through</p> <p>CrossRef API according to the extracted <code>Title</code>. If any of the two fails in extraction, the paper recording fails.</p> PARAMETER DESCRIPTION <code>llm</code> <p>The used LLM</p> <p> TYPE: <code>LLM</code> </p> <code>vector_index</code> <p>The vector database for storing shared paper contents.</p> <p> TYPE: <code>VectorStoreIndex</code> </p> <code>notes_vector_index</code> <p>The vector database fot storing non-overlapped paper content chunks and their corresponding user notes.</p> <p> TYPE: <code>VectorStoreIndex</code> </p> <code>persist_dir</code> <p>The persist directory of the vector_index.</p> <p> TYPE: <code>str</code> </p> <code>notes_persist_dir</code> <p>The persist directory of the notes_vector_index.</p> <p> TYPE: <code>str</code> </p> Source code in <code>labridge\\func_modules\\paper\\store\\shared_paper_store.py</code> <pre><code>class SharedPaperStorage(object):\n\tr\"\"\"\n\tThis class is for storing shared papers and notes.\n\tTwo vector databases are used for storage:\n\n\t- Paper vector index: This vector database records the overlapped paper content chunks along with detailed metadata.\n\tThis database is structured the same as the directory structure of the shared paper warehouse. For example:\n\n\t```\n\t\t\t\t\t\t\t\t\t\t\t\troot_node\n\t\t\t\t\t\t\t/\t\t\t\t/\t\t\t\t\\\t\t\t\\\n\t\t\t\t\t\tuser_1\t\t\tuser_2\t\t...\t\tuser_m\t\tuser_n\n\t\t\t\t\t/\t\t\t\\\n\t\t\t\tdir_1_1\t\t...\tdir_1_k\n\t\t\t\t/\t\t\t\t/\n\t\t\tdir_2_1\t\t...\tPaper_1\n\t\t\t/\t\\\t\t\t/\t\\\n\t\tPaper_1\tPaper_p\tChunk_1\tChunk_l\n\t\t/\t\\\n\tChunk_1\tChunk_l\n\t```\n\t- Notes vector index: This vector database non-overlapped content chunks of smaller size and corresponding user notes.\n\tEach paper uses its DOI as the sign. This database is structured as follows:\n\n\t```\n\t\t\t\t\t\t\t\t\t\t\t\troot_node\n\t\t\t\t\t\t/\t\t\t\t\t/\t\t\t\t\\\t\t\t\t\t\\\n\t\t\t\t\tDOI_1\t\t\t\tDOI_2\t\t\t\tDOI_m\t\t\t\tDOI_n\n\t\t\t\t/\t\t\t\\\t\t\t\t\t\t\t\t\t\t\t\t/\t\t\t\\\n\t\t\tChunk_1\t\t\tChunk_k\t\t\t\t\t\t\t\t\t\tChunk_1\t\t\tChunk_k\n\t\t/\t\t\t\\\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t/\t\t\t\\\n\tNote_1\t\t\tNote_l\t\t\t\t\t\t\t\t\t\t\t\t\t\tNote_1\t\t\tNote_l\n\t```\n\n\tThe `PaperReader` is used to parse content and metadata from the paper pdf.\n\n\tNote:\n\t\tthe metadata `Title` and `DOI` is essential. The `Title` is extracted by LLM, and the `DOI` is obtained through\n\tCrossRef API according to the extracted `Title`. If any of the two fails in extraction, the paper recording fails.\n\n\tArgs:\n\t\tllm (LLM): The used LLM\n\t\tvector_index (VectorStoreIndex): The vector database for storing shared paper contents.\n\t\tnotes_vector_index (VectorStoreIndex): The vector database fot storing non-overlapped paper content chunks and\n\t\t\ttheir corresponding user notes.\n\t\tpersist_dir (str): The persist directory of the vector_index.\n\t\tnotes_persist_dir (str): The persist directory of the notes_vector_index.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tllm: LLM,\n\t\tvector_index: VectorStoreIndex,\n\t\tnotes_vector_index: VectorStoreIndex,\n\t\tpersist_dir: str,\n\t\tnotes_persist_dir: str,\n\t):\n\t\troot = Path(__file__)\n\t\tfor idx in range(5):\n\t\t\troot = root.parent\n\t\tself._root = root\n\t\tself.vector_index = vector_index\n\t\tself.vector_index.set_index_id(index_id=SHARED_PAPER_VECTOR_INDEX_ID)\n\t\tself.notes_vector_index = notes_vector_index\n\t\tself.notes_vector_index.set_index_id(index_id=SHARED_PAPER_NOTES_INDEX_ID)\n\t\tself.vector_index.set_index_id(SHARED_PAPER_VECTOR_INDEX_ID)\n\t\tself.persist_dir = persist_dir\n\t\tself.notes_persist_dir = notes_persist_dir\n\t\tself._fs = fsspec.filesystem(\"file\")\n\t\tself._account_manager = AccountManager()\n\t\tself.paper_reader = PaperReader(llm=llm)\n\t\tself._summarizer = PaperBatchSummarize(llm=llm)\n\n\t@classmethod\n\tdef from_storage(\n\t\tcls,\n\t\tpersist_dir: str,\n\t\tnotes_persist_dir: str,\n\t\tllm: LLM,\n\t\tembed_model: BaseEmbedding,\n\t):\n\t\tvector_storage_context = StorageContext.from_defaults(persist_dir=persist_dir)\n\t\tvector_index = load_index_from_storage(\n\t\t\tstorage_context=vector_storage_context,\n\t\t\tindex_id=SHARED_PAPER_VECTOR_INDEX_ID,\n\t\t\tembed_model=embed_model,\n\t\t)\n\t\tnotes_storage_context = StorageContext.from_defaults(persist_dir=notes_persist_dir)\n\t\tnotes_vector_index = load_index_from_storage(\n\t\t\tstorage_context=notes_storage_context,\n\t\t\tindex_id=SHARED_PAPER_NOTES_INDEX_ID,\n\t\t\tembed_model=embed_model,\n\t\t)\n\t\treturn cls(\n\t\t\tllm=llm,\n\t\t\tvector_index=vector_index,\n\t\t\tnotes_vector_index=notes_vector_index,\n\t\t\tpersist_dir=persist_dir,\n\t\t\tnotes_persist_dir=notes_persist_dir,\n\t\t)\n\n\t@classmethod\n\tdef from_default(\n\t\tcls,\n\t\tllm: LLM,\n\t\tembed_model: BaseEmbedding,\n\t):\n\t\troot = Path(__file__)\n\t\tfor idx in range(5):\n\t\t\troot = root.parent\n\n\t\tpersist_dir = str(root / SHARED_PAPER_VECTOR_INDEX_PERSIST_DIR)\n\t\tnotes_persist_dir = str(root / SHARED_PAPER_NOTES_INDEX_PERSIST_DIR)\n\t\tfs = fsspec.filesystem(\"file\")\n\t\tif fs.exists(persist_dir):\n\t\t\treturn cls.from_storage(\n\t\t\t\tpersist_dir=persist_dir,\n\t\t\t\tnotes_persist_dir=notes_persist_dir,\n\t\t\t\tllm=llm,\n\t\t\t\tembed_model=embed_model,\n\t\t\t)\n\n\t\troot_node = TextNode(\n\t\t\ttext=f\"Root node for the shared papers\",\n\t\t\tid_=SHARED_PAPER_ROOT_NODE_NAME,\n\t\t\tmetadata={\n\t\t\t\tSHARED_PAPER_NODE_TYPE: SharedPaperNodeType.ROOT,\n\t\t\t}\n\t\t)\n\t\tnodes = [root_node]\n\n\t\taccount_manager = AccountManager()\n\t\tusers = account_manager.get_users()\n\n\t\troot_children = []\n\t\tfor user_id in users:\n\t\t\tuser_node = TextNode(\n\t\t\t\ttext=f\"The papers belonging to the user {user_id}\",\n\t\t\t\tid_=user_id,\n\t\t\t\tmetadata={\n\t\t\t\t\tSHARED_PAPER_NODE_TYPE: SharedPaperNodeType.USER,\n\t\t\t\t}\n\t\t\t)\n\t\t\tnodes.append(user_node)\n\t\t\troot_children.append(RelatedNodeInfo(node_id=user_node.node_id))\n\t\t\tuser_node.relationships[NodeRelationship.PARENT] = RelatedNodeInfo(node_id=root_node.node_id)\n\n\t\troot_node.relationships[NodeRelationship.CHILD] = root_children\n\n\t\tvector_index = VectorStoreIndex(\n\t\t\tnodes=nodes,\n\t\t\tembed_model=embed_model,\n\t\t)\n\n\t\tnotes_root_node = TextNode(\n\t\t\ttext=\"Root node for the paper notes.\",\n\t\t\tid_=SHARED_PAPER_ROOT_NODE_NAME,\n\t\t\tmetadata={\n\t\t\t\tSHARED_PAPER_NODE_TYPE: SharedPaperNoteNodeType.ROOT,\n\t\t\t}\n\t\t)\n\t\tnotes_vector_index = VectorStoreIndex(\n\t\t\tnodes=[notes_root_node],\n\t\t\tembed_model=embed_model,\n\t\t)\n\n\t\treturn cls(\n\t\t\tllm=llm,\n\t\t\tvector_index=vector_index,\n\t\t\tnotes_vector_index=notes_vector_index,\n\t\t\tpersist_dir=persist_dir,\n\t\t\tnotes_persist_dir=notes_persist_dir,\n\t\t)\n\n\t@property\n\tdef _default_overlapped_transformations(self):\n\t\tr\"\"\" Transformations for chunks in vector_index \"\"\"\n\t\treturn [SentenceSplitter(chunk_size=1024, chunk_overlap=256, include_metadata=True), MarkAsChunk()]\n\n\t@property\n\tdef _default_non_overlapped_transformations(self):\n\t\tr\"\"\" Transformation for chunks in notes_vector_index \"\"\"\n\t\treturn [SentenceSplitter(chunk_size=128, chunk_overlap=0, include_metadata=False), MarkAsChunkForNote()]\n\n\tdef _update_node(self, node_id: str, node: BaseNode):\n\t\tr\"\"\" Update a node in the vector_index, if the node with `node_id` does not exist, create one. \"\"\"\n\t\ttry:\n\t\t\tself.vector_index.delete_nodes([node_id])\n\t\texcept:\n\t\t\tpass\n\t\tself.vector_index.insert_nodes([node])\n\n\tdef _update_note_index_node(self, node_id: str, node: BaseNode):\n\t\tr\"\"\" Update a node in the notes_vector_index, if the node with `node_id` does not exist, create one. \"\"\"\n\t\ttry:\n\t\t\tself.notes_vector_index.delete_nodes([node_id])\n\t\texcept:\n\t\t\tpass\n\t\tself.notes_vector_index.insert_nodes([node])\n\n\tdef _get_node(self, node_id: str) -&gt; Optional[BaseNode]:\n\t\tr\"\"\" Get node from the vector_index. \"\"\"\n\t\ttry:\n\t\t\tnode = self.vector_index.docstore.get_node(node_id=node_id, raise_error=True)\n\t\t\treturn node\n\t\texcept ValueError:\n\t\t\treturn None\n\n\tdef _get_nodes(self, node_ids: List[str], node_types: List[str] = None) -&gt; List[BaseNode]:\n\t\tr\"\"\"\n\t\tGet nodes from the vector_index, with optional node type filters.\n\n\t\tArgs:\n\t\t\tnode_ids (List[str]): The ids of the nodes to be obtained.\n\t\t\tnode_types (List[str]): If given, only nodes with types in the given node_types will be selected.\n\n\t\tReturns:\n\t\t\tThe corresponding nodes.\n\t\t\"\"\"\n\t\tnodes = self.vector_index.docstore.get_nodes(node_ids=node_ids, raise_error=True)\n\t\tif node_types is not None:\n\t\t\tnodes = [n for n in nodes if n.metadata[SHARED_PAPER_NODE_TYPE] in node_types]\n\t\treturn nodes\n\n\tdef _get_notes_index_node(self, node_id: str) -&gt; Optional[BaseNode]:\n\t\tr\"\"\" Get node from the notes vector index. \"\"\"\n\t\ttry:\n\t\t\tnode = self.notes_vector_index.docstore.get_node(node_id=node_id, raise_error=True)\n\t\t\treturn node\n\t\texcept ValueError:\n\t\t\treturn None\n\n\tdef _new_dir_node(self, rel_dir_path: str) -&gt; TextNode:\n\t\tr\"\"\" Create a new DIR node in the vector_index. \"\"\"\n\t\tdir_node = TextNode(\n\t\t\ttext=f\"The directory of {rel_dir_path}\",\n\t\t\tid_=rel_dir_path,\n\t\t\tmetadata={\n\t\t\t\tSHARED_PAPER_NODE_TYPE: SharedPaperNodeType.DIR,\n\t\t\t}\n\t\t)\n\t\treturn dir_node\n\n\tdef _insert_as_child_nodes(self, node: BaseNode, child_nodes: List[BaseNode]):\n\t\tr\"\"\"\n\t\tSet the child_nodes of the given node, and set the node as the PARENT of each child node in the child_nodes.\n\n\t\tArgs:\n\t\t\tnode (BaseNode): The parent node.\n\t\t\tchild_nodes (List[BaseNode]): The child nodes.\n\n\t\tReturns:\n\t\t\tNone\n\t\t\"\"\"\n\t\tchildren = node.child_nodes or []\n\t\tfor child in child_nodes:\n\t\t\tchildren.append(\n\t\t\t\tRelatedNodeInfo(node_id=child.node_id)\n\t\t\t)\n\t\t\tchild.relationships[NodeRelationship.PARENT] = RelatedNodeInfo(\n\t\t\t\tnode_id=node.node_id\n\t\t\t)\n\t\tnode.relationships[NodeRelationship.CHILD] = children\n\n\tdef _new_paper_node(self, dir_node: BaseNode, paper_info: dict) -&gt; Tuple[BaseNode, BaseNode]:\n\t\tr\"\"\"\n\t\tCreate a paper node under the given dir_node. Use rel_path as node_id.\n\n\t\tArgs:\n\t\t\tdir_node (BaseNode): The dir_node indicating a specific directory in the paper warehouse.\n\t\t\tpaper_info (dict): The metadata of the info. `PAPER_REL_FILE_PATH` is necessary.\n\n\t\tReturns:\n\t\t\tThe updated dir_node and the created paper_node.\n\n\t\tRaises:\n\t\t\tValueError: If `PAPER_REL_FILE_PATH` is not given in the paper_info.\n\t\t\"\"\"\n\t\tpaper_rel_path = paper_info.get(PAPER_REL_FILE_PATH, None)\n\t\tif paper_rel_path is None:\n\t\t\traise ValueError(f\"Invalid paper metadata, the key: {PAPER_REL_FILE_PATH} is needed.\")\n\n\t\tmetadata = {\n\t\t\tSHARED_PAPER_NODE_TYPE: SharedPaperNodeType.PAPER,\n\t\t}\n\t\tmetadata.update(paper_info)\n\n\t\tpaper_node = TextNode(\n\t\t\ttext=\"\",\n\t\t\tid_=paper_rel_path,\n\t\t\tmetadata=metadata,\n\t\t)\n\t\tself._insert_as_child_nodes(node=dir_node, child_nodes=[paper_node])\n\t\treturn dir_node, paper_node\n\n\tdef _new_doi_node(self, doi: str) -&gt; BaseNode:\n\t\tr\"\"\"\n\t\tCreate a new DOI node in the notes vector index, as the child of the root node.\n\n\t\tArgs:\n\t\t\tdoi (str): The DOI of a paper.\n\n\t\tReturns:\n\t\t\tThe created DOI node.\n\t\t\"\"\"\n\t\tmetadata = {\n\t\t\tSHARED_PAPER_NODE_TYPE: SharedPaperNoteNodeType.DOI,\n\t\t}\n\t\tdoi_node = TextNode(\n\t\t\ttext=f\"DOI: {doi}\",\n\t\t\tid_=doi,\n\t\t\tmetadata=metadata,\n\t\t)\n\n\t\tnote_root_node = self._get_notes_index_node(node_id=SHARED_PAPER_ROOT_NODE_NAME)\n\t\tself._insert_as_child_nodes(node=note_root_node, child_nodes=[doi_node, ])\n\t\tself._update_note_index_node(node_id=note_root_node.node_id, node=note_root_node)\n\t\treturn doi_node\n\n\tdef _new_note_node(self, user_id: str, note: str) -&gt; BaseNode:\n\t\tr\"\"\" Create a new note node. \"\"\"\n\t\tnode = TextNode(\n\t\t\ttext=note,\n\t\t\tmetadata={\n\t\t\t\tSHARED_PAPER_NODE_TYPE: SharedPaperNoteNodeType.NOTE,\n\t\t\t\t\"user_id\": user_id,\n\t\t\t}\n\t\t)\n\t\treturn node\n\n\tdef _is_valid_paper_dir(self, rel_dir: str) -&gt; bool:\n\t\tr\"\"\" Only when the relative dir path is under the `SHARED_PAPER_WAREHOUSE_DIR`, it is valid. \"\"\"\n\t\ttry:\n\t\t\tPath(rel_dir).relative_to(SHARED_PAPER_WAREHOUSE_DIR)\n\t\t\treturn True\n\t\texcept ValueError:\n\t\t\treturn False\n\n\tdef make_dirs(self, rel_dir: str):\n\t\tr\"\"\"\n\t\tRecursively add DIR nodes for a rel_dir.\n\n\t\trelative path to what? match the old vector index.\n\n\t\tArgs:\n\t\t\trel_dir (str): The path of a directory relative to the root.\n\n\t\tReturns:\n\t\t\tNone\n\n\t\tRaises:\n\t\t\tValueError: If the given rel_dir is not valid, that is, the rel_dir is not under the `SHARED_PAPER_WAREHOUSE_DIR`.\n\n\t\t\"\"\"\n\t\tif not self._is_valid_paper_dir(rel_dir=rel_dir):\n\t\t\traise ValueError(f\"The directory {rel_dir} is not under the warehouse {SHARED_PAPER_WAREHOUSE_DIR}.\")\n\n\t\tpath_parts = Path(rel_dir).relative_to(SHARED_PAPER_WAREHOUSE_DIR).parts\n\t\tassert len(path_parts) &gt; 1\n\n\t\tuser_id = path_parts[0]\n\t\tself._account_manager.check_valid_user(user_id=user_id)\n\t\tuser_node = self._get_node(node_id=user_id) or self.add_user_node(user_id=user_id)\n\t\tdir_path = Path(SHARED_PAPER_WAREHOUSE_DIR) / user_id\n\t\t# [node, whether to update]\n\t\tdirs_nodes = [[user_node, False]]\n\n\t\tfor part in path_parts[1:]:\n\t\t\tdir_path = dir_path / part\n\t\t\tdir_node = self._get_node(node_id=str(dir_path))\n\t\t\tif_new_dir = dir_node is None\n\t\t\tif if_new_dir:\n\t\t\t\tdir_node = self._new_dir_node(rel_dir_path=str(dir_path))\n\t\t\t\tparent_node = dirs_nodes[-1][0]\n\t\t\t\tdirs_nodes[-1][1] = True\n\t\t\t\tdir_node.relationships[NodeRelationship.PARENT] = RelatedNodeInfo(\n\t\t\t\t\tnode_id=parent_node.node_id,\n\t\t\t\t)\n\t\t\t\tself._insert_as_child_nodes(node=parent_node, child_nodes=[dir_node])\n\t\t\tdirs_nodes.append([dir_node, if_new_dir])\n\n\t\tto_update_nodes = [pair[0] for pair in dirs_nodes if pair[1]]\n\t\tfor node in to_update_nodes:\n\t\t\tself._update_node(node_id=node.node_id, node=node)\n\n\tdef summarize_paper(self, paper_node_id: str) -&gt; Optional[str]:\n\t\tr\"\"\"\n\t\tSummarize a paper in the shared paper storage.\n\n\t\tArgs:\n\t\t\tpaper_node_id (str): The node id of the corresponding paper node.\n\n\t\tReturns:\n\t\t\tOptional[str]: The summary of th paper. If the paper does not exist, return None.\n\t\t\"\"\"\n\t\tpaper_node = self._get_node(node_id=paper_node_id)\n\t\tif paper_node is None:\n\t\t\treturn None\n\n\t\tsummary = paper_node.metadata.get(SHARED_PAPER_SUMMARY_KEY, None)\n\t\tif summary is not None:\n\t\t\treturn summary\n\n\t\tcontent_ids = [child.node_id for child in paper_node.child_nodes]\n\t\tcontent_nodes = self._get_nodes(\n\t\t\tnode_ids=content_ids,\n\t\t\tnode_types=[SharedPaperNodeType.PAPER_CHUNK]\n\t\t)\n\n\t\tnodes_with_scores = [NodeWithScore(node=n) for n in content_nodes]\n\t\t# get the summary for each doc_id\n\t\tsummary_response = self._summarizer.synthesize(nodes=nodes_with_scores, query=\"\")\n\t\tsummary_response = cast(Response, summary_response)\n\t\tsummary = summary_response.response\n\t\tpaper_node.metadata[SHARED_PAPER_SUMMARY_KEY] = summary\n\t\tself._update_node(node_id=paper_node.node_id, node=paper_node)\n\t\treturn summary\n\n\tasync def asummarize_paper(self, paper_node_id: str) -&gt; Optional[str]:\n\t\tr\"\"\"\n\t\tAsynchronously summarize a paper in the shared paper storage.\n\n\t\tArgs:\n\t\t\tpaper_node_id (str): The node id of the corresponding paper node.\n\n\t\tReturns:\n\t\t\tOptional[str]: The summary of th paper. If the paper does not exist, return None.\n\t\t\"\"\"\n\t\tpaper_node = self._get_node(node_id=paper_node_id)\n\t\tif paper_node is None:\n\t\t\treturn None\n\n\t\tsummary = paper_node.metadata.get(SHARED_PAPER_SUMMARY_KEY, None)\n\t\tif summary is not None:\n\t\t\treturn summary\n\n\t\tcontent_ids = [child.node_id for child in paper_node.child_nodes]\n\t\tcontent_nodes = self._get_nodes(\n\t\t\tnode_ids=content_ids,\n\t\t\tnode_types=[SharedPaperNodeType.PAPER_CHUNK]\n\t\t)\n\n\t\tnodes_with_scores = [NodeWithScore(node=n) for n in content_nodes]\n\t\t# get the summary for each doc_id\n\t\tsummary_response = await self._summarizer.asynthesize(nodes=nodes_with_scores, query=\"\")\n\t\tsummary_response = cast(Response, summary_response)\n\t\tsummary = summary_response.response\n\t\tpaper_node.metadata[SHARED_PAPER_SUMMARY_KEY] = summary\n\t\tself._update_node(node_id=paper_node.node_id, node=paper_node)\n\t\treturn summary\n\n\tdef insert_single_paper(\n\t\tself,\n\t\ttarget_rel_dir: str,\n\t\traw_paper_path: str,\n\t\tpaper_summary: str = None,\n\t\textra_metadata: dict = None,\n\t) -&gt; Optional[str]:\n\t\tr\"\"\"\n\t\tAdd a paper to the shared paper storage.\n\n\t\tArgs:\n\t\t\ttarget_rel_dir (str): The directory into which the new paper is inserted.\n\t\t\traw_paper_path (str): The file path of the paper.\n\t\t\tpaper_summary (str): If the paper has been summarized before, the summary can be provided to save cost.\n\t\t\textra_metadata (dict): Extra metadata obtained from other approaches such as ArXiv.\n\n\t\tReturns:\n\t\t\tOptional[str]: The node id of the new paper node.\n\t\t\t\tReturn None in these situation:\n\n\t\t\t\t- The target_rel_dir is not valid.\n\t\t\t\t- The raw_paper_path does not exist.\n\t\t\t\t- The given paper is not in pdf format.\n\t\t\t\t- The PaperReader fails to read the paper.\n\t\t\"\"\"\n\t\t# Deal with target dir\n\t\tif not self._is_valid_paper_dir(rel_dir=target_rel_dir):\n\t\t\tprint(\"Invalid paper dir.\")\n\t\t\treturn None\n\n\t\tif not self._fs.exists(raw_paper_path):\n\t\t\tprint(\"paper not exists.\")\n\t\t\treturn None\n\n\t\tpaper_name = Path(raw_paper_path).name\n\t\tif Path(raw_paper_path).suffix != \".pdf\":\n\t\t\tprint(\"is not pdf.\")\n\t\t\treturn None\n\n\t\ttarget_dir = self._root / target_rel_dir\n\t\tpaper_path = str(target_dir / paper_name)\n\t\ttarget_dir = str(target_dir)\n\n\t\tif not self._fs.exists(target_dir):\n\t\t\tself._fs.mkdirs(target_dir)\n\n\t\t# Move the paper to the warehouse.\n\t\tif paper_path != raw_paper_path:\n\t\t\tself._fs.cp(raw_paper_path, target_dir)\n\n\t\tread_content = self.paper_reader.read_single_paper(\n\t\t\tfile_path=paper_path,\n\t\t\textra_metadata=extra_metadata,\n\t\t)\n\t\tif read_content is None:\n\t\t\treturn None\n\n\t\tchunk_docs, extra_docs = read_content\n\t\tdir_node = self._get_node(node_id=target_rel_dir)\n\t\tif dir_node is None:\n\t\t\tself.make_dirs(rel_dir=target_rel_dir)\n\t\t\tdir_node = self._get_node(node_id=target_rel_dir)\n\n\t\tpaper_metadata = {\n\t\t\tkey: chunk_docs[0].metadata[key] for key in chunk_docs[0].metadata.keys() if key != CONTENT_TYPE_NAME\n\t\t}\n\t\tif paper_summary:\n\t\t\tpaper_metadata[SHARED_PAPER_SUMMARY_KEY] = paper_summary\n\t\tdir_node, paper_node = self._new_paper_node(dir_node=dir_node, paper_info=paper_metadata)\n\t\tself._update_node(node_id=dir_node.node_id, node=dir_node)\n\n\t\t# overlapped nodes\n\t\toverlapped_chunk_nodes = run_transformations(\n\t\t\tnodes=chunk_docs,\n\t\t\ttransformations=self._default_overlapped_transformations,\n\t\t)\n\t\tself._insert_as_child_nodes(node=paper_node, child_nodes=overlapped_chunk_nodes)\n\t\tfor chunk_node in overlapped_chunk_nodes:\n\t\t\tself._update_node(node_id=chunk_node.node_id, node=chunk_node)\n\n\t\t# insert non-overlapped nodes to notes_index as child nodes of doi node.\n\t\tpaper_doi = paper_metadata[PAPER_DOI]\n\t\tdoi_node = self._new_doi_node(doi=paper_doi)\n\n\t\tfor doc in chunk_docs:\n\t\t\tdoc.metadata = dict()\n\t\tnon_overlapped_chunk_nodes = run_transformations(\n\t\t\tnodes=chunk_docs,\n\t\t\ttransformations=self._default_non_overlapped_transformations,\n\t\t)\n\n\t\tself._insert_as_child_nodes(node=doi_node, child_nodes=non_overlapped_chunk_nodes)\n\t\tfor chunk_node in non_overlapped_chunk_nodes:\n\t\t\tself._update_note_index_node(node_id=chunk_node.node_id, node=chunk_node)\n\t\tself._update_note_index_node(node_id=doi_node.node_id, node=doi_node)\n\n\t\t# extra docs\n\t\tself._insert_as_child_nodes(node=paper_node, child_nodes=extra_docs)\n\t\tfor doc in extra_docs:\n\t\t\tdoc.metadata[SHARED_PAPER_NODE_TYPE] = SharedPaperNodeType.PAPER_EXTRA_INFO\n\t\t\tself._update_node(node_id=doc.node_id, node=doc)\n\n\t\tself._update_node(node_id=paper_node.node_id, node=paper_node)\n\t\treturn paper_node.node_id\n\n\tdef insert_papers(\n\t\tself,\n\t\tuser_id: str,\n\t\tpapers_root_dir: str,\n\t\tpaper_paths: List[str],\n\t\tenable_summarize: bool\n\t) -&gt; Optional[List[str]]:\n\t\tr\"\"\"\n\t\tInsert papers of a user.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user id of a laboratory member.\n\t\t\tpapers_root_dir (str): The raw root directory of these papers,\n\t\t\t\tthe directory structure will be copied to the shared paper warehouse.\n\t\t\tpaper_paths (List[str]): The paths of the papers.\n\t\t\tenable_summarize (bool): Whether to summarize these papers.\n\n\t\tReturns:\n\t\t\tOptional[List[str]]: The paths of failed papers. If no paper fails in recording, return None.\n\t\t\"\"\"\n\n\t\ttarget_dirs = []\n\t\tfor paper_path in paper_paths:\n\t\t\trel_path = str(Path(paper_path).relative_to(papers_root_dir))\n\t\t\ttarget_rel_dir = str(Path(f\"{SHARED_PAPER_WAREHOUSE_DIR}/{user_id}/{rel_path}\").parent)\n\t\t\ttarget_dirs.append(target_rel_dir)\n\n\t\tfailed_papers = []\n\t\tfor idx, paper_path in enumerate(paper_paths):\n\t\t\tpaper_id = self.insert_single_paper(\n\t\t\t\ttarget_rel_dir=target_dirs[idx],\n\t\t\t\traw_paper_path=paper_path,\n\t\t\t)\n\t\t\tif paper_id is None:\n\t\t\t\tfailed_papers.append(paper_path)\n\t\t\t\tcontinue\n\t\t\tif enable_summarize:\n\t\t\t\tself.summarize_paper(paper_node_id=paper_id)\n\t\t\tself.persist_papers()\n\t\t\tself.persist_notes()\n\n\t\tif len(failed_papers) &lt; 1:\n\t\t\treturn None\n\t\treturn failed_papers\n\n\tasync def ainsert_papers(\n\t\tself,\n\t\tuser_id: str,\n\t\tpapers_root_dir: str,\n\t\tpaper_paths: List[str],\n\t\tenable_summarize: bool\n\t) -&gt; Optional[List[str]]:\n\t\tr\"\"\"\n\t\tAsynchronously insert papers of a user.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user id of a laboratory member.\n\t\t\tpapers_root_dir (str): The raw root directory of these papers,\n\t\t\t\tthe directory structure will be copied to the shared paper warehouse.\n\t\t\tpaper_paths (List[str]): The paths of the papers.\n\t\t\tenable_summarize (bool): Whether to summarize these papers.\n\n\t\tReturns:\n\t\t\tOptional[List[str]]: The paths of failed papers. If no paper fails in recording, return None.\n\t\t\"\"\"\n\t\ttarget_dirs = []\n\t\tfor paper_path in paper_paths:\n\t\t\trel_path = str(Path(paper_path).relative_to(papers_root_dir))\n\t\t\ttarget_rel_dir = f\"{SHARED_PAPER_WAREHOUSE_DIR}/{user_id}/{rel_path}\"\n\t\t\ttarget_dirs.append(target_rel_dir)\n\n\t\tfailed_papers = []\n\t\tfor idx, paper_path in enumerate(paper_paths):\n\t\t\tpaper_id = self.insert_single_paper(\n\t\t\t\ttarget_rel_dir=target_dirs[idx],\n\t\t\t\traw_paper_path=paper_path,\n\t\t\t)\n\t\t\tif paper_id is None:\n\t\t\t\tfailed_papers.append(paper_path)\n\t\t\t\tcontinue\n\t\t\tif enable_summarize:\n\t\t\t\tawait self.asummarize_paper(paper_node_id=paper_id)\n\t\t\tself.persist_papers()\n\t\t\tself.persist_notes()\n\n\t\tif len(failed_papers) &lt; 1:\n\t\t\treturn None\n\t\treturn failed_papers\n\n\tdef persist_papers(self, persist_dir: str = None):\n\t\tr\"\"\" Save the vector_index to disk. \"\"\"\n\t\tpersist_dir = persist_dir or self.persist_dir\n\t\tif not self._fs.exists(persist_dir):\n\t\t\tself._fs.makedirs(persist_dir)\n\t\tself.vector_index.storage_context.persist(persist_dir=persist_dir)\n\n\tdef persist_notes(\n\t\tself,\n\t\tnotes_persist_dir: str = None,\n\t):\n\t\tr\"\"\" Save the notes_vector_index to disk. \"\"\"\n\t\tnotes_persist_dir = notes_persist_dir or self.notes_persist_dir\n\t\tif not self._fs.exists(notes_persist_dir):\n\t\t\tself._fs.makedirs(notes_persist_dir)\n\t\tself.notes_vector_index.storage_context.persist(persist_dir=notes_persist_dir)\n\n\tdef insert_note(\n\t\tself,\n\t\tdoi: str,\n\t\tuser_id: str,\n\t\tnotes: Dict[str, str],\n\t):\n\t\tr\"\"\"\n\t\tInsert a note into the notes vector index.\n\n\t\tArgs:\n\t\t\tdoi (str): The DOI of the corresponding paper.\n\t\t\tuser_id (str): The user id of a Lab member.\n\t\t\tnotes (Dict[str, str]): key -- corresponding paper content; value -- the user's note.\n\n\t\tReturns:\n\t\t\tNone\n\t\t\"\"\"\n\t\tdoi_node = self._get_notes_index_node(node_id=doi)\n\t\tif doi_node is None:\n\t\t\treturn\n\n\t\tchunk_ids = [node.node_id for node in doi_node.child_nodes]\n\t\tretriever = self.notes_vector_index.as_retriever(similarity_top_k=1)\n\t\tretriever._node_ids = chunk_ids\n\n\t\trecord = []\n\t\tfor chunk_info in notes.keys():\n\t\t\tretrieved_nodes = retriever.retrieve(chunk_info)\n\t\t\ttarget_node_id = retrieved_nodes[0].node_id\n\t\t\trecord.append((target_node_id, notes[chunk_info]))\n\n\t\tfor target_id, note_str in record:\n\t\t\tchunk_node = self._get_notes_index_node(node_id=target_id)\n\t\t\tnote_node = self._new_note_node(\n\t\t\t\tuser_id=user_id,\n\t\t\t\tnote=note_str,\n\t\t\t)\n\t\t\tself._insert_as_child_nodes(node=chunk_node, child_nodes=[note_node])\n\t\t\tself._update_note_index_node(node_id=chunk_node.node_id, node=chunk_node)\n\t\t\tself._update_note_index_node(node_id=note_node.node_id, node=note_node)\n\t\tself.persist_notes()\n\n\tdef get_notes(\n\t\tself,\n\t\tdoi: str,\n\t\tchunk_info: str,\n\t) -&gt; Optional[List[UserNote]]:\n\t\tr\"\"\"\n\t\tCheck whether there exists any notes corresponding to the given content.\n\n\t\tArgs:\n\t\t\tdoi (str): The DOI of the paper.\n\t\t\tchunk_info (str): The corresponding paper content.\n\n\t\tReturns:\n\t\t\tOptional[List[UserNote]]: If notes exist, return the notes. Otherwise, return None.\n\t\t\"\"\"\n\t\tdoi_node = self._get_notes_index_node(node_id=doi)\n\t\tif doi_node is None:\n\t\t\treturn None\n\t\tchunk_ids = [node.node_id for node in doi_node.child_nodes]\n\t\tretriever = self.notes_vector_index.as_retriever(similarity_top_k=1)\n\t\tretriever._node_ids = chunk_ids\n\t\tretrieved_nodes = retriever.retrieve(chunk_info)\n\t\ttarget_node_id = retrieved_nodes[0].node_id\n\t\tchunk_node = self._get_notes_index_node(node_id=target_node_id)\n\n\t\tnote_ids = [node.node_id for node in chunk_node.child_nodes]\n\t\tif len(note_ids) &lt; 1:\n\t\t\treturn None\n\n\t\tnotes = []\n\t\tfor node_id in note_ids:\n\t\t\tnote_node = self._get_notes_index_node(node_id=node_id)\n\t\t\tnotes.append(\n\t\t\t\tUserNote(\n\t\t\t\t\tuser_id=note_node.metadata[\"user_id\"],\n\t\t\t\t\tnote=note_node.text,\n\t\t\t\t\tdoi=doi,\n\t\t\t\t)\n\t\t\t)\n\t\treturn notes\n\n\tdef add_user_node(self, user_id: str) -&gt; BaseNode:\n\t\tr\"\"\"\n\t\tAdd a user node for a valid user.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user id of a Lab member.\n\n\t\tReturns:\n\t\t\tThe user node\n\t\t\"\"\"\n\t\tuser_node = TextNode(\n\t\t\ttext=f\"Directory for user {user_id}\",\n\t\t\tid_=user_id,\n\t\t\tmetadata={\n\t\t\t\tSHARED_PAPER_NODE_TYPE: SharedPaperNodeType.USER,\n\t\t\t}\n\t\t)\n\t\troot_node = self._get_node(node_id=SHARED_PAPER_ROOT_NODE_NAME)\n\t\tself._insert_as_child_nodes(node=root_node, child_nodes=[user_node])\n\t\tself._update_node(node_id=root_node.node_id, node=root_node)\n\t\tself._update_node(node_id=user_node.node_id, node=user_node)\n\t\treturn user_node\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/shared_paper_store/#labridge.func_modules.paper.store.shared_paper_store.SharedPaperStorage.add_user_node","title":"<code>labridge.func_modules.paper.store.shared_paper_store.SharedPaperStorage.add_user_node(user_id)</code>","text":"<p>Add a user node for a valid user.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user id of a Lab member.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>BaseNode</code> <p>The user node</p> Source code in <code>labridge\\func_modules\\paper\\store\\shared_paper_store.py</code> <pre><code>def add_user_node(self, user_id: str) -&gt; BaseNode:\n\tr\"\"\"\n\tAdd a user node for a valid user.\n\n\tArgs:\n\t\tuser_id (str): The user id of a Lab member.\n\n\tReturns:\n\t\tThe user node\n\t\"\"\"\n\tuser_node = TextNode(\n\t\ttext=f\"Directory for user {user_id}\",\n\t\tid_=user_id,\n\t\tmetadata={\n\t\t\tSHARED_PAPER_NODE_TYPE: SharedPaperNodeType.USER,\n\t\t}\n\t)\n\troot_node = self._get_node(node_id=SHARED_PAPER_ROOT_NODE_NAME)\n\tself._insert_as_child_nodes(node=root_node, child_nodes=[user_node])\n\tself._update_node(node_id=root_node.node_id, node=root_node)\n\tself._update_node(node_id=user_node.node_id, node=user_node)\n\treturn user_node\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/shared_paper_store/#labridge.func_modules.paper.store.shared_paper_store.SharedPaperStorage.ainsert_papers","title":"<code>labridge.func_modules.paper.store.shared_paper_store.SharedPaperStorage.ainsert_papers(user_id, papers_root_dir, paper_paths, enable_summarize)</code>  <code>async</code>","text":"<p>Asynchronously insert papers of a user.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user id of a laboratory member.</p> <p> TYPE: <code>str</code> </p> <code>papers_root_dir</code> <p>The raw root directory of these papers, the directory structure will be copied to the shared paper warehouse.</p> <p> TYPE: <code>str</code> </p> <code>paper_paths</code> <p>The paths of the papers.</p> <p> TYPE: <code>List[str]</code> </p> <code>enable_summarize</code> <p>Whether to summarize these papers.</p> <p> TYPE: <code>bool</code> </p> RETURNS DESCRIPTION <code>Optional[List[str]]</code> <p>Optional[List[str]]: The paths of failed papers. If no paper fails in recording, return None.</p> Source code in <code>labridge\\func_modules\\paper\\store\\shared_paper_store.py</code> <pre><code>async def ainsert_papers(\n\tself,\n\tuser_id: str,\n\tpapers_root_dir: str,\n\tpaper_paths: List[str],\n\tenable_summarize: bool\n) -&gt; Optional[List[str]]:\n\tr\"\"\"\n\tAsynchronously insert papers of a user.\n\n\tArgs:\n\t\tuser_id (str): The user id of a laboratory member.\n\t\tpapers_root_dir (str): The raw root directory of these papers,\n\t\t\tthe directory structure will be copied to the shared paper warehouse.\n\t\tpaper_paths (List[str]): The paths of the papers.\n\t\tenable_summarize (bool): Whether to summarize these papers.\n\n\tReturns:\n\t\tOptional[List[str]]: The paths of failed papers. If no paper fails in recording, return None.\n\t\"\"\"\n\ttarget_dirs = []\n\tfor paper_path in paper_paths:\n\t\trel_path = str(Path(paper_path).relative_to(papers_root_dir))\n\t\ttarget_rel_dir = f\"{SHARED_PAPER_WAREHOUSE_DIR}/{user_id}/{rel_path}\"\n\t\ttarget_dirs.append(target_rel_dir)\n\n\tfailed_papers = []\n\tfor idx, paper_path in enumerate(paper_paths):\n\t\tpaper_id = self.insert_single_paper(\n\t\t\ttarget_rel_dir=target_dirs[idx],\n\t\t\traw_paper_path=paper_path,\n\t\t)\n\t\tif paper_id is None:\n\t\t\tfailed_papers.append(paper_path)\n\t\t\tcontinue\n\t\tif enable_summarize:\n\t\t\tawait self.asummarize_paper(paper_node_id=paper_id)\n\t\tself.persist_papers()\n\t\tself.persist_notes()\n\n\tif len(failed_papers) &lt; 1:\n\t\treturn None\n\treturn failed_papers\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/shared_paper_store/#labridge.func_modules.paper.store.shared_paper_store.SharedPaperStorage.asummarize_paper","title":"<code>labridge.func_modules.paper.store.shared_paper_store.SharedPaperStorage.asummarize_paper(paper_node_id)</code>  <code>async</code>","text":"<p>Asynchronously summarize a paper in the shared paper storage.</p> PARAMETER DESCRIPTION <code>paper_node_id</code> <p>The node id of the corresponding paper node.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Optional[str]</code> <p>Optional[str]: The summary of th paper. If the paper does not exist, return None.</p> Source code in <code>labridge\\func_modules\\paper\\store\\shared_paper_store.py</code> <pre><code>async def asummarize_paper(self, paper_node_id: str) -&gt; Optional[str]:\n\tr\"\"\"\n\tAsynchronously summarize a paper in the shared paper storage.\n\n\tArgs:\n\t\tpaper_node_id (str): The node id of the corresponding paper node.\n\n\tReturns:\n\t\tOptional[str]: The summary of th paper. If the paper does not exist, return None.\n\t\"\"\"\n\tpaper_node = self._get_node(node_id=paper_node_id)\n\tif paper_node is None:\n\t\treturn None\n\n\tsummary = paper_node.metadata.get(SHARED_PAPER_SUMMARY_KEY, None)\n\tif summary is not None:\n\t\treturn summary\n\n\tcontent_ids = [child.node_id for child in paper_node.child_nodes]\n\tcontent_nodes = self._get_nodes(\n\t\tnode_ids=content_ids,\n\t\tnode_types=[SharedPaperNodeType.PAPER_CHUNK]\n\t)\n\n\tnodes_with_scores = [NodeWithScore(node=n) for n in content_nodes]\n\t# get the summary for each doc_id\n\tsummary_response = await self._summarizer.asynthesize(nodes=nodes_with_scores, query=\"\")\n\tsummary_response = cast(Response, summary_response)\n\tsummary = summary_response.response\n\tpaper_node.metadata[SHARED_PAPER_SUMMARY_KEY] = summary\n\tself._update_node(node_id=paper_node.node_id, node=paper_node)\n\treturn summary\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/shared_paper_store/#labridge.func_modules.paper.store.shared_paper_store.SharedPaperStorage.get_notes","title":"<code>labridge.func_modules.paper.store.shared_paper_store.SharedPaperStorage.get_notes(doi, chunk_info)</code>","text":"<p>Check whether there exists any notes corresponding to the given content.</p> PARAMETER DESCRIPTION <code>doi</code> <p>The DOI of the paper.</p> <p> TYPE: <code>str</code> </p> <code>chunk_info</code> <p>The corresponding paper content.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Optional[List[UserNote]]</code> <p>Optional[List[UserNote]]: If notes exist, return the notes. Otherwise, return None.</p> Source code in <code>labridge\\func_modules\\paper\\store\\shared_paper_store.py</code> <pre><code>def get_notes(\n\tself,\n\tdoi: str,\n\tchunk_info: str,\n) -&gt; Optional[List[UserNote]]:\n\tr\"\"\"\n\tCheck whether there exists any notes corresponding to the given content.\n\n\tArgs:\n\t\tdoi (str): The DOI of the paper.\n\t\tchunk_info (str): The corresponding paper content.\n\n\tReturns:\n\t\tOptional[List[UserNote]]: If notes exist, return the notes. Otherwise, return None.\n\t\"\"\"\n\tdoi_node = self._get_notes_index_node(node_id=doi)\n\tif doi_node is None:\n\t\treturn None\n\tchunk_ids = [node.node_id for node in doi_node.child_nodes]\n\tretriever = self.notes_vector_index.as_retriever(similarity_top_k=1)\n\tretriever._node_ids = chunk_ids\n\tretrieved_nodes = retriever.retrieve(chunk_info)\n\ttarget_node_id = retrieved_nodes[0].node_id\n\tchunk_node = self._get_notes_index_node(node_id=target_node_id)\n\n\tnote_ids = [node.node_id for node in chunk_node.child_nodes]\n\tif len(note_ids) &lt; 1:\n\t\treturn None\n\n\tnotes = []\n\tfor node_id in note_ids:\n\t\tnote_node = self._get_notes_index_node(node_id=node_id)\n\t\tnotes.append(\n\t\t\tUserNote(\n\t\t\t\tuser_id=note_node.metadata[\"user_id\"],\n\t\t\t\tnote=note_node.text,\n\t\t\t\tdoi=doi,\n\t\t\t)\n\t\t)\n\treturn notes\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/shared_paper_store/#labridge.func_modules.paper.store.shared_paper_store.SharedPaperStorage.insert_note","title":"<code>labridge.func_modules.paper.store.shared_paper_store.SharedPaperStorage.insert_note(doi, user_id, notes)</code>","text":"<p>Insert a note into the notes vector index.</p> PARAMETER DESCRIPTION <code>doi</code> <p>The DOI of the corresponding paper.</p> <p> TYPE: <code>str</code> </p> <code>user_id</code> <p>The user id of a Lab member.</p> <p> TYPE: <code>str</code> </p> <code>notes</code> <p>key -- corresponding paper content; value -- the user's note.</p> <p> TYPE: <code>Dict[str, str]</code> </p> RETURNS DESCRIPTION <p>None</p> Source code in <code>labridge\\func_modules\\paper\\store\\shared_paper_store.py</code> <pre><code>def insert_note(\n\tself,\n\tdoi: str,\n\tuser_id: str,\n\tnotes: Dict[str, str],\n):\n\tr\"\"\"\n\tInsert a note into the notes vector index.\n\n\tArgs:\n\t\tdoi (str): The DOI of the corresponding paper.\n\t\tuser_id (str): The user id of a Lab member.\n\t\tnotes (Dict[str, str]): key -- corresponding paper content; value -- the user's note.\n\n\tReturns:\n\t\tNone\n\t\"\"\"\n\tdoi_node = self._get_notes_index_node(node_id=doi)\n\tif doi_node is None:\n\t\treturn\n\n\tchunk_ids = [node.node_id for node in doi_node.child_nodes]\n\tretriever = self.notes_vector_index.as_retriever(similarity_top_k=1)\n\tretriever._node_ids = chunk_ids\n\n\trecord = []\n\tfor chunk_info in notes.keys():\n\t\tretrieved_nodes = retriever.retrieve(chunk_info)\n\t\ttarget_node_id = retrieved_nodes[0].node_id\n\t\trecord.append((target_node_id, notes[chunk_info]))\n\n\tfor target_id, note_str in record:\n\t\tchunk_node = self._get_notes_index_node(node_id=target_id)\n\t\tnote_node = self._new_note_node(\n\t\t\tuser_id=user_id,\n\t\t\tnote=note_str,\n\t\t)\n\t\tself._insert_as_child_nodes(node=chunk_node, child_nodes=[note_node])\n\t\tself._update_note_index_node(node_id=chunk_node.node_id, node=chunk_node)\n\t\tself._update_note_index_node(node_id=note_node.node_id, node=note_node)\n\tself.persist_notes()\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/shared_paper_store/#labridge.func_modules.paper.store.shared_paper_store.SharedPaperStorage.insert_papers","title":"<code>labridge.func_modules.paper.store.shared_paper_store.SharedPaperStorage.insert_papers(user_id, papers_root_dir, paper_paths, enable_summarize)</code>","text":"<p>Insert papers of a user.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user id of a laboratory member.</p> <p> TYPE: <code>str</code> </p> <code>papers_root_dir</code> <p>The raw root directory of these papers, the directory structure will be copied to the shared paper warehouse.</p> <p> TYPE: <code>str</code> </p> <code>paper_paths</code> <p>The paths of the papers.</p> <p> TYPE: <code>List[str]</code> </p> <code>enable_summarize</code> <p>Whether to summarize these papers.</p> <p> TYPE: <code>bool</code> </p> RETURNS DESCRIPTION <code>Optional[List[str]]</code> <p>Optional[List[str]]: The paths of failed papers. If no paper fails in recording, return None.</p> Source code in <code>labridge\\func_modules\\paper\\store\\shared_paper_store.py</code> <pre><code>def insert_papers(\n\tself,\n\tuser_id: str,\n\tpapers_root_dir: str,\n\tpaper_paths: List[str],\n\tenable_summarize: bool\n) -&gt; Optional[List[str]]:\n\tr\"\"\"\n\tInsert papers of a user.\n\n\tArgs:\n\t\tuser_id (str): The user id of a laboratory member.\n\t\tpapers_root_dir (str): The raw root directory of these papers,\n\t\t\tthe directory structure will be copied to the shared paper warehouse.\n\t\tpaper_paths (List[str]): The paths of the papers.\n\t\tenable_summarize (bool): Whether to summarize these papers.\n\n\tReturns:\n\t\tOptional[List[str]]: The paths of failed papers. If no paper fails in recording, return None.\n\t\"\"\"\n\n\ttarget_dirs = []\n\tfor paper_path in paper_paths:\n\t\trel_path = str(Path(paper_path).relative_to(papers_root_dir))\n\t\ttarget_rel_dir = str(Path(f\"{SHARED_PAPER_WAREHOUSE_DIR}/{user_id}/{rel_path}\").parent)\n\t\ttarget_dirs.append(target_rel_dir)\n\n\tfailed_papers = []\n\tfor idx, paper_path in enumerate(paper_paths):\n\t\tpaper_id = self.insert_single_paper(\n\t\t\ttarget_rel_dir=target_dirs[idx],\n\t\t\traw_paper_path=paper_path,\n\t\t)\n\t\tif paper_id is None:\n\t\t\tfailed_papers.append(paper_path)\n\t\t\tcontinue\n\t\tif enable_summarize:\n\t\t\tself.summarize_paper(paper_node_id=paper_id)\n\t\tself.persist_papers()\n\t\tself.persist_notes()\n\n\tif len(failed_papers) &lt; 1:\n\t\treturn None\n\treturn failed_papers\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/shared_paper_store/#labridge.func_modules.paper.store.shared_paper_store.SharedPaperStorage.insert_single_paper","title":"<code>labridge.func_modules.paper.store.shared_paper_store.SharedPaperStorage.insert_single_paper(target_rel_dir, raw_paper_path, paper_summary=None, extra_metadata=None)</code>","text":"<p>Add a paper to the shared paper storage.</p> PARAMETER DESCRIPTION <code>target_rel_dir</code> <p>The directory into which the new paper is inserted.</p> <p> TYPE: <code>str</code> </p> <code>raw_paper_path</code> <p>The file path of the paper.</p> <p> TYPE: <code>str</code> </p> <code>paper_summary</code> <p>If the paper has been summarized before, the summary can be provided to save cost.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>extra_metadata</code> <p>Extra metadata obtained from other approaches such as ArXiv.</p> <p> TYPE: <code>dict</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Optional[str]</code> <p>Optional[str]: The node id of the new paper node. Return None in these situation:</p> <ul> <li>The target_rel_dir is not valid.</li> <li>The raw_paper_path does not exist.</li> <li>The given paper is not in pdf format.</li> <li>The PaperReader fails to read the paper.</li> </ul> Source code in <code>labridge\\func_modules\\paper\\store\\shared_paper_store.py</code> <pre><code>def insert_single_paper(\n\tself,\n\ttarget_rel_dir: str,\n\traw_paper_path: str,\n\tpaper_summary: str = None,\n\textra_metadata: dict = None,\n) -&gt; Optional[str]:\n\tr\"\"\"\n\tAdd a paper to the shared paper storage.\n\n\tArgs:\n\t\ttarget_rel_dir (str): The directory into which the new paper is inserted.\n\t\traw_paper_path (str): The file path of the paper.\n\t\tpaper_summary (str): If the paper has been summarized before, the summary can be provided to save cost.\n\t\textra_metadata (dict): Extra metadata obtained from other approaches such as ArXiv.\n\n\tReturns:\n\t\tOptional[str]: The node id of the new paper node.\n\t\t\tReturn None in these situation:\n\n\t\t\t- The target_rel_dir is not valid.\n\t\t\t- The raw_paper_path does not exist.\n\t\t\t- The given paper is not in pdf format.\n\t\t\t- The PaperReader fails to read the paper.\n\t\"\"\"\n\t# Deal with target dir\n\tif not self._is_valid_paper_dir(rel_dir=target_rel_dir):\n\t\tprint(\"Invalid paper dir.\")\n\t\treturn None\n\n\tif not self._fs.exists(raw_paper_path):\n\t\tprint(\"paper not exists.\")\n\t\treturn None\n\n\tpaper_name = Path(raw_paper_path).name\n\tif Path(raw_paper_path).suffix != \".pdf\":\n\t\tprint(\"is not pdf.\")\n\t\treturn None\n\n\ttarget_dir = self._root / target_rel_dir\n\tpaper_path = str(target_dir / paper_name)\n\ttarget_dir = str(target_dir)\n\n\tif not self._fs.exists(target_dir):\n\t\tself._fs.mkdirs(target_dir)\n\n\t# Move the paper to the warehouse.\n\tif paper_path != raw_paper_path:\n\t\tself._fs.cp(raw_paper_path, target_dir)\n\n\tread_content = self.paper_reader.read_single_paper(\n\t\tfile_path=paper_path,\n\t\textra_metadata=extra_metadata,\n\t)\n\tif read_content is None:\n\t\treturn None\n\n\tchunk_docs, extra_docs = read_content\n\tdir_node = self._get_node(node_id=target_rel_dir)\n\tif dir_node is None:\n\t\tself.make_dirs(rel_dir=target_rel_dir)\n\t\tdir_node = self._get_node(node_id=target_rel_dir)\n\n\tpaper_metadata = {\n\t\tkey: chunk_docs[0].metadata[key] for key in chunk_docs[0].metadata.keys() if key != CONTENT_TYPE_NAME\n\t}\n\tif paper_summary:\n\t\tpaper_metadata[SHARED_PAPER_SUMMARY_KEY] = paper_summary\n\tdir_node, paper_node = self._new_paper_node(dir_node=dir_node, paper_info=paper_metadata)\n\tself._update_node(node_id=dir_node.node_id, node=dir_node)\n\n\t# overlapped nodes\n\toverlapped_chunk_nodes = run_transformations(\n\t\tnodes=chunk_docs,\n\t\ttransformations=self._default_overlapped_transformations,\n\t)\n\tself._insert_as_child_nodes(node=paper_node, child_nodes=overlapped_chunk_nodes)\n\tfor chunk_node in overlapped_chunk_nodes:\n\t\tself._update_node(node_id=chunk_node.node_id, node=chunk_node)\n\n\t# insert non-overlapped nodes to notes_index as child nodes of doi node.\n\tpaper_doi = paper_metadata[PAPER_DOI]\n\tdoi_node = self._new_doi_node(doi=paper_doi)\n\n\tfor doc in chunk_docs:\n\t\tdoc.metadata = dict()\n\tnon_overlapped_chunk_nodes = run_transformations(\n\t\tnodes=chunk_docs,\n\t\ttransformations=self._default_non_overlapped_transformations,\n\t)\n\n\tself._insert_as_child_nodes(node=doi_node, child_nodes=non_overlapped_chunk_nodes)\n\tfor chunk_node in non_overlapped_chunk_nodes:\n\t\tself._update_note_index_node(node_id=chunk_node.node_id, node=chunk_node)\n\tself._update_note_index_node(node_id=doi_node.node_id, node=doi_node)\n\n\t# extra docs\n\tself._insert_as_child_nodes(node=paper_node, child_nodes=extra_docs)\n\tfor doc in extra_docs:\n\t\tdoc.metadata[SHARED_PAPER_NODE_TYPE] = SharedPaperNodeType.PAPER_EXTRA_INFO\n\t\tself._update_node(node_id=doc.node_id, node=doc)\n\n\tself._update_node(node_id=paper_node.node_id, node=paper_node)\n\treturn paper_node.node_id\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/shared_paper_store/#labridge.func_modules.paper.store.shared_paper_store.SharedPaperStorage.make_dirs","title":"<code>labridge.func_modules.paper.store.shared_paper_store.SharedPaperStorage.make_dirs(rel_dir)</code>","text":"<p>Recursively add DIR nodes for a rel_dir.</p> <p>relative path to what? match the old vector index.</p> PARAMETER DESCRIPTION <code>rel_dir</code> <p>The path of a directory relative to the root.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <p>None</p> RAISES DESCRIPTION <code>ValueError</code> <p>If the given rel_dir is not valid, that is, the rel_dir is not under the <code>SHARED_PAPER_WAREHOUSE_DIR</code>.</p> Source code in <code>labridge\\func_modules\\paper\\store\\shared_paper_store.py</code> <pre><code>def make_dirs(self, rel_dir: str):\n\tr\"\"\"\n\tRecursively add DIR nodes for a rel_dir.\n\n\trelative path to what? match the old vector index.\n\n\tArgs:\n\t\trel_dir (str): The path of a directory relative to the root.\n\n\tReturns:\n\t\tNone\n\n\tRaises:\n\t\tValueError: If the given rel_dir is not valid, that is, the rel_dir is not under the `SHARED_PAPER_WAREHOUSE_DIR`.\n\n\t\"\"\"\n\tif not self._is_valid_paper_dir(rel_dir=rel_dir):\n\t\traise ValueError(f\"The directory {rel_dir} is not under the warehouse {SHARED_PAPER_WAREHOUSE_DIR}.\")\n\n\tpath_parts = Path(rel_dir).relative_to(SHARED_PAPER_WAREHOUSE_DIR).parts\n\tassert len(path_parts) &gt; 1\n\n\tuser_id = path_parts[0]\n\tself._account_manager.check_valid_user(user_id=user_id)\n\tuser_node = self._get_node(node_id=user_id) or self.add_user_node(user_id=user_id)\n\tdir_path = Path(SHARED_PAPER_WAREHOUSE_DIR) / user_id\n\t# [node, whether to update]\n\tdirs_nodes = [[user_node, False]]\n\n\tfor part in path_parts[1:]:\n\t\tdir_path = dir_path / part\n\t\tdir_node = self._get_node(node_id=str(dir_path))\n\t\tif_new_dir = dir_node is None\n\t\tif if_new_dir:\n\t\t\tdir_node = self._new_dir_node(rel_dir_path=str(dir_path))\n\t\t\tparent_node = dirs_nodes[-1][0]\n\t\t\tdirs_nodes[-1][1] = True\n\t\t\tdir_node.relationships[NodeRelationship.PARENT] = RelatedNodeInfo(\n\t\t\t\tnode_id=parent_node.node_id,\n\t\t\t)\n\t\t\tself._insert_as_child_nodes(node=parent_node, child_nodes=[dir_node])\n\t\tdirs_nodes.append([dir_node, if_new_dir])\n\n\tto_update_nodes = [pair[0] for pair in dirs_nodes if pair[1]]\n\tfor node in to_update_nodes:\n\t\tself._update_node(node_id=node.node_id, node=node)\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/shared_paper_store/#labridge.func_modules.paper.store.shared_paper_store.SharedPaperStorage.persist_notes","title":"<code>labridge.func_modules.paper.store.shared_paper_store.SharedPaperStorage.persist_notes(notes_persist_dir=None)</code>","text":"<p>Save the notes_vector_index to disk.</p> Source code in <code>labridge\\func_modules\\paper\\store\\shared_paper_store.py</code> <pre><code>def persist_notes(\n\tself,\n\tnotes_persist_dir: str = None,\n):\n\tr\"\"\" Save the notes_vector_index to disk. \"\"\"\n\tnotes_persist_dir = notes_persist_dir or self.notes_persist_dir\n\tif not self._fs.exists(notes_persist_dir):\n\t\tself._fs.makedirs(notes_persist_dir)\n\tself.notes_vector_index.storage_context.persist(persist_dir=notes_persist_dir)\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/shared_paper_store/#labridge.func_modules.paper.store.shared_paper_store.SharedPaperStorage.persist_papers","title":"<code>labridge.func_modules.paper.store.shared_paper_store.SharedPaperStorage.persist_papers(persist_dir=None)</code>","text":"<p>Save the vector_index to disk.</p> Source code in <code>labridge\\func_modules\\paper\\store\\shared_paper_store.py</code> <pre><code>def persist_papers(self, persist_dir: str = None):\n\tr\"\"\" Save the vector_index to disk. \"\"\"\n\tpersist_dir = persist_dir or self.persist_dir\n\tif not self._fs.exists(persist_dir):\n\t\tself._fs.makedirs(persist_dir)\n\tself.vector_index.storage_context.persist(persist_dir=persist_dir)\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/shared_paper_store/#labridge.func_modules.paper.store.shared_paper_store.SharedPaperStorage.summarize_paper","title":"<code>labridge.func_modules.paper.store.shared_paper_store.SharedPaperStorage.summarize_paper(paper_node_id)</code>","text":"<p>Summarize a paper in the shared paper storage.</p> PARAMETER DESCRIPTION <code>paper_node_id</code> <p>The node id of the corresponding paper node.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Optional[str]</code> <p>Optional[str]: The summary of th paper. If the paper does not exist, return None.</p> Source code in <code>labridge\\func_modules\\paper\\store\\shared_paper_store.py</code> <pre><code>def summarize_paper(self, paper_node_id: str) -&gt; Optional[str]:\n\tr\"\"\"\n\tSummarize a paper in the shared paper storage.\n\n\tArgs:\n\t\tpaper_node_id (str): The node id of the corresponding paper node.\n\n\tReturns:\n\t\tOptional[str]: The summary of th paper. If the paper does not exist, return None.\n\t\"\"\"\n\tpaper_node = self._get_node(node_id=paper_node_id)\n\tif paper_node is None:\n\t\treturn None\n\n\tsummary = paper_node.metadata.get(SHARED_PAPER_SUMMARY_KEY, None)\n\tif summary is not None:\n\t\treturn summary\n\n\tcontent_ids = [child.node_id for child in paper_node.child_nodes]\n\tcontent_nodes = self._get_nodes(\n\t\tnode_ids=content_ids,\n\t\tnode_types=[SharedPaperNodeType.PAPER_CHUNK]\n\t)\n\n\tnodes_with_scores = [NodeWithScore(node=n) for n in content_nodes]\n\t# get the summary for each doc_id\n\tsummary_response = self._summarizer.synthesize(nodes=nodes_with_scores, query=\"\")\n\tsummary_response = cast(Response, summary_response)\n\tsummary = summary_response.response\n\tpaper_node.metadata[SHARED_PAPER_SUMMARY_KEY] = summary\n\tself._update_node(node_id=paper_node.node_id, node=paper_node)\n\treturn summary\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/temporary_store/","title":"Temporary store","text":""},{"location":"code_docs/func_modules/paper/store/temporary_store/#labridge.func_modules.paper.store.temporary_store","title":"<code>labridge.func_modules.paper.store.temporary_store</code>","text":""},{"location":"code_docs/func_modules/paper/store/temporary_store/#labridge.func_modules.paper.store.temporary_store.RecentPaperStore","title":"<code>labridge.func_modules.paper.store.temporary_store.RecentPaperStore</code>","text":"<p>               Bases: <code>object</code></p> <p>This class stores the recent papers of a specific user. It is constructed as a tree, with a root node.</p> <p>Different papers are inserted as child nodes of the root node, the node_id is the absolute file path (in the recent paper warehouse) of the paper.</p> <p>For each paper node, TextNodes recording paper contents are stored as its child nodes. Like:</p> <pre><code>                                                                                root_node\n                                                                        /                               \\\n                                                                   /                             \\\n                                                                Paper1                                  Paper2\n                                                /               ...                             \\\n                                        node_1                                          node_n\n</code></pre> PARAMETER DESCRIPTION <code>vector_index</code> <p>The vector database storing recent papers.</p> <p> TYPE: <code>VectorStoreIndex</code> </p> <code>persist_dir</code> <p>The persist directory of the vector database.</p> <p> TYPE: <code>persist_dir</code> </p> Note <p>The metadata <code>date</code> and <code>time</code> is recorded in a list format for the convenience of metadata filtering. For example: ['2024-08-10'], ['09:05:03'].</p> Source code in <code>labridge\\func_modules\\paper\\store\\temporary_store.py</code> <pre><code>class RecentPaperStore(object):\n\tr\"\"\"\n\tThis class stores the recent papers of a specific user.\n\tIt is constructed as a tree, with a root node.\n\n\tDifferent papers are inserted as child nodes of the root node,\n\tthe node_id is the absolute file path (in the recent paper warehouse) of the paper.\n\n\tFor each paper node, TextNodes recording paper contents are stored as its child nodes.\n\tLike:\n\n\t```\n\t\t\t\t\t\t\t\t\t\t\troot_node\n\t\t\t\t\t\t\t\t\t\t/\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t   /\t\t\t\t \\\n\t\t\t\t\t\t\t\t\tPaper1\t\t\t\t\tPaper2\n\t\t\t\t\t\t\t/\t\t...\t\t\t\t\\\n\t\t\t\t\t\tnode_1  \t\t\t\t\tnode_n\n\t```\n\n\tArgs:\n\t\tvector_index (VectorStoreIndex): The vector database storing recent papers.\n\t\tpersist_dir (persist_dir): The persist directory of the vector database.\n\n\tNote:\n\t\tThe metadata `date` and `time` is recorded in a list format for the convenience of metadata filtering.\n\t\tFor example: ['2024-08-10'], ['09:05:03'].\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tvector_index: VectorStoreIndex,\n\t\tpersist_dir: str\n\t):\n\t\troot = Path(__file__)\n\t\tfor idx in range(5):\n\t\t\troot = root.parent\n\t\tself._root = root\n\t\tself.vector_index = vector_index\n\t\tself.vector_index.set_index_id(TMP_PAPER_VECTOR_INDEX_ID)\n\t\tself.persist_dir = persist_dir\n\t\tself._user_id = self.user_id\n\t\tself._fs = fsspec.filesystem(\"file\")\n\n\t@classmethod\n\tdef from_storage(\n\t\tcls,\n\t\tpersist_dir: str,\n\t\tembed_model: BaseEmbedding,\n\t):\n\t\tr\"\"\"\n\t\tLoad from a existing storage.\n\n\t\tArgs:\n\t\t\tpersist_dir (str): The persist directory of the existing storage.\n\t\t\tembed_model (BaseEmbedding): The used embedding model.\n\n\t\tReturns:\n\t\t\tRecentPaperStore\n\t\t\"\"\"\n\t\tvector_storage_context = StorageContext.from_defaults(persist_dir=persist_dir)\n\t\tvector_index = load_index_from_storage(\n\t\t\tstorage_context=vector_storage_context,\n\t\t\tindex_id=TMP_PAPER_VECTOR_INDEX_ID,\n\t\t\tembed_model=embed_model,\n\t\t)\n\t\treturn cls(\n\t\t\tvector_index=vector_index,\n\t\t\tpersist_dir=persist_dir,\n\t\t)\n\n\t@property\n\tdef user_id(self) -&gt; str:\n\t\tr\"\"\" Return the user_id of this RecentPaperStore \"\"\"\n\t\tuser_id = Path(self.persist_dir).relative_to(self._root / TMP_PAPER_VECTOR_INDEX_PERSIST_DIR)\n\t\treturn str(user_id)\n\n\t@classmethod\n\tdef from_user_id(\n\t\tcls,\n\t\tuser_id: str,\n\t\tembed_model: BaseEmbedding,\n\t):\n\t\tr\"\"\"\n\t\tConstruct from a user_id.\n\t\tIf the corresponding persist_dir of the user does not exist, a new RecentPaperStore will be created for the user.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user_id of a Lab member.\n\t\t\tembed_model (BaseEmbedding): The used embedding model.\n\n\t\tReturns:\n\t\t\tRecentPaperStore\n\t\t\"\"\"\n\t\taccount_manager = AccountManager()\n\n\t\tif user_id not in account_manager.get_users():\n\t\t\traise ValueError(f\"Invalid user id: {user_id}.\")\n\n\t\troot = Path(__file__)\n\t\tfor idx in range(5):\n\t\t\troot = root.parent\n\n\t\tfs = fsspec.filesystem(\"file\")\n\t\tpaper_dir = str(root / f\"{TMP_PAPER_WAREHOUSE_DIR}/{user_id}\")\n\t\tif not fs.exists(paper_dir):\n\t\t\tfs.mkdirs(paper_dir)\n\n\t\tpersist_dir = str(root / f\"{TMP_PAPER_VECTOR_INDEX_PERSIST_DIR}/{user_id}\")\n\t\tif fs.exists(persist_dir):\n\t\t\treturn cls.from_storage(\n\t\t\t\tpersist_dir=persist_dir,\n\t\t\t\tembed_model=embed_model,\n\t\t\t)\n\n\t\t# root node\n\t\troot_node = TextNode(\n\t\t\ttext=f\"Root node for the temporary papers of {user_id}\",\n\t\t\tid_=TMP_PAPER_ROOT_NODE_NAME,\n\t\t)\n\t\tnodes = [root_node]\n\t\tvector_index = VectorStoreIndex(\n\t\t\tnodes=nodes,\n\t\t\tembed_model=embed_model,\n\t\t)\n\t\treturn cls(\n\t\t\tvector_index=vector_index,\n\t\t\tpersist_dir=persist_dir,\n\t\t)\n\n\tdef _check_valid_paper(self, paper_file_path: str):\n\t\tr\"\"\" Check whether the paper path is valid. \"\"\"\n\t\tif not self._fs.exists(paper_file_path):\n\t\t\traise ValueError(f\"{paper_file_path} is not a valid file path, it does not exist.\")\n\n\t\tsuffix = Path(paper_file_path).suffix\n\t\tif suffix != \".pdf\":\n\t\t\traise ValueError(f\"Only support .pdf format.\")\n\n\tdef check_valid_paper(self, paper_file_path: str):\n\t\tr\"\"\"\n\t\tCheck whether the paper path is valid or not.\n\n\t\t1. Whether the paper_file_path exists.\n\t\t2. Whether the suffix is `.pdf`.\n\n\t\tArgs:\n\t\t\tpaper_file_path (str): The paper path.\n\n\t\tReturns:\n\t\t\tNone\n\n\t\tRaises:\n\t\t\tValueError: If the paper_file_path is not valid.\n\t\t\"\"\"\n\t\tself._check_valid_paper(paper_file_path=paper_file_path)\n\n\tdef _update_node(\n\t\tself,\n\t\tnode_id: str,\n\t\tnode: BaseNode,\n\t):\n\t\tr\"\"\" Update an existing node in vector index. \"\"\"\n\t\tself.vector_index.delete_nodes([node_id])\n\t\tself.vector_index.insert_nodes([node])\n\n\tdef _delete_nodes(self, node_ids: List[str]):\n\t\tr\"\"\" Delete a node from the vector index. \"\"\"\n\t\tself.vector_index.delete_nodes(node_ids=node_ids)\n\n\tdef _get_node(self, node_id: str) -&gt; BaseNode:\n\t\tr\"\"\" Get a node from the vector index according to node_id. \"\"\"\n\t\treturn self.vector_index.docstore.get_node(node_id)\n\n\tdef _get_nodes(self, node_ids: List[str]) -&gt; List[BaseNode]:\n\t\tr\"\"\" Get nodes from the vector index according to node_ids. \"\"\"\n\t\treturn self.vector_index.docstore.get_nodes(node_ids)\n\n\tdef _default_transformations(self) -&gt; List[TransformComponent]:\n\t\treturn [SentenceSplitter(chunk_size=1024, chunk_overlap=256, include_metadata=True), ]\n\n\tdef file_exists(self, file_path: str) -&gt; bool:\n\t\tr\"\"\"\n\t\tJudge whether a paper exists in the RecentPaperStore according to its filename.\n\n\t\tArgs:\n\t\t\tfile_path (str): The file path of the paper.\n\n\t\tReturns:\n\t\t\tbool: Whether the paper exist or not.\n\t\t\"\"\"\n\t\tfile_name = Path(file_path).name\n\t\tuser_papers_dir = self._root / f\"{TMP_PAPER_WAREHOUSE_DIR}/{self.user_id}\"\n\t\tpaper_file_path = str(user_papers_dir / file_name)\n\n\t\ttry:\n\t\t\tself._get_node(node_id=paper_file_path)\n\t\t\treturn True\n\t\texcept ValueError:\n\t\t\treturn False\n\n\tdef put(self, paper_file_path: str, extra_metadata: dict = None):\n\t\tr\"\"\"\n\t\tput a new paper into the vector index.\n\n\t\tArgs:\n\t\t\tpaper_file_path (str): The absolute path of the paper.\n\t\t\textra_metadata (dict): Extra metadata of the paper.\n\t\t\t\tFor example, if the paper is downloaded from arXiv,\n\t\t\t\tmuch structured information will be provided by the downloader.\n\n\t\tReturns:\n\t\t\tNone\n\t\t\"\"\"\n\t\ttry:\n\t\t\tself._check_valid_paper(paper_file_path=paper_file_path)\n\t\texcept ValueError:\n\t\t\treturn\n\n\t\tfile_name = Path(paper_file_path).name\n\t\tuser_papers_dir = self._root / f\"{TMP_PAPER_WAREHOUSE_DIR}/{self.user_id}\"\n\t\tstore_file_path = str(user_papers_dir / file_name)\n\n\t\ttry:\n\t\t\t_ = self._get_node(node_id=store_file_path)\n\t\t\tprint(f\"{store_file_path} already exists in the temporary papers of user {self._user_id}.\")\n\t\t\treturn\n\t\texcept ValueError:\n\t\t\tpass\n\n\t\tif str(Path(paper_file_path).parent) != str(user_papers_dir):\n\t\t\tself._fs.cp(paper_file_path, str(user_papers_dir))\n\n\t\troot_node = self._get_node(node_id=TMP_PAPER_ROOT_NODE_NAME)\n\t\tpapers = root_node.child_nodes or []\n\n\t\tdate, h_m_s = get_time()\n\t\tpaper_node = TextNode(\n\t\t\tid_=store_file_path,\n\t\t\ttext=f\"The paper {store_file_path}\",\n\t\t\tmetadata={\n\t\t\t\tTMP_PAPER_DATE: [date,],\n\t\t\t\tTMP_PAPER_TIME: [h_m_s,],\n\t\t\t}\n\t\t)\n\t\tpapers.append(RelatedNodeInfo(node_id=paper_node.node_id))\n\t\troot_node.relationships[NodeRelationship.CHILD] = papers\n\t\tself._update_node(node_id=TMP_PAPER_ROOT_NODE_NAME, node=root_node)\n\n\t\t# read the paper:\n\t\treader = SimpleDirectoryReader(\n\t\t\tinput_files=[store_file_path],\n\t\t\tfile_metadata=tmp_paper_get_file_metadata,\n\t\t\tfilename_as_id=True,\n\t\t)\n\t\tdocuments = reader.load_data()\n\n\t\tfor doc in documents:\n\t\t\tself.vector_index.docstore.set_document_hash(doc.get_doc_id(), doc.hash)\n\n\t\tdoc_nodes = run_transformations(\n\t\t\tnodes=documents,\n\t\t\ttransformations=self._default_transformations()\n\t\t)\n\n\t\tchild_nodes = []\n\t\tfor doc_node in doc_nodes:\n\t\t\tchild_nodes.append(RelatedNodeInfo(node_id=doc_node.node_id))\n\t\t\tdoc_node.relationships[NodeRelationship.PARENT] = RelatedNodeInfo(node_id=paper_node.node_id)\n\t\t\tnew_metadata = {\n\t\t\t\tTMP_PAPER_NODE_TYPE_KEY: TMP_PAPER_DOC_NODE_TYPE,\n\t\t\t\tTMP_PAPER_DATE: [date],\n\t\t\t\tTMP_PAPER_TIME: [h_m_s],\n\t\t\t}\n\t\t\tif extra_metadata:\n\t\t\t\tnew_metadata.update(extra_metadata)\n\n\t\t\tdoc_node.metadata.update(new_metadata)\n\t\t\tdoc_node.excluded_llm_metadata_keys.append(TMP_PAPER_NODE_TYPE_KEY)\n\t\t\tdoc_node.excluded_embed_metadata_keys.append(TMP_PAPER_NODE_TYPE_KEY)\n\n\t\tpaper_node.relationships[NodeRelationship.CHILD] = child_nodes\n\t\tnodes = doc_nodes + [paper_node]\n\t\tself.vector_index.insert_nodes(nodes=nodes)\n\n\tdef get_summary_node(self, paper_file_path: str) -&gt; Optional[BaseNode]:\n\t\tr\"\"\"\n\t\tGet the summary node of a paper.\n\n\t\tArgs:\n\t\t\tpaper_file_path (str): The file path of the paper, equally the node_id of the paper_node.\n\n\t\tReturns:\n\t\t\tOptional[BaseNode]: The summary node the paper. If it does not exist, return None.\n\t\t\"\"\"\n\t\tsummary_id = f\"{TMP_PAPER_SUMMARY_NODE_PREFIX}{paper_file_path}\"\n\t\ttry:\n\t\t\tsummary_node = self._get_node(node_id=summary_id)\n\t\t\treturn summary_node\n\t\texcept Exception as e:\n\t\t\tprint(f\"Summary node of {paper_file_path} does not exist. {e}\")\n\t\t\treturn None\n\n\tdef get_paper_node(self, paper_file_path: str) -&gt; Optional[BaseNode]:\n\t\tr\"\"\"\n\t\tGet the paper_node of a paper.\n\n\t\tArgs:\n\t\t\tpaper_file_path (str): The file path of the paper, equally the node_id of the paper_node.\n\n\t\tReturns:\n\t\t\tOptional[BaseNode]: The paper node.\n\n\t\tRaises:\n\t\t\tValueError: If the paper node does not exist.\n\t\t\"\"\"\n\t\tself._check_valid_paper(paper_file_path=paper_file_path)\n\t\ttry:\n\t\t\tpaper_node = self._get_node(node_id=paper_file_path)\n\t\t\treturn paper_node\n\t\texcept Exception:\n\t\t\traise ValueError(f\"{paper_file_path} does not exists in the temporary papers of user {self._user_id}.\")\n\n\tdef insert_summary_node(self, paper_file_path: str, summary_node: TextNode):\n\t\tself._check_valid_paper(paper_file_path=paper_file_path)\n\t\tpaper_node = self.get_paper_node(paper_file_path=paper_file_path)\n\n\t\tsummary_node.id_ = f\"{TMP_PAPER_SUMMARY_NODE_PREFIX}{paper_file_path}\"\n\t\tsummary_node.relationships[NodeRelationship.PARENT] = RelatedNodeInfo(node_id=paper_node.node_id)\n\n\t\tpaper_docs = paper_node.child_nodes\n\t\tpaper_docs.append(\n\t\t\tRelatedNodeInfo(node_id=summary_node.node_id)\n\t\t)\n\t\tdoc_node = self._get_node(node_id=paper_docs[0].node_id)\n\t\tsummary_node.metadata.update(doc_node.metadata)\n\n\t\tpaper_node.relationships[NodeRelationship.CHILD] = paper_docs\n\t\tself._update_node(node_id=paper_node.node_id, node=paper_node)\n\t\tself.vector_index.insert_nodes(nodes=[summary_node])\n\n\tdef get_paper_nodes(self, paper_file_path: str) -&gt; Optional[List[BaseNode]]:\n\t\tr\"\"\"\n\t\tGet the doc nodes of a paper.\n\n\t\tArgs:\n\t\t\tpaper_file_path (str): The file path of the paper, equally the node_id of the paper_node.\n\n\t\tReturns:\n\t\t\tOptional[List[BaseNode]]: The doc nodes of the paper.\n\n\t\tRaises:\n\t\t\tValueError: If the paper does not exist.\n\n\t\t\"\"\"\n\t\tself._check_valid_paper(paper_file_path=paper_file_path)\n\t\tpaper_node = self.get_paper_node(paper_file_path=paper_file_path)\n\t\tdoc_nodes = paper_node.child_nodes\n\t\tdoc_ids = [node.node_id for node in doc_nodes]\n\t\tpaper_nodes = self._get_nodes(node_ids=doc_ids)\n\t\treturn paper_nodes\n\n\tdef get_all_relevant_node_ids(self, node_ids: List[str]) -&gt; Optional[List[str]]:\n\t\tr\"\"\"\n\t\tGet all the ids of the nodes that are belong to the same papers with the input node_ids.\n\n\t\tArgs:\n\t\t\tnode_ids (List[str]): The node ids.\n\n\t\tReturns:\n\t\t\tOptional[List[str]]: The relevant doc nodes. If no relevant node exists, return None.\n\t\t\"\"\"\n\t\tpaper_ids = set()\n\t\tfor node_id in node_ids:\n\t\t\ttry:\n\t\t\t\tnode = self._get_node(node_id=node_id)\n\t\t\t\tpaper_id = node.parent_node.node_id\n\t\t\t\tpaper_ids.add(paper_id)\n\t\t\texcept Exception:\n\t\t\t\tcontinue\n\t\tif len(paper_ids) &lt; 1:\n\t\t\treturn None\n\n\t\tall_ids = []\n\t\tfor paper_id in paper_ids:\n\t\t\tpaper_nodes = self.get_paper_nodes(paper_file_path=paper_id)\n\t\t\tall_ids.extend([node.node_id for node in paper_nodes])\n\t\treturn all_ids\n\n\tdef delete(self, paper_file_path: str):\n\t\tr\"\"\"\n\t\tDelete a paper from the recent paper vector index and the recent paper warehouse.\n\n\t\tArgs:\n\t\t\tpaper_file_path (str): The file path of the paper, equally the node_id of the paper_node.\n\t\t\"\"\"\n\t\tself._check_valid_paper(paper_file_path=paper_file_path)\n\t\tpaper_node = self.get_paper_node(paper_file_path=paper_file_path)\n\t\tdoc_nodes = paper_node.child_nodes\n\t\tdelete_ids = [paper_node.node_id]\n\t\tdelete_ids.extend([doc_node.node_id for doc_node in doc_nodes])\n\t\tself._delete_nodes(node_ids=delete_ids)\n\n\t\troot_node = self._get_node(node_id=TMP_PAPER_ROOT_NODE_NAME)\n\t\tpapers = root_node.child_nodes\n\t\tfor paper in papers:\n\t\t\tif paper.node_id == paper_file_path:\n\t\t\t\tpapers.remove(paper)\n\t\troot_node.relationships[NodeRelationship.CHILD] = papers\n\t\tself._update_node(node_id=TMP_PAPER_ROOT_NODE_NAME, node=root_node)\n\t\ttry:\n\t\t\tPath(paper_file_path).relative_to(TMP_PAPER_WAREHOUSE_DIR)\n\t\t\tself._fs.rm(paper_file_path)\n\t\texcept ValueError:\n\t\t\tpass\n\n\tdef persist(self, persist_dir: str = None):\n\t\tr\"\"\"\n\t\tPersis to the disk.\n\n\t\tArgs:\n\t\t\tpersist_dir (str): The save directory. Defaults to `self.persist_dir`\n\t\t\"\"\"\n\t\tpersist_dir = persist_dir or self.persist_dir\n\t\tif not self._fs.exists(persist_dir):\n\t\t\tself._fs.makedirs(persist_dir)\n\t\tself.vector_index.storage_context.persist(persist_dir=persist_dir)\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/temporary_store/#labridge.func_modules.paper.store.temporary_store.RecentPaperStore.user_id","title":"<code>labridge.func_modules.paper.store.temporary_store.RecentPaperStore.user_id: str</code>  <code>property</code>","text":"<p>Return the user_id of this RecentPaperStore</p>"},{"location":"code_docs/func_modules/paper/store/temporary_store/#labridge.func_modules.paper.store.temporary_store.RecentPaperStore.check_valid_paper","title":"<code>labridge.func_modules.paper.store.temporary_store.RecentPaperStore.check_valid_paper(paper_file_path)</code>","text":"<p>Check whether the paper path is valid or not.</p> <ol> <li>Whether the paper_file_path exists.</li> <li>Whether the suffix is <code>.pdf</code>.</li> </ol> PARAMETER DESCRIPTION <code>paper_file_path</code> <p>The paper path.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <p>None</p> RAISES DESCRIPTION <code>ValueError</code> <p>If the paper_file_path is not valid.</p> Source code in <code>labridge\\func_modules\\paper\\store\\temporary_store.py</code> <pre><code>def check_valid_paper(self, paper_file_path: str):\n\tr\"\"\"\n\tCheck whether the paper path is valid or not.\n\n\t1. Whether the paper_file_path exists.\n\t2. Whether the suffix is `.pdf`.\n\n\tArgs:\n\t\tpaper_file_path (str): The paper path.\n\n\tReturns:\n\t\tNone\n\n\tRaises:\n\t\tValueError: If the paper_file_path is not valid.\n\t\"\"\"\n\tself._check_valid_paper(paper_file_path=paper_file_path)\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/temporary_store/#labridge.func_modules.paper.store.temporary_store.RecentPaperStore.delete","title":"<code>labridge.func_modules.paper.store.temporary_store.RecentPaperStore.delete(paper_file_path)</code>","text":"<p>Delete a paper from the recent paper vector index and the recent paper warehouse.</p> PARAMETER DESCRIPTION <code>paper_file_path</code> <p>The file path of the paper, equally the node_id of the paper_node.</p> <p> TYPE: <code>str</code> </p> Source code in <code>labridge\\func_modules\\paper\\store\\temporary_store.py</code> <pre><code>def delete(self, paper_file_path: str):\n\tr\"\"\"\n\tDelete a paper from the recent paper vector index and the recent paper warehouse.\n\n\tArgs:\n\t\tpaper_file_path (str): The file path of the paper, equally the node_id of the paper_node.\n\t\"\"\"\n\tself._check_valid_paper(paper_file_path=paper_file_path)\n\tpaper_node = self.get_paper_node(paper_file_path=paper_file_path)\n\tdoc_nodes = paper_node.child_nodes\n\tdelete_ids = [paper_node.node_id]\n\tdelete_ids.extend([doc_node.node_id for doc_node in doc_nodes])\n\tself._delete_nodes(node_ids=delete_ids)\n\n\troot_node = self._get_node(node_id=TMP_PAPER_ROOT_NODE_NAME)\n\tpapers = root_node.child_nodes\n\tfor paper in papers:\n\t\tif paper.node_id == paper_file_path:\n\t\t\tpapers.remove(paper)\n\troot_node.relationships[NodeRelationship.CHILD] = papers\n\tself._update_node(node_id=TMP_PAPER_ROOT_NODE_NAME, node=root_node)\n\ttry:\n\t\tPath(paper_file_path).relative_to(TMP_PAPER_WAREHOUSE_DIR)\n\t\tself._fs.rm(paper_file_path)\n\texcept ValueError:\n\t\tpass\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/temporary_store/#labridge.func_modules.paper.store.temporary_store.RecentPaperStore.file_exists","title":"<code>labridge.func_modules.paper.store.temporary_store.RecentPaperStore.file_exists(file_path)</code>","text":"<p>Judge whether a paper exists in the RecentPaperStore according to its filename.</p> PARAMETER DESCRIPTION <code>file_path</code> <p>The file path of the paper.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>Whether the paper exist or not.</p> <p> TYPE: <code>bool</code> </p> Source code in <code>labridge\\func_modules\\paper\\store\\temporary_store.py</code> <pre><code>def file_exists(self, file_path: str) -&gt; bool:\n\tr\"\"\"\n\tJudge whether a paper exists in the RecentPaperStore according to its filename.\n\n\tArgs:\n\t\tfile_path (str): The file path of the paper.\n\n\tReturns:\n\t\tbool: Whether the paper exist or not.\n\t\"\"\"\n\tfile_name = Path(file_path).name\n\tuser_papers_dir = self._root / f\"{TMP_PAPER_WAREHOUSE_DIR}/{self.user_id}\"\n\tpaper_file_path = str(user_papers_dir / file_name)\n\n\ttry:\n\t\tself._get_node(node_id=paper_file_path)\n\t\treturn True\n\texcept ValueError:\n\t\treturn False\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/temporary_store/#labridge.func_modules.paper.store.temporary_store.RecentPaperStore.from_storage","title":"<code>labridge.func_modules.paper.store.temporary_store.RecentPaperStore.from_storage(persist_dir, embed_model)</code>  <code>classmethod</code>","text":"<p>Load from a existing storage.</p> PARAMETER DESCRIPTION <code>persist_dir</code> <p>The persist directory of the existing storage.</p> <p> TYPE: <code>str</code> </p> <code>embed_model</code> <p>The used embedding model.</p> <p> TYPE: <code>BaseEmbedding</code> </p> RETURNS DESCRIPTION <p>RecentPaperStore</p> Source code in <code>labridge\\func_modules\\paper\\store\\temporary_store.py</code> <pre><code>@classmethod\ndef from_storage(\n\tcls,\n\tpersist_dir: str,\n\tembed_model: BaseEmbedding,\n):\n\tr\"\"\"\n\tLoad from a existing storage.\n\n\tArgs:\n\t\tpersist_dir (str): The persist directory of the existing storage.\n\t\tembed_model (BaseEmbedding): The used embedding model.\n\n\tReturns:\n\t\tRecentPaperStore\n\t\"\"\"\n\tvector_storage_context = StorageContext.from_defaults(persist_dir=persist_dir)\n\tvector_index = load_index_from_storage(\n\t\tstorage_context=vector_storage_context,\n\t\tindex_id=TMP_PAPER_VECTOR_INDEX_ID,\n\t\tembed_model=embed_model,\n\t)\n\treturn cls(\n\t\tvector_index=vector_index,\n\t\tpersist_dir=persist_dir,\n\t)\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/temporary_store/#labridge.func_modules.paper.store.temporary_store.RecentPaperStore.from_user_id","title":"<code>labridge.func_modules.paper.store.temporary_store.RecentPaperStore.from_user_id(user_id, embed_model)</code>  <code>classmethod</code>","text":"<p>Construct from a user_id. If the corresponding persist_dir of the user does not exist, a new RecentPaperStore will be created for the user.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user_id of a Lab member.</p> <p> TYPE: <code>str</code> </p> <code>embed_model</code> <p>The used embedding model.</p> <p> TYPE: <code>BaseEmbedding</code> </p> RETURNS DESCRIPTION <p>RecentPaperStore</p> Source code in <code>labridge\\func_modules\\paper\\store\\temporary_store.py</code> <pre><code>@classmethod\ndef from_user_id(\n\tcls,\n\tuser_id: str,\n\tembed_model: BaseEmbedding,\n):\n\tr\"\"\"\n\tConstruct from a user_id.\n\tIf the corresponding persist_dir of the user does not exist, a new RecentPaperStore will be created for the user.\n\n\tArgs:\n\t\tuser_id (str): The user_id of a Lab member.\n\t\tembed_model (BaseEmbedding): The used embedding model.\n\n\tReturns:\n\t\tRecentPaperStore\n\t\"\"\"\n\taccount_manager = AccountManager()\n\n\tif user_id not in account_manager.get_users():\n\t\traise ValueError(f\"Invalid user id: {user_id}.\")\n\n\troot = Path(__file__)\n\tfor idx in range(5):\n\t\troot = root.parent\n\n\tfs = fsspec.filesystem(\"file\")\n\tpaper_dir = str(root / f\"{TMP_PAPER_WAREHOUSE_DIR}/{user_id}\")\n\tif not fs.exists(paper_dir):\n\t\tfs.mkdirs(paper_dir)\n\n\tpersist_dir = str(root / f\"{TMP_PAPER_VECTOR_INDEX_PERSIST_DIR}/{user_id}\")\n\tif fs.exists(persist_dir):\n\t\treturn cls.from_storage(\n\t\t\tpersist_dir=persist_dir,\n\t\t\tembed_model=embed_model,\n\t\t)\n\n\t# root node\n\troot_node = TextNode(\n\t\ttext=f\"Root node for the temporary papers of {user_id}\",\n\t\tid_=TMP_PAPER_ROOT_NODE_NAME,\n\t)\n\tnodes = [root_node]\n\tvector_index = VectorStoreIndex(\n\t\tnodes=nodes,\n\t\tembed_model=embed_model,\n\t)\n\treturn cls(\n\t\tvector_index=vector_index,\n\t\tpersist_dir=persist_dir,\n\t)\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/temporary_store/#labridge.func_modules.paper.store.temporary_store.RecentPaperStore.get_all_relevant_node_ids","title":"<code>labridge.func_modules.paper.store.temporary_store.RecentPaperStore.get_all_relevant_node_ids(node_ids)</code>","text":"<p>Get all the ids of the nodes that are belong to the same papers with the input node_ids.</p> PARAMETER DESCRIPTION <code>node_ids</code> <p>The node ids.</p> <p> TYPE: <code>List[str]</code> </p> RETURNS DESCRIPTION <code>Optional[List[str]]</code> <p>Optional[List[str]]: The relevant doc nodes. If no relevant node exists, return None.</p> Source code in <code>labridge\\func_modules\\paper\\store\\temporary_store.py</code> <pre><code>def get_all_relevant_node_ids(self, node_ids: List[str]) -&gt; Optional[List[str]]:\n\tr\"\"\"\n\tGet all the ids of the nodes that are belong to the same papers with the input node_ids.\n\n\tArgs:\n\t\tnode_ids (List[str]): The node ids.\n\n\tReturns:\n\t\tOptional[List[str]]: The relevant doc nodes. If no relevant node exists, return None.\n\t\"\"\"\n\tpaper_ids = set()\n\tfor node_id in node_ids:\n\t\ttry:\n\t\t\tnode = self._get_node(node_id=node_id)\n\t\t\tpaper_id = node.parent_node.node_id\n\t\t\tpaper_ids.add(paper_id)\n\t\texcept Exception:\n\t\t\tcontinue\n\tif len(paper_ids) &lt; 1:\n\t\treturn None\n\n\tall_ids = []\n\tfor paper_id in paper_ids:\n\t\tpaper_nodes = self.get_paper_nodes(paper_file_path=paper_id)\n\t\tall_ids.extend([node.node_id for node in paper_nodes])\n\treturn all_ids\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/temporary_store/#labridge.func_modules.paper.store.temporary_store.RecentPaperStore.get_paper_node","title":"<code>labridge.func_modules.paper.store.temporary_store.RecentPaperStore.get_paper_node(paper_file_path)</code>","text":"<p>Get the paper_node of a paper.</p> PARAMETER DESCRIPTION <code>paper_file_path</code> <p>The file path of the paper, equally the node_id of the paper_node.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Optional[BaseNode]</code> <p>Optional[BaseNode]: The paper node.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If the paper node does not exist.</p> Source code in <code>labridge\\func_modules\\paper\\store\\temporary_store.py</code> <pre><code>def get_paper_node(self, paper_file_path: str) -&gt; Optional[BaseNode]:\n\tr\"\"\"\n\tGet the paper_node of a paper.\n\n\tArgs:\n\t\tpaper_file_path (str): The file path of the paper, equally the node_id of the paper_node.\n\n\tReturns:\n\t\tOptional[BaseNode]: The paper node.\n\n\tRaises:\n\t\tValueError: If the paper node does not exist.\n\t\"\"\"\n\tself._check_valid_paper(paper_file_path=paper_file_path)\n\ttry:\n\t\tpaper_node = self._get_node(node_id=paper_file_path)\n\t\treturn paper_node\n\texcept Exception:\n\t\traise ValueError(f\"{paper_file_path} does not exists in the temporary papers of user {self._user_id}.\")\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/temporary_store/#labridge.func_modules.paper.store.temporary_store.RecentPaperStore.get_paper_nodes","title":"<code>labridge.func_modules.paper.store.temporary_store.RecentPaperStore.get_paper_nodes(paper_file_path)</code>","text":"<p>Get the doc nodes of a paper.</p> PARAMETER DESCRIPTION <code>paper_file_path</code> <p>The file path of the paper, equally the node_id of the paper_node.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Optional[List[BaseNode]]</code> <p>Optional[List[BaseNode]]: The doc nodes of the paper.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If the paper does not exist.</p> Source code in <code>labridge\\func_modules\\paper\\store\\temporary_store.py</code> <pre><code>def get_paper_nodes(self, paper_file_path: str) -&gt; Optional[List[BaseNode]]:\n\tr\"\"\"\n\tGet the doc nodes of a paper.\n\n\tArgs:\n\t\tpaper_file_path (str): The file path of the paper, equally the node_id of the paper_node.\n\n\tReturns:\n\t\tOptional[List[BaseNode]]: The doc nodes of the paper.\n\n\tRaises:\n\t\tValueError: If the paper does not exist.\n\n\t\"\"\"\n\tself._check_valid_paper(paper_file_path=paper_file_path)\n\tpaper_node = self.get_paper_node(paper_file_path=paper_file_path)\n\tdoc_nodes = paper_node.child_nodes\n\tdoc_ids = [node.node_id for node in doc_nodes]\n\tpaper_nodes = self._get_nodes(node_ids=doc_ids)\n\treturn paper_nodes\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/temporary_store/#labridge.func_modules.paper.store.temporary_store.RecentPaperStore.get_summary_node","title":"<code>labridge.func_modules.paper.store.temporary_store.RecentPaperStore.get_summary_node(paper_file_path)</code>","text":"<p>Get the summary node of a paper.</p> PARAMETER DESCRIPTION <code>paper_file_path</code> <p>The file path of the paper, equally the node_id of the paper_node.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Optional[BaseNode]</code> <p>Optional[BaseNode]: The summary node the paper. If it does not exist, return None.</p> Source code in <code>labridge\\func_modules\\paper\\store\\temporary_store.py</code> <pre><code>def get_summary_node(self, paper_file_path: str) -&gt; Optional[BaseNode]:\n\tr\"\"\"\n\tGet the summary node of a paper.\n\n\tArgs:\n\t\tpaper_file_path (str): The file path of the paper, equally the node_id of the paper_node.\n\n\tReturns:\n\t\tOptional[BaseNode]: The summary node the paper. If it does not exist, return None.\n\t\"\"\"\n\tsummary_id = f\"{TMP_PAPER_SUMMARY_NODE_PREFIX}{paper_file_path}\"\n\ttry:\n\t\tsummary_node = self._get_node(node_id=summary_id)\n\t\treturn summary_node\n\texcept Exception as e:\n\t\tprint(f\"Summary node of {paper_file_path} does not exist. {e}\")\n\t\treturn None\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/temporary_store/#labridge.func_modules.paper.store.temporary_store.RecentPaperStore.persist","title":"<code>labridge.func_modules.paper.store.temporary_store.RecentPaperStore.persist(persist_dir=None)</code>","text":"<p>Persis to the disk.</p> PARAMETER DESCRIPTION <code>persist_dir</code> <p>The save directory. Defaults to <code>self.persist_dir</code></p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> Source code in <code>labridge\\func_modules\\paper\\store\\temporary_store.py</code> <pre><code>def persist(self, persist_dir: str = None):\n\tr\"\"\"\n\tPersis to the disk.\n\n\tArgs:\n\t\tpersist_dir (str): The save directory. Defaults to `self.persist_dir`\n\t\"\"\"\n\tpersist_dir = persist_dir or self.persist_dir\n\tif not self._fs.exists(persist_dir):\n\t\tself._fs.makedirs(persist_dir)\n\tself.vector_index.storage_context.persist(persist_dir=persist_dir)\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/temporary_store/#labridge.func_modules.paper.store.temporary_store.RecentPaperStore.put","title":"<code>labridge.func_modules.paper.store.temporary_store.RecentPaperStore.put(paper_file_path, extra_metadata=None)</code>","text":"<p>put a new paper into the vector index.</p> PARAMETER DESCRIPTION <code>paper_file_path</code> <p>The absolute path of the paper.</p> <p> TYPE: <code>str</code> </p> <code>extra_metadata</code> <p>Extra metadata of the paper. For example, if the paper is downloaded from arXiv, much structured information will be provided by the downloader.</p> <p> TYPE: <code>dict</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <p>None</p> Source code in <code>labridge\\func_modules\\paper\\store\\temporary_store.py</code> <pre><code>def put(self, paper_file_path: str, extra_metadata: dict = None):\n\tr\"\"\"\n\tput a new paper into the vector index.\n\n\tArgs:\n\t\tpaper_file_path (str): The absolute path of the paper.\n\t\textra_metadata (dict): Extra metadata of the paper.\n\t\t\tFor example, if the paper is downloaded from arXiv,\n\t\t\tmuch structured information will be provided by the downloader.\n\n\tReturns:\n\t\tNone\n\t\"\"\"\n\ttry:\n\t\tself._check_valid_paper(paper_file_path=paper_file_path)\n\texcept ValueError:\n\t\treturn\n\n\tfile_name = Path(paper_file_path).name\n\tuser_papers_dir = self._root / f\"{TMP_PAPER_WAREHOUSE_DIR}/{self.user_id}\"\n\tstore_file_path = str(user_papers_dir / file_name)\n\n\ttry:\n\t\t_ = self._get_node(node_id=store_file_path)\n\t\tprint(f\"{store_file_path} already exists in the temporary papers of user {self._user_id}.\")\n\t\treturn\n\texcept ValueError:\n\t\tpass\n\n\tif str(Path(paper_file_path).parent) != str(user_papers_dir):\n\t\tself._fs.cp(paper_file_path, str(user_papers_dir))\n\n\troot_node = self._get_node(node_id=TMP_PAPER_ROOT_NODE_NAME)\n\tpapers = root_node.child_nodes or []\n\n\tdate, h_m_s = get_time()\n\tpaper_node = TextNode(\n\t\tid_=store_file_path,\n\t\ttext=f\"The paper {store_file_path}\",\n\t\tmetadata={\n\t\t\tTMP_PAPER_DATE: [date,],\n\t\t\tTMP_PAPER_TIME: [h_m_s,],\n\t\t}\n\t)\n\tpapers.append(RelatedNodeInfo(node_id=paper_node.node_id))\n\troot_node.relationships[NodeRelationship.CHILD] = papers\n\tself._update_node(node_id=TMP_PAPER_ROOT_NODE_NAME, node=root_node)\n\n\t# read the paper:\n\treader = SimpleDirectoryReader(\n\t\tinput_files=[store_file_path],\n\t\tfile_metadata=tmp_paper_get_file_metadata,\n\t\tfilename_as_id=True,\n\t)\n\tdocuments = reader.load_data()\n\n\tfor doc in documents:\n\t\tself.vector_index.docstore.set_document_hash(doc.get_doc_id(), doc.hash)\n\n\tdoc_nodes = run_transformations(\n\t\tnodes=documents,\n\t\ttransformations=self._default_transformations()\n\t)\n\n\tchild_nodes = []\n\tfor doc_node in doc_nodes:\n\t\tchild_nodes.append(RelatedNodeInfo(node_id=doc_node.node_id))\n\t\tdoc_node.relationships[NodeRelationship.PARENT] = RelatedNodeInfo(node_id=paper_node.node_id)\n\t\tnew_metadata = {\n\t\t\tTMP_PAPER_NODE_TYPE_KEY: TMP_PAPER_DOC_NODE_TYPE,\n\t\t\tTMP_PAPER_DATE: [date],\n\t\t\tTMP_PAPER_TIME: [h_m_s],\n\t\t}\n\t\tif extra_metadata:\n\t\t\tnew_metadata.update(extra_metadata)\n\n\t\tdoc_node.metadata.update(new_metadata)\n\t\tdoc_node.excluded_llm_metadata_keys.append(TMP_PAPER_NODE_TYPE_KEY)\n\t\tdoc_node.excluded_embed_metadata_keys.append(TMP_PAPER_NODE_TYPE_KEY)\n\n\tpaper_node.relationships[NodeRelationship.CHILD] = child_nodes\n\tnodes = doc_nodes + [paper_node]\n\tself.vector_index.insert_nodes(nodes=nodes)\n</code></pre>"},{"location":"code_docs/func_modules/paper/store/temporary_store/#labridge.func_modules.paper.store.temporary_store.tmp_paper_get_file_metadata","title":"<code>labridge.func_modules.paper.store.temporary_store.tmp_paper_get_file_metadata(file_path)</code>","text":"<p>Record these metadata in each doc node:</p> <ul> <li>the absolute file path of the paper.</li> <li>the date when the file is put in.</li> <li>the time when the file is put in.</li> </ul> Source code in <code>labridge\\func_modules\\paper\\store\\temporary_store.py</code> <pre><code>def tmp_paper_get_file_metadata(file_path: str) -&gt; Dict[str, Any]:\n\tr\"\"\"\n\tRecord these metadata in each doc node:\n\n\t- the absolute file path of the paper.\n\t- the date when the file is put in.\n\t- the time when the file is put in.\n\t\"\"\"\n\tdate, h_m_s = get_time()\n\tmetadata = {\n\t\tTMP_PAPER_FILE_PATH_KEY: file_path,\n\t\tTMP_PAPER_DATE: [date,],\n\t\tTMP_PAPER_TIME: [h_m_s,],\n\t}\n\treturn metadata\n</code></pre>"},{"location":"code_docs/func_modules/paper/synthesizer/summarize/","title":"Summarize","text":""},{"location":"code_docs/func_modules/paper/synthesizer/summarize/#labridge.func_modules.paper.synthesizer.summarize","title":"<code>labridge.func_modules.paper.synthesizer.summarize</code>","text":""},{"location":"code_docs/func_modules/paper/synthesizer/summarize/#labridge.func_modules.paper.synthesizer.summarize.PaperBatchSummarize","title":"<code>labridge.func_modules.paper.synthesizer.summarize.PaperBatchSummarize</code>","text":"<p>               Bases: <code>BaseSynthesizer</code></p> <p>Summarize a paper in a batch style (Because of the video memory limits).</p> <ul> <li>Firstly, the paper contents are seperated into overlapped batches, with no batch exceeds the max_tokens.</li> <li>The batch contents are then summarized individually.</li> <li>Finally, those summaries are summarized to get the summary of the paper.</li> </ul> PARAMETER DESCRIPTION <code>llm</code> <p>The used LLM.</p> <p> TYPE: <code>LLM</code> DEFAULT: <code>None</code> </p> <code>max_tokens</code> <p>The max_tokens of a batch, set a proper value according to the video memory size.</p> <p> TYPE: <code>int</code> DEFAULT: <code>SUMMARIZE_MAX_TOKENS</code> </p> <code>overlap_chunk_num</code> <p>The overlap chunks between two adjacent batches.</p> <p> TYPE: <code>int</code> DEFAULT: <code>SUMMARIZE_OVERLAP_CHUNK_NUM</code> </p> <code>summary_query</code> <p>The summary prompt in the batch summary.</p> <p> TYPE: <code>str</code> DEFAULT: <code>PAPER_SUMMARIZE_QUERY</code> </p> <code>secondary_query</code> <p>The summary prompt in the final summary.</p> <p> TYPE: <code>str</code> DEFAULT: <code>PAPER_SECONDARY_SUMMARIZE_QUERY</code> </p> Source code in <code>labridge\\func_modules\\paper\\synthesizer\\summarize.py</code> <pre><code>class PaperBatchSummarize(BaseSynthesizer):\n\tr\"\"\"\n\tSummarize a paper in a batch style (Because of the video memory limits).\n\n\t- Firstly, the paper contents are seperated into overlapped batches, with no batch exceeds the max_tokens.\n\t- The batch contents are then summarized individually.\n\t- Finally, those summaries are summarized to get the summary of the paper.\n\n\tArgs:\n\t\tllm (LLM): The used LLM.\n\t\tmax_tokens (int): The max_tokens of a batch, set a proper value according to the video memory size.\n\t\toverlap_chunk_num (int): The overlap chunks between two adjacent batches.\n\t\tsummary_query (str): The summary prompt in the batch summary.\n\t\tsecondary_query (str): The summary prompt in the final summary.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tllm: LLM = None,\n\t\tmax_tokens: int = SUMMARIZE_MAX_TOKENS,\n\t\toverlap_chunk_num: int = SUMMARIZE_OVERLAP_CHUNK_NUM,\n\t\tsummary_query: str = PAPER_SUMMARIZE_QUERY,\n\t\tsecondary_query: str = PAPER_SECONDARY_SUMMARIZE_QUERY,\n\t):\n\t\tsuper().__init__(llm=llm)\n\t\tself._summary_template = DEFAULT_TREE_SUMMARIZE_PROMPT_SEL\n\t\tself._synthesizer = get_response_synthesizer(\n\t\t\tllm=self._llm,\n\t\t\tresponse_mode=ResponseMode.TREE_SUMMARIZE,\n\t\t)\n\t\tself._tokenizer = global_tokenizer or get_tokenizer()\n\t\tself._max_tokens = max_tokens\n\t\tself._overlap_chunk_num = overlap_chunk_num\n\t\tself._summary_query = summary_query\n\t\tself._secondary_query = secondary_query\n\n\n\t@property\n\tdef summary_query(self) -&gt; str:\n\t\treturn self._summary_query\n\n\t@summary_query.setter\n\tdef summary_query(self, value: str):\n\t\tself._summary_query = value\n\n\t@property\n\tdef secondary_query(self) -&gt; str:\n\t\treturn self._secondary_query\n\n\t@secondary_query.setter\n\tdef secondary_query(self, value: str):\n\t\tself._secondary_query = value\n\n\tdef _get_prompts(self) -&gt; PromptDictType:\n\t\t\"\"\"Get prompts.\"\"\"\n\t\treturn {\"summary_template\": self._summary_template}\n\n\tdef _update_prompts(self, prompts: PromptDictType) -&gt; None:\n\t\t\"\"\" Update prompts.\"\"\"\n\t\tif \"summary_template\" in prompts:\n\t\t\tself._summary_template = prompts[\"summary_template\"]\n\n\tdef _calculate_batch_size(self, text_chunks: Sequence[str]) -&gt; Tuple[bool, int]:\n\t\tr\"\"\"\n\t\tDecide whether to use batch mode and the batch size, according to the `text_chunks` and `self.max_tokens`.\n\n\t\tArgs:\n\t\t\ttext_chunks (Sequence[str]): The chunks of a paper.\n\n\t\tReturns:\n\t\t\tTuple[bool, int]:\n\t\t\t\t- batch_mode (bool): Whether to use batch summarize.\n\t\t\t\t- batch_size (int): Batch size in batch summarizing.\n\t\t\"\"\"\n\t\ttoken_num, max_node_tokens = 0, 0\n\t\tbatch_mode = False\n\t\tfor chunk in text_chunks:\n\t\t\ttokens = len(\n\t\t\t\tself._tokenizer(chunk)\n\t\t\t)\n\t\t\ttoken_num += tokens\n\t\t\tmax_node_tokens = max(tokens, max_node_tokens)\n\n\t\tif token_num &lt; self._max_tokens:\n\t\t\treturn batch_mode, 0\n\n\t\tbatch_mode = True\n\t\tbatch_size = self._max_tokens // max_node_tokens\n\t\treturn batch_mode, batch_size\n\n\tdef batch_chunks(self, text_chunks: Sequence[str], batch_size: int):\n\t\tr\"\"\"\n\t\tYield batch chunks according to the `batch_size` and `self._overlap_chunk_num`.\n\n\t\tArgs:\n\t\t\ttext_chunks (Sequence[str]): The chunks of a paper.\n\t\t\tbatch_size (int): The calculated batch size.\n\n\t\tReturns:\n\t\t\tSequence[str]: A batch.\n\t\t\"\"\"\n\t\tn = len(text_chunks)\n\t\tfor start in range(0, n, batch_size - self._overlap_chunk_num):\n\t\t\tyield text_chunks[start: start + batch_size]\n\n\tdef batch_get_response(self, batch_chunks: Sequence[str], query_str: str) -&gt; RESPONSE_TEXT_TYPE:\n\t\tr\"\"\"\n\t\tBatch summarize.\n\n\t\tArgs:\n\t\t\tbatch_chunks (Sequence[str]): A batch of chunks.\n\t\t\tquery_str (str): The batch query prompt.\n\n\t\tReturns:\n\t\t\tRESPONSE_TEXT_TYPE: The summary.\n\t\t\"\"\"\n\t\tsummary_template = self._summary_template.partial_format(query_str=query_str)\n\t\tresponse = self._llm.predict(\n\t\t\tsummary_template,\n\t\t\tcontext_str=\"\\n\".join(batch_chunks),\n\t\t)\n\t\treturn response\n\n\tasync def abatch_get_response(self, batch_chunks: Sequence[str], query_str: str) -&gt; RESPONSE_TEXT_TYPE:\n\t\tr\"\"\"\n\t\tAsynchronously batch summarize.\n\n\t\tArgs:\n\t\t\tbatch_chunks (Sequence[str]): A batch of chunks.\n\t\t\tquery_str (str): The batch query prompt.\n\n\t\tReturns:\n\t\t\tRESPONSE_TEXT_TYPE: The summary.\n\t\t\"\"\"\n\t\tsummary_template = self._summary_template.partial_format(query_str=query_str)\n\t\tresponse = await self._llm.apredict(\n\t\t\tsummary_template,\n\t\t\tcontext_str=\"\\n\".join(batch_chunks),\n\t\t)\n\t\treturn response\n\n\tdef get_response(\n        self,\n        query_str: str,\n        text_chunks: Sequence[str],\n        **response_kwargs: Any,\n    ) -&gt; RESPONSE_TEXT_TYPE:\n\t\tr\"\"\"\n\t\tSummarize a paper.\n\n\t\tArgs:\n\t\t\tquery_str (str): Not used.\n\t\t\ttext_chunks (Sequence[str]): The text chunks of a paper.\n\t\t\t**response_kwargs (Any): Not used.\n\n\t\tReturns:\n\t\t\tRESPONSE_TEXT_TYPE: The summary.\n\t\t\"\"\"\n\t\tbatch_mode, batch_size = self._calculate_batch_size(text_chunks=text_chunks)\n\n\t\tprint(\"summary batch size: \", batch_size)\n\t\tprint(\"Total chunks: \", len(text_chunks))\n\t\tprint(text_chunks[0])\n\t\tif not batch_mode:\n\t\t\treturn self.batch_get_response(\n\t\t\t\tbatch_chunks=text_chunks,\n\t\t\t\tquery_str=self.summary_query,\n\t\t\t)\n\n\t\tsummary_texts = []\n\t\tfor chunks in self.batch_chunks(text_chunks=text_chunks, batch_size=batch_size):\n\n\n\t\t\tresponse = self.batch_get_response(\n\t\t\t\tbatch_chunks=chunks,\n\t\t\t\tquery_str=self.summary_query\n\t\t\t)\n\t\t\tsummary_texts.append(response)\n\n\t\tfinal_response = self.batch_get_response(\n\t\t\tbatch_chunks=summary_texts,\n\t\t\tquery_str=self.secondary_query,\n\t\t)\n\t\treturn final_response\n\n\tasync def aget_response(\n        self,\n        query_str: str,\n        text_chunks: Sequence[str],\n        **response_kwargs: Any,\n    ) -&gt; RESPONSE_TEXT_TYPE:\n\t\tr\"\"\"\n\t\tSummarize a paper.\n\n\t\tArgs:\n\t\t\tquery_str (str): Not used.\n\t\t\ttext_chunks (Sequence[str]): The text chunks of a paper.\n\t\t\t**response_kwargs (Any): Not used.\n\n\t\tReturns:\n\t\t\tRESPONSE_TEXT_TYPE: The summary.\n\t\t\"\"\"\n\t\tbatch_mode, batch_size = self._calculate_batch_size(text_chunks=text_chunks)\n\t\tif not batch_mode:\n\t\t\treturn await self.abatch_get_response(\n\t\t\t\tbatch_chunks=text_chunks,\n\t\t\t\tquery_str=self.summary_query,\n\t\t\t)\n\n\t\ttasks = [\n\t\t\tself.abatch_get_response(\n\t\t\t\tbatch_chunks=batch_chunks,\n\t\t\t\tquery_str=self.summary_query,\n\t\t\t) for batch_chunks in self.batch_chunks(text_chunks=text_chunks, batch_size=batch_size)\n\t\t]\n\n\t\tsummary_texts = await asyncio.gather(*tasks)\n\n\t\tfinal_response = self.batch_get_response(\n\t\t\tbatch_chunks=summary_texts,\n\t\t\tquery_str=self.secondary_query,\n\t\t)\n\t\treturn final_response\n\n\t@dispatcher.span\n\tdef synthesize(self, query: QueryType, nodes: List[NodeWithScore],\n\t\tadditional_source_nodes: Optional[Sequence[NodeWithScore]] = None, **response_kwargs: Any, ) -&gt; RESPONSE_TYPE:\n\t\tdispatcher.event(SynthesizeStartEvent(query=query, ))\n\n\t\tif len(nodes) == 0:\n\t\t\tif self._streaming:\n\t\t\t\tempty_response = StreamingResponse(response_gen=empty_response_generator())\n\t\t\t\tdispatcher.event(SynthesizeEndEvent(query=query, response=empty_response, ))\n\t\t\t\treturn empty_response\n\t\t\telse:\n\t\t\t\tempty_response = Response(\"Empty Response\")\n\t\t\t\tdispatcher.event(SynthesizeEndEvent(query=query, response=empty_response, ))\n\t\t\t\treturn empty_response\n\n\t\tif isinstance(query, str):\n\t\t\tquery = QueryBundle(query_str=query)\n\n\t\twith self._callback_manager.event(CBEventType.SYNTHESIZE,\n\t\t\t\tpayload={EventPayload.QUERY_STR: query.query_str}, ) as event:\n\t\t\tresponse_str = self.get_response(query_str=query.query_str,\n\t\t\t\ttext_chunks=[n.node.get_content(metadata_mode=MetadataMode.NONE) for n in nodes], **response_kwargs, )\n\n\t\t\tadditional_source_nodes = additional_source_nodes or []\n\t\t\tsource_nodes = list(nodes) + list(additional_source_nodes)\n\n\t\t\tresponse = self._prepare_response_output(response_str, source_nodes)\n\n\t\t\tevent.on_end(payload={EventPayload.RESPONSE: response})\n\n\t\tdispatcher.event(SynthesizeEndEvent(query=query, response=response, ))\n\t\treturn response\n\n\t@dispatcher.span\n\tasync def asynthesize(self, query: QueryType, nodes: List[NodeWithScore],\n\t\tadditional_source_nodes: Optional[Sequence[NodeWithScore]] = None, **response_kwargs: Any, ) -&gt; RESPONSE_TYPE:\n\t\tdispatcher.event(SynthesizeStartEvent(query=query, ))\n\t\tif len(nodes) == 0:\n\t\t\tif self._streaming:\n\t\t\t\tempty_response = AsyncStreamingResponse(response_gen=empty_response_agenerator())\n\t\t\t\tdispatcher.event(SynthesizeEndEvent(query=query, response=empty_response, ))\n\t\t\t\treturn empty_response\n\t\t\telse:\n\t\t\t\tempty_response = Response(\"Empty Response\")\n\t\t\t\tdispatcher.event(SynthesizeEndEvent(query=query, response=empty_response, ))\n\t\t\t\treturn empty_response\n\n\t\tif isinstance(query, str):\n\t\t\tquery = QueryBundle(query_str=query)\n\n\t\twith self._callback_manager.event(CBEventType.SYNTHESIZE,\n\t\t\t\tpayload={EventPayload.QUERY_STR: query.query_str}, ) as event:\n\t\t\tresponse_str = await self.aget_response(query_str=query.query_str,\n\t\t\t\ttext_chunks=[n.node.get_content(metadata_mode=MetadataMode.NONE) for n in nodes], **response_kwargs, )\n\n\t\t\tadditional_source_nodes = additional_source_nodes or []\n\t\t\tsource_nodes = list(nodes) + list(additional_source_nodes)\n\n\t\t\tresponse = self._prepare_response_output(response_str, source_nodes)\n\n\t\t\tevent.on_end(payload={EventPayload.RESPONSE: response})\n\n\t\tdispatcher.event(SynthesizeEndEvent(query=query, response=response, ))\n\t\treturn response\n</code></pre>"},{"location":"code_docs/func_modules/paper/synthesizer/summarize/#labridge.func_modules.paper.synthesizer.summarize.PaperBatchSummarize.abatch_get_response","title":"<code>labridge.func_modules.paper.synthesizer.summarize.PaperBatchSummarize.abatch_get_response(batch_chunks, query_str)</code>  <code>async</code>","text":"<p>Asynchronously batch summarize.</p> PARAMETER DESCRIPTION <code>batch_chunks</code> <p>A batch of chunks.</p> <p> TYPE: <code>Sequence[str]</code> </p> <code>query_str</code> <p>The batch query prompt.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>RESPONSE_TEXT_TYPE</code> <p>The summary.</p> <p> TYPE: <code>RESPONSE_TEXT_TYPE</code> </p> Source code in <code>labridge\\func_modules\\paper\\synthesizer\\summarize.py</code> <pre><code>async def abatch_get_response(self, batch_chunks: Sequence[str], query_str: str) -&gt; RESPONSE_TEXT_TYPE:\n\tr\"\"\"\n\tAsynchronously batch summarize.\n\n\tArgs:\n\t\tbatch_chunks (Sequence[str]): A batch of chunks.\n\t\tquery_str (str): The batch query prompt.\n\n\tReturns:\n\t\tRESPONSE_TEXT_TYPE: The summary.\n\t\"\"\"\n\tsummary_template = self._summary_template.partial_format(query_str=query_str)\n\tresponse = await self._llm.apredict(\n\t\tsummary_template,\n\t\tcontext_str=\"\\n\".join(batch_chunks),\n\t)\n\treturn response\n</code></pre>"},{"location":"code_docs/func_modules/paper/synthesizer/summarize/#labridge.func_modules.paper.synthesizer.summarize.PaperBatchSummarize.aget_response","title":"<code>labridge.func_modules.paper.synthesizer.summarize.PaperBatchSummarize.aget_response(query_str, text_chunks, **response_kwargs)</code>  <code>async</code>","text":"<p>Summarize a paper.</p> PARAMETER DESCRIPTION <code>query_str</code> <p>Not used.</p> <p> TYPE: <code>str</code> </p> <code>text_chunks</code> <p>The text chunks of a paper.</p> <p> TYPE: <code>Sequence[str]</code> </p> <code>**response_kwargs</code> <p>Not used.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>RESPONSE_TEXT_TYPE</code> <p>The summary.</p> <p> TYPE: <code>RESPONSE_TEXT_TYPE</code> </p> Source code in <code>labridge\\func_modules\\paper\\synthesizer\\summarize.py</code> <pre><code>\tasync def aget_response(\n        self,\n        query_str: str,\n        text_chunks: Sequence[str],\n        **response_kwargs: Any,\n    ) -&gt; RESPONSE_TEXT_TYPE:\n\t\tr\"\"\"\n\t\tSummarize a paper.\n\n\t\tArgs:\n\t\t\tquery_str (str): Not used.\n\t\t\ttext_chunks (Sequence[str]): The text chunks of a paper.\n\t\t\t**response_kwargs (Any): Not used.\n\n\t\tReturns:\n\t\t\tRESPONSE_TEXT_TYPE: The summary.\n\t\t\"\"\"\n\t\tbatch_mode, batch_size = self._calculate_batch_size(text_chunks=text_chunks)\n\t\tif not batch_mode:\n\t\t\treturn await self.abatch_get_response(\n\t\t\t\tbatch_chunks=text_chunks,\n\t\t\t\tquery_str=self.summary_query,\n\t\t\t)\n\n\t\ttasks = [\n\t\t\tself.abatch_get_response(\n\t\t\t\tbatch_chunks=batch_chunks,\n\t\t\t\tquery_str=self.summary_query,\n\t\t\t) for batch_chunks in self.batch_chunks(text_chunks=text_chunks, batch_size=batch_size)\n\t\t]\n\n\t\tsummary_texts = await asyncio.gather(*tasks)\n\n\t\tfinal_response = self.batch_get_response(\n\t\t\tbatch_chunks=summary_texts,\n\t\t\tquery_str=self.secondary_query,\n\t\t)\n\t\treturn final_response\n</code></pre>"},{"location":"code_docs/func_modules/paper/synthesizer/summarize/#labridge.func_modules.paper.synthesizer.summarize.PaperBatchSummarize.batch_chunks","title":"<code>labridge.func_modules.paper.synthesizer.summarize.PaperBatchSummarize.batch_chunks(text_chunks, batch_size)</code>","text":"<p>Yield batch chunks according to the <code>batch_size</code> and <code>self._overlap_chunk_num</code>.</p> PARAMETER DESCRIPTION <code>text_chunks</code> <p>The chunks of a paper.</p> <p> TYPE: <code>Sequence[str]</code> </p> <code>batch_size</code> <p>The calculated batch size.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <p>Sequence[str]: A batch.</p> Source code in <code>labridge\\func_modules\\paper\\synthesizer\\summarize.py</code> <pre><code>def batch_chunks(self, text_chunks: Sequence[str], batch_size: int):\n\tr\"\"\"\n\tYield batch chunks according to the `batch_size` and `self._overlap_chunk_num`.\n\n\tArgs:\n\t\ttext_chunks (Sequence[str]): The chunks of a paper.\n\t\tbatch_size (int): The calculated batch size.\n\n\tReturns:\n\t\tSequence[str]: A batch.\n\t\"\"\"\n\tn = len(text_chunks)\n\tfor start in range(0, n, batch_size - self._overlap_chunk_num):\n\t\tyield text_chunks[start: start + batch_size]\n</code></pre>"},{"location":"code_docs/func_modules/paper/synthesizer/summarize/#labridge.func_modules.paper.synthesizer.summarize.PaperBatchSummarize.batch_get_response","title":"<code>labridge.func_modules.paper.synthesizer.summarize.PaperBatchSummarize.batch_get_response(batch_chunks, query_str)</code>","text":"<p>Batch summarize.</p> PARAMETER DESCRIPTION <code>batch_chunks</code> <p>A batch of chunks.</p> <p> TYPE: <code>Sequence[str]</code> </p> <code>query_str</code> <p>The batch query prompt.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>RESPONSE_TEXT_TYPE</code> <p>The summary.</p> <p> TYPE: <code>RESPONSE_TEXT_TYPE</code> </p> Source code in <code>labridge\\func_modules\\paper\\synthesizer\\summarize.py</code> <pre><code>def batch_get_response(self, batch_chunks: Sequence[str], query_str: str) -&gt; RESPONSE_TEXT_TYPE:\n\tr\"\"\"\n\tBatch summarize.\n\n\tArgs:\n\t\tbatch_chunks (Sequence[str]): A batch of chunks.\n\t\tquery_str (str): The batch query prompt.\n\n\tReturns:\n\t\tRESPONSE_TEXT_TYPE: The summary.\n\t\"\"\"\n\tsummary_template = self._summary_template.partial_format(query_str=query_str)\n\tresponse = self._llm.predict(\n\t\tsummary_template,\n\t\tcontext_str=\"\\n\".join(batch_chunks),\n\t)\n\treturn response\n</code></pre>"},{"location":"code_docs/func_modules/paper/synthesizer/summarize/#labridge.func_modules.paper.synthesizer.summarize.PaperBatchSummarize.get_response","title":"<code>labridge.func_modules.paper.synthesizer.summarize.PaperBatchSummarize.get_response(query_str, text_chunks, **response_kwargs)</code>","text":"<p>Summarize a paper.</p> PARAMETER DESCRIPTION <code>query_str</code> <p>Not used.</p> <p> TYPE: <code>str</code> </p> <code>text_chunks</code> <p>The text chunks of a paper.</p> <p> TYPE: <code>Sequence[str]</code> </p> <code>**response_kwargs</code> <p>Not used.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>RESPONSE_TEXT_TYPE</code> <p>The summary.</p> <p> TYPE: <code>RESPONSE_TEXT_TYPE</code> </p> Source code in <code>labridge\\func_modules\\paper\\synthesizer\\summarize.py</code> <pre><code>\tdef get_response(\n        self,\n        query_str: str,\n        text_chunks: Sequence[str],\n        **response_kwargs: Any,\n    ) -&gt; RESPONSE_TEXT_TYPE:\n\t\tr\"\"\"\n\t\tSummarize a paper.\n\n\t\tArgs:\n\t\t\tquery_str (str): Not used.\n\t\t\ttext_chunks (Sequence[str]): The text chunks of a paper.\n\t\t\t**response_kwargs (Any): Not used.\n\n\t\tReturns:\n\t\t\tRESPONSE_TEXT_TYPE: The summary.\n\t\t\"\"\"\n\t\tbatch_mode, batch_size = self._calculate_batch_size(text_chunks=text_chunks)\n\n\t\tprint(\"summary batch size: \", batch_size)\n\t\tprint(\"Total chunks: \", len(text_chunks))\n\t\tprint(text_chunks[0])\n\t\tif not batch_mode:\n\t\t\treturn self.batch_get_response(\n\t\t\t\tbatch_chunks=text_chunks,\n\t\t\t\tquery_str=self.summary_query,\n\t\t\t)\n\n\t\tsummary_texts = []\n\t\tfor chunks in self.batch_chunks(text_chunks=text_chunks, batch_size=batch_size):\n\n\n\t\t\tresponse = self.batch_get_response(\n\t\t\t\tbatch_chunks=chunks,\n\t\t\t\tquery_str=self.summary_query\n\t\t\t)\n\t\t\tsummary_texts.append(response)\n\n\t\tfinal_response = self.batch_get_response(\n\t\t\tbatch_chunks=summary_texts,\n\t\t\tquery_str=self.secondary_query,\n\t\t)\n\t\treturn final_response\n</code></pre>"},{"location":"code_docs/func_modules/reference/base/","title":"Base","text":""},{"location":"code_docs/func_modules/reference/base/#labridge.func_modules.reference.base","title":"<code>labridge.func_modules.reference.base</code>","text":""},{"location":"code_docs/func_modules/reference/base/#labridge.func_modules.reference.base.RefInfoBase","title":"<code>labridge.func_modules.reference.base.RefInfoBase</code>","text":"<p>This is the base class for reference information.</p> Source code in <code>labridge\\func_modules\\reference\\base.py</code> <pre><code>class RefInfoBase:\n\tr\"\"\"\n\tThis is the base class for reference information.\n\t\"\"\"\n\n\t@abstractmethod\n\tdef dumps(self):\n\t\tr\"\"\" Dump an object of the class to a string in JSON format. \"\"\"\n\n\t@classmethod\n\t@abstractmethod\n\tdef loads(cls, info_str):\n\t\tr\"\"\" Load an object of the class from a string in JSON format. \"\"\"\n</code></pre>"},{"location":"code_docs/func_modules/reference/base/#labridge.func_modules.reference.base.RefInfoBase.dumps","title":"<code>labridge.func_modules.reference.base.RefInfoBase.dumps()</code>  <code>abstractmethod</code>","text":"<p>Dump an object of the class to a string in JSON format.</p> Source code in <code>labridge\\func_modules\\reference\\base.py</code> <pre><code>@abstractmethod\ndef dumps(self):\n\tr\"\"\" Dump an object of the class to a string in JSON format. \"\"\"\n</code></pre>"},{"location":"code_docs/func_modules/reference/base/#labridge.func_modules.reference.base.RefInfoBase.loads","title":"<code>labridge.func_modules.reference.base.RefInfoBase.loads(info_str)</code>  <code>abstractmethod</code> <code>classmethod</code>","text":"<p>Load an object of the class from a string in JSON format.</p> Source code in <code>labridge\\func_modules\\reference\\base.py</code> <pre><code>@classmethod\n@abstractmethod\ndef loads(cls, info_str):\n\tr\"\"\" Load an object of the class from a string in JSON format. \"\"\"\n</code></pre>"},{"location":"code_docs/func_modules/reference/instrument/","title":"Instrument","text":""},{"location":"code_docs/func_modules/reference/instrument/#labridge.func_modules.reference.instrument","title":"<code>labridge.func_modules.reference.instrument</code>","text":""},{"location":"code_docs/func_modules/reference/instrument/#labridge.func_modules.reference.instrument.InstrumentInfo","title":"<code>labridge.func_modules.reference.instrument.InstrumentInfo</code>","text":"<p>               Bases: <code>RefInfoBase</code></p> <p>This class contains the information of an instrument, including:</p> PARAMETER DESCRIPTION <code>instrument_id</code> <p>The name of the instrument.</p> <p> TYPE: <code>str</code> </p> <code>super_users</code> <p>The super-users of the instrument.</p> <p> TYPE: <code>List[str]</code> </p> Source code in <code>labridge\\func_modules\\reference\\instrument.py</code> <pre><code>class InstrumentInfo(RefInfoBase):\n\tr\"\"\"\n\tThis class contains the information of an instrument, including:\n\n\tArgs:\n\t\tinstrument_id (str): The name of the instrument.\n\t\tsuper_users (List[str]): The super-users of the instrument.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tinstrument_id: str,\n\t\tsuper_users: List[str],\n\t):\n\t\tself.instrument_id = instrument_id\n\t\tself.super_users = super_users\n\n\tdef dumps(self) -&gt; str:\n\t\tr\"\"\" Dump to a string in JSON format. \"\"\"\n\t\tinfo_dict = {\n\t\t\tREF_TYPE: InstrumentInfo.__name__,\n\t\t\t\"instrument_id\": self.instrument_id,\n\t\t\t\"super_users\": self.super_users,\n\t\t}\n\t\treturn json.dumps(info_dict)\n\n\t@classmethod\n\tdef loads(\n\t\tcls,\n\t\tinfo_str: str,\n\t):\n\t\tr\"\"\" Load from a string in JSON format. \"\"\"\n\t\ttry:\n\t\t\tinfo_dict = json.loads(info_str)\n\t\t\tinstrument_id = info_dict[\"instrument_id\"]\n\t\t\tsuper_users = info_dict[\"super_users\"]\n\t\t\treturn cls(\n\t\t\t\tinstrument_id=instrument_id,\n\t\t\t\tsuper_users=super_users,\n\t\t\t)\n\t\texcept Exception:\n\t\t\traise ValueError(\"Invalid Instrument info string.\")\n</code></pre>"},{"location":"code_docs/func_modules/reference/instrument/#labridge.func_modules.reference.instrument.InstrumentInfo.dumps","title":"<code>labridge.func_modules.reference.instrument.InstrumentInfo.dumps()</code>","text":"<p>Dump to a string in JSON format.</p> Source code in <code>labridge\\func_modules\\reference\\instrument.py</code> <pre><code>def dumps(self) -&gt; str:\n\tr\"\"\" Dump to a string in JSON format. \"\"\"\n\tinfo_dict = {\n\t\tREF_TYPE: InstrumentInfo.__name__,\n\t\t\"instrument_id\": self.instrument_id,\n\t\t\"super_users\": self.super_users,\n\t}\n\treturn json.dumps(info_dict)\n</code></pre>"},{"location":"code_docs/func_modules/reference/instrument/#labridge.func_modules.reference.instrument.InstrumentInfo.loads","title":"<code>labridge.func_modules.reference.instrument.InstrumentInfo.loads(info_str)</code>  <code>classmethod</code>","text":"<p>Load from a string in JSON format.</p> Source code in <code>labridge\\func_modules\\reference\\instrument.py</code> <pre><code>@classmethod\ndef loads(\n\tcls,\n\tinfo_str: str,\n):\n\tr\"\"\" Load from a string in JSON format. \"\"\"\n\ttry:\n\t\tinfo_dict = json.loads(info_str)\n\t\tinstrument_id = info_dict[\"instrument_id\"]\n\t\tsuper_users = info_dict[\"super_users\"]\n\t\treturn cls(\n\t\t\tinstrument_id=instrument_id,\n\t\t\tsuper_users=super_users,\n\t\t)\n\texcept Exception:\n\t\traise ValueError(\"Invalid Instrument info string.\")\n</code></pre>"},{"location":"code_docs/func_modules/reference/paper/","title":"Paper","text":""},{"location":"code_docs/func_modules/reference/paper/#labridge.func_modules.reference.paper","title":"<code>labridge.func_modules.reference.paper</code>","text":""},{"location":"code_docs/func_modules/reference/paper/#labridge.func_modules.reference.paper.PaperInfo","title":"<code>labridge.func_modules.reference.paper.PaperInfo</code>","text":"<p>               Bases: <code>RefInfoBase</code></p> <p>This class contains the information of a paper, including:</p> PARAMETER DESCRIPTION <code>title</code> <p>The title of the paper.</p> <p> TYPE: <code>str</code> </p> <code>file_path</code> <p>The file path of the paper.</p> <p> TYPE: <code>str</code> </p> <code>possessor</code> <p>The user that possesses the paper.</p> <p> TYPE: <code>str</code> </p> Source code in <code>labridge\\func_modules\\reference\\paper.py</code> <pre><code>class PaperInfo(RefInfoBase):\n\tr\"\"\"\n\tThis class contains the information of a paper, including:\n\n\tArgs:\n\t\ttitle (str): The title of the paper.\n\t\tfile_path (str): The file path of the paper.\n\t\tpossessor (str): The user that possesses the paper.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\ttitle: str,\n\t\tfile_path: str,\n\t\tpossessor: str,\n\t):\n\t\tself.title = title\n\t\tself.file_path = file_path\n\t\tself.possessor = possessor\n\n\tdef dumps(self) -&gt; str:\n\t\tr\"\"\" Dump to a string in JSON format. \"\"\"\n\t\tinfo_dict = {\n\t\t\tREF_TYPE: PaperInfo.__name__,\n\t\t\t\"title\": self.title,\n\t\t\t\"file_path\": self.file_path,\n\t\t\t\"possessor\": self.possessor,\n\t\t}\n\t\treturn json.dumps(info_dict)\n\n\t@classmethod\n\tdef loads(cls, info_str: str):\n\t\tr\"\"\" Load from a string in JSON format. \"\"\"\n\t\ttry:\n\t\t\tinfo_dict = json.loads(info_str)\n\t\t\ttitle = info_dict[\"title\"]\n\t\t\tfile_path = info_dict[\"file_path\"]\n\t\t\tpossessor = info_dict[\"possessor\"]\n\t\t\treturn cls(\n\t\t\t\ttitle=title,\n\t\t\t\tfile_path=file_path,\n\t\t\t\tpossessor=possessor,\n\t\t\t)\n\t\texcept Exception:\n\t\t\traise ValueError(\"Invalid paper info string.\")\n</code></pre>"},{"location":"code_docs/func_modules/reference/paper/#labridge.func_modules.reference.paper.PaperInfo.dumps","title":"<code>labridge.func_modules.reference.paper.PaperInfo.dumps()</code>","text":"<p>Dump to a string in JSON format.</p> Source code in <code>labridge\\func_modules\\reference\\paper.py</code> <pre><code>def dumps(self) -&gt; str:\n\tr\"\"\" Dump to a string in JSON format. \"\"\"\n\tinfo_dict = {\n\t\tREF_TYPE: PaperInfo.__name__,\n\t\t\"title\": self.title,\n\t\t\"file_path\": self.file_path,\n\t\t\"possessor\": self.possessor,\n\t}\n\treturn json.dumps(info_dict)\n</code></pre>"},{"location":"code_docs/func_modules/reference/paper/#labridge.func_modules.reference.paper.PaperInfo.loads","title":"<code>labridge.func_modules.reference.paper.PaperInfo.loads(info_str)</code>  <code>classmethod</code>","text":"<p>Load from a string in JSON format.</p> Source code in <code>labridge\\func_modules\\reference\\paper.py</code> <pre><code>@classmethod\ndef loads(cls, info_str: str):\n\tr\"\"\" Load from a string in JSON format. \"\"\"\n\ttry:\n\t\tinfo_dict = json.loads(info_str)\n\t\ttitle = info_dict[\"title\"]\n\t\tfile_path = info_dict[\"file_path\"]\n\t\tpossessor = info_dict[\"possessor\"]\n\t\treturn cls(\n\t\t\ttitle=title,\n\t\t\tfile_path=file_path,\n\t\t\tpossessor=possessor,\n\t\t)\n\texcept Exception:\n\t\traise ValueError(\"Invalid paper info string.\")\n</code></pre>"},{"location":"code_docs/interact/authorize/authorize/","title":"Authorize","text":""},{"location":"code_docs/interact/authorize/authorize/#labridge.interact.authorize.authorize","title":"<code>labridge.interact.authorize.authorize</code>","text":""},{"location":"code_docs/interact/authorize/authorize/#labridge.interact.authorize.authorize.aoperation_authorize","title":"<code>labridge.interact.authorize.authorize.aoperation_authorize(user_id, op_name, kwargs_str, authorize_strict_mode=False, llm=None, embed_model=None, verbose=False)</code>  <code>async</code>","text":"<p>This function is used to query the user whether to execute a specific operation.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user that will make decisions.</p> <p> TYPE: <code>str</code> </p> <code>op_name</code> <p>The operation to be executed.</p> <p> TYPE: <code>str</code> </p> <code>kwargs_str</code> <p>The keyword arguments of the operation function, which is dumped as a json string.</p> <p> TYPE: <code>str</code> </p> <code>authorize_strict_mode</code> <p>If it is set to True, the operation will be executed only when the user response the <code>STRICT_AGREE_WORDS</code>. Defaults to False.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>llm</code> <p>The used LLM. Defaults to None. If set to None, the Settings.llm will be used.</p> <p> TYPE: <code>LLM</code> DEFAULT: <code>None</code> </p> <code>embed_model</code> <p>The used embedding model. Defaults to None. If set to None, the Settings.embed_model will be used.</p> <p> TYPE: <code>BaseEmbedding</code> DEFAULT: <code>None</code> </p> <code>verbose</code> <p>Whether to show the progress.</p> <p> TYPE: <code>str</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>callback_log</code> <p>the log string.</p> <p> TYPE: <code>str</code> </p> Source code in <code>labridge\\interact\\authorize\\authorize.py</code> <pre><code>async def aoperation_authorize(\n\tuser_id: str,\n\top_name: str,\n\tkwargs_str: str,\n\tauthorize_strict_mode: bool = False,\n\tllm: LLM = None,\n\tembed_model: BaseEmbedding = None,\n\tverbose: bool = False,\n) -&gt; OperationOutputLog:\n\tr\"\"\"\n\tThis function is used to query the user whether to execute a specific operation.\n\n\tArgs:\n\t\tuser_id (str): The user that will make decisions.\n\t\top_name (str): The operation to be executed.\n\t\tkwargs_str (str): The keyword arguments of the operation function, which is dumped as a json string.\n\t\tauthorize_strict_mode (bool): If it is set to True, the operation will be executed only when the user response\n\t\t\tthe `STRICT_AGREE_WORDS`. Defaults to False.\n\t\tllm (LLM): The used LLM. Defaults to None. If set to None, the Settings.llm will be used.\n\t\tembed_model (BaseEmbedding): The used embedding model. Defaults to None.\n\t\t\tIf set to None, the Settings.embed_model will be used.\n\t\tverbose (str): Whether to show the progress.\n\n\tReturns:\n\t\tcallback_log (str): the log string.\n\n\t\"\"\"\n\tif op_name not in CALL_BACK_OPS:\n\t\traise ValueError(f\"{op_name} is not a valid callback operation name.\")\n\n\toperation_class = getattr(callback, op_name)\n\tif not issubclass(operation_class, CallBackOperationBase):\n\t\traise ValueError(f\"{op_name} should be a subclass of 'CallBackOperationBase'.\")\n\n\tllm = llm or Settings.llm\n\tembed_model = embed_model or Settings.embed_model\n\n\toperation = operation_class(\n\t\tllm=llm,\n\t\tembed_model=embed_model,\n\t\tverbose=verbose,\n\t\top_name=op_name,\n\t)\n\tkwargs = json.loads(kwargs_str)\n\top_description = operation.operation_description(**kwargs)\n\tif authorize_strict_mode:\n\t\tquery_str = STRICT_AUTHORIZE_QUERY_TMPL.format(\n\t\t\tstrict_agree_str=\",\".join(STRICT_AGREE_WORDS),\n\t\t\toperation_description=op_description,\n\t\t)\n\telse:\n\t\tquery_str = AUTHORIZE_QUERY_TMPL.format(operation_description=op_description)\n\n\t# TODO: send the operation description to the user.\n\tChatBuffer.put_agent_reply(\n\t\tuser_id=user_id,\n\t\treply_str=query_str,\n\t\tinner_chat=True,\n\t)\n\n\t# TODO: wait for the user response.\n\tuser_msg: PackedUserMessage = await ChatBuffer.get_user_msg(user_id=user_id)\n\tif user_msg is None:\n\t\traise ValueError(\"Invalid user msg.\")\n\n\tuser_response = user_msg.user_msg\n\n\tagree = False\n\tif authorize_strict_mode:\n\t\tif user_response.encode(\"utf-8\").isalpha():\n\t\t\tuser_response = user_response.lower()\n\t\tagree = user_response in STRICT_AGREE_WORDS\n\telse:\n\t\tjudgement = await llm.apredict(\n\t\t\tprompt=AUTHORIZATION_ANALYZE_PROMPT,\n\t\t\tagree_word=ANALYZE_AGREE_WORD,\n\t\t\tdisagree_word=ANALYZE_DISAGREE_WORD,\n\t\t\tuser_response=user_response,\n\t\t)\n\t\tagree = analyze_agree(llm_response=judgement)\n\n\tif agree:\n\t\t# TODO: I need an operation buffer to store operations. two operation class: 1. real time, 2. buffer.\n\t\tcallback_log = operation.do_operation(**kwargs)\n\t\treturn callback_log\n\telse:\n\t\tcallback_log_str = (f\"The assistant tries to obtain the authorization from user {user_id} to perform an operation.\"\n\t\t\t\t\t\tf\"The user disagreed, so this operation does not be performed.\\n\"\n\t\t\t\t\t\tf\"The operation is described as follows:\\n{op_description}\\n\\n\"\n\t\t\t\t\t\tf\"The user's response is as follows:\\n{user_response}\")\n\t\treturn OperationOutputLog(\n\t\t\toperation_name=op_name,\n\t\t\toperation_output=callback_log_str,\n\t\t\tlog_to_user=None,\n\t\t\tlog_to_system={\n\t\t\t\tOP_DESCRIPTION: callback_log_str,\n\t\t\t\tOP_REFERENCES: None,\n\t\t\t},\n\t\t\toperation_abort=True,\n\t\t)\n</code></pre>"},{"location":"code_docs/interact/authorize/authorize/#labridge.interact.authorize.authorize.operation_authorize","title":"<code>labridge.interact.authorize.authorize.operation_authorize(user_id, op_name, kwargs_str, authorize_strict_mode=False, llm=None, embed_model=None, verbose=False)</code>","text":"<p>This function is used to query the user whether to execute a specific operation.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user that will make decisions.</p> <p> TYPE: <code>str</code> </p> <code>op_name</code> <p>The operation to be executed.</p> <p> TYPE: <code>str</code> </p> <code>kwargs_str</code> <p>The keyword arguments of the operation function, which is dumped as a json string.</p> <p> TYPE: <code>str</code> </p> <code>authorize_strict_mode</code> <p>If it is set to True, the operation will be executed only when the user response the <code>STRICT_AGREE_WORDS</code>. Defaults to False.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>llm</code> <p>The used LLM. Defaults to None. If set to None, the Settings.llm will be used.</p> <p> TYPE: <code>LLM</code> DEFAULT: <code>None</code> </p> <code>embed_model</code> <p>The used embedding model. Defaults to None. If set to None, the Settings.embed_model will be used.</p> <p> TYPE: <code>BaseEmbedding</code> DEFAULT: <code>None</code> </p> <code>verbose</code> <p>Whether to show the progress.</p> <p> TYPE: <code>str</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>callback_log</code> <p>the log string.</p> <p> TYPE: <code>str</code> </p> Source code in <code>labridge\\interact\\authorize\\authorize.py</code> <pre><code>def operation_authorize(\n\tuser_id: str,\n\top_name: str,\n\tkwargs_str: str,\n\tauthorize_strict_mode: bool = False,\n\tllm: LLM = None,\n\tembed_model: BaseEmbedding = None,\n\tverbose: bool = False,\n) -&gt; OperationOutputLog:\n\tr\"\"\"\n\tThis function is used to query the user whether to execute a specific operation.\n\n\tArgs:\n\t\tuser_id (str): The user that will make decisions.\n\t\top_name (str): The operation to be executed.\n\t\tkwargs_str (str): The keyword arguments of the operation function, which is dumped as a json string.\n\t\tauthorize_strict_mode (bool): If it is set to True, the operation will be executed only when the user response\n\t\t\tthe `STRICT_AGREE_WORDS`. Defaults to False.\n\t\tllm (LLM): The used LLM. Defaults to None. If set to None, the Settings.llm will be used.\n\t\tembed_model (BaseEmbedding): The used embedding model. Defaults to None.\n\t\t\tIf set to None, the Settings.embed_model will be used.\n\t\tverbose (str): Whether to show the progress.\n\n\tReturns:\n\t\tcallback_log (str): the log string.\n\n\t\"\"\"\n\tif op_name not in CALL_BACK_OPS:\n\t\traise ValueError(f\"{op_name} is not a valid callback operation name.\")\n\n\toperation_class = getattr(callback, op_name)\n\tif not issubclass(operation_class, CallBackOperationBase):\n\t\traise ValueError(f\"{op_name} should be a subclass of 'CallBackOperationBase'.\")\n\n\tllm = llm or Settings.llm\n\tembed_model = embed_model or Settings.embed_model\n\n\toperation = operation_class(\n\t\tllm=llm,\n\t\tembed_model=embed_model,\n\t\tverbose=verbose,\n\t\top_name=op_name,\n\t)\n\n\tkwargs = json.loads(kwargs_str)\n\top_description = operation.operation_description(**kwargs)\n\tif authorize_strict_mode:\n\t\tquery_str = STRICT_AUTHORIZE_QUERY_TMPL.format(\n\t\t\tstrict_agree_str=\",\".join(STRICT_AGREE_WORDS),\n\t\t\toperation_description=op_description,\n\t\t)\n\telse:\n\t\tquery_str = AUTHORIZE_QUERY_TMPL.format(operation_description=op_description)\n\n\t# TODO: send the operation description to the user.\n\tprint(query_str)\n\n\t# TODO: wait for the user response.\n\tuser_msg: PackedUserMessage = ChatBuffer.test_get_user_text(user_id=user_id)\n\tuser_response = user_msg.user_msg\n\n\tagree = False\n\tprint(\"Here 1 ....\")\n\tif authorize_strict_mode:\n\t\tif user_response.encode(\"utf-8\").isalpha():\n\t\t\tuser_response = user_response.lower()\n\t\tagree = user_response in STRICT_AGREE_WORDS\n\telse:\n\t\tjudgement = llm.predict(\n\t\t\tprompt=AUTHORIZATION_ANALYZE_PROMPT,\n\t\t\tagree_word=ANALYZE_AGREE_WORD,\n\t\t\tdisagree_word=ANALYZE_DISAGREE_WORD,\n\t\t\tuser_response=user_response,\n\t\t)\n\t\tagree = analyze_agree(llm_response=judgement)\n\t\tprint(\"Here 2 ....\")\n\n\tif agree:\n\t\t# TODO: I need an operation buffer to store operations.\n\t\tcallback_log = operation.do_operation(**kwargs)\n\t\tprint(\"Here\", callback_log.dumps())\n\t\treturn callback_log\n\telse:\n\t\tcallback_log_str = (\n\t\t\tf\"The assistant tries to obtain the authorization from user {user_id} to perform an operation.\"\n\t\t\tf\"The user disagreed, so this operation does not be performed.\\n\"\n\t\t\tf\"The operation is described as follows:\\n{op_description}\\n\\n\"\n\t\t\tf\"The user's response is as follows:\\n{user_response}\"\n\t\t)\n\t\treturn OperationOutputLog(\n\t\t\toperation_name=op_name,\n\t\t\toperation_output=callback_log_str,\n\t\t\tlog_to_user=None,\n\t\t\tlog_to_system={\n\t\t\t\tOP_DESCRIPTION: callback_log_str,\n\t\t\t\tOP_REFERENCES: None,\n\t\t\t},\n\t\t\toperation_abort=True,\n\t\t)\n</code></pre>"},{"location":"code_docs/interact/collect/pipeline/","title":"Pipeline","text":""},{"location":"code_docs/interact/collect/pipeline/#labridge.interact.collect.pipeline","title":"<code>labridge.interact.collect.pipeline</code>","text":""},{"location":"code_docs/interact/collect/pipeline/#labridge.interact.collect.pipeline.acollect_info_from_user","title":"<code>labridge.interact.collect.pipeline.acollect_info_from_user(user_id, required_infos, query_str, llm=None)</code>  <code>async</code>","text":"<p>This is an asynchronous pipeline to collect information from the user.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user id of a Lab member.</p> <p> TYPE: <code>str</code> </p> <code>required_infos</code> <p>The required information.</p> <p> TYPE: <code>List[CollectingInfoBase]</code> </p> <code>query_str</code> <p>The query string to be sent to the user.</p> <p> TYPE: <code>str</code> </p> <code>llm</code> <p>The used LLM.</p> <p> TYPE: <code>LLM</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <p>Optional[Dict[str, str]]: The collected information.</p> <ul> <li>key: The information name.</li> <li>value: The collected information.</li> </ul> <p>If the user aborts the collecting, return None.</p> Source code in <code>labridge\\interact\\collect\\pipeline.py</code> <pre><code>async def acollect_info_from_user(\n\tuser_id: str,\n\trequired_infos: List[CollectingInfoBase],\n\tquery_str: str,\n\tllm: LLM = None,\n):\n\tr\"\"\"\n\tThis is an asynchronous pipeline to collect information from the user.\n\n\tArgs:\n\t\tuser_id (str): The user id of a Lab member.\n\t\trequired_infos (List[CollectingInfoBase]): The required information.\n\t\tquery_str (str): The query string to be sent to the user.\n\t\tllm (LLM): The used LLM.\n\n\tReturns:\n\t\tOptional[Dict[str, str]]:\n\t\t\tThe collected information.\n\n\t\t\t- key: The information name.\n\t\t\t- value: The collected information.\n\n\t\t\tIf the user aborts the collecting, return None.\n\t\"\"\"\n\t# TODO: Send query_str to User\n\tprint(f\"Assistant: {query_str}\")\n\tllm = llm or Settings.llm\n\n\tcommon_info_collector = CommonInfoCollector(\n\t\tllm=llm,\n\t\trequired_infos=required_infos,\n\t)\n\tselect_info_collector = SelectInfoCollector(\n\t\tllm=llm,\n\t\trequired_infos=required_infos,\n\t)\n\n\tabort = False\n\theader_sent = False\n\n\twhile not abort and not select_info_collector.collected:\n\t\tquery = query_str if not header_sent else None\n\t\tabort = await select_info_collector.acollect(user_id=user_id, query_str=query)\n\t\theader_sent = True\n\tselect_modify = True\n\twhile not abort and select_modify:\n\t\tselect_modify, abort = await select_info_collector.amodify(user_id=user_id)\n\n\twhile not abort and not common_info_collector.collected:\n\t\tquery = query_str if not header_sent else None\n\t\tabort = await common_info_collector.acollect(user_id=user_id, query_str=query)\n\t\theader_sent = True\n\tcommon_modify = True\n\twhile not abort and common_modify:\n\t\tcommon_modify, abort = await common_info_collector.amodify(user_id=user_id)\n\n\tif abort:\n\t\treturn None\n\n\toutput_dict = {}\n\tcommon_info_dict = common_info_collector.collected_infos\n\tselect_info_dict = select_info_collector.collected_infos\n\tif common_info_dict is not None:\n\t\toutput_dict.update(common_info_dict)\n\tif select_info_dict is not None:\n\t\toutput_dict.update(select_info_dict)\n\treturn output_dict\n</code></pre>"},{"location":"code_docs/interact/collect/pipeline/#labridge.interact.collect.pipeline.collect_info_from_user","title":"<code>labridge.interact.collect.pipeline.collect_info_from_user(user_id, required_infos, query_str, llm=None)</code>","text":"<p>This is a pipeline to collect information from the user.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user id of a Lab member.</p> <p> TYPE: <code>str</code> </p> <code>required_infos</code> <p>The required information.</p> <p> TYPE: <code>List[CollectingInfoBase]</code> </p> <code>query_str</code> <p>The query string to be sent to the user.</p> <p> TYPE: <code>str</code> </p> <code>llm</code> <p>The used LLM.</p> <p> TYPE: <code>LLM</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Optional[Dict[str, str]]</code> <p>Optional[Dict[str, str]]: The collected information.</p> <ul> <li>key: The information name.</li> <li>value: The collected information.</li> </ul> <p>If the user aborts the collecting, return None.</p> Source code in <code>labridge\\interact\\collect\\pipeline.py</code> <pre><code>def collect_info_from_user(\n\tuser_id: str,\n\trequired_infos: List[CollectingInfoBase],\n\tquery_str: str,\n\tllm: LLM = None,\n) -&gt; Optional[Dict[str, str]]:\n\tr\"\"\"\n\tThis is a pipeline to collect information from the user.\n\n\tArgs:\n\t\tuser_id (str): The user id of a Lab member.\n\t\trequired_infos (List[CollectingInfoBase]): The required information.\n\t\tquery_str (str): The query string to be sent to the user.\n\t\tllm (LLM): The used LLM.\n\n\tReturns:\n\t\tOptional[Dict[str, str]]:\n\t\t\tThe collected information.\n\n\t\t\t- key: The information name.\n\t\t\t- value: The collected information.\n\n\t\t\tIf the user aborts the collecting, return None.\n\t\"\"\"\n\t# # TODO: Send query_str to User\n\tprint(f\"Assistant: {query_str}\")\n\tllm = llm or Settings.llm\n\n\t# for info in required_infos:\n\t# \tprint(info.info_name)\n\n\tcommon_info_collector = CommonInfoCollector(\n\t\tllm=llm,\n\t\trequired_infos=required_infos,\n\t)\n\tselect_info_collector = SelectInfoCollector(\n\t\tllm=llm,\n\t\trequired_infos=required_infos,\n\t)\n\n\tabort = False\n\theader_sent = False\n\n\twhile not abort and not select_info_collector.collected:\n\t\tquery = query_str if not header_sent else None\n\t\tabort = select_info_collector.collect(user_id=user_id, query_str=query)\n\t\theader_sent = True\n\tselect_modify = True\n\twhile not abort and select_modify:\n\t\tselect_modify, abort = select_info_collector.modify(user_id=user_id)\n\n\twhile not abort and not common_info_collector.collected:\n\t\tquery = query_str if not header_sent else None\n\t\tabort = common_info_collector.collect(user_id=user_id, query_str=query)\n\t\theader_sent = True\n\tcommon_modify = True\n\twhile not abort and common_modify:\n\t\tcommon_modify, abort = common_info_collector.modify(user_id=user_id)\n\n\tif abort:\n\t\treturn None\n\n\toutput_dict = {}\n\tcommon_info_dict = common_info_collector.collected_infos\n\tselect_info_dict = select_info_collector.collected_infos\n\tif common_info_dict is not None:\n\t\toutput_dict.update(common_info_dict)\n\tif select_info_dict is not None:\n\t\toutput_dict.update(select_info_dict)\n\treturn output_dict\n</code></pre>"},{"location":"code_docs/interact/collect/utils/","title":"Utils","text":""},{"location":"code_docs/interact/collect/utils/#labridge.interact.collect.utils","title":"<code>labridge.interact.collect.utils</code>","text":""},{"location":"code_docs/interact/collect/utils/#labridge.interact.collect.utils.acondition_analyze","title":"<code>labridge.interact.collect.utils.acondition_analyze(llm, prompt, condition_true_word, **kwargs)</code>  <code>async</code>","text":"<p>Asynchronously choose from two conditions according to the input.</p> PARAMETER DESCRIPTION <code>llm</code> <p>The used LLM.</p> <p> TYPE: <code>LLM</code> </p> <code>prompt</code> <p>The prompt template.</p> <p> TYPE: <code>PromptTemplate</code> </p> <code>condition_true_word</code> <p>The word that the LLM is supposed to output in the True condition.</p> <p> TYPE: <code>str</code> </p> <code>**kwargs</code> <p> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True condition or False.</p> <p> TYPE: <code>bool</code> </p> Source code in <code>labridge\\interact\\collect\\utils.py</code> <pre><code>async def acondition_analyze(\n\tllm: LLM,\n\tprompt: PromptTemplate,\n\tcondition_true_word: str,\n\t**kwargs,\n) -&gt; bool:\n\tr\"\"\"\n\tAsynchronously choose from two conditions according to the input.\n\n\tArgs:\n\t\tllm (LLM): The used LLM.\n\t\tprompt (PromptTemplate): The prompt template.\n\t\tcondition_true_word (str): The word that the LLM is supposed to output in the True condition.\n\t\t**kwargs:\n\n\tReturns:\n\t\tbool: True condition or False.\n\t\"\"\"\n\tllm_response = await llm.apredict(\n\t\tprompt=prompt,\n\t\t**kwargs,\n\t)\n\n\tllm_str = filter(lambda x: x.isalpha(), [char for char in llm_response])\n\tllm_str = \"\".join(llm_str)\n\treturn llm_str == condition_true_word\n</code></pre>"},{"location":"code_docs/interact/collect/utils/#labridge.interact.collect.utils.condition_analyze","title":"<code>labridge.interact.collect.utils.condition_analyze(llm, prompt, condition_true_word, **kwargs)</code>","text":"<p>Choose from two conditions according to the input.</p> PARAMETER DESCRIPTION <code>llm</code> <p>The used LLM.</p> <p> TYPE: <code>LLM</code> </p> <code>prompt</code> <p>The prompt template.</p> <p> TYPE: <code>PromptTemplate</code> </p> <code>condition_true_word</code> <p>The word that the LLM is supposed to output in the True condition.</p> <p> TYPE: <code>str</code> </p> <code>**kwargs</code> <p> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>True condition or False.</p> <p> TYPE: <code>bool</code> </p> Source code in <code>labridge\\interact\\collect\\utils.py</code> <pre><code>def condition_analyze(\n\tllm: LLM,\n\tprompt: PromptTemplate,\n\tcondition_true_word: str,\n\t**kwargs,\n) -&gt; bool:\n\tr\"\"\"\n\tChoose from two conditions according to the input.\n\n\tArgs:\n\t\tllm (LLM): The used LLM.\n\t\tprompt (PromptTemplate): The prompt template.\n\t\tcondition_true_word (str): The word that the LLM is supposed to output in the True condition.\n\t\t**kwargs:\n\n\tReturns:\n\t\tbool: True condition or False.\n\t\"\"\"\n\tllm_response = llm.predict(\n\t\tprompt=prompt,\n\t\t**kwargs,\n\t)\n\n\tllm_str = filter(lambda x: x.isalpha(), [char for char in llm_response])\n\tllm_str = \"\".join(llm_str)\n\treturn llm_str.lower() == condition_true_word.lower()\n</code></pre>"},{"location":"code_docs/interact/collect/collector/common_collector/","title":"Common collector","text":""},{"location":"code_docs/interact/collect/collector/common_collector/#labridge.interact.collect.collector.common_collector","title":"<code>labridge.interact.collect.collector.common_collector</code>","text":""},{"location":"code_docs/interact/collect/collector/common_collector/#labridge.interact.collect.collector.common_collector.CommonInfoCollector","title":"<code>labridge.interact.collect.collector.common_collector.CommonInfoCollector</code>","text":"<p>Collect CommonInfo from the user. refer to <code>..types.common_info.CollectingCommonInfo</code> for the detail of CommonInfo.</p> PARAMETER DESCRIPTION <code>llm</code> <p>The used LLM.</p> <p> TYPE: <code>LLM</code> </p> <code>required_infos</code> <p>The required infos.</p> <p> TYPE: <code>List[CollectingInfoBase]</code> </p> Source code in <code>labridge\\interact\\collect\\collector\\common_collector.py</code> <pre><code>class CommonInfoCollector:\n\tr\"\"\"\n\tCollect CommonInfo from the user.\n\trefer to `..types.common_info.CollectingCommonInfo` for the detail of CommonInfo.\n\n\tArgs:\n\t\tllm (LLM): The used LLM.\n\t\trequired_infos (List[CollectingInfoBase]): The required infos.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tllm: LLM,\n\t\trequired_infos: List[CollectingInfoBase],\n\t):\n\t\tself._llm = llm\n\t\tself._common_infos = self.get_common_infos(required_infos=required_infos)\n\t\tself._collect_manager = CollectManager(llm=llm)\n\n\tdef get_common_infos(\n\t\tself,\n\t\trequired_infos: List[CollectingInfoBase],\n\t) -&gt; CollectingCommonInfo:\n\t\tr\"\"\"\n\t\tChoose the CollectingCommonInfo from the required_infos.\n\n\t\tArgs:\n\t\t\trequired_infos (List[CollectingInfoBase]): The required infos.\n\n\t\tReturns:\n\t\t\tCollectingCommonInfo: All required CollectingCommonInfo are aggregated in a  CollectingCommonInfo.\n\t\t\t\tIf no CollectingCommonInfo required, return None.\n\t\t\"\"\"\n\t\tcommon_info = None\n\t\tfor info in required_infos:\n\t\t\tif isinstance(info, CollectingCommonInfo):\n\t\t\t\tif common_info is None:\n\t\t\t\t\tcommon_info = copy.deepcopy(info)\n\t\t\t\telse:\n\t\t\t\t\tcommon_info.insert_info(info)\n\t\treturn common_info\n\n\t@property\n\tdef collecting_keys(self) -&gt; Optional[List[str]]:\n\t\tr\"\"\" The information to be collected currently. \"\"\"\n\t\tif self._common_infos is None:\n\t\t\treturn None\n\n\t\treturn self._common_infos.collecting_keys\n\n\t@property\n\tdef collected_infos(self) -&gt; Optional[Dict[str, str]]:\n\t\tr\"\"\" The Collected Common information. \"\"\"\n\t\tif self._common_infos is None:\n\t\t\treturn None\n\n\t\treturn self._common_infos.collected_infos\n\n\t@property\n\tdef collected(self):\n\t\tr\"\"\" Whether all Common information are collected or not. \"\"\"\n\t\tif self._common_infos is None:\n\t\t\treturn True\n\n\t\treturn self._common_infos.collected\n\n\t@property\n\tdef collecting_query(self) -&gt; str:\n\t\tr\"\"\" This query will be sent to user to collect rest Common information. \"\"\"\n\t\tquery_to_user = f\"{COLLECT_COMMON_INFO_QUERY}\\n\"\n\t\tfor key in self.collecting_keys:\n\t\t\tquery_to_user += f\"\\t{key}\\n\"\n\t\treturn query_to_user\n\n\tdef collect(\n\t\tself,\n\t\tuser_id: str,\n\t\tquery_str: Optional[str] = None,\n\t) -&gt; bool:\n\t\tr\"\"\"\n\t\tCollect the Common information.\n\n\t\tReturns:\n\t\t\tbool: Whether the user aborts the collecting process.\n\t\t\"\"\"\n\t\tif self._common_infos is None:\n\t\t\treturn False\n\n\t\tquery_to_user = self.collecting_query\n\t\tif query_str:\n\t\t\tquery_to_user = \"\\n\".join([query_str, query_to_user])\n\n\t\t# TODO: send the message to the user.\n\t\tprint(query_to_user)\n\n\t\t# TODO: receive the message from the user.\n\t\tuser_msg = ChatBuffer.test_get_user_text(user_id=user_id)\n\t\tuser_response = user_msg.user_msg\n\t\tabort = self._collect_manager.analyze_whether_abort(user_response=user_response)\n\t\tif abort:\n\t\t\treturn abort\n\n\t\tfor batch_info_dict in self._common_infos.info_content():\n\t\t\tpredict_kwargs = {\n\t\t\t\t\"prompt\": COLLECT_COMMON_INFO_PROMPT,\n\t\t\t\tCollectPromptKeys.user_response_key: user_response,\n\t\t\t}\n\t\t\tpredict_kwargs.update(batch_info_dict)\n\t\t\textract_info = self._llm.predict(**predict_kwargs)\n\t\t\tnew_info_dict = parse_common_collected_info(\n\t\t\t\textract_info=extract_info,\n\t\t\t\tinfo_keys=self._common_infos.collecting_keys,\n\t\t\t)\n\t\t\tself._common_infos.update_collected_info(collected_info_dict=new_info_dict)\n\t\treturn abort\n\n\tasync def acollect(\n\t\tself,\n\t\tuser_id: str,\n\t\tquery_str: Optional[str] = None,\n\t) -&gt; bool:\n\t\tr\"\"\"\n\t\tAsynchronously collect the Common information.\n\n\t\tReturns:\n\t\t\tbool: Whether the user aborts the collecting process.\n\t\t\"\"\"\n\t\tif self._common_infos is None:\n\t\t\treturn False\n\n\t\tquery_to_user = self.collecting_query\n\t\tif query_str:\n\t\t\tquery_to_user = \"\\n\".join([query_str, query_to_user])\n\n\t\t# TODO: send the message to the user.\n\t\tChatBuffer.put_agent_reply(\n\t\t\tuser_id=user_id,\n\t\t\treply_str=query_to_user,\n\t\t\tinner_chat=True,\n\t\t)\n\n\t\t# TODO: receive the message from the user.\n\t\tuser_msg = await ChatBuffer.get_user_msg(user_id=user_id)\n\n\n\n\n\t\tuser_response = user_msg.user_msg\n\n\t\tabort = await self._collect_manager.async_analyze_whether_abort(user_response=user_response)\n\t\tif abort:\n\t\t\treturn abort\n\n\t\tfor batch_info_dict in self._common_infos.info_content():\n\t\t\tpredict_kwargs = {\n\t\t\t\t\"prompt\": COLLECT_COMMON_INFO_PROMPT,\n\t\t\t\tCollectPromptKeys.user_response_key: user_response,\n\t\t\t}\n\t\t\tpredict_kwargs.update(batch_info_dict)\n\t\t\textract_info = await self._llm.apredict(**predict_kwargs)\n\t\t\tnew_info_dict = parse_common_collected_info(\n\t\t\t\textract_info=extract_info,\n\t\t\t\tinfo_keys=self._common_infos.collecting_keys,\n\t\t\t)\n\t\t\tself._common_infos.update_collected_info(collected_info_dict=new_info_dict)\n\t\treturn abort\n\n\tdef modify(self, user_id: str) -&gt; Tuple[bool, bool]:\n\t\tr\"\"\"\n\t\tModify the collected information according to the user's comment.\n\n\t\tReturns:\n\t\t\tTuple[str, str]:\n\t\t\t\t- doing_modify: Whether the user thinks the collected information need modification.\n\t\t\t\t- abort: Whether the user aborts the collection process.\n\t\t\"\"\"\n\t\tif self._common_infos is None:\n\t\t\treturn False, False\n\n\t\tdoing_modify = True\n\t\tabort = False\n\t\twhile doing_modify and not abort:\n\t\t\tquery_to_user =self._collect_manager.verify_query(collected_info_dict=self.collected_infos)\n\t\t\t# TODO: send the message to the user.\n\t\t\tprint(query_to_user)\n\t\t\t# TODO: receive the message from the user.\n\t\t\tuser_msg = ChatBuffer.test_get_user_text(user_id=user_id)\n\t\t\tuser_response = user_msg.user_msg\n\t\t\tabort = self._collect_manager.analyze_whether_abort(user_response=user_response)\n\t\t\tif abort:\n\t\t\t\tbreak\n\t\t\tdoing_modify = self._collect_manager.analyze_whether_modify(\n\t\t\t\tuser_response=user_response,\n\t\t\t\tcollected_info_dict=self.collected_infos\n\t\t\t)\n\t\t\tif doing_modify:\n\t\t\t\tself.single_modify(user_response=user_response)\n\t\treturn doing_modify, abort\n\n\tasync def amodify(self, user_id: str) -&gt; Tuple[bool, bool]:\n\t\tr\"\"\"\n\t\tAsynchronously modify the collected information according to the user's comment.\n\n\t\tReturns:\n\t\t\tTuple[str, str]:\n\t\t\t\t- doing_modify: Whether the user thinks the collected information need modification.\n\t\t\t\t- abort: Whether the user aborts the collection process.\n\t\t\"\"\"\n\t\tif self._common_infos is None:\n\t\t\treturn False, False\n\n\t\tdoing_modify = True\n\t\tabort = False\n\t\twhile doing_modify and not abort:\n\t\t\tquery_to_user = self._collect_manager.verify_query(collected_info_dict=self.collected_infos)\n\t\t\t# TODO: send the message to the user.\n\t\t\tChatBuffer.put_agent_reply(\n\t\t\t\tuser_id=user_id,\n\t\t\t\treply_str=query_to_user,\n\t\t\t\tinner_chat=True,\n\t\t\t)\n\t\t\t# TODO: receive the message from the user.\n\t\t\tuser_msg = await ChatBuffer.get_user_msg(user_id=user_id)\n\t\t\tuser_response = user_msg.user_msg\n\t\t\tabort = await self._collect_manager.async_analyze_whether_abort(user_response=user_response)\n\t\t\tif abort:\n\t\t\t\tbreak\n\t\t\tdoing_modify = await self._collect_manager.async_analyze_whether_modify(\n\t\t\t\tuser_response=user_response,\n\t\t\t\tcollected_info_dict=self.collected_infos\n\t\t\t)\n\t\t\tif doing_modify:\n\t\t\t\tawait self.asingle_modify(user_response=user_response)\n\t\treturn doing_modify, abort\n\n\n\tdef single_modify(self, user_response: str):\n\t\tr\"\"\"\n\t\tModify the collected information according to the user's comment.\n\n\t\tArgs:\n\t\t\tuser_response (str): The user's comment.\n\n\t\tReturns:\n\t\t\tNone\n\t\t\"\"\"\n\t\tfor batch_info_dict in self._common_infos.modify_info_content():\n\t\t\tpredict_kwargs = {\n\t\t\t\t\"prompt\": MODIFY_COMMON_INFO_PROMPT,\n\t\t\t\tModifyPromptKeys.user_comment_key: user_response,\n\t\t\t}\n\t\t\tpredict_kwargs.update(batch_info_dict)\n\t\t\textract_info = self._llm.predict(**predict_kwargs)\n\t\t\tnew_info_dict = parse_common_collected_info(\n\t\t\t\textract_info=extract_info,\n\t\t\t\tinfo_keys=list(self._common_infos.required_infos.keys()),\n\t\t\t)\n\t\t\tprint(\"modified: \", new_info_dict)\n\t\t\tself._common_infos.update_collected_info(collected_info_dict=new_info_dict)\n\n\tasync def asingle_modify(self, user_response: str):\n\t\tr\"\"\"\n\t\tAsynchronously modify the collected information according to the user's comment.\n\n\t\tArgs:\n\t\t\tuser_response (str): The user's comment.\n\n\t\tReturns:\n\t\t\tNone\n\t\t\"\"\"\n\t\tfor batch_info_dict in self._common_infos.modify_info_content():\n\t\t\tpredict_kwargs = {\n\t\t\t\t\"prompt\": MODIFY_COMMON_INFO_PROMPT,\n\t\t\t\tModifyPromptKeys.user_comment_key: user_response,\n\t\t\t}\n\t\t\tpredict_kwargs.update(batch_info_dict)\n\t\t\textract_info = await self._llm.apredict(**predict_kwargs)\n\t\t\tnew_info_dict = parse_common_collected_info(\n\t\t\t\textract_info=extract_info,\n\t\t\t\tinfo_keys=list(self._common_infos.required_infos.keys()),\n\t\t\t)\n\t\t\tprint(\"modified: \", new_info_dict)\n\t\t\tself._common_infos.update_collected_info(collected_info_dict=new_info_dict)\n</code></pre>"},{"location":"code_docs/interact/collect/collector/common_collector/#labridge.interact.collect.collector.common_collector.CommonInfoCollector.collected","title":"<code>labridge.interact.collect.collector.common_collector.CommonInfoCollector.collected</code>  <code>property</code>","text":"<p>Whether all Common information are collected or not.</p>"},{"location":"code_docs/interact/collect/collector/common_collector/#labridge.interact.collect.collector.common_collector.CommonInfoCollector.collected_infos","title":"<code>labridge.interact.collect.collector.common_collector.CommonInfoCollector.collected_infos: Optional[Dict[str, str]]</code>  <code>property</code>","text":"<p>The Collected Common information.</p>"},{"location":"code_docs/interact/collect/collector/common_collector/#labridge.interact.collect.collector.common_collector.CommonInfoCollector.collecting_keys","title":"<code>labridge.interact.collect.collector.common_collector.CommonInfoCollector.collecting_keys: Optional[List[str]]</code>  <code>property</code>","text":"<p>The information to be collected currently.</p>"},{"location":"code_docs/interact/collect/collector/common_collector/#labridge.interact.collect.collector.common_collector.CommonInfoCollector.collecting_query","title":"<code>labridge.interact.collect.collector.common_collector.CommonInfoCollector.collecting_query: str</code>  <code>property</code>","text":"<p>This query will be sent to user to collect rest Common information.</p>"},{"location":"code_docs/interact/collect/collector/common_collector/#labridge.interact.collect.collector.common_collector.CommonInfoCollector.acollect","title":"<code>labridge.interact.collect.collector.common_collector.CommonInfoCollector.acollect(user_id, query_str=None)</code>  <code>async</code>","text":"<p>Asynchronously collect the Common information.</p> RETURNS DESCRIPTION <code>bool</code> <p>Whether the user aborts the collecting process.</p> <p> TYPE: <code>bool</code> </p> Source code in <code>labridge\\interact\\collect\\collector\\common_collector.py</code> <pre><code>async def acollect(\n\tself,\n\tuser_id: str,\n\tquery_str: Optional[str] = None,\n) -&gt; bool:\n\tr\"\"\"\n\tAsynchronously collect the Common information.\n\n\tReturns:\n\t\tbool: Whether the user aborts the collecting process.\n\t\"\"\"\n\tif self._common_infos is None:\n\t\treturn False\n\n\tquery_to_user = self.collecting_query\n\tif query_str:\n\t\tquery_to_user = \"\\n\".join([query_str, query_to_user])\n\n\t# TODO: send the message to the user.\n\tChatBuffer.put_agent_reply(\n\t\tuser_id=user_id,\n\t\treply_str=query_to_user,\n\t\tinner_chat=True,\n\t)\n\n\t# TODO: receive the message from the user.\n\tuser_msg = await ChatBuffer.get_user_msg(user_id=user_id)\n\n\n\n\n\tuser_response = user_msg.user_msg\n\n\tabort = await self._collect_manager.async_analyze_whether_abort(user_response=user_response)\n\tif abort:\n\t\treturn abort\n\n\tfor batch_info_dict in self._common_infos.info_content():\n\t\tpredict_kwargs = {\n\t\t\t\"prompt\": COLLECT_COMMON_INFO_PROMPT,\n\t\t\tCollectPromptKeys.user_response_key: user_response,\n\t\t}\n\t\tpredict_kwargs.update(batch_info_dict)\n\t\textract_info = await self._llm.apredict(**predict_kwargs)\n\t\tnew_info_dict = parse_common_collected_info(\n\t\t\textract_info=extract_info,\n\t\t\tinfo_keys=self._common_infos.collecting_keys,\n\t\t)\n\t\tself._common_infos.update_collected_info(collected_info_dict=new_info_dict)\n\treturn abort\n</code></pre>"},{"location":"code_docs/interact/collect/collector/common_collector/#labridge.interact.collect.collector.common_collector.CommonInfoCollector.amodify","title":"<code>labridge.interact.collect.collector.common_collector.CommonInfoCollector.amodify(user_id)</code>  <code>async</code>","text":"<p>Asynchronously modify the collected information according to the user's comment.</p> RETURNS DESCRIPTION <code>Tuple[bool, bool]</code> <p>Tuple[str, str]: - doing_modify: Whether the user thinks the collected information need modification. - abort: Whether the user aborts the collection process.</p> Source code in <code>labridge\\interact\\collect\\collector\\common_collector.py</code> <pre><code>async def amodify(self, user_id: str) -&gt; Tuple[bool, bool]:\n\tr\"\"\"\n\tAsynchronously modify the collected information according to the user's comment.\n\n\tReturns:\n\t\tTuple[str, str]:\n\t\t\t- doing_modify: Whether the user thinks the collected information need modification.\n\t\t\t- abort: Whether the user aborts the collection process.\n\t\"\"\"\n\tif self._common_infos is None:\n\t\treturn False, False\n\n\tdoing_modify = True\n\tabort = False\n\twhile doing_modify and not abort:\n\t\tquery_to_user = self._collect_manager.verify_query(collected_info_dict=self.collected_infos)\n\t\t# TODO: send the message to the user.\n\t\tChatBuffer.put_agent_reply(\n\t\t\tuser_id=user_id,\n\t\t\treply_str=query_to_user,\n\t\t\tinner_chat=True,\n\t\t)\n\t\t# TODO: receive the message from the user.\n\t\tuser_msg = await ChatBuffer.get_user_msg(user_id=user_id)\n\t\tuser_response = user_msg.user_msg\n\t\tabort = await self._collect_manager.async_analyze_whether_abort(user_response=user_response)\n\t\tif abort:\n\t\t\tbreak\n\t\tdoing_modify = await self._collect_manager.async_analyze_whether_modify(\n\t\t\tuser_response=user_response,\n\t\t\tcollected_info_dict=self.collected_infos\n\t\t)\n\t\tif doing_modify:\n\t\t\tawait self.asingle_modify(user_response=user_response)\n\treturn doing_modify, abort\n</code></pre>"},{"location":"code_docs/interact/collect/collector/common_collector/#labridge.interact.collect.collector.common_collector.CommonInfoCollector.asingle_modify","title":"<code>labridge.interact.collect.collector.common_collector.CommonInfoCollector.asingle_modify(user_response)</code>  <code>async</code>","text":"<p>Asynchronously modify the collected information according to the user's comment.</p> PARAMETER DESCRIPTION <code>user_response</code> <p>The user's comment.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <p>None</p> Source code in <code>labridge\\interact\\collect\\collector\\common_collector.py</code> <pre><code>async def asingle_modify(self, user_response: str):\n\tr\"\"\"\n\tAsynchronously modify the collected information according to the user's comment.\n\n\tArgs:\n\t\tuser_response (str): The user's comment.\n\n\tReturns:\n\t\tNone\n\t\"\"\"\n\tfor batch_info_dict in self._common_infos.modify_info_content():\n\t\tpredict_kwargs = {\n\t\t\t\"prompt\": MODIFY_COMMON_INFO_PROMPT,\n\t\t\tModifyPromptKeys.user_comment_key: user_response,\n\t\t}\n\t\tpredict_kwargs.update(batch_info_dict)\n\t\textract_info = await self._llm.apredict(**predict_kwargs)\n\t\tnew_info_dict = parse_common_collected_info(\n\t\t\textract_info=extract_info,\n\t\t\tinfo_keys=list(self._common_infos.required_infos.keys()),\n\t\t)\n\t\tprint(\"modified: \", new_info_dict)\n\t\tself._common_infos.update_collected_info(collected_info_dict=new_info_dict)\n</code></pre>"},{"location":"code_docs/interact/collect/collector/common_collector/#labridge.interact.collect.collector.common_collector.CommonInfoCollector.collect","title":"<code>labridge.interact.collect.collector.common_collector.CommonInfoCollector.collect(user_id, query_str=None)</code>","text":"<p>Collect the Common information.</p> RETURNS DESCRIPTION <code>bool</code> <p>Whether the user aborts the collecting process.</p> <p> TYPE: <code>bool</code> </p> Source code in <code>labridge\\interact\\collect\\collector\\common_collector.py</code> <pre><code>def collect(\n\tself,\n\tuser_id: str,\n\tquery_str: Optional[str] = None,\n) -&gt; bool:\n\tr\"\"\"\n\tCollect the Common information.\n\n\tReturns:\n\t\tbool: Whether the user aborts the collecting process.\n\t\"\"\"\n\tif self._common_infos is None:\n\t\treturn False\n\n\tquery_to_user = self.collecting_query\n\tif query_str:\n\t\tquery_to_user = \"\\n\".join([query_str, query_to_user])\n\n\t# TODO: send the message to the user.\n\tprint(query_to_user)\n\n\t# TODO: receive the message from the user.\n\tuser_msg = ChatBuffer.test_get_user_text(user_id=user_id)\n\tuser_response = user_msg.user_msg\n\tabort = self._collect_manager.analyze_whether_abort(user_response=user_response)\n\tif abort:\n\t\treturn abort\n\n\tfor batch_info_dict in self._common_infos.info_content():\n\t\tpredict_kwargs = {\n\t\t\t\"prompt\": COLLECT_COMMON_INFO_PROMPT,\n\t\t\tCollectPromptKeys.user_response_key: user_response,\n\t\t}\n\t\tpredict_kwargs.update(batch_info_dict)\n\t\textract_info = self._llm.predict(**predict_kwargs)\n\t\tnew_info_dict = parse_common_collected_info(\n\t\t\textract_info=extract_info,\n\t\t\tinfo_keys=self._common_infos.collecting_keys,\n\t\t)\n\t\tself._common_infos.update_collected_info(collected_info_dict=new_info_dict)\n\treturn abort\n</code></pre>"},{"location":"code_docs/interact/collect/collector/common_collector/#labridge.interact.collect.collector.common_collector.CommonInfoCollector.get_common_infos","title":"<code>labridge.interact.collect.collector.common_collector.CommonInfoCollector.get_common_infos(required_infos)</code>","text":"<p>Choose the CollectingCommonInfo from the required_infos.</p> PARAMETER DESCRIPTION <code>required_infos</code> <p>The required infos.</p> <p> TYPE: <code>List[CollectingInfoBase]</code> </p> RETURNS DESCRIPTION <code>CollectingCommonInfo</code> <p>All required CollectingCommonInfo are aggregated in a  CollectingCommonInfo. If no CollectingCommonInfo required, return None.</p> <p> TYPE: <code>CollectingCommonInfo</code> </p> Source code in <code>labridge\\interact\\collect\\collector\\common_collector.py</code> <pre><code>def get_common_infos(\n\tself,\n\trequired_infos: List[CollectingInfoBase],\n) -&gt; CollectingCommonInfo:\n\tr\"\"\"\n\tChoose the CollectingCommonInfo from the required_infos.\n\n\tArgs:\n\t\trequired_infos (List[CollectingInfoBase]): The required infos.\n\n\tReturns:\n\t\tCollectingCommonInfo: All required CollectingCommonInfo are aggregated in a  CollectingCommonInfo.\n\t\t\tIf no CollectingCommonInfo required, return None.\n\t\"\"\"\n\tcommon_info = None\n\tfor info in required_infos:\n\t\tif isinstance(info, CollectingCommonInfo):\n\t\t\tif common_info is None:\n\t\t\t\tcommon_info = copy.deepcopy(info)\n\t\t\telse:\n\t\t\t\tcommon_info.insert_info(info)\n\treturn common_info\n</code></pre>"},{"location":"code_docs/interact/collect/collector/common_collector/#labridge.interact.collect.collector.common_collector.CommonInfoCollector.modify","title":"<code>labridge.interact.collect.collector.common_collector.CommonInfoCollector.modify(user_id)</code>","text":"<p>Modify the collected information according to the user's comment.</p> RETURNS DESCRIPTION <code>Tuple[bool, bool]</code> <p>Tuple[str, str]: - doing_modify: Whether the user thinks the collected information need modification. - abort: Whether the user aborts the collection process.</p> Source code in <code>labridge\\interact\\collect\\collector\\common_collector.py</code> <pre><code>def modify(self, user_id: str) -&gt; Tuple[bool, bool]:\n\tr\"\"\"\n\tModify the collected information according to the user's comment.\n\n\tReturns:\n\t\tTuple[str, str]:\n\t\t\t- doing_modify: Whether the user thinks the collected information need modification.\n\t\t\t- abort: Whether the user aborts the collection process.\n\t\"\"\"\n\tif self._common_infos is None:\n\t\treturn False, False\n\n\tdoing_modify = True\n\tabort = False\n\twhile doing_modify and not abort:\n\t\tquery_to_user =self._collect_manager.verify_query(collected_info_dict=self.collected_infos)\n\t\t# TODO: send the message to the user.\n\t\tprint(query_to_user)\n\t\t# TODO: receive the message from the user.\n\t\tuser_msg = ChatBuffer.test_get_user_text(user_id=user_id)\n\t\tuser_response = user_msg.user_msg\n\t\tabort = self._collect_manager.analyze_whether_abort(user_response=user_response)\n\t\tif abort:\n\t\t\tbreak\n\t\tdoing_modify = self._collect_manager.analyze_whether_modify(\n\t\t\tuser_response=user_response,\n\t\t\tcollected_info_dict=self.collected_infos\n\t\t)\n\t\tif doing_modify:\n\t\t\tself.single_modify(user_response=user_response)\n\treturn doing_modify, abort\n</code></pre>"},{"location":"code_docs/interact/collect/collector/common_collector/#labridge.interact.collect.collector.common_collector.CommonInfoCollector.single_modify","title":"<code>labridge.interact.collect.collector.common_collector.CommonInfoCollector.single_modify(user_response)</code>","text":"<p>Modify the collected information according to the user's comment.</p> PARAMETER DESCRIPTION <code>user_response</code> <p>The user's comment.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <p>None</p> Source code in <code>labridge\\interact\\collect\\collector\\common_collector.py</code> <pre><code>def single_modify(self, user_response: str):\n\tr\"\"\"\n\tModify the collected information according to the user's comment.\n\n\tArgs:\n\t\tuser_response (str): The user's comment.\n\n\tReturns:\n\t\tNone\n\t\"\"\"\n\tfor batch_info_dict in self._common_infos.modify_info_content():\n\t\tpredict_kwargs = {\n\t\t\t\"prompt\": MODIFY_COMMON_INFO_PROMPT,\n\t\t\tModifyPromptKeys.user_comment_key: user_response,\n\t\t}\n\t\tpredict_kwargs.update(batch_info_dict)\n\t\textract_info = self._llm.predict(**predict_kwargs)\n\t\tnew_info_dict = parse_common_collected_info(\n\t\t\textract_info=extract_info,\n\t\t\tinfo_keys=list(self._common_infos.required_infos.keys()),\n\t\t)\n\t\tprint(\"modified: \", new_info_dict)\n\t\tself._common_infos.update_collected_info(collected_info_dict=new_info_dict)\n</code></pre>"},{"location":"code_docs/interact/collect/collector/select_collector/","title":"Select collector","text":""},{"location":"code_docs/interact/collect/collector/select_collector/#labridge.interact.collect.collector.select_collector","title":"<code>labridge.interact.collect.collector.select_collector</code>","text":""},{"location":"code_docs/interact/collect/collector/select_collector/#labridge.interact.collect.collector.select_collector.SelectInfoCollector","title":"<code>labridge.interact.collect.collector.select_collector.SelectInfoCollector</code>","text":"<p>Collect SelectInfo from the user. refer to <code>..types.select_info.CollectingSelectInfo</code> for the detail of SelectInfo.</p> PARAMETER DESCRIPTION <code>llm</code> <p>The used LLM.</p> <p> TYPE: <code>LLM</code> </p> <code>required_infos</code> <p>The required infos.</p> <p> TYPE: <code>List[CollectingInfoBase]</code> </p> Source code in <code>labridge\\interact\\collect\\collector\\select_collector.py</code> <pre><code>class SelectInfoCollector:\n\tr\"\"\"\n\tCollect SelectInfo from the user.\n\trefer to `..types.select_info.CollectingSelectInfo` for the detail of SelectInfo.\n\n\tArgs:\n\t\tllm (LLM): The used LLM.\n\t\trequired_infos (List[CollectingInfoBase]): The required infos.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tllm: LLM,\n\t\trequired_infos: List[CollectingInfoBase],\n\t):\n\t\tself._llm = llm\n\t\tself._select_infos = self.get_select_infos(required_infos=required_infos)\n\t\tself._collect_manager = CollectManager(llm=llm)\n\n\tdef get_select_infos(\n\t\tself,\n\t\trequired_infos: List[CollectingInfoBase],\n\t) -&gt; List[CollectingSelectInfo]:\n\t\tr\"\"\"\n\t\tChoose the CollectingSelectInfo from the required_infos.\n\n\t\tArgs:\n\t\t\trequired_infos (List[CollectingInfoBase]): The required infos.\n\n\t\tReturns:\n\t\t\tList[CollectingSelectInfo]: All required CollectingSelectInfo. They will be collected one by one.\n\t\t\"\"\"\n\t\tselect_infos = []\n\t\tfor info in required_infos:\n\t\t\tif isinstance(info, CollectingSelectInfo):\n\t\t\t\tselect_infos.append(info)\n\t\treturn select_infos\n\n\tdef collect_single_info(\n\t\tself,\n\t\tinfo: CollectingSelectInfo,\n\t\tuser_id: str,\n\t\tquery_str: Optional[str] = None,\n\t) -&gt; bool:\n\t\tr\"\"\"\n\t\tCollect a SelectInfo from the user.\n\n\t\tArgs:\n\t\t\tinfo (CollectingSelectInfo): The info waiting for the user's selection.\n\t\t\tuser_id (str): The user id of a Lab member.\n\n\t\tReturns:\n\t\t\tbool: Whether the user aborts the collecting process.\n\t\t\"\"\"\n\t\t# TODO: send to user:\n\t\tquery_to_user = self.collecting_query(info=info)\n\t\tif query_str:\n\t\t\tquery_to_user = \"\\n\".join([query_str, query_to_user])\n\n\t\tprint(\"Assistant: \", query_to_user)\n\n\t\t# TODO: receive from user.\n\t\tuser_msg = ChatBuffer.test_get_user_text(user_id=user_id)\n\t\tuser_response = user_msg.user_msg\n\n\t\tabort = self._collect_manager.analyze_whether_abort(user_response=user_response)\n\t\tif abort:\n\t\t\treturn abort\n\n\t\tpredict_kwargs = {\n\t\t\t\"prompt\": COLLECT_SELECT_INFO_PROMPT,\n\t\t\tCollectPromptKeys.user_response_key: user_response,\n\t\t}\n\n\t\tall_choices, all_relevances = [], []\n\t\tfor batch_info_dict, batch_candidates in info.info_content():\n\t\t\tpredict_kwargs.update(batch_info_dict)\n\t\t\traw_response = self._llm.predict(**predict_kwargs)\n\n\t\t\traw_choices, relevances = default_parse_choice_select_answer_fn(raw_response, len(batch_candidates))\n\t\t\tchoice_idxs = [choice - 1 for choice in raw_choices]\n\t\t\tbatch_choices = [batch_candidates[ci] for ci in choice_idxs]\n\n\t\t\tall_choices.extend(batch_choices)\n\t\t\tall_relevances.extend(relevances)\n\n\t\tif all_choices:\n\t\t\tzipped_list = list(zip(all_choices, all_relevances))\n\t\t\tsorted_list = sorted(zipped_list, key=lambda x: x[1], reverse=True)\n\t\t\tcollected_info, score = sorted_list[0]\n\t\t\tinfo.update_collected_info(\n\t\t\t\tcollected_info_dict={info.info_name: collected_info}\n\t\t\t)\n\t\treturn abort\n\n\tasync def acollect_single_info(\n\t\tself,\n\t\tinfo: CollectingSelectInfo,\n\t\tuser_id: str,\n\t\tquery_str: Optional[str] = None,\n\t) -&gt; bool:\n\t\tr\"\"\"\n\t\tAsynchronously collect a SelectInfo from the user.\n\n\t\tArgs:\n\t\t\tinfo (CollectingSelectInfo): The info waiting for the user's selection.\n\t\t\tuser_id (str): The user id of a Lab member.\n\n\t\tReturns:\n\t\t\tbool: Whether the user aborts the collecting process.\n\t\t\"\"\"\n\t\t# TODO: send to user:\n\t\tquery_to_user = self.collecting_query(info=info)\n\t\tif query_str:\n\t\t\tquery_to_user = \"\\n\".join([query_str, query_to_user])\n\n\t\tChatBuffer.put_agent_reply(\n\t\t\tuser_id=user_id,\n\t\t\treply_str=query_to_user,\n\t\t\tinner_chat=True,\n\t\t)\n\n\t\t# TODO: receive from user.\n\t\tuser_msg = await ChatBuffer.get_user_msg(user_id=user_id)\n\t\tuser_response = user_msg.user_msg\n\n\t\tabort = await self._collect_manager.async_analyze_whether_abort(user_response=user_response)\n\t\tif abort:\n\t\t\treturn abort\n\n\t\tpredict_kwargs = {\n\t\t\t\"prompt\": COLLECT_SELECT_INFO_PROMPT,\n\t\t\tCollectPromptKeys.user_response_key: user_response,\n\t\t}\n\n\t\tall_choices, all_relevances = [], []\n\t\tfor batch_info_dict, batch_candidates in info.info_content():\n\t\t\tpredict_kwargs.update(batch_info_dict)\n\t\t\traw_response = await self._llm.apredict(**predict_kwargs)\n\n\t\t\traw_choices, relevances = default_parse_choice_select_answer_fn(raw_response, len(batch_candidates))\n\t\t\tchoice_idxs = [choice - 1 for choice in raw_choices]\n\t\t\tbatch_choices = [batch_candidates[ci] for ci in choice_idxs]\n\n\t\t\tall_choices.extend(batch_choices)\n\t\t\tall_relevances.extend(relevances)\n\n\t\tif all_choices:\n\t\t\tzipped_list = list(zip(all_choices, all_relevances))\n\t\t\tsorted_list = sorted(zipped_list, key=lambda x: x[1], reverse=True)\n\t\t\tcollected_info, score = sorted_list[0]\n\t\t\tinfo.update_collected_info(\n\t\t\t\tcollected_info_dict={info.info_name: collected_info}\n\t\t\t)\n\t\treturn abort\n\n\tdef collect(\n\t\tself,\n\t\tuser_id: str,\n\t\tquery_str: Optional[str] = None,\n\t) -&gt; bool:\n\t\tr\"\"\"\n\t\tCollect all SelectInfo.\n\n\t\tReturns:\n\t\t\tbool: Whether the user aborts the collecting process.\n\t\t\"\"\"\n\t\tfor info in self._select_infos:\n\t\t\tabort = self.collect_single_info(info=info, user_id=user_id, query_str=query_str)\n\t\t\tif abort:\n\t\t\t\treturn True\n\t\treturn False\n\n\tasync def acollect(\n\t\tself,\n\t\tuser_id: str,\n\t\tquery_str: Optional[str] = None,\n\t) -&gt; bool:\n\t\tr\"\"\"\n\t\tAsynchronously collect all SelectInfo.\n\n\t\tReturns:\n\t\t\tbool: Whether the user aborts the collecting process.\n\t\t\"\"\"\n\t\tfor info in self._select_infos:\n\t\t\tabort = await self.acollect_single_info(info=info, user_id=user_id, query_str=query_str)\n\t\t\tif abort:\n\t\t\t\treturn True\n\t\treturn False\n\n\tdef collecting_query(self, info: CollectingSelectInfo) -&gt; str:\n\t\tr\"\"\"\n\t\tThis query will be sent to user to collect rest Common information\n\n\t\tArgs:\n\t\t\tinfo (CollectingSelectInfo): The SelectInfo to be collected.\n\n\t\tReturns:\n\t\t\tThe query.\n\t\t\"\"\"\n\t\tif info is None:\n\t\t\treturn \"\"\n\t\tquery_to_user = f\"{COLLECT_SELECT_INFO_QUERY}\\n\"\n\t\tfor key in info.collecting_keys:\n\t\t\tquery_to_user += f\"\\t{key}\\n\"\n\t\tquery_to_user += \"Candidates:\\n\"\n\t\tfor choice in info.candidates:\n\t\t\tquery_to_user += f\"\\t{choice}\\n\"\n\t\treturn query_to_user\n\n\tdef modify_single_info(self, user_response: str,  info: CollectingSelectInfo):\n\t\tr\"\"\"\n\t\tModify a collected SelectInfo according to the user's comment.\n\n\t\tArgs:\n\t\t\tuser_response (str): The user's comment.\n\t\t\tinfo (CollectingSelectInfo): The collected SelectInfo.\n\n\t\tReturns:\n\t\t\tNone\n\t\t\"\"\"\n\t\tpredict_kwargs = {\n\t\t\t\"prompt\": MODIFY_SELECT_INFO_PROMPT,\n\t\t\tModifyPromptKeys.user_comment_key: user_response,\n\t\t}\n\n\t\tall_choices, all_possibilities = [], []\n\t\tfor batch_info_dict, batch_candidates in info.modify_info_content():\n\t\t\tpredict_kwargs.update(batch_info_dict)\n\t\t\traw_response = self._llm.predict(**predict_kwargs)\n\n\t\t\traw_choices, possibilities = default_parse_choice_select_answer_fn(raw_response, len(batch_candidates))\n\t\t\tchoice_idxs = [choice - 1 for choice in raw_choices]\n\t\t\tbatch_choices = [batch_candidates[ci] for ci in choice_idxs]\n\n\t\t\tall_choices.extend(batch_choices)\n\t\t\tall_possibilities.extend(possibilities)\n\n\t\tzipped_list = list(zip(all_choices, all_possibilities))\n\t\tsorted_list = sorted(zipped_list, key=lambda x: x[1], reverse=True)\n\t\tif sorted_list:\n\t\t\tcollected_info, score = sorted_list[0]\n\t\t\tif score &gt;= SELECT_MIN_SCORE:\n\t\t\t\tinfo.update_collected_info(\n\t\t\t\t\tcollected_info_dict={info.info_name: collected_info}\n\t\t\t\t)\n\n\tasync def amodify_single_info(self, user_response: str,  info: CollectingSelectInfo):\n\t\tr\"\"\"\n\t\tAsynchronously modify a collected SelectInfo according to the user's comment.\n\n\t\tArgs:\n\t\t\tuser_response (str): The user's comment.\n\t\t\tinfo (CollectingSelectInfo): The collected SelectInfo.\n\n\t\tReturns:\n\t\t\tNone\n\t\t\"\"\"\n\t\tpredict_kwargs = {\n\t\t\t\"prompt\": MODIFY_SELECT_INFO_PROMPT,\n\t\t\tModifyPromptKeys.user_comment_key: user_response,\n\t\t}\n\n\t\tall_choices, all_possibilities = [], []\n\t\tfor batch_info_dict, batch_candidates in info.modify_info_content():\n\t\t\tpredict_kwargs.update(batch_info_dict)\n\t\t\traw_response = await self._llm.apredict(**predict_kwargs)\n\n\t\t\traw_choices, possibilities = default_parse_choice_select_answer_fn(raw_response, len(batch_candidates))\n\t\t\tchoice_idxs = [choice - 1 for choice in raw_choices]\n\t\t\tbatch_choices = [batch_candidates[ci] for ci in choice_idxs]\n\n\t\t\tall_choices.extend(batch_choices)\n\t\t\tall_possibilities.extend(possibilities)\n\n\t\tzipped_list = list(zip(all_choices, all_possibilities))\n\t\tsorted_list = sorted(zipped_list, key=lambda x: x[1], reverse=True)\n\t\tif sorted_list:\n\t\t\tcollected_info, score = sorted_list[0]\n\t\t\tif score &gt;= SELECT_MIN_SCORE:\n\t\t\t\tinfo.update_collected_info(\n\t\t\t\t\tcollected_info_dict={info.info_name: collected_info}\n\t\t\t\t)\n\n\tdef modify(self, user_id: str) -&gt; Tuple[bool, bool]:\n\t\tr\"\"\"\n\t\tModify the collected SelectInfo according to the user's comment.\n\n\t\tReturns:\n\t\t\tTuple[str, str]:\n\t\t\t\t- doing_modify: Whether the user thinks the collected information need modification.\n\t\t\t\t- abort: Whether the user aborts the collection process.\n\t\t\"\"\"\n\t\tif len(self._select_infos) &lt; 1:\n\t\t\treturn False, False\n\n\t\tdoing_modify = True\n\t\tabort = False\n\t\twhile doing_modify and not abort:\n\t\t\tquery_to_user =self._collect_manager.verify_query(collected_info_dict=self.collected_infos)\n\t\t\t# TODO: send the message to the user.\n\t\t\tprint(query_to_user)\n\n\t\t\t# TODO: receive the message from the user.\n\t\t\tuser_msg = ChatBuffer.test_get_user_text(user_id=user_id)\n\t\t\tuser_response = user_msg.user_msg\n\t\t\tabort = self._collect_manager.analyze_whether_abort(user_response=user_response)\n\t\t\tif abort:\n\t\t\t\tbreak\n\t\t\tdoing_modify = self._collect_manager.analyze_whether_modify(\n\t\t\t\tuser_response=user_response,\n\t\t\t\tcollected_info_dict=self.collected_infos\n\t\t\t)\n\t\t\tif doing_modify:\n\t\t\t\tself.single_modify(user_response=user_response)\n\t\treturn doing_modify, abort\n\n\tasync def amodify(self, user_id: str) -&gt; Tuple[bool, bool]:\n\t\tr\"\"\"\n\t\tAsynchronously modify the collected SelectInfo according to the user's comment.\n\n\t\tReturns:\n\t\t\tTuple[str, str]:\n\t\t\t\t- doing_modify: Whether the user thinks the collected information need modification.\n\t\t\t\t- abort: Whether the user aborts the collection process.\n\t\t\"\"\"\n\t\tif len(self._select_infos) &lt; 1:\n\t\t\treturn False, False\n\n\t\tdoing_modify = True\n\t\tabort = False\n\t\twhile doing_modify and not abort:\n\t\t\tquery_to_user =self._collect_manager.verify_query(collected_info_dict=self.collected_infos)\n\t\t\t# TODO: send the message to the user.\n\t\t\tChatBuffer.put_agent_reply(\n\t\t\t\tuser_id=user_id,\n\t\t\t\treply_str=query_to_user,\n\t\t\t\tinner_chat=True,\n\t\t\t)\n\n\t\t\t# TODO: receive the message from the user.\n\t\t\tuser_msg = await ChatBuffer.get_user_msg(user_id=user_id)\n\t\t\tuser_response = user_msg.user_msg\n\t\t\tabort = await self._collect_manager.async_analyze_whether_abort(user_response=user_response)\n\t\t\tif abort:\n\t\t\t\tbreak\n\t\t\tdoing_modify = await self._collect_manager.async_analyze_whether_modify(\n\t\t\t\tuser_response=user_response,\n\t\t\t\tcollected_info_dict=self.collected_infos\n\t\t\t)\n\t\t\tif doing_modify:\n\t\t\t\tawait self.asingle_modify(user_response=user_response)\n\t\treturn doing_modify, abort\n\n\n\tdef single_modify(self, user_response: str):\n\t\tr\"\"\" Modify \"\"\"\n\t\tfor info in self._select_infos:\n\t\t\tself.modify_single_info(user_response=user_response, info=info)\n\n\tasync def asingle_modify(self, user_response: str):\n\t\tr\"\"\" Asynchronously modify \"\"\"\n\t\tfor info in self._select_infos:\n\t\t\tawait self.amodify_single_info(user_response=user_response, info=info)\n\n\t@property\n\tdef collecting_keys(self) -&gt; List[str]:\n\t\tr\"\"\"\n\t\tThe SelectInfo to be collected currently.\n\t\t\"\"\"\n\t\tcollecting = []\n\t\tfor info in self._select_infos:\n\t\t\tcollecting.extend(info.collecting_keys)\n\t\treturn collecting\n\n\t@property\n\tdef collected_infos(self) -&gt; Dict[str, str]:\n\t\tr\"\"\" The Collected SelectInfo. \"\"\"\n\t\tinfos = {}\n\t\tfor info in self._select_infos:\n\t\t\tinfos.update(info.collected_infos)\n\t\treturn infos\n\n\t@property\n\tdef collected(self):\n\t\tr\"\"\" Whether all SelectInfo are collected or not. \"\"\"\n\t\tfor info in self._select_infos:\n\t\t\tif not info.collected:\n\t\t\t\treturn False\n\t\treturn True\n</code></pre>"},{"location":"code_docs/interact/collect/collector/select_collector/#labridge.interact.collect.collector.select_collector.SelectInfoCollector.collected","title":"<code>labridge.interact.collect.collector.select_collector.SelectInfoCollector.collected</code>  <code>property</code>","text":"<p>Whether all SelectInfo are collected or not.</p>"},{"location":"code_docs/interact/collect/collector/select_collector/#labridge.interact.collect.collector.select_collector.SelectInfoCollector.collected_infos","title":"<code>labridge.interact.collect.collector.select_collector.SelectInfoCollector.collected_infos: Dict[str, str]</code>  <code>property</code>","text":"<p>The Collected SelectInfo.</p>"},{"location":"code_docs/interact/collect/collector/select_collector/#labridge.interact.collect.collector.select_collector.SelectInfoCollector.collecting_keys","title":"<code>labridge.interact.collect.collector.select_collector.SelectInfoCollector.collecting_keys: List[str]</code>  <code>property</code>","text":"<p>The SelectInfo to be collected currently.</p>"},{"location":"code_docs/interact/collect/collector/select_collector/#labridge.interact.collect.collector.select_collector.SelectInfoCollector.acollect","title":"<code>labridge.interact.collect.collector.select_collector.SelectInfoCollector.acollect(user_id, query_str=None)</code>  <code>async</code>","text":"<p>Asynchronously collect all SelectInfo.</p> RETURNS DESCRIPTION <code>bool</code> <p>Whether the user aborts the collecting process.</p> <p> TYPE: <code>bool</code> </p> Source code in <code>labridge\\interact\\collect\\collector\\select_collector.py</code> <pre><code>async def acollect(\n\tself,\n\tuser_id: str,\n\tquery_str: Optional[str] = None,\n) -&gt; bool:\n\tr\"\"\"\n\tAsynchronously collect all SelectInfo.\n\n\tReturns:\n\t\tbool: Whether the user aborts the collecting process.\n\t\"\"\"\n\tfor info in self._select_infos:\n\t\tabort = await self.acollect_single_info(info=info, user_id=user_id, query_str=query_str)\n\t\tif abort:\n\t\t\treturn True\n\treturn False\n</code></pre>"},{"location":"code_docs/interact/collect/collector/select_collector/#labridge.interact.collect.collector.select_collector.SelectInfoCollector.acollect_single_info","title":"<code>labridge.interact.collect.collector.select_collector.SelectInfoCollector.acollect_single_info(info, user_id, query_str=None)</code>  <code>async</code>","text":"<p>Asynchronously collect a SelectInfo from the user.</p> PARAMETER DESCRIPTION <code>info</code> <p>The info waiting for the user's selection.</p> <p> TYPE: <code>CollectingSelectInfo</code> </p> <code>user_id</code> <p>The user id of a Lab member.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>Whether the user aborts the collecting process.</p> <p> TYPE: <code>bool</code> </p> Source code in <code>labridge\\interact\\collect\\collector\\select_collector.py</code> <pre><code>async def acollect_single_info(\n\tself,\n\tinfo: CollectingSelectInfo,\n\tuser_id: str,\n\tquery_str: Optional[str] = None,\n) -&gt; bool:\n\tr\"\"\"\n\tAsynchronously collect a SelectInfo from the user.\n\n\tArgs:\n\t\tinfo (CollectingSelectInfo): The info waiting for the user's selection.\n\t\tuser_id (str): The user id of a Lab member.\n\n\tReturns:\n\t\tbool: Whether the user aborts the collecting process.\n\t\"\"\"\n\t# TODO: send to user:\n\tquery_to_user = self.collecting_query(info=info)\n\tif query_str:\n\t\tquery_to_user = \"\\n\".join([query_str, query_to_user])\n\n\tChatBuffer.put_agent_reply(\n\t\tuser_id=user_id,\n\t\treply_str=query_to_user,\n\t\tinner_chat=True,\n\t)\n\n\t# TODO: receive from user.\n\tuser_msg = await ChatBuffer.get_user_msg(user_id=user_id)\n\tuser_response = user_msg.user_msg\n\n\tabort = await self._collect_manager.async_analyze_whether_abort(user_response=user_response)\n\tif abort:\n\t\treturn abort\n\n\tpredict_kwargs = {\n\t\t\"prompt\": COLLECT_SELECT_INFO_PROMPT,\n\t\tCollectPromptKeys.user_response_key: user_response,\n\t}\n\n\tall_choices, all_relevances = [], []\n\tfor batch_info_dict, batch_candidates in info.info_content():\n\t\tpredict_kwargs.update(batch_info_dict)\n\t\traw_response = await self._llm.apredict(**predict_kwargs)\n\n\t\traw_choices, relevances = default_parse_choice_select_answer_fn(raw_response, len(batch_candidates))\n\t\tchoice_idxs = [choice - 1 for choice in raw_choices]\n\t\tbatch_choices = [batch_candidates[ci] for ci in choice_idxs]\n\n\t\tall_choices.extend(batch_choices)\n\t\tall_relevances.extend(relevances)\n\n\tif all_choices:\n\t\tzipped_list = list(zip(all_choices, all_relevances))\n\t\tsorted_list = sorted(zipped_list, key=lambda x: x[1], reverse=True)\n\t\tcollected_info, score = sorted_list[0]\n\t\tinfo.update_collected_info(\n\t\t\tcollected_info_dict={info.info_name: collected_info}\n\t\t)\n\treturn abort\n</code></pre>"},{"location":"code_docs/interact/collect/collector/select_collector/#labridge.interact.collect.collector.select_collector.SelectInfoCollector.amodify","title":"<code>labridge.interact.collect.collector.select_collector.SelectInfoCollector.amodify(user_id)</code>  <code>async</code>","text":"<p>Asynchronously modify the collected SelectInfo according to the user's comment.</p> RETURNS DESCRIPTION <code>Tuple[bool, bool]</code> <p>Tuple[str, str]: - doing_modify: Whether the user thinks the collected information need modification. - abort: Whether the user aborts the collection process.</p> Source code in <code>labridge\\interact\\collect\\collector\\select_collector.py</code> <pre><code>async def amodify(self, user_id: str) -&gt; Tuple[bool, bool]:\n\tr\"\"\"\n\tAsynchronously modify the collected SelectInfo according to the user's comment.\n\n\tReturns:\n\t\tTuple[str, str]:\n\t\t\t- doing_modify: Whether the user thinks the collected information need modification.\n\t\t\t- abort: Whether the user aborts the collection process.\n\t\"\"\"\n\tif len(self._select_infos) &lt; 1:\n\t\treturn False, False\n\n\tdoing_modify = True\n\tabort = False\n\twhile doing_modify and not abort:\n\t\tquery_to_user =self._collect_manager.verify_query(collected_info_dict=self.collected_infos)\n\t\t# TODO: send the message to the user.\n\t\tChatBuffer.put_agent_reply(\n\t\t\tuser_id=user_id,\n\t\t\treply_str=query_to_user,\n\t\t\tinner_chat=True,\n\t\t)\n\n\t\t# TODO: receive the message from the user.\n\t\tuser_msg = await ChatBuffer.get_user_msg(user_id=user_id)\n\t\tuser_response = user_msg.user_msg\n\t\tabort = await self._collect_manager.async_analyze_whether_abort(user_response=user_response)\n\t\tif abort:\n\t\t\tbreak\n\t\tdoing_modify = await self._collect_manager.async_analyze_whether_modify(\n\t\t\tuser_response=user_response,\n\t\t\tcollected_info_dict=self.collected_infos\n\t\t)\n\t\tif doing_modify:\n\t\t\tawait self.asingle_modify(user_response=user_response)\n\treturn doing_modify, abort\n</code></pre>"},{"location":"code_docs/interact/collect/collector/select_collector/#labridge.interact.collect.collector.select_collector.SelectInfoCollector.amodify_single_info","title":"<code>labridge.interact.collect.collector.select_collector.SelectInfoCollector.amodify_single_info(user_response, info)</code>  <code>async</code>","text":"<p>Asynchronously modify a collected SelectInfo according to the user's comment.</p> PARAMETER DESCRIPTION <code>user_response</code> <p>The user's comment.</p> <p> TYPE: <code>str</code> </p> <code>info</code> <p>The collected SelectInfo.</p> <p> TYPE: <code>CollectingSelectInfo</code> </p> RETURNS DESCRIPTION <p>None</p> Source code in <code>labridge\\interact\\collect\\collector\\select_collector.py</code> <pre><code>async def amodify_single_info(self, user_response: str,  info: CollectingSelectInfo):\n\tr\"\"\"\n\tAsynchronously modify a collected SelectInfo according to the user's comment.\n\n\tArgs:\n\t\tuser_response (str): The user's comment.\n\t\tinfo (CollectingSelectInfo): The collected SelectInfo.\n\n\tReturns:\n\t\tNone\n\t\"\"\"\n\tpredict_kwargs = {\n\t\t\"prompt\": MODIFY_SELECT_INFO_PROMPT,\n\t\tModifyPromptKeys.user_comment_key: user_response,\n\t}\n\n\tall_choices, all_possibilities = [], []\n\tfor batch_info_dict, batch_candidates in info.modify_info_content():\n\t\tpredict_kwargs.update(batch_info_dict)\n\t\traw_response = await self._llm.apredict(**predict_kwargs)\n\n\t\traw_choices, possibilities = default_parse_choice_select_answer_fn(raw_response, len(batch_candidates))\n\t\tchoice_idxs = [choice - 1 for choice in raw_choices]\n\t\tbatch_choices = [batch_candidates[ci] for ci in choice_idxs]\n\n\t\tall_choices.extend(batch_choices)\n\t\tall_possibilities.extend(possibilities)\n\n\tzipped_list = list(zip(all_choices, all_possibilities))\n\tsorted_list = sorted(zipped_list, key=lambda x: x[1], reverse=True)\n\tif sorted_list:\n\t\tcollected_info, score = sorted_list[0]\n\t\tif score &gt;= SELECT_MIN_SCORE:\n\t\t\tinfo.update_collected_info(\n\t\t\t\tcollected_info_dict={info.info_name: collected_info}\n\t\t\t)\n</code></pre>"},{"location":"code_docs/interact/collect/collector/select_collector/#labridge.interact.collect.collector.select_collector.SelectInfoCollector.asingle_modify","title":"<code>labridge.interact.collect.collector.select_collector.SelectInfoCollector.asingle_modify(user_response)</code>  <code>async</code>","text":"<p>Asynchronously modify</p> Source code in <code>labridge\\interact\\collect\\collector\\select_collector.py</code> <pre><code>async def asingle_modify(self, user_response: str):\n\tr\"\"\" Asynchronously modify \"\"\"\n\tfor info in self._select_infos:\n\t\tawait self.amodify_single_info(user_response=user_response, info=info)\n</code></pre>"},{"location":"code_docs/interact/collect/collector/select_collector/#labridge.interact.collect.collector.select_collector.SelectInfoCollector.collect","title":"<code>labridge.interact.collect.collector.select_collector.SelectInfoCollector.collect(user_id, query_str=None)</code>","text":"<p>Collect all SelectInfo.</p> RETURNS DESCRIPTION <code>bool</code> <p>Whether the user aborts the collecting process.</p> <p> TYPE: <code>bool</code> </p> Source code in <code>labridge\\interact\\collect\\collector\\select_collector.py</code> <pre><code>def collect(\n\tself,\n\tuser_id: str,\n\tquery_str: Optional[str] = None,\n) -&gt; bool:\n\tr\"\"\"\n\tCollect all SelectInfo.\n\n\tReturns:\n\t\tbool: Whether the user aborts the collecting process.\n\t\"\"\"\n\tfor info in self._select_infos:\n\t\tabort = self.collect_single_info(info=info, user_id=user_id, query_str=query_str)\n\t\tif abort:\n\t\t\treturn True\n\treturn False\n</code></pre>"},{"location":"code_docs/interact/collect/collector/select_collector/#labridge.interact.collect.collector.select_collector.SelectInfoCollector.collect_single_info","title":"<code>labridge.interact.collect.collector.select_collector.SelectInfoCollector.collect_single_info(info, user_id, query_str=None)</code>","text":"<p>Collect a SelectInfo from the user.</p> PARAMETER DESCRIPTION <code>info</code> <p>The info waiting for the user's selection.</p> <p> TYPE: <code>CollectingSelectInfo</code> </p> <code>user_id</code> <p>The user id of a Lab member.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>Whether the user aborts the collecting process.</p> <p> TYPE: <code>bool</code> </p> Source code in <code>labridge\\interact\\collect\\collector\\select_collector.py</code> <pre><code>def collect_single_info(\n\tself,\n\tinfo: CollectingSelectInfo,\n\tuser_id: str,\n\tquery_str: Optional[str] = None,\n) -&gt; bool:\n\tr\"\"\"\n\tCollect a SelectInfo from the user.\n\n\tArgs:\n\t\tinfo (CollectingSelectInfo): The info waiting for the user's selection.\n\t\tuser_id (str): The user id of a Lab member.\n\n\tReturns:\n\t\tbool: Whether the user aborts the collecting process.\n\t\"\"\"\n\t# TODO: send to user:\n\tquery_to_user = self.collecting_query(info=info)\n\tif query_str:\n\t\tquery_to_user = \"\\n\".join([query_str, query_to_user])\n\n\tprint(\"Assistant: \", query_to_user)\n\n\t# TODO: receive from user.\n\tuser_msg = ChatBuffer.test_get_user_text(user_id=user_id)\n\tuser_response = user_msg.user_msg\n\n\tabort = self._collect_manager.analyze_whether_abort(user_response=user_response)\n\tif abort:\n\t\treturn abort\n\n\tpredict_kwargs = {\n\t\t\"prompt\": COLLECT_SELECT_INFO_PROMPT,\n\t\tCollectPromptKeys.user_response_key: user_response,\n\t}\n\n\tall_choices, all_relevances = [], []\n\tfor batch_info_dict, batch_candidates in info.info_content():\n\t\tpredict_kwargs.update(batch_info_dict)\n\t\traw_response = self._llm.predict(**predict_kwargs)\n\n\t\traw_choices, relevances = default_parse_choice_select_answer_fn(raw_response, len(batch_candidates))\n\t\tchoice_idxs = [choice - 1 for choice in raw_choices]\n\t\tbatch_choices = [batch_candidates[ci] for ci in choice_idxs]\n\n\t\tall_choices.extend(batch_choices)\n\t\tall_relevances.extend(relevances)\n\n\tif all_choices:\n\t\tzipped_list = list(zip(all_choices, all_relevances))\n\t\tsorted_list = sorted(zipped_list, key=lambda x: x[1], reverse=True)\n\t\tcollected_info, score = sorted_list[0]\n\t\tinfo.update_collected_info(\n\t\t\tcollected_info_dict={info.info_name: collected_info}\n\t\t)\n\treturn abort\n</code></pre>"},{"location":"code_docs/interact/collect/collector/select_collector/#labridge.interact.collect.collector.select_collector.SelectInfoCollector.collecting_query","title":"<code>labridge.interact.collect.collector.select_collector.SelectInfoCollector.collecting_query(info)</code>","text":"<p>This query will be sent to user to collect rest Common information</p> PARAMETER DESCRIPTION <code>info</code> <p>The SelectInfo to be collected.</p> <p> TYPE: <code>CollectingSelectInfo</code> </p> RETURNS DESCRIPTION <code>str</code> <p>The query.</p> Source code in <code>labridge\\interact\\collect\\collector\\select_collector.py</code> <pre><code>def collecting_query(self, info: CollectingSelectInfo) -&gt; str:\n\tr\"\"\"\n\tThis query will be sent to user to collect rest Common information\n\n\tArgs:\n\t\tinfo (CollectingSelectInfo): The SelectInfo to be collected.\n\n\tReturns:\n\t\tThe query.\n\t\"\"\"\n\tif info is None:\n\t\treturn \"\"\n\tquery_to_user = f\"{COLLECT_SELECT_INFO_QUERY}\\n\"\n\tfor key in info.collecting_keys:\n\t\tquery_to_user += f\"\\t{key}\\n\"\n\tquery_to_user += \"Candidates:\\n\"\n\tfor choice in info.candidates:\n\t\tquery_to_user += f\"\\t{choice}\\n\"\n\treturn query_to_user\n</code></pre>"},{"location":"code_docs/interact/collect/collector/select_collector/#labridge.interact.collect.collector.select_collector.SelectInfoCollector.get_select_infos","title":"<code>labridge.interact.collect.collector.select_collector.SelectInfoCollector.get_select_infos(required_infos)</code>","text":"<p>Choose the CollectingSelectInfo from the required_infos.</p> PARAMETER DESCRIPTION <code>required_infos</code> <p>The required infos.</p> <p> TYPE: <code>List[CollectingInfoBase]</code> </p> RETURNS DESCRIPTION <code>List[CollectingSelectInfo]</code> <p>List[CollectingSelectInfo]: All required CollectingSelectInfo. They will be collected one by one.</p> Source code in <code>labridge\\interact\\collect\\collector\\select_collector.py</code> <pre><code>def get_select_infos(\n\tself,\n\trequired_infos: List[CollectingInfoBase],\n) -&gt; List[CollectingSelectInfo]:\n\tr\"\"\"\n\tChoose the CollectingSelectInfo from the required_infos.\n\n\tArgs:\n\t\trequired_infos (List[CollectingInfoBase]): The required infos.\n\n\tReturns:\n\t\tList[CollectingSelectInfo]: All required CollectingSelectInfo. They will be collected one by one.\n\t\"\"\"\n\tselect_infos = []\n\tfor info in required_infos:\n\t\tif isinstance(info, CollectingSelectInfo):\n\t\t\tselect_infos.append(info)\n\treturn select_infos\n</code></pre>"},{"location":"code_docs/interact/collect/collector/select_collector/#labridge.interact.collect.collector.select_collector.SelectInfoCollector.modify","title":"<code>labridge.interact.collect.collector.select_collector.SelectInfoCollector.modify(user_id)</code>","text":"<p>Modify the collected SelectInfo according to the user's comment.</p> RETURNS DESCRIPTION <code>Tuple[bool, bool]</code> <p>Tuple[str, str]: - doing_modify: Whether the user thinks the collected information need modification. - abort: Whether the user aborts the collection process.</p> Source code in <code>labridge\\interact\\collect\\collector\\select_collector.py</code> <pre><code>def modify(self, user_id: str) -&gt; Tuple[bool, bool]:\n\tr\"\"\"\n\tModify the collected SelectInfo according to the user's comment.\n\n\tReturns:\n\t\tTuple[str, str]:\n\t\t\t- doing_modify: Whether the user thinks the collected information need modification.\n\t\t\t- abort: Whether the user aborts the collection process.\n\t\"\"\"\n\tif len(self._select_infos) &lt; 1:\n\t\treturn False, False\n\n\tdoing_modify = True\n\tabort = False\n\twhile doing_modify and not abort:\n\t\tquery_to_user =self._collect_manager.verify_query(collected_info_dict=self.collected_infos)\n\t\t# TODO: send the message to the user.\n\t\tprint(query_to_user)\n\n\t\t# TODO: receive the message from the user.\n\t\tuser_msg = ChatBuffer.test_get_user_text(user_id=user_id)\n\t\tuser_response = user_msg.user_msg\n\t\tabort = self._collect_manager.analyze_whether_abort(user_response=user_response)\n\t\tif abort:\n\t\t\tbreak\n\t\tdoing_modify = self._collect_manager.analyze_whether_modify(\n\t\t\tuser_response=user_response,\n\t\t\tcollected_info_dict=self.collected_infos\n\t\t)\n\t\tif doing_modify:\n\t\t\tself.single_modify(user_response=user_response)\n\treturn doing_modify, abort\n</code></pre>"},{"location":"code_docs/interact/collect/collector/select_collector/#labridge.interact.collect.collector.select_collector.SelectInfoCollector.modify_single_info","title":"<code>labridge.interact.collect.collector.select_collector.SelectInfoCollector.modify_single_info(user_response, info)</code>","text":"<p>Modify a collected SelectInfo according to the user's comment.</p> PARAMETER DESCRIPTION <code>user_response</code> <p>The user's comment.</p> <p> TYPE: <code>str</code> </p> <code>info</code> <p>The collected SelectInfo.</p> <p> TYPE: <code>CollectingSelectInfo</code> </p> RETURNS DESCRIPTION <p>None</p> Source code in <code>labridge\\interact\\collect\\collector\\select_collector.py</code> <pre><code>def modify_single_info(self, user_response: str,  info: CollectingSelectInfo):\n\tr\"\"\"\n\tModify a collected SelectInfo according to the user's comment.\n\n\tArgs:\n\t\tuser_response (str): The user's comment.\n\t\tinfo (CollectingSelectInfo): The collected SelectInfo.\n\n\tReturns:\n\t\tNone\n\t\"\"\"\n\tpredict_kwargs = {\n\t\t\"prompt\": MODIFY_SELECT_INFO_PROMPT,\n\t\tModifyPromptKeys.user_comment_key: user_response,\n\t}\n\n\tall_choices, all_possibilities = [], []\n\tfor batch_info_dict, batch_candidates in info.modify_info_content():\n\t\tpredict_kwargs.update(batch_info_dict)\n\t\traw_response = self._llm.predict(**predict_kwargs)\n\n\t\traw_choices, possibilities = default_parse_choice_select_answer_fn(raw_response, len(batch_candidates))\n\t\tchoice_idxs = [choice - 1 for choice in raw_choices]\n\t\tbatch_choices = [batch_candidates[ci] for ci in choice_idxs]\n\n\t\tall_choices.extend(batch_choices)\n\t\tall_possibilities.extend(possibilities)\n\n\tzipped_list = list(zip(all_choices, all_possibilities))\n\tsorted_list = sorted(zipped_list, key=lambda x: x[1], reverse=True)\n\tif sorted_list:\n\t\tcollected_info, score = sorted_list[0]\n\t\tif score &gt;= SELECT_MIN_SCORE:\n\t\t\tinfo.update_collected_info(\n\t\t\t\tcollected_info_dict={info.info_name: collected_info}\n\t\t\t)\n</code></pre>"},{"location":"code_docs/interact/collect/collector/select_collector/#labridge.interact.collect.collector.select_collector.SelectInfoCollector.single_modify","title":"<code>labridge.interact.collect.collector.select_collector.SelectInfoCollector.single_modify(user_response)</code>","text":"<p>Modify</p> Source code in <code>labridge\\interact\\collect\\collector\\select_collector.py</code> <pre><code>def single_modify(self, user_response: str):\n\tr\"\"\" Modify \"\"\"\n\tfor info in self._select_infos:\n\t\tself.modify_single_info(user_response=user_response, info=info)\n</code></pre>"},{"location":"code_docs/interact/collect/manager/collect_manager/","title":"Collect manager","text":""},{"location":"code_docs/interact/collect/manager/collect_manager/#labridge.interact.collect.manager.collect_manager","title":"<code>labridge.interact.collect.manager.collect_manager</code>","text":""},{"location":"code_docs/interact/collect/manager/collect_manager/#labridge.interact.collect.manager.collect_manager.CollectManager","title":"<code>labridge.interact.collect.manager.collect_manager.CollectManager</code>","text":"<p>This manager judges whether to abort the collecting process according to the user's response, and whether the collected information need modification.</p> PARAMETER DESCRIPTION <code>llm</code> <p>The used LLM.</p> <p> TYPE: <code>LLM</code> </p> Source code in <code>labridge\\interact\\collect\\manager\\collect_manager.py</code> <pre><code>class CollectManager:\n\tr\"\"\"\n\tThis manager judges whether to abort the collecting process according to the user's response,\n\tand whether the collected information need modification.\n\n\tArgs:\n\t\tllm (LLM): The used LLM.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tllm: LLM,\n\t):\n\t\tself._llm = llm\n\n\tdef analyze_whether_abort(self, user_response: str) -&gt; bool:\n\t\tr\"\"\"\n\t\tWhether the user tends to abort.\n\n\t\tArgs:\n\t\t\tuser_response (str): The user's response.\n\n\t\tReturns:\n\t\t\tbool: Whether to abort or not.\n\t\t\"\"\"\n\t\tabort = condition_analyze(\n\t\t\tllm=self._llm,\n\t\t\tprompt=COLLECT_ABORT_PROMPT,\n\t\t\tcondition_true_word=COLLECT_ABORT_WORD,\n\t\t\tabort_word=COLLECT_ABORT_WORD,\n\t\t\tcontinue_word=COLLECT_CONTINUE_WORD,\n\t\t\tuser_response=user_response,\n\t\t)\n\t\treturn abort\n\n\tasync def async_analyze_whether_abort(self, user_response: str) -&gt; bool:\n\t\tr\"\"\"\n\t\tAsync version.\n\t\tWhether the user tends to abort.\n\n\t\tArgs:\n\t\t\tuser_response (str): The user's response.\n\n\t\tReturns:\n\t\t\tbool: Whether to abort or not.\n\t\t\"\"\"\n\t\tabort = await acondition_analyze(\n\t\t\tllm=self._llm,\n\t\t\tprompt=COLLECT_ABORT_PROMPT,\n\t\t\tcondition_true_word=COLLECT_ABORT_WORD,\n\t\t\tabort_word=COLLECT_ABORT_WORD,\n\t\t\tcontinue_word=COLLECT_CONTINUE_WORD,\n\t\t\tuser_response=user_response,\n\t\t)\n\t\treturn abort\n\n\tasync def async_analyze_whether_modify(\n\t\tself,\n\t\tuser_response: str,\n\t\tcollected_info_dict: Dict[str, str],\n\t) -&gt; bool:\n\t\tr\"\"\"\n\t\tAsync version.\n\t\tWhether the user thinks the collected information need modification.\n\n\t\tArgs:\n\t\t\tuser_response (str): The user's response.\n\n\t\tReturns:\n\t\t\tbool: Whether to modify or not.\n\t\t\"\"\"\n\t\tdo_modify = await acondition_analyze(\n\t\t\tllm=self._llm,\n\t\t\tprompt=WHETHER_MODIFY_INFO_PROMPT,\n\t\t\tcondition_true_word=DO_MODIFY_WORD,\n\t\t\tdo_modify_word=DO_MODIFY_WORD,\n\t\t\tnot_modify_word=NOT_MODIFY_WORD,\n\t\t\tcollected_infos_str=json.dumps(collected_info_dict),\n\t\t\tuser_comment_str=user_response,\n\t\t)\n\t\treturn do_modify\n\n\tdef analyze_whether_modify(\n\t\tself,\n\t\tuser_response: str,\n\t\tcollected_info_dict: Dict[str, str],\n\t) -&gt; bool:\n\t\tr\"\"\"\n\t\tWhether the user thinks the collected information need modification.\n\n\t\tArgs:\n\t\t\tuser_response (str): The user's response.\n\n\t\tReturns:\n\t\t\tbool: Whether to modify or not.\n\t\t\"\"\"\n\t\tdo_modify = condition_analyze(\n\t\t\tllm=self._llm,\n\t\t\tprompt=WHETHER_MODIFY_INFO_PROMPT,\n\t\t\tcondition_true_word=DO_MODIFY_WORD,\n\t\t\tdo_modify_word=DO_MODIFY_WORD,\n\t\t\tnot_modify_word=NOT_MODIFY_WORD,\n\t\t\tcollected_infos_str=json.dumps(collected_info_dict),\n\t\t\tuser_comment_str=user_response,\n\t\t)\n\t\treturn do_modify\n\n\tdef verify_query(self, collected_info_dict: Dict[str, str]) -&gt; str:\n\t\tr\"\"\" This query will be sent to the user to verify the correctness of the collected information. \"\"\"\n\t\tverify_str = f\"{VERIFY_COLLECTED_INFO_QUERY}\\n\"\n\t\tfor key in collected_info_dict.keys():\n\t\t\tverify_str += f\"{key}:\\n\\t{collected_info_dict[key]}\\n\"\n\t\treturn verify_str\n</code></pre>"},{"location":"code_docs/interact/collect/manager/collect_manager/#labridge.interact.collect.manager.collect_manager.CollectManager.analyze_whether_abort","title":"<code>labridge.interact.collect.manager.collect_manager.CollectManager.analyze_whether_abort(user_response)</code>","text":"<p>Whether the user tends to abort.</p> PARAMETER DESCRIPTION <code>user_response</code> <p>The user's response.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>Whether to abort or not.</p> <p> TYPE: <code>bool</code> </p> Source code in <code>labridge\\interact\\collect\\manager\\collect_manager.py</code> <pre><code>def analyze_whether_abort(self, user_response: str) -&gt; bool:\n\tr\"\"\"\n\tWhether the user tends to abort.\n\n\tArgs:\n\t\tuser_response (str): The user's response.\n\n\tReturns:\n\t\tbool: Whether to abort or not.\n\t\"\"\"\n\tabort = condition_analyze(\n\t\tllm=self._llm,\n\t\tprompt=COLLECT_ABORT_PROMPT,\n\t\tcondition_true_word=COLLECT_ABORT_WORD,\n\t\tabort_word=COLLECT_ABORT_WORD,\n\t\tcontinue_word=COLLECT_CONTINUE_WORD,\n\t\tuser_response=user_response,\n\t)\n\treturn abort\n</code></pre>"},{"location":"code_docs/interact/collect/manager/collect_manager/#labridge.interact.collect.manager.collect_manager.CollectManager.analyze_whether_modify","title":"<code>labridge.interact.collect.manager.collect_manager.CollectManager.analyze_whether_modify(user_response, collected_info_dict)</code>","text":"<p>Whether the user thinks the collected information need modification.</p> PARAMETER DESCRIPTION <code>user_response</code> <p>The user's response.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>Whether to modify or not.</p> <p> TYPE: <code>bool</code> </p> Source code in <code>labridge\\interact\\collect\\manager\\collect_manager.py</code> <pre><code>def analyze_whether_modify(\n\tself,\n\tuser_response: str,\n\tcollected_info_dict: Dict[str, str],\n) -&gt; bool:\n\tr\"\"\"\n\tWhether the user thinks the collected information need modification.\n\n\tArgs:\n\t\tuser_response (str): The user's response.\n\n\tReturns:\n\t\tbool: Whether to modify or not.\n\t\"\"\"\n\tdo_modify = condition_analyze(\n\t\tllm=self._llm,\n\t\tprompt=WHETHER_MODIFY_INFO_PROMPT,\n\t\tcondition_true_word=DO_MODIFY_WORD,\n\t\tdo_modify_word=DO_MODIFY_WORD,\n\t\tnot_modify_word=NOT_MODIFY_WORD,\n\t\tcollected_infos_str=json.dumps(collected_info_dict),\n\t\tuser_comment_str=user_response,\n\t)\n\treturn do_modify\n</code></pre>"},{"location":"code_docs/interact/collect/manager/collect_manager/#labridge.interact.collect.manager.collect_manager.CollectManager.async_analyze_whether_abort","title":"<code>labridge.interact.collect.manager.collect_manager.CollectManager.async_analyze_whether_abort(user_response)</code>  <code>async</code>","text":"<p>Async version. Whether the user tends to abort.</p> PARAMETER DESCRIPTION <code>user_response</code> <p>The user's response.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>Whether to abort or not.</p> <p> TYPE: <code>bool</code> </p> Source code in <code>labridge\\interact\\collect\\manager\\collect_manager.py</code> <pre><code>async def async_analyze_whether_abort(self, user_response: str) -&gt; bool:\n\tr\"\"\"\n\tAsync version.\n\tWhether the user tends to abort.\n\n\tArgs:\n\t\tuser_response (str): The user's response.\n\n\tReturns:\n\t\tbool: Whether to abort or not.\n\t\"\"\"\n\tabort = await acondition_analyze(\n\t\tllm=self._llm,\n\t\tprompt=COLLECT_ABORT_PROMPT,\n\t\tcondition_true_word=COLLECT_ABORT_WORD,\n\t\tabort_word=COLLECT_ABORT_WORD,\n\t\tcontinue_word=COLLECT_CONTINUE_WORD,\n\t\tuser_response=user_response,\n\t)\n\treturn abort\n</code></pre>"},{"location":"code_docs/interact/collect/manager/collect_manager/#labridge.interact.collect.manager.collect_manager.CollectManager.async_analyze_whether_modify","title":"<code>labridge.interact.collect.manager.collect_manager.CollectManager.async_analyze_whether_modify(user_response, collected_info_dict)</code>  <code>async</code>","text":"<p>Async version. Whether the user thinks the collected information need modification.</p> PARAMETER DESCRIPTION <code>user_response</code> <p>The user's response.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>Whether to modify or not.</p> <p> TYPE: <code>bool</code> </p> Source code in <code>labridge\\interact\\collect\\manager\\collect_manager.py</code> <pre><code>async def async_analyze_whether_modify(\n\tself,\n\tuser_response: str,\n\tcollected_info_dict: Dict[str, str],\n) -&gt; bool:\n\tr\"\"\"\n\tAsync version.\n\tWhether the user thinks the collected information need modification.\n\n\tArgs:\n\t\tuser_response (str): The user's response.\n\n\tReturns:\n\t\tbool: Whether to modify or not.\n\t\"\"\"\n\tdo_modify = await acondition_analyze(\n\t\tllm=self._llm,\n\t\tprompt=WHETHER_MODIFY_INFO_PROMPT,\n\t\tcondition_true_word=DO_MODIFY_WORD,\n\t\tdo_modify_word=DO_MODIFY_WORD,\n\t\tnot_modify_word=NOT_MODIFY_WORD,\n\t\tcollected_infos_str=json.dumps(collected_info_dict),\n\t\tuser_comment_str=user_response,\n\t)\n\treturn do_modify\n</code></pre>"},{"location":"code_docs/interact/collect/manager/collect_manager/#labridge.interact.collect.manager.collect_manager.CollectManager.verify_query","title":"<code>labridge.interact.collect.manager.collect_manager.CollectManager.verify_query(collected_info_dict)</code>","text":"<p>This query will be sent to the user to verify the correctness of the collected information.</p> Source code in <code>labridge\\interact\\collect\\manager\\collect_manager.py</code> <pre><code>def verify_query(self, collected_info_dict: Dict[str, str]) -&gt; str:\n\tr\"\"\" This query will be sent to the user to verify the correctness of the collected information. \"\"\"\n\tverify_str = f\"{VERIFY_COLLECTED_INFO_QUERY}\\n\"\n\tfor key in collected_info_dict.keys():\n\t\tverify_str += f\"{key}:\\n\\t{collected_info_dict[key]}\\n\"\n\treturn verify_str\n</code></pre>"},{"location":"code_docs/interact/collect/types/common_info/","title":"Common info","text":""},{"location":"code_docs/interact/collect/types/common_info/#labridge.interact.collect.types.common_info","title":"<code>labridge.interact.collect.types.common_info</code>","text":""},{"location":"code_docs/interact/collect/types/common_info/#labridge.interact.collect.types.common_info.CollectingCommonInfo","title":"<code>labridge.interact.collect.types.common_info.CollectingCommonInfo</code>","text":"<p>               Bases: <code>CollectingBatchInfoBase</code></p> <p>This class defines the common information to be collected from the user. The common information can be collected in batch mode.</p> PARAMETER DESCRIPTION <code>info_name</code> <p>The name of the information to be collected.</p> <p> TYPE: <code>str</code> </p> <code>info_description</code> <p>The description of the information to be collected.</p> <p> TYPE: <code>str</code> </p> Source code in <code>labridge\\interact\\collect\\types\\common_info.py</code> <pre><code>class CollectingCommonInfo(CollectingBatchInfoBase):\n\tr\"\"\"\n\tThis class defines the common information to be collected from the user.\n\tThe common information can be collected in batch mode.\n\n\tArgs:\n\t\tinfo_name (str): The name of the information to be collected.\n\t\tinfo_description (str): The description of the information to be collected.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tinfo_name: str,\n\t\tinfo_description: str,\n\t):\n\t\tself.info_dict = {\n\t\t\tCollectPromptKeys.required_infos_key: {info_name: info_description}\n\t\t}\n\t\tsuper().__init__(\n\t\t\tinfo_name=info_name,\n\t\t\tinfo_description=info_description,\n\t\t\tinfo_type=CollectingInfoType.COMMON,\n\t\t)\n\n\tdef insert_info(self, info: CollectingInfoBase):\n\t\tr\"\"\"\n\t\tInsert a new CommonInfo to current one.\n\n\t\tArgs:\n\t\t\tinfo (CollectingInfoBase): The new CollectingCommonInfo.\n\n\t\tReturns:\n\t\t\tNone.\n\t\t\"\"\"\n\t\tself.info_dict[CollectPromptKeys.required_infos_key].update(\n\t\t\t{info.info_name: info.info_description}\n\t\t)\n\n\tdef _collected(self) -&gt; bool:\n\t\tr\"\"\" Whether all information is collected. \"\"\"\n\t\treturn len(self.collecting_keys) == 0\n\n\tdef _required_infos(self) -&gt; Dict[str, str]:\n\t\tr\"\"\" Return the required information names and descriptions. \"\"\"\n\t\treturn self.info_dict[CollectPromptKeys.required_infos_key]\n\n\tdef update_collected_info(self, collected_info_dict: Dict[str, str]):\n\t\tr\"\"\" Update the collected information. \"\"\"\n\t\tfor key in collected_info_dict.keys():\n\t\t\tif key in self.required_infos:\n\t\t\t\tself._collected_infos[key] = collected_info_dict[key]\n\n\tdef _collecting_keys(self) -&gt; List[str]:\n\t\tr\"\"\" Return the information names to be collected currently. \"\"\"\n\t\tcollecting_keys = set(self.required_infos.keys()) - set(self._collected_infos.keys())\n\t\treturn list(collecting_keys)\n\n\tdef info_content(self) -&gt; Iterator[Dict[str, str]]:\n\t\tr\"\"\" Yield a batch of information names and descriptions to the LLM for extraction \"\"\"\n\t\tinfo_keys = self.collecting_keys\n\t\tinfo_num = len(info_keys)\n\t\tstart = 0\n\t\twhile start &lt; info_num:\n\t\t\tbatch_keys = info_keys[start: start + COMMON_COLLECT_BATCH_SIZE]\n\t\t\tstart += COMMON_COLLECT_BATCH_SIZE\n\t\t\tbatch_info = {key: self.required_infos[key] for key in batch_keys}\n\t\t\tyield {\n\t\t\t\tCollectPromptKeys.required_infos_key: json.dumps(batch_info),\n\t\t\t\tCollectPromptKeys.extra_info_key: DEFAULT_EXTRA_INFO,\n\t\t\t}\n\n\tdef modify_info_content(self) -&gt; Iterator[Dict[str, str]]:\n\t\tr\"\"\" Yield a batch of information names, descriptions and collected content to the LLM for modification. \"\"\"\n\t\tinfo_keys = list(self.collected_infos.keys())\n\t\tinfo_num = len(info_keys)\n\t\tstart = 0\n\t\twhile start &lt; info_num:\n\t\t\tbatch_keys = info_keys[start: start + COMMON_COLLECT_BATCH_SIZE]\n\t\t\tstart += COMMON_COLLECT_BATCH_SIZE\n\t\t\tbatch_info = {key: self.required_infos[key] for key in batch_keys}\n\t\t\tbatch_collected_info = {key: self.collected_infos[key] for key in batch_keys}\n\t\t\tyield {\n\t\t\t\tModifyPromptKeys.required_infos_key: json.dumps(batch_info),\n\t\t\t\tModifyPromptKeys.collected_infos_key: json.dumps(batch_collected_info),\n\t\t\t\tModifyPromptKeys.extra_info_key: DEFAULT_EXTRA_INFO,\n\t\t\t}\n</code></pre>"},{"location":"code_docs/interact/collect/types/common_info/#labridge.interact.collect.types.common_info.CollectingCommonInfo.info_content","title":"<code>labridge.interact.collect.types.common_info.CollectingCommonInfo.info_content()</code>","text":"<p>Yield a batch of information names and descriptions to the LLM for extraction</p> Source code in <code>labridge\\interact\\collect\\types\\common_info.py</code> <pre><code>def info_content(self) -&gt; Iterator[Dict[str, str]]:\n\tr\"\"\" Yield a batch of information names and descriptions to the LLM for extraction \"\"\"\n\tinfo_keys = self.collecting_keys\n\tinfo_num = len(info_keys)\n\tstart = 0\n\twhile start &lt; info_num:\n\t\tbatch_keys = info_keys[start: start + COMMON_COLLECT_BATCH_SIZE]\n\t\tstart += COMMON_COLLECT_BATCH_SIZE\n\t\tbatch_info = {key: self.required_infos[key] for key in batch_keys}\n\t\tyield {\n\t\t\tCollectPromptKeys.required_infos_key: json.dumps(batch_info),\n\t\t\tCollectPromptKeys.extra_info_key: DEFAULT_EXTRA_INFO,\n\t\t}\n</code></pre>"},{"location":"code_docs/interact/collect/types/common_info/#labridge.interact.collect.types.common_info.CollectingCommonInfo.insert_info","title":"<code>labridge.interact.collect.types.common_info.CollectingCommonInfo.insert_info(info)</code>","text":"<p>Insert a new CommonInfo to current one.</p> PARAMETER DESCRIPTION <code>info</code> <p>The new CollectingCommonInfo.</p> <p> TYPE: <code>CollectingInfoBase</code> </p> RETURNS DESCRIPTION <p>None.</p> Source code in <code>labridge\\interact\\collect\\types\\common_info.py</code> <pre><code>def insert_info(self, info: CollectingInfoBase):\n\tr\"\"\"\n\tInsert a new CommonInfo to current one.\n\n\tArgs:\n\t\tinfo (CollectingInfoBase): The new CollectingCommonInfo.\n\n\tReturns:\n\t\tNone.\n\t\"\"\"\n\tself.info_dict[CollectPromptKeys.required_infos_key].update(\n\t\t{info.info_name: info.info_description}\n\t)\n</code></pre>"},{"location":"code_docs/interact/collect/types/common_info/#labridge.interact.collect.types.common_info.CollectingCommonInfo.modify_info_content","title":"<code>labridge.interact.collect.types.common_info.CollectingCommonInfo.modify_info_content()</code>","text":"<p>Yield a batch of information names, descriptions and collected content to the LLM for modification.</p> Source code in <code>labridge\\interact\\collect\\types\\common_info.py</code> <pre><code>def modify_info_content(self) -&gt; Iterator[Dict[str, str]]:\n\tr\"\"\" Yield a batch of information names, descriptions and collected content to the LLM for modification. \"\"\"\n\tinfo_keys = list(self.collected_infos.keys())\n\tinfo_num = len(info_keys)\n\tstart = 0\n\twhile start &lt; info_num:\n\t\tbatch_keys = info_keys[start: start + COMMON_COLLECT_BATCH_SIZE]\n\t\tstart += COMMON_COLLECT_BATCH_SIZE\n\t\tbatch_info = {key: self.required_infos[key] for key in batch_keys}\n\t\tbatch_collected_info = {key: self.collected_infos[key] for key in batch_keys}\n\t\tyield {\n\t\t\tModifyPromptKeys.required_infos_key: json.dumps(batch_info),\n\t\t\tModifyPromptKeys.collected_infos_key: json.dumps(batch_collected_info),\n\t\t\tModifyPromptKeys.extra_info_key: DEFAULT_EXTRA_INFO,\n\t\t}\n</code></pre>"},{"location":"code_docs/interact/collect/types/common_info/#labridge.interact.collect.types.common_info.CollectingCommonInfo.update_collected_info","title":"<code>labridge.interact.collect.types.common_info.CollectingCommonInfo.update_collected_info(collected_info_dict)</code>","text":"<p>Update the collected information.</p> Source code in <code>labridge\\interact\\collect\\types\\common_info.py</code> <pre><code>def update_collected_info(self, collected_info_dict: Dict[str, str]):\n\tr\"\"\" Update the collected information. \"\"\"\n\tfor key in collected_info_dict.keys():\n\t\tif key in self.required_infos:\n\t\t\tself._collected_infos[key] = collected_info_dict[key]\n</code></pre>"},{"location":"code_docs/interact/collect/types/info_base/","title":"Info base","text":""},{"location":"code_docs/interact/collect/types/info_base/#labridge.interact.collect.types.info_base","title":"<code>labridge.interact.collect.types.info_base</code>","text":""},{"location":"code_docs/interact/collect/types/info_base/#labridge.interact.collect.types.info_base.CollectingBatchInfoBase","title":"<code>labridge.interact.collect.types.info_base.CollectingBatchInfoBase</code>","text":"<p>               Bases: <code>CollectingInfoBase</code></p> <p>The CollectingInfo which can be collected in a batch mode.</p> Source code in <code>labridge\\interact\\collect\\types\\info_base.py</code> <pre><code>class CollectingBatchInfoBase(CollectingInfoBase):\n\tr\"\"\"\n\tThe CollectingInfo which can be collected in a batch mode.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tinfo_name: str,\n\t\tinfo_description: str,\n\t\tinfo_type: CollectingInfoType,\n\t):\n\t\tsuper().__init__(\n\t\t\tinfo_name=info_name,\n\t\t\tinfo_description=info_description,\n\t\t\tinfo_type=info_type,\n\t\t\tbatch_mode=True,\n\t\t)\n\n\t@abstractmethod\n\tdef insert_info(self, **kwargs):\n\t\tr\"\"\" insert info \"\"\"\n</code></pre>"},{"location":"code_docs/interact/collect/types/info_base/#labridge.interact.collect.types.info_base.CollectingBatchInfoBase.insert_info","title":"<code>labridge.interact.collect.types.info_base.CollectingBatchInfoBase.insert_info(**kwargs)</code>  <code>abstractmethod</code>","text":"<p>insert info</p> Source code in <code>labridge\\interact\\collect\\types\\info_base.py</code> <pre><code>@abstractmethod\ndef insert_info(self, **kwargs):\n\tr\"\"\" insert info \"\"\"\n</code></pre>"},{"location":"code_docs/interact/collect/types/info_base/#labridge.interact.collect.types.info_base.CollectingInfoBase","title":"<code>labridge.interact.collect.types.info_base.CollectingInfoBase</code>","text":"<p>This is the base class for the CollectingInfo.</p> PARAMETER DESCRIPTION <code>info_name</code> <p>The information name.</p> <p> TYPE: <code>str</code> </p> <code>info_description</code> <p>The information description.</p> <p> TYPE: <code>str</code> </p> <code>info_type</code> <p>The information type.</p> <p> TYPE: <code>CollectingInfoType</code> </p> <code>batch_mode</code> <p>Whether the information can be collected in a batch mode.</p> <p> TYPE: <code>bool</code> </p> Source code in <code>labridge\\interact\\collect\\types\\info_base.py</code> <pre><code>class CollectingInfoBase:\n\tr\"\"\"\n\tThis is the base class for the CollectingInfo.\n\n\tArgs:\n\t\tinfo_name (str): The information name.\n\t\tinfo_description (str): The information description.\n\t\tinfo_type (CollectingInfoType): The information type.\n\t\tbatch_mode (bool): Whether the information can be collected in a batch mode.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tinfo_name: str,\n\t\tinfo_description: str,\n\t\tinfo_type: CollectingInfoType,\n\t\tbatch_mode: bool,\n\t):\n\t\tself.info_name = info_name\n\t\tself.info_description = info_description\n\t\tself.info_type = info_type\n\t\tself._batch_mode = batch_mode\n\t\tself._collect_finish = False\n\t\tself._collected_infos = {}\n\n\t@abstractmethod\n\tdef info_content(self) -&gt; Dict[str, str]:\n\t\tr\"\"\" Yield the information to the LLM for extraction. \"\"\"\n\n\t@abstractmethod\n\tdef _required_infos(self) -&gt; Dict[str, str]:\n\t\tr\"\"\" Required infos \"\"\"\n\n\t@abstractmethod\n\tdef update_collected_info(self, collected_info):\n\t\tr\"\"\" Update self._collected_infos \"\"\"\n\n\t@property\n\tdef required_infos(self) -&gt; Dict[str, str]:\n\t\tr\"\"\" Required infos \"\"\"\n\t\treturn self._required_infos()\n\n\t@property\n\tdef batch_mode(self) -&gt; bool:\n\t\treturn self._batch_mode\n\n\t@abstractmethod\n\tdef _collected(self) -&gt; bool:\n\t\tr\"\"\" Whether the collecting process ends. \"\"\"\n\n\t@property\n\tdef collected(self) -&gt; bool:\n\t\tr\"\"\" Whether all required infos are collected. \"\"\"\n\t\treturn self._collected()\n\n\t@property\n\tdef collected_infos(self) -&gt; dict:\n\t\tr\"\"\" Return the collected info . \"\"\"\n\t\treturn self._collected_infos\n\n\t@abstractmethod\n\tdef _collecting_keys(self) -&gt; List[str]:\n\t\tr\"\"\" The keys in collecting. \"\"\"\n\n\t@property\n\tdef collecting_keys(self) -&gt; List[str]:\n\t\tr\"\"\" The collecting information names. \"\"\"\n\t\treturn self._collecting_keys()\n</code></pre>"},{"location":"code_docs/interact/collect/types/info_base/#labridge.interact.collect.types.info_base.CollectingInfoBase.collected","title":"<code>labridge.interact.collect.types.info_base.CollectingInfoBase.collected: bool</code>  <code>property</code>","text":"<p>Whether all required infos are collected.</p>"},{"location":"code_docs/interact/collect/types/info_base/#labridge.interact.collect.types.info_base.CollectingInfoBase.collected_infos","title":"<code>labridge.interact.collect.types.info_base.CollectingInfoBase.collected_infos: dict</code>  <code>property</code>","text":"<p>Return the collected info .</p>"},{"location":"code_docs/interact/collect/types/info_base/#labridge.interact.collect.types.info_base.CollectingInfoBase.collecting_keys","title":"<code>labridge.interact.collect.types.info_base.CollectingInfoBase.collecting_keys: List[str]</code>  <code>property</code>","text":"<p>The collecting information names.</p>"},{"location":"code_docs/interact/collect/types/info_base/#labridge.interact.collect.types.info_base.CollectingInfoBase.required_infos","title":"<code>labridge.interact.collect.types.info_base.CollectingInfoBase.required_infos: Dict[str, str]</code>  <code>property</code>","text":"<p>Required infos</p>"},{"location":"code_docs/interact/collect/types/info_base/#labridge.interact.collect.types.info_base.CollectingInfoBase.info_content","title":"<code>labridge.interact.collect.types.info_base.CollectingInfoBase.info_content()</code>  <code>abstractmethod</code>","text":"<p>Yield the information to the LLM for extraction.</p> Source code in <code>labridge\\interact\\collect\\types\\info_base.py</code> <pre><code>@abstractmethod\ndef info_content(self) -&gt; Dict[str, str]:\n\tr\"\"\" Yield the information to the LLM for extraction. \"\"\"\n</code></pre>"},{"location":"code_docs/interact/collect/types/info_base/#labridge.interact.collect.types.info_base.CollectingInfoBase.update_collected_info","title":"<code>labridge.interact.collect.types.info_base.CollectingInfoBase.update_collected_info(collected_info)</code>  <code>abstractmethod</code>","text":"<p>Update self._collected_infos</p> Source code in <code>labridge\\interact\\collect\\types\\info_base.py</code> <pre><code>@abstractmethod\ndef update_collected_info(self, collected_info):\n\tr\"\"\" Update self._collected_infos \"\"\"\n</code></pre>"},{"location":"code_docs/interact/collect/types/select_info/","title":"Select info","text":""},{"location":"code_docs/interact/collect/types/select_info/#labridge.interact.collect.types.select_info","title":"<code>labridge.interact.collect.types.select_info</code>","text":""},{"location":"code_docs/interact/collect/types/select_info/#labridge.interact.collect.types.select_info.CollectingSelectInfo","title":"<code>labridge.interact.collect.types.select_info.CollectingSelectInfo</code>","text":"<p>               Bases: <code>CollectingInfoBase</code></p> <p>This class defines the select information to be collected from the user. The select information should be selected between several given choices.</p> PARAMETER DESCRIPTION <code>info_name</code> <p>The name of the information to be collected.</p> <p> TYPE: <code>str</code> </p> <code>info_description</code> <p>The description of the information to be collected.</p> <p> TYPE: <code>str</code> </p> <code>choices</code> <p>The given choices.</p> <ul> <li>key (str): The choice.</li> <li>value (str): The description of the choice.</li> </ul> <p> TYPE: <code>Dict[str, str]</code> </p> Source code in <code>labridge\\interact\\collect\\types\\select_info.py</code> <pre><code>class CollectingSelectInfo(CollectingInfoBase):\n\tr\"\"\"\n\tThis class defines the select information to be collected from the user.\n\tThe select information should be selected between several given choices.\n\n\tArgs:\n\t\tinfo_name (str): The name of the information to be collected.\n\t\tinfo_description (str): The description of the information to be collected.\n\t\tchoices (Dict[str, str]):\n\t\t\tThe given choices.\n\n\t\t\t- key (str): The choice.\n\t\t\t- value (str): The description of the choice.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tinfo_name: str,\n\t\tinfo_description: str,\n\t\tchoices: Dict[str, str],\n\t):\n\t\tself._choices = choices\n\t\tsuper().__init__(\n\t\t\tinfo_name=info_name,\n\t\t\tinfo_description=info_description,\n\t\t\tinfo_type=CollectingInfoType.SELECT,\n\t\t\tbatch_mode=False,\n\t\t)\n\n\tdef _collected(self) -&gt; bool:\n\t\tr\"\"\" Whether all information is collected. \"\"\"\n\t\treturn self.info_name in self._collected_infos.keys()\n\n\tdef update_collected_info(self, collected_info_dict: Dict[str, str]):\n\t\tr\"\"\" Update the collected information. \"\"\"\n\t\tif self.info_name in collected_info_dict:\n\t\t\tself._collected_infos[self.info_name] = collected_info_dict[self.info_name]\n\n\tdef _required_infos(self) -&gt; Dict[str, str]:\n\t\tr\"\"\" Return the required information names and descriptions. \"\"\"\n\t\treturn {self.info_name: self.info_description}\n\n\tdef _collecting_keys(self) -&gt; List[str]:\n\t\tr\"\"\" Return the information names to be collected currently. \"\"\"\n\t\tif self.collected:\n\t\t\treturn []\n\t\treturn [self.info_name]\n\n\t@property\n\tdef candidates(self) -&gt; List[str]:\n\t\tr\"\"\" Get the candidates \"\"\"\n\t\treturn list(self._choices.keys())\n\n\tdef _extra_info_format(self, choice_keys: List[str]) -&gt; str:\n\t\tr\"\"\" The prompt format for selecting. \"\"\"\n\t\tcontents = []\n\t\tfor idx, key in enumerate(choice_keys):\n\t\t\tcontent = f\"Paragraph {idx + 1}\\n\"\n\t\t\tcontent += f\"Name: {key}\\nDescription: {self._choices[key]}\".strip()\n\t\t\tcontents.append(content)\n\t\tchoices_str = \"\\n\\n\".join(contents)\n\t\treturn choices_str\n\n\tdef info_content(self) -&gt; Iterator[Tuple[Dict[str, str], List[str]]]:\n\t\tr\"\"\" Yield the information name, description and corresponding choices to the LLM for selection. \"\"\"\n\t\trequired_infos_str = json.dumps({self.info_name: self.info_description})\n\t\tcandidates = self.candidates\n\t\tif not self.collected:\n\t\t\tfor idx in range(0, len(candidates), SELECT_CHOICE_BATCH_SIZE):\n\t\t\t\textra_info = self._extra_info_format(choice_keys=candidates[idx: idx + SELECT_CHOICE_BATCH_SIZE])\n\t\t\t\tyield {\n\t\t\t\t\tCollectPromptKeys.required_infos_key: required_infos_str,\n\t\t\t\t\tCollectPromptKeys.extra_info_key: extra_info,\n\t\t\t\t}, candidates[idx: idx + SELECT_CHOICE_BATCH_SIZE]\n\n\tdef modify_info_content(self) -&gt; Iterator[Tuple[Dict[str, str], List[str]]]:\n\t\tr\"\"\" Yield the information name, description, collected content and corresponding choices to the LLM for modification. \"\"\"\n\t\trequired_infos_str = json.dumps({self.info_name: self.info_description})\n\t\tcandidates = self.candidates\n\t\tfor idx in range(0, len(candidates), SELECT_CHOICE_BATCH_SIZE):\n\t\t\textra_info = self._extra_info_format(choice_keys=candidates[idx: idx + SELECT_CHOICE_BATCH_SIZE])\n\t\t\tyield {\n\t\t\t\tCollectPromptKeys.required_infos_key: required_infos_str,\n\t\t\t\tModifyPromptKeys.collected_infos_key: json.dumps(self.collected_infos),\n\t\t\t\tCollectPromptKeys.extra_info_key: extra_info,\n\t\t\t}, candidates[idx: idx + SELECT_CHOICE_BATCH_SIZE]\n</code></pre>"},{"location":"code_docs/interact/collect/types/select_info/#labridge.interact.collect.types.select_info.CollectingSelectInfo.candidates","title":"<code>labridge.interact.collect.types.select_info.CollectingSelectInfo.candidates: List[str]</code>  <code>property</code>","text":"<p>Get the candidates</p>"},{"location":"code_docs/interact/collect/types/select_info/#labridge.interact.collect.types.select_info.CollectingSelectInfo.info_content","title":"<code>labridge.interact.collect.types.select_info.CollectingSelectInfo.info_content()</code>","text":"<p>Yield the information name, description and corresponding choices to the LLM for selection.</p> Source code in <code>labridge\\interact\\collect\\types\\select_info.py</code> <pre><code>def info_content(self) -&gt; Iterator[Tuple[Dict[str, str], List[str]]]:\n\tr\"\"\" Yield the information name, description and corresponding choices to the LLM for selection. \"\"\"\n\trequired_infos_str = json.dumps({self.info_name: self.info_description})\n\tcandidates = self.candidates\n\tif not self.collected:\n\t\tfor idx in range(0, len(candidates), SELECT_CHOICE_BATCH_SIZE):\n\t\t\textra_info = self._extra_info_format(choice_keys=candidates[idx: idx + SELECT_CHOICE_BATCH_SIZE])\n\t\t\tyield {\n\t\t\t\tCollectPromptKeys.required_infos_key: required_infos_str,\n\t\t\t\tCollectPromptKeys.extra_info_key: extra_info,\n\t\t\t}, candidates[idx: idx + SELECT_CHOICE_BATCH_SIZE]\n</code></pre>"},{"location":"code_docs/interact/collect/types/select_info/#labridge.interact.collect.types.select_info.CollectingSelectInfo.modify_info_content","title":"<code>labridge.interact.collect.types.select_info.CollectingSelectInfo.modify_info_content()</code>","text":"<p>Yield the information name, description, collected content and corresponding choices to the LLM for modification.</p> Source code in <code>labridge\\interact\\collect\\types\\select_info.py</code> <pre><code>def modify_info_content(self) -&gt; Iterator[Tuple[Dict[str, str], List[str]]]:\n\tr\"\"\" Yield the information name, description, collected content and corresponding choices to the LLM for modification. \"\"\"\n\trequired_infos_str = json.dumps({self.info_name: self.info_description})\n\tcandidates = self.candidates\n\tfor idx in range(0, len(candidates), SELECT_CHOICE_BATCH_SIZE):\n\t\textra_info = self._extra_info_format(choice_keys=candidates[idx: idx + SELECT_CHOICE_BATCH_SIZE])\n\t\tyield {\n\t\t\tCollectPromptKeys.required_infos_key: required_infos_str,\n\t\t\tModifyPromptKeys.collected_infos_key: json.dumps(self.collected_infos),\n\t\t\tCollectPromptKeys.extra_info_key: extra_info,\n\t\t}, candidates[idx: idx + SELECT_CHOICE_BATCH_SIZE]\n</code></pre>"},{"location":"code_docs/interact/collect/types/select_info/#labridge.interact.collect.types.select_info.CollectingSelectInfo.update_collected_info","title":"<code>labridge.interact.collect.types.select_info.CollectingSelectInfo.update_collected_info(collected_info_dict)</code>","text":"<p>Update the collected information.</p> Source code in <code>labridge\\interact\\collect\\types\\select_info.py</code> <pre><code>def update_collected_info(self, collected_info_dict: Dict[str, str]):\n\tr\"\"\" Update the collected information. \"\"\"\n\tif self.info_name in collected_info_dict:\n\t\tself._collected_infos[self.info_name] = collected_info_dict[self.info_name]\n</code></pre>"},{"location":"code_docs/interact/prompt/authorize/analyze_agree/","title":"Analyze agree","text":""},{"location":"code_docs/interact/prompt/authorize/analyze_agree/#labridge.interact.prompt.authorize.analyze_agree","title":"<code>labridge.interact.prompt.authorize.analyze_agree</code>","text":""},{"location":"code_docs/interact/prompt/collect/collect_info/common_info/","title":"Common info","text":""},{"location":"code_docs/interact/prompt/collect/collect_info/common_info/#labridge.interact.prompt.collect.collect_info.common_info","title":"<code>labridge.interact.prompt.collect.collect_info.common_info</code>","text":""},{"location":"code_docs/interact/prompt/collect/collect_info/prompt_keys/","title":"Prompt keys","text":""},{"location":"code_docs/interact/prompt/collect/collect_info/prompt_keys/#labridge.interact.prompt.collect.collect_info.prompt_keys","title":"<code>labridge.interact.prompt.collect.collect_info.prompt_keys</code>","text":""},{"location":"code_docs/interact/prompt/collect/collect_info/select_info/","title":"Select info","text":""},{"location":"code_docs/interact/prompt/collect/collect_info/select_info/#labridge.interact.prompt.collect.collect_info.select_info","title":"<code>labridge.interact.prompt.collect.collect_info.select_info</code>","text":""},{"location":"code_docs/interact/prompt/collect/manager/abort/","title":"Abort","text":""},{"location":"code_docs/interact/prompt/collect/manager/abort/#labridge.interact.prompt.collect.manager.abort","title":"<code>labridge.interact.prompt.collect.manager.abort</code>","text":""},{"location":"code_docs/interact/prompt/collect/manager/do_modify/","title":"Do modify","text":""},{"location":"code_docs/interact/prompt/collect/manager/do_modify/#labridge.interact.prompt.collect.manager.do_modify","title":"<code>labridge.interact.prompt.collect.manager.do_modify</code>","text":""},{"location":"code_docs/interact/prompt/collect/manager/verify/","title":"Verify","text":""},{"location":"code_docs/interact/prompt/collect/manager/verify/#labridge.interact.prompt.collect.manager.verify","title":"<code>labridge.interact.prompt.collect.manager.verify</code>","text":""},{"location":"code_docs/interact/prompt/collect/modify_info/common_info/","title":"Common info","text":""},{"location":"code_docs/interact/prompt/collect/modify_info/common_info/#labridge.interact.prompt.collect.modify_info.common_info","title":"<code>labridge.interact.prompt.collect.modify_info.common_info</code>","text":""},{"location":"code_docs/interact/prompt/collect/modify_info/prompt_keys/","title":"Prompt keys","text":""},{"location":"code_docs/interact/prompt/collect/modify_info/prompt_keys/#labridge.interact.prompt.collect.modify_info.prompt_keys","title":"<code>labridge.interact.prompt.collect.modify_info.prompt_keys</code>","text":""},{"location":"code_docs/interact/prompt/collect/modify_info/select_info/","title":"Select info","text":""},{"location":"code_docs/interact/prompt/collect/modify_info/select_info/#labridge.interact.prompt.collect.modify_info.select_info","title":"<code>labridge.interact.prompt.collect.modify_info.select_info</code>","text":""},{"location":"code_docs/interface/http_server/","title":"Http server","text":""},{"location":"code_docs/interface/http_server/#labridge.interface.http_server","title":"<code>labridge.interface.http_server</code>","text":""},{"location":"code_docs/interface/utils/","title":"Utils","text":""},{"location":"code_docs/interface/utils/#labridge.interface.utils","title":"<code>labridge.interface.utils</code>","text":""},{"location":"code_docs/models/local/mindspore_models/","title":"Mindspore models","text":""},{"location":"code_docs/models/local/mindspore_models/#labridge.models.local.mindspore_models","title":"<code>labridge.models.local.mindspore_models</code>","text":""},{"location":"code_docs/models/local/mindspore_models/#labridge.models.local.mindspore_models.MindsporeEmbedding","title":"<code>labridge.models.local.mindspore_models.MindsporeEmbedding</code>","text":"<p>               Bases: <code>BaseEmbedding</code></p> <p>The Embedding model based on Mindspore framework and MindNLP.</p> ATTRIBUTE DESCRIPTION <code>cache_folder</code> <p>Cache folder for Hugging Face files.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>normalize</code> <p>Normalize embeddings or not.</p> <p> TYPE: <code>bool</code> </p> <code>query_instruction</code> <p>Instruction to prepend to query text.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>text_instruction</code> <p>Instruction to prepend to text.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>_embed_model</code> <p>The loaded embedding model.</p> <p> TYPE: <code>SentenceTransformer</code> </p> <code>_device</code> <p>The deployed device.</p> <p> TYPE: <code>str</code> </p> Source code in <code>labridge\\models\\local\\mindspore_models.py</code> <pre><code>class MindsporeEmbedding(BaseEmbedding):\n\tr\"\"\"\n\tThe Embedding model based on Mindspore framework and MindNLP.\n\n\tAttributes:\n\t\tcache_folder (Optional[str]): Cache folder for Hugging Face files.\n\t\tnormalize (bool): Normalize embeddings or not.\n\t\tquery_instruction (Optional[str]): Instruction to prepend to query text.\n\t\ttext_instruction (Optional[str]): Instruction to prepend to text.\n\t\t_embed_model (SentenceTransformer): The loaded embedding model.\n\t\t_device (str): The deployed device.\n\t\"\"\"\n\tcache_folder: Optional[str] = Field(\n\t\tdescription=\"Cache folder for Hugging Face files.\"\n\t)\n\tnormalize: bool = Field(\n\t\tdefault=True,\n\t\tdescription=\"Normalize embeddings or not.\"\n\t)\n\tquery_instruction: Optional[str] = Field(\n\t\tdescription=\"Instruction to prepend to query text.\"\n\t)\n\ttext_instruction: Optional[str] = Field(\n\t\tdescription=\"Instruction to prepend to text.\"\n\t)\n\t_embed_model: Any = PrivateAttr()\n\t_device: str = PrivateAttr()\n\n\tdef __init__(\n\t\tself,\n\t\tmodel_name: str = DEFAULT_MINDSPORE_EMBEDDING,\n\t\tdevice: str = \"Ascend\",\n\t\tquery_instruction: Optional[str] = None,\n\t\ttext_instruction: Optional[str] = None,\n\t\tnormalize: bool = True,\n\t\tembed_batch_size: int = DEFAULT_EMBED_BATCH_SIZE,\n\t\tcache_folder: Optional[str] = None,\n\t):\n\t\tsuper().__init__(\n\t\t\tmodel_name=model_name,\n\t\t\tembed_batch_size=embed_batch_size,\n\t\t\tnormalize = normalize,\n\t\t)\n\t\tcache_folder = cache_folder or get_cache_dir()\n\t\tself._device = device\n\n\t\tself._embed_model = SentenceTransformer(\n\t\t\tmodel_name_or_path=model_name,\n\t\t\tdevice=\"CPU\",\n\t\t\tcache_folder=cache_folder,\n\t\t\tprompts={\n\t\t\t\t\"query\": query_instruction\n\t\t\t\t\t\t or get_query_instruct_for_model_name(model_name),\n\t\t\t\t\"text\": text_instruction\n\t\t\t\t\t\tor get_text_instruct_for_model_name(model_name),\n\t\t\t}\n\t\t)\n\n\tdef _get_query_embedding(self, query: str) -&gt; Embedding:\n\t\tr\"\"\" Get the embeddings of a query from the Mindspore embedding model. \"\"\"\n\t\treturn self._embed(query, prompt_name=\"query\")\n\n\tdef _embed(\n\t\tself,\n\t\tsentences: str,\n\t\tprompt_name: Optional[str] = None,\n\t) -&gt; Embedding:\n\t\tr\"\"\" Mindspore embedding. \"\"\"\n\t\tembedding = self._embed_model.encode(\n\t\t\tsentences,\n\t\t\tprompt_name=prompt_name,\n\t\t\tbatch_size=self.embed_batch_size,\n\t\t\tnormalize_embeddings=True,\n\t\t)\n\t\treturn list(embedding.numpy())\n\n\tasync def _aget_query_embedding(self, query: str) -&gt; Embedding:\n\t\treturn self._get_query_embedding(query=query)\n\n\tdef _get_text_embedding(self, text: str) -&gt; Embedding:\n\t\tr\"\"\" Get the embeddings of a text from the Mindspore embedding model. \"\"\"\n\t\treturn self._embed(text, prompt_name=\"text\")\n</code></pre>"},{"location":"code_docs/models/local/mindspore_models/#labridge.models.local.mindspore_models.MindsporeLLM","title":"<code>labridge.models.local.mindspore_models.MindsporeLLM</code>","text":"<p>               Bases: <code>CustomLLM</code></p> <p>The LLM based on Mindspore framework and MindNLP.</p> ATTRIBUTE DESCRIPTION <code>model_name</code> <p>The model name to use from HuggingFace or local model directory.</p> <p> TYPE: <code>str</code> </p> <code>tokenizer_name</code> <p>The name of the tokenizer to use from HuggingFace.</p> <p> TYPE: <code>str</code> </p> <code>context_window</code> <p>The maximum number of tokens available for input.</p> <p> TYPE: <code>int</code> </p> <code>max_new_tokens</code> <p>The maximum number of tokens to generate.</p> <p> TYPE: <code>int</code> </p> <code>generate_kwargs</code> <p>The kwargs to pass to the model during generation.</p> <p> TYPE: <code>dict</code> </p> <code>is_chat_model</code> <p>is a chat model or not.</p> <p> TYPE: <code>bool</code> </p> <code>_model</code> <p>The loaded model.</p> <p> TYPE: <code>AutoModelForCausalLM</code> </p> <code>_tokenizer</code> <p>The loaded tokenizer.</p> <p> TYPE: <code>AutoTokenizer</code> </p> Source code in <code>labridge\\models\\local\\mindspore_models.py</code> <pre><code>class MindsporeLLM(CustomLLM):\n\tr\"\"\"\n\tThe LLM based on Mindspore framework and MindNLP.\n\n\tAttributes:\n\t\tmodel_name (str): The model name to use from HuggingFace or local model directory.\n\t\ttokenizer_name (str): The name of the tokenizer to use from HuggingFace.\n\t\tcontext_window (int): The maximum number of tokens available for input.\n\t\tmax_new_tokens (int): The maximum number of tokens to generate.\n\t\tgenerate_kwargs (dict): The kwargs to pass to the model during generation.\n\t\tis_chat_model (bool): is a chat model or not.\n\t\t_model (AutoModelForCausalLM): The loaded model.\n\t\t_tokenizer (AutoTokenizer): The loaded tokenizer.\n\t\"\"\"\n\tnum_output: int = 1024\n\n\tmodel_name: str = Field(\n\t\tdefault=DEFAULT_MINDSPORE_MODEL,\n\t\tdescription=(\n\t\t\t\"The model name to use from HuggingFace. \"\n\t\t),\n\t)\n\ttokenizer_name: str = Field(\n\t\tdefault=DEFAULT_MINDSPORE_MODEL,\n\t\tdescription=(\n\t\t\t\"The name of the tokenizer to use from HuggingFace. \"\n\t\t\t\"Unused if `tokenizer` is passed in directly.\"\n\t\t),\n\t)\n\tcontext_window: int = Field(\n\t\tdefault=DEFAULT_CONTEXT_WINDOW,\n\t\tdescription=\"The maximum number of tokens available for input.\",\n\t\tgt=0,\n\t)\n\tmax_new_tokens: int = Field(\n\t\tdefault=DEFAULT_NUM_OUTPUTS,\n\t\tdescription=\"The maximum number of tokens to generate.\",\n\t\tgt=0,\n\t)\n\tgenerate_kwargs: dict = Field(\n\t\tdefault=DEFAULT_MINDSPORE_GENERATE_KWARGS,\n\t\t# default_factory=dict,\n\t\tdescription=\"The kwargs to pass to the model during generation.\",\n\t)\n\tis_chat_model: bool = Field(\n\t\tdefault=False,\n\t\tdescription=(\n\t\t\t\tLLMMetadata.__fields__[\"is_chat_model\"].field_info.description\n\t\t\t\t+ \" Be sure to verify that you either pass an appropriate tokenizer \"\n\t\t\t\t\"that can convert prompts to properly formatted chat messages or a \"\n\t\t\t\t\"`messages_to_prompt` that does so.\"\n\t\t),\n\t)\n\n\t_model: Any = PrivateAttr()\n\t_tokenizer: Any = PrivateAttr()\n\n\tdef __init__(\n\t\tself,\n\t\tmodel_name: str = DEFAULT_MINDSPORE_MODEL,\n\t\ttokenizer_name: str = DEFAULT_MINDSPORE_MODEL,\n\t\tcontext_window: int = DEFAULT_CONTEXT_WINDOW,\n\t\tmax_new_tokens: int = DEFAULT_NUM_OUTPUTS,\n\t\tgenerate_kwargs: Optional[dict] = None,\n\t\tis_chat_model: Optional[bool] = False,\n\t\tsystem_prompt: str = \"\",\n\t\tmessages_to_prompt: Optional[Callable[[Sequence[ChatMessage]], str]] = None,\n\t\tcompletion_to_prompt: Optional[Callable[[str], str]] = None,\n\t):\n\t\tself._model = AutoModelForCausalLM.from_pretrained(\n\t\t\tpretrained_model_name_or_path=model_name,\n\t\t\tmirror='modelscope',\n\t\t\tms_dtype=mindspore.float16,\n\t\t).eval()\n\n\t\tconfig_dict = self._model.config.to_dict()\n\t\tmodel_context_window = int(\n\t\t\tconfig_dict.get(\"max_position_embeddings\", context_window)\n\t\t)\n\t\tif model_context_window and model_context_window &lt; context_window:\n\t\t\tcontext_window = model_context_window\n\n\t\tself._tokenizer = AutoTokenizer.from_pretrained(\n\t\t\tpretrained_model_name_or_path=model_name,\n\t\t\tmirror='modelscope',\n\t\t\tmax_length=context_window,\n\t\t)\n\t\tsuper().__init__(\n\t\t\tcontext_window=context_window,\n\t\t\tmax_new_tokens=max_new_tokens,\n\t\t\ttokenizer_name=tokenizer_name,\n\t\t\tmodel_name=model_name,\n\t\t\tgenerate_kwargs=generate_kwargs or DEFAULT_MINDSPORE_GENERATE_KWARGS,\n\t\t\tis_chat_model=is_chat_model,\n\t\t\tsystem_prompt = system_prompt,\n\t\t\tmessages_to_prompt=messages_to_prompt,\n\t\t\tcompletion_to_prompt=completion_to_prompt,\n\t\t)\n\n\t@property\n\tdef metadata(self) -&gt; LLMMetadata:\n\t\t\"\"\"Get LLM metadata.\"\"\"\n\t\treturn LLMMetadata(\n\t\t\tcontext_window=self.context_window,\n\t\t\tnum_output=self.max_new_tokens,\n\t\t\tmodel_name=self.model_name,\n\t\t\tis_chat_model=self.is_chat_model,\n\t\t)\n\n\t@llm_completion_callback()\n\tdef complete(self, prompt: str, **kwargs: Any) -&gt; CompletionResponse:\n\t\tr\"\"\" Get response from the Mindspore LLM. \"\"\"\n\t\tinputs = self._tokenizer(prompt, return_tensors=\"ms\")\n\t\toutputs = self._model.generate(**inputs, **self.generate_kwargs)\n\t\toutputs = outputs[:, inputs['input_ids'].shape[1]:]\n\t\tresponse_text = self._tokenizer.decode(outputs[0], skip_special_tokens=True)\n\t\treturn CompletionResponse(text=response_text)\n\n\t@llm_completion_callback()\n\tdef stream_complete(self, prompt: str, **kwargs: Any) -&gt; CompletionResponseGen:\n\t\tr\"\"\" Get response from the Mindspore LLM. \"\"\"\n\t\tinputs = self._tokenizer(prompt, return_tensors=\"ms\")\n\t\toutputs = self._model.generate(**inputs, **self.generate_kwargs)\n\t\toutputs = outputs[:, inputs['input_ids'].shape[1]:]\n\t\tresponse_text = self._tokenizer.decode(outputs[0], skip_special_tokens=True)\n\t\tgen_tokens = \"\"\n\t\tfor token in response_text:\n\t\t\tgen_tokens += token\n\t\t\tyield CompletionResponse(text=gen_tokens, delta=token)\n</code></pre>"},{"location":"code_docs/models/local/mindspore_models/#labridge.models.local.mindspore_models.MindsporeLLM.metadata","title":"<code>labridge.models.local.mindspore_models.MindsporeLLM.metadata: LLMMetadata</code>  <code>property</code>","text":"<p>Get LLM metadata.</p>"},{"location":"code_docs/models/local/mindspore_models/#labridge.models.local.mindspore_models.MindsporeLLM.complete","title":"<code>labridge.models.local.mindspore_models.MindsporeLLM.complete(prompt, **kwargs)</code>","text":"<p>Get response from the Mindspore LLM.</p> Source code in <code>labridge\\models\\local\\mindspore_models.py</code> <pre><code>@llm_completion_callback()\ndef complete(self, prompt: str, **kwargs: Any) -&gt; CompletionResponse:\n\tr\"\"\" Get response from the Mindspore LLM. \"\"\"\n\tinputs = self._tokenizer(prompt, return_tensors=\"ms\")\n\toutputs = self._model.generate(**inputs, **self.generate_kwargs)\n\toutputs = outputs[:, inputs['input_ids'].shape[1]:]\n\tresponse_text = self._tokenizer.decode(outputs[0], skip_special_tokens=True)\n\treturn CompletionResponse(text=response_text)\n</code></pre>"},{"location":"code_docs/models/local/mindspore_models/#labridge.models.local.mindspore_models.MindsporeLLM.stream_complete","title":"<code>labridge.models.local.mindspore_models.MindsporeLLM.stream_complete(prompt, **kwargs)</code>","text":"<p>Get response from the Mindspore LLM.</p> Source code in <code>labridge\\models\\local\\mindspore_models.py</code> <pre><code>@llm_completion_callback()\ndef stream_complete(self, prompt: str, **kwargs: Any) -&gt; CompletionResponseGen:\n\tr\"\"\" Get response from the Mindspore LLM. \"\"\"\n\tinputs = self._tokenizer(prompt, return_tensors=\"ms\")\n\toutputs = self._model.generate(**inputs, **self.generate_kwargs)\n\toutputs = outputs[:, inputs['input_ids'].shape[1]:]\n\tresponse_text = self._tokenizer.decode(outputs[0], skip_special_tokens=True)\n\tgen_tokens = \"\"\n\tfor token in response_text:\n\t\tgen_tokens += token\n\t\tyield CompletionResponse(text=gen_tokens, delta=token)\n</code></pre>"},{"location":"code_docs/models/remote/remote_models/","title":"Remote models","text":""},{"location":"code_docs/models/remote/remote_models/#labridge.models.remote.remote_models","title":"<code>labridge.models.remote.remote_models</code>","text":""},{"location":"code_docs/models/remote/remote_models/#labridge.models.remote.remote_models.AsyncModelClient","title":"<code>labridge.models.remote.remote_models.AsyncModelClient</code>","text":"<p>               Bases: <code>object</code></p> <p>This is an asynchronous client to communicate with a LLM deployed on a server through HTTP.</p> PARAMETER DESCRIPTION <code>base_url</code> <p>The base URL of the server.</p> <p> TYPE: <code>URL</code> </p> <code>model_type</code> <p>LLM or Embed.</p> <p> TYPE: <code>RemoteModelType</code> </p> <code>timeout</code> <p>The timeout of a request.</p> <p> TYPE: <code>Timeout</code> DEFAULT: <code>None</code> </p> <code>limits</code> <p>The limits configuration to use.</p> <p> TYPE: <code>Limits</code> DEFAULT: <code>None</code> </p> Source code in <code>labridge\\models\\remote\\remote_models.py</code> <pre><code>class AsyncModelClient(object):\n\tr\"\"\"\n\tThis is an asynchronous client to communicate with a LLM deployed on a server through HTTP.\n\n\tArgs:\n\t\tbase_url (URL): The base URL of the server.\n\t\tmodel_type (RemoteModelType): LLM or Embed.\n\t\ttimeout (Timeout): The timeout of a request.\n\t\tlimits (Limits): The limits configuration to use.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tmodel_type: RemoteModelType,\n\t\ttimeout: Timeout = None,\n\t\tlimits: Limits = None,\n\t):\n\t\tself._model_type = model_type\n\t\tself._timeout = timeout or DEFAULT_LLM_TIMEOUT\n\t\tself._limits = limits or DEFAULT_LLM_LIMITS\n\t\tself._client = httpx.AsyncClient(\n\t\t\ttimeout=self._timeout,\n\t\t\tlimits=self._limits,\n\t\t)\n\n\tdef formatted_input(self, input_str: str) -&gt; dict:\n\t\tr\"\"\" Pack the query string in a JSON format to send to the server. \"\"\"\n\t\treturn {\n\t\t\t\"text\": input_str,\n\t\t}\n\n\tasync def arequest(self, url: URL, input_str: str):\n\t\tr\"\"\"\n\t\tAsynchronous version.\n\n\t\tSend the query string to the server's model and get the results.\n\n\t\tArgs:\n\t\t\turl (URL): The server's serve URL.\n\t\t\tinput_str (str): The query string.\n\n\t\tReturns:\n\t\t\tUnion[str, List[float]]: The results of a remote LLM or remote embedding model.\n\t\t\"\"\"\n\t\tquery = self.formatted_input(input_str=input_str)\n\n\t\tresponse = await self._client.send(\n\t\t\trequest=Request(\n\t\t\t\tmethod=\"post\",\n\t\t\t\turl=url,\n\t\t\t\tjson=query\n\t\t\t)\n\t\t)\n\t\toutput_dict = json.loads(response.text)\n\t\toutput = output_dict[\"output\"]\n\t\treturn output\n</code></pre>"},{"location":"code_docs/models/remote/remote_models/#labridge.models.remote.remote_models.AsyncModelClient.arequest","title":"<code>labridge.models.remote.remote_models.AsyncModelClient.arequest(url, input_str)</code>  <code>async</code>","text":"<p>Asynchronous version.</p> <p>Send the query string to the server's model and get the results.</p> PARAMETER DESCRIPTION <code>url</code> <p>The server's serve URL.</p> <p> TYPE: <code>URL</code> </p> <code>input_str</code> <p>The query string.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <p>Union[str, List[float]]: The results of a remote LLM or remote embedding model.</p> Source code in <code>labridge\\models\\remote\\remote_models.py</code> <pre><code>async def arequest(self, url: URL, input_str: str):\n\tr\"\"\"\n\tAsynchronous version.\n\n\tSend the query string to the server's model and get the results.\n\n\tArgs:\n\t\turl (URL): The server's serve URL.\n\t\tinput_str (str): The query string.\n\n\tReturns:\n\t\tUnion[str, List[float]]: The results of a remote LLM or remote embedding model.\n\t\"\"\"\n\tquery = self.formatted_input(input_str=input_str)\n\n\tresponse = await self._client.send(\n\t\trequest=Request(\n\t\t\tmethod=\"post\",\n\t\t\turl=url,\n\t\t\tjson=query\n\t\t)\n\t)\n\toutput_dict = json.loads(response.text)\n\toutput = output_dict[\"output\"]\n\treturn output\n</code></pre>"},{"location":"code_docs/models/remote/remote_models/#labridge.models.remote.remote_models.AsyncModelClient.formatted_input","title":"<code>labridge.models.remote.remote_models.AsyncModelClient.formatted_input(input_str)</code>","text":"<p>Pack the query string in a JSON format to send to the server.</p> Source code in <code>labridge\\models\\remote\\remote_models.py</code> <pre><code>def formatted_input(self, input_str: str) -&gt; dict:\n\tr\"\"\" Pack the query string in a JSON format to send to the server. \"\"\"\n\treturn {\n\t\t\"text\": input_str,\n\t}\n</code></pre>"},{"location":"code_docs/models/remote/remote_models/#labridge.models.remote.remote_models.ModelClient","title":"<code>labridge.models.remote.remote_models.ModelClient</code>","text":"<p>               Bases: <code>object</code></p> <p>This is a client to communicate with a LLM deployed on a server through HTTP.</p> PARAMETER DESCRIPTION <code>base_url</code> <p>The base URL of the server.</p> <p> TYPE: <code>URL</code> </p> <code>model_type</code> <p>LLM or Embed.</p> <p> TYPE: <code>RemoteModelType</code> </p> <code>timeout</code> <p>The timeout of a request.</p> <p> TYPE: <code>Timeout</code> DEFAULT: <code>None</code> </p> <code>limits</code> <p>The limits configuration to use.</p> <p> TYPE: <code>Limits</code> DEFAULT: <code>None</code> </p> Source code in <code>labridge\\models\\remote\\remote_models.py</code> <pre><code>class ModelClient(object):\n\tr\"\"\"\n\tThis is a client to communicate with a LLM deployed on a server through HTTP.\n\n\tArgs:\n\t\tbase_url (URL): The base URL of the server.\n\t\tmodel_type (RemoteModelType): LLM or Embed.\n\t\ttimeout (Timeout): The timeout of a request.\n\t\tlimits (Limits): The limits configuration to use.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tbase_url: URL,\n\t\tmodel_type: RemoteModelType,\n\t\ttimeout: Timeout = None,\n\t\tlimits: Limits = None,\n\t):\n\t\tself._model_type = model_type\n\t\tself._timeout = timeout or DEFAULT_LLM_TIMEOUT\n\t\tself._limits = limits or DEFAULT_LLM_LIMITS\n\t\tself._client = httpx.Client(\n\t\t\tbase_url=base_url,\n\t\t\ttimeout=self._timeout,\n\t\t\tlimits=self._limits,\n\t\t)\n\n\tdef formatted_input(self, input_str: str) -&gt; dict:\n\t\tr\"\"\" Pack the query string in a JSON format to send to the server. \"\"\"\n\t\treturn {\n\t\t\t\"text\": input_str,\n\t\t}\n\n\tdef request(self, url: URL, input_str: str) -&gt; Union[str, List[float]]:\n\t\tr\"\"\"\n\t\tSend the query string to the server's model and get the results.\n\n\t\tArgs:\n\t\t\turl (URL): The server's serve URL.\n\t\t\tinput_str (str): The query string.\n\n\t\tReturns:\n\t\t\tUnion[str, List[float]]: The results of a remote LLM or remote embedding model.\n\t\t\"\"\"\n\t\tquery = self.formatted_input(input_str=input_str)\n\n\t\tresponse = self._client.send(\n\t\t\trequest=Request(\n\t\t\t\tmethod=\"post\",\n\t\t\t\turl=url,\n\t\t\t\tjson=query\n\t\t\t)\n\t\t)\n\t\toutput_dict = json.loads(response.text)\n\t\toutput = output_dict[\"output\"]\n\t\treturn output\n</code></pre>"},{"location":"code_docs/models/remote/remote_models/#labridge.models.remote.remote_models.ModelClient.formatted_input","title":"<code>labridge.models.remote.remote_models.ModelClient.formatted_input(input_str)</code>","text":"<p>Pack the query string in a JSON format to send to the server.</p> Source code in <code>labridge\\models\\remote\\remote_models.py</code> <pre><code>def formatted_input(self, input_str: str) -&gt; dict:\n\tr\"\"\" Pack the query string in a JSON format to send to the server. \"\"\"\n\treturn {\n\t\t\"text\": input_str,\n\t}\n</code></pre>"},{"location":"code_docs/models/remote/remote_models/#labridge.models.remote.remote_models.ModelClient.request","title":"<code>labridge.models.remote.remote_models.ModelClient.request(url, input_str)</code>","text":"<p>Send the query string to the server's model and get the results.</p> PARAMETER DESCRIPTION <code>url</code> <p>The server's serve URL.</p> <p> TYPE: <code>URL</code> </p> <code>input_str</code> <p>The query string.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Union[str, List[float]]</code> <p>Union[str, List[float]]: The results of a remote LLM or remote embedding model.</p> Source code in <code>labridge\\models\\remote\\remote_models.py</code> <pre><code>def request(self, url: URL, input_str: str) -&gt; Union[str, List[float]]:\n\tr\"\"\"\n\tSend the query string to the server's model and get the results.\n\n\tArgs:\n\t\turl (URL): The server's serve URL.\n\t\tinput_str (str): The query string.\n\n\tReturns:\n\t\tUnion[str, List[float]]: The results of a remote LLM or remote embedding model.\n\t\"\"\"\n\tquery = self.formatted_input(input_str=input_str)\n\n\tresponse = self._client.send(\n\t\trequest=Request(\n\t\t\tmethod=\"post\",\n\t\t\turl=url,\n\t\t\tjson=query\n\t\t)\n\t)\n\toutput_dict = json.loads(response.text)\n\toutput = output_dict[\"output\"]\n\treturn output\n</code></pre>"},{"location":"code_docs/models/remote/remote_models/#labridge.models.remote.remote_models.RemoteLLM","title":"<code>labridge.models.remote.remote_models.RemoteLLM</code>","text":"<p>               Bases: <code>CustomLLM</code></p> <p>A remote LLM deployed on the server.</p> ATTRIBUTE DESCRIPTION <code>context_window</code> <p>The maximum number of tokens available for input.</p> <p> TYPE: <code>int</code> </p> <code>num_output</code> <p>The maximum number of tokens to generate.</p> <p> TYPE: <code>int</code> </p> <code>model_name</code> <p>The model name to use from HuggingFace or local model directory.</p> <p> TYPE: <code>str</code> </p> <code>is_chat_model</code> <p>is a chat model or not.</p> <p> TYPE: <code>bool</code> </p> <code>base_url</code> <p>The base URL of the server.</p> <p> TYPE: <code>str</code> </p> <code>llm_url</code> <p>Server's URL for receiving local inputs.</p> <p> TYPE: <code>str</code> </p> <code>async_llm_url</code> <p>Server's URL for asynchronously receiving local inputs.</p> <p> TYPE: <code>str</code> </p> <code>_client</code> <p>The local client.</p> <p> TYPE: <code>ModelClient</code> </p> <code>_async_client</code> <p>The asynchronous local client.</p> <p> TYPE: <code>AsyncModelClient</code> </p> Source code in <code>labridge\\models\\remote\\remote_models.py</code> <pre><code>class RemoteLLM(CustomLLM):\n\tr\"\"\"\n\tA remote LLM deployed on the server.\n\n\tAttributes:\n\t\tcontext_window (int): The maximum number of tokens available for input.\n\t\tnum_output (int): The maximum number of tokens to generate.\n\t\tmodel_name (str): The model name to use from HuggingFace or local model directory.\n\t\tis_chat_model (bool): is a chat model or not.\n\t\tbase_url (str): The base URL of the server.\n\t\tllm_url (str): Server's URL for receiving local inputs.\n\t\tasync_llm_url (str): Server's URL for asynchronously receiving local inputs.\n\t\t_client (ModelClient): The local client.\n\t\t_async_client (AsyncModelClient): The asynchronous local client.\n\t\"\"\"\n\tcontext_window: int = 16000 # useless\n\tnum_output: int = 1024\t# useless\n\tmodel_name: str = \"remote\"\n\tis_chat_model: bool = False\n\n\tbase_url: str = Field(\n\t\tdefault=DEFAULT_BASE_URL,\n\t\tdescription=\"Base URL\",\n\t)\n\tllm_url: str = Field(\n\t\tdefault=DEFAULT_LLM_URL,\n\t\tdescription=\"URL for receiving local inputs\"\n\t)\n\tasync_llm_url: str = Field(\n\t\tdefault=DEFAULT_ASYNC_LLM_URL,\n\t\tdescription=\"URL for asynchronously receiving local inputs\"\n\t)\n\n\t_client: ModelClient = PrivateAttr()\n\t_async_client: AsyncModelClient = PrivateAttr()\n\n\tdef __init__(\n\t\tself,\n\t\tbase_url: str,\n\t\tllm_url: str,\n\t\tasync_llm_url: str,\n\t\tcontext_window: int = 16000,\n\t\tnum_output: int = 1024,\n\t\tmodel_name: str = \"remote\",\n\t\tis_chat_model: bool = False,\n\n\t):\n\t\tbase_url = base_url or DEFAULT_BASE_URL\n\t\tllm_url = llm_url or DEFAULT_LLM_URL\n\t\tasync_llm_url = async_llm_url or DEFAULT_ASYNC_LLM_URL\n\t\tself._client = ModelClient(\n\t\t\tbase_url=URL(base_url),\n\t\t\tmodel_type=RemoteModelType.LLM,\n\t\t)\n\t\tself._async_client = AsyncModelClient(\n\t\t\tmodel_type=RemoteModelType.LLM,\n\t\t)\n\t\tsuper().__init__(\n\t\t\tbase_url=base_url,\n\t\t\tllm_url=llm_url,\n\t\t\tasync_llm_url = async_llm_url,\n\t\t\tcontext_window=context_window,\n\t\t\tnum_output=num_output,\n\t\t\tmodel_name=model_name,\n\t\t\tis_chat_model=is_chat_model,\n\t\t)\n\n\t@property\n\tdef metadata(self) -&gt; LLMMetadata:\n\t\t\"\"\"Get LLM metadata.\"\"\"\n\t\treturn LLMMetadata(\n\t\t\tcontext_window=self.context_window,\n\t\t\tnum_output=self.num_output,\n\t\t\tmodel_name=self.model_name,\n\t\t)\n\n\t@llm_completion_callback()\n\tdef complete(self, prompt: str, **kwargs: Any) -&gt; CompletionResponse:\n\t\tr\"\"\" Get response from the Remote LLM. \"\"\"\n\t\ttry:\n\t\t\tresponse = self._client.request(\n\t\t\t\turl=URL(self.llm_url),\n\t\t\t\tinput_str=prompt,\n\t\t\t)\n\t\t\treturn CompletionResponse(text=response)\n\t\texcept Exception as e:\n\t\t\treturn CompletionResponse(text=e)\n\n\n\t@llm_completion_callback()\n\tasync def acomplete(self, prompt: str, **kwargs: Any) -&gt; CompletionResponse:\n\t\tr\"\"\" Asynchronously get response from the Remote LLM. \"\"\"\n\t\ttry:\n\t\t\tprint(\"User: \", prompt)\n\t\t\tresponse = await self._async_client.arequest(\n\t\t\t\turl=URL(self.async_llm_url),\n\t\t\t\tinput_str=prompt,\n\t\t\t)\n\t\t\treturn CompletionResponse(text=response)\n\t\texcept Exception as e:\n\t\t\treturn CompletionResponse(text=e)\n\n\t@llm_completion_callback()\n\tdef stream_complete(self, prompt: str, **kwargs: Any) -&gt; CompletionResponseGen:\n\t\ttry:\n\t\t\tresponse = self._client.request(\n\t\t\t\turl=URL(self.llm_url),\n\t\t\t\tinput_str=prompt,\n\t\t\t)\n\t\texcept Exception as e:\n\t\t\tresponse = e\n\n\t\tgen_tokens = \"\"\n\t\tfor token in response:\n\t\t\tgen_tokens += token\n\t\t\tyield CompletionResponse(text=response, delta=token)\n</code></pre>"},{"location":"code_docs/models/remote/remote_models/#labridge.models.remote.remote_models.RemoteLLM.metadata","title":"<code>labridge.models.remote.remote_models.RemoteLLM.metadata: LLMMetadata</code>  <code>property</code>","text":"<p>Get LLM metadata.</p>"},{"location":"code_docs/models/remote/remote_models/#labridge.models.remote.remote_models.RemoteLLM.acomplete","title":"<code>labridge.models.remote.remote_models.RemoteLLM.acomplete(prompt, **kwargs)</code>  <code>async</code>","text":"<p>Asynchronously get response from the Remote LLM.</p> Source code in <code>labridge\\models\\remote\\remote_models.py</code> <pre><code>@llm_completion_callback()\nasync def acomplete(self, prompt: str, **kwargs: Any) -&gt; CompletionResponse:\n\tr\"\"\" Asynchronously get response from the Remote LLM. \"\"\"\n\ttry:\n\t\tprint(\"User: \", prompt)\n\t\tresponse = await self._async_client.arequest(\n\t\t\turl=URL(self.async_llm_url),\n\t\t\tinput_str=prompt,\n\t\t)\n\t\treturn CompletionResponse(text=response)\n\texcept Exception as e:\n\t\treturn CompletionResponse(text=e)\n</code></pre>"},{"location":"code_docs/models/remote/remote_models/#labridge.models.remote.remote_models.RemoteLLM.complete","title":"<code>labridge.models.remote.remote_models.RemoteLLM.complete(prompt, **kwargs)</code>","text":"<p>Get response from the Remote LLM.</p> Source code in <code>labridge\\models\\remote\\remote_models.py</code> <pre><code>@llm_completion_callback()\ndef complete(self, prompt: str, **kwargs: Any) -&gt; CompletionResponse:\n\tr\"\"\" Get response from the Remote LLM. \"\"\"\n\ttry:\n\t\tresponse = self._client.request(\n\t\t\turl=URL(self.llm_url),\n\t\t\tinput_str=prompt,\n\t\t)\n\t\treturn CompletionResponse(text=response)\n\texcept Exception as e:\n\t\treturn CompletionResponse(text=e)\n</code></pre>"},{"location":"code_docs/models/remote/remote_server/","title":"Remote server","text":""},{"location":"code_docs/models/remote/remote_server/#labridge.models.remote.remote_server","title":"<code>labridge.models.remote.remote_server</code>","text":""},{"location":"code_docs/tools/utils/","title":"Utils","text":""},{"location":"code_docs/tools/utils/#labridge.tools.utils","title":"<code>labridge.tools.utils</code>","text":""},{"location":"code_docs/tools/utils/#labridge.tools.utils.create_schema_from_fn_or_method","title":"<code>labridge.tools.utils.create_schema_from_fn_or_method(name, func, additional_fields=None)</code>","text":"<p>Create schema from function.</p> Source code in <code>labridge\\tools\\utils.py</code> <pre><code>def create_schema_from_fn_or_method(\n    name: str,\n    func: Callable[..., Any],\n    additional_fields: Optional[\n        List[Union[Tuple[str, Type, Any], Tuple[str, Type]]]\n    ] = None,\n) -&gt; Type[BaseModel]:\n\t\"\"\"Create schema from function.\"\"\"\n\tfields = {}\n\tparams = signature(func).parameters\n\tfor param_name in params:\n\t\tif param_name in [\"self\", \"cls\"]:\n\t\t\tcontinue\n\t\tparam_type = params[param_name].annotation\n\t\tparam_default = params[param_name].default\n\n\t\tif param_type is params[param_name].empty:\n\t\t\tparam_type = Any\n\n\t\tif param_default is params[param_name].empty:\n\t\t\t# Required field\n\t\t\tfields[param_name] = (param_type, FieldInfo())\n\t\telif isinstance(param_default, FieldInfo):\n\t\t\t# Field with pydantic.Field as default value\n\t\t\tfields[param_name] = (param_type, param_default)\n\t\telse:\n\t\t\tfields[param_name] = (param_type, FieldInfo(default=param_default))\n\n\tadditional_fields = additional_fields or []\n\tfor field_info in additional_fields:\n\t\tif len(field_info) == 3:\n\t\t\tfield_info = cast(Tuple[str, Type, Any], field_info)\n\t\t\tfield_name, field_type, field_default = field_info\n\t\t\tfields[field_name] = (field_type, FieldInfo(default=field_default))\n\t\telif len(field_info) == 2:\n\t\t\t# Required field has no default value\n\t\t\tfield_info = cast(Tuple[str, Type], field_info)\n\t\t\tfield_name, field_type = field_info\n\t\t\tfields[field_name] = (field_type, FieldInfo())\n\t\telse:\n\t\t\traise ValueError(\n\t\t\t\tf\"Invalid additional field info: {field_info}. \"\n\t\t\t\t\"Must be a tuple of length 2 or 3.\"\n\t\t\t)\n\n\treturn create_model(name, **fields)  # type: ignore\n</code></pre>"},{"location":"code_docs/tools/utils/#labridge.tools.utils.get_extra_str_to_user","title":"<code>labridge.tools.utils.get_extra_str_to_user(tool_logs)</code>","text":"<p>The <code>log_to_user</code> and the value of the key <code>references</code> in ToolLog will be presented to the user.</p> Source code in <code>labridge\\tools\\utils.py</code> <pre><code>def get_extra_str_to_user(tool_logs: List[ToolLog]) -&gt; str:\n\tr\"\"\"\n\tThe `log_to_user` and the value of the key `references` in ToolLog will be presented to the user.\n\t\"\"\"\n\tstr_list = []\n\n\textra_refs_dict = get_all_ref_info(tool_logs=tool_logs)\n\n\tfor log in tool_logs:\n\t\tif log.log_to_user is not None:\n\t\t\tstr_list.append(log.log_to_user.strip())\n\n\tfor ref_type in extra_refs_dict.keys():\n\t\tfn = REF_INFO_TO_STR_FUNC_DICT[ref_type]\n\t\tref_str = fn(extra_refs_dict[ref_type])\n\t\tstr_list.append(ref_str.strip())\n\treturn \"\\n\".join(str_list)\n</code></pre>"},{"location":"code_docs/tools/utils/#labridge.tools.utils.get_ref_file_paths","title":"<code>labridge.tools.utils.get_ref_file_paths(tool_logs)</code>","text":"Source code in <code>labridge\\tools\\utils.py</code> <pre><code>def get_ref_file_paths(tool_logs: List[ToolLog]) -&gt; List[str]:\n\tr\"\"\"\n\n\t\"\"\"\n\textra_refs_dict = get_all_ref_info(tool_logs=tool_logs)\n\n\tfile_paths = []\n\tfor ref_type in extra_refs_dict.keys():\n\t\tif ref_type in REF_INFO_TO_FILE_PATH_FUNC_DICT.keys():\n\t\t\tfn = REF_INFO_TO_FILE_PATH_FUNC_DICT[ref_type]\n\t\t\tpaths = fn(extra_refs_dict[ref_type])\n\t\t\tfile_paths.extend(paths)\n\treturn file_paths\n</code></pre>"},{"location":"code_docs/tools/utils/#labridge.tools.utils.pack_tool_output","title":"<code>labridge.tools.utils.pack_tool_output(tool_output, tool_log=None)</code>","text":"<p>Pack the tool output and tool log in a dict and dump to string.</p> PARAMETER DESCRIPTION <code>tool_output</code> <p>The tool output string.</p> <p> TYPE: <code>str</code> </p> <code>tool_log</code> <p>The tool log string.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>str</code> <p>The dumped tool output and log.</p> Source code in <code>labridge\\tools\\utils.py</code> <pre><code>def pack_tool_output(tool_output: str, tool_log: str = None) -&gt; str:\n\tr\"\"\"\n\tPack the tool output and tool log in a dict and dump to string.\n\n\tArgs:\n\t\ttool_output (str): The tool output string.\n\t\ttool_log (str): The tool log string.\n\n\tReturns:\n\t\tThe dumped tool output and log.\n\t\"\"\"\n\ttool_out_dict = {\n\t\t\"tool_output\": tool_output,\n\t\t\"tool_log\": tool_log,\n\t}\n\ttool_out_str = json.dumps(tool_out_dict)\n\treturn tool_out_str\n</code></pre>"},{"location":"code_docs/tools/utils/#labridge.tools.utils.unpack_tool_output","title":"<code>labridge.tools.utils.unpack_tool_output(tool_out_json)</code>","text":"<p>Unpack the tool output string and tool log string from</p> PARAMETER DESCRIPTION <code>tool_out_json</code> <p> TYPE: <code>str</code> </p> Source code in <code>labridge\\tools\\utils.py</code> <pre><code>def unpack_tool_output(tool_out_json: str) -&gt; Tuple[str, Optional[str]]:\n\tr\"\"\"\n\tUnpack the tool output string and tool log string from\n\n\tArgs:\n\t\ttool_out_json:\n\n\tReturns:\n\n\t\"\"\"\n\ttry:\n\t\ttool_out_dict = json.loads(tool_out_json)\n\t\ttool_output, tool_log = tool_out_dict[\"tool_output\"], tool_out_dict[\"tool_log\"]\n\t\treturn tool_output, tool_log\n\texcept Exception:\n\t\treturn tool_out_json, None\n</code></pre>"},{"location":"code_docs/tools/utils/#labridge.tools.utils.whether_abort_tool","title":"<code>labridge.tools.utils.whether_abort_tool(tool_output)</code>","text":"<p>Whether a tool is aborted during execution.</p> PARAMETER DESCRIPTION <code>tool_output</code> <p>The tool output of a tool.</p> <p> TYPE: <code>ToolOutput</code> </p> RETURNS DESCRIPTION <code>Optional[bool]</code> <p>Optional[bool]:</p> <ul> <li>If the tool's execution is aborted, return True.</li> <li>If the tool's execution is performed normally, return False.</li> <li>If error raises in this function, return None.</li> </ul> Source code in <code>labridge\\tools\\utils.py</code> <pre><code>def whether_abort_tool(tool_output: ToolOutput) -&gt; Optional[bool]:\n\tr\"\"\"\n\tWhether a tool is aborted during execution.\n\n\tArgs:\n\t\ttool_output (ToolOutput): The tool output of a tool.\n\n\tReturns:\n\t\tOptional[bool]:\n\n\t\t\t- If the tool's execution is aborted, return True.\n\t\t\t- If the tool's execution is performed normally, return False.\n\t\t\t- If error raises in this function, return None.\n\n\t\"\"\"\n\ttry:\n\t\t_, create_log_str = unpack_tool_output(tool_output.content)\n\t\tcreate_log = ToolLog.loads(log_str=create_log_str)\n\t\t# if the user abort in the creation pipeline\n\t\treturn create_log.tool_abort\n\texcept ValueError:\n\t\treturn None\n</code></pre>"},{"location":"code_docs/tools/base/function_base_tools/","title":"Function base tools","text":""},{"location":"code_docs/tools/base/function_base_tools/#labridge.tools.base.function_base_tools","title":"<code>labridge.tools.base.function_base_tools</code>","text":""},{"location":"code_docs/tools/base/function_base_tools/#labridge.tools.base.function_base_tools.CallBackBaseTool","title":"<code>labridge.tools.base.function_base_tools.CallBackBaseTool</code>","text":"<p>               Bases: <code>FunctionBaseTool</code></p> <p>This is base of tools that will execute operations that need authorization. Refer to the <code>callback</code> module for details.</p> PARAMETER DESCRIPTION <code>fn</code> <p>The function or method that will be called by the agent.</p> <p> TYPE: <code>Callable</code> </p> <code>async_fn</code> <p>The asynchronous version of <code>fn</code>.</p> <p> TYPE: <code>Callable</code> </p> <code>callback_operation</code> <p>The operation that needs the user's authorization.</p> <p> TYPE: <code>CallBackOperationBase</code> </p> <code>tool_name</code> <p>The tool name.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>return_direct</code> <p>Whether to return the tool output directly in Reasoning &amp; Acting process.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> Source code in <code>labridge\\tools\\base\\function_base_tools.py</code> <pre><code>class CallBackBaseTool(FunctionBaseTool):\n\tr\"\"\"\n\tThis is base of tools that will execute operations that need authorization.\n\tRefer to the `callback` module for details.\n\n\tArgs:\n\t\tfn (Callable): The function or method that will be called by the agent.\n\t\tasync_fn (Callable): The asynchronous version of `fn`.\n\t\tcallback_operation (CallBackOperationBase): The operation that needs the user's authorization.\n\t\ttool_name (str): The tool name.\n\t\treturn_direct (bool): Whether to return the tool output directly in Reasoning &amp; Acting process.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tfn: Callable[..., Any],\n\t\tasync_fn: Callable[..., Any],\n\t\tcallback_operation: CallBackOperationBase,\n\t\ttool_name: str = None,\n\t\treturn_direct: bool = False,\n\t):\n\t\tself._callback_operation = callback_operation\n\t\tsuper().__init__(\n\t\t\tfn=fn,\n\t\t\tasync_fn=async_fn,\n\t\t\ttool_name=tool_name,\n\t\t\treturn_direct=return_direct,\n\t\t)\n\n\t@abstractmethod\n\tdef log(self, **kwargs: Any) -&gt; ToolLog:\n\t\tr\"\"\" Return the log json string, describing the tool's operation. \"\"\"\n</code></pre>"},{"location":"code_docs/tools/base/function_base_tools/#labridge.tools.base.function_base_tools.CallBackBaseTool.log","title":"<code>labridge.tools.base.function_base_tools.CallBackBaseTool.log(**kwargs)</code>  <code>abstractmethod</code>","text":"<p>Return the log json string, describing the tool's operation.</p> Source code in <code>labridge\\tools\\base\\function_base_tools.py</code> <pre><code>@abstractmethod\ndef log(self, **kwargs: Any) -&gt; ToolLog:\n\tr\"\"\" Return the log json string, describing the tool's operation. \"\"\"\n</code></pre>"},{"location":"code_docs/tools/base/function_base_tools/#labridge.tools.base.function_base_tools.FuncOutputWithLog","title":"<code>labridge.tools.base.function_base_tools.FuncOutputWithLog</code>","text":"<p>This class is the output format of the function in a FunctionBaseTool.</p> PARAMETER DESCRIPTION <code>fn_output</code> <p>The output of the function.</p> <p> TYPE: <code>str</code> </p> <code>fn_log</code> <p>The log of the function.</p> <p> TYPE: <code>Union[str, Dict[str, Any]]</code> </p> Source code in <code>labridge\\tools\\base\\function_base_tools.py</code> <pre><code>class FuncOutputWithLog:\n\tr\"\"\"\n\tThis class is the output format of the function in a FunctionBaseTool.\n\n\tArgs:\n\t\tfn_output (str): The output of the function.\n\t\tfn_log (Union[str, Dict[str, Any]]): The log of the function.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tfn_output: Optional[str],\n\t\tfn_log: Union[str, Dict[str, Any]]\n\t):\n\t\tself.fn_output = fn_output\n\t\tself.fn_log = fn_log\n</code></pre>"},{"location":"code_docs/tools/base/function_base_tools/#labridge.tools.base.function_base_tools.FunctionBaseTool","title":"<code>labridge.tools.base.function_base_tools.FunctionBaseTool</code>","text":"<p>               Bases: <code>CheckBaseTool</code></p> <p>This tool is the base of function-type or method-type tools.</p> PARAMETER DESCRIPTION <code>fn</code> <p>The function or method that will be called by the agent.</p> <p> TYPE: <code>Callable</code> </p> <code>async_fn</code> <p>The asynchronous version of <code>fn</code>.</p> <p> TYPE: <code>Callable</code> DEFAULT: <code>None</code> </p> <code>tool_name</code> <p>The tool name. If not specified, the <code>fn.__name__</code> will be used as the tool name.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>return_direct</code> <p>Whether to return the tool output directly in the Reasoning &amp; Acting process. Refer to <code>ReactAgent</code> for details.</p> <p> TYPE: <code>str</code> DEFAULT: <code>False</code> </p> Source code in <code>labridge\\tools\\base\\function_base_tools.py</code> <pre><code>class FunctionBaseTool(CheckBaseTool):\n\tr\"\"\"\n\tThis tool is the base of function-type or method-type tools.\n\n\tArgs:\n\t\tfn (Callable): The function or method that will be called by the agent.\n\t\tasync_fn (Callable): The asynchronous version of `fn`.\n\t\ttool_name (str): The tool name. If not specified, the `fn.__name__` will be used as the tool name.\n\t\treturn_direct (str): Whether to return the tool output directly in the Reasoning &amp; Acting process.\n\t\t\tRefer to `ReactAgent` for details.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tfn: Callable[..., Any],\n\t\tasync_fn: Callable[..., Any] = None,\n\t\ttool_name: str = None,\n\t\treturn_direct: bool = False,\n\t):\n\t\tname = tool_name or fn.__name__\n\t\tdocstring = fn.__doc__\n\t\tdescription = f\"{name}{signature(fn)}\\n{docstring}\"\n\t\tfn_schema = create_schema_from_fn_or_method(f\"{name}\", fn, additional_fields=None)\n\t\tmetadata = ToolMetadata(\n\t\t\tname=name,\n\t\t\tdescription=description,\n\t\t\tfn_schema=fn_schema,\n\t\t\treturn_direct=return_direct,\n\t\t)\n\n\t\tself._fn = fn\n\t\tif async_fn is not None:\n\t\t\tself._async_fn = async_fn\n\t\telse:\n\t\t\tself._async_fn = sync_to_async(self._fn)\n\t\tsuper().__init__(metadata=metadata)\n\n\t@abstractmethod\n\tdef log(self, **kwargs: Any) -&gt; ToolLog:\n\t\tr\"\"\" Return the log json string, describing the tool's operation. \"\"\"\n\n\tdef call(self, **kwargs: Any) -&gt; ToolOutput:\n\t\t\"\"\" Call, return output and log. \"\"\"\n\t\tchecked_kwargs = self._get_input(**kwargs)\n\t\toutput_with_log = self._fn(**checked_kwargs)\n\n\t\tif not isinstance(output_with_log, FuncOutputWithLog):\n\t\t\traise ValueError(\"The function of a function tool must output 'FuncOutputWithLog'.\")\n\n\t\tfn_output = output_with_log.fn_output\n\t\tfn_log = output_with_log.fn_log\n\t\tif not isinstance(fn_log, dict):\n\t\t\tfn_log = {\"fn_log\": fn_log}\n\t\telse:\n\t\t\tfn_log = fn_log\n\n\t\tchecked_kwargs.update(fn_log)\n\t\ttool_log = self.log(**checked_kwargs)\n\t\ttool_output = pack_tool_output(tool_output=fn_output, tool_log=tool_log.dumps())\n\n\t\treturn ToolOutput(\n\t\t\tcontent=str(tool_output),\n\t\t\ttool_name=self.metadata.name,\n\t\t\traw_input={\"kwargs\": kwargs},\n\t\t\traw_output=tool_output,\n\t\t)\n\n\tasync def acall(self, **kwargs: Any) -&gt; ToolOutput:\n\t\t\"\"\" Asynchronous Call. \"\"\"\n\t\tchecked_kwargs = self._get_input(**kwargs)\n\t\toutput_with_log = await self._async_fn(**checked_kwargs)\n\t\tif not isinstance(output_with_log, FuncOutputWithLog):\n\t\t\traise ValueError(\"The function of a function tool must output 'FuncOutputWithLog'.\")\n\n\t\tfn_output = output_with_log.fn_output\n\t\tfn_log = output_with_log.fn_log\n\t\tif not isinstance(fn_log, dict):\n\t\t\tfn_log = {\"fn_log\": fn_log}\n\t\telse:\n\t\t\tfn_log = fn_log\n\n\t\tchecked_kwargs.update(fn_log)\n\t\ttool_log = self.log(**checked_kwargs)\n\t\ttool_output = pack_tool_output(tool_output=fn_output, tool_log=tool_log.dumps())\n\t\treturn ToolOutput(\n\t\t\tcontent=str(tool_output),\n\t\t\ttool_name=self.metadata.name,\n\t\t\traw_input={\"kwargs\": kwargs},\n\t\t\traw_output=tool_output,\n\t\t)\n</code></pre>"},{"location":"code_docs/tools/base/function_base_tools/#labridge.tools.base.function_base_tools.FunctionBaseTool.acall","title":"<code>labridge.tools.base.function_base_tools.FunctionBaseTool.acall(**kwargs)</code>  <code>async</code>","text":"<p>Asynchronous Call.</p> Source code in <code>labridge\\tools\\base\\function_base_tools.py</code> <pre><code>async def acall(self, **kwargs: Any) -&gt; ToolOutput:\n\t\"\"\" Asynchronous Call. \"\"\"\n\tchecked_kwargs = self._get_input(**kwargs)\n\toutput_with_log = await self._async_fn(**checked_kwargs)\n\tif not isinstance(output_with_log, FuncOutputWithLog):\n\t\traise ValueError(\"The function of a function tool must output 'FuncOutputWithLog'.\")\n\n\tfn_output = output_with_log.fn_output\n\tfn_log = output_with_log.fn_log\n\tif not isinstance(fn_log, dict):\n\t\tfn_log = {\"fn_log\": fn_log}\n\telse:\n\t\tfn_log = fn_log\n\n\tchecked_kwargs.update(fn_log)\n\ttool_log = self.log(**checked_kwargs)\n\ttool_output = pack_tool_output(tool_output=fn_output, tool_log=tool_log.dumps())\n\treturn ToolOutput(\n\t\tcontent=str(tool_output),\n\t\ttool_name=self.metadata.name,\n\t\traw_input={\"kwargs\": kwargs},\n\t\traw_output=tool_output,\n\t)\n</code></pre>"},{"location":"code_docs/tools/base/function_base_tools/#labridge.tools.base.function_base_tools.FunctionBaseTool.call","title":"<code>labridge.tools.base.function_base_tools.FunctionBaseTool.call(**kwargs)</code>","text":"<p>Call, return output and log.</p> Source code in <code>labridge\\tools\\base\\function_base_tools.py</code> <pre><code>def call(self, **kwargs: Any) -&gt; ToolOutput:\n\t\"\"\" Call, return output and log. \"\"\"\n\tchecked_kwargs = self._get_input(**kwargs)\n\toutput_with_log = self._fn(**checked_kwargs)\n\n\tif not isinstance(output_with_log, FuncOutputWithLog):\n\t\traise ValueError(\"The function of a function tool must output 'FuncOutputWithLog'.\")\n\n\tfn_output = output_with_log.fn_output\n\tfn_log = output_with_log.fn_log\n\tif not isinstance(fn_log, dict):\n\t\tfn_log = {\"fn_log\": fn_log}\n\telse:\n\t\tfn_log = fn_log\n\n\tchecked_kwargs.update(fn_log)\n\ttool_log = self.log(**checked_kwargs)\n\ttool_output = pack_tool_output(tool_output=fn_output, tool_log=tool_log.dumps())\n\n\treturn ToolOutput(\n\t\tcontent=str(tool_output),\n\t\ttool_name=self.metadata.name,\n\t\traw_input={\"kwargs\": kwargs},\n\t\traw_output=tool_output,\n\t)\n</code></pre>"},{"location":"code_docs/tools/base/function_base_tools/#labridge.tools.base.function_base_tools.FunctionBaseTool.log","title":"<code>labridge.tools.base.function_base_tools.FunctionBaseTool.log(**kwargs)</code>  <code>abstractmethod</code>","text":"<p>Return the log json string, describing the tool's operation.</p> Source code in <code>labridge\\tools\\base\\function_base_tools.py</code> <pre><code>@abstractmethod\ndef log(self, **kwargs: Any) -&gt; ToolLog:\n\tr\"\"\" Return the log json string, describing the tool's operation. \"\"\"\n</code></pre>"},{"location":"code_docs/tools/base/tool_base/","title":"Tool base","text":""},{"location":"code_docs/tools/base/tool_base/#labridge.tools.base.tool_base","title":"<code>labridge.tools.base.tool_base</code>","text":""},{"location":"code_docs/tools/base/tool_base/#labridge.tools.base.tool_base.CheckBaseTool","title":"<code>labridge.tools.base.tool_base.CheckBaseTool</code>","text":"<p>               Bases: <code>AsyncBaseTool</code></p> <p>The base tool that will check the input keyword arguments according to the tool's fn_schema.</p> PARAMETER DESCRIPTION <code>metadata</code> <p>the tool's metadata.</p> <p> TYPE: <code>ToolMetadata</code> </p> Source code in <code>labridge\\tools\\base\\tool_base.py</code> <pre><code>class CheckBaseTool(AsyncBaseTool):\n\tr\"\"\"\n\tThe base tool that will check the input keyword arguments according to the tool's fn_schema.\n\n\tArgs:\n\t\tmetadata (ToolMetadata): the tool's metadata.\n\t\"\"\"\n\n\tdef __init__(self, metadata: ToolMetadata):\n\t\tself._metadata = metadata\n\t\tsuper().__init__()\n\n\t@property\n\tdef metadata(self) -&gt; ToolMetadata:\n\t\treturn self._metadata\n\n\tdef _get_input(self, **kwargs: Any) -&gt; dict:\n\t\tr\"\"\" Parse the required keyword arguments from the provided keyword arguments. \"\"\"\n\t\tfn_schema = json.loads(self.metadata.fn_schema_str)\n\t\targument_keys = list(fn_schema[\"properties\"].keys())\n\t\trequired_kwargs = fn_schema[\"required\"]\n\t\tmissing_keys = []\n\t\tfor key in required_kwargs:\n\t\t\tif key not in kwargs:\n\t\t\t\tmissing_keys.append(key)\n\t\tif len(missing_keys) &gt; 0:\n\t\t\tmissing_keys = ','.join(missing_keys)\n\t\t\traise ValueError(f\"The required parameters are not provided: {missing_keys}\")\n\n\t\tif \"kwargs\" in argument_keys:\n\t\t\treturn kwargs\n\n\t\treturn {key: kwargs[key] for key in argument_keys}\n\n\t@abstractmethod\n\tdef call(self, **kwargs) -&gt; ToolOutput:\n\t\tr\"\"\" Tool call \"\"\"\n\n\t@abstractmethod\n\tasync def acall(self, **kwargs) -&gt; ToolOutput:\n\t\tr\"\"\" Asynchronously tool call \"\"\"\n</code></pre>"},{"location":"code_docs/tools/base/tool_base/#labridge.tools.base.tool_base.CheckBaseTool.acall","title":"<code>labridge.tools.base.tool_base.CheckBaseTool.acall(**kwargs)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Asynchronously tool call</p> Source code in <code>labridge\\tools\\base\\tool_base.py</code> <pre><code>@abstractmethod\nasync def acall(self, **kwargs) -&gt; ToolOutput:\n\tr\"\"\" Asynchronously tool call \"\"\"\n</code></pre>"},{"location":"code_docs/tools/base/tool_base/#labridge.tools.base.tool_base.CheckBaseTool.call","title":"<code>labridge.tools.base.tool_base.CheckBaseTool.call(**kwargs)</code>  <code>abstractmethod</code>","text":"<p>Tool call</p> Source code in <code>labridge\\tools\\base\\tool_base.py</code> <pre><code>@abstractmethod\ndef call(self, **kwargs) -&gt; ToolOutput:\n\tr\"\"\" Tool call \"\"\"\n</code></pre>"},{"location":"code_docs/tools/base/tool_base/#labridge.tools.base.tool_base.QueryEngineBaseTool","title":"<code>labridge.tools.base.tool_base.QueryEngineBaseTool</code>","text":"<p>               Bases: <code>QueryEngineTool</code></p> Source code in <code>labridge\\tools\\base\\tool_base.py</code> <pre><code>class QueryEngineBaseTool(QueryEngineTool):\n\tdef __init__(\n\t\tself,\n\t\tquery_engine: BaseQueryEngine,\n\t\tname: str,\n\t\tdescription: str,\n\t\treturn_direct: bool = False,\n\t\tresolve_input_errors: bool = True,\n\t):\n\t\tmetadata = ToolMetadata(name=name, description=description, return_direct=return_direct)\n\t\tsuper().__init__(\n\t\t\tquery_engine=query_engine,\n\t\t\tmetadata=metadata,\n\t\t\tresolve_input_errors=resolve_input_errors,\n\t\t)\n\n\t@abstractmethod\n\tdef log(self) -&gt; ToolLog:\n\t\tr\"\"\" Return the ToolLog, describing the tool's operation. \"\"\"\n\n\tdef call(self, *args: Any, **kwargs: Any) -&gt; ToolOutput:\n\t\tquery_str = self._get_query_str(*args, **kwargs)\n\t\tresponse = self._query_engine.query(query_str)\n\t\ttool_log = self.log()\n\t\tresponse = pack_tool_output(tool_output=str(response), tool_log=tool_log.dumps())\n\t\treturn ToolOutput(\n\t\t\tcontent=response,\n\t\t\ttool_name=self.metadata.name,\n\t\t\traw_input={\"input\": query_str},\n\t\t\traw_output=response,\n\t\t)\n\n\tasync def acall(self, *args: Any, **kwargs: Any) -&gt; ToolOutput:\n\t\tquery_str = self._get_query_str(*args, **kwargs)\n\t\tresponse = await self._query_engine.aquery(query_str)\n\t\ttool_log = self.log()\n\t\tresponse = pack_tool_output(tool_output=str(response), tool_log=tool_log.dumps())\n\t\treturn ToolOutput(\n\t\t\tcontent=response,\n\t\t\ttool_name=self.metadata.name,\n\t\t\traw_input={\"input\": query_str},\n\t\t\traw_output=response,\n\t\t)\n</code></pre>"},{"location":"code_docs/tools/base/tool_base/#labridge.tools.base.tool_base.QueryEngineBaseTool.log","title":"<code>labridge.tools.base.tool_base.QueryEngineBaseTool.log()</code>  <code>abstractmethod</code>","text":"<p>Return the ToolLog, describing the tool's operation.</p> Source code in <code>labridge\\tools\\base\\tool_base.py</code> <pre><code>@abstractmethod\ndef log(self) -&gt; ToolLog:\n\tr\"\"\" Return the ToolLog, describing the tool's operation. \"\"\"\n</code></pre>"},{"location":"code_docs/tools/base/tool_base/#labridge.tools.base.tool_base.RetrieverBaseTool","title":"<code>labridge.tools.base.tool_base.RetrieverBaseTool</code>","text":"<p>               Bases: <code>CheckBaseTool</code></p> <p>This is the base of retrieving tools.</p> PARAMETER DESCRIPTION <code>name</code> <p>The tool name.</p> <p> TYPE: <code>str</code> </p> <code>retriever</code> <p>The retriever that retrieves in something.</p> <p> TYPE: <code>Any</code> </p> <code>retrieve_fn</code> <p>The retrieving function or method that will be called by the agent.</p> <p> TYPE: <code>Callable</code> </p> <code>description</code> <p>The tool description. If not specified, the tool description will be set as the docstring of the <code>retrieve_fn</code>.</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> Source code in <code>labridge\\tools\\base\\tool_base.py</code> <pre><code>class RetrieverBaseTool(CheckBaseTool):\n\tr\"\"\"\n\tThis is the base of retrieving tools.\n\n\tArgs:\n\t\tname (str): The tool name.\n\t\tretriever (Any): The retriever that retrieves in something.\n\t\tretrieve_fn (Callable): The retrieving function or method that will be called by the agent.\n\t\tdescription (Optional[str]): The tool description. If not specified, the tool description will be set as the\n\t\t\tdocstring of the `retrieve_fn`.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tname: str,\n\t\tretriever: Any,\n\t\tretrieve_fn: Callable,\n\t\tdescription: Optional[str] = None,\n\t):\n\t\tfn_schema = self._get_retriever_fn_schema(name=name, fn=retrieve_fn)\n\t\tdescription = description or self._retriever_fn_description_from_docstring(name=name, fn=retrieve_fn)\n\n\t\tself._retriever = retriever\n\t\tmetadata = ToolMetadata(\n\t\t\tname=name,\n\t\t\tdescription=description,\n\t\t\tfn_schema=fn_schema,\n\t\t)\n\t\tsuper().__init__(metadata=metadata)\n\n\tdef _get_retriever_fn_schema(self, name: str, fn: Callable) -&gt; Type[BaseModel]:\n\t\tr\"\"\" Get the fn_schema from the provided function or method. \"\"\"\n\t\tfn_schema = create_schema_from_fn_or_method(name=name, func=fn)\n\t\treturn fn_schema\n\n\tdef _retriever_fn_description_from_docstring(self, name: str, fn: Callable) -&gt; str:\n\t\tr\"\"\" Get the tool description from docstring of the function. \"\"\"\n\t\tdocstring = fn.__doc__\n\t\tdescription = f\"{name}{signature(fn)}\\n{docstring}\"\n\t\treturn description\n\n\t@abstractmethod\n\tdef log(self, log_dict: dict) -&gt; ToolLog:\n\t\tr\"\"\" Return the ToolLog with log string in a specific format. \"\"\"\n\n\t@abstractmethod\n\tdef _retrieve(self, retrieve_kwargs: dict) -&gt; List[NodeWithScore]:\n\t\tr\"\"\" Use the retriever to retrieve relevant nodes. \"\"\"\n\n\t@abstractmethod\n\tasync def _aretrieve(self, retrieve_kwargs: dict) -&gt; List[NodeWithScore]:\n\t\tr\"\"\" Asynchronously use the retriever to retrieve relevant nodes. \"\"\"\n\n\t@abstractmethod\n\tdef _nodes_to_tool_output(self, nodes: List[NodeWithScore]) -&gt; Tuple[str, dict]:\n\t\tr\"\"\" output the retrieved contents in a specific format, and the output log. \"\"\"\n\n\t@abstractmethod\n\tdef get_ref_info(self, nodes: List[NodeWithScore]) -&gt; List[RefInfoBase]:\n\t\tr\"\"\" Get the reference infos from the retrieved nodes. \"\"\"\n\n\t@property\n\tdef retriever(self) -&gt; BaseRetriever:\n\t\treturn self._retriever\n\n\t@property\n\tdef metadata(self) -&gt; ToolMetadata:\n\t\treturn self._metadata\n\n\tdef call(self, **kwargs: Any) -&gt; ToolOutput:\n\t\tr\"\"\"\n\t\tCall the retrieving function or method, and pack the output and logs.\n\n\t\tArgs:\n\t\t\t**kwargs: The keyword arguments will be provided by the agent.\n\n\t\tReturns:\n\t\t\tToolOutput: The tool output and logs.\n\n\t\t\"\"\"\n\t\tretrieve_kwargs = self._get_input(**kwargs)\n\t\tnodes = self._retrieve(retrieve_kwargs=retrieve_kwargs)\n\t\tretrieve_output, output_log_dict = self._nodes_to_tool_output(nodes=nodes)\n\t\toutput_log_dict.update(retrieve_kwargs)\n\t\ttool_log = self.log(log_dict=output_log_dict)\n\n\t\tcontent = pack_tool_output(tool_output=retrieve_output, tool_log=tool_log.dumps())\n\t\treturn ToolOutput(\n\t\t\tcontent=content,\n\t\t\ttool_name=self.metadata.name,\n\t\t\traw_input={\"input\": retrieve_kwargs},\n\t\t\traw_output=nodes,\n\t\t)\n\n\tasync def acall(self, **kwargs: Any) -&gt; ToolOutput:\n\t\tr\"\"\"\n\t\tAsynchronously call the retrieving function or method, and pack the output and logs.\n\n\t\tArgs:\n\t\t\t**kwargs: The keyword arguments will be provided by the agent.\n\n\t\tReturns:\n\t\t\tToolOutput: The tool output and logs.\n\n\t\t\"\"\"\n\t\tretrieve_kwargs = self._get_input(**kwargs)\n\t\tnodes = await self._aretrieve(retrieve_kwargs=retrieve_kwargs)\n\t\tretrieve_output, output_log_dict = self._nodes_to_tool_output(nodes=nodes)\n\t\toutput_log_dict.update(retrieve_kwargs)\n\t\ttool_log = self.log(log_dict=output_log_dict)\n\n\t\tcontent = pack_tool_output(tool_output=retrieve_output, tool_log=tool_log.dumps())\n\t\treturn ToolOutput(\n\t\t\tcontent=content,\n\t\t\ttool_name=self.metadata.name,\n\t\t\traw_input={\"input\": retrieve_kwargs},\n\t\t\traw_output=nodes,\n\t\t)\n</code></pre>"},{"location":"code_docs/tools/base/tool_base/#labridge.tools.base.tool_base.RetrieverBaseTool.acall","title":"<code>labridge.tools.base.tool_base.RetrieverBaseTool.acall(**kwargs)</code>  <code>async</code>","text":"<p>Asynchronously call the retrieving function or method, and pack the output and logs.</p> PARAMETER DESCRIPTION <code>**kwargs</code> <p>The keyword arguments will be provided by the agent.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>ToolOutput</code> <p>The tool output and logs.</p> <p> TYPE: <code>ToolOutput</code> </p> Source code in <code>labridge\\tools\\base\\tool_base.py</code> <pre><code>async def acall(self, **kwargs: Any) -&gt; ToolOutput:\n\tr\"\"\"\n\tAsynchronously call the retrieving function or method, and pack the output and logs.\n\n\tArgs:\n\t\t**kwargs: The keyword arguments will be provided by the agent.\n\n\tReturns:\n\t\tToolOutput: The tool output and logs.\n\n\t\"\"\"\n\tretrieve_kwargs = self._get_input(**kwargs)\n\tnodes = await self._aretrieve(retrieve_kwargs=retrieve_kwargs)\n\tretrieve_output, output_log_dict = self._nodes_to_tool_output(nodes=nodes)\n\toutput_log_dict.update(retrieve_kwargs)\n\ttool_log = self.log(log_dict=output_log_dict)\n\n\tcontent = pack_tool_output(tool_output=retrieve_output, tool_log=tool_log.dumps())\n\treturn ToolOutput(\n\t\tcontent=content,\n\t\ttool_name=self.metadata.name,\n\t\traw_input={\"input\": retrieve_kwargs},\n\t\traw_output=nodes,\n\t)\n</code></pre>"},{"location":"code_docs/tools/base/tool_base/#labridge.tools.base.tool_base.RetrieverBaseTool.call","title":"<code>labridge.tools.base.tool_base.RetrieverBaseTool.call(**kwargs)</code>","text":"<p>Call the retrieving function or method, and pack the output and logs.</p> PARAMETER DESCRIPTION <code>**kwargs</code> <p>The keyword arguments will be provided by the agent.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>ToolOutput</code> <p>The tool output and logs.</p> <p> TYPE: <code>ToolOutput</code> </p> Source code in <code>labridge\\tools\\base\\tool_base.py</code> <pre><code>def call(self, **kwargs: Any) -&gt; ToolOutput:\n\tr\"\"\"\n\tCall the retrieving function or method, and pack the output and logs.\n\n\tArgs:\n\t\t**kwargs: The keyword arguments will be provided by the agent.\n\n\tReturns:\n\t\tToolOutput: The tool output and logs.\n\n\t\"\"\"\n\tretrieve_kwargs = self._get_input(**kwargs)\n\tnodes = self._retrieve(retrieve_kwargs=retrieve_kwargs)\n\tretrieve_output, output_log_dict = self._nodes_to_tool_output(nodes=nodes)\n\toutput_log_dict.update(retrieve_kwargs)\n\ttool_log = self.log(log_dict=output_log_dict)\n\n\tcontent = pack_tool_output(tool_output=retrieve_output, tool_log=tool_log.dumps())\n\treturn ToolOutput(\n\t\tcontent=content,\n\t\ttool_name=self.metadata.name,\n\t\traw_input={\"input\": retrieve_kwargs},\n\t\traw_output=nodes,\n\t)\n</code></pre>"},{"location":"code_docs/tools/base/tool_base/#labridge.tools.base.tool_base.RetrieverBaseTool.get_ref_info","title":"<code>labridge.tools.base.tool_base.RetrieverBaseTool.get_ref_info(nodes)</code>  <code>abstractmethod</code>","text":"<p>Get the reference infos from the retrieved nodes.</p> Source code in <code>labridge\\tools\\base\\tool_base.py</code> <pre><code>@abstractmethod\ndef get_ref_info(self, nodes: List[NodeWithScore]) -&gt; List[RefInfoBase]:\n\tr\"\"\" Get the reference infos from the retrieved nodes. \"\"\"\n</code></pre>"},{"location":"code_docs/tools/base/tool_base/#labridge.tools.base.tool_base.RetrieverBaseTool.log","title":"<code>labridge.tools.base.tool_base.RetrieverBaseTool.log(log_dict)</code>  <code>abstractmethod</code>","text":"<p>Return the ToolLog with log string in a specific format.</p> Source code in <code>labridge\\tools\\base\\tool_base.py</code> <pre><code>@abstractmethod\ndef log(self, log_dict: dict) -&gt; ToolLog:\n\tr\"\"\" Return the ToolLog with log string in a specific format. \"\"\"\n</code></pre>"},{"location":"code_docs/tools/base/tool_log/","title":"Tool log","text":""},{"location":"code_docs/tools/base/tool_log/#labridge.tools.base.tool_log","title":"<code>labridge.tools.base.tool_log</code>","text":""},{"location":"code_docs/tools/base/tool_log/#labridge.tools.base.tool_log.ToolLog","title":"<code>labridge.tools.base.tool_log.ToolLog</code>","text":"<p>               Bases: <code>object</code></p> <p>This class record the log of a specific tool. The <code>log_to_user</code> and <code>references</code> in <code>log_to_system</code> will be presented to the users.</p> PARAMETER DESCRIPTION <code>tool_name</code> <p>The tool name.</p> <p> TYPE: <code>str</code> </p> <code>log_to_user</code> <p>This log might be presented to the users.</p> <p> TYPE: <code>str</code> </p> <code>log_to_system</code> <p>This log is more structured, specifically, it is a dictionary in JSON format. The keys 'operation_description' and 'references' are required. The values of <code>references</code> are either None or List[str], where the <code>str</code> is in JSON format.</p> <p> TYPE: <code>dict</code> </p> Source code in <code>labridge\\tools\\base\\tool_log.py</code> <pre><code>class ToolLog(object):\n\tr\"\"\"\n\tThis class record the log of a specific tool.\n\tThe `log_to_user` and `references` in `log_to_system` will be presented to the users.\n\n\tArgs:\n\t\ttool_name (str): The tool name.\n\t\tlog_to_user (str): This log might be presented to the users.\n\t\tlog_to_system (dict): This log is more structured, specifically, it is a dictionary in JSON format.\n\t\t\tThe keys 'operation_description' and 'references' are required. The values of `references` are either\n\t\t\tNone or List[str], where the `str` is in JSON format.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\ttool_name: str,\n\t\tlog_to_user: Optional[str],\n\t\tlog_to_system: Dict[str, Union[str, Optional[List[str]]]],\n\t\ttool_abort: Optional[bool] = False,\n\t):\n\t\tself.tool_name = tool_name\n\t\tself.log_to_user = log_to_user\n\t\tself.tool_abort = tool_abort\n\n\t\tfor key in LOG_TO_SYSTEM_KEYS:\n\t\t\tif key not in log_to_system.keys():\n\t\t\t\traise ValueError(f\"The key {key} is required in the log_to_system.\")\n\n\t\tref = log_to_system[TOOL_REFERENCES]\n\t\tif ref and not isinstance(ref, list):\n\t\t\traise ValueError(f\"The value of '{TOOL_REFERENCES}' can only be list or None.\")\n\t\tself.log_to_system = log_to_system\n\n\t@classmethod\n\tdef construct(\n\t\tcls,\n\t\ttool_name: str,\n\t\ttool_op_description: str,\n\t\ttool_references: Optional[List[str]] = None,\n\t\tlog_to_user: str = None,\n\t\ttool_abort: Optional[bool] = False,\n\t):\n\t\treturn cls(\n\t\t\ttool_name=tool_name,\n\t\t\tlog_to_user=log_to_user,\n\t\t\tlog_to_system={\n\t\t\t\tTOOL_OP_DESCRIPTION: tool_op_description,\n\t\t\t\tTOOL_REFERENCES: tool_references,\n\t\t\t},\n\t\t\ttool_abort=tool_abort,\n\t\t)\n\n\tdef dumps(self) -&gt; str:\n\t\tr\"\"\"\n\t\tDump to a string.\n\n\t\tReturns:\n\t\t\tstr: the dumped string.\n\t\t\"\"\"\n\t\tlogs = {\n\t\t\t\"tool_name\": self.tool_name,\n\t\t\t\"log_to_user\": self.log_to_user,\n\t\t\t\"log_to_system\": self.log_to_system,\n\t\t\t\"tool_abort\": self.tool_abort,\n\t\t}\n\t\treturn json.dumps(logs)\n\n\t@classmethod\n\tdef loads(\n\t\tcls,\n\t\tlog_str: str,\n\t):\n\t\tr\"\"\"\n\t\tLoad from a string.\n\n\t\tArgs:\n\t\t\tlog_str (str): The dumped string of a ToolLog object.\n\n\t\tReturns:\n\t\t\tThe loaded ToolLog object.\n\t\t\"\"\"\n\t\ttry:\n\t\t\tlogs = json.loads(log_str)\n\t\t\ttool_name = logs[\"tool_name\"]\n\t\t\tlog_to_user = logs[\"log_to_user\"]\n\t\t\tlog_to_system = logs[\"log_to_system\"]\n\t\t\ttool_abort = logs[\"tool_abort\"]\n\t\t\treturn cls(\n\t\t\t\ttool_name=tool_name,\n\t\t\t\tlog_to_user=log_to_user,\n\t\t\t\tlog_to_system=log_to_system,\n\t\t\t\ttool_abort=tool_abort,\n\t\t\t)\n\t\texcept Exception:\n\t\t\traise ValueError(\"Invalid tool log string.\")\n</code></pre>"},{"location":"code_docs/tools/base/tool_log/#labridge.tools.base.tool_log.ToolLog.dumps","title":"<code>labridge.tools.base.tool_log.ToolLog.dumps()</code>","text":"<p>Dump to a string.</p> RETURNS DESCRIPTION <code>str</code> <p>the dumped string.</p> <p> TYPE: <code>str</code> </p> Source code in <code>labridge\\tools\\base\\tool_log.py</code> <pre><code>def dumps(self) -&gt; str:\n\tr\"\"\"\n\tDump to a string.\n\n\tReturns:\n\t\tstr: the dumped string.\n\t\"\"\"\n\tlogs = {\n\t\t\"tool_name\": self.tool_name,\n\t\t\"log_to_user\": self.log_to_user,\n\t\t\"log_to_system\": self.log_to_system,\n\t\t\"tool_abort\": self.tool_abort,\n\t}\n\treturn json.dumps(logs)\n</code></pre>"},{"location":"code_docs/tools/base/tool_log/#labridge.tools.base.tool_log.ToolLog.loads","title":"<code>labridge.tools.base.tool_log.ToolLog.loads(log_str)</code>  <code>classmethod</code>","text":"<p>Load from a string.</p> PARAMETER DESCRIPTION <code>log_str</code> <p>The dumped string of a ToolLog object.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <p>The loaded ToolLog object.</p> Source code in <code>labridge\\tools\\base\\tool_log.py</code> <pre><code>@classmethod\ndef loads(\n\tcls,\n\tlog_str: str,\n):\n\tr\"\"\"\n\tLoad from a string.\n\n\tArgs:\n\t\tlog_str (str): The dumped string of a ToolLog object.\n\n\tReturns:\n\t\tThe loaded ToolLog object.\n\t\"\"\"\n\ttry:\n\t\tlogs = json.loads(log_str)\n\t\ttool_name = logs[\"tool_name\"]\n\t\tlog_to_user = logs[\"log_to_user\"]\n\t\tlog_to_system = logs[\"log_to_system\"]\n\t\ttool_abort = logs[\"tool_abort\"]\n\t\treturn cls(\n\t\t\ttool_name=tool_name,\n\t\t\tlog_to_user=log_to_user,\n\t\t\tlog_to_system=log_to_system,\n\t\t\ttool_abort=tool_abort,\n\t\t)\n\texcept Exception:\n\t\traise ValueError(\"Invalid tool log string.\")\n</code></pre>"},{"location":"code_docs/tools/common/date_time/","title":"Date time","text":""},{"location":"code_docs/tools/common/date_time/#labridge.tools.common.date_time","title":"<code>labridge.tools.common.date_time</code>","text":""},{"location":"code_docs/tools/common/date_time/#labridge.tools.common.date_time.get_current_date_time","title":"<code>labridge.tools.common.date_time.get_current_date_time()</code>","text":"<p>This function is used to get the date of today, current time. If you are not sure about current date or time, use this tool to help you.</p> <p>The returned date is of the following format: \"Year-Month-Day\". The returned time is of the following format: \"Hour:Minute:Time\".</p> Source code in <code>labridge\\tools\\common\\date_time.py</code> <pre><code>def get_current_date_time() -&gt; FuncOutputWithLog:\n\tr\"\"\"\n\tThis function is used to get the date of today, current time.\n\tIf you are not sure about current date or time, use this tool to help you.\n\n\tThe returned date is of the following format: \"Year-Month-Day\".\n\tThe returned time is of the following format: \"Hour:Minute:Time\".\n\t\"\"\"\n\ttoday = datetime.datetime.today()\n\tcurrent_date = today.date().strftime(DATE_FORMAT)\n\tcurrent_time = today.time().strftime(TIME_FORMAT)\n\tcurrent_weekday = today.weekday() + 1\n\n\tdatetime_str = (\n\t\tf\"Today is {current_date}\\n\"\n\t\tf\"Today is the No.{current_weekday} day in a week.\\n\"\n\t\tf\"Current time is {current_time}\\n\"\n\t)\n\treturn FuncOutputWithLog(\n\t\tfn_output=datetime_str,\n\t\tfn_log=\"\",\n\t)\n</code></pre>"},{"location":"code_docs/tools/common/date_time/#labridge.tools.common.date_time.get_date_time_from_now","title":"<code>labridge.tools.common.date_time.get_date_time_from_now(backward, days)</code>","text":"<p>This function is used to infer the exact date that a statement means. such as '3 days ago', '2 months later'.</p> PARAMETER DESCRIPTION <code>backward</code> <p>the direction, if the statement means the date earlier than now, it is set to <code>True</code>. Otherwise, it is <code>False</code>.</p> <p> TYPE: <code>bool</code> </p> <code>days</code> <p>the number of days</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>FuncOutputWithLog</code> <p>the result date.</p> Source code in <code>labridge\\tools\\common\\date_time.py</code> <pre><code>def get_date_time_from_now(backward: bool, days: int) -&gt; FuncOutputWithLog:\n\tr\"\"\"\n\tThis function is used to infer the exact date that a statement means. such as '3 days ago', '2 months later'.\n\n\tArgs:\n\t\tbackward (bool): the direction, if the statement means the date earlier than now, it is set to `True`.\n\t\t\tOtherwise, it is `False`.\n\t\tdays (int): the number of days\n\n\tReturns:\n\t\tthe result date.\n\t\"\"\"\n\ttoday = datetime.datetime.today()\n\tif backward:\n\t\tresult_datetime = today - datetime.timedelta(days=days)\n\telse:\n\t\tresult_datetime = today + datetime.timedelta(days=days)\n\n\tresult_date = result_datetime.date().strftime(DATE_FORMAT)\n\tresult_weekday = result_datetime.weekday() + 1\n\tdirection_str = \"ago\" if backward else \"later\"\n\tdatetime_str = (\n\t\tf\"{days} days {direction_str} is {result_date}\\n\"\n\t\tf\"the No.{result_weekday} day in a week.\\n\"\n\t)\n\treturn FuncOutputWithLog(\n\t\tfn_output=datetime_str,\n\t\tfn_log=\"\",\n\t)\n</code></pre>"},{"location":"code_docs/tools/instrument/retrieve/","title":"Retrieve","text":""},{"location":"code_docs/tools/instrument/retrieve/#labridge.tools.instrument.retrieve","title":"<code>labridge.tools.instrument.retrieve</code>","text":""},{"location":"code_docs/tools/instrument/retrieve/#labridge.tools.instrument.retrieve.InstrumentRetrieverTool","title":"<code>labridge.tools.instrument.retrieve.InstrumentRetrieverTool</code>","text":"<p>               Bases: <code>RetrieverBaseTool</code></p> Source code in <code>labridge\\tools\\instrument\\retrieve.py</code> <pre><code>class InstrumentRetrieverTool(RetrieverBaseTool):\n\tdef __init__(\n\t\tself,\n\t\tllm: LLM = None,\n\t\tembed_model: BaseEmbedding = None,\n\t\tmetadata_mode: MetadataMode = MetadataMode.NONE,\n\t):\n\t\tinstrument_retriever = InstrumentRetriever(\n\t\t\tllm=llm,\n\t\t\tembed_model=embed_model,\n\t\t)\n\t\tself.metadata_mode = metadata_mode\n\t\tself.super_user_manager = InstrumentSuperUserManager()\n\t\tsuper().__init__(\n\t\t\tretriever=instrument_retriever,\n\t\t\tname=InstrumentRetrieverTool.__name__,\n\t\t\tretrieve_fn=InstrumentRetriever.retrieve\n\t\t)\n\n\tdef log(self, log_dict: dict) -&gt; ToolLog:\n\t\tref_infos: List[InstrumentInfo] = log_dict[TOOL_LOG_REF_INFO_KEY]\n\t\tinstrument_infos = [info.dumps() for info in ref_infos]\n\n\t\tlog_to_user = None\n\t\tlog_to_system = {\n\t\t\tTOOL_OP_DESCRIPTION: f\"Use the {self.metadata.name} to retrieve the instrument docs.\",\n\t\t\tTOOL_REFERENCES: instrument_infos,\n\t\t}\n\n\t\treturn ToolLog(\n\t\t\ttool_name=self.metadata.name,\n\t\t\tlog_to_user=log_to_user,\n\t\t\tlog_to_system=log_to_system,\n\t\t)\n\n\tdef _retrieve(self, retrieve_kwargs: dict) -&gt; List[NodeWithScore]:\n\t\tnodes = self._retriever.retrieve(**retrieve_kwargs)\n\t\treturn nodes\n\n\tasync def _aretrieve(self, retrieve_kwargs: dict) -&gt; List[NodeWithScore]:\n\t\tnodes = await self._retriever.aretrieve(**retrieve_kwargs)\n\t\treturn nodes\n\n\tdef get_ref_info(self, nodes: List[NodeWithScore]) -&gt; List[RefInfoBase]:\n\t\tr\"\"\" Get the reference infos from the retrieved nodes. \"\"\"\n\t\tinstrument_infos = []\n\t\tinstrument_set = set()\n\t\tfor node in nodes:\n\t\t\tinstrument_id = node.metadata.get(INSTRUMENT_NAME_KEY, node.node_id)\n\t\t\t# TODO: Add node type and filter.\n\t\t\tif instrument_id == INSTRUMENT_ROOT_NODE_NAME or instrument_id in instrument_set:\n\t\t\t\tcontinue\n\t\t\tinstrument_set.add(instrument_id)\n\t\t\tsuper_users = self.super_user_manager.get_super_users(\n\t\t\t\tinstrument_id=instrument_id,\n\t\t\t)\n\t\t\tinfo = InstrumentInfo(\n\t\t\t\tinstrument_id=instrument_id,\n\t\t\t\tsuper_users=super_users,\n\t\t\t)\n\t\t\tinstrument_infos.append(info)\n\t\treturn instrument_infos\n\n\tdef _nodes_to_tool_output(self, nodes: List[NodeWithScore]) -&gt; Tuple[str, dict]:\n\t\tr\"\"\" output the retrieved contents in a specific format. \"\"\"\n\t\toutput = \"\"\n\t\theader = f\"Have retrieved the docs of several relevant instruments:\\n\\n\"\n\t\toutput += header\n\n\t\tif len(nodes) &lt; 1:\n\t\t\toutput += \"No relevant instrument contents found.\"\n\n\t\tref_infos = self.get_ref_info(nodes=nodes)\n\t\tlog_dict = {\n\t\t\tTOOL_LOG_REF_INFO_KEY: ref_infos,\n\t\t}\n\n\t\tinstrument_docs = dict()\n\t\tfor node in nodes:\n\t\t\tinstrument_id = node.metadata.get(INSTRUMENT_NAME_KEY, node.node_id)\n\t\t\t# TODO: Add node type and filter.\n\t\t\tif instrument_id == INSTRUMENT_ROOT_NODE_NAME:\n\t\t\t\tcontinue\n\t\t\tif instrument_id not in instrument_docs:\n\t\t\t\tinstrument_docs[instrument_id] = []\n\t\t\tinstrument_docs[instrument_id].append(node)\n\n\t\tfor instrument_id in instrument_docs.keys():\n\t\t\tinstrument_content = f\"Instrument Name: {instrument_id}\\n\"\n\t\t\tfor idx, node in enumerate(instrument_docs[instrument_id]):\n\t\t\t\tinstrument_content += (\n\t\t\t\t\tf\"Retrieved content {idx + 1}:\\n\"\n\t\t\t\t\tf\"{node.node.get_content(metadata_mode=self.metadata_mode)}\\n\"\n\t\t\t)\n\t\t\toutput += f\"{instrument_content}\\n\"\n\t\treturn output, log_dict\n</code></pre>"},{"location":"code_docs/tools/instrument/retrieve/#labridge.tools.instrument.retrieve.InstrumentRetrieverTool.get_ref_info","title":"<code>labridge.tools.instrument.retrieve.InstrumentRetrieverTool.get_ref_info(nodes)</code>","text":"<p>Get the reference infos from the retrieved nodes.</p> Source code in <code>labridge\\tools\\instrument\\retrieve.py</code> <pre><code>def get_ref_info(self, nodes: List[NodeWithScore]) -&gt; List[RefInfoBase]:\n\tr\"\"\" Get the reference infos from the retrieved nodes. \"\"\"\n\tinstrument_infos = []\n\tinstrument_set = set()\n\tfor node in nodes:\n\t\tinstrument_id = node.metadata.get(INSTRUMENT_NAME_KEY, node.node_id)\n\t\t# TODO: Add node type and filter.\n\t\tif instrument_id == INSTRUMENT_ROOT_NODE_NAME or instrument_id in instrument_set:\n\t\t\tcontinue\n\t\tinstrument_set.add(instrument_id)\n\t\tsuper_users = self.super_user_manager.get_super_users(\n\t\t\tinstrument_id=instrument_id,\n\t\t)\n\t\tinfo = InstrumentInfo(\n\t\t\tinstrument_id=instrument_id,\n\t\t\tsuper_users=super_users,\n\t\t)\n\t\tinstrument_infos.append(info)\n\treturn instrument_infos\n</code></pre>"},{"location":"code_docs/tools/interact/collect_and_authorize/","title":"Collect and authorize","text":""},{"location":"code_docs/tools/interact/collect_and_authorize/#labridge.tools.interact.collect_and_authorize","title":"<code>labridge.tools.interact.collect_and_authorize</code>","text":""},{"location":"code_docs/tools/interact/collect_and_authorize/#labridge.tools.interact.collect_and_authorize.CollectAndAuthorizeTool","title":"<code>labridge.tools.interact.collect_and_authorize.CollectAndAuthorizeTool</code>","text":"<p>               Bases: <code>CallBackBaseTool</code></p> <p>This tool is the template for tools whose process involves information collection from users and the getting final operation authorization from the user.</p> PARAMETER DESCRIPTION <code>tool_fn</code> <p>The function that executes the entire process of a specific tool.</p> <p> TYPE: <code>Callable</code> </p> <code>tool_async_fn</code> <p>The function that asynchronously executes the entire process of a specific tool.</p> <p> TYPE: <code>Callable</code> </p> <code>callback_operation</code> <p>The operation that needs the user's authorization.</p> <p> TYPE: <code>CallBackOperationBase</code> </p> <code>tool_name</code> <p>The tool name, recommend the name of the specified tool class.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>llm</code> <p>The used large language model.</p> <p> TYPE: <code>LLM</code> DEFAULT: <code>None</code> </p> <code>embed_model</code> <p>The used embedding model.</p> <p> TYPE: <code>BaseEmbedding</code> DEFAULT: <code>None</code> </p> <code>verbose</code> <p>Whether to show the inner progress.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> Source code in <code>labridge\\tools\\interact\\collect_and_authorize.py</code> <pre><code>class CollectAndAuthorizeTool(CallBackBaseTool):\n\tr\"\"\"\n\tThis tool is the template for tools whose process involves information collection from users\n\tand the getting final operation authorization from the user.\n\n\tArgs:\n\t\ttool_fn (Callable): The function that executes the entire process of a specific tool.\n\t\ttool_async_fn (Callable): The function that asynchronously executes the entire process of a specific tool.\n\t\tcallback_operation (CallBackOperationBase): The operation that needs the user's authorization.\n\t\ttool_name (str): The tool name, recommend the name of the specified tool class.\n\t\tllm (LLM): The used large language model.\n\t\tembed_model (BaseEmbedding): The used embedding model.\n\t\tverbose (bool): Whether to show the inner progress.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\ttool_fn: Callable[..., Any],\n\t\ttool_async_fn: Callable[..., Any],\n\t\tcallback_operation: CallBackOperationBase,\n\t\ttool_name: str = None,\n\t\tllm: LLM = None,\n\t\tembed_model: BaseEmbedding = None,\n\t\tverbose: bool = False,\n\t):\n\t\tself._llm = llm or Settings.llm\n\t\tself._embed_model = embed_model or Settings.embed_model\n\t\tself._verbose = verbose\n\t\tsuper().__init__(\n\t\t\tfn=tool_fn,\n\t\t\tasync_fn=tool_async_fn,\n\t\t\ttool_name=tool_name,\n\t\t\tcallback_operation=callback_operation,\n\t\t)\n\n\t@abstractmethod\n\tdef required_infos(self) -&gt; List[CollectingInfoBase]:\n\t\tr\"\"\" The required infos. \"\"\"\n\n\n\t@abstractmethod\n\tdef required_info_dict(self) -&gt; Dict[str, str]:\n\t\tr\"\"\" The required info names and their descriptions \"\"\"\n\n\tdef log(self, **kwargs: Any) -&gt; ToolLog:\n\t\tr\"\"\"\n\t\tRecord the tool's logs.\n\n\t\tArgs:\n\t\t\t**kwargs: The input keyword arguments and the (output, log) of the callback operation.\n\n\t\tReturns:\n\t\t\ttool_log (ToolLog): The tool logs, including tool_to_user and tool_to_system.\n\t\t\"\"\"\n\t\tuser_id = kwargs[\"user_id\"]\n\t\tcollected_info = \",\".join(list(self.required_info_dict().keys()))\n\t\tlog_to_system_str = (\n\t\t\tf\"Have collected these information from the user {user_id}:\\n\"\n\t\t\tf\"{collected_info}\\n\"\n\t\t\tf\"Then try to do the following operation.\\n\"\n\t\t)\n\n\t\top_log: OperationOutputLog = kwargs[\"operation_log\"]\n\t\tif not isinstance(op_log, OperationOutputLog):\n\t\t\traise ValueError(\"The operation_log must be 'OperationOutputLog'.\")\n\n\t\tlog_to_system_str += op_log.log_to_system[OP_DESCRIPTION]\n\n\t\tlog_to_user = op_log.log_to_user\n\t\tlog_to_system = {\n\t\t\tTOOL_OP_DESCRIPTION: log_to_system_str,\n\t\t\tTOOL_REFERENCES: op_log.log_to_system[OP_REFERENCES],\n\t\t}\n\n\t\ttool_log = ToolLog(\n\t\t\ttool_name=self.metadata.name,\n\t\t\tlog_to_user=log_to_user,\n\t\t\tlog_to_system=log_to_system,\n\t\t\ttool_abort=op_log.operation_abort,\n\t\t)\n\t\treturn tool_log\n\n\tdef collect_and_authorize(\n\t\tself,\n\t\tuser_id: str,\n\t\tquery_str: str,\n\t) -&gt; FuncOutputWithLog:\n\t\tr\"\"\"\n\t\tThis Method is a template method can be reused in subclass to reduce code redundancy.\n\n\t\tFirstly, this method will collect the required infos from the user.\n\t\tThen, the agent will generate the operation description according to the collected information.\n\t\tFinally, the agent will ask for the user's authorization to execute the operation.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user_id of a lab member.\n\t\t\tquery_str (str): The query from the user.\n\n\t\tReturns:\n\t\t\toutput_log (FuncOutputWithLog):\n\t\t\t\tincluding the output of the callback operation and the tool's log.\n\t\t\"\"\"\n\t\tinfo_dict = collect_info_from_user(\n\t\t\tuser_id=user_id,\n\t\t\trequired_infos=self.required_infos(),\n\t\t\tquery_str=query_str,\n\t\t)\n\n\t\tif info_dict is None:\n\t\t\top_name = self._callback_operation.__name__\n\t\t\toperation_log_str = (\n\t\t\t\tf\"The user {user_id} aborts this operation {op_name}.\"\n\t\t\t)\n\t\t\toperation_log = OperationOutputLog(\n\t\t\t\toperation_name=op_name,\n\t\t\t\toperation_output=None,\n\t\t\t\tlog_to_user=None,\n\t\t\t\tlog_to_system={\n\t\t\t\t\tOP_DESCRIPTION: operation_log_str,\n\t\t\t\t\tOP_REFERENCES: None,\n\t\t\t\t},\n\t\t\t\toperation_abort=True,\n\t\t\t)\n\t\t\tlog_dict = {\"operation_log\": operation_log}\n\n\t\t\treturn FuncOutputWithLog(\n\t\t\t\tfn_output=f\"The user {user_id} abort the collecting process in the operation {op_name}\",\n\t\t\t\tfn_log=log_dict,\n\t\t\t)\n\n\t\top_name = self._callback_operation.__name__\n\t\tkwargs = {\"user_id\": user_id, }\n\t\tfor key in self.required_info_dict().keys():\n\t\t\tkwargs[key] = info_dict[key]\n\t\tkwargs_str = json.dumps(kwargs)\n\t\toperation_log = operation_authorize(\n\t\t\tuser_id=user_id,\n\t\t\top_name=op_name,\n\t\t\tkwargs_str=kwargs_str,\n\t\t\tllm=self._llm,\n\t\t\tembed_model=self._embed_model,\n\t\t\tverbose=self._verbose,\n\t\t)\n\t\tlog = {\"operation_log\": operation_log}\n\t\tfn_output = f\"Have done the operation {op_name} with the agreement of the user {user_id}.\"\n\t\tif operation_log.operation_output is not None:\n\t\t\tfn_output += f\"\\nOperation output:\\n{operation_log.operation_output}\"\n\t\treturn FuncOutputWithLog(\n\t\t\tfn_output=fn_output,\n\t\t\tfn_log=log,\n\t\t)\n\n\tasync def acollect_and_authorize(\n\t\tself,\n\t\tuser_id: str,\n\t\tquery_str: str,\n\t) -&gt; FuncOutputWithLog:\n\t\tr\"\"\"\n\t\tThis Method is an asynchronous version template method can be reused in subclass to reduce code redundancy.\n\n\t\tFirstly, this method will collect the required infos from the user.\n\t\tThen, the agent will generate the operation description according to the collected information.\n\t\tFinally, the agent will ask for the user's authorization to execute the operation.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user_id of a lab member.\n\t\t\tquery_str (str): The query from the user.\n\n\t\tReturns:\n\t\t\toutput_log (FuncOutputWithLog):\n\t\t\t\tincluding the output of the callback operation and the tool's log.\n\t\t\"\"\"\n\t\tinfo_dict = await acollect_info_from_user(\n\t\t\tuser_id=user_id,\n\t\t\trequired_infos=self.required_infos(),\n\t\t\tquery_str=query_str,\n\t\t)\n\n\t\top_name = self._callback_operation.__name__\n\t\tif info_dict is None:\n\t\t\toperation_log_str = (\n\t\t\t\tf\"The user {user_id} abort this operation.\"\n\t\t\t)\n\t\t\toperation_log = OperationOutputLog(\n\t\t\t\toperation_name=self._callback_operation.__name__,\n\t\t\t\toperation_output=None,\n\t\t\t\tlog_to_user=None,\n\t\t\t\tlog_to_system={\n\t\t\t\t\tOP_DESCRIPTION: operation_log_str,\n\t\t\t\t\tOP_REFERENCES: None,\n\t\t\t\t},\n\t\t\t\toperation_abort=True,\n\t\t\t)\n\t\t\tlog_dict = {\"operation_log\": operation_log}\n\t\t\treturn FuncOutputWithLog(\n\t\t\t\tfn_output=f\"The user {user_id} abort the collecting process in the operation {op_name}\",\n\t\t\t\tfn_log=log_dict,\n\t\t\t)\n\n\t\tkwargs = {\"user_id\": user_id, }\n\t\tfor key in self.required_info_dict().keys():\n\t\t\tkwargs[key] = info_dict[key]\n\t\tkwargs_str = json.dumps(kwargs)\n\t\toperation_log = await aoperation_authorize(\n\t\t\tuser_id=user_id,\n\t\t\top_name=op_name,\n\t\t\tkwargs_str=kwargs_str,\n\t\t\tllm=self._llm,\n\t\t\tembed_model=self._embed_model,\n\t\t\tverbose=self._verbose,\n\t\t)\n\t\tprint(\"Here: after refuse: \", operation_log)\n\t\tlog_dict = {\"operation_log\": operation_log}\n\t\tfn_output = f\"Have done the operation {op_name} with the agreement of the user {user_id}.\"\n\t\tif operation_log.operation_output is not None:\n\t\t\tfn_output += f\"\\nOperation output:\\n{operation_log.operation_output}\"\n\t\treturn FuncOutputWithLog(\n\t\t\tfn_output=fn_output,\n\t\t\tfn_log=log_dict,\n\t\t)\n</code></pre>"},{"location":"code_docs/tools/interact/collect_and_authorize/#labridge.tools.interact.collect_and_authorize.CollectAndAuthorizeTool.acollect_and_authorize","title":"<code>labridge.tools.interact.collect_and_authorize.CollectAndAuthorizeTool.acollect_and_authorize(user_id, query_str)</code>  <code>async</code>","text":"<p>This Method is an asynchronous version template method can be reused in subclass to reduce code redundancy.</p> <p>Firstly, this method will collect the required infos from the user. Then, the agent will generate the operation description according to the collected information. Finally, the agent will ask for the user's authorization to execute the operation.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user_id of a lab member.</p> <p> TYPE: <code>str</code> </p> <code>query_str</code> <p>The query from the user.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>output_log</code> <p>including the output of the callback operation and the tool's log.</p> <p> TYPE: <code>FuncOutputWithLog</code> </p> Source code in <code>labridge\\tools\\interact\\collect_and_authorize.py</code> <pre><code>async def acollect_and_authorize(\n\tself,\n\tuser_id: str,\n\tquery_str: str,\n) -&gt; FuncOutputWithLog:\n\tr\"\"\"\n\tThis Method is an asynchronous version template method can be reused in subclass to reduce code redundancy.\n\n\tFirstly, this method will collect the required infos from the user.\n\tThen, the agent will generate the operation description according to the collected information.\n\tFinally, the agent will ask for the user's authorization to execute the operation.\n\n\tArgs:\n\t\tuser_id (str): The user_id of a lab member.\n\t\tquery_str (str): The query from the user.\n\n\tReturns:\n\t\toutput_log (FuncOutputWithLog):\n\t\t\tincluding the output of the callback operation and the tool's log.\n\t\"\"\"\n\tinfo_dict = await acollect_info_from_user(\n\t\tuser_id=user_id,\n\t\trequired_infos=self.required_infos(),\n\t\tquery_str=query_str,\n\t)\n\n\top_name = self._callback_operation.__name__\n\tif info_dict is None:\n\t\toperation_log_str = (\n\t\t\tf\"The user {user_id} abort this operation.\"\n\t\t)\n\t\toperation_log = OperationOutputLog(\n\t\t\toperation_name=self._callback_operation.__name__,\n\t\t\toperation_output=None,\n\t\t\tlog_to_user=None,\n\t\t\tlog_to_system={\n\t\t\t\tOP_DESCRIPTION: operation_log_str,\n\t\t\t\tOP_REFERENCES: None,\n\t\t\t},\n\t\t\toperation_abort=True,\n\t\t)\n\t\tlog_dict = {\"operation_log\": operation_log}\n\t\treturn FuncOutputWithLog(\n\t\t\tfn_output=f\"The user {user_id} abort the collecting process in the operation {op_name}\",\n\t\t\tfn_log=log_dict,\n\t\t)\n\n\tkwargs = {\"user_id\": user_id, }\n\tfor key in self.required_info_dict().keys():\n\t\tkwargs[key] = info_dict[key]\n\tkwargs_str = json.dumps(kwargs)\n\toperation_log = await aoperation_authorize(\n\t\tuser_id=user_id,\n\t\top_name=op_name,\n\t\tkwargs_str=kwargs_str,\n\t\tllm=self._llm,\n\t\tembed_model=self._embed_model,\n\t\tverbose=self._verbose,\n\t)\n\tprint(\"Here: after refuse: \", operation_log)\n\tlog_dict = {\"operation_log\": operation_log}\n\tfn_output = f\"Have done the operation {op_name} with the agreement of the user {user_id}.\"\n\tif operation_log.operation_output is not None:\n\t\tfn_output += f\"\\nOperation output:\\n{operation_log.operation_output}\"\n\treturn FuncOutputWithLog(\n\t\tfn_output=fn_output,\n\t\tfn_log=log_dict,\n\t)\n</code></pre>"},{"location":"code_docs/tools/interact/collect_and_authorize/#labridge.tools.interact.collect_and_authorize.CollectAndAuthorizeTool.collect_and_authorize","title":"<code>labridge.tools.interact.collect_and_authorize.CollectAndAuthorizeTool.collect_and_authorize(user_id, query_str)</code>","text":"<p>This Method is a template method can be reused in subclass to reduce code redundancy.</p> <p>Firstly, this method will collect the required infos from the user. Then, the agent will generate the operation description according to the collected information. Finally, the agent will ask for the user's authorization to execute the operation.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user_id of a lab member.</p> <p> TYPE: <code>str</code> </p> <code>query_str</code> <p>The query from the user.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>output_log</code> <p>including the output of the callback operation and the tool's log.</p> <p> TYPE: <code>FuncOutputWithLog</code> </p> Source code in <code>labridge\\tools\\interact\\collect_and_authorize.py</code> <pre><code>def collect_and_authorize(\n\tself,\n\tuser_id: str,\n\tquery_str: str,\n) -&gt; FuncOutputWithLog:\n\tr\"\"\"\n\tThis Method is a template method can be reused in subclass to reduce code redundancy.\n\n\tFirstly, this method will collect the required infos from the user.\n\tThen, the agent will generate the operation description according to the collected information.\n\tFinally, the agent will ask for the user's authorization to execute the operation.\n\n\tArgs:\n\t\tuser_id (str): The user_id of a lab member.\n\t\tquery_str (str): The query from the user.\n\n\tReturns:\n\t\toutput_log (FuncOutputWithLog):\n\t\t\tincluding the output of the callback operation and the tool's log.\n\t\"\"\"\n\tinfo_dict = collect_info_from_user(\n\t\tuser_id=user_id,\n\t\trequired_infos=self.required_infos(),\n\t\tquery_str=query_str,\n\t)\n\n\tif info_dict is None:\n\t\top_name = self._callback_operation.__name__\n\t\toperation_log_str = (\n\t\t\tf\"The user {user_id} aborts this operation {op_name}.\"\n\t\t)\n\t\toperation_log = OperationOutputLog(\n\t\t\toperation_name=op_name,\n\t\t\toperation_output=None,\n\t\t\tlog_to_user=None,\n\t\t\tlog_to_system={\n\t\t\t\tOP_DESCRIPTION: operation_log_str,\n\t\t\t\tOP_REFERENCES: None,\n\t\t\t},\n\t\t\toperation_abort=True,\n\t\t)\n\t\tlog_dict = {\"operation_log\": operation_log}\n\n\t\treturn FuncOutputWithLog(\n\t\t\tfn_output=f\"The user {user_id} abort the collecting process in the operation {op_name}\",\n\t\t\tfn_log=log_dict,\n\t\t)\n\n\top_name = self._callback_operation.__name__\n\tkwargs = {\"user_id\": user_id, }\n\tfor key in self.required_info_dict().keys():\n\t\tkwargs[key] = info_dict[key]\n\tkwargs_str = json.dumps(kwargs)\n\toperation_log = operation_authorize(\n\t\tuser_id=user_id,\n\t\top_name=op_name,\n\t\tkwargs_str=kwargs_str,\n\t\tllm=self._llm,\n\t\tembed_model=self._embed_model,\n\t\tverbose=self._verbose,\n\t)\n\tlog = {\"operation_log\": operation_log}\n\tfn_output = f\"Have done the operation {op_name} with the agreement of the user {user_id}.\"\n\tif operation_log.operation_output is not None:\n\t\tfn_output += f\"\\nOperation output:\\n{operation_log.operation_output}\"\n\treturn FuncOutputWithLog(\n\t\tfn_output=fn_output,\n\t\tfn_log=log,\n\t)\n</code></pre>"},{"location":"code_docs/tools/interact/collect_and_authorize/#labridge.tools.interact.collect_and_authorize.CollectAndAuthorizeTool.log","title":"<code>labridge.tools.interact.collect_and_authorize.CollectAndAuthorizeTool.log(**kwargs)</code>","text":"<p>Record the tool's logs.</p> PARAMETER DESCRIPTION <code>**kwargs</code> <p>The input keyword arguments and the (output, log) of the callback operation.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>tool_log</code> <p>The tool logs, including tool_to_user and tool_to_system.</p> <p> TYPE: <code>ToolLog</code> </p> Source code in <code>labridge\\tools\\interact\\collect_and_authorize.py</code> <pre><code>def log(self, **kwargs: Any) -&gt; ToolLog:\n\tr\"\"\"\n\tRecord the tool's logs.\n\n\tArgs:\n\t\t**kwargs: The input keyword arguments and the (output, log) of the callback operation.\n\n\tReturns:\n\t\ttool_log (ToolLog): The tool logs, including tool_to_user and tool_to_system.\n\t\"\"\"\n\tuser_id = kwargs[\"user_id\"]\n\tcollected_info = \",\".join(list(self.required_info_dict().keys()))\n\tlog_to_system_str = (\n\t\tf\"Have collected these information from the user {user_id}:\\n\"\n\t\tf\"{collected_info}\\n\"\n\t\tf\"Then try to do the following operation.\\n\"\n\t)\n\n\top_log: OperationOutputLog = kwargs[\"operation_log\"]\n\tif not isinstance(op_log, OperationOutputLog):\n\t\traise ValueError(\"The operation_log must be 'OperationOutputLog'.\")\n\n\tlog_to_system_str += op_log.log_to_system[OP_DESCRIPTION]\n\n\tlog_to_user = op_log.log_to_user\n\tlog_to_system = {\n\t\tTOOL_OP_DESCRIPTION: log_to_system_str,\n\t\tTOOL_REFERENCES: op_log.log_to_system[OP_REFERENCES],\n\t}\n\n\ttool_log = ToolLog(\n\t\ttool_name=self.metadata.name,\n\t\tlog_to_user=log_to_user,\n\t\tlog_to_system=log_to_system,\n\t\ttool_abort=op_log.operation_abort,\n\t)\n\treturn tool_log\n</code></pre>"},{"location":"code_docs/tools/interact/collect_and_authorize/#labridge.tools.interact.collect_and_authorize.CollectAndAuthorizeTool.required_info_dict","title":"<code>labridge.tools.interact.collect_and_authorize.CollectAndAuthorizeTool.required_info_dict()</code>  <code>abstractmethod</code>","text":"<p>The required info names and their descriptions</p> Source code in <code>labridge\\tools\\interact\\collect_and_authorize.py</code> <pre><code>@abstractmethod\ndef required_info_dict(self) -&gt; Dict[str, str]:\n\tr\"\"\" The required info names and their descriptions \"\"\"\n</code></pre>"},{"location":"code_docs/tools/interact/collect_and_authorize/#labridge.tools.interact.collect_and_authorize.CollectAndAuthorizeTool.required_infos","title":"<code>labridge.tools.interact.collect_and_authorize.CollectAndAuthorizeTool.required_infos()</code>  <code>abstractmethod</code>","text":"<p>The required infos.</p> Source code in <code>labridge\\tools\\interact\\collect_and_authorize.py</code> <pre><code>@abstractmethod\ndef required_infos(self) -&gt; List[CollectingInfoBase]:\n\tr\"\"\" The required infos. \"\"\"\n</code></pre>"},{"location":"code_docs/tools/memory/chat/retrieve/","title":"Retrieve","text":""},{"location":"code_docs/tools/memory/chat/retrieve/#labridge.tools.memory.chat.retrieve","title":"<code>labridge.tools.memory.chat.retrieve</code>","text":""},{"location":"code_docs/tools/memory/chat/retrieve/#labridge.tools.memory.chat.retrieve.ChatMemoryRetrieverTool","title":"<code>labridge.tools.memory.chat.retrieve.ChatMemoryRetrieverTool</code>","text":"<p>               Bases: <code>RetrieverBaseTool</code></p> <p>This tool is used to retrieve in the permanent chat memory of a user or a chat group.</p> PARAMETER DESCRIPTION <code>chat_memory_retriever</code> <p>The chat memory retriever.</p> <p> TYPE: <code>ChatMemoryRetriever</code> DEFAULT: <code>None</code> </p> <code>metadata_mode</code> <p>The metadata mode, defaults to <code>MetadataMode.LLM</code>.</p> <p> TYPE: <code>MetadataMode</code> DEFAULT: <code>LLM</code> </p> Source code in <code>labridge\\tools\\memory\\chat\\retrieve.py</code> <pre><code>class ChatMemoryRetrieverTool(RetrieverBaseTool):\n\tr\"\"\"\n\tThis tool is used to retrieve in the permanent chat memory of a user or a chat group.\n\n\tArgs:\n\t\tchat_memory_retriever (ChatMemoryRetriever): The chat memory retriever.\n\t\tmetadata_mode (MetadataMode): The metadata mode, defaults to `MetadataMode.LLM`.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tchat_memory_retriever: ChatMemoryRetriever = None,\n\t\tmetadata_mode: MetadataMode = MetadataMode.LLM,\n\t):\n\t\tself.metadata_mode = metadata_mode\n\n\t\tchat_memory_retriever = chat_memory_retriever or ChatMemoryRetriever()\n\t\tsuper().__init__(\n\t\t\tretriever=chat_memory_retriever,\n\t\t\tname=ChatMemoryRetrieverTool.__name__,\n\t\t\tretrieve_fn=ChatMemoryRetriever.retrieve,\n\t\t)\n\n\tdef get_ref_info(self, nodes: List[NodeWithScore]) -&gt; List[RefInfoBase]:\n\t\tr\"\"\" Get the reference infos from the retrieved nodes. \"\"\"\n\t\treturn []\n\n\tdef log(self, log_dict) -&gt; ToolLog:\n\t\tr\"\"\" tool log \"\"\"\n\t\titem = log_dict[\"item_to_be_retrieved\"]\n\t\tmemory_id = log_dict[\"memory_id\"]\n\t\tstart_date = log_dict[\"start_date\"]\n\t\tend_date = log_dict[\"end_date\"]\n\t\tlog_string = (\n\t\t\tf\"Using {self.metadata.name} to retrieve '{item}' in the chat history memory with memory_id: '{memory_id}'\\n\"\n\t\t\tf\"Retrieve date is ranging from {start_date} to {end_date}\\n\"\n\t\t)\n\n\t\tlog_to_user = None\n\t\tlog_to_system = {\n\t\t\tTOOL_OP_DESCRIPTION: log_string,\n\t\t\tTOOL_REFERENCES: None,\n\t\t}\n\t\treturn ToolLog(\n\t\t\ttool_name=self.metadata.name,\n\t\t\tlog_to_user=log_to_user,\n\t\t\tlog_to_system=log_to_system,\n\t\t)\n\n\tdef _retrieve(self, retrieve_kwargs: dict) -&gt; List[NodeWithScore]:\n\t\tr\"\"\" Use the retriever to retrieve relevant nodes. \"\"\"\n\t\tnodes = self._retriever.retrieve(**retrieve_kwargs)\n\t\treturn nodes\n\n\tasync def _aretrieve(self, retrieve_kwargs: dict) -&gt; List[NodeWithScore]:\n\t\tr\"\"\" Asynchronously use the retriever to retrieve relevant nodes. \"\"\"\n\t\tnodes = await self._retriever.aretrieve(**retrieve_kwargs)\n\t\treturn nodes\n\n\tdef _nodes_to_tool_output(self, nodes: List[NodeWithScore]) -&gt; Tuple[str, dict]:\n\t\tr\"\"\" output the retrieved contents in a specific format. \"\"\"\n\t\tif nodes:\n\t\t\toutput = f\"Have retrieved relevant conversations in the chat memory\\n\\n\"\n\t\t\tcontents = []\n\t\t\tfor idx, node in enumerate(nodes):\n\t\t\t\tnode_content = (\n\t\t\t\t\tf\"Conversation {idx + 1}:\\n\"\n\t\t\t\t\tf\"{node.node.get_content(metadata_mode=self.metadata_mode)}\"\n\t\t\t\t)\n\t\t\t\tcontents.append(node_content.strip())\n\t\t\toutput += \"\\n\\n\".join(contents)\n\t\telse:\n\t\t\toutput = \"No Relevant chat history found.\"\n\n\t\toutput_log = dict()\n\t\treturn output, output_log\n</code></pre>"},{"location":"code_docs/tools/memory/chat/retrieve/#labridge.tools.memory.chat.retrieve.ChatMemoryRetrieverTool.get_ref_info","title":"<code>labridge.tools.memory.chat.retrieve.ChatMemoryRetrieverTool.get_ref_info(nodes)</code>","text":"<p>Get the reference infos from the retrieved nodes.</p> Source code in <code>labridge\\tools\\memory\\chat\\retrieve.py</code> <pre><code>def get_ref_info(self, nodes: List[NodeWithScore]) -&gt; List[RefInfoBase]:\n\tr\"\"\" Get the reference infos from the retrieved nodes. \"\"\"\n\treturn []\n</code></pre>"},{"location":"code_docs/tools/memory/chat/retrieve/#labridge.tools.memory.chat.retrieve.ChatMemoryRetrieverTool.log","title":"<code>labridge.tools.memory.chat.retrieve.ChatMemoryRetrieverTool.log(log_dict)</code>","text":"<p>tool log</p> Source code in <code>labridge\\tools\\memory\\chat\\retrieve.py</code> <pre><code>def log(self, log_dict) -&gt; ToolLog:\n\tr\"\"\" tool log \"\"\"\n\titem = log_dict[\"item_to_be_retrieved\"]\n\tmemory_id = log_dict[\"memory_id\"]\n\tstart_date = log_dict[\"start_date\"]\n\tend_date = log_dict[\"end_date\"]\n\tlog_string = (\n\t\tf\"Using {self.metadata.name} to retrieve '{item}' in the chat history memory with memory_id: '{memory_id}'\\n\"\n\t\tf\"Retrieve date is ranging from {start_date} to {end_date}\\n\"\n\t)\n\n\tlog_to_user = None\n\tlog_to_system = {\n\t\tTOOL_OP_DESCRIPTION: log_string,\n\t\tTOOL_REFERENCES: None,\n\t}\n\treturn ToolLog(\n\t\ttool_name=self.metadata.name,\n\t\tlog_to_user=log_to_user,\n\t\tlog_to_system=log_to_system,\n\t)\n</code></pre>"},{"location":"code_docs/tools/memory/experiment/insert/","title":"Insert","text":""},{"location":"code_docs/tools/memory/experiment/insert/#labridge.tools.memory.experiment.insert","title":"<code>labridge.tools.memory.experiment.insert</code>","text":""},{"location":"code_docs/tools/memory/experiment/insert/#labridge.tools.memory.experiment.insert.CreateNewExperimentLogTool","title":"<code>labridge.tools.memory.experiment.insert.CreateNewExperimentLogTool</code>","text":"<p>               Bases: <code>CollectAndAuthorizeTool</code></p> <p>This tool is used to create a new experiment record in the user's experiment log storage. It is a <code>CollectAndAuthorizeTool</code> that needs information collection and authorization.</p> PARAMETER DESCRIPTION <code>llm</code> <p>The used LLM.</p> <p> TYPE: <code>LLM</code> DEFAULT: <code>None</code> </p> <code>embed_model</code> <p>The used embedding model.</p> <p> TYPE: <code>BaseEmbedding</code> DEFAULT: <code>None</code> </p> <code>verbose</code> <p>Whether to show the inner progress.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> Source code in <code>labridge\\tools\\memory\\experiment\\insert.py</code> <pre><code>class CreateNewExperimentLogTool(CollectAndAuthorizeTool):\n\tr\"\"\"\n\tThis tool is used to create a new experiment record in the user's experiment log storage.\n\tIt is a `CollectAndAuthorizeTool` that needs information collection and authorization.\n\n\tArgs:\n\t\tllm (LLM): The used LLM.\n\t\tembed_model (BaseEmbedding): The used embedding model.\n\t\tverbose (bool): Whether to show the inner progress.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tllm: LLM = None,\n\t\tembed_model: BaseEmbedding = None,\n\t\tverbose: bool = False\n\t):\n\t\tsuper().__init__(\n\t\t\ttool_fn=self.create_new_experiment_log,\n\t\t\ttool_async_fn=self.acreate_new_experiment_log,\n\t\t\ttool_name=CreateNewExperimentLogTool.__name__,\n\t\t\tcallback_operation=CreateNewExperimentLogOperation,\n\t\t\tllm=llm,\n\t\t\tembed_model=embed_model,\n\t\t\tverbose=verbose,\n\t\t)\n\n\tdef required_info_dict(self) -&gt; Dict[str, str]:\n\t\tr\"\"\"\n\t\tThe required information.\n\n\t\tReturns:\n\t\t\tDict[str, str]:\n\n\t\t\t\t- key: the information name.\n\t\t\t\t- value: the information description.\n\t\t\"\"\"\n\t\treturn NEW_EXPERIMENT_REQUIRED_INFOS\n\n\tdef required_infos(self) -&gt; List[CollectingInfoBase]:\n\t\tr\"\"\"\n\t\tThe required infos.\n\n\t\tReturns:\n\t\t\tList[CollectingInfoBase]:\n\t\t\t\tReturn the packed info in CollectingInfoBase, such as `CollectingCommonInfo`.\n\t\t\"\"\"\n\t\tinfos = []\n\t\tinfo_dict = self.required_info_dict()\n\t\tfor key in info_dict.keys():\n\t\t\tcommon_info = CollectingCommonInfo(\n\t\t\t\tinfo_name=key,\n\t\t\t\tinfo_description=info_dict[key],\n\t\t\t)\n\t\t\tinfos.append(common_info)\n\t\treturn infos\n\n\tdef create_new_experiment_log(\n\t\tself,\n\t\tuser_id: str,\n\t) -&gt; FuncOutputWithLog:\n\t\tr\"\"\"\n\t\tThis tool is used to create a new experiment log record for the user.\n\t\tThis tool is only used when the user asks for creating a new experiment log record, or other tools call this tool.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user_id of a lab member.\n\n\t\tReturns:\n\t\t\tThe tool's output and log.\n\t\t\"\"\"\n\t\t# This docstring is used as the tool description.\n\t\treturn self.collect_and_authorize(\n\t\t\tuser_id=user_id,\n\t\t\tquery_str=COLLECT_NEW_EXPERIMENT_INFO_QUERY,\n\t\t)\n\n\tasync def acreate_new_experiment_log(\n\t\tself,\n\t\tuser_id: str,\n\t) -&gt; FuncOutputWithLog:\n\t\tr\"\"\"\n\t\tThis tool is used to create a new experiment log record for the user.\n\t\tThis tool is only used when the user asks for creating a new experiment log record,\n\t\tor when other tools call this tool.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user_id of a lab member.\n\n\t\tReturns:\n\t\t\tThe tool's output and log.\n\t\t\"\"\"\n\t\toutput = await self.acollect_and_authorize(\n\t\t\tuser_id=user_id,\n\t\t\tquery_str=COLLECT_NEW_EXPERIMENT_INFO_QUERY,\n\t\t)\n\t\tprint(\"Here: \", output.fn_output)\n\t\tprint(\"Here: \", output.fn_log)\n\t\treturn output\n</code></pre>"},{"location":"code_docs/tools/memory/experiment/insert/#labridge.tools.memory.experiment.insert.CreateNewExperimentLogTool.acreate_new_experiment_log","title":"<code>labridge.tools.memory.experiment.insert.CreateNewExperimentLogTool.acreate_new_experiment_log(user_id)</code>  <code>async</code>","text":"<p>This tool is used to create a new experiment log record for the user. This tool is only used when the user asks for creating a new experiment log record, or when other tools call this tool.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user_id of a lab member.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>FuncOutputWithLog</code> <p>The tool's output and log.</p> Source code in <code>labridge\\tools\\memory\\experiment\\insert.py</code> <pre><code>async def acreate_new_experiment_log(\n\tself,\n\tuser_id: str,\n) -&gt; FuncOutputWithLog:\n\tr\"\"\"\n\tThis tool is used to create a new experiment log record for the user.\n\tThis tool is only used when the user asks for creating a new experiment log record,\n\tor when other tools call this tool.\n\n\tArgs:\n\t\tuser_id (str): The user_id of a lab member.\n\n\tReturns:\n\t\tThe tool's output and log.\n\t\"\"\"\n\toutput = await self.acollect_and_authorize(\n\t\tuser_id=user_id,\n\t\tquery_str=COLLECT_NEW_EXPERIMENT_INFO_QUERY,\n\t)\n\tprint(\"Here: \", output.fn_output)\n\tprint(\"Here: \", output.fn_log)\n\treturn output\n</code></pre>"},{"location":"code_docs/tools/memory/experiment/insert/#labridge.tools.memory.experiment.insert.CreateNewExperimentLogTool.create_new_experiment_log","title":"<code>labridge.tools.memory.experiment.insert.CreateNewExperimentLogTool.create_new_experiment_log(user_id)</code>","text":"<p>This tool is used to create a new experiment log record for the user. This tool is only used when the user asks for creating a new experiment log record, or other tools call this tool.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user_id of a lab member.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>FuncOutputWithLog</code> <p>The tool's output and log.</p> Source code in <code>labridge\\tools\\memory\\experiment\\insert.py</code> <pre><code>def create_new_experiment_log(\n\tself,\n\tuser_id: str,\n) -&gt; FuncOutputWithLog:\n\tr\"\"\"\n\tThis tool is used to create a new experiment log record for the user.\n\tThis tool is only used when the user asks for creating a new experiment log record, or other tools call this tool.\n\n\tArgs:\n\t\tuser_id (str): The user_id of a lab member.\n\n\tReturns:\n\t\tThe tool's output and log.\n\t\"\"\"\n\t# This docstring is used as the tool description.\n\treturn self.collect_and_authorize(\n\t\tuser_id=user_id,\n\t\tquery_str=COLLECT_NEW_EXPERIMENT_INFO_QUERY,\n\t)\n</code></pre>"},{"location":"code_docs/tools/memory/experiment/insert/#labridge.tools.memory.experiment.insert.CreateNewExperimentLogTool.required_info_dict","title":"<code>labridge.tools.memory.experiment.insert.CreateNewExperimentLogTool.required_info_dict()</code>","text":"<p>The required information.</p> RETURNS DESCRIPTION <code>Dict[str, str]</code> <p>Dict[str, str]:</p> <ul> <li>key: the information name.</li> <li>value: the information description.</li> </ul> Source code in <code>labridge\\tools\\memory\\experiment\\insert.py</code> <pre><code>def required_info_dict(self) -&gt; Dict[str, str]:\n\tr\"\"\"\n\tThe required information.\n\n\tReturns:\n\t\tDict[str, str]:\n\n\t\t\t- key: the information name.\n\t\t\t- value: the information description.\n\t\"\"\"\n\treturn NEW_EXPERIMENT_REQUIRED_INFOS\n</code></pre>"},{"location":"code_docs/tools/memory/experiment/insert/#labridge.tools.memory.experiment.insert.CreateNewExperimentLogTool.required_infos","title":"<code>labridge.tools.memory.experiment.insert.CreateNewExperimentLogTool.required_infos()</code>","text":"<p>The required infos.</p> RETURNS DESCRIPTION <code>List[CollectingInfoBase]</code> <p>List[CollectingInfoBase]: Return the packed info in CollectingInfoBase, such as <code>CollectingCommonInfo</code>.</p> Source code in <code>labridge\\tools\\memory\\experiment\\insert.py</code> <pre><code>def required_infos(self) -&gt; List[CollectingInfoBase]:\n\tr\"\"\"\n\tThe required infos.\n\n\tReturns:\n\t\tList[CollectingInfoBase]:\n\t\t\tReturn the packed info in CollectingInfoBase, such as `CollectingCommonInfo`.\n\t\"\"\"\n\tinfos = []\n\tinfo_dict = self.required_info_dict()\n\tfor key in info_dict.keys():\n\t\tcommon_info = CollectingCommonInfo(\n\t\t\tinfo_name=key,\n\t\t\tinfo_description=info_dict[key],\n\t\t)\n\t\tinfos.append(common_info)\n\treturn infos\n</code></pre>"},{"location":"code_docs/tools/memory/experiment/insert/#labridge.tools.memory.experiment.insert.RecordExperimentLogTool","title":"<code>labridge.tools.memory.experiment.insert.RecordExperimentLogTool</code>","text":"<p>               Bases: <code>FunctionBaseTool</code></p> <p>This tool is used to record the experiment log for users. Use this tool When the user asks you to record anything about his/her experiment.</p> <ul> <li>If the recorded experiment in progress is valid (That is, current time is not beyond this experiment's duration), the experiment log will be directly record to the record of the experiment in progress.</li> <li>If the recorded experiment in progress is not valid, this tool will implicitly call the <code>SetCurrentExperimentTool</code> to set current experiment (Output the tool call requirement in the tool output.).</li> </ul> PARAMETER DESCRIPTION <code>llm</code> <p>The used LLM. If not specified, the <code>Settings.llm</code> will be used.</p> <p> TYPE: <code>LLM</code> DEFAULT: <code>None</code> </p> <code>embed_model</code> <p>The used embedding model. If not specified, the <code>Settings.embed_model</code> will be used.</p> <p> TYPE: <code>BaseEmbedding</code> DEFAULT: <code>None</code> </p> <code>verbose</code> <p>Whether to show the inner progress.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> Source code in <code>labridge\\tools\\memory\\experiment\\insert.py</code> <pre><code>class RecordExperimentLogTool(FunctionBaseTool):\n\tr\"\"\"\n\tThis tool is used to record the experiment log for users.\n\tUse this tool When the user asks you to record anything about his/her experiment.\n\n\t- If the recorded experiment in progress is valid (That is, current time is not beyond this experiment's duration),\n\tthe experiment log will be directly record to the record of the experiment in progress.\n\t- If the recorded experiment in progress is not valid, this tool will implicitly call the `SetCurrentExperimentTool`\n\tto set current experiment (Output the tool call requirement in the tool output.).\n\n\tArgs:\n\t\tllm (LLM): The used LLM. If not specified, the `Settings.llm` will be used.\n\t\tembed_model (BaseEmbedding): The used embedding model. If not specified, the `Settings.embed_model` will be used.\n\t\tverbose (bool): Whether to show the inner progress.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tllm: LLM = None,\n\t\tembed_model: BaseEmbedding = None,\n\t\tverbose: bool = False,\n\t):\n\t\tself._llm = llm or Settings.llm\n\t\tself._embed_model = embed_model or Settings.embed_model\n\t\tself._verbose = verbose\n\t\tsuper().__init__(\n\t\t\tfn=self.record_log,\n\t\t\tasync_fn=self.arecord_log,\n\t\t\ttool_name=RecordExperimentLogTool.__name__,\n\t\t)\n\n\tdef log(self, **kwargs: Any) -&gt; ToolLog:\n\t\tr\"\"\"\n\t\tRecord the tool log.\n\n\t\tArgs:\n\t\t\t**kwargs (Any): The input keyword arguments and the (output, log) of the executed operation.\n\n\t\tReturns:\n\n\t\t\"\"\"\n\t\top_log: OperationOutputLog = kwargs[\"operation_log\"]\n\n\t\treturn ToolLog.construct(\n\t\t\ttool_name=self.metadata.name,\n\t\t\ttool_op_description=op_log.log_to_system[OP_DESCRIPTION],\n\t\t)\n\n\tdef record_log(\n\t\tself,\n\t\tuser_id: str,\n\t\tlog_str: str,\n\t\tattached_file_path: str = None,\n\t\t**kwargs,\n\t) -&gt; FuncOutputWithLog:\n\t\tr\"\"\"\n\t\tThis tool is used to record the experiment log of the experiment in progress for a user.\n\n\t\tIf the no experiment record exists or experiment in progress is not valid, this tool will call\n\t\tthe corresponding tools to help the user.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user_id of a lab member.\n\t\t\tlog_str (str): The experiment log to be recorded.\n\t\t\tattached_file_path (str): The path of the attached file, If the user attaches a file along with the experiment log.\n\t\t\t\tDefaults to None.\n\n\t\tReturns:\n\t\t\tThe tool output and log.\n\t\t\"\"\"\n\t\t# This docstring is used as the tool description.\n\t\texpr_log_store = ExperimentLog.from_user_id(\n\t\t\tuser_id=user_id,\n\t\t\tembed_model=self._embed_model,\n\t\t)\n\n\t\t# If no experiment log record exists.\n\t\tif expr_log_store.get_all_experiments() is None:\n\t\t\tcreate_tool = CreateNewExperimentLogTool(\n\t\t\t\tllm=self._llm,\n\t\t\t\tembed_model=self._embed_model,\n\t\t\t)\n\t\t\tcreate_output = create_tool.call(user_id=user_id)\n\t\t\tabort = whether_abort_tool(tool_output=create_output)\n\t\t\tif abort is None or abort:\n\t\t\t\tstatus = (\n\t\t\t\t\tf\"The user does not want to continue, and abort the create experiment operation.\"\n\t\t\t\t\tf\"This conversation should be ended.\"\n\t\t\t\t)\n\t\t\t\tif abort is None:\n\t\t\t\t\tstatus = f\"The tool output of the CreateNewExperimentLogTool is invalid.\"\n\n\t\t\t\top_log = OperationOutputLog.construct(\n\t\t\t\t\toperation_name=create_tool.metadata.name,\n\t\t\t\t\top_description=status,\n\t\t\t\t\toperation_output=status,\n\t\t\t\t)\n\t\t\t\treturn FuncOutputWithLog(\n\t\t\t\t\tfn_output=status,\n\t\t\t\t\tfn_log={\"operation_log\": op_log}\n\t\t\t\t)\n\n\t\t# If current experiment in progress is not valid.\n\t\trecent_expr = expr_log_store.get_recent_experiment()\n\t\tif recent_expr is None:\n\t\t\tset_tool = SetCurrentExperimentTool(\n\t\t\t\tllm=self._llm,\n\t\t\t\tembed_model=self._embed_model,\n\t\t\t)\n\n\t\t\tset_output = set_tool.call(user_id=user_id)\n\t\t\tabort = whether_abort_tool(tool_output=set_output)\n\t\t\tif abort is None or abort:\n\t\t\t\tstatus = (\n\t\t\t\t\tf\"The user does not want to continue, and abort the set experiment operation.\"\n\t\t\t\t\tf\"This conversation should be ended.\"\n\t\t\t\t)\n\t\t\t\tif abort is None:\n\t\t\t\t\tstatus = f\"The tool output of the SetCurrentExperimentTool is invalid.\"\n\n\t\t\t\top_log = OperationOutputLog.construct(\n\t\t\t\t\toperation_name=set_tool.metadata.name,\n\t\t\t\t\top_description=status,\n\t\t\t\t\toperation_output=status,\n\t\t\t\t)\n\t\t\t\treturn FuncOutputWithLog(\n\t\t\t\t\tfn_output=status,\n\t\t\t\t\tfn_log={\"operation_log\": op_log},\n\t\t\t\t)\n\n\t\t\t# reload\n\t\t\texpr_log_store = ExperimentLog.from_user_id(\n\t\t\t\tuser_id=user_id,\n\t\t\t\tembed_model=self._embed_model,\n\t\t\t)\n\t\t\trecent_expr = expr_log_store.get_recent_experiment()\n\n\t\texpr_log_store.put(\n\t\t\texperiment_name=recent_expr,\n\t\t\tlog_str=log_str,\n\t\t\tattached_file_path=attached_file_path,\n\t\t)\n\t\texpr_log_store.persist()\n\n\t\top_log_str = (\n\t\t\tf\"Have put a new experiment log into the experiment log store of the user: {user_id}.\\n\" \n\t\t\tf\"Experiment name: {recent_expr}\\n\"\n\t\t)\n\t\top_log = OperationOutputLog.construct(\n\t\t\toperation_name=self.metadata.name,\n\t\t\top_description=op_log_str,\n\t\t\toperation_output=op_log_str,\n\t\t)\n\t\treturn FuncOutputWithLog(\n\t\t\tfn_output=f\"Have record the log {log_str}\",\n\t\t\tfn_log={\"operation_log\": op_log}\n\t\t)\n\n\tasync def arecord_log(\n\t\tself,\n\t\tuser_id: str,\n\t\tlog_str: str,\n\t\tattached_file_path: str = None,\n\t\t**kwargs,\n\t) -&gt; FuncOutputWithLog:\n\t\tr\"\"\"\n\t\tThis tool is used to record the experiment log of the experiment in progress for a user.\n\n\t\tIf the no experiment record exists or experiment in progress is not valid, this tool will call\n\t\tthe corresponding tools to help the user.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user_id of a lab member.\n\t\t\tlog_str (str): The experiment log to be recorded.\n\t\t\tattached_file_path (str): The path of the attached file, If the user attaches a file along with the experiment log.\n\t\t\t\tDefaults to None.\n\n\t\tReturns:\n\t\t\tThe tool output and log.\n\t\t\"\"\"\n\t\t# This docstring is used as the tool description.\n\t\texpr_log_store = ExperimentLog.from_user_id(\n\t\t\tuser_id=user_id,\n\t\t\tembed_model=self._embed_model,\n\t\t)\n\n\t\t# If no experiment log record exists.\n\t\tif expr_log_store.get_all_experiments() is None:\n\t\t\tcreate_tool = CreateNewExperimentLogTool(\n\t\t\t\tllm=self._llm,\n\t\t\t\tembed_model=self._embed_model,\n\t\t\t)\n\t\t\tcreate_output = await create_tool.acall(user_id=user_id)\n\n\t\t\tabort = whether_abort_tool(tool_output=create_output)\n\t\t\tif abort is None or abort:\n\t\t\t\tstatus = f\"The user does not want to continue, and abort the create experiment operation.\"\n\t\t\t\tif abort is None:\n\t\t\t\t\tstatus = f\"The tool output of the CreateNewExperimentLogTool is invalid.\"\n\n\t\t\t\top_log = OperationOutputLog.construct(\n\t\t\t\t\toperation_name=create_tool.metadata.name,\n\t\t\t\t\top_description=status,\n\t\t\t\t\toperation_output=status,\n\t\t\t\t)\n\t\t\t\treturn FuncOutputWithLog(\n\t\t\t\t\tfn_output=status,\n\t\t\t\t\tfn_log={\"operation_log\": op_log}\n\t\t\t\t)\n\n\t\t# If current experiment in progress is not valid.\n\t\trecent_expr = expr_log_store.get_recent_experiment()\n\t\tif recent_expr is None:\n\t\t\tset_tool = SetCurrentExperimentTool(\n\t\t\t\tllm=self._llm,\n\t\t\t\tembed_model=self._embed_model,\n\t\t\t)\n\t\t\tset_output = await set_tool.acall(user_id=user_id)\n\n\t\t\tabort = whether_abort_tool(tool_output=set_output)\n\t\t\tif abort is None or abort:\n\t\t\t\tstatus = f\"The user does not want to continue, and abort the set experiment operation.\"\n\t\t\t\tif abort is None:\n\t\t\t\t\tstatus = f\"The tool output of the SetCurrentExperimentTool is invalid.\"\n\n\t\t\t\top_log = OperationOutputLog.construct(\n\t\t\t\t\toperation_name=set_tool.metadata.name,\n\t\t\t\t\top_description=status,\n\t\t\t\t\toperation_output=status,\n\t\t\t\t)\n\t\t\t\treturn FuncOutputWithLog(\n\t\t\t\t\tfn_output=status,\n\t\t\t\t\tfn_log={\"operation_log\": op_log},\n\t\t\t\t)\n\n\t\t\t# reload\n\t\t\texpr_log_store = ExperimentLog.from_user_id(\n\t\t\t\tuser_id=user_id,\n\t\t\t\tembed_model=self._embed_model,\n\t\t\t)\n\t\t\trecent_expr = expr_log_store.get_recent_experiment()\n\n\t\texpr_log_store.put(\n\t\t\texperiment_name=recent_expr,\n\t\t\tlog_str=log_str,\n\t\t\tattached_file_path=attached_file_path,\n\t\t)\n\t\texpr_log_store.persist()\n\n\t\top_log_str = (\n\t\t\tf\"Have put a new experiment log into the experiment log store of the user: {user_id}.\\n\"\n\t\t\tf\"Experiment name: {recent_expr}\\n\"\n\t\t)\n\t\top_log = OperationOutputLog.construct(\n\t\t\toperation_name=self.metadata.name,\n\t\t\top_description=op_log_str,\n\t\t\toperation_output=op_log_str,\n\t\t)\n\t\treturn FuncOutputWithLog(\n\t\t\tfn_output=f\"Have record the log {log_str}\",\n\t\t\tfn_log={\"operation_log\": op_log}\n\t\t)\n</code></pre>"},{"location":"code_docs/tools/memory/experiment/insert/#labridge.tools.memory.experiment.insert.RecordExperimentLogTool.arecord_log","title":"<code>labridge.tools.memory.experiment.insert.RecordExperimentLogTool.arecord_log(user_id, log_str, attached_file_path=None, **kwargs)</code>  <code>async</code>","text":"<p>This tool is used to record the experiment log of the experiment in progress for a user.</p> <p>If the no experiment record exists or experiment in progress is not valid, this tool will call the corresponding tools to help the user.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user_id of a lab member.</p> <p> TYPE: <code>str</code> </p> <code>log_str</code> <p>The experiment log to be recorded.</p> <p> TYPE: <code>str</code> </p> <code>attached_file_path</code> <p>The path of the attached file, If the user attaches a file along with the experiment log. Defaults to None.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>FuncOutputWithLog</code> <p>The tool output and log.</p> Source code in <code>labridge\\tools\\memory\\experiment\\insert.py</code> <pre><code>async def arecord_log(\n\tself,\n\tuser_id: str,\n\tlog_str: str,\n\tattached_file_path: str = None,\n\t**kwargs,\n) -&gt; FuncOutputWithLog:\n\tr\"\"\"\n\tThis tool is used to record the experiment log of the experiment in progress for a user.\n\n\tIf the no experiment record exists or experiment in progress is not valid, this tool will call\n\tthe corresponding tools to help the user.\n\n\tArgs:\n\t\tuser_id (str): The user_id of a lab member.\n\t\tlog_str (str): The experiment log to be recorded.\n\t\tattached_file_path (str): The path of the attached file, If the user attaches a file along with the experiment log.\n\t\t\tDefaults to None.\n\n\tReturns:\n\t\tThe tool output and log.\n\t\"\"\"\n\t# This docstring is used as the tool description.\n\texpr_log_store = ExperimentLog.from_user_id(\n\t\tuser_id=user_id,\n\t\tembed_model=self._embed_model,\n\t)\n\n\t# If no experiment log record exists.\n\tif expr_log_store.get_all_experiments() is None:\n\t\tcreate_tool = CreateNewExperimentLogTool(\n\t\t\tllm=self._llm,\n\t\t\tembed_model=self._embed_model,\n\t\t)\n\t\tcreate_output = await create_tool.acall(user_id=user_id)\n\n\t\tabort = whether_abort_tool(tool_output=create_output)\n\t\tif abort is None or abort:\n\t\t\tstatus = f\"The user does not want to continue, and abort the create experiment operation.\"\n\t\t\tif abort is None:\n\t\t\t\tstatus = f\"The tool output of the CreateNewExperimentLogTool is invalid.\"\n\n\t\t\top_log = OperationOutputLog.construct(\n\t\t\t\toperation_name=create_tool.metadata.name,\n\t\t\t\top_description=status,\n\t\t\t\toperation_output=status,\n\t\t\t)\n\t\t\treturn FuncOutputWithLog(\n\t\t\t\tfn_output=status,\n\t\t\t\tfn_log={\"operation_log\": op_log}\n\t\t\t)\n\n\t# If current experiment in progress is not valid.\n\trecent_expr = expr_log_store.get_recent_experiment()\n\tif recent_expr is None:\n\t\tset_tool = SetCurrentExperimentTool(\n\t\t\tllm=self._llm,\n\t\t\tembed_model=self._embed_model,\n\t\t)\n\t\tset_output = await set_tool.acall(user_id=user_id)\n\n\t\tabort = whether_abort_tool(tool_output=set_output)\n\t\tif abort is None or abort:\n\t\t\tstatus = f\"The user does not want to continue, and abort the set experiment operation.\"\n\t\t\tif abort is None:\n\t\t\t\tstatus = f\"The tool output of the SetCurrentExperimentTool is invalid.\"\n\n\t\t\top_log = OperationOutputLog.construct(\n\t\t\t\toperation_name=set_tool.metadata.name,\n\t\t\t\top_description=status,\n\t\t\t\toperation_output=status,\n\t\t\t)\n\t\t\treturn FuncOutputWithLog(\n\t\t\t\tfn_output=status,\n\t\t\t\tfn_log={\"operation_log\": op_log},\n\t\t\t)\n\n\t\t# reload\n\t\texpr_log_store = ExperimentLog.from_user_id(\n\t\t\tuser_id=user_id,\n\t\t\tembed_model=self._embed_model,\n\t\t)\n\t\trecent_expr = expr_log_store.get_recent_experiment()\n\n\texpr_log_store.put(\n\t\texperiment_name=recent_expr,\n\t\tlog_str=log_str,\n\t\tattached_file_path=attached_file_path,\n\t)\n\texpr_log_store.persist()\n\n\top_log_str = (\n\t\tf\"Have put a new experiment log into the experiment log store of the user: {user_id}.\\n\"\n\t\tf\"Experiment name: {recent_expr}\\n\"\n\t)\n\top_log = OperationOutputLog.construct(\n\t\toperation_name=self.metadata.name,\n\t\top_description=op_log_str,\n\t\toperation_output=op_log_str,\n\t)\n\treturn FuncOutputWithLog(\n\t\tfn_output=f\"Have record the log {log_str}\",\n\t\tfn_log={\"operation_log\": op_log}\n\t)\n</code></pre>"},{"location":"code_docs/tools/memory/experiment/insert/#labridge.tools.memory.experiment.insert.RecordExperimentLogTool.log","title":"<code>labridge.tools.memory.experiment.insert.RecordExperimentLogTool.log(**kwargs)</code>","text":"<p>Record the tool log.</p> PARAMETER DESCRIPTION <code>**kwargs</code> <p>The input keyword arguments and the (output, log) of the executed operation.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> Source code in <code>labridge\\tools\\memory\\experiment\\insert.py</code> <pre><code>def log(self, **kwargs: Any) -&gt; ToolLog:\n\tr\"\"\"\n\tRecord the tool log.\n\n\tArgs:\n\t\t**kwargs (Any): The input keyword arguments and the (output, log) of the executed operation.\n\n\tReturns:\n\n\t\"\"\"\n\top_log: OperationOutputLog = kwargs[\"operation_log\"]\n\n\treturn ToolLog.construct(\n\t\ttool_name=self.metadata.name,\n\t\ttool_op_description=op_log.log_to_system[OP_DESCRIPTION],\n\t)\n</code></pre>"},{"location":"code_docs/tools/memory/experiment/insert/#labridge.tools.memory.experiment.insert.RecordExperimentLogTool.record_log","title":"<code>labridge.tools.memory.experiment.insert.RecordExperimentLogTool.record_log(user_id, log_str, attached_file_path=None, **kwargs)</code>","text":"<p>This tool is used to record the experiment log of the experiment in progress for a user.</p> <p>If the no experiment record exists or experiment in progress is not valid, this tool will call the corresponding tools to help the user.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user_id of a lab member.</p> <p> TYPE: <code>str</code> </p> <code>log_str</code> <p>The experiment log to be recorded.</p> <p> TYPE: <code>str</code> </p> <code>attached_file_path</code> <p>The path of the attached file, If the user attaches a file along with the experiment log. Defaults to None.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>FuncOutputWithLog</code> <p>The tool output and log.</p> Source code in <code>labridge\\tools\\memory\\experiment\\insert.py</code> <pre><code>def record_log(\n\tself,\n\tuser_id: str,\n\tlog_str: str,\n\tattached_file_path: str = None,\n\t**kwargs,\n) -&gt; FuncOutputWithLog:\n\tr\"\"\"\n\tThis tool is used to record the experiment log of the experiment in progress for a user.\n\n\tIf the no experiment record exists or experiment in progress is not valid, this tool will call\n\tthe corresponding tools to help the user.\n\n\tArgs:\n\t\tuser_id (str): The user_id of a lab member.\n\t\tlog_str (str): The experiment log to be recorded.\n\t\tattached_file_path (str): The path of the attached file, If the user attaches a file along with the experiment log.\n\t\t\tDefaults to None.\n\n\tReturns:\n\t\tThe tool output and log.\n\t\"\"\"\n\t# This docstring is used as the tool description.\n\texpr_log_store = ExperimentLog.from_user_id(\n\t\tuser_id=user_id,\n\t\tembed_model=self._embed_model,\n\t)\n\n\t# If no experiment log record exists.\n\tif expr_log_store.get_all_experiments() is None:\n\t\tcreate_tool = CreateNewExperimentLogTool(\n\t\t\tllm=self._llm,\n\t\t\tembed_model=self._embed_model,\n\t\t)\n\t\tcreate_output = create_tool.call(user_id=user_id)\n\t\tabort = whether_abort_tool(tool_output=create_output)\n\t\tif abort is None or abort:\n\t\t\tstatus = (\n\t\t\t\tf\"The user does not want to continue, and abort the create experiment operation.\"\n\t\t\t\tf\"This conversation should be ended.\"\n\t\t\t)\n\t\t\tif abort is None:\n\t\t\t\tstatus = f\"The tool output of the CreateNewExperimentLogTool is invalid.\"\n\n\t\t\top_log = OperationOutputLog.construct(\n\t\t\t\toperation_name=create_tool.metadata.name,\n\t\t\t\top_description=status,\n\t\t\t\toperation_output=status,\n\t\t\t)\n\t\t\treturn FuncOutputWithLog(\n\t\t\t\tfn_output=status,\n\t\t\t\tfn_log={\"operation_log\": op_log}\n\t\t\t)\n\n\t# If current experiment in progress is not valid.\n\trecent_expr = expr_log_store.get_recent_experiment()\n\tif recent_expr is None:\n\t\tset_tool = SetCurrentExperimentTool(\n\t\t\tllm=self._llm,\n\t\t\tembed_model=self._embed_model,\n\t\t)\n\n\t\tset_output = set_tool.call(user_id=user_id)\n\t\tabort = whether_abort_tool(tool_output=set_output)\n\t\tif abort is None or abort:\n\t\t\tstatus = (\n\t\t\t\tf\"The user does not want to continue, and abort the set experiment operation.\"\n\t\t\t\tf\"This conversation should be ended.\"\n\t\t\t)\n\t\t\tif abort is None:\n\t\t\t\tstatus = f\"The tool output of the SetCurrentExperimentTool is invalid.\"\n\n\t\t\top_log = OperationOutputLog.construct(\n\t\t\t\toperation_name=set_tool.metadata.name,\n\t\t\t\top_description=status,\n\t\t\t\toperation_output=status,\n\t\t\t)\n\t\t\treturn FuncOutputWithLog(\n\t\t\t\tfn_output=status,\n\t\t\t\tfn_log={\"operation_log\": op_log},\n\t\t\t)\n\n\t\t# reload\n\t\texpr_log_store = ExperimentLog.from_user_id(\n\t\t\tuser_id=user_id,\n\t\t\tembed_model=self._embed_model,\n\t\t)\n\t\trecent_expr = expr_log_store.get_recent_experiment()\n\n\texpr_log_store.put(\n\t\texperiment_name=recent_expr,\n\t\tlog_str=log_str,\n\t\tattached_file_path=attached_file_path,\n\t)\n\texpr_log_store.persist()\n\n\top_log_str = (\n\t\tf\"Have put a new experiment log into the experiment log store of the user: {user_id}.\\n\" \n\t\tf\"Experiment name: {recent_expr}\\n\"\n\t)\n\top_log = OperationOutputLog.construct(\n\t\toperation_name=self.metadata.name,\n\t\top_description=op_log_str,\n\t\toperation_output=op_log_str,\n\t)\n\treturn FuncOutputWithLog(\n\t\tfn_output=f\"Have record the log {log_str}\",\n\t\tfn_log={\"operation_log\": op_log}\n\t)\n</code></pre>"},{"location":"code_docs/tools/memory/experiment/insert/#labridge.tools.memory.experiment.insert.SetCurrentExperimentTool","title":"<code>labridge.tools.memory.experiment.insert.SetCurrentExperimentTool</code>","text":"<p>               Bases: <code>CollectAndAuthorizeTool</code></p> <p>This tool is used to set the experiment in progress for a user.</p> PARAMETER DESCRIPTION <code>llm</code> <p>The used LLM.</p> <p> TYPE: <code>LLM</code> DEFAULT: <code>None</code> </p> <code>embed_model</code> <p>The used embedding model.</p> <p> TYPE: <code>BaseEmbedding</code> DEFAULT: <code>None</code> </p> <code>verbose</code> <p>Whether to show the inner progress.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> Source code in <code>labridge\\tools\\memory\\experiment\\insert.py</code> <pre><code>class SetCurrentExperimentTool(CollectAndAuthorizeTool):\n\tr\"\"\"\n\tThis tool is used to set the experiment in progress for a user.\n\n\tArgs:\n\t\tllm (LLM): The used LLM.\n\t\tembed_model (BaseEmbedding): The used embedding model.\n\t\tverbose (bool): Whether to show the inner progress.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tllm: LLM = None,\n\t\tembed_model: BaseEmbedding = None,\n\t\tverbose: bool = False,\n\t):\n\t\tself.expr_log_store = None\n\t\tsuper().__init__(\n\t\t\ttool_fn=self.set_current_experiment,\n\t\t\ttool_async_fn=self.aset_current_experiment,\n\t\t\ttool_name=SetCurrentExperimentTool.__name__,\n\t\t\tcallback_operation=SetCurrentExperimentOperation,\n\t\t\tllm=llm,\n\t\t\tembed_model=embed_model,\n\t\t\tverbose=verbose,\n\t\t)\n\n\tdef required_info_dict(self) -&gt; Dict[str, str]:\n\t\tr\"\"\"\n\t\tThe required information.\n\n\t\tReturns:\n\t\t\tDict[str, str]:\n\n\t\t\t\t- key: the information name.\n\t\t\t\t- value: the information description.\n\t\t\"\"\"\n\t\treturn SET_CURRENT_EXPERIMENT_REQUIRED_INFOS\n\n\tdef required_infos(self) -&gt; List[CollectingInfoBase]:\n\t\tr\"\"\"\n\t\tThe required infos.\n\n\t\tReturns:\n\t\t\tList[CollectingInfoBase]:\n\t\t\t\tReturn the packed info in CollectingInfoBase, such as `CollectingCommonInfo` and `CollectingSelectInfo`.\n\t\t\"\"\"\n\t\texperiments = self.expr_log_store.get_all_experiments_with_description()\n\t\tselect_name_info = CollectingSelectInfo(\n\t\t\tinfo_name=CURRENT_EXPERIMENT_NAME_KEY,\n\t\t\tinfo_description=self.required_info_dict()[CURRENT_EXPERIMENT_NAME_KEY],\n\t\t\tchoices=experiments,\n\t\t)\n\n\t\tduration_info = CollectingCommonInfo(\n\t\t\tinfo_name=CURRENT_EXPERIMENT_DURATION_KEY,\n\t\t\tinfo_description=self.required_info_dict()[CURRENT_EXPERIMENT_DURATION_KEY]\n\t\t)\n\t\treturn [select_name_info, duration_info]\n\n\tdef set_experiment_log_store(self, user_id: str):\n\t\tr\"\"\"\n\t\tLoad the user's experiment log storage.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user_id of a lab member.\n\t\t\"\"\"\n\t\tif self.expr_log_store is None or self.expr_log_store.user_id != user_id:\n\t\t\tself.expr_log_store = ExperimentLog.from_user_id(\n\t\t\t\tuser_id=user_id,\n\t\t\t\tembed_model=self._embed_model,\n\t\t\t)\n\n\tdef set_current_experiment(\n\t\tself,\n\t\tuser_id: str,\n\t) -&gt; FuncOutputWithLog:\n\t\tr\"\"\"\n\t\tThis tool is used to set the experiment in progress for the user, through interacting with the user.\n\t\tThis tool is used ONLY when the user ask for setting his/her experiment in progress,\n\t\tor when other tools call this tool.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user_id of a lab member.\n\n\t\tReturns:\n\t\t\tThe tool output and log.\n\t\t\"\"\"\n\t\t# This docstring is used as tool description.\n\t\tself.set_experiment_log_store(user_id=user_id)\n\n\t\texpr_list = self.expr_log_store.get_all_experiments()\n\n\t\tif expr_list is None:\n\t\t\tcreate_tool = CreateNewExperimentLogTool(\n\t\t\t\tllm=self._llm,\n\t\t\t\tembed_model=self._embed_model,\n\t\t\t)\n\t\t\tcreate_output = create_tool.call(user_id=user_id)\n\n\t\t\tabort = whether_abort_tool(tool_output=create_output)\n\t\t\tif abort is None or abort:\n\t\t\t\tstatus = (\n\t\t\t\t\tf\"The user does not want to continue, and abort the set experiment operation.\"\n\t\t\t\t\tf\"This conversation should be ended.\"\n\t\t\t\t)\n\t\t\t\tif abort is None:\n\t\t\t\t\tstatus = f\"The tool output of the CreateNewExperimentLogTool is invalid.\"\n\t\t\t\tfn_log = OperationOutputLog.construct(\n\t\t\t\t\toperation_name=create_tool.metadata.name,\n\t\t\t\t\toperation_output=status,\n\t\t\t\t\top_description=status,\n\t\t\t\t\toperation_abort=True,\n\t\t\t\t)\n\t\t\t\treturn FuncOutputWithLog(\n\t\t\t\t\tfn_output=status,\n\t\t\t\t\tfn_log={\"operation_log\": fn_log},\n\t\t\t\t)\n\n\t\tquery_str = SET_CURRENT_EXPERIMENT_MSG\n\t\toutput_log = self.collect_and_authorize(\n\t\t\tuser_id=user_id,\n\t\t\tquery_str=query_str,\n\t\t)\n\t\treturn output_log\n\n\tasync def aset_current_experiment(\n\t\tself,\n\t\tuser_id: str,\n\t) -&gt; FuncOutputWithLog:\n\t\tr\"\"\"\n\t\tThis tool is used to set the experiment in progress for the user, through interacting with the user.\n\t\tThis tool is used ONLY when the user ask for setting his/her experiment in progress,\n\t\tor when other tools call this tool.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user_id of a lab member.\n\n\t\tReturns:\n\t\t\tThe tool output and log.\n\t\t\"\"\"\n\t\tself.set_experiment_log_store(user_id=user_id)\n\t\texpr_list = self.expr_log_store.get_all_experiments()\n\t\tif expr_list is None:\n\t\t\tcreate_tool = CreateNewExperimentLogTool(\n\t\t\t\tllm=self._llm,\n\t\t\t\tembed_model=self._embed_model,\n\t\t\t)\n\t\t\tcreate_output = await create_tool.acall(user_id=user_id)\n\t\t\tabort = whether_abort_tool(tool_output=create_output)\n\t\t\tif abort is None or abort:\n\t\t\t\tstatus = (\n\t\t\t\t\tf\"The user does not want to continue, and abort the set experiment operation.\"\n\t\t\t\t\tf\"This conversation should be ended.\"\n\t\t\t\t)\n\t\t\t\tif abort is None:\n\t\t\t\t\tstatus = f\"The tool output of the CreateNewExperimentLogTool is invalid.\"\n\t\t\t\tfn_log = OperationOutputLog.construct(\n\t\t\t\t\toperation_name=create_tool.metadata.name,\n\t\t\t\t\toperation_output=status,\n\t\t\t\t\top_description=status,\n\t\t\t\t\toperation_abort=True,\n\t\t\t\t)\n\t\t\t\treturn FuncOutputWithLog(\n\t\t\t\t\tfn_output=status,\n\t\t\t\t\tfn_log={\"operation_log\": fn_log},\n\t\t\t\t)\n\n\t\tquery_str = SET_CURRENT_EXPERIMENT_MSG\n\t\toutput_log = await self.acollect_and_authorize(\n\t\t\tuser_id=user_id,\n\t\t\tquery_str=query_str,\n\t\t)\n\t\treturn output_log\n</code></pre>"},{"location":"code_docs/tools/memory/experiment/insert/#labridge.tools.memory.experiment.insert.SetCurrentExperimentTool.aset_current_experiment","title":"<code>labridge.tools.memory.experiment.insert.SetCurrentExperimentTool.aset_current_experiment(user_id)</code>  <code>async</code>","text":"<p>This tool is used to set the experiment in progress for the user, through interacting with the user. This tool is used ONLY when the user ask for setting his/her experiment in progress, or when other tools call this tool.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user_id of a lab member.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>FuncOutputWithLog</code> <p>The tool output and log.</p> Source code in <code>labridge\\tools\\memory\\experiment\\insert.py</code> <pre><code>async def aset_current_experiment(\n\tself,\n\tuser_id: str,\n) -&gt; FuncOutputWithLog:\n\tr\"\"\"\n\tThis tool is used to set the experiment in progress for the user, through interacting with the user.\n\tThis tool is used ONLY when the user ask for setting his/her experiment in progress,\n\tor when other tools call this tool.\n\n\tArgs:\n\t\tuser_id (str): The user_id of a lab member.\n\n\tReturns:\n\t\tThe tool output and log.\n\t\"\"\"\n\tself.set_experiment_log_store(user_id=user_id)\n\texpr_list = self.expr_log_store.get_all_experiments()\n\tif expr_list is None:\n\t\tcreate_tool = CreateNewExperimentLogTool(\n\t\t\tllm=self._llm,\n\t\t\tembed_model=self._embed_model,\n\t\t)\n\t\tcreate_output = await create_tool.acall(user_id=user_id)\n\t\tabort = whether_abort_tool(tool_output=create_output)\n\t\tif abort is None or abort:\n\t\t\tstatus = (\n\t\t\t\tf\"The user does not want to continue, and abort the set experiment operation.\"\n\t\t\t\tf\"This conversation should be ended.\"\n\t\t\t)\n\t\t\tif abort is None:\n\t\t\t\tstatus = f\"The tool output of the CreateNewExperimentLogTool is invalid.\"\n\t\t\tfn_log = OperationOutputLog.construct(\n\t\t\t\toperation_name=create_tool.metadata.name,\n\t\t\t\toperation_output=status,\n\t\t\t\top_description=status,\n\t\t\t\toperation_abort=True,\n\t\t\t)\n\t\t\treturn FuncOutputWithLog(\n\t\t\t\tfn_output=status,\n\t\t\t\tfn_log={\"operation_log\": fn_log},\n\t\t\t)\n\n\tquery_str = SET_CURRENT_EXPERIMENT_MSG\n\toutput_log = await self.acollect_and_authorize(\n\t\tuser_id=user_id,\n\t\tquery_str=query_str,\n\t)\n\treturn output_log\n</code></pre>"},{"location":"code_docs/tools/memory/experiment/insert/#labridge.tools.memory.experiment.insert.SetCurrentExperimentTool.required_info_dict","title":"<code>labridge.tools.memory.experiment.insert.SetCurrentExperimentTool.required_info_dict()</code>","text":"<p>The required information.</p> RETURNS DESCRIPTION <code>Dict[str, str]</code> <p>Dict[str, str]:</p> <ul> <li>key: the information name.</li> <li>value: the information description.</li> </ul> Source code in <code>labridge\\tools\\memory\\experiment\\insert.py</code> <pre><code>def required_info_dict(self) -&gt; Dict[str, str]:\n\tr\"\"\"\n\tThe required information.\n\n\tReturns:\n\t\tDict[str, str]:\n\n\t\t\t- key: the information name.\n\t\t\t- value: the information description.\n\t\"\"\"\n\treturn SET_CURRENT_EXPERIMENT_REQUIRED_INFOS\n</code></pre>"},{"location":"code_docs/tools/memory/experiment/insert/#labridge.tools.memory.experiment.insert.SetCurrentExperimentTool.required_infos","title":"<code>labridge.tools.memory.experiment.insert.SetCurrentExperimentTool.required_infos()</code>","text":"<p>The required infos.</p> RETURNS DESCRIPTION <code>List[CollectingInfoBase]</code> <p>List[CollectingInfoBase]: Return the packed info in CollectingInfoBase, such as <code>CollectingCommonInfo</code> and <code>CollectingSelectInfo</code>.</p> Source code in <code>labridge\\tools\\memory\\experiment\\insert.py</code> <pre><code>def required_infos(self) -&gt; List[CollectingInfoBase]:\n\tr\"\"\"\n\tThe required infos.\n\n\tReturns:\n\t\tList[CollectingInfoBase]:\n\t\t\tReturn the packed info in CollectingInfoBase, such as `CollectingCommonInfo` and `CollectingSelectInfo`.\n\t\"\"\"\n\texperiments = self.expr_log_store.get_all_experiments_with_description()\n\tselect_name_info = CollectingSelectInfo(\n\t\tinfo_name=CURRENT_EXPERIMENT_NAME_KEY,\n\t\tinfo_description=self.required_info_dict()[CURRENT_EXPERIMENT_NAME_KEY],\n\t\tchoices=experiments,\n\t)\n\n\tduration_info = CollectingCommonInfo(\n\t\tinfo_name=CURRENT_EXPERIMENT_DURATION_KEY,\n\t\tinfo_description=self.required_info_dict()[CURRENT_EXPERIMENT_DURATION_KEY]\n\t)\n\treturn [select_name_info, duration_info]\n</code></pre>"},{"location":"code_docs/tools/memory/experiment/insert/#labridge.tools.memory.experiment.insert.SetCurrentExperimentTool.set_current_experiment","title":"<code>labridge.tools.memory.experiment.insert.SetCurrentExperimentTool.set_current_experiment(user_id)</code>","text":"<p>This tool is used to set the experiment in progress for the user, through interacting with the user. This tool is used ONLY when the user ask for setting his/her experiment in progress, or when other tools call this tool.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user_id of a lab member.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>FuncOutputWithLog</code> <p>The tool output and log.</p> Source code in <code>labridge\\tools\\memory\\experiment\\insert.py</code> <pre><code>def set_current_experiment(\n\tself,\n\tuser_id: str,\n) -&gt; FuncOutputWithLog:\n\tr\"\"\"\n\tThis tool is used to set the experiment in progress for the user, through interacting with the user.\n\tThis tool is used ONLY when the user ask for setting his/her experiment in progress,\n\tor when other tools call this tool.\n\n\tArgs:\n\t\tuser_id (str): The user_id of a lab member.\n\n\tReturns:\n\t\tThe tool output and log.\n\t\"\"\"\n\t# This docstring is used as tool description.\n\tself.set_experiment_log_store(user_id=user_id)\n\n\texpr_list = self.expr_log_store.get_all_experiments()\n\n\tif expr_list is None:\n\t\tcreate_tool = CreateNewExperimentLogTool(\n\t\t\tllm=self._llm,\n\t\t\tembed_model=self._embed_model,\n\t\t)\n\t\tcreate_output = create_tool.call(user_id=user_id)\n\n\t\tabort = whether_abort_tool(tool_output=create_output)\n\t\tif abort is None or abort:\n\t\t\tstatus = (\n\t\t\t\tf\"The user does not want to continue, and abort the set experiment operation.\"\n\t\t\t\tf\"This conversation should be ended.\"\n\t\t\t)\n\t\t\tif abort is None:\n\t\t\t\tstatus = f\"The tool output of the CreateNewExperimentLogTool is invalid.\"\n\t\t\tfn_log = OperationOutputLog.construct(\n\t\t\t\toperation_name=create_tool.metadata.name,\n\t\t\t\toperation_output=status,\n\t\t\t\top_description=status,\n\t\t\t\toperation_abort=True,\n\t\t\t)\n\t\t\treturn FuncOutputWithLog(\n\t\t\t\tfn_output=status,\n\t\t\t\tfn_log={\"operation_log\": fn_log},\n\t\t\t)\n\n\tquery_str = SET_CURRENT_EXPERIMENT_MSG\n\toutput_log = self.collect_and_authorize(\n\t\tuser_id=user_id,\n\t\tquery_str=query_str,\n\t)\n\treturn output_log\n</code></pre>"},{"location":"code_docs/tools/memory/experiment/insert/#labridge.tools.memory.experiment.insert.SetCurrentExperimentTool.set_experiment_log_store","title":"<code>labridge.tools.memory.experiment.insert.SetCurrentExperimentTool.set_experiment_log_store(user_id)</code>","text":"<p>Load the user's experiment log storage.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user_id of a lab member.</p> <p> TYPE: <code>str</code> </p> Source code in <code>labridge\\tools\\memory\\experiment\\insert.py</code> <pre><code>def set_experiment_log_store(self, user_id: str):\n\tr\"\"\"\n\tLoad the user's experiment log storage.\n\n\tArgs:\n\t\tuser_id (str): The user_id of a lab member.\n\t\"\"\"\n\tif self.expr_log_store is None or self.expr_log_store.user_id != user_id:\n\t\tself.expr_log_store = ExperimentLog.from_user_id(\n\t\t\tuser_id=user_id,\n\t\t\tembed_model=self._embed_model,\n\t\t)\n</code></pre>"},{"location":"code_docs/tools/memory/experiment/retrieve/","title":"Retrieve","text":""},{"location":"code_docs/tools/memory/experiment/retrieve/#labridge.tools.memory.experiment.retrieve","title":"<code>labridge.tools.memory.experiment.retrieve</code>","text":""},{"location":"code_docs/tools/memory/experiment/retrieve/#labridge.tools.memory.experiment.retrieve.ExperimentLogRetrieveTool","title":"<code>labridge.tools.memory.experiment.retrieve.ExperimentLogRetrieveTool</code>","text":"<p>               Bases: <code>RetrieverBaseTool</code></p> <p>This tool is used to retrieve the relevant experiment log in the user's experiment log storage. The tool description is set as the docstring of the method <code>retrieve</code> of the <code>retriever</code>.</p> PARAMETER DESCRIPTION <code>embed_model</code> <p>The used embedding model. If not specified, the <code>Setting.embed_model</code> will be used.</p> <p> TYPE: <code>BaseEmbedding</code> DEFAULT: <code>None</code> </p> <code>final_use_context</code> <p>Whether to add the context nodes to the final retrieving results.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>relevant_top_k</code> <p>The top-k relevant nodes will be used as the retrieved results.</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> Source code in <code>labridge\\tools\\memory\\experiment\\retrieve.py</code> <pre><code>class ExperimentLogRetrieveTool(RetrieverBaseTool):\n\tr\"\"\"\n\tThis tool is used to retrieve the relevant experiment log in the user's experiment log storage.\n\tThe tool description is set as the docstring of the method `retrieve` of the `retriever`.\n\n\tArgs:\n\t\tembed_model (BaseEmbedding): The used embedding model. If not specified, the `Setting.embed_model` will be used.\n\t\tfinal_use_context (bool): Whether to add the context nodes to the final retrieving results.\n\t\trelevant_top_k (int): The top-k relevant nodes will be used as the retrieved results.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tembed_model: BaseEmbedding = None,\n\t\tfinal_use_context: bool = True,\n\t\trelevant_top_k: int = None,\n\t):\n\t\tretriever = ExperimentLogRetriever(\n\t\t\tembed_model=embed_model,\n\t\t\tfinal_use_context=final_use_context,\n\t\t\trelevant_top_k=relevant_top_k,\n\t\t)\n\t\tsuper().__init__(\n\t\t\tname=ExperimentLogRetrieveTool.__name__,\n\t\t\tretriever=retriever,\n\t\t\tretrieve_fn=retriever.retrieve,\n\t\t)\n\n\tdef log(self, log_dict: dict) -&gt; ToolLog:\n\t\tr\"\"\"\n\t\tRecord the tool log.\n\n\t\tArgs:\n\t\t\tlog_dict (dict): Including the input keyword arguments and the (output, log) of retrieving.\n\n\t\tReturns:\n\t\t\tThe tool log.\n\t\t\"\"\"\n\t\tuser_id = log_dict[\"memory_id\"]\n\t\titem_to_be_retrieved = log_dict[\"item_to_be_retrieved\"]\n\t\tstart_date = log_dict.get(\"start_date\", None)\n\t\tend_date = log_dict.get(\"end_date\", None)\n\n\t\tref_infos: List[ExperimentLogRefInfo] = log_dict.get(TOOL_LOG_REF_INFO_KEY)\n\n\t\tlog_string = (\n\t\t\tf\"Retrieve in the experiment log memory of the user: {user_id}.\\n\"\n\t\t\tf\"retrieve string: {item_to_be_retrieved}\\n\"\n\t\t)\n\t\tif None not in [start_date, end_date]:\n\t\t\tlog_string += (\n\t\t\t\tf\"start_date: {start_date}\\n\"\n\t\t\t\tf\"end_date: {end_date}\"\n\t\t\t)\n\n\t\tlog_to_user = None\n\t\tlog_to_system = {\n\t\t\tTOOL_OP_DESCRIPTION: log_string,\n\t\t\tTOOL_REFERENCES: [ref_info.dumps() for ref_info in ref_infos],\n\t\t}\n\t\treturn ToolLog(\n\t\t\tlog_to_user=log_to_user,\n\t\t\tlog_to_system=log_to_system,\n\t\t\ttool_name=self.metadata.name,\n\t\t)\n\n\tdef get_ref_info(self, nodes: List[NodeWithScore]) -&gt; List[ExperimentLogRefInfo]:\n\t\tr\"\"\"\n\t\tGet the reference paper infos\n\n\t\tReturns:\n\t\t\tList[PaperInfo]: The reference paper infos in answering.\n\t\t\"\"\"\n\t\tref_infos = []\n\t\tfor node_score in nodes:\n\t\t\tmetadata = node_score.node.metadata\n\t\t\tlog_str = node_score.node.text\n\t\t\texperiment_name = node_score.node.parent_node.node_id\n\t\t\tattachment_path = metadata.get(EXPERIMENT_LOG_ATTACHMENT_KEY, None)\n\t\t\tdate = metadata.get(LOG_DATE_NAME)\n\t\t\th_m_s = metadata.get(LOG_TIME_NAME)\n\t\t\tlog_ref_info = ExperimentLogRefInfo(\n\t\t\t\tdate_time=f\"{date} {h_m_s}\",\n\t\t\t\tlog_str=log_str,\n\t\t\t\tattachment_path=attachment_path,\n\t\t\t\texperiment_name=experiment_name,\n\t\t\t)\n\t\t\tref_infos.append(log_ref_info)\n\t\treturn ref_infos\n\n\tdef _retrieve(self, retrieve_kwargs: dict) -&gt; List[NodeWithScore]:\n\t\tr\"\"\" Use the retriever to retrieve relevant nodes. \"\"\"\n\t\tnodes = self._retriever.retrieve(**retrieve_kwargs)\n\t\treturn nodes\n\n\tasync def _aretrieve(self, retrieve_kwargs: dict) -&gt; List[NodeWithScore]:\n\t\tr\"\"\" Asynchronously use the retriever to retrieve relevant nodes. \"\"\"\n\t\tnodes = await self._retriever.aretrieve(**retrieve_kwargs)\n\t\treturn nodes\n\n\tdef _nodes_to_tool_output(self, nodes: List[NodeWithScore]) -&gt; Tuple[str, dict]:\n\t\tr\"\"\" output the retrieved contents in a specific format, and the output log. \"\"\"\n\t\texpr_nodes_dict = {}\n\n\t\tref_infos = self.get_ref_info(nodes=nodes)\n\t\tlog_dict = {\n\t\t\tTOOL_LOG_REF_INFO_KEY: ref_infos,\n\t\t}\n\n\t\tfor node in nodes:\n\t\t\texpr_node = node.node.parent_node\n\t\t\tif expr_node is not None:\n\t\t\t\tif expr_node.node_id not in expr_nodes_dict.keys():\n\t\t\t\t\texpr_nodes_dict[expr_node.node_id] = [node]\n\t\t\t\telse:\n\t\t\t\t\texpr_nodes_dict[expr_node.node_id].append(node)\n\n\t\tif expr_nodes_dict:\n\t\t\tmsg = \"Have retrieved the following experiment logs:\"\n\t\t\tcontents = [msg]\n\t\t\tfor expr_name in expr_nodes_dict.keys():\n\t\t\t\tmsg = f\"The following logs are from the experiment: {expr_name}\"\n\t\t\t\tcontents.append(msg)\n\t\t\t\tfor idx, node in enumerate(expr_nodes_dict[expr_name]):\n\t\t\t\t\tcontent_str = (\n\t\t\t\t\t\tf\"Log {idx + 1}:\\n\"\n\t\t\t\t\t\tf\"{node.node.get_content(metadata_mode=MetadataMode.LLM)}\"\n\t\t\t\t\t)\n\t\t\t\t\tcontents.append(content_str.strip())\n\t\t\toutput_str = \"\\n\\n\".join(contents)\n\t\telse:\n\t\t\toutput_str = \"Have retrieved nothing relevant.\"\n\t\treturn output_str, log_dict\n</code></pre>"},{"location":"code_docs/tools/memory/experiment/retrieve/#labridge.tools.memory.experiment.retrieve.ExperimentLogRetrieveTool.get_ref_info","title":"<code>labridge.tools.memory.experiment.retrieve.ExperimentLogRetrieveTool.get_ref_info(nodes)</code>","text":"<p>Get the reference paper infos</p> RETURNS DESCRIPTION <code>List[ExperimentLogRefInfo]</code> <p>List[PaperInfo]: The reference paper infos in answering.</p> Source code in <code>labridge\\tools\\memory\\experiment\\retrieve.py</code> <pre><code>def get_ref_info(self, nodes: List[NodeWithScore]) -&gt; List[ExperimentLogRefInfo]:\n\tr\"\"\"\n\tGet the reference paper infos\n\n\tReturns:\n\t\tList[PaperInfo]: The reference paper infos in answering.\n\t\"\"\"\n\tref_infos = []\n\tfor node_score in nodes:\n\t\tmetadata = node_score.node.metadata\n\t\tlog_str = node_score.node.text\n\t\texperiment_name = node_score.node.parent_node.node_id\n\t\tattachment_path = metadata.get(EXPERIMENT_LOG_ATTACHMENT_KEY, None)\n\t\tdate = metadata.get(LOG_DATE_NAME)\n\t\th_m_s = metadata.get(LOG_TIME_NAME)\n\t\tlog_ref_info = ExperimentLogRefInfo(\n\t\t\tdate_time=f\"{date} {h_m_s}\",\n\t\t\tlog_str=log_str,\n\t\t\tattachment_path=attachment_path,\n\t\t\texperiment_name=experiment_name,\n\t\t)\n\t\tref_infos.append(log_ref_info)\n\treturn ref_infos\n</code></pre>"},{"location":"code_docs/tools/memory/experiment/retrieve/#labridge.tools.memory.experiment.retrieve.ExperimentLogRetrieveTool.log","title":"<code>labridge.tools.memory.experiment.retrieve.ExperimentLogRetrieveTool.log(log_dict)</code>","text":"<p>Record the tool log.</p> PARAMETER DESCRIPTION <code>log_dict</code> <p>Including the input keyword arguments and the (output, log) of retrieving.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>ToolLog</code> <p>The tool log.</p> Source code in <code>labridge\\tools\\memory\\experiment\\retrieve.py</code> <pre><code>def log(self, log_dict: dict) -&gt; ToolLog:\n\tr\"\"\"\n\tRecord the tool log.\n\n\tArgs:\n\t\tlog_dict (dict): Including the input keyword arguments and the (output, log) of retrieving.\n\n\tReturns:\n\t\tThe tool log.\n\t\"\"\"\n\tuser_id = log_dict[\"memory_id\"]\n\titem_to_be_retrieved = log_dict[\"item_to_be_retrieved\"]\n\tstart_date = log_dict.get(\"start_date\", None)\n\tend_date = log_dict.get(\"end_date\", None)\n\n\tref_infos: List[ExperimentLogRefInfo] = log_dict.get(TOOL_LOG_REF_INFO_KEY)\n\n\tlog_string = (\n\t\tf\"Retrieve in the experiment log memory of the user: {user_id}.\\n\"\n\t\tf\"retrieve string: {item_to_be_retrieved}\\n\"\n\t)\n\tif None not in [start_date, end_date]:\n\t\tlog_string += (\n\t\t\tf\"start_date: {start_date}\\n\"\n\t\t\tf\"end_date: {end_date}\"\n\t\t)\n\n\tlog_to_user = None\n\tlog_to_system = {\n\t\tTOOL_OP_DESCRIPTION: log_string,\n\t\tTOOL_REFERENCES: [ref_info.dumps() for ref_info in ref_infos],\n\t}\n\treturn ToolLog(\n\t\tlog_to_user=log_to_user,\n\t\tlog_to_system=log_to_system,\n\t\ttool_name=self.metadata.name,\n\t)\n</code></pre>"},{"location":"code_docs/tools/paper/download/arxiv_download/","title":"Arxiv download","text":""},{"location":"code_docs/tools/paper/download/arxiv_download/#labridge.tools.paper.download.arxiv_download","title":"<code>labridge.tools.paper.download.arxiv_download</code>","text":""},{"location":"code_docs/tools/paper/download/arxiv_download/#labridge.tools.paper.download.arxiv_download.ArXivSearchDownloadTool","title":"<code>labridge.tools.paper.download.arxiv_download.ArXivSearchDownloadTool</code>","text":"<p>               Bases: <code>CallBackBaseTool</code></p> <p>This tool is used to search and download papers from arXiv.org for the user.</p> PARAMETER DESCRIPTION <code>llm</code> <p>The used LLM.</p> <p> TYPE: <code>LLM</code> DEFAULT: <code>None</code> </p> <code>embed_model</code> <p>The used embedding model.</p> <p> TYPE: <code>BaseEmbedding</code> DEFAULT: <code>None</code> </p> <code>verbose</code> <p>Whether to show the inner progress.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>max_results_num</code> <p>The maximum search results that are presented to the user. The actually used value is <code>min(max_results_num, MAX_SEARCH_RESULTS_NUM)</code>.</p> <p> TYPE: <code>int</code> DEFAULT: <code>3</code> </p> Source code in <code>labridge\\tools\\paper\\download\\arxiv_download.py</code> <pre><code>class ArXivSearchDownloadTool(CallBackBaseTool):\n\tr\"\"\"\n\tThis tool is used to search and download papers from arXiv.org for the user.\n\n\tArgs:\n\t\tllm (LLM): The used LLM.\n\t\tembed_model (BaseEmbedding): The used embedding model.\n\t\tverbose (bool): Whether to show the inner progress.\n\t\tmax_results_num (int): The maximum search results that are presented to the user.\n\t\t\tThe actually used value is `min(max_results_num, MAX_SEARCH_RESULTS_NUM)`.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tllm: LLM = None,\n\t\tembed_model: BaseEmbedding = None,\n\t\tverbose: bool = False,\n\t\tmax_results_num: int = 3,\n\t):\n\t\tself._llm = llm or Settings.llm\n\t\tself._embed_model = embed_model or Settings.embed_model\n\t\tself._verbose = verbose\n\t\tself._max_results_num = min(max_results_num, MAX_SEARCH_RESULTS_NUM)\n\t\tsuper().__init__(\n\t\t\tfn=self.search_download_pipeline,\n\t\t\tasync_fn=self.asearch_download_pipeline,\n\t\t\ttool_name=ArXivSearchDownloadTool.__name__,\n\t\t\tcallback_operation=ArxivDownloadOperation,\n\t\t)\n\t\tself.account_manager = AccountManager()\n\n\tdef _user_select_results(self, user_id: str, results: List[Result]) -&gt; Tuple[List[int], str]:\n\t\tr\"\"\" Let the user select among the candidate papers \"\"\"\n\t\tselect_info = self._select_query(results=results)\n\t\t# TODO: Send the query str to the user.\n\t\tprint(USER_SELECT_ARXIV_PAPERS_QUERY)\n\t\tprint(select_info)\n\t\t# TODO receive the message from the user.\n\t\tuser_msg = ChatBuffer.test_get_user_text(user_id=user_id)\n\t\tuser_response = user_msg.user_msg\n\t\tif user_response is None:\n\t\t\traise RuntimeError(\"The User does not reply.\")\n\n\t\tnumbers = self._parse_user_select(\n\t\t\tuser_response=user_response,\n\t\t\tresult_num=len(results),\n\t\t)\n\t\tindices = [n - 1 for n in numbers]\n\t\treturn indices, user_response\n\n\tasync def _auser_select_results(self, user_id: str, results: List[Result]) -&gt; Tuple[List[int], str]:\n\t\tr\"\"\" Let the user select among the candidate papers \"\"\"\n\t\tselect_info = self._select_query(results=results)\n\t\t# TODO: Send the query str to the user.\n\t\tChatBuffer.put_agent_reply(\n\t\t\tuser_id=user_id,\n\t\t\treply_str=USER_SELECT_ARXIV_PAPERS_QUERY,\n\t\t\tinner_chat=True,\n\t\t\textra_info=select_info,\n\t\t)\n\n\t\t# TODO receive the message from the user.\n\t\tuser_msg = await ChatBuffer.get_user_msg(user_id=user_id)\n\t\tuser_response = user_msg.user_msg\n\n\t\tnumbers = self._parse_user_select(\n\t\t\tuser_response=user_response,\n\t\t\tresult_num=len(results),\n\t\t)\n\t\tindices = [n - 1 for n in numbers]\n\t\treturn indices, user_response\n\n\t@staticmethod\n\tdef _parse_user_select(user_response: str, result_num: int) -&gt; List[int]:\n\t\tr\"\"\" parse the user response to select numbers \"\"\"\n\t\tnumbers = []\n\t\tdigit_stack = []\n\t\tfor char in user_response:\n\t\t\tif char.isdigit():\n\t\t\t\tdigit_stack.append(char)\n\t\t\telse:\n\t\t\t\tif digit_stack:\n\t\t\t\t\tnumber = int(\"\".join(digit_stack))\n\t\t\t\t\tif 0 &lt; number &lt;= result_num:\n\t\t\t\t\t\tnumbers.append(int(number))\n\t\t\t\t\tdigit_stack = []\n\t\telse:\n\t\t\tif digit_stack:\n\t\t\t\tnumber = int(\"\".join(digit_stack))\n\t\t\t\tif 0 &lt; number &lt;= result_num:\n\t\t\t\t\tnumbers.append(int(number))\n\t\treturn numbers\n\n\t@staticmethod\n\tdef _select_query(results: List[Result]) -&gt; str:\n\t\tr\"\"\" The message including the searched paper infos. \"\"\"\n\t\tpapers = []\n\t\tfor idx, result in enumerate(results):\n\t\t\tpaper_info = ARXIV_PAPER_INFO_TMPL.format(\n\t\t\t\tpaper_idx=idx + 1,\n\t\t\t\ttitle=result.title,\n\t\t\t\tabstract=result.summary,\n\t\t\t)\n\t\t\tpapers.append(paper_info)\n\t\tquery_str = \"\\n\\n\".join(papers)\n\t\treturn query_str\n\n\tdef log(self, *args, **kwargs) -&gt; ToolLog:\n\t\top_log: OperationOutputLog = kwargs[\"operation_log\"]\n\n\t\tif not isinstance(op_log, OperationOutputLog):\n\t\t\traise ValueError(\"operation_log must be 'OperationLog'.\")\n\n\t\tlog_to_user = op_log.log_to_user\n\t\tlog_to_system = {\n\t\t\tTOOL_OP_DESCRIPTION: op_log.log_to_system[OP_DESCRIPTION],\n\t\t\tTOOL_REFERENCES: op_log.log_to_system[OP_REFERENCES],\n\t\t}\n\n\t\treturn ToolLog(\n\t\t\ttool_name=self.metadata.name,\n\t\t\tlog_to_system=log_to_system,\n\t\t\tlog_to_user=log_to_user,\n\t\t)\n\n\tdef search_download_pipeline(\n\t\tself,\n\t\tuser_id: str,\n\t\tsearch_str: str,\n\t\t**kwargs,\n\t) -&gt; FuncOutputWithLog:\n\t\tr\"\"\"\n\t\tThis tool is used to search relevant papers in arXiv and download the papers that the user is interested in.\n\t\tWhen using the tool, be sure that the search_str MUST be English.\n\t\tIf the user do not use English, translate the search string to English first.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user_id of a lab member.\n\t\t\tsearch_str (str): The string that is used to search in arXiv.\n\n\t\tReturns:\n\t\t\tFuncOutputWithLog: the operation output and log.\n\t\t\"\"\"\n\t\tself.account_manager.check_valid_user(user_id=user_id)\n\n\t\tresults = search_arxiv(search_str=search_str, max_results_num=self._max_results_num)\n\t\tindices, user_response = self._user_select_results(user_id=user_id, results=results)\n\n\t\tif len(indices) &lt; 1:\n\t\t\toperation_log_str = (\n\t\t\t\tf\"The user has no interest to the searched papers, end download operation.\\n\"\n\t\t\t\tf\"This is the user's response: {user_response}\"\n\t\t\t)\n\t\t\toperation_log = OperationOutputLog(\n\t\t\t\toperation_name=self._callback_operation.__name__,\n\t\t\t\toperation_output=None,\n\t\t\t\tlog_to_user=None,\n\t\t\t\tlog_to_system={\n\t\t\t\t\tOP_DESCRIPTION: operation_log_str,\n\t\t\t\t\tOP_REFERENCES: None,\n\t\t\t\t}\n\t\t\t)\n\t\t\tlog_dict = {\"operation_log\": operation_log}\n\t\t\treturn FuncOutputWithLog(\n\t\t\t\tfn_output=operation_log_str,\n\t\t\t\tfn_log=log_dict,\n\t\t\t)\n\n\t\tpaper_infos = list()\n\t\tfor idx in indices:\n\t\t\tpaper = results[idx]\n\t\t\tpaper_infos.append(\n\t\t\t\t{\n\t\t\t\t\t\"title\": paper.title,\n\t\t\t\t\t\"abstract\": paper.summary,\n\t\t\t\t\t\"pdf_url\": paper.pdf_url,\n\t\t\t\t}\n\t\t\t)\n\n\t\top_name = ArxivDownloadOperation.__name__\n\t\tkwargs = {\n\t\t\t\"user_id\": user_id,\n\t\t\t\"paper_infos\": paper_infos\n\t\t}\n\t\tkwargs_str = json.dumps(kwargs)\n\t\toperation_log = operation_authorize(\n\t\t\tuser_id=user_id,\n\t\t\top_name=op_name,\n\t\t\tkwargs_str=kwargs_str,\n\t\t\tllm=self._llm,\n\t\t\tembed_model=self._embed_model,\n\t\t\tverbose=self._verbose,\n\t\t)\n\t\tlog_dict = {\"operation_log\": operation_log}\n\t\treturn FuncOutputWithLog(\n\t\t\tfn_output=f\"Have downloaded papers for user {user_id}\",\n\t\t\tfn_log=log_dict,\n\t\t)\n\n\tasync def asearch_download_pipeline(\n\t\tself,\n\t\tuser_id: str,\n\t\tsearch_str: str,\n\t\t**kwargs,\n\t) -&gt; FuncOutputWithLog:\n\t\tr\"\"\"\n\t\tThis tool is used to search relevant papers in arXiv and download the papers that the user is interested in.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user_id of a lab member.\n\t\t\tsearch_str (str): The search string.\n\n\t\tReturns:\n\t\t\tFuncOutputWithLog: the operation output and log.\n\t\t\"\"\"\n\t\tself.account_manager.check_valid_user(user_id=user_id)\n\n\t\tresults = search_arxiv(search_str=search_str, max_results_num=self._max_results_num)\n\t\tindices, user_response = await self._auser_select_results(user_id=user_id, results=results)\n\n\t\tif len(indices) &lt; 1:\n\t\t\toperation_log_str = (\n\t\t\t\tf\"The user has no interest to the searched papers, end download operation.\\n\"\n\t\t\t\tf\"This is the user's response: {user_response}\"\n\t\t\t)\n\t\t\toperation_log = OperationOutputLog(\n\t\t\t\toperation_name=self._callback_operation.__name__,\n\t\t\t\toperation_output=None,\n\t\t\t\tlog_to_user=None,\n\t\t\t\tlog_to_system={OP_DESCRIPTION: operation_log_str,\n\t\t\t\t\tOP_REFERENCES: None,\n\t\t\t\t}\n\t\t\t)\n\t\t\tlog_dict = {\"operation_log\": operation_log}\n\t\t\treturn FuncOutputWithLog(\n\t\t\t\tfn_output=operation_log_str,\n\t\t\t\tfn_log=log_dict,\n\t\t\t)\n\n\t\tpaper_infos = list()\n\t\tfor idx in indices:\n\t\t\tpaper = results[idx]\n\t\t\tpaper_infos.append(\n\t\t\t\t{\n\t\t\t\t\t\"title\": paper.title,\n\t\t\t\t\t\"abstract\": paper.summary,\n\t\t\t\t\t\"pdf_url\": paper.pdf_url,\n\t\t\t\t}\n\t\t\t)\n\n\t\top_name = ArxivDownloadOperation.__name__\n\t\tkwargs = {\n\t\t\t\"user_id\": user_id,\n\t\t\t\"paper_infos\": paper_infos\n\t\t}\n\t\tkwargs_str = json.dumps(kwargs)\n\t\toperation_log = await aoperation_authorize(\n\t\t\tuser_id=user_id,\n\t\t\top_name=op_name,\n\t\t\tkwargs_str=kwargs_str,\n\t\t\tllm=self._llm,\n\t\t\tembed_model=self._embed_model,\n\t\t\tverbose=self._verbose,\n\t\t)\n\t\tlog_dict = {\"operation_log\": operation_log}\n\t\treturn FuncOutputWithLog(\n\t\t\tfn_output=f\"Have downloaded papers for user {user_id}\",\n\t\t\tfn_log=log_dict,\n\t\t)\n</code></pre>"},{"location":"code_docs/tools/paper/download/arxiv_download/#labridge.tools.paper.download.arxiv_download.ArXivSearchDownloadTool.asearch_download_pipeline","title":"<code>labridge.tools.paper.download.arxiv_download.ArXivSearchDownloadTool.asearch_download_pipeline(user_id, search_str, **kwargs)</code>  <code>async</code>","text":"<p>This tool is used to search relevant papers in arXiv and download the papers that the user is interested in.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user_id of a lab member.</p> <p> TYPE: <code>str</code> </p> <code>search_str</code> <p>The search string.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>FuncOutputWithLog</code> <p>the operation output and log.</p> <p> TYPE: <code>FuncOutputWithLog</code> </p> Source code in <code>labridge\\tools\\paper\\download\\arxiv_download.py</code> <pre><code>async def asearch_download_pipeline(\n\tself,\n\tuser_id: str,\n\tsearch_str: str,\n\t**kwargs,\n) -&gt; FuncOutputWithLog:\n\tr\"\"\"\n\tThis tool is used to search relevant papers in arXiv and download the papers that the user is interested in.\n\n\tArgs:\n\t\tuser_id (str): The user_id of a lab member.\n\t\tsearch_str (str): The search string.\n\n\tReturns:\n\t\tFuncOutputWithLog: the operation output and log.\n\t\"\"\"\n\tself.account_manager.check_valid_user(user_id=user_id)\n\n\tresults = search_arxiv(search_str=search_str, max_results_num=self._max_results_num)\n\tindices, user_response = await self._auser_select_results(user_id=user_id, results=results)\n\n\tif len(indices) &lt; 1:\n\t\toperation_log_str = (\n\t\t\tf\"The user has no interest to the searched papers, end download operation.\\n\"\n\t\t\tf\"This is the user's response: {user_response}\"\n\t\t)\n\t\toperation_log = OperationOutputLog(\n\t\t\toperation_name=self._callback_operation.__name__,\n\t\t\toperation_output=None,\n\t\t\tlog_to_user=None,\n\t\t\tlog_to_system={OP_DESCRIPTION: operation_log_str,\n\t\t\t\tOP_REFERENCES: None,\n\t\t\t}\n\t\t)\n\t\tlog_dict = {\"operation_log\": operation_log}\n\t\treturn FuncOutputWithLog(\n\t\t\tfn_output=operation_log_str,\n\t\t\tfn_log=log_dict,\n\t\t)\n\n\tpaper_infos = list()\n\tfor idx in indices:\n\t\tpaper = results[idx]\n\t\tpaper_infos.append(\n\t\t\t{\n\t\t\t\t\"title\": paper.title,\n\t\t\t\t\"abstract\": paper.summary,\n\t\t\t\t\"pdf_url\": paper.pdf_url,\n\t\t\t}\n\t\t)\n\n\top_name = ArxivDownloadOperation.__name__\n\tkwargs = {\n\t\t\"user_id\": user_id,\n\t\t\"paper_infos\": paper_infos\n\t}\n\tkwargs_str = json.dumps(kwargs)\n\toperation_log = await aoperation_authorize(\n\t\tuser_id=user_id,\n\t\top_name=op_name,\n\t\tkwargs_str=kwargs_str,\n\t\tllm=self._llm,\n\t\tembed_model=self._embed_model,\n\t\tverbose=self._verbose,\n\t)\n\tlog_dict = {\"operation_log\": operation_log}\n\treturn FuncOutputWithLog(\n\t\tfn_output=f\"Have downloaded papers for user {user_id}\",\n\t\tfn_log=log_dict,\n\t)\n</code></pre>"},{"location":"code_docs/tools/paper/download/arxiv_download/#labridge.tools.paper.download.arxiv_download.ArXivSearchDownloadTool.search_download_pipeline","title":"<code>labridge.tools.paper.download.arxiv_download.ArXivSearchDownloadTool.search_download_pipeline(user_id, search_str, **kwargs)</code>","text":"<p>This tool is used to search relevant papers in arXiv and download the papers that the user is interested in. When using the tool, be sure that the search_str MUST be English. If the user do not use English, translate the search string to English first.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user_id of a lab member.</p> <p> TYPE: <code>str</code> </p> <code>search_str</code> <p>The string that is used to search in arXiv.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>FuncOutputWithLog</code> <p>the operation output and log.</p> <p> TYPE: <code>FuncOutputWithLog</code> </p> Source code in <code>labridge\\tools\\paper\\download\\arxiv_download.py</code> <pre><code>def search_download_pipeline(\n\tself,\n\tuser_id: str,\n\tsearch_str: str,\n\t**kwargs,\n) -&gt; FuncOutputWithLog:\n\tr\"\"\"\n\tThis tool is used to search relevant papers in arXiv and download the papers that the user is interested in.\n\tWhen using the tool, be sure that the search_str MUST be English.\n\tIf the user do not use English, translate the search string to English first.\n\n\tArgs:\n\t\tuser_id (str): The user_id of a lab member.\n\t\tsearch_str (str): The string that is used to search in arXiv.\n\n\tReturns:\n\t\tFuncOutputWithLog: the operation output and log.\n\t\"\"\"\n\tself.account_manager.check_valid_user(user_id=user_id)\n\n\tresults = search_arxiv(search_str=search_str, max_results_num=self._max_results_num)\n\tindices, user_response = self._user_select_results(user_id=user_id, results=results)\n\n\tif len(indices) &lt; 1:\n\t\toperation_log_str = (\n\t\t\tf\"The user has no interest to the searched papers, end download operation.\\n\"\n\t\t\tf\"This is the user's response: {user_response}\"\n\t\t)\n\t\toperation_log = OperationOutputLog(\n\t\t\toperation_name=self._callback_operation.__name__,\n\t\t\toperation_output=None,\n\t\t\tlog_to_user=None,\n\t\t\tlog_to_system={\n\t\t\t\tOP_DESCRIPTION: operation_log_str,\n\t\t\t\tOP_REFERENCES: None,\n\t\t\t}\n\t\t)\n\t\tlog_dict = {\"operation_log\": operation_log}\n\t\treturn FuncOutputWithLog(\n\t\t\tfn_output=operation_log_str,\n\t\t\tfn_log=log_dict,\n\t\t)\n\n\tpaper_infos = list()\n\tfor idx in indices:\n\t\tpaper = results[idx]\n\t\tpaper_infos.append(\n\t\t\t{\n\t\t\t\t\"title\": paper.title,\n\t\t\t\t\"abstract\": paper.summary,\n\t\t\t\t\"pdf_url\": paper.pdf_url,\n\t\t\t}\n\t\t)\n\n\top_name = ArxivDownloadOperation.__name__\n\tkwargs = {\n\t\t\"user_id\": user_id,\n\t\t\"paper_infos\": paper_infos\n\t}\n\tkwargs_str = json.dumps(kwargs)\n\toperation_log = operation_authorize(\n\t\tuser_id=user_id,\n\t\top_name=op_name,\n\t\tkwargs_str=kwargs_str,\n\t\tllm=self._llm,\n\t\tembed_model=self._embed_model,\n\t\tverbose=self._verbose,\n\t)\n\tlog_dict = {\"operation_log\": operation_log}\n\treturn FuncOutputWithLog(\n\t\tfn_output=f\"Have downloaded papers for user {user_id}\",\n\t\tfn_log=log_dict,\n\t)\n</code></pre>"},{"location":"code_docs/tools/paper/download/arxiv_download/#labridge.tools.paper.download.arxiv_download.search_arxiv","title":"<code>labridge.tools.paper.download.arxiv_download.search_arxiv(search_str, max_results_num=3)</code>","text":"<p>Search in aXiv.org</p> PARAMETER DESCRIPTION <code>search_str</code> <p>the search string.</p> <p> TYPE: <code>str</code> </p> <code>max_results_num</code> <p>the maximum number of returned results. Defaults to 3.</p> <p> TYPE: <code>int</code> DEFAULT: <code>3</code> </p> RETURNS DESCRIPTION <code>List[Result]</code> <p>the paper info results.</p> Source code in <code>labridge\\tools\\paper\\download\\arxiv_download.py</code> <pre><code>def search_arxiv(search_str: str, max_results_num: int = 3) -&gt; List[Result]:\n\tr\"\"\"\n\tSearch in aXiv.org\n\n\tArgs:\n\t\tsearch_str (str): the search string.\n\t\tmax_results_num (int): the maximum number of returned results. Defaults to 3.\n\n\tReturns:\n\t\tthe paper info results.\n\t\"\"\"\n\tsearcher = ArxivSearcher(max_results_num=max_results_num)\n\tresults = searcher.search(search_str)\n\tif len(results) &lt; 1:\n\t\traise ValueError(\"Do not find relevant papers.\")\n\n\treturn results\n</code></pre>"},{"location":"code_docs/tools/paper/shared_papers/query/","title":"Query","text":""},{"location":"code_docs/tools/paper/shared_papers/query/#labridge.tools.paper.shared_papers.query","title":"<code>labridge.tools.paper.shared_papers.query</code>","text":"<p>All functions in this file need the authorization of the users before execution.</p> <p>All Interactions should be returned as tool output.</p>"},{"location":"code_docs/tools/paper/shared_papers/query/#labridge.tools.paper.shared_papers.query.PaperQueryTool","title":"<code>labridge.tools.paper.shared_papers.query.PaperQueryTool</code>","text":"<p>               Bases: <code>QueryEngineBaseTool</code></p> <p>This tool is used to answer the query with access to the shared paper storage.</p> Source code in <code>labridge\\tools\\paper\\shared_papers\\query.py</code> <pre><code>class PaperQueryTool(QueryEngineBaseTool):\n\tr\"\"\"\n\tThis tool is used to answer the query with access to the shared paper storage.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tpaper_query_engine: PaperQueryEngine,\n\t\tname=PAPER_QUERY_TOOL_NAME,\n\t\tdescription=PAPER_QUERY_TOOL_DESCRIPTION,\n\t):\n\t\tsuper().__init__(\n\t\t\tquery_engine=paper_query_engine,\n\t\t\tname=name,\n\t\t\tdescription=description,\n\t\t)\n\n\tdef log(self) -&gt; ToolLog:\n\t\tr\"\"\"\n\t\tGet the log: specifically, the references.\n\t\t\"\"\"\n\t\tref_infos: List[PaperInfo] = self.query_engine.get_ref_info()\n\n\t\tlog_to_user = None\n\t\tlog_to_system = {\n\t\t\tTOOL_OP_DESCRIPTION: f\"User the {self.metadata.name} to answer the user's query.\",\n\t\t\tTOOL_REFERENCES: [ref_info.dumps() for ref_info in ref_infos]\n\t\t}\n\t\treturn ToolLog(\n\t\t\ttool_name=self.metadata.name,\n\t\t\tlog_to_user=log_to_user,\n\t\t\tlog_to_system=log_to_system,\n\t\t)\n</code></pre>"},{"location":"code_docs/tools/paper/shared_papers/query/#labridge.tools.paper.shared_papers.query.PaperQueryTool.log","title":"<code>labridge.tools.paper.shared_papers.query.PaperQueryTool.log()</code>","text":"<p>Get the log: specifically, the references.</p> Source code in <code>labridge\\tools\\paper\\shared_papers\\query.py</code> <pre><code>def log(self) -&gt; ToolLog:\n\tr\"\"\"\n\tGet the log: specifically, the references.\n\t\"\"\"\n\tref_infos: List[PaperInfo] = self.query_engine.get_ref_info()\n\n\tlog_to_user = None\n\tlog_to_system = {\n\t\tTOOL_OP_DESCRIPTION: f\"User the {self.metadata.name} to answer the user's query.\",\n\t\tTOOL_REFERENCES: [ref_info.dumps() for ref_info in ref_infos]\n\t}\n\treturn ToolLog(\n\t\ttool_name=self.metadata.name,\n\t\tlog_to_user=log_to_user,\n\t\tlog_to_system=log_to_system,\n\t)\n</code></pre>"},{"location":"code_docs/tools/paper/shared_papers/retriever/","title":"Retriever","text":""},{"location":"code_docs/tools/paper/shared_papers/retriever/#labridge.tools.paper.shared_papers.retriever","title":"<code>labridge.tools.paper.shared_papers.retriever</code>","text":""},{"location":"code_docs/tools/paper/shared_papers/retriever/#labridge.tools.paper.shared_papers.retriever.SharedPaperRetrieverTool","title":"<code>labridge.tools.paper.shared_papers.retriever.SharedPaperRetrieverTool</code>","text":"<p>               Bases: <code>RetrieverBaseTool</code></p> <p>This tool is used to retrieve in the shared papers storage of the laboratory.</p> <p>Multi-level, hybrid retrieving is used for accurate results. For details of retrieving, refer to the docstring of <code>PaperRetriever</code>.</p> PARAMETER DESCRIPTION <code>llm</code> <p>The used LLM.</p> <p> TYPE: <code>LLM</code> DEFAULT: <code>None</code> </p> <code>embed_model</code> <p>The used embedding model.</p> <p> TYPE: <code>BaseEmbedding</code> DEFAULT: <code>None</code> </p> <code>vector_similarity_top_k</code> <p>The top-k of content-based retrieving. Defaults to <code>PAPER_VECTOR_TOP_K</code>.</p> <p> TYPE: <code>int</code> DEFAULT: <code>PAPER_VECTOR_TOP_K</code> </p> <code>summary_similarity_top_k</code> <p>The top-k of summary-based retrieving. Defaults tp <code>PAPER_SUMMARY_TOP_K</code>.</p> <p> TYPE: <code>int</code> DEFAULT: <code>PAPER_SUMMARY_TOP_K</code> </p> <code>docs_top_k</code> <p>The top-k docs will be selected. Defaults to <code>PAPER_TOP_K</code>.</p> <p> TYPE: <code>int</code> DEFAULT: <code>PAPER_TOP_K</code> </p> <code>re_retrieve_top_k</code> <p>The top-k of retrieving among the selected <code>docs_top_k</code> docs. Defaults to <code>PAPER_RETRIEVE_TOP_K</code>.</p> <p> TYPE: <code>int</code> DEFAULT: <code>PAPER_RETRIEVE_TOP_K</code> </p> <code>final_use_context</code> <p>Whether to use the context nodes of the retrieved nodes as parts of results. Defaults to True.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>final_use_summary</code> <p>Whether to use the summary nodes of the retrieved nodes' relevant docs as parts of results. Defaults to True.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> Source code in <code>labridge\\tools\\paper\\shared_papers\\retriever.py</code> <pre><code>class SharedPaperRetrieverTool(RetrieverBaseTool):\n\tr\"\"\"\n\tThis tool is used to retrieve in the shared papers storage of the laboratory.\n\n\tMulti-level, hybrid retrieving is used for accurate results.\n\tFor details of retrieving, refer to the docstring of `PaperRetriever`.\n\n\tArgs:\n\t\tllm (LLM): The used LLM.\n\t\tembed_model (BaseEmbedding): The used embedding model.\n\t\tvector_similarity_top_k (int): The top-k of content-based retrieving. Defaults to `PAPER_VECTOR_TOP_K`.\n\t\tsummary_similarity_top_k (int): The top-k of summary-based retrieving. Defaults tp `PAPER_SUMMARY_TOP_K`.\n\t\tdocs_top_k (int): The top-k docs will be selected. Defaults to `PAPER_TOP_K`.\n\t\tre_retrieve_top_k (int): The top-k of retrieving among the selected `docs_top_k` docs.\n\t\t\tDefaults to `PAPER_RETRIEVE_TOP_K`.\n\t\tfinal_use_context (bool): Whether to use the context nodes of the retrieved nodes as parts of results.\n\t\t\tDefaults to True.\n\t\tfinal_use_summary (bool): Whether to use the summary nodes of the retrieved nodes' relevant docs as parts of results.\n\t\t\tDefaults to True.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tllm: LLM = None,\n\t\tembed_model: BaseEmbedding = None,\n\t\tvector_similarity_top_k: int = PAPER_VECTOR_TOP_K,\n\t\tsummary_similarity_top_k: int = PAPER_SUMMARY_TOP_K,\n\t\tdocs_top_k: int = PAPER_TOP_K,\n\t\tre_retrieve_top_k: int = PAPER_RETRIEVE_TOP_K,\n\t\tfinal_use_context: bool = True,\n\t\tfinal_use_summary: bool = True,\n\t):\n\t\tself._llm = llm or Settings.llm\n\t\tself._embed_model = embed_model or Settings.embed_model\n\t\tpaper_retriever = PaperRetriever.from_storage(\n\t\t\tllm=self._llm,\n\t\t\tembed_model=self._embed_model,\n\t\t\tvector_similarity_top_k=vector_similarity_top_k,\n\t\t\tsummary_similarity_top_k=summary_similarity_top_k,\n\t\t\tdocs_top_k=docs_top_k,\n\t\t\tre_retrieve_top_k=re_retrieve_top_k,\n\t\t\tfinal_use_context=final_use_context,\n\t\t\tfinal_use_summary=final_use_summary,\n\t\t)\n\t\tsuper().__init__(\n\t\t\tname=SharedPaperRetrieverTool.__name__,\n\t\t\tretriever=paper_retriever,\n\t\t\tretrieve_fn=paper_retriever.retrieve,\n\t\t)\n\t\troot = Path(__file__)\n\t\tfor i in range(5):\n\t\t\troot = root.parent\n\t\tself.root = root\n\n\tdef log(self, log_dict: dict) -&gt; ToolLog:\n\t\tr\"\"\" Return the ToolLog with log string in a specific format. \"\"\"\n\t\titem_to_be_retrieved = log_dict[\"item_to_be_retrieved\"]\n\n\t\tref_infos: List[PaperInfo] = log_dict.get(TOOL_LOG_REF_INFO_KEY)\n\n\t\top_log = (\n\t\t\tf\"Retrieve in the shared papers.\\n\"\n\t\t\tf\"retrieve string: {item_to_be_retrieved}\\n\"\n\t\t)\n\t\tlog_to_user = None\n\t\tlog_to_system = {\n\t\t\tTOOL_OP_DESCRIPTION: op_log,\n\t\t\tTOOL_REFERENCES: [ref_info.dumps() for ref_info in ref_infos]\n\t\t}\n\t\treturn ToolLog(\n\t\t\ttool_name=self.metadata.name,\n\t\t\tlog_to_user=log_to_user,\n\t\t\tlog_to_system=log_to_system,\n\t\t)\n\n\tdef _retrieve(self, retrieve_kwargs: dict) -&gt; List[NodeWithScore]:\n\t\tr\"\"\" Use the retriever to retrieve relevant nodes. \"\"\"\n\t\tnodes = self._retriever.retrieve(**retrieve_kwargs)\n\t\treturn nodes\n\n\tasync def _aretrieve(self, retrieve_kwargs: dict) -&gt; List[NodeWithScore]:\n\t\tr\"\"\" Asynchronously use the retriever to retrieve relevant nodes. \"\"\"\n\t\tnodes = await self._retriever.aretrieve(**retrieve_kwargs)\n\t\treturn nodes\n\n\tdef get_ref_info(self, nodes: List[NodeWithScore]) -&gt; List[PaperInfo]:\n\t\tr\"\"\"\n\t\tGet the reference paper infos\n\n\t\tReturns:\n\t\t\tList[PaperInfo]: The reference paper infos in answering.\n\t\t\"\"\"\n\t\tdoc_ids, doc_titles, doc_possessors = [], [], []\n\t\tref_infos = []\n\t\tfor node_score in nodes:\n\t\t\tref_doc_id = node_score.node.ref_doc_id\n\t\t\tif ref_doc_id not in doc_ids:\n\t\t\t\tdoc_ids.append(ref_doc_id)\n\t\t\t\ttitle = node_score.node.metadata.get(PAPER_TITLE) or ref_doc_id\n\t\t\t\tpossessor = node_score.node.metadata.get(PAPER_POSSESSOR)\n\t\t\t\trel_path = node_score.node.metadata.get(PAPER_REL_FILE_PATH)\n\t\t\t\tif rel_path is None:\n\t\t\t\t\traise ValueError(\"Invalid database.\")\n\t\t\t\tpaper_info = PaperInfo(\n\t\t\t\t\ttitle=title,\n\t\t\t\t\tpossessor=possessor,\n\t\t\t\t\tfile_path=str(self.root / rel_path),\n\t\t\t\t)\n\t\t\t\tref_infos.append(paper_info)\n\n\t\t\t\tdoc_titles.append(title)\n\t\t\t\tdoc_possessors.append(possessor)\n\t\treturn ref_infos\n\n\tdef _nodes_to_tool_output(self, nodes: List[NodeWithScore]) -&gt; Tuple[str, dict]:\n\t\tr\"\"\" output the retrieved contents in a specific format, and the output log. \"\"\"\n\t\tref_infos = self.get_ref_info(nodes=nodes)\n\t\tlog_dict = {\n\t\t\tTOOL_LOG_REF_INFO_KEY: ref_infos,\n\t\t}\n\n\t\tpaper_contents = {}\n\t\tfor node in nodes:\n\t\t\tdoc_name = node.node.ref_doc_id\n\t\t\tif doc_name not in paper_contents:\n\t\t\t\tpaper_contents[doc_name] = [node.get_content(metadata_mode=MetadataMode.LLM)]\n\t\t\telse:\n\t\t\t\tpaper_contents[doc_name].append(node.get_content(metadata_mode=MetadataMode.LLM))\n\n\t\tif paper_contents:\n\t\t\tcontent_str = \"Have retrieved the following contents: \\n\"\n\t\t\tcontents = []\n\t\t\tfor doc_name in paper_contents.keys():\n\t\t\t\teach_str = f\"Following contents are from the paper: {doc_name}:\\n\"\n\t\t\t\teach_str += \"\\n\".join(paper_contents[doc_name])\n\t\t\t\tcontents.append(each_str.strip())\n\t\t\tcontent_str += \"\\n\\n\".join(contents)\n\t\telse:\n\t\t\tcontent_str = \"Have retrieved nothing.\\n\"\n\t\treturn content_str, log_dict\n</code></pre>"},{"location":"code_docs/tools/paper/shared_papers/retriever/#labridge.tools.paper.shared_papers.retriever.SharedPaperRetrieverTool.get_ref_info","title":"<code>labridge.tools.paper.shared_papers.retriever.SharedPaperRetrieverTool.get_ref_info(nodes)</code>","text":"<p>Get the reference paper infos</p> RETURNS DESCRIPTION <code>List[PaperInfo]</code> <p>List[PaperInfo]: The reference paper infos in answering.</p> Source code in <code>labridge\\tools\\paper\\shared_papers\\retriever.py</code> <pre><code>def get_ref_info(self, nodes: List[NodeWithScore]) -&gt; List[PaperInfo]:\n\tr\"\"\"\n\tGet the reference paper infos\n\n\tReturns:\n\t\tList[PaperInfo]: The reference paper infos in answering.\n\t\"\"\"\n\tdoc_ids, doc_titles, doc_possessors = [], [], []\n\tref_infos = []\n\tfor node_score in nodes:\n\t\tref_doc_id = node_score.node.ref_doc_id\n\t\tif ref_doc_id not in doc_ids:\n\t\t\tdoc_ids.append(ref_doc_id)\n\t\t\ttitle = node_score.node.metadata.get(PAPER_TITLE) or ref_doc_id\n\t\t\tpossessor = node_score.node.metadata.get(PAPER_POSSESSOR)\n\t\t\trel_path = node_score.node.metadata.get(PAPER_REL_FILE_PATH)\n\t\t\tif rel_path is None:\n\t\t\t\traise ValueError(\"Invalid database.\")\n\t\t\tpaper_info = PaperInfo(\n\t\t\t\ttitle=title,\n\t\t\t\tpossessor=possessor,\n\t\t\t\tfile_path=str(self.root / rel_path),\n\t\t\t)\n\t\t\tref_infos.append(paper_info)\n\n\t\t\tdoc_titles.append(title)\n\t\t\tdoc_possessors.append(possessor)\n\treturn ref_infos\n</code></pre>"},{"location":"code_docs/tools/paper/shared_papers/retriever/#labridge.tools.paper.shared_papers.retriever.SharedPaperRetrieverTool.log","title":"<code>labridge.tools.paper.shared_papers.retriever.SharedPaperRetrieverTool.log(log_dict)</code>","text":"<p>Return the ToolLog with log string in a specific format.</p> Source code in <code>labridge\\tools\\paper\\shared_papers\\retriever.py</code> <pre><code>def log(self, log_dict: dict) -&gt; ToolLog:\n\tr\"\"\" Return the ToolLog with log string in a specific format. \"\"\"\n\titem_to_be_retrieved = log_dict[\"item_to_be_retrieved\"]\n\n\tref_infos: List[PaperInfo] = log_dict.get(TOOL_LOG_REF_INFO_KEY)\n\n\top_log = (\n\t\tf\"Retrieve in the shared papers.\\n\"\n\t\tf\"retrieve string: {item_to_be_retrieved}\\n\"\n\t)\n\tlog_to_user = None\n\tlog_to_system = {\n\t\tTOOL_OP_DESCRIPTION: op_log,\n\t\tTOOL_REFERENCES: [ref_info.dumps() for ref_info in ref_infos]\n\t}\n\treturn ToolLog(\n\t\ttool_name=self.metadata.name,\n\t\tlog_to_user=log_to_user,\n\t\tlog_to_system=log_to_system,\n\t)\n</code></pre>"},{"location":"code_docs/tools/paper/shared_papers/utils/","title":"Utils","text":""},{"location":"code_docs/tools/paper/shared_papers/utils/#labridge.tools.paper.shared_papers.utils","title":"<code>labridge.tools.paper.shared_papers.utils</code>","text":""},{"location":"code_docs/tools/paper/shared_papers/utils/#labridge.tools.paper.shared_papers.utils.ref_papers_file_path","title":"<code>labridge.tools.paper.shared_papers.utils.ref_papers_file_path(ref_infos)</code>","text":"<p>Get all file paths of the PaperInfos.</p> Source code in <code>labridge\\tools\\paper\\shared_papers\\utils.py</code> <pre><code>def ref_papers_file_path(ref_infos: List[PaperInfo]) -&gt; List[str]:\n\tr\"\"\" Get all file paths of the PaperInfos. \"\"\"\n\treturn [paper_info.file_path for paper_info in ref_infos]\n</code></pre>"},{"location":"code_docs/tools/paper/shared_papers/utils/#labridge.tools.paper.shared_papers.utils.ref_papers_str_to_user","title":"<code>labridge.tools.paper.shared_papers.utils.ref_papers_str_to_user(ref_infos)</code>","text":"<p>Transform the relevant PaperInfos into formatted strings that will be added as extra info of the assistant's answer.</p> PARAMETER DESCRIPTION <code>ref_infos</code> <p>The reference paper infos.</p> <p> TYPE: <code>List[PaperInfo]</code> </p> RETURNS DESCRIPTION <code>str</code> <p>The formatted string.</p> <p> TYPE: <code>str</code> </p> Source code in <code>labridge\\tools\\paper\\shared_papers\\utils.py</code> <pre><code>def ref_papers_str_to_user(ref_infos: List[PaperInfo]) -&gt; str:\n\tr\"\"\"\n\tTransform the relevant PaperInfos into formatted strings\n\tthat will be added as extra info of the assistant's answer.\n\n\tArgs:\n\t\tref_infos (List[PaperInfo]): The reference paper infos.\n\n\tReturns:\n\t\tstr: The formatted string.\n\t\"\"\"\n\treferences, ref_titles, valid_refs = [], [], []\n\n\tfor paper_info in ref_infos:\n\t\tif paper_info.title not in ref_titles:\n\t\t\tref_titles.append(paper_info.title)\n\t\t\tvalid_refs.append(paper_info)\n\n\tref_str = f\"**REFERENCE:**\\n\"\n\tfor paper_info in valid_refs:\n\t\tpaper_str = f\"\\t**Title:** {paper_info.title}\\n\"\n\t\tpaper_str += f\"\\t\u200b\u8fd9\u200b\u7bc7\u6587\u7ae0\u200b\u7531\u200b{paper_info.possessor}\u200b\u6301\u6709\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u4e0e\u200bta\u200b\u591a\u591a\u200b\u4ea4\u6d41\u200b\u54e6\u200b\u3002\"\n\t\treferences.append(paper_str)\n\tref_str += \"\\n\".join(references)\n\treturn ref_str\n</code></pre>"},{"location":"code_docs/tools/paper/temporary_papers/insert/","title":"Insert","text":""},{"location":"code_docs/tools/paper/temporary_papers/insert/#labridge.tools.paper.temporary_papers.insert","title":"<code>labridge.tools.paper.temporary_papers.insert</code>","text":""},{"location":"code_docs/tools/paper/temporary_papers/insert/#labridge.tools.paper.temporary_papers.insert.AddNewRecentPaperTool","title":"<code>labridge.tools.paper.temporary_papers.insert.AddNewRecentPaperTool</code>","text":"<p>               Bases: <code>CallBackBaseTool</code></p> <p>This tool is used to add a new paper into a specific user's recent papers storage.</p> PARAMETER DESCRIPTION <code>llm</code> <p>The used LLM. If not specified, the <code>Settings.llm</code> will be used.</p> <p> TYPE: <code>LLM</code> DEFAULT: <code>None</code> </p> <code>embed_model</code> <p>The used embedding model. If not specified, the <code>Settings.embed_model</code> will be used.</p> <p> TYPE: <code>BaseEmbedding</code> DEFAULT: <code>None</code> </p> <code>verbose</code> <p>Whether to show the inner progress.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> Source code in <code>labridge\\tools\\paper\\temporary_papers\\insert.py</code> <pre><code>class AddNewRecentPaperTool(CallBackBaseTool):\n\tr\"\"\"\n\tThis tool is used to add a new paper into a specific user's recent papers storage.\n\n\tArgs:\n\t\tllm (LLM): The used LLM. If not specified, the `Settings.llm` will be used.\n\t\tembed_model (BaseEmbedding): The used embedding model. If not specified, the `Settings.embed_model` will be used.\n\t\tverbose (bool): Whether to show the inner progress.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tllm: LLM = None,\n\t\tembed_model: BaseEmbedding = None,\n\t\tverbose: bool = False,\n\t):\n\t\tself._llm = llm or Settings.llm\n\t\tself._embed_model = embed_model or Settings.embed_model\n\t\tself._verbose = verbose\n\t\tsuper().__init__(\n\t\t\tfn=self.add_paper,\n\t\t\tasync_fn=self.a_add_paper,\n\t\t\ttool_name=AddNewRecentPaperTool.__name__,\n\t\t\tcallback_operation=AddNewRecentPaperOperation,\n\t\t)\n\n\tdef log(self, **kwargs: Any) -&gt; ToolLog:\n\t\top_log = kwargs[\"operation_log\"]\n\t\tif not isinstance(op_log, OperationOutputLog):\n\t\t\traise ValueError(\"operation_log must be 'OperationLog'.\")\n\t\tlog_to_user = op_log.log_to_user\n\t\tlog_to_system = op_log.log_to_system\n\t\treturn ToolLog(\n\t\t\ttool_name=self.metadata.name,\n\t\t\tlog_to_user=log_to_user,\n\t\t\tlog_to_system=log_to_system,\n\t\t)\n\n\tdef add_paper(\n\t\tself,\n\t\tuser_id: str,\n\t\tpaper_file_path: str,\n\t) -&gt; FuncOutputWithLog:\n\t\tr\"\"\"\n\t\tThis tool is used to add a new paper to a specific user's recent papers storage.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user_id of a lab member.\n\t\t\tpaper_file_path (str): The file path of the paper to be added. Browse the chat context or tool logs\n\t\t\t\tto get the correct and valid file path.\n\n\t\tReturns:\n\t\t\tFuncOutputWithLog: The output and log.\n\t\t\"\"\"\n\t\t# This docstring is used as the tool description.\n\t\top_name = self._callback_operation.__name__\n\t\tkwargs = {\n\t\t\t\"user_id\": user_id,\n\t\t\t\"paper_file_path\": paper_file_path,\n\t\t}\n\n\t\tkwargs_str = json.dumps(kwargs)\n\t\toperation_log = operation_authorize(\n\t\t\tuser_id=user_id,\n\t\t\top_name=op_name,\n\t\t\tkwargs_str=kwargs_str,\n\t\t\tllm=self._llm,\n\t\t\tembed_model=self._embed_model,\n\t\t\tverbose=self._verbose,\n\t\t)\n\t\tlog_dict = {\"operation_log\": operation_log}\n\n\t\treturn FuncOutputWithLog(\n\t\t\tfn_output=f\"Have Added the paper {paper_file_path} to recent papers of the user {user_id}\",\n\t\t\tfn_log=log_dict,\n\t\t)\n\n\tasync def a_add_paper(\n\t\tself,\n\t\tuser_id: str,\n\t\tpaper_file_path: str,\n\t) -&gt; FuncOutputWithLog:\n\t\tr\"\"\"\n\t\tThis tool is used to add a new paper to a specific user's recent papers storage.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user_id of a lab member.\n\t\t\tpaper_file_path (str): The file path of the paper to be added. Browse the chat context or tool logs\n\t\t\t\tto get the correct and valid file path.\n\n\t\tReturns:\n\t\t\tFuncOutputWithLog: The output and log.\n\t\t\"\"\"\n\t\t# This docstring is used as the tool description.\n\t\top_name = self._callback_operation.__name__\n\t\tkwargs = {\n\t\t\t\"user_id\": user_id,\n\t\t\t\"paper_file_path\": paper_file_path,\n\t\t}\n\n\t\tkwargs_str = json.dumps(kwargs)\n\t\toperation_log = await aoperation_authorize(\n\t\t\tuser_id=user_id,\n\t\t\top_name=op_name,\n\t\t\tkwargs_str=kwargs_str,\n\t\t\tllm=self._llm,\n\t\t\tembed_model=self._embed_model,\n\t\t\tverbose=self._verbose,\n\t\t)\n\n\t\tlog_dict = {\"operation_log\": operation_log}\n\t\treturn FuncOutputWithLog(\n\t\t\tfn_output=f\"Have Added the paper {paper_file_path} to recent papers of the user {user_id}\",\n\t\t\tfn_log=log_dict,\n\t\t)\n</code></pre>"},{"location":"code_docs/tools/paper/temporary_papers/insert/#labridge.tools.paper.temporary_papers.insert.AddNewRecentPaperTool.a_add_paper","title":"<code>labridge.tools.paper.temporary_papers.insert.AddNewRecentPaperTool.a_add_paper(user_id, paper_file_path)</code>  <code>async</code>","text":"<p>This tool is used to add a new paper to a specific user's recent papers storage.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user_id of a lab member.</p> <p> TYPE: <code>str</code> </p> <code>paper_file_path</code> <p>The file path of the paper to be added. Browse the chat context or tool logs to get the correct and valid file path.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>FuncOutputWithLog</code> <p>The output and log.</p> <p> TYPE: <code>FuncOutputWithLog</code> </p> Source code in <code>labridge\\tools\\paper\\temporary_papers\\insert.py</code> <pre><code>async def a_add_paper(\n\tself,\n\tuser_id: str,\n\tpaper_file_path: str,\n) -&gt; FuncOutputWithLog:\n\tr\"\"\"\n\tThis tool is used to add a new paper to a specific user's recent papers storage.\n\n\tArgs:\n\t\tuser_id (str): The user_id of a lab member.\n\t\tpaper_file_path (str): The file path of the paper to be added. Browse the chat context or tool logs\n\t\t\tto get the correct and valid file path.\n\n\tReturns:\n\t\tFuncOutputWithLog: The output and log.\n\t\"\"\"\n\t# This docstring is used as the tool description.\n\top_name = self._callback_operation.__name__\n\tkwargs = {\n\t\t\"user_id\": user_id,\n\t\t\"paper_file_path\": paper_file_path,\n\t}\n\n\tkwargs_str = json.dumps(kwargs)\n\toperation_log = await aoperation_authorize(\n\t\tuser_id=user_id,\n\t\top_name=op_name,\n\t\tkwargs_str=kwargs_str,\n\t\tllm=self._llm,\n\t\tembed_model=self._embed_model,\n\t\tverbose=self._verbose,\n\t)\n\n\tlog_dict = {\"operation_log\": operation_log}\n\treturn FuncOutputWithLog(\n\t\tfn_output=f\"Have Added the paper {paper_file_path} to recent papers of the user {user_id}\",\n\t\tfn_log=log_dict,\n\t)\n</code></pre>"},{"location":"code_docs/tools/paper/temporary_papers/insert/#labridge.tools.paper.temporary_papers.insert.AddNewRecentPaperTool.add_paper","title":"<code>labridge.tools.paper.temporary_papers.insert.AddNewRecentPaperTool.add_paper(user_id, paper_file_path)</code>","text":"<p>This tool is used to add a new paper to a specific user's recent papers storage.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user_id of a lab member.</p> <p> TYPE: <code>str</code> </p> <code>paper_file_path</code> <p>The file path of the paper to be added. Browse the chat context or tool logs to get the correct and valid file path.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>FuncOutputWithLog</code> <p>The output and log.</p> <p> TYPE: <code>FuncOutputWithLog</code> </p> Source code in <code>labridge\\tools\\paper\\temporary_papers\\insert.py</code> <pre><code>def add_paper(\n\tself,\n\tuser_id: str,\n\tpaper_file_path: str,\n) -&gt; FuncOutputWithLog:\n\tr\"\"\"\n\tThis tool is used to add a new paper to a specific user's recent papers storage.\n\n\tArgs:\n\t\tuser_id (str): The user_id of a lab member.\n\t\tpaper_file_path (str): The file path of the paper to be added. Browse the chat context or tool logs\n\t\t\tto get the correct and valid file path.\n\n\tReturns:\n\t\tFuncOutputWithLog: The output and log.\n\t\"\"\"\n\t# This docstring is used as the tool description.\n\top_name = self._callback_operation.__name__\n\tkwargs = {\n\t\t\"user_id\": user_id,\n\t\t\"paper_file_path\": paper_file_path,\n\t}\n\n\tkwargs_str = json.dumps(kwargs)\n\toperation_log = operation_authorize(\n\t\tuser_id=user_id,\n\t\top_name=op_name,\n\t\tkwargs_str=kwargs_str,\n\t\tllm=self._llm,\n\t\tembed_model=self._embed_model,\n\t\tverbose=self._verbose,\n\t)\n\tlog_dict = {\"operation_log\": operation_log}\n\n\treturn FuncOutputWithLog(\n\t\tfn_output=f\"Have Added the paper {paper_file_path} to recent papers of the user {user_id}\",\n\t\tfn_log=log_dict,\n\t)\n</code></pre>"},{"location":"code_docs/tools/paper/temporary_papers/paper_retriever/","title":"Paper retriever","text":""},{"location":"code_docs/tools/paper/temporary_papers/paper_retriever/#labridge.tools.paper.temporary_papers.paper_retriever","title":"<code>labridge.tools.paper.temporary_papers.paper_retriever</code>","text":""},{"location":"code_docs/tools/paper/temporary_papers/paper_retriever/#labridge.tools.paper.temporary_papers.paper_retriever.RecentPaperRetrieveTool","title":"<code>labridge.tools.paper.temporary_papers.paper_retriever.RecentPaperRetrieveTool</code>","text":"<p>               Bases: <code>RetrieverBaseTool</code></p> <p>This tool is used to retrieve in the recent papers store of a specific user. A multilevel retrieving strategy is used. For details, refer to the <code>RecentPaperRetriever</code>. (start_date, end_date) can be provided to confine the retrieving range.</p> PARAMETER DESCRIPTION <code>embed_model</code> <p>The used embedding model. If not specified, The <code>Settings.embed_model</code> will be used.</p> <p> TYPE: <code>BaseEmbedding</code> DEFAULT: <code>None</code> </p> <code>first_top_k</code> <p>The similarity_top_k in the first retrieving. Defaults to <code>RECENT_PAPER_INFO_SIMILARITY_TOP_K</code>.</p> <p> TYPE: <code>int</code> DEFAULT: <code>RECENT_PAPER_INFO_SIMILARITY_TOP_K</code> </p> <code>secondary_top_k</code> <p>The similarity_top_k in the secondary retrieving. Defaults to <code>RECENT_PAPER_SIMILARITY_TOP_K</code>.</p> <p> TYPE: <code>int</code> DEFAULT: <code>RECENT_PAPER_SIMILARITY_TOP_K</code> </p> Source code in <code>labridge\\tools\\paper\\temporary_papers\\paper_retriever.py</code> <pre><code>class RecentPaperRetrieveTool(RetrieverBaseTool):\n\tr\"\"\"\n\tThis tool is used to retrieve in the recent papers store of a specific user.\n\tA multilevel retrieving strategy is used. For details, refer to the `RecentPaperRetriever`.\n\t(start_date, end_date) can be provided to confine the retrieving range.\n\n\tArgs:\n\t\tembed_model (BaseEmbedding): The used embedding model. If not specified, The `Settings.embed_model` will be used.\n\t\tfirst_top_k (int): The similarity_top_k in the first retrieving.\n\t\t\tDefaults to `RECENT_PAPER_INFO_SIMILARITY_TOP_K`.\n\t\tsecondary_top_k (int): The similarity_top_k in the secondary retrieving.\n\t\t\tDefaults to `RECENT_PAPER_SIMILARITY_TOP_K`.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tembed_model: BaseEmbedding = None,\n\t\tfirst_top_k: int = RECENT_PAPER_INFO_SIMILARITY_TOP_K,\n\t\tsecondary_top_k: int = RECENT_PAPER_SIMILARITY_TOP_K,\n\t\tuse_context: bool = False,\n\n\t):\n\t\tretriever = RecentPaperRetriever(\n\t\t\tembed_model=embed_model,\n\t\t\tfinal_use_context=use_context,\n\t\t\tfirst_top_k=first_top_k,\n\t\t\tsecondary_top_k=secondary_top_k,\n\t\t)\n\t\tsuper().__init__(\n\t\t\tname=RecentPaperRetrieveTool.__name__,\n\t\t\tretriever=retriever,\n\t\t\tretrieve_fn=retriever.retrieve,\n\t\t)\n\n\tdef log(self, log_dict: dict) -&gt; ToolLog:\n\t\tr\"\"\"\n\t\tRecord the tool log.\n\n\t\tArgs:\n\t\t\tlog_dict (dict): Including the input keyword arguments and the retrieving logs.\n\n\t\tReturns:\n\t\t\tToolLog: The packed tool log.\n\t\t\"\"\"\n\t\tuser_id = log_dict[\"user_id\"]\n\t\titem_to_be_retrieved = log_dict[\"item_to_be_retrieved\"]\n\t\tpaper_file_path = log_dict.get(\"paper_file_path\", None)\n\t\tstart_date = log_dict.get(\"start_date\", None)\n\t\tend_date = log_dict.get(\"end_date\", None)\n\n\t\top_log = (\n\t\t\tf\"Retrieve in the recent papers of the user: {user_id}.\\n\"\n\t\t\tf\"retrieve string: {item_to_be_retrieved}\\n\"\n\t\t)\n\t\tif paper_file_path is not None:\n\t\t\top_log += f\"target paper file path: {paper_file_path}\\n\"\n\t\tif None not in [start_date, end_date]:\n\t\t\top_log += (\n\t\t\t\tf\"start_date: {start_date}\\n\"\n\t\t\t\tf\"end_date: {end_date}\"\n\t\t\t)\n\n\t\tlog_to_user = None\n\t\tlog_to_system = {\n\t\t\tTOOL_OP_DESCRIPTION: op_log,\n\t\t\tTOOL_REFERENCES: None,\n\t\t}\n\n\t\treturn ToolLog(\n\t\t\ttool_name=self.metadata.name,\n\t\t\tlog_to_user=log_to_user,\n\t\t\tlog_to_system=log_to_system,\n\t\t)\n\n\tdef get_ref_info(self, nodes: List[NodeWithScore]) -&gt; List[RefInfoBase]:\n\t\tr\"\"\" Get the reference infos from the retrieved nodes. \"\"\"\n\t\treturn []\n\n\tdef _retrieve(self, retrieve_kwargs: dict) -&gt; List[NodeWithScore]:\n\t\tr\"\"\" Use the retriever to retrieve relevant nodes. \"\"\"\n\t\tnodes = self._retriever.retrieve(**retrieve_kwargs)\n\t\treturn nodes\n\n\tasync def _aretrieve(self, retrieve_kwargs: dict) -&gt; List[NodeWithScore]:\n\t\tr\"\"\" Asynchronously use the retriever to retrieve relevant nodes. \"\"\"\n\t\tnodes = await self._retriever.aretrieve(**retrieve_kwargs)\n\t\treturn nodes\n\n\tdef _nodes_to_tool_output(self, nodes: List[NodeWithScore]) -&gt; Tuple[str, dict]:\n\t\tr\"\"\" output the retrieved contents in a specific format, and the output log. \"\"\"\n\t\tpaper_contents = {}\n\n\t\tfor node in nodes:\n\t\t\tfile_path = node.node.parent_node.node_id\n\t\t\tif file_path not in paper_contents:\n\t\t\t\tpaper_contents[file_path] = [node.get_content(metadata_mode=MetadataMode.LLM)]\n\t\t\telse:\n\t\t\t\tpaper_contents[file_path].append(node.get_content(metadata_mode=MetadataMode.LLM))\n\n\t\tif paper_contents:\n\t\t\tcontent_str = \"Have retrieved the following content: \\n\"\n\t\t\tcontents = []\n\t\t\tfor paper_path in paper_contents.keys():\n\t\t\t\teach_str = f\"Following contents are from the paper stored in {paper_path}:\\n\"\n\t\t\t\teach_str += \"\\n\".join(paper_contents[paper_path])\n\t\t\t\tcontents.append(each_str.strip())\n\t\t\tcontent_str += \"\\n\\n\".join(contents)\n\t\telse:\n\t\t\tcontent_str = \"Have retrieved nothing.\\n\"\n\t\treturn content_str, dict()\n</code></pre>"},{"location":"code_docs/tools/paper/temporary_papers/paper_retriever/#labridge.tools.paper.temporary_papers.paper_retriever.RecentPaperRetrieveTool.get_ref_info","title":"<code>labridge.tools.paper.temporary_papers.paper_retriever.RecentPaperRetrieveTool.get_ref_info(nodes)</code>","text":"<p>Get the reference infos from the retrieved nodes.</p> Source code in <code>labridge\\tools\\paper\\temporary_papers\\paper_retriever.py</code> <pre><code>def get_ref_info(self, nodes: List[NodeWithScore]) -&gt; List[RefInfoBase]:\n\tr\"\"\" Get the reference infos from the retrieved nodes. \"\"\"\n\treturn []\n</code></pre>"},{"location":"code_docs/tools/paper/temporary_papers/paper_retriever/#labridge.tools.paper.temporary_papers.paper_retriever.RecentPaperRetrieveTool.log","title":"<code>labridge.tools.paper.temporary_papers.paper_retriever.RecentPaperRetrieveTool.log(log_dict)</code>","text":"<p>Record the tool log.</p> PARAMETER DESCRIPTION <code>log_dict</code> <p>Including the input keyword arguments and the retrieving logs.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>ToolLog</code> <p>The packed tool log.</p> <p> TYPE: <code>ToolLog</code> </p> Source code in <code>labridge\\tools\\paper\\temporary_papers\\paper_retriever.py</code> <pre><code>def log(self, log_dict: dict) -&gt; ToolLog:\n\tr\"\"\"\n\tRecord the tool log.\n\n\tArgs:\n\t\tlog_dict (dict): Including the input keyword arguments and the retrieving logs.\n\n\tReturns:\n\t\tToolLog: The packed tool log.\n\t\"\"\"\n\tuser_id = log_dict[\"user_id\"]\n\titem_to_be_retrieved = log_dict[\"item_to_be_retrieved\"]\n\tpaper_file_path = log_dict.get(\"paper_file_path\", None)\n\tstart_date = log_dict.get(\"start_date\", None)\n\tend_date = log_dict.get(\"end_date\", None)\n\n\top_log = (\n\t\tf\"Retrieve in the recent papers of the user: {user_id}.\\n\"\n\t\tf\"retrieve string: {item_to_be_retrieved}\\n\"\n\t)\n\tif paper_file_path is not None:\n\t\top_log += f\"target paper file path: {paper_file_path}\\n\"\n\tif None not in [start_date, end_date]:\n\t\top_log += (\n\t\t\tf\"start_date: {start_date}\\n\"\n\t\t\tf\"end_date: {end_date}\"\n\t\t)\n\n\tlog_to_user = None\n\tlog_to_system = {\n\t\tTOOL_OP_DESCRIPTION: op_log,\n\t\tTOOL_REFERENCES: None,\n\t}\n\n\treturn ToolLog(\n\t\ttool_name=self.metadata.name,\n\t\tlog_to_user=log_to_user,\n\t\tlog_to_system=log_to_system,\n\t)\n</code></pre>"},{"location":"code_docs/tools/paper/temporary_papers/paper_summarize/","title":"Paper summarize","text":""},{"location":"code_docs/tools/paper/temporary_papers/paper_summarize/#labridge.tools.paper.temporary_papers.paper_summarize","title":"<code>labridge.tools.paper.temporary_papers.paper_summarize</code>","text":""},{"location":"code_docs/tools/paper/temporary_papers/paper_summarize/#labridge.tools.paper.temporary_papers.paper_summarize.RecentPaperSummarizeTool","title":"<code>labridge.tools.paper.temporary_papers.paper_summarize.RecentPaperSummarizeTool</code>","text":"<p>               Bases: <code>CallBackBaseTool</code></p> <p>This tool summarize a recent paper of a user (stored in the RecentPaperStore).</p> PARAMETER DESCRIPTION <code>llm</code> <p>The used llm.</p> <p> TYPE: <code>LLM</code> DEFAULT: <code>None</code> </p> <code>embed_model</code> <p>The used embedding model.</p> <p> TYPE: <code>BaseEmbedding</code> DEFAULT: <code>None</code> </p> Source code in <code>labridge\\tools\\paper\\temporary_papers\\paper_summarize.py</code> <pre><code>class RecentPaperSummarizeTool(CallBackBaseTool):\n\tr\"\"\"\n\tThis tool summarize a recent paper of a user (stored in the RecentPaperStore).\n\n\tArgs:\n\t\tllm (LLM): The used llm.\n\t\tembed_model (BaseEmbedding): The used embedding model.\n\t\"\"\"\n\tdef __init__(\n\t\tself,\n\t\tllm: LLM = None,\n\t\tembed_model: BaseEmbedding = None,\n\t\tverbose: bool = False,\n\t):\n\t\tself._llm = llm or Settings.llm\n\t\tself._embed_model = embed_model or Settings.embed_model\n\t\tself._verbose = verbose\n\t\tsuper().__init__(\n\t\t\tfn=self.summarize_paper,\n\t\t\tasync_fn=self.asummarize_paper,\n\t\t\ttool_name=RecentPaperSummarizeTool.__name__,\n\t\t\tcallback_operation=PaperSummarizeOperation,\n\t\t\treturn_direct=True,\n\t\t)\n\n\tdef summarize_paper(\n\t\tself,\n\t\tuser_id: str,\n\t\tpaper_file_path: str,\n\t) -&gt; FuncOutputWithLog:\n\t\tr\"\"\"\n\t\tThis tool is used to summarize a paper that is stored in a specific user's recent papers storage.\n\t\tThis tool is used ONLY when the user explicitly ask for a summarization of the paper.\n\t\tDO NOT use this tool by yourself.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user_id of a lab member.\n\t\t\tpaper_file_path (str): The file path of a specific paper. Browse the chat context to get the correct\n\t\t\t\tand valid file path of the paper.\n\n\t\tReturns:\n\t\t\tThe summary of the paper.\n\t\t\"\"\"\n\t\t# This docstring is used as the tool description.\n\t\top_name = self._callback_operation.__name__\n\t\tkwargs = {\"user_id\": user_id, \"paper_file_path\": paper_file_path}\n\t\tkwargs_str = json.dumps(kwargs)\n\t\toperation_log = operation_authorize(\n\t\t\tuser_id=user_id,\n\t\t\top_name=op_name,\n\t\t\tkwargs_str=kwargs_str,\n\t\t\tllm=self._llm,\n\t\t\tembed_model=self._embed_model,\n\t\t\tverbose=self._verbose,\n\t\t)\n\t\tfn_output = operation_log.operation_output\n\t\tfn_log = {\"operation_log\": operation_log}\n\t\treturn FuncOutputWithLog(\n\t\t\tfn_output=fn_output,\n\t\t\tfn_log=fn_log,\n\t\t)\n\n\tasync def asummarize_paper(\n\t\tself,\n\t\tuser_id: str,\n\t\tpaper_file_path: str,\n\t) -&gt; FuncOutputWithLog:\n\t\tr\"\"\"\n\t\tThis tool is used to summarize a paper that is stored in a specific user's recent papers storage.\n\t\tThis tool is used ONLY when the user explicitly ask for a summarization of the paper.\n\t\tDO NOT use this tool by yourself.\n\n\t\tArgs:\n\t\t\tuser_id (str): The user_id of a lab member.\n\t\t\tpaper_file_path (str): The file path of a specific paper. Browse the chat context to get the correct\n\t\t\t\tand valid file path of the paper.\n\n\t\tReturns:\n\t\t\tThe summary of the paper.\n\t\t\"\"\"\n\t\t# This docstring is used as the tool description.\n\t\top_name = self._callback_operation.__name__\n\t\tkwargs = {\"user_id\": user_id, \"paper_file_path\": paper_file_path}\n\t\tkwargs_str = json.dumps(kwargs)\n\t\toperation_log = await aoperation_authorize(\n\t\t\tuser_id=user_id,\n\t\t\top_name=op_name,\n\t\t\tkwargs_str=kwargs_str,\n\t\t\tllm=self._llm,\n\t\t\tembed_model=self._embed_model,\n\t\t\tverbose=self._verbose,\n\t\t)\n\t\tfn_output = operation_log.operation_output\n\t\tfn_log = {\"operation_log\": operation_log}\n\t\treturn FuncOutputWithLog(\n\t\t\tfn_output=fn_output,\n\t\t\tfn_log=fn_log,\n\t\t)\n\n\tdef log(self, **kwargs: Any) -&gt; ToolLog:\n\t\tpaper_file_path = kwargs[\"paper_file_path\"]\n\t\tuser_id = kwargs[\"user_id\"]\n\t\tlog_str = f\"Summarize the paper {paper_file_path} for the user {user_id}.\"\n\t\tlog_to_user = None\n\t\tlog_to_system = {\n\t\t\tTOOL_OP_DESCRIPTION: log_str,\n\t\t\tTOOL_REFERENCES: None,\n\t\t}\n\n\t\treturn ToolLog(\n\t\t\ttool_name=self.metadata.name,\n\t\t\tlog_to_user=log_to_user,\n\t\t\tlog_to_system=log_to_system,\n\t\t)\n</code></pre>"},{"location":"code_docs/tools/paper/temporary_papers/paper_summarize/#labridge.tools.paper.temporary_papers.paper_summarize.RecentPaperSummarizeTool.asummarize_paper","title":"<code>labridge.tools.paper.temporary_papers.paper_summarize.RecentPaperSummarizeTool.asummarize_paper(user_id, paper_file_path)</code>  <code>async</code>","text":"<p>This tool is used to summarize a paper that is stored in a specific user's recent papers storage. This tool is used ONLY when the user explicitly ask for a summarization of the paper. DO NOT use this tool by yourself.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user_id of a lab member.</p> <p> TYPE: <code>str</code> </p> <code>paper_file_path</code> <p>The file path of a specific paper. Browse the chat context to get the correct and valid file path of the paper.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>FuncOutputWithLog</code> <p>The summary of the paper.</p> Source code in <code>labridge\\tools\\paper\\temporary_papers\\paper_summarize.py</code> <pre><code>async def asummarize_paper(\n\tself,\n\tuser_id: str,\n\tpaper_file_path: str,\n) -&gt; FuncOutputWithLog:\n\tr\"\"\"\n\tThis tool is used to summarize a paper that is stored in a specific user's recent papers storage.\n\tThis tool is used ONLY when the user explicitly ask for a summarization of the paper.\n\tDO NOT use this tool by yourself.\n\n\tArgs:\n\t\tuser_id (str): The user_id of a lab member.\n\t\tpaper_file_path (str): The file path of a specific paper. Browse the chat context to get the correct\n\t\t\tand valid file path of the paper.\n\n\tReturns:\n\t\tThe summary of the paper.\n\t\"\"\"\n\t# This docstring is used as the tool description.\n\top_name = self._callback_operation.__name__\n\tkwargs = {\"user_id\": user_id, \"paper_file_path\": paper_file_path}\n\tkwargs_str = json.dumps(kwargs)\n\toperation_log = await aoperation_authorize(\n\t\tuser_id=user_id,\n\t\top_name=op_name,\n\t\tkwargs_str=kwargs_str,\n\t\tllm=self._llm,\n\t\tembed_model=self._embed_model,\n\t\tverbose=self._verbose,\n\t)\n\tfn_output = operation_log.operation_output\n\tfn_log = {\"operation_log\": operation_log}\n\treturn FuncOutputWithLog(\n\t\tfn_output=fn_output,\n\t\tfn_log=fn_log,\n\t)\n</code></pre>"},{"location":"code_docs/tools/paper/temporary_papers/paper_summarize/#labridge.tools.paper.temporary_papers.paper_summarize.RecentPaperSummarizeTool.summarize_paper","title":"<code>labridge.tools.paper.temporary_papers.paper_summarize.RecentPaperSummarizeTool.summarize_paper(user_id, paper_file_path)</code>","text":"<p>This tool is used to summarize a paper that is stored in a specific user's recent papers storage. This tool is used ONLY when the user explicitly ask for a summarization of the paper. DO NOT use this tool by yourself.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user_id of a lab member.</p> <p> TYPE: <code>str</code> </p> <code>paper_file_path</code> <p>The file path of a specific paper. Browse the chat context to get the correct and valid file path of the paper.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>FuncOutputWithLog</code> <p>The summary of the paper.</p> Source code in <code>labridge\\tools\\paper\\temporary_papers\\paper_summarize.py</code> <pre><code>def summarize_paper(\n\tself,\n\tuser_id: str,\n\tpaper_file_path: str,\n) -&gt; FuncOutputWithLog:\n\tr\"\"\"\n\tThis tool is used to summarize a paper that is stored in a specific user's recent papers storage.\n\tThis tool is used ONLY when the user explicitly ask for a summarization of the paper.\n\tDO NOT use this tool by yourself.\n\n\tArgs:\n\t\tuser_id (str): The user_id of a lab member.\n\t\tpaper_file_path (str): The file path of a specific paper. Browse the chat context to get the correct\n\t\t\tand valid file path of the paper.\n\n\tReturns:\n\t\tThe summary of the paper.\n\t\"\"\"\n\t# This docstring is used as the tool description.\n\top_name = self._callback_operation.__name__\n\tkwargs = {\"user_id\": user_id, \"paper_file_path\": paper_file_path}\n\tkwargs_str = json.dumps(kwargs)\n\toperation_log = operation_authorize(\n\t\tuser_id=user_id,\n\t\top_name=op_name,\n\t\tkwargs_str=kwargs_str,\n\t\tllm=self._llm,\n\t\tembed_model=self._embed_model,\n\t\tverbose=self._verbose,\n\t)\n\tfn_output = operation_log.operation_output\n\tfn_log = {\"operation_log\": operation_log}\n\treturn FuncOutputWithLog(\n\t\tfn_output=fn_output,\n\t\tfn_log=fn_log,\n\t)\n</code></pre>"},{"location":"demonstration/","title":"\u5e94\u7528\u200b\u5c55\u793a","text":"<p>\u200b\u6211\u4eec\u200b\u5728\u200b\u901a\u8fc7\u200b\u4e00\u4e9b\u200b\u5e94\u7528\u200b\u4f8b\u5b50\u200b\u5c55\u793a\u200bLabridge\u200b\u5982\u4f55\u200b\u6784\u5efa\u200b\u5b9e\u9a8c\u5ba4\u200b\u6c9f\u901a\u200b\u5408\u4f5c\u200b\u7684\u200b\u6865\u6881\u200b</p> <ul> <li>example1</li> </ul>"},{"location":"demonstration/developer_mode/comment_mode/","title":"\u5728\u200b Acting phase \u200b\u8bc4\u8bba","text":"<p>\u200b\u5982\u679c\u200b\u4f60\u200b\u6253\u5f00\u200b\u8bc4\u8bba\u200b\u6a21\u5f0f\u200b\uff0c\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u5728\u200bLabridge\u200b\u7684\u200b Acting phase \u200b\u5bf9\u200bta\u200b\u7684\u200b\u52a8\u4f5c\u200b\u6240\u200b\u5f97\u5230\u200b\u7684\u200bobservation\u200b\u8fdb\u884c\u200b\u8bc4\u8bba\u200b\uff0cLabridge\u200b\u4f1a\u200b\u53c2\u8003\u200b\u4f60\u200b\u7684\u200b\u8bc4\u8bba\u200b\u8fdb\u884c\u200b\u4e0b\u200b\u4e00\u6b65\u200b\u51b3\u7b56\u200b\u3002</p>"},{"location":"demonstration/developer_mode/comment_mode/#_1","title":"\u8bc4\u8bba\u200b\u6a21\u5f0f\u200b\u8bbe\u7f6e","text":"<p>\u200b\u5728\u200b\u8fd9\u4e2a\u200b\u4f8b\u5b50\u200b\u4e2d\u200b\uff0c\u200b\u6211\u4eec\u200b\u540c\u65f6\u200b\u6253\u5f00\u200b\u4e86\u200b\u6307\u4ee4\u200b\u6a21\u5f0f\u200b\u4e0e\u200b\u8bc4\u8bba\u200b\u6a21\u5f0f\u200b\u3002</p> <p></p>"},{"location":"demonstration/developer_mode/comment_mode/#_2","title":"\u793a\u4f8b","text":""},{"location":"demonstration/developer_mode/instruct_mode/","title":"\u5728\u200b reasoning phase \u200b\u6307\u5bfc\u200b\u601d\u8003","text":"<p>\u200b\u5982\u679c\u200b\u4f60\u200b\u6253\u5f00\u200b\u4e86\u200b\u6307\u4ee4\u200b\u6a21\u5f0f\u200b\uff0cLabridge\u200b\u4f1a\u200b\u5728\u200b Reasoning phase \u200b\u5c06\u200bta\u200b\u7684\u200b\u601d\u8003\u200b\u51b3\u7b56\u200b\u5c55\u73b0\u200b\u7ed9\u200b\u4f60\u200b\uff0c\u200b\u5e76\u200b\u6839\u636e\u200b\u4f60\u200b\u7684\u200b\u6307\u5bfc\u200b\u8fdb\u884c\u200b\u8c03\u6574\u200b\u3002</p>"},{"location":"demonstration/developer_mode/instruct_mode/#_1","title":"\u6307\u4ee4\u200b\u6a21\u5f0f\u200b\u8bbe\u7f6e\u200b:","text":""},{"location":"demonstration/developer_mode/instruct_mode/#_2","title":"\u793a\u4f8b\u200b:","text":""},{"location":"demonstration/experiment_log/record_log/","title":"\u5b9e\u9a8c\u200b\u65e5\u5fd7\u200b\u8bb0\u5f55","text":""},{"location":"demonstration/experiment_log/retrieve_log/","title":"\u5b9e\u9a8c\u200b\u65e5\u5fd7\u200b QA","text":""},{"location":"demonstration/instrument/instrument_docs/","title":"\u4eea\u5668\u200b\u4fe1\u606f\u200b QA","text":""},{"location":"demonstration/paper/paper_download/","title":"\u6587\u732e\u200b\u4e0b\u8f7d","text":""},{"location":"demonstration/paper/recent_papers_qa/","title":"\u8fd1\u671f\u200b\u6587\u732e\u200b QA","text":"<p>\u200b\u57fa\u4e8e\u200b\u5728\u200b\u6587\u732e\u200b\u4e0b\u8f7d\u200b\u4e2d\u200b\u4e0b\u8f7d\u200b\u7684\u200b\u6587\u732e\u200b:</p> <p></p>"},{"location":"demonstration/paper/shared_papers/","title":"\u5171\u4eab\u200b\u6587\u732e\u200b QA","text":""},{"location":"deployment/","title":"\u57fa\u4e8e\u200b\u6607\u200b\u817e\u200b\u8f6f\u786c\u4ef6\u200b\u7684\u200b\u9879\u76ee\u200b\u90e8\u7f72","text":"<p>\u200b\u57fa\u4e8e\u200b\u6607\u200b\u817e\u200b\u7684\u200b\u8f6f\u786c\u4ef6\u200b\u751f\u6001\u200b\uff0c\u200b\u6211\u4eec\u200b\u5bf9\u200bLabridge\u200b\u7684\u200b\u9879\u76ee\u200b\u90e8\u7f72\u200b\u91c7\u7528\u200b\u4e86\u200b\u591a\u5c42\u6b21\u200b\u7684\u200b\u90e8\u7f72\u200b\u65b9\u5f0f\u200b\u3002</p> <p></p>"},{"location":"deployment/#ailabridge","title":"\u6607\u200b\u817e\u200bAI\u200b\u82af\u7247\u200b\u52a0\u901f\u200bLabridge\u200b\u8fd0\u884c","text":"<p>\u200b\u6211\u4eec\u200b\u91c7\u7528\u200b\u642d\u8f7d\u200b\u6607\u200b\u817e\u200bAI\u200b\u82af\u7247\u200b\u7684\u200b OrangePi \u200b\u8fdb\u884c\u200bEmbedding\u200b\u6a21\u578b\u200b\u7684\u200b\u90e8\u7f72\u200b\uff0c\u200b\u5176\u200b\u642d\u8f7d\u200b\u7684\u200b\u6607\u200b\u817e\u200bAI\u200b\u82af\u7247\u200b\u5177\u5907\u200b 20TOPS (FP16) AI\u200b\u7b97\u529b\u200b\uff0c</p> <p>\u200b\u5145\u5206\u200b\u52a0\u901f\u200bLabridge\u200b\u7684\u200b\u4fe1\u606f\u68c0\u7d22\u200b\uff0c\u200b\u53d1\u6325\u200b\u6570\u636e\u200b\u672c\u5730\u200b\u90e8\u7f72\u200b\u7684\u200b\u4f18\u52bf\u200b\uff0c\u200b\u4fdd\u969c\u200b\u6570\u636e\u5b89\u5168\u200b\u3002</p> <p>\u200b\u540c\u65f6\u200b\uff0c\u200b\u5927\u200b\u8bed\u8a00\u200b\u6a21\u578b\u200b (LLM) \u200b\u90e8\u7f72\u200b\u5728\u200bGPU\u200b\u670d\u52a1\u5668\u200b\uff0c\u200b\u901a\u8fc7\u200bHTTP\u200b\u4e0e\u200bEmbedding\u200b\u6a21\u578b\u200b\u8fdb\u884c\u200b\u901a\u4fe1\u200b\u3002</p>"},{"location":"deployment/#labridge","title":"\u6607\u200b\u601d\u8d4b\u200b\u80fd\u200bLabridge","text":"<p>\u200b\u4e0d\u8bba\u662f\u200bEmbedding\u200b\u6a21\u578b\u200b\u8fd8\u662f\u200bLLM\uff0c\u200b\u90fd\u200b\u4f9d\u8d56\u4e8e\u200b Mindspore \u200b\u6df1\u5ea6\u200b\u5b66\u4e60\u200b\u6846\u67b6\u200b\u4e0e\u200b MindNLP \u200b\u81ea\u7136\u8bed\u8a00\u200b\u5904\u7406\u200b\u5957\u4ef6\u200b\u5b9e\u73b0\u200b\uff0c</p> <p>\u200b\u6607\u200b\u817e\u200b\u7684\u200b\u8f6f\u4ef6\u200b\u751f\u6001\u200b\u8d4b\u4e88\u200b\u4e86\u200bLabridge\u200b\u7075\u9b42\u200b\u4e0e\u200b\u667a\u80fd\u200b\u5f15\u64ce\u200b\u3002</p>"},{"location":"function_modules/chat_history/","title":"\u4ea4\u4e92\u200b\u65e5\u5fd7","text":""},{"location":"function_modules/chat_history/#_2","title":"\u201c\u200b\u6e29\u6545\u800c\u77e5\u65b0\u200b\u201d","text":"<p>\u200b\u9664\u4e86\u200b\u4e3a\u200b\u5f53\u524d\u200b\u4f1a\u8bdd\u200b\u670d\u52a1\u200b\u7684\u200bshort-term memory\u200b\u4e4b\u5916\u200b\uff0cLabridge\u200b\u4f1a\u200b\u4fdd\u5b58\u200b\u4e0e\u200b\u5b9e\u9a8c\u5ba4\u200b\u6bcf\u4e2a\u200b\u6210\u5458\u200b\u95f4\u200b\u7684\u200b\u4ea4\u4e92\u200b\u65e5\u5fd7\u200b\uff0c \u200b\u4ea4\u4e92\u200b\u65e5\u5fd7\u200b\u7684\u200b\u5185\u5bb9\u200b\u5305\u62ec\u200b\uff1a</p>"},{"location":"function_modules/chat_history/#_3","title":"\u804a\u5929\u8bb0\u5f55","text":"<p>\u200b\u4ee5\u200b\u5355\u6b21\u200b QA \u200b\u4e3a\u200b\u5355\u5143\u200b\uff0c\u200b\u8bb0\u5f55\u200b\u4e0b\u200b\u6210\u5458\u200b\u4e0e\u200bLabridge\u200b\u4e4b\u95f4\u200b\u7684\u200b\u804a\u5929\u8bb0\u5f55\u200b\u3002</p>"},{"location":"function_modules/chat_history/#_4","title":"\u5de5\u5177\u200b\u8c03\u7528\u200b\u65e5\u5fd7","text":"<p>\u200b\u5982\u679c\u200b\u5728\u200bQA\u200b\u7684\u200b\u8fc7\u7a0b\u200b\u4e2d\u200b\uff0cLabridge\u200b\u8c03\u7528\u200b\u4e86\u200b\u67d0\u4e9b\u200b\u5de5\u5177\u200b(Tools)\uff0c\u200b\u76f8\u5173\u200b\u5de5\u5177\u200b\u7684\u200b\u65e5\u5fd7\u200b(ToolLog)\u200b\u540c\u6837\u200b\u4f1a\u200b\u8bb0\u5f55\u200b\u5728\u200b\u672c\u6b21\u200bQA\u200b\u7684\u200b\u8bb0\u5f55\u200b\u4e2d\u200b\u3002 \u200b\u5173\u4e8e\u200b <code>ToolLog</code> \u200b\u7684\u200b\u6570\u636e\u7ed3\u6784\u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>tools.base.tool_log</code>\u3002</p> <p>\u200b\u4ee5\u4e0a\u200b\u4fe1\u606f\u200b\u5c06\u200b\u8bb0\u5f55\u200b\u4e3a\u200b\u5411\u91cf\u200b\u6570\u636e\u5e93\u200b\uff0c\u200b\u4f9b\u200bLabridge\u200b\u5728\u200b\u5408\u9002\u200b\u7684\u200b\u65f6\u673a\u200b\u8fdb\u884c\u200b\u68c0\u7d22\u200b\uff0c\u200b\u4e3a\u200bLabridge\u200b\u63d0\u4f9b\u200b\u957f\u671f\u200b\u8bb0\u5fc6\u200b\u7684\u200b\u529f\u80fd\u200b\u3002</p> <p>\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u8fdb\u4e00\u6b65\u200b\u4e86\u89e3\u200b\u4ea4\u4e92\u200b\u65e5\u5fd7\u200b\u5411\u91cf\u200b\u6570\u636e\u5e93\u200b\u7684\u200b\u7ed3\u6784\u200b\u4e0e\u200b\u68c0\u7d22\u200b</p>"},{"location":"function_modules/chat_history/short-term_history/","title":"\u77ed\u671f\u200b\u8bb0\u5fc6","text":"<p>Labridge\u200b\u4e3a\u200b\u6bcf\u4f4d\u200b\u6210\u5458\u200b\u6216\u200b\u6210\u5458\u200b\u5c0f\u7ec4\u200b\u5b58\u50a8\u200b\u4e00\u6bb5\u200b\u8fd1\u671f\u200b\u7684\u200b\u4ea4\u4e92\u200b\u8bb0\u5f55\u200b\uff0c\u200b\u8be5\u200b\u4ea4\u4e92\u200b\u8bb0\u5f55\u200b\u4e3a\u200b\u961f\u5217\u200b\u5f0f\u200b\u7ed3\u6784\u200b\uff0c\u200b\u5176\u200b\u957f\u5ea6\u200b\u56fa\u5b9a\u200b\u3002</p> <p>\u200b\u6bcf\u6b21\u200b\u4e0e\u200b\u6210\u5458\u200b\u8fdb\u884c\u200b\u4ea4\u4e92\u200b\uff0c\u200b\u76f8\u5e94\u200b\u7684\u200b\u4ea4\u4e92\u200b\u8bb0\u5f55\u200b\u4f1a\u200b\u4e0e\u200b\u8be5\u200b\u6210\u5458\u200b\u5f53\u524d\u200b\u7684\u200b\u6d88\u606f\u200b\u4f5c\u4e3a\u200b\u63d0\u793a\u200b\u8bcd\u200b\u7684\u200b\u4e00\u90e8\u5206\u200b\u8f93\u5165\u200b\u7ed9\u200b LLM\u3002</p> <p>\u200b\u7528\u6237\u200b\u53ef\u4ee5\u200b\u624b\u52a8\u200b\u6e05\u7a7a\u200b\u8be5\u200b\u77ed\u671f\u200b\u8bb0\u5fc6\u200b\u5f00\u542f\u200b\u65b0\u200b\u7684\u200b\u8bdd\u9898\u200b\uff0c\u200b\u907f\u514d\u200b\u5386\u53f2\u200b\u4f1a\u8bdd\u200b\u7684\u200b\u5e72\u6270\u200b\u3002</p>"},{"location":"function_modules/chat_history/long-term_history/retrieve/","title":"\u4ea4\u4e92\u200b\u65e5\u5fd7\u200b\u68c0\u7d22","text":"<p>\u200b\u4ea4\u4e92\u200b\u65e5\u5fd7\u200b\u68c0\u7d22\u200b\u7684\u200b\u7279\u70b9\u200b\u662f\u200b\u4e0e\u200b\u65f6\u95f4\u200b\u5f3a\u200b\u76f8\u5173\u200b\uff0c\u200b\u56e0\u6b64\u200bLabridge\u200b\u91c7\u7528\u200b\u76f8\u4f3c\u6027\u200b\u68c0\u7d22\u200b + \u200b\u65f6\u95f4\u200b\u6233\u200b\u8fc7\u6ee4\u200b\u7684\u200b\u68c0\u7d22\u200b\u65b9\u5f0f\u200b\u6765\u200b\u8fdb\u884c\u200b\u4ea4\u4e92\u200b\u65e5\u5fd7\u200b\u68c0\u7d22\u200b\u3002</p> <p></p>"},{"location":"function_modules/chat_history/long-term_history/retrieve/#_2","title":"\u65f6\u95f4\u200b\u6233\u200b\u8fc7\u6ee4\u200b\uff1a","text":"<p>\u200b\u6bcf\u4e2a\u200b QA \u200b\u65e5\u5fd7\u200b\u8282\u70b9\u200b\u90fd\u200b\u8bb0\u5f55\u200b\u4e86\u200b\u76f8\u5e94\u200b\u7684\u200b\u65f6\u95f4\u200b\u6233\u200b\uff0cLabridge\u200b\u6839\u636e\u200b\u8f93\u5165\u200b\u7684\u200b\u5f00\u59cb\u200b\u65f6\u95f4\u200b\u4e0e\u200b\u7ed3\u675f\u200b\u65f6\u95f4\u200b\u6765\u200b\u5bf9\u200b\u65e5\u5fd7\u200b\u8282\u70b9\u200b\u8fdb\u884c\u200b\u8fc7\u6ee4\u200b\uff0c\u200b\u7f29\u5c0f\u200b\u68c0\u7d22\u200b\u8303\u56f4\u200b\u3002</p>"},{"location":"function_modules/chat_history/long-term_history/retrieve/#_3","title":"\u76f8\u4f3c\u6027\u200b\u68c0\u7d22\u200b\uff1a","text":"<p>\u200b\u5728\u200b\u7ecf\u8fc7\u200b\u8fc7\u6ee4\u200b\u7f29\u5c0f\u200b\u8303\u56f4\u200b\u540e\u200b\u7684\u200b\u65e5\u5fd7\u200b\u8282\u70b9\u200b\u4e2d\u200b\uff0c\u200b\u6839\u636e\u200bQuery\u200b\u7684\u200b<code>Embedding\u200b\u5411\u91cf\u200b</code>\u200b\u4e0e\u200b QA \u200b\u65e5\u5fd7\u200b\u5411\u91cf\u200b\u7684\u200b\u76f8\u4f3c\u6027\u200b\u68c0\u7d22\u200b\u51fa\u200b\u6700\u200b\u76f8\u4f3c\u200b\u7684\u200b<code>relevant_top_k</code>\u200b\u6761\u200b\u4ea4\u4e92\u200b\u65e5\u5fd7\u200b\u3002</p>"},{"location":"function_modules/chat_history/long-term_history/retrieve/#_4","title":"\u6dfb\u52a0\u200b\u4e0a\u4e0b\u6587\u200b\uff1a","text":"<p>\u200b\u7531\u4e8e\u200bLabridge\u200b\u4e0e\u200b\u6210\u5458\u200b\u4e4b\u95f4\u200b\u7684\u200b\u4ea4\u4e92\u200b\u5f80\u5f80\u200b\u662f\u200b\u8fde\u7eed\u200b\u7684\u200b\u591a\u8f6e\u200b <code>QA</code>\uff0c\u200b\u56e0\u6b64\u200b\u4e3a\u200b\u6240\u6709\u200b\u68c0\u7d22\u200b\u7ed3\u679c\u200b\u6dfb\u52a0\u200b\u4e0a\u4e0b\u6587\u200b(\u200b\u5373\u200b\u4e4b\u524d\u200b\u7684\u200bQA\u200b\u4e0e\u200b\u4e4b\u540e\u200b\u7684\u200bQA)\uff0c\u200b\u4fdd\u8bc1\u200b\u4ea4\u4e92\u200b\u65e5\u5fd7\u200b\u7684\u200b\u5b8c\u6574\u6027\u200b\u3002</p>"},{"location":"function_modules/chat_history/long-term_history/retrieve/#_5","title":"\u6309\u200b\u65f6\u95f4\u200b\u91cd\u6392\u200b\uff1a","text":"<p>\u200b\u4ea4\u4e92\u200b\u65e5\u5fd7\u200b\u7684\u200b\u7279\u70b9\u200b\u662f\u200b\u65f6\u95f4\u200b\u5355\u5411\u6027\u200b\uff0c\u200b\u65e5\u5fd7\u200b\u4e4b\u95f4\u200b\u7684\u200b\u987a\u5e8f\u200b\u5f88\u5927\u200b\u7a0b\u5ea6\u200b\u5f71\u54cd\u200b\u5bf9\u8bdd\u200b\u7684\u200b\u8bed\u4e49\u200b\uff0c\u200b\u56e0\u6b64\u200b\u5728\u200b\u6dfb\u52a0\u200b\u4e0a\u4e0b\u6587\u200b\u540e\u200b\uff0c\u200b\u5bf9\u200b\u5f97\u5230\u200b\u7684\u200b QA \u200b\u65e5\u5fd7\u200b\u8282\u70b9\u200b\u8fdb\u884c\u200b\u53bb\u200b\u91cd\u200b\u4e0e\u200b\u6392\u5e8f\u200b\uff0c\u200b\u4fdd\u8bc1\u200b\u4ea4\u4e92\u200b\u65e5\u5fd7\u200b\u7684\u200b\u8fde\u8d2f\u6027\u200b\u3002</p> <p>\u200b\u5173\u4e8e\u200b\u4ea4\u4e92\u200b\u65e5\u5fd7\u200b\u68c0\u7d22\u200b\u7684\u200b\u5177\u4f53\u200b\u7ec6\u8282\u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Func_modules.memory.chat.retrieve</code></p>"},{"location":"function_modules/chat_history/long-term_history/store/","title":"\u4ea4\u4e92\u200b\u65e5\u5fd7\u200b\u5b58\u50a8\u200b\u7ed3\u6784","text":"<p>\u200b\u4ea4\u4e92\u200b\u65e5\u5fd7\u200b\u4ee5\u200b\u5355\u8f6e\u200b QA \u200b\u4e3a\u200b\u57fa\u672c\u200b\u5355\u5143\u200b\uff0c\u200b\u5185\u5bb9\u200b\u5305\u542b\u200b\u804a\u5929\u8bb0\u5f55\u200b\u4e0e\u200b\u671f\u95f4\u200b\u7684\u200b\u5de5\u5177\u200b\u65e5\u5fd7\u200b\u3002\u200b\u4e3a\u200b\u6bcf\u4f4d\u200b\u6210\u5458\u200b\u6216\u200b\u6210\u5458\u200b\u5c0f\u7ec4\u200b\u5b58\u50a8\u200b\u72ec\u7acb\u200b\u7684\u200b\u5411\u91cf\u200b\u6570\u636e\u5e93\u200b\u3002</p> <p>\u200b\u6bcf\u4e2a\u200b\u5411\u91cf\u200b\u6570\u636e\u5e93\u200b\u7684\u200b\u7ed3\u6784\u200b\u7c7b\u4f3c\u200b\u4e8e\u200b\u4e00\u4e2a\u200b\u53cc\u5411\u200b\u94fe\u8868\u200b\u7684\u200b\u7ed3\u6784\u200b\u3002</p> <p></p> <ul> <li>\u200b\u6700\u200b\u5f00\u59cb\u200b\u7684\u200b\u8282\u70b9\u200b\u4e3a\u200b\u521d\u59cb\u200b\u8282\u70b9\u200b(first node)\uff0c\u200b\u521d\u59cb\u200b\u8282\u70b9\u200b\u4e2d\u200b\u5b58\u50a8\u200b\u4e86\u200b\u8be5\u200b\u6570\u636e\u5e93\u200b\u7684\u200b\u6240\u5c5e\u200b\u5bf9\u8c61\u200b\uff0c\u200b\u4e0e\u200b\u8be5\u200b\u6570\u636e\u5e93\u200b\u7684\u200b\u63cf\u8ff0\u200b\u3002\u200b\u989d\u5916\u200b\u4fe1\u606f\u200b\u5305\u62ec\u200b\u8be5\u200b\u6570\u636e\u5e93\u200b\u7684\u200b\u521b\u5efa\u200b\u65f6\u95f4\u200b\u3002</li> <li>\u200b\u65b0\u200b\u52a0\u5165\u200b\u7684\u200b QA \u200b\u65e5\u5fd7\u200b\u5355\u5143\u200b\u5c06\u200b\u4f5c\u4e3a\u200b\u6700\u540e\u200b\u4e00\u4e2a\u200b\u8282\u70b9\u200b\u52a0\u5165\u200b\u8be5\u200b\u94fe\u8868\u200b\u7ed3\u6784\u200b\uff0c\u200b\u8be5\u200b\u8282\u70b9\u200b\u4e2d\u200b\u5b58\u50a8\u200b\u4e86\u200b QA \u200b\u7684\u200b\u65e5\u5fd7\u200b\uff0c\u200b\u989d\u5916\u200b\u4fe1\u606f\u200b\u5305\u62ec\u200b\u8be5\u200b QA \u200b\u7684\u200b\u53d1\u751f\u200b\u65f6\u95f4\u200b(<code>date</code> <code>time</code>)\u3002</li> </ul> <p>\u200b\u5728\u200b\u6bcf\u6b21\u200b\u4e0e\u200b\u6210\u5458\u200b\u8fdb\u884c\u200b\u4ea4\u4e92\u200b\uff0c\u200b\u6216\u200b\u5728\u200b\u6210\u5458\u200b\u5c0f\u7ec4\u200b\u7684\u200b\u7fa4\u804a\u200b\u4e2d\u200b\u4ea4\u4e92\u200b\u540e\u200b\uff0c\u200b\u4ea4\u4e92\u200b\u65e5\u5fd7\u200b\u90fd\u200b\u4f1a\u200b\u88ab\u200b\u8bb0\u5f55\u200b\u5728\u200b\u76f8\u5e94\u200b\u7684\u200b\u5411\u91cf\u200b\u6570\u636e\u5e93\u200b\u4e2d\u200b\uff0c\u200b\u5e76\u200b\u6301\u4e45\u200b\u5316\u200b\u3002</p> <p>\u200b\u5173\u4e8e\u200b\u4ea4\u4e92\u200b\u65e5\u5fd7\u200b\u5b58\u50a8\u200b\u7ed3\u6784\u200b\u7684\u200b\u7ec6\u8282\u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Func_modules.memory.chat.store</code></p>"},{"location":"function_modules/experiment_log/","title":"\u5b9e\u9a8c\u200b\u65e5\u5fd7","text":""},{"location":"function_modules/experiment_log/#_2","title":"\u201c\u200b\u4f60\u200b\u7684\u200b\u6bcf\u200b\u4e00\u4e2a\u200b\u5b9e\u9a8c\u200b\u7ed3\u679c\u200b\uff0c\u200b\u90fd\u200b\u6709\u200b\u53ef\u80fd\u200b\u6539\u53d8\u200b\u4e16\u754c\u200b\u201d","text":"<p>\u200b\u7814\u7a76\u8005\u200b\u4eec\u200b\u901a\u8fc7\u200b\u5b9e\u9a8c\u200b\u6765\u200b\u63a2\u7d22\u200b\u4eba\u7c7b\u200b\u77e5\u8bc6\u200b\u7684\u200b\u8fb9\u754c\u200b\uff0c\u200b\u867d\u7136\u200b\u5927\u90e8\u5206\u200b\u63a2\u7d22\u200b\u90fd\u200b\u662f\u200b\u201c\u200b\u5931\u8d25\u200b\u7684\u200b\u201d\uff0c\u200b\u4f46\u200b\u968f\u7740\u200b\u7814\u7a76\u8005\u200b\u8ba4\u77e5\u200b\u7684\u200b\u53d8\u5316\u200b\uff0c \u200b\u6216\u8bb8\u200b\u53ef\u4ee5\u200b\u4ece\u200b\u201c\u200b\u5931\u8d25\u200b\u201d\u200b\u7684\u200b\u5b9e\u9a8c\u200b\u7ed3\u679c\u200b\u4e2d\u200b\u53d1\u6398\u200b\u51fa\u65b0\u200b\u7684\u200b\u4ef7\u503c\u200b\uff1b\u200b\u53c8\u200b\u6216\u8005\u200b\u5176\u5b83\u200b\u65b9\u5411\u200b\u7684\u200b\u7814\u7a76\u8005\u200b\u80fd\u200b\u4ece\u200b\u53e6\u200b\u4e00\u4e2a\u200b\u89d2\u5ea6\u200b\u53d1\u73b0\u200b\u5b83\u200b\u72ec\u7279\u200b\u7684\u200b\u4ef7\u503c\u200b\u3002</p> <p>\u200b\u56e0\u6b64\u200b\u6bcf\u200b\u4e00\u6b21\u200b\u7684\u200b\u5b9e\u9a8c\u200b\u7ed3\u679c\u200b\u90fd\u200b\u503c\u5f97\u200b\u8be6\u7ec6\u200b\u8bb0\u5f55\u200b\uff0cLabridge\u200b\u4e3a\u200b\u5b9e\u9a8c\u5ba4\u200b\u6210\u5458\u200b\u4eec\u200b\u63d0\u4f9b\u200b\u5b9e\u9a8c\u200b\u65e5\u5fd7\u200b\u8bb0\u5f55\u200b\u7684\u200b\u529f\u80fd\u200b\uff1a</p>"},{"location":"function_modules/experiment_log/#_3","title":"\u4e2a\u4eba\u200b\u5b9e\u9a8c\u200b\u65e5\u5fd7\u200b\u8bb0\u5f55\u200b\uff1a","text":"<p>Labridge\u200b\u4e3a\u200b\u5b9e\u9a8c\u5ba4\u200b\u6bcf\u4e2a\u200b\u6210\u5458\u200b\u72ec\u7acb\u200b\u5730\u200b\u8bb0\u5f55\u200b\u5176\u200b\u4e2a\u4eba\u200b\u5b9e\u9a8c\u200b\u65e5\u5fd7\u200b, \u200b\u5e76\u200b\u534f\u52a9\u200b\u6210\u5458\u200b\u68b3\u7406\u200b\u3001\u200b\u6574\u5408\u200b\u5b9e\u9a8c\u200b\u7ed3\u679c\u200b\u3002</p>"},{"location":"function_modules/experiment_log/#_4","title":"\u5171\u4eab\u200b\u5b9e\u9a8c\u200b\u65e5\u5fd7\u200b\u8bb0\u5f55\u200b\uff1a","text":"<p>Labridge\u200b\u540c\u65f6\u200b\u4e3a\u200b\u6574\u4e2a\u200b\u5b9e\u9a8c\u5ba4\u200b\u8bb0\u5f55\u200b\u5171\u4eab\u200b\u5b9e\u9a8c\u200b\u7ed3\u679c\u200b\u8bb0\u5f55\u200b\uff0c \u200b\u6210\u5458\u200b\u4eec\u200b\u53ef\u4ee5\u200b\u5c06\u200b\u81ea\u5df1\u200b\u7684\u200b\u5b9e\u9a8c\u200b\u7ed3\u679c\u200b\u52a0\u5165\u200b\u5230\u200b\u5171\u4eab\u200b\u8bb0\u5f55\u200b\u4e2d\u200b\uff0c\u200b\u4f9b\u200b\u6240\u6709\u200b\u6210\u5458\u200b\u68c0\u7d22\u200b\u4e0e\u200b\u9605\u89c8\u200b\u3002</p>"},{"location":"function_modules/experiment_log/personal_experiment/","title":"\u4e2a\u4eba\u200b\u5b9e\u9a8c\u200b\u65e5\u5fd7","text":"<p>Labridge\u200b\u4e3a\u200b\u5b9e\u9a8c\u5ba4\u200b\u7684\u200b\u6bcf\u4f4d\u200b\u6210\u5458\u200b\u8bb0\u5f55\u200b\u5176\u200b\u5b9e\u9a8c\u200b\u65e5\u5fd7\u200b\u3002</p>"},{"location":"function_modules/experiment_log/personal_experiment/#_2","title":"\u4e2a\u4eba\u200b\u5b9e\u9a8c\u200b\u65e5\u5fd7\u200b\u5b58\u50a8\u200b\u7ed3\u6784","text":"<p>\u200b\u6210\u5458\u200b\u7684\u200b\u6bcf\u4e2a\u200b\u5b9e\u9a8c\u200b\u5bf9\u5e94\u200b\u7684\u200b\u8bb0\u5f55\u200b\u5b58\u50a8\u200b\u5728\u200b\u4e2a\u4eba\u200b\u5b9e\u9a8c\u200b\u65e5\u5fd7\u200b\u5411\u91cf\u200b\u6570\u636e\u5e93\u200b</p>"},{"location":"function_modules/experiment_log/personal_experiment/#_3","title":"\u4e2a\u4eba\u200b\u5b9e\u9a8c\u200b\u65e5\u5fd7\u200b\u68c0\u7d22","text":"<p>Labridge\u200b\u4ece\u200b\u5b9e\u9a8c\u200b\u65e5\u5fd7\u200b\u8bb0\u5f55\u200b\u4e2d\u200b\u68c0\u7d22\u200b\u4fe1\u606f\u200b\u534f\u52a9\u200b\u6210\u5458\u200b\u8fdb\u884c\u200b\u5b9e\u9a8c\u200b\u3002</p>"},{"location":"function_modules/experiment_log/personal_experiment/#_4","title":"\u4e2a\u4eba\u200b\u5b9e\u9a8c\u200b\u65e5\u5fd7\u200b\u7ba1\u7406","text":"<p>Labridge\u200b\u901a\u8fc7\u200b\u8c03\u7528\u200b\u5de5\u5177\u200b(Tools)\u200b\u4e3a\u200b\u6210\u5458\u200b\u7ba1\u7406\u200b\u5176\u200b\u5b9e\u9a8c\u200b\u65e5\u5fd7\u200b\uff0c\u200b\u5177\u4f53\u200b\u7ec6\u8282\u200b\u53c2\u89c1\u200b <code>Agent\u200b\u4e0e\u200b\u53ef\u7528\u200b\u5de5\u5177\u200b</code></p>"},{"location":"function_modules/experiment_log/personal_experiment/retrieve/","title":"\u4e2a\u4eba\u200b\u5b9e\u9a8c\u200b\u65e5\u5fd7\u200b\u68c0\u7d22","text":"<p>\u200b\u5b9e\u9a8c\u200b\u65e5\u5fd7\u200b\u4e0e\u200b\u65f6\u95f4\u200b\u6709\u5173\u200b\uff0c\u200b\u56e0\u6b64\u200bLabridge\u200b\u6839\u636e\u200b\u5b9e\u9a8c\u200b\u65e5\u5fd7\u200b\u7684\u200b\u5b58\u50a8\u200b\u7ed3\u6784\u200b\u91c7\u7528\u200b\u591a\u7ea7\u200b\u68c0\u7d22\u200b + \u200b\u65f6\u95f4\u200b\u6233\u200b\u8fc7\u6ee4\u200b\u7684\u200b\u68c0\u7d22\u200b\u65b9\u5f0f\u200b</p> <p></p>"},{"location":"function_modules/experiment_log/personal_experiment/retrieve/#_2","title":"\u7b2c\u4e00\u6b65\u200b\u68c0\u7d22","text":"<p>\u200b\u5728\u200b\u7b2c\u4e00\u6b65\u200b\u68c0\u7d22\u200b\u4e2d\u200b\uff0cLabridge\u200b\u6839\u636e\u200bQuery\u200b\u5411\u91cf\u200b\u4e0e\u200b\u6240\u6709\u200b\u5b9e\u9a8c\u200b\u8282\u70b9\u200b\u7684\u200b\u5b9e\u9a8c\u200b\u63cf\u8ff0\u200b\u4e4b\u95f4\u200b\u7684\u200b\u76f8\u4f3c\u6027\u200b\uff0c\u200b\u68c0\u7d22\u200b\u51fa\u200b\u6700\u200b\u6709\u200b\u53ef\u80fd\u200b\u7684\u200b <code>experiment_top_k</code> \u200b\u4e2a\u200b\u5b9e\u9a8c\u200b\u3002 \u200b\u540c\u65f6\u200b\uff0cLabridge\u200b\u5728\u200b\u6240\u6709\u200b\u7684\u200b\u65e5\u5fd7\u200b\u7c7b\u578b\u200b\u7684\u200b\u8282\u70b9\u200b\u4e2d\u200b\uff0c\u200b\u6839\u636e\u200b\u76f8\u4f3c\u6027\u200b\u68c0\u7d22\u200b\u51fa\u200b\u6700\u200b\u76f8\u4f3c\u200b\u7684\u200b <code>first_top_k</code> \u200b\u65e5\u5fd7\u200b\u8282\u70b9\u200b\uff0c\u200b\u5e76\u200b\u83b7\u53d6\u200b\u5b83\u4eec\u200b\u5bf9\u5e94\u200b\u7684\u200b\u5b9e\u9a8c\u200b\u8282\u70b9\u200b\u3002</p> <p>\u200b\u8fd9\u4e9b\u200b\u68c0\u7d22\u200b\u6240\u5f97\u200b\u7684\u200b\u5b9e\u9a8c\u200b\u8282\u70b9\u200b\u5c06\u200b\u4f5c\u4e3a\u200b\u4e0b\u200b\u4e00\u6b65\u200b\u68c0\u7d22\u200b\u7684\u200b\u8303\u56f4\u200b\u3002</p>"},{"location":"function_modules/experiment_log/personal_experiment/retrieve/#_3","title":"\u7b2c\u4e8c\u6b65\u200b\u68c0\u7d22","text":"<p>\u200b\u5728\u200b\u7b2c\u4e00\u6b65\u200b\u68c0\u7d22\u200b\u6240\u5f97\u200b\u7684\u200b\u5b9e\u9a8c\u200b\u8282\u70b9\u200b\u8303\u56f4\u200b\u5185\u200b\uff0cLabridge\u200b\u5728\u200b\u8fd9\u4e9b\u200b\u5b9e\u9a8c\u200b\u8282\u70b9\u200b\u7684\u200b\u65e5\u5fd7\u200b\u8282\u70b9\u200b\u4e2d\u200b\u68c0\u7d22\u200b\u51fa\u200b <code>second_top_k</code> \u200b\u4e2a\u200b\u65e5\u5fd7\u200b\u8282\u70b9\u200b\uff0c\u200b\u4f5c\u4e3a\u200b\u68c0\u7d22\u200b\u7ed3\u679c\u200b\u3002</p>"},{"location":"function_modules/experiment_log/personal_experiment/retrieve/#_4","title":"\u65f6\u95f4\u200b\u6233\u200b\u8fc7\u6ee4","text":"<p>\u200b\u5728\u200b\u7b2c\u4e8c\u6b65\u200b\u68c0\u7d22\u200b\u4e2d\u200b\uff0cLabridge\u200b\u4f1a\u200b\u6839\u636e\u200b\u8f93\u5165\u200b\u7684\u200b\u8d77\u6b62\u200b\u65f6\u95f4\u200b\uff08\u200b\u5982\u679c\u200b\u63d0\u4f9b\u200b\u4e86\u200b\uff09\u200b\u8fdb\u884c\u200b\u65f6\u95f4\u200b\u6233\u200b\u8fc7\u6ee4\u200b\u3002\u200b\u6700\u7ec8\u200b\u68c0\u7d22\u200b\u51fa\u200b\u7684\u200b\u5b9e\u9a8c\u200b\u65e5\u5fd7\u200b\u5185\u5bb9\u200b\u5c06\u200b\u63d0\u4f9b\u200b\u7ed9\u200b LLM \u200b\u4f5c\u4e3a\u200b\u8f93\u5165\u200b\u3002</p> <p>\u200b\u5173\u4e8e\u200b\u4e2a\u4eba\u200b\u5b9e\u9a8c\u200b\u65e5\u5fd7\u200b\u68c0\u7d22\u200b\u7684\u200b\u5177\u4f53\u200b\u7ec6\u8282\u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Func_modules.memory.experiment.retrieve_log</code></p>"},{"location":"function_modules/experiment_log/personal_experiment/store/","title":"\u4e2a\u4eba\u200b\u5b9e\u9a8c\u200b\u65e5\u5fd7\u200b\u5b58\u50a8\u200b\u7ed3\u6784","text":"<p>\u200b\u5b9e\u9a8c\u200b\u65e5\u5fd7\u200b\u5b58\u50a8\u200b\u4e8e\u200b\u4e00\u4e2a\u200b\u5411\u91cf\u200b\u6570\u636e\u5e93\u200b\u4e2d\u200b\uff0c\u200b\u7ed3\u6784\u200b\u5982\u4e0b\u200b\u56fe\u200b\u6240\u793a\u200b\u3002</p> <p></p> <ul> <li>\u200b\u6570\u636e\u5e93\u200b\u4e2d\u200b\u5b58\u5728\u200b\u4e00\u4e2a\u200b\u6839\u200b\u8282\u70b9\u200b\uff0c\u200b\u6240\u6709\u200b\u7684\u200b\u5b9e\u9a8c\u200b\u8282\u70b9\u200b\u662f\u200b\u8be5\u200b\u6839\u200b\u8282\u70b9\u200b\u7684\u200b\u5b50\u200b\u8282\u70b9\u200b\u3002</li> <li> <p>\u200b\u6bcf\u4e2a\u200b\u5b9e\u9a8c\u200b\u8282\u70b9\u200b\u5305\u542b\u200b\u5982\u4e0b\u200b\u4fe1\u606f\u200b\uff1a</p> </li> <li> <p>\u200b\u5b9e\u9a8c\u200b\u540d\u79f0\u200b</p> </li> <li>\u200b\u5b9e\u9a8c\u200b\u63cf\u8ff0\u200b</li> <li>\u200b\u5b9e\u9a8c\u200b\u76f8\u5173\u200b\u7684\u200b\u4eea\u5668\u8bbe\u5907\u200b</li> <li>\u200b\u672c\u200b\u5b9e\u9a8c\u200b\u8bb0\u5f55\u200b\u521b\u5efa\u200b\u7684\u200b\u65f6\u95f4\u200b</li> <li>\u200b\u5bf9\u4e8e\u200b\u6bcf\u4e2a\u200b\u5b9e\u9a8c\u200b\uff0c\u200b\u5b9e\u9a8c\u200b\u65e5\u5fd7\u200b\u88ab\u200b\u8bb0\u5f55\u200b\u4e3a\u200b\u5b9e\u9a8c\u200b\u8282\u70b9\u200b\u7684\u200b\u5b50\u200b\u8282\u70b9\u200b\uff0c\u200b\u65e5\u5fd7\u200b\u8282\u70b9\u200b\u95f4\u200b\u6309\u200b\u65f6\u95f4\u200b\u987a\u5e8f\u200b\u5f62\u6210\u200b\u7c7b\u4f3c\u200b\u53cc\u5411\u200b\u94fe\u8868\u200b\u7684\u200b\u7ed3\u6784\u200b\u3002</li> <li> <p>\u200b\u65e5\u5fd7\u200b\u8282\u70b9\u200b\u5305\u542b\u200b\u5982\u4e0b\u200b\u4fe1\u606f\u200b\uff1a</p> </li> <li> <p>\u200b\u5b9e\u9a8c\u200b\u7ed3\u679c\u200b</p> </li> <li>\u200b\u8bb0\u5f55\u65f6\u95f4\u200b</li> </ul> <p>\u200b\u5f53\u200b\u5b9e\u9a8c\u5ba4\u200b\u6210\u5458\u200b\u8981\u6c42\u200bLabridge\u200b\u5e2e\u52a9\u200b\u8bb0\u5f55\u200b\u5b9e\u9a8c\u200b\u7ed3\u679c\u200b\u65f6\u200b\uff0cLabridge\u200b\u4f1a\u200b\u5c06\u200b\u8be5\u200b\u5b9e\u9a8c\u200b\u7ed3\u679c\u200b\u8bb0\u5f55\u200b\u8fdb\u5176\u200b\u5b9e\u9a8c\u200b\u65e5\u5fd7\u200b\u6570\u636e\u5e93\u200b\u4e2d\u200b\u7684\u200b\u5bf9\u5e94\u200b\u5b9e\u9a8c\u200b\u8bb0\u5f55\u200b\u4e2d\u200b\u3002</p> <p>\u200b\u66f4\u200b\u591a\u200b\u6709\u5173\u200b\u4e2a\u4eba\u200b\u5b9e\u9a8c\u200b\u65e5\u5fd7\u200b\u5b58\u50a8\u200b\u7ed3\u6784\u200b\u7684\u200b\u7ec6\u8282\u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Func_modules.memory.experiment.experiment_log</code></p>"},{"location":"function_modules/experiment_log/shared_experiment/","title":"\u5171\u4eab\u200b\u5b9e\u9a8c\u200b\u65e5\u5fd7","text":""},{"location":"function_modules/experiment_log/shared_experiment/#to-be-continued","title":"TO BE CONTINUED ...","text":""},{"location":"function_modules/instrument/","title":"\u5b9e\u9a8c\u200b\u4eea\u5668\u200b\u4fe1\u606f","text":""},{"location":"function_modules/instrument/#_2","title":"\u201c\u200b\u541b\u5b50\u200b\u5584\u5047\u200b\u4e8e\u7269\u200b\u4e5f\u200b\u201d","text":"<p>\u200b\u5b9e\u9a8c\u200b\u4eea\u5668\u200b\u662f\u200b\u7814\u7a76\u8005\u200b\u63a2\u7d22\u200b\u53d1\u73b0\u200b\u7684\u200b\u5de5\u5177\u200b\uff0c\u200b\u5de5\u4e8e\u200b\u5584\u200b\u5176\u4e8b\u200b\uff0c\u200b\u5fc5\u5148\u5229\u5176\u5668\u200b\u3002\u200b\u7814\u7a76\u8005\u200b\u5e94\u8be5\u200b\u5bf9\u200b\u6bcf\u4e2a\u200b\u4eea\u5668\u200b\u7684\u200b\u4fe1\u606f\u200b\u4e86\u5982\u6307\u638c\u200b\uff0c\u200b\u624d\u80fd\u200b\u514b\u670d\u200b\u5b9e\u9a8c\u200b\u8fc7\u7a0b\u200b\u4e2d\u200b\u7684\u200b\u56f0\u96be\u200b\uff0c\u200b\u83b7\u5f97\u200b\u53ef\u4fe1\u200b\u7684\u200b\u7ed3\u679c\u200b\u3002</p> <p>Labridge\u200b\u6574\u5408\u200b\u5b9e\u9a8c\u5ba4\u200b\u7684\u200b\u6240\u6709\u200b\u79d1\u5b66\u200b\u4eea\u5668\u8bbe\u5907\u200b\u7684\u200b\u4f7f\u7528\u200b\u89c4\u8303\u200b\u3001\u200b\u4f7f\u7528\u624b\u518c\u200b\u3001\u200b\u6ce8\u610f\u4e8b\u9879\u200b\uff0c\u200b\u534f\u52a9\u200b\u5b9e\u9a8c\u5ba4\u200b\u6210\u5458\u200b\u4eec\u200b\u4e86\u89e3\u200b\u5b9e\u9a8c\u200b\u4eea\u5668\u200b\u7684\u200b\u4f7f\u7528\u200b\u3001\u200b\u534f\u52a9\u200b\u8fdb\u884c\u200b\u4eea\u5668\u200b\u7ba1\u7406\u200b\u3001\u200b\u7b80\u5316\u200b\u5b9e\u9a8c\u200b\u64cd\u4f5c\u200b\u57f9\u8bad\u200b\u3002</p>"},{"location":"function_modules/instrument/#_3","title":"\u5b9e\u9a8c\u5ba4\u200b\u4eea\u5668\u200b\u4fe1\u606f\u5e93","text":"<p>Labridge\u200b\u5c06\u200b\u5b9e\u9a8c\u5ba4\u200b\u6240\u6709\u200b\u4eea\u5668\u200b\u7684\u200b\u76f8\u5173\u200b\u4fe1\u606f\u200b\u6574\u5408\u200b\u4e3a\u200b\u4eea\u5668\u200b\u4fe1\u606f\u5e93\u200b\uff0c\u200b\u81f4\u529b\u4e8e\u200b\u51cf\u5c11\u200b\u6210\u5458\u200b\u5728\u200b\u5b9e\u9a8c\u200b\u4eea\u5668\u200b\u65b9\u9762\u200b\u7684\u200b\u5b66\u4e60\u200b\u3001\u200b\u64cd\u4f5c\u200b\u6210\u672c\u200b\u3002</p>"},{"location":"function_modules/instrument/#_4","title":"\u5b9e\u9a8c\u200b\u4eea\u5668\u200b\u4fe1\u606f\u68c0\u7d22","text":"<p>Labridge\u200b\u5728\u200b\u4eea\u5668\u200b\u4fe1\u606f\u5e93\u200b\u7684\u200b\u5185\u5bb9\u200b\u4e2d\u200b\u8fdb\u884c\u200b\u68c0\u7d22\u200b\uff0c\u200b\u4ee5\u200b\u56de\u7b54\u200b\u5b9e\u9a8c\u5ba4\u200b\u6210\u5458\u200b\u5173\u4e8e\u200b\u4eea\u5668\u200b\u7684\u200b\u95ee\u9898\u200b\uff0c\u200b\u5e76\u200b\u7ed9\u51fa\u200b\u76f8\u5e94\u200b\u4eea\u5668\u200b\u7684\u200b Super Users\u3002</p>"},{"location":"function_modules/instrument/#_5","title":"\u5b9e\u9a8c\u200b\u4eea\u5668\u200b\u7ba1\u7406","text":"<p>Labridge\u200b\u901a\u8fc7\u200b\u8c03\u7528\u200b\u5de5\u5177\u200b(Tools)\u200b\u4e3a\u200b\u6210\u5458\u200b\u7ba1\u7406\u200b\u5176\u200b\u5b9e\u9a8c\u200b\u65e5\u5fd7\u200b\uff0c\u200b\u5177\u4f53\u200b\u7ec6\u8282\u200b\u53c2\u89c1\u200b <code>Agent\u200b\u4e0e\u200b\u53ef\u7528\u200b\u5de5\u5177\u200b</code></p>"},{"location":"function_modules/instrument/retrieve/","title":"\u4eea\u5668\u200b\u4fe1\u606f\u68c0\u7d22","text":"<p>Labridge\u200b\u4f7f\u7528\u200b\u591a\u7ea7\u200b\u68c0\u7d22\u200b\u7684\u200b\u65b9\u5f0f\u200b\u68c0\u7d22\u200b\u76f8\u5173\u200b\u4eea\u5668\u200b\u4fe1\u606f\u200b</p> <p></p>"},{"location":"function_modules/instrument/retrieve/#_2","title":"\u7b2c\u4e00\u6b65\u200b\u68c0\u7d22","text":"<p>\u200b\u5728\u200b\u7b2c\u4e00\u6b65\u200b\u68c0\u7d22\u200b\u4e2d\u200b\uff0cLabridge\u200b\u4f7f\u7528\u200b LLM \u200b\u5bf9\u200bQuery\u200b\u6587\u672c\u200b\u4e0e\u200b\u5404\u200b\u5b9e\u9a8c\u200b\u4eea\u5668\u200b\u4e4b\u95f4\u200b\u7684\u200b\u76f8\u5173\u6027\u200b\uff08\u200b\u4f9d\u636e\u200b\u4eea\u5668\u200b\u63cf\u8ff0\u200b\uff09\u200b\u8fdb\u884c\u200b\u6253\u5206\u200b\uff0c\u200b\u7b5b\u9009\u200b\u51fa\u200b\u6700\u200b\u76f8\u5173\u200b\u7684\u200b <code>instrument_top_k</code> \u200b\u4e2a\u200b\u4eea\u5668\u200b\u3002</p>"},{"location":"function_modules/instrument/retrieve/#_3","title":"\u7b2c\u4e8c\u6b65\u200b\u68c0\u7d22\u200b\uff1a","text":"<p>\u200b\u5c06\u200b\u68c0\u7d22\u200b\u8303\u56f4\u200b\u9650\u5b9a\u200b\u4e3a\u200b\u7b2c\u4e00\u6b65\u200b\u68c0\u7d22\u200b\u6240\u5f97\u200b\u7684\u200b\u4eea\u5668\u200b\uff0c\u200b\u5728\u200b\u8fd9\u4e9b\u200b\u4eea\u5668\u200b\u7684\u200b\u4fe1\u606f\u200b\u4e2d\u200b\u8fdb\u884c\u200b\u76f8\u4f3c\u6027\u200b\u68c0\u7d22\u200b\uff0c\u200b\u5f97\u5230\u200b\u4e0e\u200bQuery\u200b\u5411\u91cf\u200b\u6700\u200b\u76f8\u5173\u200b\u7684\u200b <code>top_k</code> \u200b\u6761\u200b\u4fe1\u606f\u200b\u3002 \u200b\u8fd9\u4e9b\u200b\u4fe1\u606f\u200b\u4f5c\u4e3a\u200b\u68c0\u7d22\u200b\u7ed3\u679c\u200b\u63d0\u4f9b\u200b\u7ed9\u200b LLM \u200b\u4f5c\u4e3a\u200b\u53c2\u8003\u200b\u4fe1\u606f\u200b\u3002</p> <p>\u200b\u5173\u4e8e\u200b\u4eea\u5668\u200b\u4fe1\u606f\u68c0\u7d22\u200b\u7684\u200b\u7ec6\u8282\u200b\uff0c\u200b\u8bf7\u200b\u53c2\u8003\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Func_modules.instrument.retrieve.instrument_retrieve</code></p>"},{"location":"function_modules/instrument/store/","title":"\u4eea\u5668\u200b\u4fe1\u606f\u200b\u5b58\u50a8\u200b\u7ed3\u6784","text":"<p>\u200b\u5b9e\u9a8c\u200b\u4eea\u5668\u200b\u4fe1\u606f\u200b\u5b58\u50a8\u200b\u4e8e\u200b\u4e00\u4e2a\u200b\u5411\u91cf\u200b\u6570\u636e\u5e93\u200b\u4e2d\u200b, \u200b\u5176\u200b\u7ed3\u6784\u200b\u5982\u4e0b\u200b\u56fe\u200b\u6240\u793a\u200b\u3002</p> <p></p> <ul> <li>\u200b\u6570\u636e\u5e93\u200b\u4e2d\u200b\u5b58\u5728\u200b\u4e00\u4e2a\u200b\u6839\u200b\u8282\u70b9\u200b\uff0c\u200b\u6240\u6709\u200b\u7684\u200b\u4eea\u5668\u200b\u8282\u70b9\u200b\u662f\u200b\u8be5\u200b\u6839\u200b\u8282\u70b9\u200b\u7684\u200b\u5b50\u200b\u8282\u70b9\u200b\u3002</li> <li> <p>\u200b\u6bcf\u4e2a\u200b\u4eea\u5668\u200b\u8282\u70b9\u200b\u5305\u542b\u200b\u5982\u4e0b\u200b\u4fe1\u606f\u200b\uff1a</p> </li> <li> <p>\u200b\u4eea\u5668\u200b\u540d\u79f0\u200b</p> </li> <li>\u200b\u4eea\u5668\u200b\u63cf\u8ff0\u200b</li> <li>Super Users (\u200b\u8d1f\u8d23\u7ba1\u7406\u200b\u4eea\u5668\u200b\u4fe1\u606f\u200b\u3001\u200b\u5bf9\u200b\u4eea\u5668\u200b\u5177\u6709\u200b\u5b8c\u5168\u200b\u6743\u9650\u200b\u7684\u200b\u5b9e\u9a8c\u5ba4\u200b\u6210\u5458\u200b)</li> <li>\u200b\u5bf9\u4e8e\u200b\u6bcf\u4e2a\u200b\u4eea\u5668\u200b\uff0c\u200b\u4eea\u5668\u200b\u4fe1\u606f\u200b\u88ab\u200b\u8bb0\u5f55\u200b\u4e3a\u200b\u4eea\u5668\u200b\u8282\u70b9\u200b\u7684\u200b\u5b50\u200b\u8282\u70b9\u200b\uff0c\u200b\u5982\u200b\u4f7f\u7528\u200b\u89c4\u8303\u200b\uff0c\u200b\u64cd\u4f5c\u624b\u518c\u200b\uff0c\u200b\u4eea\u5668\u200b\u53c2\u6570\u200b\u7b49\u200b\u3002</li> </ul> <p>\u200b\u66f4\u200b\u591a\u200b\u5173\u4e8e\u200b\u4eea\u5668\u200b\u4fe1\u606f\u200b\u5b58\u50a8\u200b\u7ed3\u6784\u200b\u7684\u200b\u7ec6\u8282\u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Func_modules.instrument.store.instrument_store</code></p>"},{"location":"function_modules/paper/","title":"\u6587\u732e\u200b\u7ba1\u7406","text":""},{"location":"function_modules/paper/#_2","title":"\u201c\u200b\u5728\u200b\u77e5\u8bc6\u200b\u7684\u200b\u6d41\u52a8\u200b\u4e2d\u200b\u50ac\u5316\u200b\u65b0\u200b\u77e5\u8bc6\u200b\u7684\u200b\u8bde\u751f\u200b\u201d","text":"<p>\u200b\u4e00\u4e2a\u200b\u4f18\u79c0\u200b\u7684\u200b\u7814\u7a76\u8005\u200b\u5e94\u8be5\u200b\u8ffd\u8e2a\u200b\u7814\u7a76\u200b\u9886\u57df\u200b\u5185\u200b\u7684\u200b\u6700\u65b0\u200b\u7814\u7a76\u6210\u679c\u200b\uff0c\u200b\u540c\u65f6\u200b\u4fdd\u6301\u200b\u5bf9\u200b\u65b0\u200b\u9886\u57df\u200b\u7684\u200b\u597d\u5947\u200b\u4e0e\u200b\u5f00\u653e\u200b\uff0c\u200b\u56e0\u4e3a\u200b\u8bb8\u591a\u200b\u4f1f\u5927\u200b\u7684\u200b\u79d1\u5b66\u200b\u6210\u5c31\u200b\u5f80\u5f80\u200b\u6765\u81ea\u200b\u4e8e\u200b\u4e0d\u540c\u200b\u9886\u57df\u200b\u95f4\u200b\u7684\u200b\u601d\u7ef4\u200b\u78b0\u649e\u200b\u3002</p> <p>\u200b\u56e0\u6b64\u200b\u6587\u732e\u200b\u7ba1\u7406\u200b\u662f\u200b\u4e00\u4e2a\u200b\u79d1\u5b66\u200b\u5b9e\u9a8c\u5ba4\u200b\u81f3\u5173\u91cd\u8981\u200b\u7684\u200b\u90e8\u5206\u200b\u4e4b\u4e00\u200b\u3002\u200b\u6211\u4eec\u200b\u5e0c\u671b\u200bLabridge\u200b\u80fd\u591f\u200b\u5e2e\u52a9\u200b\u7814\u7a76\u8005\u200b\u4eec\u200b\u7ba1\u7406\u200b\u8fd9\u4e9b\u200b\u5b9d\u8d35\u200b\u7684\u200b\u77e5\u8bc6\u200b\u8d22\u5bcc\u200b\uff0c\u200b\u5e76\u200b\u6784\u5efa\u200b\u5b9e\u9a8c\u5ba4\u200b\u7684\u200b\u5171\u4eab\u200b\u6587\u732e\u200b\u77e5\u8bc6\u5e93\u200b\uff0c \u200b\u4e3a\u200b\u5b9e\u9a8c\u5ba4\u200b\u6210\u5458\u200b\u4e4b\u95f4\u200b\u7684\u200b\u79d1\u7814\u200b\u4ea4\u6d41\u200b\u4e0e\u200b\u5408\u4f5c\u200b\u63d0\u4f9b\u200b\u5e73\u53f0\u200b\u3002</p> <p></p> <p>Labridge\u200b\u901a\u8fc7\u200b\u5982\u4e0b\u200b\u65b9\u5f0f\u200b\u4fc3\u8fdb\u200b\u6587\u732e\u200b\u77e5\u8bc6\u200b\u7684\u200b\u6d41\u52a8\u200b\u4e0e\u200b\u77e5\u8bc6\u200b\u7684\u200b\u4ea4\u53c9\u200b\u878d\u5408\u200b\uff1a</p>"},{"location":"function_modules/paper/#_3","title":"\u5b9e\u9a8c\u5ba4\u200b\u5171\u4eab\u200b\u6587\u732e\u200b\u5e93\u200b\uff1a","text":"<p>Labridge\u200b\u6536\u96c6\u200b\u5b9e\u9a8c\u5ba4\u200b\u6240\u6709\u200b\u6210\u5458\u200b\u7684\u200b\u6587\u732e\u200b\u6784\u6210\u200b\u5171\u4eab\u200b\u77e5\u8bc6\u5e93\u200b\u3002Labridge\u200b\u4f1a\u200b\u4f9d\u636e\u200b\u5171\u4eab\u200b\u77e5\u8bc6\u5e93\u200b\u7684\u200b\u5185\u5bb9\u200b\u56de\u7b54\u200b\u5b9e\u9a8c\u5ba4\u200b\u6210\u5458\u200b\u7684\u200b\u76f8\u5173\u200b\u95ee\u9898\u200b\uff0c \u200b\u5e76\u200b\u63d0\u4f9b\u200b\u53c2\u8003\u200b\u5185\u5bb9\u200b\u7684\u200b\u6765\u6e90\u200b\uff08\u200b\u5982\u200b\u8fd9\u7bc7\u200b\u6587\u732e\u200b\u6765\u81ea\u200b\u4e8e\u200b\u6210\u5458\u200bXXX\uff09\u3002\u200b\u8ba9\u200b\u77e5\u8bc6\u200b\u7684\u200b\u6d41\u52a8\u200b\u4e0d\u200b\u53d7\u200b\u65f6\u95f4\u200b\u4e0e\u200b\u7a7a\u95f4\u200b\u7684\u200b\u9650\u5236\u200b\u3002</p>"},{"location":"function_modules/paper/#_4","title":"\u4e2a\u4eba\u200b\u8fd1\u671f\u200b\u6587\u732e\u200b\uff1a","text":"<p>Labridge\u200b\u4e3a\u200b\u6bcf\u4f4d\u200b\u5b9e\u9a8c\u200b\u6210\u5458\u200b\u63d0\u4f9b\u200b\u4e2a\u4eba\u200b\u7684\u200b\u8fd1\u671f\u200b\u6587\u732e\u200b\u5e93\u200b\uff0c\u200b\u4ee5\u200b\u8bb0\u5f55\u200b\u8be5\u200b\u6210\u5458\u200b\u8fd1\u671f\u200b\u901a\u8fc7\u200bLabridge\u200b\u4ece\u200b\u671f\u520a\u200b\u7f51\u7ad9\u200b\u4e0b\u8f7d\u200b\u3001\u200b\u5411\u200bLabridge\u200b\u4e0a\u4f20\u200b\u7684\u200b\u6587\u732e\u200b\u3002 Labridge\u200b\u57fa\u4e8e\u200b\u8fd1\u671f\u200b\u6587\u732e\u200b\u5e93\u200b\u534f\u52a9\u200b\u6bcf\u4f4d\u200b\u6210\u5458\u200b\u66f4\u597d\u200b\u5730\u200b\u7406\u89e3\u200bta\u200b\u6700\u8fd1\u200b\u611f\u5174\u8da3\u200b\u7684\u200b\u7814\u7a76\u200b\u5185\u5bb9\u200b\u3002\u200b\u5e76\u200b\u652f\u6301\u200b\u6210\u5458\u200b\u901a\u8fc7\u200b\u81ea\u7136\u8bed\u8a00\u200b\u7ba1\u7406\u200b\u4e2a\u4eba\u200b\u7684\u200b\u6587\u732e\u200b\u5e93\u200b\u3002</p>"},{"location":"function_modules/paper/#_5","title":"\u6587\u732e\u200b\u641c\u7d22\u200b\u4e0e\u200b\u4e0b\u8f7d\u200b\uff1a","text":"<p>Labridge\u200b\u63d0\u4f9b\u200b\u81ea\u7136\u8bed\u8a00\u200b\u4ea4\u4e92\u200b\u7684\u200b\u6587\u732e\u200b\u641c\u7d22\u200b\u4e0e\u200b\u4e0b\u8f7d\u5de5\u5177\u200b\uff0c\u200b\u8ba9\u200b\u7814\u7a76\u8005\u200b\u4fdd\u6301\u200b\u5bf9\u200b\u9886\u57df\u200b\u6700\u65b0\u200b\u7814\u7a76\u200b\u52a8\u6001\u200b\u7684\u200b\u8ffd\u8e2a\u200b\u3002 Labridge\u200b\u76ee\u524d\u200b\u652f\u6301\u200b\u5728\u200b\u5982\u4e0b\u200b\u671f\u520a\u200b\u7f51\u7ad9\u200b\u8fdb\u884c\u200b\u641c\u7d22\u200b\u4e0e\u200b\u4e0b\u8f7d\u200b\uff1a</p> <ul> <li>arXiv</li> </ul>"},{"location":"function_modules/paper/shared_papers/","title":"\u5171\u4eab\u200b\u6587\u732e\u200b\u77e5\u8bc6\u5e93","text":"<p>Labridge\u200b\u6536\u96c6\u200b\u5b9e\u9a8c\u5ba4\u200b\u6210\u5458\u200b\u7684\u200b\u6587\u732e\u200b\u6784\u6210\u200b\u5171\u4eab\u200b\u6587\u732e\u200b\u77e5\u8bc6\u5e93\u200b\u3002</p>"},{"location":"function_modules/paper/shared_papers/#_2","title":"\u5171\u4eab\u200b\u6587\u732e\u200b\u5e93\u200b\u6784\u5efa","text":"<p>\u200b\u5171\u4eab\u200b\u6587\u732e\u200b\u77e5\u8bc6\u5e93\u200b\u7684\u200b\u6784\u5efa\u200b\u5305\u62ec\u200b\u5982\u4e0b\u200b\u65b9\u9762\u200b\uff1a</p> <ul> <li>\u200b\u6587\u732e\u200b\u89e3\u6790\u200b\u4e0e\u200b\u4fe1\u606f\u63d0\u53d6\u200b\uff1a \u200b\u4e3a\u4e86\u200b\u4f7f\u200b\u6784\u5efa\u200b\u7684\u200b\u5171\u4eab\u200b\u6587\u732e\u200b\u77e5\u8bc6\u5e93\u200b\u652f\u6301\u200b\u66f4\u52a0\u200b\u7cbe\u51c6\u200b\u7684\u200b\u68c0\u7d22\u200b\uff0c\u200b\u6211\u4eec\u200b\u5bf9\u200b\u6536\u96c6\u200b\u7684\u200b\u6587\u732e\u200b\u6587\u4ef6\u200b\u8fdb\u884c\u200b\u7ec6\u81f4\u200b\u7684\u200b\u89e3\u6790\u200b\u4e0e\u200b\u5185\u5bb9\u200b\u63d0\u53d6\u200b\u3002</li> <li>\u200b\u6587\u732e\u6570\u636e\u5e93\u200b\u6784\u5efa\u200b\uff1a \u200b\u57fa\u4e8e\u200b\u63d0\u53d6\u200b\u51fa\u200b\u7684\u200b\u6587\u732e\u200b\u5185\u5bb9\u200b\u4e0e\u200b\u4fe1\u606f\u200b\uff0cLabridge\u200b\u6784\u5efa\u200b\u6587\u732e\u200b\u7684\u200bSummary\u200b\u5411\u91cf\u200b\u6570\u636e\u5e93\u200b\u4ee5\u53ca\u200b\u5185\u5bb9\u200b\u5411\u91cf\u200b\u6570\u636e\u5e93\u200b\u3002</li> </ul>"},{"location":"function_modules/paper/shared_papers/#_3","title":"\u5171\u4eab\u200b\u6587\u732e\u200b\u5e93\u200b\u68c0\u7d22","text":"<p>\u200b\u5728\u200b\u5171\u4eab\u200b\u6587\u732e\u200b\u5e93\u200b\u6784\u5efa\u200b\u5b8c\u6210\u200b\u540e\u200b\uff0cLabridge\u200b\u4f1a\u200b\u57fa\u4e8e\u200b\u8be5\u200b\u6587\u732e\u200b\u5e93\u200b\u68c0\u7d22\u200b\u6587\u732e\u200b\u5e76\u200b\u56de\u7b54\u200b\u5b9e\u9a8c\u5ba4\u200b\u6210\u5458\u200b\u7684\u200b\u95ee\u9898\u200b\u3002</p> <ul> <li>\u200b\u6587\u732e\u6570\u636e\u5e93\u200b\u68c0\u7d22\u200b:  Labridge\u200b\u91c7\u7528\u200b\u591a\u200b\u5c42\u7ea7\u200b\u3001\u200b\u6df7\u5408\u5f0f\u200b\u7684\u200b\u68c0\u7d22\u200b\u65b9\u5f0f\u200b\u4fdd\u8bc1\u200b\u68c0\u7d22\u200b\u7ed3\u679c\u200b\u7684\u200b\u51c6\u786e\u6027\u200b\u3002</li> </ul>"},{"location":"function_modules/paper/shared_papers/parse/","title":"\u6587\u732e\u200b\u5185\u5bb9\u200b\u89e3\u6790\u200b\u4e0e\u200b\u63d0\u53d6","text":"<p>\u200b\u4e3a\u4e86\u200b\u4f7f\u200b\u6784\u5efa\u200b\u7684\u200b\u5171\u4eab\u200b\u6587\u732e\u200b\u77e5\u8bc6\u5e93\u200b\u652f\u6301\u200b\u66f4\u52a0\u200b\u7cbe\u51c6\u200b\u7684\u200b\u68c0\u7d22\u200b\uff0c\u200b\u6211\u4eec\u200b\u5bf9\u200b\u6536\u96c6\u200b\u7684\u200b\u6587\u732e\u200b\u6587\u4ef6\u200b\u8fdb\u884c\u200b\u7ec6\u81f4\u200b\u7684\u200b\u89e3\u6790\u200b\u4e0e\u200b\u5185\u5bb9\u200b\u63d0\u53d6\u200b\u3002</p> <p></p>"},{"location":"function_modules/paper/shared_papers/parse/#_2","title":"\u6587\u732e\u200b\u6765\u6e90\u200b\u5206\u6790\u200b\uff1a","text":"<p>\u200b\u6211\u4eec\u200b\u901a\u8fc7\u200b \u200b\u7ed3\u6784\u5316\u200bPDF\u200b\u89e3\u6790\u200b\u3001\u200b\u5173\u952e\u5b57\u200b\u9891\u6b21\u200b\u5206\u6790\u200b\u3001LLM\u200b\u8f85\u52a9\u200b\u5206\u6790\u200b \u200b\u7b49\u200b\u591a\u79cd\u624b\u6bb5\u200b\u5bf9\u200b\u4e00\u7bc7\u200bPDF\u200b\u6587\u732e\u200b\u7684\u200b\u6765\u6e90\u200b\u8fdb\u884c\u200b\u5206\u6790\u200b\uff0c \u200b\u5982\u8be5\u200b\u6587\u732e\u200b\u6765\u81ea\u200b\u4e8e\u200b<code>Nature</code>\u3001<code>IEEE</code>\u200b\u7b49\u200b\u3002 \u200b\u5177\u4f53\u200b\u7684\u200b\u7ec6\u8282\u200b\u8bf7\u200b\u53c2\u8003\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b:<code>Fun_modules.paper.parse.extractors.source_analyze</code></p>"},{"location":"function_modules/paper/shared_papers/parse/#_3","title":"\u6587\u732e\u200b\u7ed3\u6784\u5316\u200b\u89e3\u6790\u200b\uff1a","text":"<p>\u200b\u6839\u636e\u200b\u5206\u6790\u200b\u51fa\u200b\u7684\u200b\u6587\u732e\u200b\u6765\u6e90\u200b\uff0c\u200b\u6211\u4eec\u200b\u4f7f\u7528\u200b\u76f8\u5e94\u200b\u7684\u200b\u89e3\u6790\u200b\u6a21\u677f\u200b\u5bf9\u200b\u6587\u732e\u200b\u8fdb\u884c\u200b\u89e3\u6790\u200b\uff0c\u200b\u5982\u200b\u5c06\u200b\u5176\u200b\u5185\u5bb9\u200b\u4e2d\u200b\u7684\u200b  <code>Abstract</code>, <code>MainText</code>, <code>Methods</code>, <code>References</code> \u200b\u7b49\u200b\u63d0\u53d6\u200b\u51fa\u6765\u200b\uff0c\u200b\u4ee5\u200b\u652f\u6301\u200b\u66f4\u200b\u7cbe\u51c6\u200b\u7684\u200b\u6587\u732e\u200b\u5e93\u200b\u68c0\u7d22\u200b\u3002 Labridge\u200b\u76ee\u524d\u200b\u652f\u6301\u200b\u7684\u200b\u89e3\u6790\u200b\u6a21\u677f\u200b\u5305\u62ec\u200b\uff1a   - Nature Parser: \u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Fun_modules.paper.parse.parsers.nature_parser</code>   - IEEE Parser: \u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Fun_modules.paper.parse.parsers.ieee_parser</code></p>"},{"location":"function_modules/paper/shared_papers/parse/#metadata","title":"Metadata\u200b\u63d0\u53d6\u200b\uff1a","text":"<p>Labridge\u200b\u5229\u7528\u200b LLM \u200b\u5bf9\u200b\u6587\u732e\u200b\u7684\u200bMetadata\u200b\u8fdb\u884c\u200b\u63d0\u53d6\u200b\uff0c\u200b\u5982\u200b \u200b\u6587\u7ae0\u200b\u6807\u9898\u200b\u3001\u200b\u6587\u7ae0\u200b\u5173\u952e\u8bcd\u200b\u3001\u200b\u4f5c\u8005\u200b\u4fe1\u606f\u200b\u3001\u200b\u4f5c\u8005\u200b\u5355\u4f4d\u200b\u3001\u200b\u53d1\u8868\u200b\u65f6\u95f4\u200b \u200b\u7b49\u200b\u3002 Labridge\u200b\u4ece\u200b\u671f\u520a\u200b\u7f51\u7ad9\u200b\u4e0a\u200b\u4e0b\u8f7d\u200b\u7684\u200b\u6587\u732e\u200b\u5f80\u5f80\u200b\u5df2\u7ecf\u200b\u5305\u542b\u200b\u4e86\u200b\u5145\u5206\u200b\u7684\u200bMetadata,\u200b\u5bf9\u4e8e\u200b\u8fd9\u200b\u7c7b\u200b\u6587\u732e\u200b\uff0c\u200b\u5728\u200b\u672c\u200b\u73af\u8282\u200b\u4f1a\u200b\u5bf9\u200b\u5176\u4e2d\u200b\u672a\u200b\u63d0\u4f9b\u200b\u7684\u200bMetdata\u200b\u8fdb\u884c\u200b\u8865\u5145\u200b\u3002 \u200b\u5177\u4f53\u200b\u7ec6\u8282\u200b\u53c2\u89c1\u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Fun_modules.paper.parse.extractors.metadata_extract</code></p> Metadata\u200b\u63d0\u53d6\u200b\u793a\u4f8b"},{"location":"function_modules/paper/shared_papers/retrieve/","title":"\u5171\u4eab\u200b\u6587\u732e\u200b\u5e93\u200b\u68c0\u7d22","text":"<p>Labridge\u200b\u5c06\u200b\u5728\u200b\u6784\u5efa\u200b\u597d\u200b\u7684\u200b\u5171\u4eab\u200b\u6587\u732e\u200b\u5e93\u4e2d\u200b\u8fdb\u884c\u200b\u68c0\u7d22\u200b\uff0c\u200b\u4ee5\u200b\u83b7\u5f97\u200b\u89e3\u51b3\u95ee\u9898\u200b\u6240\u200b\u9700\u8981\u200b\u7684\u200b\u4fe1\u606f\u200b\u3002</p> <p>\u200b\u6211\u4eec\u200b\u4f7f\u7528\u200b\u4e86\u200b\u591a\u200b\u5c42\u7ea7\u200b\u3001\u200b\u6df7\u5408\u5f0f\u200b\u7684\u200b\u68c0\u7d22\u200b\u65b9\u5f0f\u200b\u6765\u200b\u63d0\u9ad8\u200b\u68c0\u7d22\u200b\u7ed3\u679c\u200b\u7684\u200b\u51c6\u786e\u6027\u200b\u3002\u200b\u5177\u4f53\u200b\u7684\u200b\u7ec6\u8282\u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Fun_modules.paper.retrieve.shared_paper_retrieve</code></p> <p></p>"},{"location":"function_modules/paper/shared_papers/retrieve/#_2","title":"\u7b2c\u4e00\u6b65\u200b\u68c0\u7d22\u200b\uff1a","text":"<p>\u200b\u5728\u200b\u7b2c\u4e00\u6b65\u200b\u68c0\u7d22\u200b\u4e2d\u200b\uff0c\u200b\u6211\u4eec\u200b\u5728\u200b\u5171\u4eab\u200b\u6587\u732e\u200b\u5e93\u4e2d\u200b\u7684\u200b\u5185\u5bb9\u200b\u5411\u91cf\u200b\u6570\u636e\u5e93\u200b\u4e2d\u200b\u641c\u7d22\u200b\u4e0e\u200b\u95ee\u9898\u200b\u5411\u91cf\u200b\u6700\u200b\u76f8\u4f3c\u200b\u7684\u200b<code>vector_similarity_top_k</code>\u200b\u4e2a\u200b\u6587\u672c\u200b\u5757\u200b\uff0c\u200b\u5e76\u200b\u83b7\u53d6\u200b\u5b83\u4eec\u200b\u6240\u5c5e\u200b\u7684\u200b\u6587\u732e\u200b\u8282\u70b9\u200b\u3002 \u200b\u5982\u679c\u200b\u5236\u5b9a\u200b\u4e86\u200b\u7279\u5b9a\u200b\u7684\u200b <code>user_id</code>, \u200b\u5c06\u200b\u4ec5\u200b\u5728\u200b\u8be5\u200b\u7528\u6237\u200b\u7684\u200b\u6587\u732e\u200b\u4e2d\u200b\u8fdb\u884c\u200b\u68c0\u7d22\u200b\u3002</p>"},{"location":"function_modules/paper/shared_papers/retrieve/#_3","title":"\u7b2c\u4e8c\u6b65\u200b\u76f8\u5173\u6027\u200b\u5206\u6790\u200b\uff1a","text":"<p>\u200b\u5728\u200b\u7b2c\u4e00\u6b65\u200b\u68c0\u7d22\u200b\u51fa\u200b\u7684\u200b\u76f8\u5173\u200b\u6587\u732e\u200b\u7684\u200b\u8303\u56f4\u200b\u5185\u200b\uff0c\u200b\u6211\u4eec\u200b\u5c06\u200b\u4f7f\u7528\u200b LLM \u200b\u5bf9\u200b\u8fd9\u4e9b\u200b\u6587\u732e\u200b\u7684\u200bAbstract &amp; Summary\u200b\u548c\u200b\u95ee\u9898\u200b\u6587\u672c\u200b\u7684\u200b\u76f8\u5173\u6027\u200b\u8fdb\u884c\u200b\u6253\u5206\u200b\uff0c \u200b\u83b7\u53d6\u200b\u76f8\u5173\u6027\u200b\u5206\u6570\u200b\u6700\u9ad8\u200b\u7684\u200b <code>docs_top_k</code> \u200b\u4efd\u200b\u6587\u732e\u200b\u3002</p>"},{"location":"function_modules/paper/shared_papers/retrieve/#_4","title":"\u6700\u540e\u200b\u7684\u200b\u76f8\u4f3c\u6027\u200b\u68c0\u7d22\u200b\uff1a","text":"<p>\u200b\u5728\u200b\u7b2c\u4e8c\u6b65\u200b\u7b5b\u9009\u200b\u51fa\u200b\u7684\u200b\u6587\u732e\u200b\u8303\u56f4\u200b\u5185\u200b\uff0c\u200b\u6211\u4eec\u200b\u5728\u200b\u8fd9\u4e9b\u200b\u6587\u732e\u200b\u7684\u200b\u6587\u672c\u200b\u4e2d\u200b\u68c0\u7d22\u200b\u4e0e\u200b\u95ee\u9898\u200b\u5411\u91cf\u200b\u6700\u200b\u76f8\u4f3c\u200b\u7684\u200b <code>re_retrieve_top_k</code> \u200b\u4e2a\u200b\u6587\u672c\u200b\u5757\u200b\u3002 \u200b\u7531\u4e8e\u200b\u672c\u6b21\u200b\u68c0\u7d22\u200b\u662f\u200b\u6700\u7ec8\u200b\u7684\u200b\u7ec6\u7c92\u5ea6\u200b\u7684\u200b\u68c0\u7d22\u200b\uff0c\u200b\u56e0\u6b64\u200b\u672c\u6b21\u200b\u68c0\u7d22\u200b\u8fc7\u7a0b\u200b\u4e2d\u200b\uff0c\u200b\u63d0\u4f9b\u200b\u7ed9\u200bEmbedding\u200b\u6a21\u578b\u200b\u7684\u200b\u6587\u672c\u200b\u53ea\u6709\u200b\u6587\u732e\u200b\u6587\u672c\u200b\u5757\u200b\u672c\u8eab\u200b\u7684\u200b\u6587\u672c\u200b\uff0c\u200b\u4e0d\u200b\u5305\u542b\u200b\u4efb\u4f55\u200b\u989d\u5916\u200b\u7684\u200bMetadata\u3002</p>"},{"location":"function_modules/paper/shared_papers/retrieve/#_5","title":"\u6dfb\u52a0\u200b\u4e0a\u4e0b\u6587\u200b\u4e0e\u200b\u76f8\u5173\u200b\u603b\u7ed3\u200b\uff1a","text":"<p>\u200b\u5728\u200b\u6700\u540e\u200b\uff0c\u200b\u6211\u4eec\u200b\u53ef\u4ee5\u200b\u9009\u62e9\u200b\u4e3a\u200b\u68c0\u7d22\u200b\u51fa\u200b\u7684\u200b\u6587\u672c\u200b\u5757\u200b\u52a0\u4e0a\u200b\u5b83\u4eec\u200b\u7684\u200b\u4e0a\u4e0b\u6587\u200b\uff0c\u200b\u4ee5\u53ca\u200b\u5b83\u4eec\u200b\u6240\u5c5e\u200b\u6587\u732e\u200b\u7684\u200b\u603b\u7ed3\u200b\u3002\u200b\u5c06\u200b\u8fd9\u4e9b\u200b\u5185\u5bb9\u200b\u4f5c\u4e3a\u200b\u6700\u7ec8\u200b\u7684\u200b\u68c0\u7d22\u200b\u7ed3\u679c\u200b\u63d0\u4f9b\u200b\u7ed9\u200b LLM \u3002</p>"},{"location":"function_modules/paper/shared_papers/store/","title":"\u5171\u4eab\u200b\u6587\u732e\u200b\u5e93\u200b\u6784\u5efa","text":"<p>\u200b\u5171\u4eab\u200b\u6587\u732e\u200b\u5e93\u200b\u7684\u200b\u539f\u59cb\u200b\u6587\u4ef6\u200b\u5b58\u653e\u200b\u5728\u200b <code>documents/papers</code>\u200b\u8def\u5f84\u200b\u4e0b\u200b\u3002\u200b\u8be5\u200b\u6587\u732e\u200b\u4ed3\u5e93\u200b\u7684\u200b\u4e00\u7ea7\u200b\u5b50\u76ee\u5f55\u200b\u4e3a\u200b\u5b9e\u9a8c\u5ba4\u200b\u6210\u5458\u200b\u7684\u200b<code>user_id</code></p> <p>Labridge\u200b\u57fa\u4e8e\u200bParse\u200b\u83b7\u5f97\u200b\u7684\u200b\u6587\u732e\u200b\u5185\u5bb9\u200b\u4e0e\u200b\u4fe1\u606f\u200b\u6784\u5efa\u200b\u5145\u5206\u200b\u7fd4\u5b9e\u200b\u7684\u200b\u5171\u4eab\u200b\u6587\u732e\u200b\u5e93\u200b\uff0c\u200b\u4ee5\u200b\u652f\u6301\u200b\u591a\u79cd\u200b\u65b9\u5f0f\u200b\u7684\u200b\u68c0\u7d22\u200b\u3002</p>"},{"location":"function_modules/paper/shared_papers/store/#_2","title":"\u5171\u4eab\u200b\u6587\u732e\u200b\u5411\u91cf\u200b\u6570\u636e\u5e93\u200b\uff1a","text":"<p>Labridge\u200b\u4e3a\u200b\u6240\u6709\u200b\u7684\u200b\u5171\u4eab\u200b\u6587\u732e\u200b\u6784\u5efa\u200b\u5411\u91cf\u200b\u6570\u636e\u5e93\u200b(VectorIndex)\uff0c\u200b\u5e76\u200b\u8bb0\u5f55\u200b\u6bcf\u7bc7\u200b\u6587\u732e\u200b\u7684\u200bMetadata\uff0c\u200b\u4ee5\u53ca\u200b\u8be5\u200b\u6587\u732e\u200b\u7684\u200b\u6240\u6709\u8005\u200b\u3002 \u200b\u5185\u5bb9\u200b\u5411\u91cf\u200b\u6570\u636e\u5e93\u200b\u7684\u200b\u6784\u5efa\u200b\u53c2\u89c1\u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Func_modules.paper.store.shared_paper_store</code></p> <p>\u200b\u5171\u4eab\u200b\u6587\u732e\u200b\u5411\u91cf\u200b\u6570\u636e\u5e93\u200b\u7684\u200b\u7ed3\u6784\u200b\u5982\u4e0b\u200b\u56fe\u200b\u6240\u793a\u200b\u3002\u200b\u8be5\u200b\u6570\u636e\u5e93\u200b\u4e3a\u200b\u6811\u5f62\u200b\u7ed3\u6784\u200b\uff0c\u200b\u7b2c\u4e00\u5c42\u200b\u5b50\u200b\u8282\u70b9\u200b\u4e3a\u200b\u4e0d\u540c\u200b\u7684\u200b\u7528\u6237\u200b\uff0c\u200b\u6bcf\u4e2a\u200b\u7528\u6237\u200b\u8282\u70b9\u200b\u4e0b\u4f1a\u200b\u4f9d\u7167\u200b\u539f\u59cb\u200b\u6587\u732e\u200b\u5e93\u4e2d\u200b\u7684\u200b\u76ee\u5f55\u200b\u6811\u200b\u6784\u5efa\u200b\u76f8\u5e94\u200b\u7684\u200b \u200b\u76ee\u5f55\u200b\u8282\u70b9\u200b\u3002\u200b\u6587\u732e\u200b\u8282\u70b9\u200b\u8bb0\u5f55\u200b\u8be5\u200b\u6587\u732e\u200b\u539f\u59cb\u200b\u6587\u4ef6\u200b\u7684\u200b\u76f8\u5bf9\u8def\u5f84\u200b\uff0c\u200b\u4ee5\u53ca\u200b\u989d\u5916\u200b\u7684\u200bMetadata\u200b\u5982\u200b<code>Abstract</code>, <code>Summary</code>, <code>Authors</code>, <code>Title</code> \u200b\u7b49\u7b49\u200b\u3002 \u200b\u6700\u540e\u200b\u7684\u200b\u53f6\u5b50\u200b\u8282\u70b9\u200b\u4e3a\u200b\u6bcf\u7bc7\u200b\u6587\u732e\u200b\u5185\u5bb9\u200b\u7684\u200b\u6587\u672c\u200b\u5757\u200b\uff0c\u200b\u524d\u540e\u200b\u6587\u672c\u200b\u5757\u200b\u4e4b\u95f4\u200b\u4f1a\u200b\u6709\u200b\u4e00\u5b9a\u200b\u4ea4\u53e0\u200b\u3002</p> <p></p>"},{"location":"function_modules/paper/shared_papers/store/#_3","title":"\u5185\u5bb9\u200b\u603b\u7ed3\u200b\uff1a","text":"<p>Labridge\u200b\u4f1a\u200b\u4f7f\u7528\u200b LLM \u200b\u5bf9\u200b\u52a0\u5165\u200b\u5171\u4eab\u200b\u6587\u732e\u200b\u5e93\u200b\u7684\u200b\u6bcf\u200b\u4e00\u7bc7\u200b\u6587\u732e\u200b\u7684\u200b<code>MainText</code>\u200b\u90e8\u5206\u200b\u4e0e\u200b<code>Methods</code>\u200b\u90e8\u5206\u200b\u8fdb\u884c\u200b\u603b\u7ed3\u200b\uff0c\u200b\u5e76\u200b\u6784\u5efa\u200b\u76f8\u5e94\u200b\u7684\u200bSummary\u200b\u5411\u91cf\u200b\u6570\u636e\u5e93\u200b(SummaryVectorIndex)\u3002 \u200b\u5bf9\u4e8e\u200b<code>MainText</code>\u200b\u4e0e\u200b<code>Methods</code>\u200b\u8fdb\u884c\u200b\u603b\u7ed3\u200b\u7684\u200b\u4fa7\u91cd\u70b9\u200b\u4e0d\u200b\u4e00\u6837\u200b\u3002\u200b\u5bf9\u4e8e\u200b<code>MainText</code>\u200b\u7684\u200b\u603b\u7ed3\u200b\u4fa7\u91cd\u4e8e\u200b\u6587\u7ae0\u200b\u7684\u200b\u6574\u4f53\u200b\u5185\u5bb9\u200b\uff0c\u200b\u4e3b\u8981\u200b\u521b\u65b0\u200b\u70b9\u200b\u7b49\u200b\uff1b \u200b\u5bf9\u4e8e\u200b<code>Methods</code>\u200b\u7684\u200b\u603b\u7ed3\u200b\u4fa7\u91cd\u4e8e\u200b\u6587\u7ae0\u200b\u4f7f\u7528\u200b\u7684\u200b\u6280\u672f\u200b\u8def\u5f84\u200b\u3002</p> <ul> <li>\u200b\u5185\u5bb9\u200b\u603b\u7ed3\u200b\u7684\u200b\u5177\u4f53\u200b\u7ec6\u8282\u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Func_modules.paper.synthesizer.summarize</code></li> <li>\u200b\u4e0e\u200bSummary\u200b\u5411\u91cf\u200b\u6570\u636e\u5e93\u200b\u76f8\u5173\u200b\u7684\u200b\u7ec6\u8282\u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Func_modules.paper.store.paper_store</code></li> <li><code>MainText</code>, <code>Methods</code>\u200b\u603b\u7ed3\u200b\u76f8\u5173\u200b\u63d0\u793a\u200b\u8bcd\u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b <code>func_modules.paper.prompt.synthesize.paper_summarize</code></li> </ul>"},{"location":"function_modules/paper/shared_papers/store/#_4","title":"\u6587\u732e\u200b\u76ee\u5f55\u200b\u603b\u7ed3\u200b\uff1a","text":"<p>Labridge\u200b\u4f7f\u7528\u200b LLM \u200b\u9012\u5f52\u200b\u5730\u4e3a\u200b\u6587\u732e\u200b\u4ed3\u5e93\u200b\u7684\u200b\u6bcf\u200b\u4e00\u7ea7\u200b\u76ee\u5f55\u200b\u751f\u6210\u200b\u8be5\u200b\u76ee\u5f55\u200b\u7684\u200b\u6587\u732e\u200b\u7b80\u4ecb\u200b\uff0c\u200b\u5982\u200b\u6bcf\u4e2a\u200b\u76ee\u5f55\u200b\u4e0b\u200b\u6587\u732e\u200b\u6d89\u53ca\u200b\u7684\u200b\u7814\u7a76\u200b\u9886\u57df\u200b\u7b49\u200b\u3002 \u200b\u8fd9\u4e9b\u200b\u4fe1\u606f\u200b\u4f1a\u200b\u4f5c\u4e3a\u200bLabridge\u200b\u4e3a\u200b\u5b9e\u9a8c\u5ba4\u200b\u6210\u5458\u200b\u63a8\u8350\u200b\u6587\u732e\u200b\u4ee5\u53ca\u200b\u5411\u200b\u5171\u4eab\u200b\u6587\u732e\u200b\u5e93\u200b\u63d2\u5165\u200b\u65b0\u200b\u6587\u732e\u200b\u7684\u200b\u91cd\u8981\u200b\u53c2\u8003\u200b\u3002 \u200b\u6587\u732e\u200b\u76ee\u5f55\u200b\u603b\u7ed3\u200b\u7684\u200b\u5177\u4f53\u200b\u7ec6\u8282\u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Func_modules.paper.store.paper_store</code></p>"},{"location":"function_modules/paper/shared_papers/store/#_5","title":"\u5171\u4eab\u200b\u6587\u732e\u200b\u7b14\u8bb0\u200b\u5411\u91cf\u200b\u6570\u636e\u5e93","text":"<p>\u200b\u5171\u4eab\u200b\u6587\u732e\u200b\u7b14\u8bb0\u200b\u5411\u91cf\u200b\u6570\u636e\u5e93\u200b\u7684\u200b\u7ed3\u6784\u200b\u5982\u4e0b\u200b\u56fe\u200b\u6240\u793a\u200b\u3002\u200b\u8be5\u200b\u6570\u636e\u5e93\u200b\u662f\u200b\u4e00\u4e2a\u200b\u8f83\u4e3a\u200b\u6241\u5e73\u5316\u200b\u7684\u200b\u6811\u5f62\u200b\u7ed3\u6784\u200b\uff0c\u200b\u7b2c\u4e00\u5c42\u200b\u8282\u70b9\u200b\u4e3a\u200b\u6587\u732e\u200b\u7684\u200bDOI\uff0c\u200b\u5bf9\u5e94\u200b\u4e00\u4efd\u200b\u72ec\u4e00\u65e0\u4e8c\u200b\u7684\u200b\u6587\u732e\u200b\uff0c\u200b\u5176\u5b50\u200b\u8282\u70b9\u200b\u4e3a\u200b \u200b\u4e0d\u200b\u4ea4\u53e0\u200b\u7684\u200b\u5185\u5bb9\u200b\u6587\u672c\u200b\u5757\u200b\uff0c\u200b\u4e14\u200b\u6587\u672c\u200b\u5757\u200b\u957f\u5ea6\u200b\u8f83\u200b\u77ed\u200b\uff0c\u200b\u4ee5\u200b\u63d0\u4f9b\u200b\u7cbe\u7ec6\u5316\u200b\u7684\u200b\u68c0\u7d22\u200b\u3002\u200b\u6bcf\u4e2a\u200b\u6587\u672c\u200b\u5757\u200b\u8282\u70b9\u200b\u7684\u200b\u5b50\u200b\u8282\u70b9\u200b\u4e3a\u200b\u7b14\u8bb0\u200b\u8282\u70b9\u200b\uff0c\u200b\u8bb0\u5f55\u200b\u8be5\u200b\u6587\u672c\u200b\u5757\u200b\u4e2d\u200b\u7528\u6237\u200b\u8bb0\u5f55\u200b\u7684\u200b\u7b14\u8bb0\u200b\u5185\u5bb9\u200b\u3002</p> <p></p>"},{"location":"function_modules/paper/temporary_papers/","title":"\u4e2a\u4eba\u200b\u8fd1\u671f\u200b\u6587\u732e\u200b\u5e93","text":"<p>Labridge\u200b\u4e3a\u200b\u5b9e\u9a8c\u5ba4\u200b\u6bcf\u4e2a\u200b\u6210\u5458\u200b\u63d0\u4f9b\u200b\u4e00\u4e2a\u200b\u72ec\u7acb\u200b\u7684\u200b\u4e34\u65f6\u200b\u6587\u732e\u200b\u5e93\u200b\uff0c\u200b\u8be5\u200b\u6587\u732e\u200b\u5e93\u4f1a\u200b\u5b58\u653e\u200bLabridge\u200b\u534f\u52a9\u200b\u6210\u5458\u200b\u4e0b\u8f7d\u200b\u7684\u200b\u6587\u732e\u200b\uff0c\u200b\u4e0e\u200b\u6210\u5458\u200b\u4e0a\u4f20\u200b\u7684\u200b\u6587\u732e\u200b\u3002 \u200b\u8be5\u200b\u4e34\u65f6\u200b\u6587\u732e\u200b\u5e93\u4f1a\u200b\u5b9a\u65f6\u200b\u6e05\u7406\u200b\uff0c\u200b\u5982\u679c\u200b\u8981\u200b\u6c38\u4e45\u200b\u4fdd\u5b58\u200b\uff0c\u200b\u6210\u5458\u200b\u53ef\u4ee5\u200b\u8981\u6c42\u200bLabridge\u200b\u5c06\u200b\u6709\u200b\u4ef7\u503c\u200b\u7684\u200b\u6587\u732e\u200b\u5b58\u653e\u200b\u8fdb\u200b\u5b9e\u9a8c\u5ba4\u200b\u5171\u4eab\u200b\u6587\u732e\u200b\u5e93\u200b\u3002</p>"},{"location":"function_modules/paper/temporary_papers/#_2","title":"\u6587\u732e\u200b\u5e93\u200b\u6784\u5efa","text":"<p>\u200b\u4e2a\u4eba\u200b\u8fd1\u671f\u200b\u6587\u732e\u200b\u5e93\u200b\u7ed3\u6784\u200b</p>"},{"location":"function_modules/paper/temporary_papers/#_3","title":"\u6587\u732e\u200b\u5e93\u200b\u68c0\u7d22","text":"<p>\u200b\u4e2a\u4eba\u200b\u8fd1\u671f\u200b\u6587\u732e\u200b\u5e93\u200b\u68c0\u7d22\u200b</p>"},{"location":"function_modules/paper/temporary_papers/retrieve/","title":"\u4e2a\u4eba\u200b\u4e34\u65f6\u200b\u6587\u732e\u200b\u5e93\u200b\u68c0\u7d22","text":"<p>\u200b\u5bf9\u4e8e\u200b\u4e2a\u4eba\u200b\u4e34\u65f6\u200b\u6587\u732e\u200b\u5e93\u200b\u7684\u200b\u68c0\u7d22\u200b\uff0c\u200b\u6211\u4eec\u200b\u540c\u6837\u200b\u91c7\u7528\u200b\u4e86\u200b\u591a\u7ea7\u200b\u6df7\u5408\u200b\u68c0\u7d22\u200b\u3002\u200b\u4e2a\u4eba\u200b\u4e34\u65f6\u200b\u6587\u732e\u200b\u5e93\u200b\u7684\u200b\u4f7f\u7528\u200b\u573a\u666f\u200b\u66f4\u200b\u591a\u200b\u5730\u200b\u662f\u200b\u9488\u5bf9\u200b\u67d0\u200b\u4e00\u7bc7\u200b\u7279\u5b9a\u200b\u6587\u732e\u200b\u8fdb\u884c\u200b\u8be2\u95ee\u200b\uff0c \u200b\u4e14\u200b\u5bf9\u4e8e\u200b\u65f6\u6548\u6027\u200b\u6709\u200b\u8f83\u200b\u9ad8\u200b\u8981\u6c42\u200b\u3002\u200b\u56e0\u6b64\u200b\u6211\u4eec\u200b\u91c7\u7528\u200b\u4e86\u200b \u200b\u6a21\u7cca\u200b\u68c0\u7d22\u200b\u5b9a\u4f4d\u200b\u6587\u732e\u200b\u8303\u56f4\u200b + \u200b\u8fdb\u4e00\u6b65\u200b\u76f8\u4f3c\u6027\u200b\u68c0\u7d22\u200b \u200b\u7684\u200b\u7b56\u7565\u200b\u3002</p> <p></p>"},{"location":"function_modules/paper/temporary_papers/retrieve/#_2","title":"\u6a21\u7cca\u200b\u68c0\u7d22\u200b\u786e\u5b9a\u200b\u6587\u732e\u200b\u8303\u56f4","text":"<p>\u200b\u9996\u5148\u200b\uff0cLabridge\u200b\u4f1a\u200b\u4ece\u200b\u5de5\u5177\u200b\u8c03\u7528\u200b\u65e5\u5fd7\u200b\u4ee5\u53ca\u200b\u804a\u5929\u8bb0\u5f55\u200b\u4e2d\u200b\u786e\u5b9a\u200b\u6240\u200b\u9700\u200b\u6587\u732e\u200b\u7684\u200b\u5927\u81f4\u200b\u4fe1\u606f\u200b(PaperInfo)\uff08\u200b\u5982\u200b\u6807\u9898\u200b\u3001\u200b\u6587\u4ef6\u200b\u8def\u5f84\u200b\u7b49\u200b\uff09\u3002 \u200b\u6839\u636e\u200b\u8be5\u200bPaperInfo\uff0cLabridge\u200b\u5728\u200b\u4e2a\u4eba\u200b\u4e34\u65f6\u200b\u6587\u732e\u200b\u5e93\u4e2d\u200b\u8fdb\u884c\u200b\u76f8\u4f3c\u6027\u200b\u68c0\u7d22\u200b\u83b7\u5f97\u200b\u76f8\u5173\u200bnodes\uff0c\u200b\u8fd9\u4e9b\u200bnodes\u200b\u6240\u5c5e\u200b\u7684\u200b\u6587\u732e\u200b\u5373\u200b\u4e3a\u200bLabridge\u200b\u5728\u200b \u200b\u4e0b\u200b\u4e00\u6b65\u200b\u68c0\u7d22\u200b\u4e2d\u200b\u7684\u200b\u68c0\u7d22\u200b\u8303\u56f4\u200b\u3002</p>"},{"location":"function_modules/paper/temporary_papers/retrieve/#_3","title":"\u65e5\u671f\u200b\u8fc7\u6ee4","text":"<p>Labridge\u200b\u53ef\u4ee5\u200b\u63d0\u4f9b\u200b\u8d77\u6b62\u200b\u65f6\u95f4\u200b\u6765\u200b\u8fdb\u4e00\u6b65\u200b\u7f29\u5c0f\u200b\u68c0\u7d22\u200b\u8303\u56f4\u200b\u3002</p>"},{"location":"function_modules/paper/temporary_papers/retrieve/#_4","title":"\u8fdb\u4e00\u6b65\u200b\u68c0\u7d22","text":"<p>\u200b\u5728\u200b\u8fd9\u200b\u4e00\u6b65\u200b\u68c0\u7d22\u200b\u4e2d\u200b\uff0cLabridge\u200b\u5728\u200b\u4e0a\u200b\u4e00\u6b65\u200b\u68c0\u7d22\u200b\u7684\u200b\u6587\u732e\u200b\u8303\u56f4\u200b\u4e2d\u200b\uff0c\u200b\u6839\u636e\u200b\u7528\u6237\u200b\u7684\u200b\u68c0\u7d22\u200b\u6587\u672c\u200b\u8fdb\u884c\u200b\u76f8\u4f3c\u6027\u200b\u68c0\u7d22\u200b\uff0c\u200b\u5e76\u200b\u83b7\u5f97\u200b\u6700\u200b\u76f8\u5173\u200b\u7684\u200b\u5185\u5bb9\u200b\u8282\u70b9\u200b(doc nodes)</p>"},{"location":"function_modules/paper/temporary_papers/retrieve/#_5","title":"\u6dfb\u52a0\u200b\u4e0a\u4e0b\u6587","text":"<p>\u200b\u53ef\u4ee5\u200b\u9009\u62e9\u200b\u4e3a\u200b\u68c0\u7d22\u200b\u5f97\u5230\u200b\u7684\u200b\u7ed3\u679c\u200b\u6dfb\u52a0\u200b\u4e0a\u4e0b\u6587\u200b\uff0c\u200b\u4f5c\u4e3a\u200b\u6700\u7ec8\u200b\u7ed3\u679c\u200b\u4f20\u7ed9\u200b LLM\uff0c\u200b\u4ee5\u200b\u907f\u514d\u200b\u6587\u672c\u200b\u5206\u5757\u200b\u5bfc\u81f4\u200b\u7684\u200b\u5185\u5bb9\u200b\u4e0d\u200b\u5b8c\u6574\u200b\u3002</p>"},{"location":"function_modules/paper/temporary_papers/store/","title":"\u4e2a\u4eba\u200b\u8fd1\u671f\u200b\u6587\u732e\u200b\u5e93\u200b\u7ed3\u6784","text":"<p>\u200b\u6bcf\u4e2a\u200b\u4e34\u65f6\u200b\u6587\u732e\u200b\u5e93\u200b\u90fd\u200b\u662f\u200b\u4e00\u4e2a\u200b\u5411\u91cf\u200b\u6570\u636e\u5e93\u200b\uff0c\u200b\u5b58\u50a8\u200b\u6bcf\u4e2a\u200b\u7528\u6237\u200b\u5404\u81ea\u200b\u8fd1\u671f\u200b\u7684\u200b\u6587\u732e\u200b\u3002\u200b\u5176\u200b\u7ed3\u6784\u200b\u5982\u4e0b\u200b\u56fe\u200b\u6240\u793a\u200b\uff1a</p> <p></p> <ul> <li>\u200b\u4e34\u65f6\u200b\u6587\u732e\u200b\u6587\u4ef6\u200b\u5b58\u653e\u200b\u5728\u200b\u9879\u76ee\u200b\u8def\u5f84\u200b <code>documents\\tmp_papers\\{user_id}</code>, \u200b\u4e34\u65f6\u200b\u6587\u732e\u200b\u5e93\u662f\u200b user-specific \u200b\u7684\u200b\u3002</li> <li>\u200b\u6bcf\u4e2a\u200b\u6587\u732e\u200b\u5e93\u5b58\u200b\u5728\u200b\u4e00\u4e2a\u200b\u6839\u200b\u8282\u70b9\u200b(root node), \u200b\u6240\u6709\u200b\u7684\u200b\u6587\u732e\u200b\u8282\u70b9\u200b(paper node)\u200b\u90fd\u200b\u662f\u200b\u6839\u200b\u8282\u70b9\u200b\u7684\u200b\u5b50\u200b\u8282\u70b9\u200b\u3002</li> <li>\u200b\u6587\u732e\u200b\u8282\u70b9\u200b\u7684\u200b<code>ID</code>\u200b\u4e3a\u200b\u8be5\u200b\u6587\u732e\u200b\u6587\u4ef6\u200b\u7684\u200b\u7edd\u5bf9\u8def\u5f84\u200b\u3002\u200b\u5176\u5b83\u200b\u989d\u5916\u200b\u4fe1\u606f\u200b\u5305\u62ec\u200b\u8be5\u200b\u6587\u4ef6\u200b\u5b58\u653e\u200b\u8fdb\u200b\u4e34\u65f6\u200b\u6587\u732e\u200b\u5e93\u200b\u7684\u200b\u65f6\u95f4\u200b(<code>date</code> <code>time</code>)\uff0c\u200b\u65f6\u95f4\u200b\u6233\u200b\u4fe1\u606f\u200b\u53ef\u4ee5\u200b\u7528\u4e8e\u200b\u5728\u200b\u68c0\u7d22\u200b\u8fc7\u7a0b\u200b\u4e2d\u200b\u8fdb\u884c\u200b\u65f6\u95f4\u200b\u8fc7\u6ee4\u200b\u3002</li> <li>\u200b\u6bcf\u7bc7\u200b\u6587\u732e\u200b\u7684\u200b\u6240\u6709\u200b\u5185\u5bb9\u200b\u8282\u70b9\u200b(doc node)\u200b\u4f5c\u4e3a\u200b\u5bf9\u5e94\u200b\u6587\u732e\u200b\u8282\u70b9\u200b\u7684\u200b\u5b50\u200b\u8282\u70b9\u200b\u3002</li> <li>\u200b\u5982\u679c\u200b\u8be5\u200b\u6210\u5458\u200b\u4f7f\u7528\u200b\u4e86\u200b\u6587\u732e\u200b\u603b\u7ed3\u200b\u529f\u80fd\u200b\uff0c\u200b\u76f8\u5e94\u200b\u7684\u200b\u6587\u732e\u200b\u603b\u7ed3\u200b\u6587\u672c\u200b\u4f1a\u200b\u4f5c\u4e3a\u200b\u5b50\u200b\u8282\u70b9\u200b\u52a0\u5165\u200b\u5bf9\u5e94\u200b\u7684\u200b\u6587\u732e\u200b\u8282\u70b9\u200b\u3002</li> </ul>"},{"location":"function_modules/paper/temporary_papers/download/arXiv/","title":"\u5728\u200barXiv\u200b\u4e0a\u200b\u68c0\u7d22\u200b\u4e0e\u200b\u4e0b\u8f7d\u200b\u6587\u732e","text":"<p>Labridge\u200b\u4f7f\u7528\u200barXiv\u200b\u63d0\u4f9b\u200b\u7684\u200bAPI, \u200b\u652f\u6301\u200b\u5f02\u6b65\u200b\u5730\u200b\u4ece\u200barXiv.org\u200b\u68c0\u7d22\u200b\u4e0e\u200b\u83b7\u53d6\u200b\u6587\u732e\u200b\u3002</p> <p>\u200b\u5177\u4f53\u200b\u7ec6\u8282\u200b\u53c2\u89c1\u200b \u200b\u6e90\u7801\u200b\u6587\u6863\u200b <code>Fun_modules.paper.download.arxiv</code></p>"},{"location":"function_modules/reference/","title":"\u53c2\u8003\u200b\u6587\u4ef6","text":""},{"location":"function_modules/reference/#_2","title":"\u201c\u200b\u6388\u4eba\u200b\u4ee5\u9c7c\u200b\u4e0d\u5982\u200b\u6388\u4eba\u4ee5\u6e14\u200b\u201d","text":"<p>\u200b\u4e3a\u4e86\u200b\u4fdd\u8bc1\u200bLabridge\u200b\u56de\u7b54\u200b\u7684\u200b\u53ef\u4fe1\u5ea6\u200b\u4e0e\u200b\u51c6\u786e\u6027\u200b\uff0c\u200b\u5728\u200b\u8c03\u7528\u200b\u68c0\u7d22\u200b\u7c7b\u200b\u76f8\u5173\u200b\u5de5\u5177\u200b\u65f6\u200b\uff0c\u200b\u8be5\u200b\u5de5\u5177\u200b\u540c\u65f6\u200b\u4f1a\u200b\u8fd4\u56de\u200b\u53c2\u8003\u200b\u7684\u200b\u6587\u4ef6\u200b\u4fe1\u606f\u200b\u3002</p> <p>\u200b\u6b64\u5916\u200b\uff0cLabridge\u200b\u7684\u200b\u76ee\u6807\u200b\u4e0d\u4ec5\u4ec5\u200b\u662f\u200b\u7ed9\u51fa\u200b\u6b63\u786e\u200b\u7ed3\u679c\u200b\uff0cLabridge\u200b\u8fd8\u200b\u81f4\u529b\u4e8e\u200b\u4fc3\u8fdb\u200b\u77e5\u8bc6\u200b\u7684\u200b\u6d41\u52a8\u200b\uff0c\u200b\u6388\u4eba\u4ee5\u6e14\u200b\u3002\u200b\u56e0\u6b64\u200b\u53c2\u8003\u200b\u6587\u4ef6\u200b\u662f\u200b\u5341\u5206\u200b\u6709\u200b\u5fc5\u8981\u200b\u7684\u200b\u3002</p> <ul> <li>\u200b\u53c2\u8003\u6587\u732e\u200b</li> <li>\u200b\u53c2\u8003\u200b\u4eea\u5668\u200b\u6587\u6863\u200b</li> </ul>"},{"location":"function_modules/reference/instrument_reference/","title":"\u53c2\u8003\u200b\u4eea\u5668\u200b\u6587\u6863","text":"<p>\u200b\u53c2\u8003\u200b\u4eea\u5668\u200b\u6587\u6863\u200b\u4fe1\u606f\u200b\u5305\u542b\u200b\u5982\u4e0b\u200b\u5185\u5bb9\u200b\uff1a</p> <ul> <li>\u200b\u4eea\u5668\u200b\u540d\u79f0\u200b</li> <li>\u200b\u8be5\u200b\u4eea\u5668\u200b\u7684\u200b Super Users</li> </ul>"},{"location":"function_modules/reference/paper_reference/","title":"\u53c2\u8003\u6587\u732e","text":"<p>\u200b\u53c2\u8003\u6587\u732e\u200b\u4fe1\u606f\u200b\u5305\u542b\u200b\u5982\u4e0b\u200b\u5185\u5bb9\u200b\uff1a</p> <ul> <li>\u200b\u6587\u732e\u200b\u6807\u9898\u200b</li> <li>\u200b\u6587\u732e\u200b\u8def\u5f84\u200b</li> <li>\u200b\u62e5\u6709\u200b\u8be5\u200b\u6587\u732e\u200b\u7684\u200b\u6210\u5458\u200b\u3002</li> </ul>"},{"location":"interface/app/","title":"App\u200b\u4ea4\u4e92\u200b\u754c\u9762","text":"<p>\u200b\u6211\u4eec\u200b\u4e3a\u200b\u7528\u6237\u200b\u4e0e\u200bLabridge\u200b\u7684\u200b\u4ea4\u4e92\u200b\u63d0\u4f9b\u200bapp\u200b\u4ea4\u4e92\u200b\u754c\u9762\u200b\uff0c\u200b\u5982\u4e0b\u200b\u56fe\u200b\u6240\u793a\u200b\u3002</p> <p></p>"},{"location":"interface/app/#_1","title":"\u591a\u6837\u5316\u200b\u4ea4\u4e92\u65b9\u5f0f","text":"<p>Labridge\u200b\u652f\u6301\u200b\u591a\u6837\u5316\u200b\u7684\u200b\u4ea4\u4e92\u65b9\u5f0f\u200b\uff1a\u200b\u6587\u5b57\u200b\uff0c\u200b\u8bed\u97f3\u200b\uff0c\u200b\u6587\u4ef6\u200b\u7b49\u200b\uff1b</p> <p>Labridge\u200b\u8fd8\u200b\u652f\u6301\u200b\u4f7f\u200b\u7528\u6237\u200b\u4ecb\u5165\u200b\u667a\u80fd\u200b\u4f53\u200b\u7684\u200b\u601d\u8003\u200b\u4e0e\u200b\u51b3\u7b56\u200b\u7684\u200b\u5f00\u53d1\u8005\u200b\u6a21\u5f0f\u200b\u3002</p> <p> </p>"},{"location":"interface/app/#app_1","title":"App\u200b\u4ee3\u7801\u200b\u63cf\u8ff0\u200b\u4e0e\u200b\u7f16\u8bd1\u200b\u8bf4\u660e","text":""},{"location":"interface/server-client/","title":"Server\u200b\u4e0e\u200bClient\u200b\u4e4b\u95f4\u200b\u7684\u200b\u901a\u4fe1\u200b\u8bf4\u660e","text":""},{"location":"interface/server-client/#_1","title":"\u6570\u636e\u7ed3\u6784\u200b\uff1a","text":""},{"location":"interface/server-client/#client","title":"Client\u200b\u4e0a\u4f20\u200b\u7684\u200b\u6570\u636e\u200b\uff1a","text":""},{"location":"interface/server-client/#chat-with-text","title":"Chat with text:","text":"<p>ClientTextReq: - text (str): \u200b\u7528\u6237\u200b\u7684\u200b\u6d88\u606f\u200b\u5b57\u7b26\u4e32\u200b - reply_in_speech (bool): \u200b\u7528\u6237\u200b\u5e0c\u671b\u200b\u5f97\u5230\u200b\u8bed\u97f3\u200b\u56de\u590d\u200b\u8fd8\u662f\u200b\u6587\u672c\u200b\u56de\u590d\u200b\u3002 - enable_instruct (bool): \u200b\u5f53\u524d\u200b\u8f6e\u6b21\u200bQA, \u200b\u7528\u6237\u200b\u662f\u5426\u200b\u4ecb\u5165\u200bAgent\u200b\u7684\u200bReasoning - enable_comment (bool): \u200b\u5f53\u524d\u200b\u8f6e\u6b21\u200bQA, \u200b\u7528\u6237\u200b\u662f\u5426\u200b\u4ecb\u5165\u200bAgent\u200b\u7684\u200bActing</p> <p>Post URL: <code>/users/{user_id}/chat_text</code></p>"},{"location":"interface/server-client/#download-file","title":"Download File:","text":"<p>ClientDownloadReq: - filepath (str): \u200b\u7533\u8bf7\u200b\u4e0b\u8f7d\u200b\u7684\u200b\u6587\u4ef6\u200b\u8def\u5f84\u200b</p> <p>Post URL: <code>/users/{user_id}/files/bytes</code></p>"},{"location":"interface/server-client/#chat-with-file","title":"Chat with file:","text":"<ul> <li>file (bytes): \u200b\u4e0a\u4f20\u200b\u6587\u4ef6\u200b\u7684\u200b\u4e8c\u8fdb\u5236\u200b\u6570\u636e\u200b</li> <li>file_name (str): \u200b\u4e0a\u4f20\u200b\u6587\u4ef6\u200b\u7684\u200b\u6587\u4ef6\u540d\u200b\uff08\u200b\u5305\u542b\u200b\u540e\u7f00\u200b\uff09</li> <li>text (str): \u200b\u7528\u6237\u200b\u4e0e\u200b\u8be5\u200b\u6587\u4ef6\u200b\u76f8\u5173\u200b\u7684\u200b\u6d88\u606f\u200b</li> <li>reply_in_speech (bool): \u200b\u7528\u6237\u200b\u5e0c\u671b\u200b\u5f97\u5230\u200b\u8bed\u97f3\u200b\u56de\u590d\u200b\u8fd8\u662f\u200b\u6587\u672c\u200b\u56de\u590d\u200b\u3002</li> <li>enable_instruct (bool): \u200b\u5f53\u524d\u200b\u8f6e\u6b21\u200bQA, \u200b\u7528\u6237\u200b\u662f\u5426\u200b\u4ecb\u5165\u200bAgent\u200b\u7684\u200bReasoning</li> <li>enable_comment (bool): \u200b\u5f53\u524d\u200b\u8f6e\u6b21\u200bQA, \u200b\u7528\u6237\u200b\u662f\u5426\u200b\u4ecb\u5165\u200bAgent\u200b\u7684\u200bActing</li> </ul> <p>Post URL: <code>/users/{user_id}/chat_with_file</code></p>"},{"location":"interface/server-client/#chat-with-speech","title":"Chat with speech:","text":"<ul> <li>file (bytes): \u200b\u8bed\u97f3\u200b\u6587\u4ef6\u200b\u7684\u200b\u4e8c\u8fdb\u5236\u200b\u6570\u636e\u200b</li> <li>enable_instruct (bool): \u200b\u5f53\u524d\u200b\u8f6e\u6b21\u200bQA, \u200b\u7528\u6237\u200b\u662f\u5426\u200b\u4ecb\u5165\u200bAgent\u200b\u7684\u200bReasoning</li> <li>enable_comment (bool): \u200b\u5f53\u524d\u200b\u8f6e\u6b21\u200bQA, \u200b\u7528\u6237\u200b\u662f\u5426\u200b\u4ecb\u5165\u200bAgent\u200b\u7684\u200bActing</li> </ul> <p>Post URL: <code>/users/{user_id}/chat_speech</code></p>"},{"location":"interface/server-client/#server","title":"\u4ece\u200bServer\u200b\u83b7\u53d6\u200b\u56de\u590d\u200b:","text":"<p>Get URL: <code>/users/{user_id}/response</code></p>"},{"location":"interface/server-client/#_2","title":"\u8fd4\u56de\u200b\u7684\u200b\u6570\u636e\u7ed3\u6784","text":"<p>ServerReply: - reply_text (str): Agent\u200b\u7684\u200b\u56de\u590d\u200b\u5b57\u7b26\u4e32\u200b - valid (bool): \u200b\u672c\u200b\u56de\u590d\u200b\u662f\u5426\u662f\u200b\u6709\u6548\u200b\u56de\u590d\u200b\uff0c\u200b\u82e5\u200b\u6ca1\u6709\u200b\u5f97\u5230\u200b\u6709\u6548\u200b\u56de\u590d\u200b\uff0c\u200b\u5ba2\u6237\u7aef\u200b\u5e94\u200b\u8f6e\u8be2\u200b\u76f4\u81f3\u200b\u83b7\u5f97\u200b\u6709\u6548\u200b\u56de\u590d\u200b - references (Dict[str, int]): \u200b\u53c2\u8003\u200b\u6587\u4ef6\u200b\u5728\u200bserver\u200b\u7684\u200b\u5b58\u50a8\u200b\u8def\u5f84\u200b\u4e0e\u200b\u6587\u4ef6\u200b\u5b57\u8282\u6570\u200b\u3002 - error (str): \u200b\u9519\u8bef\u4fe1\u606f\u200b\uff0c\u200b\u5982\u679c\u200b\u6ca1\u6709\u200b\u9519\u8bef\u200b\uff0c\u200b\u5219\u200b\u4e3a\u200b<code>None</code>. - inner_chat (bool): \u200b\u672c\u200b\u56de\u590d\u200b\u662f\u5426\u662f\u200b\u4e00\u4e2a\u200bChat\u200b\u8c03\u7528\u200b\u5185\u90e8\u200b\u7684\u200b\u56de\u590d\u200b\u3002\u200b\u5982\u679c\u200b\u4e3a\u200b<code>True</code>, \u200b\u5ba2\u6237\u7aef\u200b\u5e94\u8be5\u200b\u628a\u200b\u7528\u6237\u200b\u63a5\u4e0b\u6765\u200b\u7684\u200b\u56de\u590d\u200b\u53d1\u9001\u5230\u200b\u76f8\u5e94\u200b\u7684\u200b <code>Inner</code> URL.</p> <p>ServerSpeechReply: - reply_speech (Dict[str, int]): Key: Agent\u200b\u56de\u590d\u200b\u7684\u200b\u8bed\u97f3\u200b\u6587\u4ef6\u200b\u5728\u200bServer\u200b\u7684\u200b\u5b58\u50a8\u200b\u8def\u5f84\u200b, Value: \u200b\u8bed\u97f3\u200b\u6587\u4ef6\u200b\u5b57\u8282\u6570\u200b\u3002 - valid (bool): \u200b\u672c\u200b\u56de\u590d\u200b\u662f\u5426\u662f\u200b\u6709\u6548\u200b\u56de\u590d\u200b\uff0c\u200b\u82e5\u200b\u6ca1\u6709\u200b\u5f97\u5230\u200b\u6709\u6548\u200b\u56de\u590d\u200b\uff0c\u200b\u5ba2\u6237\u7aef\u200b\u5e94\u200b\u8f6e\u8be2\u200b\u76f4\u81f3\u200b\u83b7\u5f97\u200b\u6709\u6548\u200b\u56de\u590d\u200b - references (Dict[str, int]): \u200b\u53c2\u8003\u200b\u6587\u4ef6\u200b\u5728\u200bserver\u200b\u7684\u200b\u5b58\u50a8\u200b\u8def\u5f84\u200b\u4e0e\u200b\u6587\u4ef6\u200b\u5b57\u8282\u6570\u200b\u3002 - inner_chat: Optional[bool] = False - error (str): \u200b\u9519\u8bef\u4fe1\u606f\u200b\uff0c\u200b\u5982\u679c\u200b\u6ca1\u6709\u200b\u9519\u8bef\u200b\uff0c\u200b\u5219\u200b\u4e3a\u200b<code>None</code>.</p>"},{"location":"interface/server-client/#inner-url","title":"\u76f8\u5e94\u200b\u7684\u200b Inner URL:","text":""},{"location":"interface/server-client/#chat-with-text_1","title":"Chat with text:","text":"<p>Inner URL: <code>/users/{user_id}/inner_chat_text</code></p>"},{"location":"interface/server-client/#chat-with-speech_1","title":"Chat with speech:","text":"<p>Inner URL: <code>/users/{user_id}/inner_chat_speech</code></p>"},{"location":"interface/server-client/#chat-with-file_1","title":"Chat with file:","text":"<p>Inner URL: <code>/users/{user_id}/inner_chat_with_file</code></p>"},{"location":"interface/web_ui/","title":"Web\u200b\u4ea4\u4e92\u200b\u754c\u9762","text":"<p>\u200b\u6211\u4eec\u200b\u4e3a\u200b\u7528\u6237\u200b\u4e0e\u200bLabridge\u200b\u7684\u200b\u4ea4\u4e92\u200b\u63d0\u4f9b\u200bweb\u200b\u4ea4\u4e92\u200b\u754c\u9762\u200b\uff0c\u200b\u5982\u4e0b\u200b\u56fe\u200b\u6240\u793a\u200b\u3002</p>"},{"location":"interface/web_ui/#web_1","title":"Web\u200b\u754c\u9762\u200b\u4ee3\u7801\u200b\u63cf\u8ff0\u200b\u4e0e\u200b\u7f16\u8bd1\u200b\u6d41\u7a0b","text":"<p>\u200b\u4f7f\u7528\u200b\u4e86\u200b\u4ec0\u4e48\u200b\u8bed\u8a00\u200b\uff0c\u200b\u57fa\u4e8e\u200b\u4ec0\u4e48\u200b\u6846\u67b6\u200b\u5f00\u53d1\u200b\uff0c\u200b\u5982\u4f55\u200b\u8fdb\u884c\u200b\u7f16\u8bd1\u200b\u3002</p>"},{"location":"overview/introduction/","title":"This is the inner introduction.","text":""}]}